package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Catalan ; public class CatalanConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Catalan ( ) ; } @ Override protected String createSampleText ( ) { return "Si tot i així encara no apareix, potser la pàgina ha estat suprimida." ; } }
package org . languagetool . rules . es ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Spanish ; import org . languagetool . rules . GenericUnpairedBracketsRule ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Collections ; public class GenericUnpairedBracketsRuleTest extends TestCase { private GenericUnpairedBracketsRule rule ; private JLanguageTool langTool ; public void testSpanishRule ( ) throws IOException { langTool = new JLanguageTool ( new Spanish ( ) ) ; rule = org . languagetool . rules . GenericUnpairedBracketsRuleTest . getBracketsRule ( langTool ) ; assertMatches ( "Soy un hombre (muy honrado)." , 0 ) ; assertMatches ( "De dónde vas?" , 1 ) ; assertMatches ( "¡Atención" , 1 ) ; } private void assertMatches ( String input , int expectedMatches ) throws IOException { final RuleMatch [ ] matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( input ) ) ) ; assertEquals ( expectedMatches , matches . length ) ; } }
package org . languagetool . rules . es ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class SpanishPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . es ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Spanish ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import static org . junit . Assert . assertEquals ; public class MorfologikSpanishSpellerRuleTest { @ Test public void testMorfologikSpeller ( ) throws IOException { Spanish language = new Spanish ( ) ; MorfologikSpanishSpellerRule rule = new MorfologikSpanishSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Escriba un texto aquí. LanguageTool le ayudará a afrontar algunas dificultades propias de la escritura." ) ) . length ) ; RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "Se a hecho un esfuerzo para detectar errores tipográficos, ortograficos y incluso gramaticales." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 59 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 71 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( "ortográficos" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . tagging . es ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Spanish ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; public class SpanishTaggerTest extends TestCase { private SpanishTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new SpanishTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Spanish ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "Soy un hombre muy honrado." , "Soy/[ser]VSIP1S0 -- un/[uno]DI0MS0 -- hombre/[hombre]I|hombre/[hombre]NCMS000 -- muy/[muy]RG -- honrado/[honrar]VMP00SM" , tokenizer , tagger ) ; TestTools . myAssert ( "Tengo que ir a mi casa." , "Tengo/[tener]VMIP1S0 -- que/[que]CS|que/[que]PR0CN000 -- ir/[ir]VMN0000 -- a/[a]NCFS000|a/[a]SPS00 -- mi/[mi]DP1CSS|mi/[mi]NCMS000 -- casa/[casa]NCFS000|casa/[casar]VMIP3S0|casa/[casar]VMM02S0" , tokenizer , tagger ) ; TestTools . myAssert ( "blablabla" , "blablabla/[null]null" , tokenizer , tagger ) ; } }
package org . languagetool . language ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . es . MorfologikSpanishSpellerRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . es . SpanishSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . es . SpanishHybridDisambiguator ; import org . languagetool . tagging . es . SpanishTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . es . SpanishWordTokenizer ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; public class Spanish extends Language { private SentenceTokenizer sentenceTokenizer ; private Tokenizer wordTokenizer ; private Synthesizer synthesizer ; private Tagger tagger ; private Disambiguator disambiguator ; @ Override public String getName ( ) { return "Spanish" ; } @ Override public String getShortName ( ) { return "es" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "ES" , "" , "MX" , "GT" , "CR" , "PA" , "DO" , "VE" , "PE" , "AR" , "EC" , "CL" , "UY" , "PY" , "BO" , "SV" , "HN" , "NI" , "PR" , "US" , "CU" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new SpanishTagger ( ) ; } return tagger ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new SpanishHybridDisambiguator ( ) ; } return disambiguator ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new SpanishWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new SpanishSynthesizer ( ) ; } return synthesizer ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Juan Martorell" , "http://languagetool-es.blogspot.com/" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages , Arrays . asList ( "[" , "(" , "{" , "“" , "«" , "»" , "¿" , "¡" ) , Arrays . asList ( "]" , ")" , "}" , "”" , "»" , "«" , "?" , "!" ) ) , new MorfologikSpanishSpellerRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new WordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) ) ; } }
package org . languagetool . synthesis . es ; import org . languagetool . synthesis . BaseSynthesizer ; public class SpanishSynthesizer extends BaseSynthesizer { private static final String RESOURCE_FILENAME = "/es/spanish_synth.dict" ; private static final String TAGS_FILE_NAME = "/es/spanish_tags.txt" ; public SpanishSynthesizer ( ) { super ( RESOURCE_FILENAME , TAGS_FILE_NAME ) ; } }
package org . languagetool . rules . es ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; import java . io . IOException ; import java . util . ResourceBundle ; public class MorfologikSpanishSpellerRule extends MorfologikSpellerRule { public MorfologikSpanishSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return "/es/hunspell/es_ES.dict" ; } @ Override public final String getId ( ) { return "MORFOLOGIK_RULE_ES" ; } }
package org . languagetool . rules . es ; import org . languagetool . rules . Rule ; public abstract class SpanishRule extends Rule { }
package org . languagetool . tagging . es ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class SpanishTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/es/added.txt" ; } public SpanishTagger ( ) { super ( "/es/spanish.dict" , new Locale ( "es" ) ) ; } }
package org . languagetool . tagging . disambiguation . es ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . language . Spanish ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . MultiWordChunker ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; public class SpanishHybridDisambiguator implements Disambiguator { private final Disambiguator chunker = new MultiWordChunker ( "/es/multiwords.txt" ) ; private final Disambiguator disambiguator = new XmlRuleDisambiguator ( new Spanish ( ) ) ; @ Override public final AnalyzedSentence disambiguate ( AnalyzedSentence input ) throws IOException { return disambiguator . disambiguate ( chunker . disambiguate ( input ) ) ; } }
package org . languagetool . rules . ca ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class ReflexiveVerbsRuleTest extends TestCase { private ReflexiveVerbsRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new ReflexiveVerbsRule ( TestTools . getEnglishMessages ( ) ) ; langTool = new JLanguageTool ( new Catalan ( ) ) ; } public void testRule ( ) throws IOException { assertCorrect ( "Alguns ens adonàrem que era veritat" ) ; assertCorrect ( "M'he baixat moltes imatges" ) ; assertCorrect ( "baixeu-vos l'Aspell des de http://aspell.net/win32/" ) ; assertCorrect ( "els fitxers de traducció es baixaran automàticament" ) ; assertCorrect ( "Baixeu-vos el programa de l'enllaç" ) ; assertCorrect ( "No em plantejo anar a un altre partit" ) ; assertCorrect ( "-Deixa't caure al canal i prou" ) ; assertCorrect ( "Deixa't caure al canal i prou" ) ; assertCorrect ( "Durant el 2010 s'ha crescut molt" ) ; assertCorrect ( "de què tant ens queixem" ) ; assertCorrect ( "cada zona més meridional esdevingué adient per als éssers àrtics" ) ; assertCorrect ( "cereals, garrofers, vinya i olivar." ) ; assertCorrect ( "m'aniria bé probablement posar els quilos" ) ; assertCorrect ( "tot m'aniria bé" ) ; assertCorrect ( "tot m'havia anat bé" ) ; assertCorrect ( "tot m'havia anat molt bé fins que m'ha passat" ) ; assertCorrect ( "el cor m'anava a cent per hora." ) ; assertIncorrect ( "Jo m'anava a cent per hora." ) ; assertIncorrect ( "M'anava a casa a cent per hora." ) ; assertCorrect ( "Sempre li havia anat bé" ) ; assertCorrect ( "Em va bé" ) ; assertIncorrect ( "Sempre t'havies anat bé" ) ; assertCorrect ( "Sempre m'havia vingut bé" ) ; assertCorrect ( "Sempre m'havia anat bé" ) ; assertCorrect ( "T'agraeixo molt que m'hagis deixat robar-te una mica del teu temp" ) ; assertCorrect ( "sense haver-s'hi d'esforçar gaire" ) ; assertCorrect ( "cosa que li permetia, sense haver-s'hi d'esforçar gaire, seguir entre classe i classe" ) ; assertCorrect ( "fins que no em vingui la inspiració" ) ; assertCorrect ( "Si no ho trobes bé, vés-te a queixar al director" ) ; assertCorrect ( "potser em vindria de gust fer un mossec" ) ; assertCorrect ( "li ho va fer empassar de cop" ) ; assertCorrect ( "i matar-se caient de més de vuitanta peus d'altura" ) ; assertCorrect ( "Deixa de portar-me la contra." ) ; assertCorrect ( "quan ja es tornava a envolar li va caure aquest" ) ; assertCorrect ( "Van fer agenollar els presos" ) ; assertCorrect ( "Deixa'm dir-t'ho a l'orella" ) ; assertCorrect ( "Em deixes demanar-te una cosa?" ) ; assertCorrect ( "havien fet desbocar un cavall sense brida" ) ; assertCorrect ( "quan el vent ja m'hauria portat les rondalles" ) ; assertCorrect ( "Llavors m'oloro les mans" ) ; assertCorrect ( "Hem de poder-nos queixar" ) ; assertCorrect ( "Ens hem de poder queixar" ) ; assertCorrect ( "Després d'acomiadar-nos vam pujar a la nau" ) ; assertCorrect ( "li havia impedit defensar-se." ) ; assertCorrect ( "L'instant que havia trigat a fer-lo li havia impedit defensar-se." ) ; assertCorrect ( "quan ja s’olorava en l’aire la primavera" ) ; assertCorrect ( "que la vergonya em pugés a les galtes" ) ; assertCorrect ( "En Feliu em fa dir-te que el dispensis" ) ; assertCorrect ( "i que ja em vindria la son" ) ; assertCorrect ( "La mort del pare m’havia portat la imatge d’aquests morts" ) ; assertCorrect ( "Una onada de foc em pujava del pit a la cara." ) ; assertCorrect ( "D'aquest Decret se n'ha donat compte al Ple de l'Ajuntament" ) ; assertCorrect ( "Encara em cal donar compte d'un altre recull" ) ; assertCorrect ( "Michael Kirby ens dóna compte a Anàlisi estructural" ) ; assertIncorrect ( "Ell es va donar compte de l'error" ) ; assertIncorrect ( "Joan es va donar compte de l'error" ) ; assertIncorrect ( "Algú se n'hauria de donar compte." ) ; assertIncorrect ( "Vas donar-te compte de l'error" ) ; assertIncorrect ( "llavors comenten discretament l'afer i es callen, tanmateix, els noms" ) ; assertCorrect ( "el qui amb mi delira està lliure" ) ; assertCorrect ( "per venir-vos a veure " ) ; assertCorrect ( "No li ho ensenyis, que el faràs delir." ) ; assertCorrect ( "per a portar-te aigua" ) ; assertCorrect ( "que no em costi d'anar al llit" ) ; assertCorrect ( "el senyor Colomines s'anà progressivament reposant" ) ; assertCorrect ( "en sentir els plors s'encongeix automàticament," ) ; assertCorrect ( "La penya de l'Ateneu es va de mica en mica reconstruint" ) ; assertCorrect ( "no m'he pogut endur l'espasa" ) ; assertCorrect ( "un llop es podria haver endut la criatura" ) ; assertCorrect ( "Quan se'l van haver endut a casa" ) ; assertCorrect ( "Ja et deus haver adonat que no" ) ; assertCorrect ( "fins que se'n va haver desempallegat" ) ; assertCorrect ( "per haver-se deixat endur per l'orgull" ) ; assertCorrect ( "i de venir-vos a trobar" ) ; assertCorrect ( "el sol s'havia post, li anaven portant tots els malalts" ) ; assertCorrect ( "que no em caigui la casa" ) ; assertCorrect ( "que no em caigui al damunt res" ) ; assertCorrect ( "Em queia bé." ) ; assertCorrect ( "Els qui s'havien dispersat van anar pertot arreu" ) ; assertCorrect ( "Els qui volen enriquir-se cauen en temptacions" ) ; assertCorrect ( "Després d'acomiadar-nos, vam pujar a la nau" ) ; assertCorrect ( "que em vingui a ajudar" ) ; assertCorrect ( "fins i tot us vendríeu un amic" ) ; assertCorrect ( "ens hem esforçat molt per venir-vos a veure" ) ; assertCorrect ( "Un altre dia s'anava a l'Ermita i un tercer dia se solia anar a altres indrets de caràcter comarcal." ) ; assertCorrect ( "La nit de sant Joan es baixaven falles de la muntanya." ) ; assertCorrect ( "que no pertanyen a ells mateixos es cau en una contradicció." ) ; assertCorrect ( "Els salts els fan impulsant-se amb les cames" ) ; assertCorrect ( "Zheng, adonant-se que gairebé totes les forces singaleses" ) ; assertCorrect ( "que s'havien anat instal·lant" ) ; assertCorrect ( "gràcies a la presència del Riu Set s'hi alberga una gran arboreda amb taules" ) ; assertCorrect ( "no fa gaires anys també s'hi portaven alguns animals" ) ; assertCorrect ( "el sòlid es va \"descomponent\"." ) ; assertCorrect ( "la divisió s'ha d'anar amb cura per evitar ambigüitats" ) ; assertCorrect ( "la senyera s'ha de baixar" ) ; assertCorrect ( "Es van témer assalts a altres edificis de la CNT " ) ; assertCorrect ( "que Joan em dugués el mocador" ) ; assertCorrect ( "em duràs un mocador de seda del teu color" ) ; assertCorrect ( "El va deixar per a dedicar-se a la música" ) ; assertCorrect ( "Hermes s'encarregava de dur les ànimes que acabaven de morir a l'Inframón" ) ; assertCorrect ( "aquest nom és poc adequat ja que es poden portar les propostes de l'escalada clàssica" ) ; assertCorrect ( "en fer-lo girar se'n podia observar el moviment" ) ; assertCorrect ( "el segon dia es duien a terme les carreres individuals" ) ; assertCorrect ( "Normalment no es duu un registre oficial extern" ) ; assertCorrect ( "Ens portem força bé" ) ; assertCorrect ( "Hem de portar-nos bé" ) ; assertCorrect ( "Ells es porten tres anys" ) ; assertCorrect ( "Fan que em malfiï." ) ; assertCorrect ( "Em fan malfiar." ) ; assertCorrect ( "El fan agenollar." ) ; assertCorrect ( "ens anem a aferrissar" ) ; assertCorrect ( "anem a aferrissar-nos" ) ; assertCorrect ( "ens preparem per a anar" ) ; assertCorrect ( "comencen queixant-se" ) ; assertCorrect ( "comenceu a queixar-vos" ) ; assertCorrect ( "no em podia pas queixar" ) ; assertCorrect ( "em puc queixar" ) ; assertCorrect ( "en teniu prou amb queixar-vos" ) ; assertCorrect ( "ens en podem queixar" ) ; assertCorrect ( "es queixa" ) ; assertCorrect ( "es va queixant" ) ; assertCorrect ( "es va queixar" ) ; assertCorrect ( "has d'emportar-t'hi" ) ; assertCorrect ( "has de poder-te queixar" ) ; assertCorrect ( "t'has de poder queixar" ) ; assertCorrect ( "havent-se queixat" ) ; assertCorrect ( "haver-se queixat" ) ; assertCorrect ( "no es va poder emportar" ) ; assertCorrect ( "no has de poder-te queixar" ) ; assertCorrect ( "no has de queixar-te" ) ; assertCorrect ( "no podeu deixar de queixar-vos" ) ; assertCorrect ( "no t'has de queixar" ) ; assertCorrect ( "no us podeu deixar de queixar" ) ; assertCorrect ( "pareu de queixar-vos" ) ; assertCorrect ( "podent abstenir-se" ) ; assertCorrect ( "poder-se queixar" ) ; assertCorrect ( "podeu queixar-vos" ) ; assertCorrect ( "queixa't" ) ; assertCorrect ( "queixant-vos" ) ; assertCorrect ( "queixar-se" ) ; assertCorrect ( "queixeu-vos" ) ; assertCorrect ( "s'ha queixat" ) ; assertCorrect ( "se li ha queixat" ) ; assertCorrect ( "se li queixa" ) ; assertCorrect ( "se li va queixar" ) ; assertCorrect ( "va decidir suïcidar-se" ) ; assertCorrect ( "va queixant-se" ) ; assertCorrect ( "va queixar-se" ) ; assertCorrect ( "va queixar-se-li" ) ; assertCorrect ( "Se'n pujà al cel" ) ; assertCorrect ( "Se li'n va anar la mà" ) ; assertCorrect ( "El nen pot callar" ) ; assertCorrect ( "es va desfent" ) ; assertCorrect ( "s'ha anat configurant" ) ; assertCorrect ( "s'han anat fabricant amb materials" ) ; assertCorrect ( "la matèria que cau s'accelera" ) ; assertCorrect ( "Altres muntanyes foren pujades per pastors, caçadors o aventurers." ) ; assertCorrect ( "mai assolí èxit social" ) ; assertCorrect ( "Aquests polímers són lineals i no ramificats." ) ; assertCorrect ( "tornaven a assolar la Vall de l'Ebre." ) ; assertCorrect ( "està previst que s'acabin per a anar directament a la zona" ) ; assertCorrect ( "es deixaven caure" ) ; assertCorrect ( "es van deixar caure" ) ; assertCorrect ( "van deixar-se caure" ) ; assertCorrect ( "et deixaves pujar" ) ; assertCorrect ( "Els animals es feien témer amb cops secs de ferro" ) ; assertCorrect ( "es veié obligat a marxar el 1512." ) ; assertCorrect ( "Francesc III es va anar a asseure sobre el tron" ) ; assertCorrect ( "Va anar a dutxar-se" ) ; assertCorrect ( "es va anar a dutxar" ) ; assertCorrect ( "es van deixar anar molts empresonats." ) ; assertCorrect ( "A Joan se li'n va anar la mà" ) ; assertCorrect ( "se'ns en va anar la mà" ) ; assertCorrect ( "ja que si l'arròs se sega molt verd" ) ; assertCorrect ( "s'hi afegeixen bolets abans d'enfundar-la en l'intestí" ) ; assertCorrect ( "Joan ha anat a fer-se la prova." ) ; assertCorrect ( "Cada grup s'ha anat a dutxar." ) ; assertCorrect ( "Joan ha anat a dutxar-se." ) ; assertCorrect ( "Joan s'ha anat a dutxar." ) ; assertCorrect ( "amb els Confederats intentant burlar el bloqueig a Maryland." ) ; assertCorrect ( "l'altre es duu la mà al llavi inferior" ) ; assertCorrect ( "l'altre s'olora les mans" ) ; assertCorrect ( "Es pot baixar la darrera versió." ) ; assertCorrect ( "Se'l va fer callar." ) ; assertCorrect ( "Se li va fer callar." ) ; assertCorrect ( "Se'ns va fer callar." ) ; assertCorrect ( "També es canta quan es va a pasturar als animals" ) ; assertCorrect ( "Quan es baixa a l'ordinador de l'usuari," ) ; assertCorrect ( "sinó que es baixa per parts a l'atzar." ) ; assertCorrect ( "Es tem que la radioactivitat afecti la població local" ) ; assertCorrect ( "Després de tot això es va témer la possibilitat" ) ; assertCorrect ( "probablement es vagi a destil·lar l'etanol" ) ; assertCorrect ( ", es podia anar a Madrid per aconseguir en Celebi" ) ; assertCorrect ( "Els soldats es preparen per a marxar a la guerra." ) ; assertCorrect ( "Tu et prepares per marxar a la guerra." ) ; assertCorrect ( "i que es temia que s'aconseguís el nombre previst." ) ; assertCorrect ( "Des del principi es temia el pitjor" ) ; assertCorrect ( "La primera muntanya que es va pujar per motius purament esportius," ) ; assertCorrect ( "Quan el so era via fora, s'anava a guerrejar fora de la terra." ) ; assertCorrect ( "els algorismes, de manera que s'evita caure" ) ; assertCorrect ( "En acabar l'assalt, és comú que es pugi un banc" ) ; assertCorrect ( "Es va caure en la provocació." ) ; assertCorrect ( "Abans d'això ja s'havien pujat muntanyes," ) ; assertCorrect ( "a una representació de La Passió no només s'hi va a veure un espectacle sumptuós" ) ; assertCorrect ( "A escola no s'hi va a plorar." ) ; assertCorrect ( "A escola no es va a jugar." ) ; assertCorrect ( "A escola no es va a plorar." ) ; assertCorrect ( "Al nostre pis de la Torre es pujava per aquella llarga escala" ) ; assertCorrect ( "Joan no es va a jugar la feina." ) ; assertCorrect ( "I aquella flaire que em pujava al cap" ) ; assertCorrect ( "el que no s'olora, el que no es tasta" ) ; assertIncorrect ( "Ells s'han crescut molt" ) ; assertIncorrect ( "Em vaig créixer davant les dificultats" ) ; assertIncorrect ( "Joan s'ha crescut molt" ) ; assertIncorrect ( "Joana s'ha crescut molt" ) ; assertIncorrect ( "Ada Martínez s'ha crescut molt" ) ; assertIncorrect ( "Ada Colau s'ha crescut molt" ) ; assertIncorrect ( "Ha arribat l'hora de saltar-se la legalitat." ) ; assertIncorrect ( "Delia per menjar-ne." ) ; assertIncorrect ( "Ells es volen dur les ànimes a l'Inframón" ) ; assertIncorrect ( "Joan es va portar el carretó" ) ; assertIncorrect ( "en aquesta vida ens portem moltes sorpreses" ) ; assertIncorrect ( "Ens hem portat massa material al campament" ) ; assertIncorrect ( "Hem de dur-nos tot això." ) ; assertIncorrect ( "L'has fet tornar-se vermell." ) ; assertIncorrect ( "El fan agenollar-se." ) ; assertIncorrect ( "Fes-lo agenollar-se." ) ; assertIncorrect ( "Deixa'm agenollar-me." ) ; assertIncorrect ( "l'havia fet ufanejar-se obertament" ) ; assertIncorrect ( "un dels pocs moviments que poden fer és intentar pujar-se al carro de la indignació." ) ; assertIncorrect ( "és intentar pujar-se al carro de la indignació." ) ; assertIncorrect ( "Pujar-se al carro de la indignació." ) ; assertIncorrect ( "Pujar-vos al carro de la indignació." ) ; assertIncorrect ( "se li va caure la cara de vergonya" ) ; assertIncorrect ( "se'ns va caure la cara de vergonya" ) ; assertIncorrect ( "A mi se'm va caure la cara de vergonya" ) ; assertIncorrect ( "Joan no es va a l'escola" ) ; assertIncorrect ( "que el procés no se'ns vagi de les mans" ) ; assertIncorrect ( "Ho volen per a anar-se de la zona" ) ; assertIncorrect ( "Ho volen per anar-se de la zona" ) ; assertIncorrect ( "Ho desitgen per anar-se de la zona" ) ; assertIncorrect ( "els grups que es van caure del cartell" ) ; assertIncorrect ( "el nen que es va caure al pou" ) ; assertCorrect ( "el dia que es va anar a la ciutat" ) ; assertIncorrect ( "tot l'auditori es callà" ) ; assertIncorrect ( "les gotes que es van caure fora" ) ; assertIncorrect ( "Ells s'han baixat del tren." ) ; assertIncorrect ( "Ximo Puig i Rubalcaba no s'han baixat del cotxe oficial des del 79." ) ; assertIncorrect ( "Se'ns va callar." ) ; assertIncorrect ( "Tothom es va callar." ) ; assertIncorrect ( "Els nens van poder-se caure" ) ; assertIncorrect ( "Aleshores ell es va anar a estudiar a Barcelona" ) ; assertIncorrect ( "Joan es va anar a estudiar a Barcelona." ) ; assertIncorrect ( "se'ns va anar la mà" ) ; assertIncorrect ( "A Joan se li va anar la mà" ) ; assertIncorrect ( "Al pare se li va anar la mà" ) ; assertIncorrect ( "Escriu que quan era mosso «se li anaven els ulls»" ) ; assertIncorrect ( "Es van caure en la trampa." ) ; assertIncorrect ( "Aleshores es van anar a la ciutat a presentar una queixa." ) ; assertIncorrect ( "Va entrar l'avi que pujava del taller i es va seure." ) ; assertIncorrect ( "havent queixat" ) ; assertIncorrect ( "haver queixat" ) ; assertIncorrect ( "les membranes s'han anat fabricat amb materials sintètics" ) ; assertIncorrect ( "s'han anat fabricat amb materials sintètics" ) ; assertIncorrect ( "Holmes i Watson s'han anat d'acampada" ) ; assertIncorrect ( "L'independentisme s'ha anat a Brussel·les!" ) ; assertIncorrect ( "El seu marit s'ha anat a la Xina per negocios" ) ; assertIncorrect ( "L'home es marxà de seguida" ) ; assertIncorrect ( "L'home s'anà de seguida" ) ; assertIncorrect ( "A Joan se li va caure la cara de vergonya" ) ; assertIncorrect ( "El nen es cau" ) ; assertIncorrect ( "El nen se li cau" ) ; assertIncorrect ( "A la nena se li caigueren les arracades" ) ; assertIncorrect ( "El nen s'ha de caure" ) ; assertIncorrect ( "El nen pot caure's" ) ; assertIncorrect ( "Calleu-vos" ) ; assertIncorrect ( "El berenar es pujà al cel" ) ; assertIncorrect ( "Va baixar-se del cotxe en marxa." ) ; assertIncorrect ( "comencen queixant" ) ; assertIncorrect ( "comenceu a queixar-nos" ) ; assertIncorrect ( "et puc queixar" ) ; assertIncorrect ( "en teniu prou amb queixar" ) ; assertIncorrect ( "en podem queixar" ) ; assertIncorrect ( "et queixa" ) ; assertIncorrect ( "em va queixant" ) ; assertIncorrect ( "li va queixar" ) ; assertIncorrect ( "hem d'emportar-t'hi" ) ; assertIncorrect ( "heu de poder-te queixar" ) ; assertIncorrect ( "m'has de poder queixar" ) ; assertIncorrect ( "havent queixat" ) ; assertIncorrect ( "haver queixat" ) ; assertIncorrect ( "no es vam poder emportar" ) ; assertIncorrect ( "no has de poder-vos queixar" ) ; assertIncorrect ( "no has de queixar-ne" ) ; assertIncorrect ( "no podeu deixar de queixar-ne" ) ; assertIncorrect ( "no li has de queixar" ) ; assertIncorrect ( "no em podeu queixar" ) ; assertIncorrect ( "pareu de queixar-se'n" ) ; assertIncorrect ( "podent abstenir" ) ; assertIncorrect ( "poder queixar" ) ; assertIncorrect ( "podeu queixar" ) ; assertIncorrect ( "queixa'n" ) ; assertIncorrect ( "queixant" ) ; assertIncorrect ( "queixar" ) ; assertIncorrect ( "queixeu-se'n" ) ; assertIncorrect ( "de n'ha queixat" ) ; assertIncorrect ( "me li ha queixat" ) ; assertIncorrect ( "te li queixa" ) ; assertIncorrect ( "us li va queixar" ) ; assertIncorrect ( "va decidir suïcidar-me" ) ; assertIncorrect ( "va queixant" ) ; assertIncorrect ( "va queixar" ) ; assertIncorrect ( "va queixar-li" ) ; assertIncorrect ( "anem a aferrissar" ) ; } private void assertCorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( 0 , matches . length ) ; } private void assertIncorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . tokenizers . es ; import java . util . ArrayList ; import java . util . List ; import java . util . StringTokenizer ; import org . languagetool . tokenizers . Tokenizer ; public class SpanishWordTokenizer implements Tokenizer { public SpanishWordTokenizer ( ) { } @ Override public List < String > tokenize ( final String text ) { final List < String > l = new ArrayList < > ( ) ; final StringTokenizer st = new StringTokenizer ( text , "\u0020\u00A0\u115f\u1160\u1680" + "\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007" + "\u2008\u2009\u200A\u200B\u200c\u200d\u200e\u200f" + "\u2013\u2014\u2015" + "\u2028\u2029\u202a\u202b\u202c\u202d\u202e\u202f" + "\u205F\u2060\u2061\u2062\u2063\u206A\u206b\u206c\u206d" + "\u206E\u206F\u3000\u3164\ufeff\uffa0\ufff9\ufffa\ufffb" + ",.;()[]{}<>!?:/\\\"'«»„”“‘`’…¿¡\t\n\r" , true ) ; while ( st . hasMoreElements ( ) ) { l . add ( st . nextToken ( ) ) ; } return l ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Tagalog ; public class TagalogConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Tagalog ( ) ; } @ Override protected String createSampleText ( ) { return "Mula sa Wikipediang Tagalog, ang malayang ensiklopedya" ; } }
package org . languagetool . language . tl ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Tagalog ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import static org . junit . Assert . assertEquals ; public class MorfologikTagalogSpellerRuleTest { @ Test public void testMorfologikSpeller ( ) throws IOException { Tagalog language = new Tagalog ( ) ; MorfologikTagalogSpellerRule rule = new MorfologikTagalogSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Ang talatang ito ay nagpapakita ng ng kakayahan ng LanguageTool at halimbawa kung paano ito gamitin." ) ) . length ) ; RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "Ang talatang ito ay nagpapakita ng ng kakayahan ng LanguageTool at hinahalimbawa kung paano ito gamitin." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 67 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 80 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( "hina halimbawa" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . tl ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class TagalogPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . tokenizers . tl ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Tagalog ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class TagalogSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Tagalog ( ) ) ; public void testTokenize ( ) { testSplit ( "Ang Linux ay isang operating system kernel para sa mga operating system na humahalintulad sa Unix. " , "Isa ang Linux sa mga pinaka-prominanteng halimbawa ng malayang software at pagsasagawa ng open source; " + "madalas, malayang mapapalitan, gamitin, at maipamahagi ninuman ang " + "lahat ng pinag-ugatang source code (pinagmulang kodigo)." ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . language . tl . MorfologikTagalogSpellerRule ; import org . languagetool . language . tokenizers . TagalogWordTokenizer ; import org . languagetool . rules . * ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . tl . TagalogTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . WordTokenizer ; public class Tagalog extends Language { private SentenceTokenizer sentenceTokenizer ; private WordTokenizer wordTokenizer ; private Tagger tagger ; @ Override public String getName ( ) { return "Tagalog" ; } @ Override public String getShortName ( ) { return "tl" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "PH" } ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public WordTokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new TagalogWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new TagalogTagger ( ) ; } return tagger ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Nathaniel Oco" , "http://www.dlsu.edu.ph/research/centers/adric/nlp/" ) , new Contributor ( "Allan Borra" , "http://www.dlsu.edu.ph/research/centers/adric/nlp/faculty/borra.asp" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new MorfologikTagalogSpellerRule ( messages , this ) ) ; } }
package org . languagetool . language . tl ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; import java . io . IOException ; import java . util . ResourceBundle ; public class MorfologikTagalogSpellerRule extends MorfologikSpellerRule { public MorfologikTagalogSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return "/tl/hunspell/tl_PH.dict" ; } @ Override public final String getId ( ) { return "MORFOLOGIK_RULE_TL" ; } }
package org . languagetool . language . tokenizers ; import org . languagetool . tokenizers . WordTokenizer ; public class TagalogWordTokenizer extends WordTokenizer { @ Override public String getTokenizingCharacters ( ) { return super . getTokenizingCharacters ( ) + "-" ; } }
package org . languagetool . tagging . tl ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class TagalogTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/tl/added.txt" ; } public TagalogTagger ( ) { super ( "/tl/tagalog.dict" , Locale . ENGLISH ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Ukrainian ; public class UkrainianConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Ukrainian ( ) ; } @ Override protected String createSampleText ( ) { return "Матеріал з Вікіпедії — вільної енциклопедії." ; } }
package org . languagetool . rules . ca ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Catalan ; import java . io . IOException ; public class CatalanWrongWordInContextRuleTest extends TestCase { public void testRule ( ) throws IOException { CatalanWrongWordInContextRule rule = new CatalanWrongWordInContextRule ( null ) ; JLanguageTool langTool = new JLanguageTool ( new Catalan ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Una empresa molt rendible." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Una empresa molt rentable." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Uns cultius rentables." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Es venen bé i són rentables." ) ) . length ) ; assertEquals ( "rendibles" , rule . match ( langTool . getAnalyzedSentence ( "Uns projectes molt rentables." ) ) [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Li va infringir un mal terrible." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "És un terreny abonat per als problemes." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "No li va cosir bé les betes." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Sempre li seguia la beta." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "un any en el qual la reina Victoria encara era al tro britànic" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Sota els palis." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Els pal·lis." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "El pal·li i el sànscrit." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "El pali i el sànscrit." ) ) . length ) ; } }
package org . languagetool . synthesis . uk ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; public class UkrainianSynthesizerTest extends TestCase { public final void testSynthesizeString ( ) throws IOException { UkrainianSynthesizer synth = new UkrainianSynthesizer ( ) ; assertEquals ( synth . synthesize ( dummyToken ( "щосьтамтаке" ) , "щосьтамтаке" ) . length , 0 ) ; assertEquals ( "[міста]" , Arrays . toString ( synth . synthesize ( dummyToken ( "місто" ) , "noun:n:v_rod" ) ) ) ; assertEquals ( "[найчервонішої, червоної, червонішої]" , Arrays . toString ( getSortedArray ( synth . synthesize ( dummyToken ( "червоний" ) , "adj:f:v_rod.*" , true ) ) ) ) ; assertEquals ( "[червоної]" , Arrays . toString ( getSortedArray ( synth . synthesize ( dummyToken ( "червоний" ) , "adj:f:v_rod:compb" , true ) ) ) ) ; assertEquals ( "[червоним, червоним, червоними, червоною]" , Arrays . toString ( getSortedArray ( synth . synthesize ( dummyToken ( "червоний" ) , "adj:.:v_oru:compb" , true ) ) ) ) ; } private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } private String [ ] getSortedArray ( String [ ] ar ) { String [ ] newAr = ar . clone ( ) ; Arrays . sort ( newAr ) ; return newAr ; } }
package org . languagetool . rules . uk ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Arrays ; import static org . junit . Assert . assertEquals ; public class HiddenCharacterRuleTest { @ Test public void testRule ( ) throws IOException { final MixedAlphabetsRule rule = new MixedAlphabetsRule ( TestTools . getMessages ( "uk" ) ) ; final JLanguageTool langTool = new JLanguageTool ( new Ukrainian ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "сміття" ) ) . length ) ; RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "смi\u00ADття" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "сміття" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; } }
package org . languagetool . rules . uk ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertTrue ; import java . io . IOException ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import org . junit . Before ; import org . junit . Test ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . rules . RuleMatch ; public class TokenAgreementRuleTest { private JLanguageTool langTool ; private TokenAgreementRule rule ; @ Before public void setUp ( ) throws IOException { rule = new TokenAgreementRule ( TestTools . getMessages ( "uk" ) ) ; langTool = new JLanguageTool ( new Ukrainian ( ) ) ; } @ Test public void testRule ( ) throws IOException { assertEmptyMatch ( "без повного" ) ; assertEmptyMatch ( "без неба" ) ; assertEmptyMatch ( "по авеню" ) ; assertEmptyMatch ( "що за ганебна непослідовність?" ) ; assertEmptyMatch ( "щодо власне людини" ) ; assertEmptyMatch ( "у загалом симпатичній повістині" ) ; assertEmptyMatch ( "понад половина людей" ) ; assertEmptyMatch ( "з понад ста людей" ) ; assertEmptyMatch ( "по нервах" ) ; assertEmptyMatch ( "з особливою увагою" ) ; assertEmptyMatch ( "щодо бодай гіпотетичної здатності" ) ; assertEmptyMatch ( "хто їде на заробітки за кордон" ) ; assertEmptyMatch ( "піти в президенти" ) ; assertEmptyMatch ( "піти межі люди" ) ; assertEmptyMatch ( "що то була за людина" ) ; assertEmptyMatch ( "що за людина" ) ; assertEmptyMatch ( "що балотувався за цім округом" ) ; assertEmptyMatch ( "на дому" ) ; assertEmptyMatch ( "окрім як українці" ) ; assertEmptyMatch ( "за двісті метрів" ) ; assertEmptyMatch ( "переходить у Фрідріх Штрассе" ) ; assertEmptyMatch ( "від мінус 1 до плюс 1" ) ; assertEmptyMatch ( "до мінус сорока град" ) ; assertEmptyMatch ( "до мінус шістдесяти" ) ; assertEmptyMatch ( "через років 10" ) ; assertEmptyMatch ( "на хвилин 9-10" ) ; assertEmptyMatch ( "співпрацювати із собі подібними" ) ; assertEmptyMatch ( "через усім відомі причини" ) ; assertEmptyMatch ( "через нікому не відомі причини" ) ; assertEmptyMatch ( "прийшли до ВАТ «Кривий Ріг цемент»" ) ; assertEmptyMatch ( "від А до Я" ) ; assertEmptyMatch ( "до та після" ) ; assertEmptyMatch ( "до схід сонця" ) ; assertEmptyMatch ( "з рана до вечора, від рана до ночі" ) ; assertEmptyMatch ( "до НАК «Надра України»" ) ; assertEmptyMatch ( "призвів до значною мірою демократичного середнього класу" ) ; assertEmptyMatch ( "Вони замість Андрій вибрали Юрій" ) ; assertEmptyMatch ( "на мохом стеленому дні" ) ; assertEmptyMatch ( "час від часу нам доводилось" ) ; assertEmptyMatch ( "який до речі вони присягалися" ) ; assertEmptyMatch ( "ні до чого доброго силові дії не призведуть" ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "призвів до значною мірою демократичному середньому класу" ) ) . length ) ; RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "без небу" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "неба" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "не в останню чергу через корупцією, міжрелігійну ворожнечу" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "по нервам" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 3 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 9 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( Arrays . asList ( "нервах" , "нерви" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "в п'ятьом людям" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "в понад п'ятьом людям" ) ) . length ) ; AnalyzedSentence analyzedSentence = langTool . getAnalyzedSentence ( "завдяки їх вдалим трюкам" ) ; RuleMatch [ ] match = rule . match ( analyzedSentence ) ; assertEquals ( 1 , match . length ) ; List < String > suggestedReplacements = match [ 0 ] . getSuggestedReplacements ( ) ; assertTrue ( "Did not find «їхній»: " + suggestedReplacements , suggestedReplacements . contains ( "їхнім" ) ) ; analyzedSentence = langTool . getAnalyzedSentence ( "О дівчина!" ) ; match = rule . match ( analyzedSentence ) ; assertEquals ( 1 , match . length ) ; suggestedReplacements = match [ 0 ] . getSuggestedReplacements ( ) ; assertTrue ( "Did not find кличний «дівчино»: " + suggestedReplacements , suggestedReplacements . contains ( "дівчино" ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "по церковним канонам" ) ) ; assertEquals ( 1 , matches . length ) ; assertEmptyMatch ( "на Купала" ) ; assertEmptyMatch ( "на Явдохи" ) ; assertEmptyMatch ( "на Мазепи" ) ; assertEmptyMatch ( "на Кульчицької" ) ; assertEmptyMatch ( "на Правди" ) ; assertEmptyMatch ( "на Ломоносова" ) ; assertEmptyMatch ( "як на Кучми іменини" ) ; assertEmptyMatch ( "спиралося на місячної давнини рішення" ) ; assertEmptyMatch ( "На середньої довжини шубу" ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "спиралося на місячної давнини рішенням" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Від стягу Ататюрка до піратського прапору" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "згідно з документа" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "зацікавлених у ви користанні" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "В йому заграла кров." ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( " В йому заграла кров." ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "І от «В йому заграла кров»." ) ) ; assertEquals ( 1 , matches . length ) ; assertEmptyMatch ( "гепатитів В та С" ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "— О пан Єзус, захисти їх!" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "На фото: З Голлівуду Яринка Шуст привезла дві золоті медалі" ) ) ; assertEquals ( 1 , matches . length ) ; } private void assertEmptyMatch ( String text ) throws IOException { assertEquals ( Collections . < RuleMatch > emptyList ( ) , Arrays . asList ( rule . match ( langTool . getAnalyzedSentence ( text ) ) ) ) ; } @ Test public void testSpecialChars ( ) throws IOException { TokenAgreementRule rule = new TokenAgreementRule ( TestTools . getMessages ( "uk" ) ) ; JLanguageTool langTool = new JLanguageTool ( new Ukrainian ( ) ) ; RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "по не́рвам, по мо\u00ADстам, по воротам" ) ) ; assertEquals ( 3 , matches . length ) ; assertEmptyMatch ( "до їм поді\u00ADбних" ) ; assertEquals ( 3 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 10 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( Arrays . asList ( "нервах" , "нерви" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; assertEquals ( 15 , matches [ 1 ] . getFromPos ( ) ) ; assertEquals ( Arrays . asList ( "мостах" , "мости" ) , matches [ 1 ] . getSuggestedReplacements ( ) ) ; assertEquals ( 27 , matches [ 2 ] . getFromPos ( ) ) ; assertEquals ( Arrays . asList ( "воротах" , "ворота" ) , matches [ 2 ] . getSuggestedReplacements ( ) ) ; } }
package org . languagetool . rules . uk ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class PunctuationCheckRuleTest extends TestCase { public void testRule ( ) throws IOException { PunctuationCheckRule rule = new PunctuationCheckRule ( TestTools . getEnglishMessages ( ) ) ; RuleMatch [ ] matches ; JLanguageTool langTool = new JLanguageTool ( new Ukrainian ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Дві, коми. Ось: дві!!!" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "- Це ваша пряма мова?!!" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Дві,- коми!.." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Таке питання?.." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Два пробіли." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Дві крапки.." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 1 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( "." , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Дві,, коми." ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Не там ,кома." ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Двокрапка:- з тире." ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . rules . uk ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Arrays ; public class SimpleReplaceRuleTest extends TestCase { public void testRule ( ) throws IOException { SimpleReplaceRule rule = new SimpleReplaceRule ( TestTools . getEnglishMessages ( ) ) ; RuleMatch [ ] matches ; JLanguageTool langTool = new JLanguageTool ( new Ukrainian ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Ці рядки повинні збігатися." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Ці рядки повинні співпадати." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 2 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( Arrays . asList ( "збігатися" , "сходитися" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Нападаючий" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "Нападник" , "Нападальний" , "Нападний" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Нападаючого" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "Нападник" , "Нападальний" , "Нападний" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "відображаються" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "показуватися" , "зображатися" , "відбиватися" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "щедрота" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "щедрість" , "гойність" , "щедриня" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "щедроти" ) ) ; assertEquals ( 0 , matches . length ) ; } }
package org . languagetool . rules . uk ; import static org . junit . Assert . assertEquals ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . rules . RuleMatch ; public class MorfologikUkrainianSpellerRuleTest { @ Test public void testMorfologikSpeller ( ) throws IOException { MorfologikUkrainianSpellerRule rule = new MorfologikUkrainianSpellerRule ( TestTools . getMessages ( "uk" ) , new Ukrainian ( ) ) ; JLanguageTool langTool = new JLanguageTool ( new Ukrainian ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "До вас прийде заввідділу!" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "До нас приїде The Beatles!" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "піс\u00ADні" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "піс\u00ADні піс\u00ADні" ) ) . length ) ; RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "атакуючий" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "шкляний" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "скляний" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "а" ) ) . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "прийдешнiй" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "прийдешній" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Жакет був синьо-жовтого кольору" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Він багато сидів на інтернет-форумах" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Він багато сидів на інтермет-форумах" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "екс-креветка" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "банд-формування." ) ) . length ) ; RuleMatch [ ] match = rule . match ( langTool . getAnalyzedSentence ( "Читання віршів Т.Г.Шевченко і Г.Тютюнника" ) ) ; assertEquals ( new ArrayList < RuleMatch > ( ) , Arrays . asList ( match ) ) ; match = rule . match ( langTool . getAnalyzedSentence ( "Читання віршів Т. Г. Шевченко і Г. Тютюнника" ) ) ; assertEquals ( new ArrayList < RuleMatch > ( ) , Arrays . asList ( match ) ) ; match = rule . match ( langTool . getAnalyzedSentence ( "Англі́йська мова (англ. English language, English) належить до германської групи" ) ) ; assertEquals ( new ArrayList < RuleMatch > ( ) , Arrays . asList ( match ) ) ; match = rule . match ( langTool . getAnalyzedSentence ( "Англі́йська мова (англ English language, English) належить до германської групи" ) ) ; assertEquals ( 1 , match . length ) ; match = rule . match ( langTool . getAnalyzedSentence ( "100 тис. гривень" ) ) ; assertEquals ( new ArrayList < RuleMatch > ( ) , Arrays . asList ( match ) ) ; match = rule . match ( langTool . getAnalyzedSentence ( "100 кв. м" ) ) ; assertEquals ( new ArrayList < RuleMatch > ( ) , Arrays . asList ( match ) ) ; match = rule . match ( langTool . getAnalyzedSentence ( "100 кв м" ) ) ; assertEquals ( 1 , Arrays . asList ( match ) . size ( ) ) ; } }
package org . languagetool . rules . uk ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Arrays ; public class SimpleReplaceSoftRuleTest extends TestCase { public void testRule ( ) throws IOException { SimpleReplaceSoftRule rule = new SimpleReplaceSoftRule ( TestTools . getEnglishMessages ( ) ) ; RuleMatch [ ] matches ; JLanguageTool langTool = new JLanguageTool ( new Ukrainian ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Ці рядки повинні збігатися." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Цей графин." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "карафа" , "карафка" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; } }
package org . languagetool . rules . uk ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class UkrainianPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . uk ; import java . io . IOException ; import java . util . Arrays ; import java . util . Collections ; import org . junit . Before ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . rules . RuleMatch ; import static org . junit . Assert . assertEquals ; public class UkrainianWordRepeatRuleTest { private JLanguageTool langTool ; private UkrainianWordRepeatRule rule ; @ Before public void setUp ( ) throws IOException { langTool = new JLanguageTool ( new Ukrainian ( ) ) ; rule = new UkrainianWordRepeatRule ( TestTools . getMessages ( "uk" ) , langTool . getLanguage ( ) ) ; } @ Test public void testRule ( ) throws IOException { assertEmptyMatch ( "без повного розрахунку" ) ; assertEmptyMatch ( "без бугіма бугіма" ) ; assertEmptyMatch ( "без 100 100" ) ; assertEmptyMatch ( "1.30 3.20 3.20" ) ; assertEmptyMatch ( "ще в В.Кандинського" ) ; assertEmptyMatch ( "Від добра добра не шукають." ) ; assertEmptyMatch ( "Що що, а кіно в Україні..." ) ; assertEmptyMatch ( "Відповідно до ст. ст. 3, 7, 18." ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "без без повного розрахунку" ) ) . length ) ; RuleMatch [ ] match = rule . match ( langTool . getAnalyzedSentence ( "Верховної Ради І і ІІ скликань" ) ) ; assertEquals ( 1 , match . length ) ; assertEquals ( 2 , match [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; } private void assertEmptyMatch ( String text ) throws IOException { assertEquals ( text , Collections . < RuleMatch > emptyList ( ) , Arrays . asList ( rule . match ( langTool . getAnalyzedSentence ( text ) ) ) ) ; } }
package org . languagetool . rules . uk ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Arrays ; import static org . junit . Assert . assertEquals ; public class MixedAlphabetsRuleTest { @ Test public void testRule ( ) throws IOException { final MixedAlphabetsRule rule = new MixedAlphabetsRule ( TestTools . getMessages ( "uk" ) ) ; final JLanguageTool langTool = new JLanguageTool ( new Ukrainian ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "сміття" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "not mixed" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "смiття" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "сміття" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "mіхed" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "mixed" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "XІ" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "XI" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "ХI" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "XI" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "ХІ" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( Arrays . asList ( "XI" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Щеплення від гепатиту В." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "B" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "група А" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "A" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "На 0,6°С." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "0,6°C" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . ca ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class AccentuationCheckRuleTest extends TestCase { private AccentuationCheckRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new AccentuationCheckRule ( TestTools . getEnglishMessages ( ) ) ; langTool = new JLanguageTool ( new Catalan ( ) ) ; } public void testRule ( ) throws IOException { assertCorrect ( "A ponent continua la serra de Fontpobra" ) ; assertCorrect ( "com a base de la categoria faria que els enllaços" ) ; assertCorrect ( "De jove faria amistat amb ells" ) ; assertCorrect ( "De jove tenia admiració" ) ; assertCorrect ( "Per tant, espero ansiós." ) ; assertCorrect ( "M'espero qualsevol cosa." ) ; assertCorrect ( "Carrega de nou l'arxiu." ) ; assertCorrect ( "Espero d'ell moltes coses" ) ; assertCorrect ( "cal que abans figuri inscrit en l'Ordre del dia" ) ; assertCorrect ( "El lloc era, però, habitat de molt abans," ) ; assertCorrect ( "i del bel canto del rococó." ) ; assertCorrect ( "El lloc fou habitat de forma contínua" ) ; assertCorrect ( "que havia estat habitat fins al regnat de Joan II" ) ; assertCorrect ( "López-Picó publica el seu llibre de poesies" ) ; assertCorrect ( "Vaig perdut, tremolo de por." ) ; assertCorrect ( "l'home marra el camí" ) ; assertCorrect ( "veié que darrere venia el deixeble" ) ; assertCorrect ( "Però el qui begui de l'aigua" ) ; assertCorrect ( "a qualsevol qui en mati un altre" ) ; assertCorrect ( "tu que prediques de no robar" ) ; assertCorrect ( "els següents territoris externs habitats:" ) ; assertCorrect ( "Cap faria una cosa així." ) ; assertCorrect ( "El cos genera suficient pressió interna." ) ; assertCorrect ( "Les seues contràries." ) ; assertCorrect ( "Això és una frase de prova." ) ; assertCorrect ( "Amb renúncies i esforç." ) ; assertCorrect ( "He vingut per a cantar" ) ; assertCorrect ( "Són circumstàncies d'un altre caire." ) ; assertCorrect ( "La renúncia del president." ) ; assertCorrect ( "Circumstàncies extraordinàries." ) ; assertCorrect ( "Les circumstàncies que ens envolten." ) ; assertCorrect ( "Ella continua enfadada." ) ; assertCorrect ( "Ell obvia els problemes." ) ; assertCorrect ( "De manera òbvia." ) ; assertCorrect ( "Ell fa tasques específiques." ) ; assertCorrect ( "Un home adúlter." ) ; assertCorrect ( "Jo adulter el resultat." ) ; assertCorrect ( "Va deixar els nens atònits." ) ; assertCorrect ( "La sureda ocupa àmplies extensions en la muntanya." ) ; assertCorrect ( "Féu una magnífica digitació." ) ; assertCorrect ( "La disputa continua oberta." ) ; assertCorrect ( "La llum tarda 22 minuts." ) ; assertCorrect ( "És el tretzè municipi més habitat de la comarca." ) ; assertCorrect ( "Els hàbitats de la comarca." ) ; assertCorrect ( "Joan Pau II beatifica Paula Montal." ) ; assertCorrect ( "La magnífica conservació del palau." ) ; assertIncorrect ( "Com s'ha dit les primaries autonòmiques s'han ajornat" ) ; assertIncorrect ( "Com sabeu les primaries s'han ajornat" ) ; assertIncorrect ( "Les continues al·lusions a la victòria." ) ; assertIncorrect ( "De positiva influencia en ell." ) ; assertIncorrect ( "tren de llarga distancia" ) ; assertIncorrect ( "Cal una nova formula que substitueixi el caduc Estat del benestar." ) ; assertIncorrect ( "Porta-la i nosaltres fem la copia i la compulsem." ) ; assertIncorrect ( "Carrega d'arxius." ) ; assertIncorrect ( "Vaig arribar a fer una radio que no va funcionar mai." ) ; assertIncorrect ( "No em fumaré una faria com feia abans." ) ; assertIncorrect ( "M'he fumat una faria." ) ; assertIncorrect ( "Les seues contraries." ) ; assertIncorrect ( "Amb renuncies i esforç." ) ; assertIncorrect ( "La renuncia del president." ) ; assertIncorrect ( "Són circumstancies d'un altre caire." ) ; assertIncorrect ( "Circumstancies extraordinàries." ) ; assertIncorrect ( "Les circumstancies que ens envolten." ) ; assertIncorrect ( "De manera obvia." ) ; assertIncorrect ( "Ell fa tasques especifiques." ) ; assertIncorrect ( "Un home adulter." ) ; assertIncorrect ( "La sureda ocupa amplies extensions en la muntanya." ) ; assertIncorrect ( "Féu una magnifica digitació." ) ; assertIncorrect ( "La magnifica conservació del palau." ) ; final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "Les circumstancies que ens envolten són circumstancies extraordinàries." ) ) ; assertEquals ( 2 , matches . length ) ; } private void assertCorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( 0 , matches . length ) ; } private void assertIncorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( 1 , matches . length ) ; } public void testPositions ( ) throws IOException { final AccentuationCheckRule rule = new AccentuationCheckRule ( TestTools . getEnglishMessages ( ) ) ; final RuleMatch [ ] matches ; final JLanguageTool langTool = new JLanguageTool ( new Catalan ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Són circumstancies extraordinàries." ) ) ; assertEquals ( 4 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 18 , matches [ 0 ] . getToPos ( ) ) ; } }
package org . languagetool . rules . uk ; import org . junit . Test ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class DateCheckFilterTest { @ Test public void testGetDayOfWeek ( ) throws Exception { DateCheckFilter filter = new DateCheckFilter ( ) ; assertThat ( filter . getDayOfWeek ( "Нед" ) , is ( 1 ) ) ; assertThat ( filter . getDayOfWeek ( "Пон" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "пон" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Понед." ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Понеділок" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "понеділок" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Вт" ) , is ( 3 ) ) ; assertThat ( filter . getDayOfWeek ( "Сер" ) , is ( 4 ) ) ; assertThat ( filter . getDayOfWeek ( "П'ят" ) , is ( 6 ) ) ; assertThat ( filter . getDayOfWeek ( "Суб" ) , is ( 7 ) ) ; } @ Test public void testMonth ( ) throws Exception { DateCheckFilter filter = new DateCheckFilter ( ) ; assertThat ( filter . getMonth ( "січ" ) , is ( 1 ) ) ; assertThat ( filter . getMonth ( "гру" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "грудень" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "Грудень" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "ГРУДЕНЬ" ) , is ( 12 ) ) ; } }
package org . languagetool . rules . uk ; import java . io . IOException ; import java . util . ArrayList ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . UppercaseSentenceStartRule ; public class UppercaseSentenceStartRuleTest extends TestCase { public void testUkrainian ( ) throws IOException { final Ukrainian ukrainian = new Ukrainian ( ) ; final UppercaseSentenceStartRule rule = new UppercaseSentenceStartRule ( TestTools . getEnglishMessages ( ) , ukrainian ) ; final JLanguageTool lt = new JLanguageTool ( ukrainian ) ; assertEquals ( 0 , rule . match ( lt . getAnalyzedSentence ( "Автор написав це речення з великої літери." ) ) . length ) ; final RuleMatch [ ] matches = rule . match ( lt . getAnalyzedSentence ( "автор написав це речення з маленької літери." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 1 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( "Автор" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( new ArrayList < RuleMatch > ( ) , lt . check ( "Це список з декількох рядків:\n\nрядок 1,\n\nрядок 2,\n\nрядок 3." ) ) ; assertEquals ( 0 , lt . check ( "Це список з декількох рядків:\n\nрядок 1;\n\nрядок 2;\n\nрядок 3." ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "Це список з декількох рядків:\n\n 1) рядок 1;\n\n2) рядок 2;\n\n3)рядок 3." ) . size ( ) ) ; } }
package org . languagetool . tagging . uk ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . tokenizers . uk . UkrainianWordTokenizer ; public class UkrainianTaggerTest extends TestCase { private UkrainianTagger tagger ; private UkrainianWordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new UkrainianTagger ( ) ; tokenizer = new UkrainianWordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Ukrainian ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "києві" , "києві/[кий]noun:m:v_dav|києві/[кий]noun:m:v_mis" , tokenizer , tagger ) ; TestTools . myAssert ( "Києві" , "Києві/[Київ]noun:m:v_mis|Києві/[кий]noun:m:v_dav|Києві/[кий]noun:m:v_mis" , tokenizer , tagger ) ; TestTools . myAssert ( "віл" , "віл/[віл]noun:m:v_naz:anim" , tokenizer , tagger ) ; TestTools . myAssert ( "Віл" , "Віл/[віл]noun:m:v_naz:anim" , tokenizer , tagger ) ; TestTools . myAssert ( "ВІЛ" , "ВІЛ/[ВІЛ]noun:m:v_dav:nv:np:abbr|ВІЛ/[ВІЛ]noun:m:v_mis:nv:np:abbr|ВІЛ/[ВІЛ]noun:m:v_naz:nv:np:abbr|ВІЛ/[ВІЛ]noun:m:v_oru:nv:np:abbr|ВІЛ/[ВІЛ]noun:m:v_rod:nv:np:abbr|ВІЛ/[ВІЛ]noun:m:v_zna:nv:np:abbr|ВІЛ/[віл]noun:m:v_naz:anim" , tokenizer , tagger ) ; TestTools . myAssert ( "далі" , "далі/[далі]adv" , tokenizer , tagger ) ; TestTools . myAssert ( "Далі" , "Далі/[Даль]noun:m:v_mis:anim:lname|Далі/[Далі]noun:m:v_dav:nv:np:anim:lname|Далі/[Далі]noun:m:v_mis:nv:np:anim:lname|Далі/[Далі]noun:m:v_naz:nv:np:anim:lname|Далі/[Далі]noun:m:v_oru:nv:np:anim:lname|Далі/[Далі]noun:m:v_rod:nv:np:anim:lname|Далі/[Далі]noun:m:v_zna:nv:np:anim:lname|Далі/[далі]adv" , tokenizer , tagger ) ; TestTools . myAssert ( "Бен" , "Бен/[Бен]noun:m:v_naz:anim:fname|Бен/[бен]unknown" , tokenizer , tagger ) ; TestTools . myAssert ( "бен" , "бен/[бен]unknown" , tokenizer , tagger ) ; TestTools . myAssert ( "Справу порушено судом" , "Справу/[справа]noun:f:v_zna -- порушено/[порушити]verb:impers:perf -- судом/[суд]noun:m:v_oru|судом/[судома]noun:p:v_rod" , tokenizer , tagger ) ; String expected = "Майже/[майже]adv -- два/[два]numr:m:v_naz|два/[два]numr:m:v_zna|два/[два]numr:n:v_naz|два/[два]numr:n:v_zna -- роки/[рік]noun:p:v_naz|роки/[рік]noun:p:v_zna" + " -- тому/[той]adj:m:v_dav:&pron:dem|тому/[той]adj:m:v_mis:&pron:dem|тому/[той]adj:n:v_dav:&pron:dem|тому/[той]adj:n:v_mis:&pron:dem|тому/[том]noun:m:v_dav|тому/[том]noun:m:v_mis|тому/[том]noun:m:v_rod|тому/[тому]adv|тому/[тому]conj:subord" + " -- Люба/[Люба]noun:f:v_naz:anim:fname|Люба/[любий]adj:f:v_naz -- разом/[раз]noun:m:v_oru|разом/[разом]adv -- із/[із]prep:rv_rod:rv_zna:rv_oru" + " -- чоловіком/[чоловік]noun:m:v_oru:anim -- Степаном/[Степан]noun:m:v_oru:anim:fname -- виїхали/[виїхати]verb:past:m:perf -- туди/[туди]adv:&pron:dem" + " -- на/[на]excl|на/[на]part|на/[на]prep:rv_zna:rv_mis -- " + "проживання/[проживання]noun:n:v_naz|проживання/[проживання]noun:n:v_rod|проживання/[проживання]noun:n:v_zna|проживання/[проживання]noun:p:v_naz|проживання/[проживання]noun:p:v_zna" ; TestTools . myAssert ( "Майже два роки тому Люба разом із чоловіком Степаном виїхали туди на проживання." , expected , tokenizer , tagger ) ; } public void testNumberTagging ( ) throws IOException { TestTools . myAssert ( "101,234" , "101,234/[101,234]number" , tokenizer , tagger ) ; TestTools . myAssert ( "3,5-5,6% 7° 7,4°С" , "3,5-5,6%/[3,5-5,6%]number -- 7°/[7°]number -- 7,4°С/[7,4°С]number" , tokenizer , tagger ) ; TestTools . myAssert ( "XIX" , "XIX/[XIX]number" , tokenizer , tagger ) ; TestTools . myAssert ( "14.07.2001" , "14.07.2001/[14.07.2001]date" , tokenizer , tagger ) ; TestTools . myAssert ( "о 15.33" , "о/[о]excl|о/[о]prep:rv_zna:rv_mis -- 15.33/[15.33]time" , tokenizer , tagger ) ; TestTools . myAssert ( "О 1:05" , "О/[о]excl|О/[о]prep:rv_zna:rv_mis -- 1:05/[1:05]time" , tokenizer , tagger ) ; } public void testTaggingWithDots ( ) throws IOException { TestTools . myAssert ( "300 р. до н. е." , "300/[300]number -- р./[р.]noun:f:v_dav:nv:np:abbr|р./[р.]noun:f:v_mis:nv:np:abbr|р./[р.]noun:f:v_naz:nv:np:abbr|р./[р.]noun:f:v_oru:nv:np:abbr|р./[р.]noun:f:v_rod:nv:np:abbr|р./[р.]noun:f:v_zna:nv:np:abbr|р./[р.]noun:m:v_dav:nv:np:abbr|р./[р.]noun:m:v_mis:nv:np:abbr|р./[р.]noun:m:v_naz:nv:np:abbr|р./[р.]noun:m:v_oru:nv:np:abbr|р./[р.]noun:m:v_rod:nv:np:abbr|р./[р.]noun:m:v_zna:nv:np:abbr -- до/[до]noun:n:v_dav:nv|до/[до]noun:n:v_mis:nv|до/[до]noun:n:v_naz:nv|до/[до]noun:n:v_oru:nv|до/[до]noun:n:v_rod:nv|до/[до]noun:n:v_zna:nv|до/[до]noun:p:v_dav:nv|до/[до]noun:p:v_mis:nv|до/[до]noun:p:v_naz:nv|до/[до]noun:p:v_oru:nv|до/[до]noun:p:v_rod:nv|до/[до]noun:p:v_zna:nv|до/[до]prep:rv_rod -- " + "н./[н.]adj:f:v_dav:nv:abbr|н./[н.]adj:f:v_mis:nv:abbr|н./[н.]adj:f:v_naz:nv:abbr|н./[н.]adj:f:v_oru:nv:abbr|н./[н.]adj:f:v_rod:nv:abbr|н./[н.]adj:f:v_zna:nv:abbr|н./[н.]adj:m:v_dav:nv:abbr|н./[н.]adj:m:v_mis:nv:abbr|н./[н.]adj:m:v_naz:nv:abbr|н./[н.]adj:m:v_oru:nv:abbr|н./[н.]adj:m:v_rod:nv:abbr|н./[н.]adj:m:v_zna:nv:abbr|н./[н.]adj:n:v_dav:nv:abbr|н./[н.]adj:n:v_mis:nv:abbr|н./[н.]adj:n:v_naz:nv:abbr|н./[н.]adj:n:v_oru:nv:abbr|н./[н.]adj:n:v_rod:nv:abbr|н./[н.]adj:n:v_zna:nv:abbr|н./[н.]adj:p:v_dav:nv:abbr|н./[н.]adj:p:v_mis:nv:abbr|н./[н.]adj:p:v_naz:nv:abbr|н./[н.]adj:p:v_oru:nv:abbr|н./[н.]adj:p:v_rod:nv:abbr|н./[н.]adj:p:v_zna:nv:abbr -- " + "е./[е.]noun:f:v_dav:nv:abbr|е./[е.]noun:f:v_mis:nv:abbr|е./[е.]noun:f:v_naz:nv:abbr|е./[е.]noun:f:v_oru:nv:abbr|е./[е.]noun:f:v_rod:nv:abbr|е./[е.]noun:f:v_zna:nv:abbr|е./[е.]noun:p:v_dav:nv:abbr|е./[е.]noun:p:v_mis:nv:abbr|е./[е.]noun:p:v_naz:nv:abbr|е./[е.]noun:p:v_oru:nv:abbr|е./[е.]noun:p:v_rod:nv:abbr|е./[е.]noun:p:v_zna:nv:abbr" , tokenizer , tagger ) ; TestTools . myAssert ( "300 тис. гривень" , "300/[300]number -- тис./[тис.]numr:f:v_dav:nv:abbr|тис./[тис.]numr:f:v_mis:nv:abbr|тис./[тис.]numr:f:v_naz:nv:abbr|тис./[тис.]numr:f:v_oru:nv:abbr|тис./[тис.]numr:f:v_rod:nv:abbr|тис./[тис.]numr:f:v_zna:nv:abbr -- гривень/[гривня]noun:p:v_rod" , tokenizer , tagger ) ; } public void testDynamicTagging ( ) throws IOException { TestTools . myAssert ( "г-г-г" , "г-г-г/[null]null" , tokenizer , tagger ) ; TestTools . myAssert ( "100-річному" , "100-річному/[100-річний]adj:m:v_dav|100-річному/[100-річний]adj:m:v_mis|100-річному/[100-річний]adj:n:v_dav|100-річному/[100-річний]adj:n:v_mis" , tokenizer , tagger ) ; TestTools . myAssert ( "100-й" , "100-й/[100-й]adj:m:v_naz|100-й/[100-й]adj:m:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "50-х" , "50-х/[50-й]adj:p:v_rod|50-х/[50-й]adj:p:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "по-свинячому" , "по-свинячому/[по-свинячому]adv" , tokenizer , tagger ) ; TestTools . myAssert ( "по-сибірськи" , "по-сибірськи/[по-сибірськи]adv" , tokenizer , tagger ) ; TestTools . myAssert ( "давай-но" , "давай-но/[давати]verb:impr:s:2:imperf" , tokenizer , tagger ) ; TestTools . myAssert ( "дивіться-но" , "дивіться-но/[дивитися]verb:rev:impr:p:2:imperf" , tokenizer , tagger ) ; TestTools . myAssert ( "той-таки" , "той-таки/[той-таки]adj:m:v_naz:&pron:dem|той-таки/[той-таки]adj:m:v_zna:&pron:dem" , tokenizer , tagger ) ; TestTools . myAssert ( "буде-таки" , "буде-таки/[бути]verb:futr:s:3:imperf" , tokenizer , tagger ) ; TestTools . myAssert ( "оцей-от" , "оцей-от/[оцей]adj:m:v_naz:&pron:dem|оцей-от/[оцей]adj:m:v_zna:&pron:dem" , tokenizer , tagger ) ; TestTools . myAssert ( "оттакий-то" , "оттакий-то/[оттакий]adj:m:v_naz:&pron:dem:rare|оттакий-то/[оттакий]adj:m:v_zna:&pron:dem:rare" , tokenizer , tagger ) ; TestTools . myAssert ( "геть-то" , "геть-то/[геть]adv|геть-то/[геть]part" , tokenizer , tagger ) ; TestTools . myAssert ( "ану-бо" , "ану-бо/[ану]excl|ану-бо/[ану]part" , tokenizer , tagger ) ; TestTools . myAssert ( "годі-бо" , "годі-бо/[годі]predic" , tokenizer , tagger ) ; TestTools . myAssert ( "гей-но" , "гей-но/[гей]excl" , tokenizer , tagger ) ; TestTools . myAssert ( "цить-но" , "цить-но/[цить]excl" , tokenizer , tagger ) ; TestTools . myAssert ( "екс-партнер" , "екс-партнер/[екс-партнер]noun:m:v_naz:anim" , tokenizer , tagger ) ; TestTools . myAssert ( "Алієва-старшого" , "Алієва-старшого/[Алієв-старий]noun:m:v_rod:anim:lname|Алієва-старшого/[Алієв-старий]noun:m:v_zna:anim:lname" , tokenizer , tagger ) ; TestTools . myAssert ( "жило-було" , "жило-було/[жити-бути]verb:past:n:imperf" , tokenizer , tagger ) ; TestTools . myAssert ( "учиш-учиш" , "учиш-учиш/[учити-учити]verb:pres:s:2:imperf:v-u" , tokenizer , tagger ) ; TestTools . myAssert ( "вгору-вниз" , "вгору-вниз/[вгору-вниз]adv:v-u" , tokenizer , tagger ) ; TestTools . myAssert ( "низенько-низенько" , "низенько-низенько/[низенько-низенько]adv" , tokenizer , tagger ) ; TestTools . myAssert ( "такого-сякого" , "такого-сякого/[такий-сякий]adj:m:v_rod:&pron:def|такого-сякого/[такий-сякий]adj:m:v_zna:&pron:def|такого-сякого/[такий-сякий]adj:n:v_rod:&pron:def" , tokenizer , tagger ) ; TestTools . myAssert ( "великий-превеликий" , "великий-превеликий/[великий-превеликий]adj:m:v_naz|великий-превеликий/[великий-превеликий]adj:m:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "чорній-чорній" , "чорній-чорній/[чорний-чорний]adj:f:v_dav|чорній-чорній/[чорний-чорний]adj:f:v_mis|чорній-чорній/[чорніти-чорніти]verb:impr:s:2:imperf" , tokenizer , tagger ) ; TestTools . myAssert ( "лікар-гомеопат" , "лікар-гомеопат/[лікар-гомеопат]noun:m:v_naz:anim" , tokenizer , tagger ) ; TestTools . myAssert ( "лікаря-гомеопата" , "лікаря-гомеопата/[лікар-гомеопат]noun:m:v_rod:anim|лікаря-гомеопата/[лікар-гомеопат]noun:m:v_zna:anim" , tokenizer , tagger ) ; TestTools . myAssert ( "шмкр-гомеопат" , "шмкр-гомеопат/[null]null" , tokenizer , tagger ) ; TestTools . myAssert ( "шмкр-ткр" , "шмкр-ткр/[null]null" , tokenizer , tagger ) ; TestTools . myAssert ( "вчинок-приклад" , "вчинок-приклад/[вчинок-приклад]noun:m:v_naz:v-u|вчинок-приклад/[вчинок-приклад]noun:m:v_zna:v-u" , tokenizer , tagger ) ; TestTools . myAssert ( "міста-фортеці" , "міста-фортеці/[місто-фортеця]noun:n:v_rod|міста-фортеці/[місто-фортеця]noun:p:v_naz|міста-фортеці/[місто-фортеця]noun:p:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "вчених-новаторів" , "вчених-новаторів/[вчений-новатор]noun:p:v_rod:anim:v-u|вчених-новаторів/[вчений-новатор]noun:p:v_zna:anim:v-u" , tokenizer , tagger ) ; TestTools . myAssert ( "країна-виробник" , "країна-виробник/[країна-виробник]noun:f:v_naz" , tokenizer , tagger ) ; TestTools . myAssert ( "банк-виробник" , "банк-виробник/[банк-виробник]noun:m:v_naz|банк-виробник/[банк-виробник]noun:m:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "банки-агенти" , "банки-агенти/[банк-агент]noun:p:v_naz|банки-агенти/[банк-агент]noun:p:v_zna|банки-агенти/[банка-агент]noun:p:v_naz|банки-агенти/[банка-агент]noun:p:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "місто-гігант" , "місто-гігант/[місто-гігант]noun:n:v_naz|місто-гігант/[місто-гігант]noun:n:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "країни-агресори" , "країни-агресори/[країна-агресор]noun:p:v_naz|країни-агресори/[країна-агресор]noun:p:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "поселення-гігант" , "поселення-гігант/[поселення-гігант]noun:n:v_naz|поселення-гігант/[поселення-гігант]noun:n:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "сонях-красень" , "сонях-красень/[сонях-красень]noun:m:v_naz|сонях-красень/[сонях-красень]noun:m:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "красень-сонях" , "красень-сонях/[красень-сонях]noun:m:v_naz|красень-сонях/[красень-сонях]noun:m:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "депутатів-привидів" , "депутатів-привидів/[депутат-привид]noun:p:v_rod:anim|депутатів-привидів/[депутат-привид]noun:p:v_zna:anim" , tokenizer , tagger ) ; TestTools . myAssert ( "дівчата-зірочки" , "дівчата-зірочки/[дівча-зірочка]noun:p:v_naz:anim" , tokenizer , tagger ) ; TestTools . myAssert ( "абзац-два" , "абзац-два/[абзац-два]noun:m:v_naz|абзац-два/[абзац-два]noun:m:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "сотні-дві" , "сотні-дві/[сотня-два]noun:p:v_naz|сотні-дві/[сотня-два]noun:p:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "тисячею-трьома" , "тисячею-трьома/[тисяча-три]noun:f:v_oru|тисячею-трьома/[тисяча-троє]noun:f:v_oru" , tokenizer , tagger ) ; TestTools . myAssert ( "одним-двома" , "одним-двома/[один-два]numr:m:v_oru|одним-двома/[один-два]numr:n:v_oru|одним-двома/[один-двоє]numr:m:v_oru|одним-двома/[один-двоє]numr:n:v_oru" , tokenizer , tagger ) ; TestTools . myAssert ( "п'яти-шести" , "п'яти-шести/[п'ята-шість]noun:f:v_rod|п'яти-шести/[п'ять-шість]numr:p:v_dav|п'яти-шести/[п'ять-шість]numr:p:v_mis|п'яти-шести/[п'ять-шість]numr:p:v_rod" , tokenizer , tagger ) ; TestTools . myAssert ( "півтори-дві" , "півтори-дві/[півтори-два]numr:f:v_naz|півтори-дві/[півтори-два]numr:f:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "три-чотири" , "три-чотири/[три-чотири]numr:p:v_naz|три-чотири/[три-чотири]numr:p:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "два-чотири" , "два-чотири/[два-чотири]numr:m:v_naz|два-чотири/[два-чотири]numr:m:v_zna|два-чотири/[два-чотири]numr:n:v_naz|два-чотири/[два-чотири]numr:n:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "одному-двох" , "одному-двох/[один-два]numr:m:v_mis|одному-двох/[один-два]numr:n:v_mis|одному-двох/[один-двоє]numr:m:v_mis|одному-двох/[один-двоє]numr:n:v_mis" , tokenizer , tagger ) ; TestTools . myAssert ( "три–чотири" , "три–чотири/[три–чотири]numr:p:v_naz|три–чотири/[три–чотири]numr:p:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "а-а" , "а-а/[а-а]excl" , tokenizer , tagger ) ; TestTools . myAssert ( "Москви-ріки" , "Москви-ріки/[Москва-ріка]noun:f:v_rod" , tokenizer , tagger ) ; TestTools . myAssert ( "пів-України" , "пів-України/[пів-України]noun:f:v_dav|пів-України/[пів-України]noun:f:v_mis|пів-України/[пів-України]noun:f:v_naz|пів-України/[пів-України]noun:f:v_oru|пів-України/[пів-України]noun:f:v_rod|пів-України/[пів-України]noun:f:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "кава-еспресо" , "кава-еспресо/[кава-еспресо]noun:f:v_naz" , tokenizer , tagger ) ; TestTools . myAssert ( "кави-еспресо" , "кави-еспресо/[кава-еспресо]noun:f:v_rod" , tokenizer , tagger ) ; TestTools . myAssert ( "еспресо-машина" , "еспресо-машина/[еспресо-машина]noun:f:v_naz" , tokenizer , tagger ) ; TestTools . myAssert ( "програмою-максимум" , "програмою-максимум/[програма-максимум]noun:f:v_oru" , tokenizer , tagger ) ; TestTools . myAssert ( "Пенсильванія-авеню" , "Пенсильванія-авеню/[Пенсильванія-авеню]noun:f:nv" , tokenizer , tagger ) ; TestTools . myAssert ( "патолого-анатомічний" , "патолого-анатомічний/[патолого-анатомічний]adj:m:v_naz|патолого-анатомічний/[патолого-анатомічний]adj:m:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "паталого-анатомічний" , "паталого-анатомічний/[null]null" , tokenizer , tagger ) ; TestTools . myAssert ( "патолого-гмкнх" , "патолого-гмкнх/[null]null" , tokenizer , tagger ) ; TestTools . myAssert ( "патолого-голова" , "патолого-голова/[null]null" , tokenizer , tagger ) ; TestTools . myAssert ( "освітньо-культурний" , "освітньо-культурний/[освітньо-культурний]adj:m:v_naz:compb|освітньо-культурний/[освітньо-культурний]adj:m:v_zna:compb" , tokenizer , tagger ) ; TestTools . myAssert ( "бірмюково-блакитний" , "бірмюково-блакитний/[null]null" , tokenizer , tagger ) ; TestTools . myAssert ( "сліпуче-яскравого" , "сліпуче-яскравого/[сліпуче-яскравий]adj:m:v_rod:compb|сліпуче-яскравого/[сліпуче-яскравий]adj:m:v_zna:compb|сліпуче-яскравого/[сліпуче-яскравий]adj:n:v_rod:compb" , tokenizer , tagger ) ; TestTools . myAssert ( "дво-триметровий" , "дво-триметровий/[дво-триметровий]adj:m:v_naz|дво-триметровий/[дво-триметровий]adj:m:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "україно-болгарський" , "україно-болгарський/[україно-болгарський]adj:m:v_naz|україно-болгарський/[україно-болгарський]adj:m:v_zna" , tokenizer , tagger ) ; TestTools . myAssert ( "Дівчинка-першокласниця" , "Дівчинка-першокласниця/[дівчинка-першокласниця]noun:f:v_naz:anim" , tokenizer , tagger ) ; TestTools . myAssert ( "RPM-пакунок" , "RPM-пакунок/[RPM-пакунок]noun:m:v_naz|RPM-пакунок/[RPM-пакунок]noun:m:v_zna" , tokenizer , tagger ) ; } }
package org . languagetool . tagging . disambiguation . rules . uk ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . MultiWordChunker ; import org . languagetool . tagging . disambiguation . rules . DisambiguationRuleTest ; import org . languagetool . tagging . disambiguation . uk . UkrainianHybridDisambiguator ; import org . languagetool . tagging . disambiguation . xx . DemoDisambiguator ; import org . languagetool . tagging . uk . UkrainianTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . uk . UkrainianWordTokenizer ; public class UkrainianDisambiguationRuleTest extends DisambiguationRuleTest { private UkrainianTagger tagger ; private UkrainianWordTokenizer tokenizer ; private SRXSentenceTokenizer sentenceTokenizer ; private UkrainianHybridDisambiguator disambiguator ; private DemoDisambiguator demoDisambiguator ; private Disambiguator chunker ; @ Override public void setUp ( ) { tagger = new UkrainianTagger ( ) ; tokenizer = new UkrainianWordTokenizer ( ) ; sentenceTokenizer = new SRXSentenceTokenizer ( new Ukrainian ( ) ) ; disambiguator = new UkrainianHybridDisambiguator ( ) ; demoDisambiguator = new DemoDisambiguator ( ) ; chunker = new MultiWordChunker ( "/uk/multiwords.txt" , true ) ; } public void testDisambiguator ( ) throws IOException { TestTools . myAssert ( "Танцювати до впаду" , "/[null]SENT_START Танцювати/[танцювати]verb:inf:imperf /[null]null до/[до впаду]<adv>|до/[до]prep:rv_rod /[null]null " + "впаду/[впасти]verb:futr:s:1:perf:v-u|впаду/[до впаду]</adv>" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Прийшла Люба додому." , "/[null]SENT_START Прийшла/[прийти]verb:past:f:perf /[null]null Люба/[Люба]noun:f:v_naz:anim:fname|Люба/[любий]adj:f:v_naz /[null]null додому/[додому]adv ./[null]null" , tokenizer , sentenceTokenizer , tagger , demoDisambiguator ) ; TestTools . myAssert ( "Прийшла Люба додому." , "/[null]SENT_START Прийшла/[прийти]verb:past:f:perf /[null]null Люба/[Люба]noun:f:v_naz:anim:fname /[null]null додому/[додому]adv ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; } public void testDisambiguatorForInitials ( ) throws IOException { TestTools . myAssert ( "Є.Бакуліна" , "/[null]SENT_START" + " Є/[Є]noun:f:v_naz:anim:fname:abbr|Є/[Є]noun:m:v_rod:anim:fname:abbr|Є/[Є]noun:m:v_zna:anim:fname:abbr" + " ./[null]null" + " Бакуліна/[Бакулін]noun:m:v_rod:anim:lname|Бакуліна/[Бакулін]noun:m:v_zna:anim:lname|Бакуліна/[Бакуліна]noun:f:v_naz:anim:lname" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( " Є. Бакуліна" , "/[null]SENT_START" + " /[null]null" + " Є/[Є]noun:f:v_naz:anim:fname:abbr|Є/[Є]noun:m:v_rod:anim:fname:abbr|Є/[Є]noun:m:v_zna:anim:fname:abbr" + " ./[null]null" + " /[null]null" + " Бакуліна/[Бакулін]noun:m:v_rod:anim:lname|Бакуліна/[Бакулін]noun:m:v_zna:anim:lname|Бакуліна/[Бакуліна]noun:f:v_naz:anim:lname" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( " Є.\u00A0Бакуліна" , "/[null]SENT_START" + " /[null]null" + " Є/[Є]noun:f:v_naz:anim:fname:abbr|Є/[Є]noun:m:v_rod:anim:fname:abbr|Є/[Є]noun:m:v_zna:anim:fname:abbr" + " ./[null]null" + " \u00A0/[null]null" + " Бакуліна/[Бакулін]noun:m:v_rod:anim:lname|Бакуліна/[Бакулін]noun:m:v_zna:anim:lname|Бакуліна/[Бакуліна]noun:f:v_naz:anim:lname" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Є.Л.Бакуліна" , "/[null]SENT_START" + " Є/[Є]noun:f:v_naz:anim:fname:abbr|Є/[Є]noun:m:v_rod:anim:fname:abbr|Є/[Є]noun:m:v_zna:anim:fname:abbr" + " ./[null]null" + " Л/[Л]noun:f:v_naz:anim:patr:abbr|Л/[Л]noun:m:v_rod:anim:patr:abbr|Л/[Л]noun:m:v_zna:anim:patr:abbr" + " ./[null]null" + " Бакуліна/[Бакулін]noun:m:v_rod:anim:lname|Бакуліна/[Бакулін]noun:m:v_zna:anim:lname|Бакуліна/[Бакуліна]noun:f:v_naz:anim:lname" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( " Є. Л. Бакуліна" , "/[null]SENT_START" + " /[null]null" + " Є/[Є]noun:f:v_naz:anim:fname:abbr|Є/[Є]noun:m:v_rod:anim:fname:abbr|Є/[Є]noun:m:v_zna:anim:fname:abbr" + " ./[null]null" + " /[null]null" + " Л/[Л]noun:f:v_naz:anim:patr:abbr|Л/[Л]noun:m:v_rod:anim:patr:abbr|Л/[Л]noun:m:v_zna:anim:patr:abbr" + " ./[null]null" + " /[null]null" + " Бакуліна/[Бакулін]noun:m:v_rod:anim:lname|Бакуліна/[Бакулін]noun:m:v_zna:anim:lname|Бакуліна/[Бакуліна]noun:f:v_naz:anim:lname" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( " Є. Л. Бакуліна і Г. К. Бакулін" , "/[null]SENT_START" + " /[null]null" + " Є/[Є]noun:f:v_naz:anim:fname:abbr|Є/[Є]noun:m:v_rod:anim:fname:abbr|Є/[Є]noun:m:v_zna:anim:fname:abbr" + " ./[null]null" + " /[null]null" + " Л/[Л]noun:f:v_naz:anim:patr:abbr|Л/[Л]noun:m:v_rod:anim:patr:abbr|Л/[Л]noun:m:v_zna:anim:patr:abbr" + " ./[null]null" + " /[null]null" + " Бакуліна/[Бакулін]noun:m:v_rod:anim:lname|Бакуліна/[Бакулін]noun:m:v_zna:anim:lname|Бакуліна/[Бакуліна]noun:f:v_naz:anim:lname" + " /[null]null" + " і/[і]conj:coord|і/[і]part" + " /[null]null" + " Г/[Г]noun:m:v_naz:anim:fname:abbr" + " ./[null]null" + " /[null]null" + " К/[К]noun:m:v_naz:anim:patr:abbr" + " ./[null]null" + " /[null]null" + " Бакулін/[Бакулін]noun:m:v_naz:anim:lname" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Комендант, преподобний С. С. Мокітімі, був чудовою людиною." , "/[null]SENT_START Комендант/[комендант]noun:m:v_naz:anim ,/[null]null" + " /[null]null преподобний/[преподобний]adj:m:v_naz|преподобний/[преподобний]adj:m:v_zna" + " /[null]null С/[null]null ./[null]null  /[null]null С/[null]null ./[null]null /[null]null" + " Мокітімі/[null]null ,/[null]null /[null]null" + " був/[бути]verb:past:m:imperf /[null]null чудовою/[чудовий]adj:f:v_oru:compb /[null]null людиною/[людина]noun:f:v_oru:anim ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; } public void testChunker ( ) throws Exception { JLanguageTool lt = new JLanguageTool ( new Ukrainian ( ) ) ; AnalyzedSentence analyzedSentence = lt . getAnalyzedSentence ( "Для годиться." ) ; AnalyzedSentence disambiguated = chunker . disambiguate ( analyzedSentence ) ; AnalyzedTokenReadings [ ] tokens = disambiguated . getTokens ( ) ; assertTrue ( tokens [ 1 ] . getReadings ( ) . toString ( ) . contains ( "<adv>" ) ) ; assertTrue ( tokens [ 4 ] . getReadings ( ) . toString ( ) . contains ( "</adv>" ) ) ; } }
package org . languagetool . tokenizers . uk ; import java . util . Arrays ; import java . util . List ; import junit . framework . TestCase ; public class UkrainianWordTokenizerTest extends TestCase { private final UkrainianWordTokenizer w = new UkrainianWordTokenizer ( ) ; public void testTokenizeUrl ( ) { String url = "http://youtube.com:80/herewego?start=11&quality=high%3F" ; List < String > testList = w . tokenize ( url ) ; assertEquals ( Arrays . asList ( url ) , testList ) ; } public void testNumbers ( ) { List < String > testList = w . tokenize ( "300 грн на балансі" ) ; assertEquals ( Arrays . asList ( "300" , " " , "грн" , " " , "на" , " " , "балансі" ) , testList ) ; testList = w . tokenize ( "надійшло 2,2 мільйона" ) ; assertEquals ( Arrays . asList ( "надійшло" , " " , "2,2" , " " , "мільйона" ) , testList ) ; testList = w . tokenize ( "надійшло 84,46 мільйона" ) ; assertEquals ( Arrays . asList ( "надійшло" , " " , "84,46" , " " , "мільйона" ) , testList ) ; testList = w . tokenize ( "сталося 14.07.2001 вночі" ) ; assertEquals ( Arrays . asList ( "сталося" , " " , "14.07.2001" , " " , "вночі" ) , testList ) ; testList = w . tokenize ( "вчора о 7.30 ранку" ) ; assertEquals ( Arrays . asList ( "вчора" , " " , "о" , " " , "7.30" , " " , "ранку" ) , testList ) ; } public void testTokenize ( ) { List < String > testList = w . tokenize ( "Вони прийшли додому." ) ; assertEquals ( Arrays . asList ( "Вони" , " " , "прийшли" , " " , "додому" , "." ) , testList ) ; testList = w . tokenize ( "Вони прийшли пʼятими зів’ялими." ) ; assertEquals ( Arrays . asList ( "Вони" , " " , "прийшли" , " " , "п'ятими" , " " , "зів'ялими" , "." ) , testList ) ; testList = w . tokenize ( "я українець(сміється" ) ; assertEquals ( Arrays . asList ( "я" , " " , "українець" , "(" , "сміється" ) , testList ) ; testList = w . tokenize ( "ОУН(б) та КП(б)У" ) ; assertEquals ( Arrays . asList ( "ОУН(б)" , " " , "та" , " " , "КП(б)У" ) , testList ) ; testList = w . tokenize ( "Негода є... заступником" ) ; assertEquals ( Arrays . asList ( "Негода" , " " , "є" , "..." , " " , "заступником" ) , testList ) ; testList = w . tokenize ( "Запагубили!.. також" ) ; assertEquals ( Arrays . asList ( "Запагубили" , "!.." , " " , "також" ) , testList ) ; testList = w . tokenize ( "Цей графин." ) ; assertEquals ( Arrays . asList ( "Цей" , " " , "графин" , "." ) , testList ) ; testList = w . tokenize ( "— Гм." ) ; assertEquals ( Arrays . asList ( "—" , " " , "Гм" , "." ) , testList ) ; } public void testAbbreviations ( ) { List < String > testList = w . tokenize ( "Засідав І.Єрмолюк." ) ; assertEquals ( Arrays . asList ( "Засідав" , " " , "І" , "." , "Єрмолюк" , "." ) , testList ) ; testList = w . tokenize ( "Засідав І.П.Єрмолюк." ) ; assertEquals ( Arrays . asList ( "Засідав" , " " , "І" , "." , "П" , "." , "Єрмолюк" , "." ) , testList ) ; testList = w . tokenize ( "І.\u00A0Єрмолюк." ) ; assertEquals ( Arrays . asList ( "І" , "." , "\u00A0" , "Єрмолюк" , "." ) , testList ) ; testList = w . tokenize ( "140 тис. працівників" ) ; assertEquals ( Arrays . asList ( "140" , " " , "тис." , " " , "працівників" ) , testList ) ; testList = w . tokenize ( "проф. Артюхов" ) ; assertEquals ( Arrays . asList ( "проф." , " " , "Артюхов" ) , testList ) ; testList = w . tokenize ( "проф.\u00A0Артюхов" ) ; assertEquals ( Arrays . asList ( "проф." , "\u00A0" , "Артюхов" ) , testList ) ; testList = w . tokenize ( "до н. е." ) ; assertEquals ( Arrays . asList ( "до" , " " , "н." , " " , "е." ) , testList ) ; testList = w . tokenize ( "до н.е." ) ; assertEquals ( Arrays . asList ( "до" , " " , "н." , "е." ) , testList ) ; testList = w . tokenize ( "1998 р.н." ) ; assertEquals ( Arrays . asList ( "1998" , " " , "р." , "н." ) , testList ) ; testList = w . tokenize ( "18-19 ст.ст. були" ) ; assertEquals ( Arrays . asList ( "18-19" , " " , "ст." , "ст." , " " , "були" ) , testList ) ; testList = w . tokenize ( "І ст. 11" ) ; assertEquals ( Arrays . asList ( "І" , " " , "ст." , " " , "11" ) , testList ) ; testList = w . tokenize ( "У с. Вижва" ) ; assertEquals ( Arrays . asList ( "У" , " " , "с." , " " , "Вижва" ) , testList ) ; testList = w . tokenize ( "Довжиною 30 с. з гаком." ) ; assertEquals ( Arrays . asList ( "Довжиною" , " " , "30" , " " , "с" , "." , " " , "з" , " " , "гаком" , "." ) , testList ) ; testList = w . tokenize ( "Довжиною 30 с. Поїхали." ) ; assertEquals ( Arrays . asList ( "Довжиною" , " " , "30" , " " , "с" , "." , " " , "Поїхали" , "." ) , testList ) ; testList = w . tokenize ( "100 м. дороги." ) ; assertEquals ( Arrays . asList ( "100" , " " , "м" , "." , " " , "дороги" , "." ) , testList ) ; testList = w . tokenize ( "На висоті 4000 м..." ) ; assertEquals ( Arrays . asList ( "На" , " " , "висоті" , " " , "4000" , " " , "м" , "..." ) , testList ) ; testList = w . tokenize ( "№47 (м. Слов'янськ)" ) ; assertEquals ( Arrays . asList ( "№47" , " " , "(" , "м." , " " , "Слов'янськ" , ")" ) , testList ) ; testList = w . tokenize ( "с.-г." ) ; assertEquals ( Arrays . asList ( "с.-г." ) , testList ) ; testList = w . tokenize ( "100 грн. в банк" ) ; assertEquals ( Arrays . asList ( "100" , " " , "грн" , "." , " " , "в" , " " , "банк" ) , testList ) ; testList = w . tokenize ( "таке та ін." ) ; assertEquals ( Arrays . asList ( "таке" , " " , "та" , " " , "ін." ) , testList ) ; testList = w . tokenize ( "і т. ін." ) ; assertEquals ( Arrays . asList ( "і" , " " , "т." , " " , "ін." ) , testList ) ; testList = w . tokenize ( "Інститут ім. акад. Вернадського." ) ; assertEquals ( Arrays . asList ( "Інститут" , " " , "ім." , " " , "акад." , " " , "Вернадського" , "." ) , testList ) ; testList = w . tokenize ( "Палац ім. гетьмана Скоропадського." ) ; assertEquals ( Arrays . asList ( "Палац" , " " , "ім." , " " , "гетьмана" , " " , "Скоропадського" , "." ) , testList ) ; testList = w . tokenize ( "від лат. momento" ) ; assertEquals ( Arrays . asList ( "від" , " " , "лат." , " " , "momento" ) , testList ) ; testList = w . tokenize ( "на 1-кімн. кв. в центрі" ) ; assertEquals ( Arrays . asList ( "на" , " " , "1-кімн." , " " , "кв." , " " , "в" , " " , "центрі" ) , testList ) ; } }
package org . languagetool . tokenizers . uk ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Ukrainian ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class UkrainianSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Ukrainian ( ) ) ; public final void testTokenize ( ) { testSplit ( "Це просте речення." ) ; testSplit ( "Вони приїхали в Париж. " , "Але там їм геть не сподобалося." ) ; testSplit ( "Панк-рок — напрям у рок-музиці, що виник у середині 1970-х рр. у США і Великобританії." ) ; testSplit ( "Разом із втечами, вже у XV ст. почастішали збройні виступи селян." ) ; testSplit ( "На початок 1994 р. державний борг України становив 4,8 млрд. дол." ) ; testSplit ( "Київ, вул. Сагайдачного, буд. 43, кв. 4." ) ; testSplit ( "Наша зустріч з А. Марчуком і Г. В. Тріскою відбулася в грудні минулого року." ) ; testSplit ( "Наша зустріч з А.Марчуком і М.В.Хвилею відбулася в грудні минулого року." ) ; testSplit ( "Комендант преподобний С.\u00A0Мокітімі" ) ; testSplit ( "Комендант преподобний С.\u00A0С.\u00A0Мокітімі 1." ) ; testSplit ( "Комендант преподобний С.\u00A0С. Мокітімі 2." ) ; testSplit ( "Склад: акад. Вернадський, проф. Харченко, доц. Семеняк." ) ; testSplit ( "Опергрупа приїхала в с. Лісове." ) ; testSplit ( "300 р. до н. е." ) ; testSplit ( "З 300 р. до н.е., і по цей день." ) ; testSplit ( "Пролісок (рос. пролесок) — маленька квітка." ) ; testSplit ( "Квітка Цісик (англ. Kvitka Cisyk також Kacey Cisyk від ініціалів К.С.); 4 квітня 1953р., Квінз, Нью-Йорк — 29 березня 1998 р., Мангеттен, Нью-Йорк) — американська співачка українського походження." ) ; testSplit ( "До Інституту ім. Глієра під'їжджає чорне авто." ) ; testSplit ( "До Інституту ім. акад. Вернадського." ) ; testSplit ( "До вулиці гетьмана Скоропадського під'їжджає чорне авто." ) ; testSplit ( "До табору «Артек»." ) ; testSplit ( "Спільні пральні й т. д." ) ; testSplit ( "Спільні пральні й т. д. й т. п." ) ; testSplit ( "див. стор. 24." ) ; testSplit ( "Є.Бакуліна" ) ; testSplit ( "Від англ.\n File." ) ; testSplit ( "Від фр. \nparachute." ) ; testSplit ( "В цих світлих просторих апартаментах... м’які крісла, килими, дорогі статуетки" ) ; testSplit ( "(вони самі це визнали. - Ред.)" ) ; testSplit ( "Всього 33 тис. 356 особи" ) ; testSplit ( "Всього 33 тис. (за словами прораба)" ) ; testSplit ( "з яких приблизно 1,2 тис. – чоловіки." ) ; testSplit ( "У с. Вижва" ) ; testSplit ( "Книжка (с. 200)" ) ; testSplit ( "позначені: «с. Вижва»" ) ; testSplit ( "Микола Васюк (с. Корнієнки, Полтавська обл.)" ) ; testSplit ( "U.S. Marine" ) ; testSplit ( "B.B. King" ) ; testSplit ( "Церква Св. Духа і церква св. Духа" ) ; } public void testTokenizeWithSplit ( ) { testSplit ( "Всього 33 тис." , "А можей й більше" ) ; testSplit ( "Їх було 7,5 млн." , "В кожного була сорочка." ) ; testSplit ( "Довжиною 30 с. " , "Поїхали." ) ; testSplit ( "Швидкістю 30 м/с. " , "Поїхали." ) ; testSplit ( "Останні 100 м. " , "І тут все пропало." ) ; testSplit ( "Корисна площа 67 тис. кв. м. " , "У 1954 році над Держпромом..." ) ; testSplit ( "На 0,6°C. " , "Але ми все маємо." ) ; testSplit ( "На 0,6°С. " , "Але ми все маємо." ) ; testSplit ( "На 0,6 °C. " , "Але ми все маємо." ) ; testSplit ( "На 0,6 °С. " , "Але ми все маємо." ) ; testSplit ( "Приїхав у США. " , "Проте на другий рік." ) ; } private void testSplit ( final String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . Locale ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . databroker . ResourceDataBroker ; import org . languagetool . rules . CommaWhitespaceRule ; import org . languagetool . rules . MultipleWhitespaceRule ; import org . languagetool . rules . Rule ; import org . languagetool . rules . uk . HiddenCharacterRule ; import org . languagetool . rules . uk . MixedAlphabetsRule ; import org . languagetool . rules . uk . MorfologikUkrainianSpellerRule ; import org . languagetool . rules . uk . SimpleReplaceRule ; import org . languagetool . rules . uk . SimpleReplaceSoftRule ; import org . languagetool . rules . uk . TokenAgreementRule ; import org . languagetool . rules . uk . UkrainianWordRepeatRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . uk . UkrainianSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . uk . UkrainianHybridDisambiguator ; import org . languagetool . tagging . uk . UkrainianTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . uk . UkrainianWordTokenizer ; public class Ukrainian extends Language { private static final List < String > RULE_FILES = Arrays . asList ( "grammar-spelling.xml" , "grammar-grammar.xml" , "grammar-barbarism.xml" , "grammar-style.xml" , "grammar-punctuation.xml" ) ; private Tagger tagger ; private SRXSentenceTokenizer sentenceTokenizer ; private Tokenizer wordTokenizer ; private Synthesizer synthesizer ; private Disambiguator disambiguator ; public Ukrainian ( ) { } @ Override public Pattern getIgnoredCharactersRegex ( ) { return Pattern . compile ( "[\u00AD\u0301]" ) ; } @ Override public Locale getLocale ( ) { return new Locale ( getShortName ( ) ) ; } @ Override public String getName ( ) { return "Ukrainian" ; } @ Override public String getShortName ( ) { return "uk" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "UA" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new UkrainianTagger ( ) ; } return tagger ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new UkrainianSynthesizer ( ) ; } return synthesizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new UkrainianHybridDisambiguator ( ) ; } return disambiguator ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new UkrainianWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public SRXSentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Andriy Rysin" ) , new Contributor ( "Maksym Davydov" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new MorfologikUkrainianSpellerRule ( messages , this ) , new MixedAlphabetsRule ( messages ) , new MultipleWhitespaceRule ( messages , this ) , new UkrainianWordRepeatRule ( messages , this ) , new SimpleReplaceRule ( messages ) , new SimpleReplaceSoftRule ( messages ) , new TokenAgreementRule ( messages ) , new HiddenCharacterRule ( messages ) ) ; } @ Override public List < String > getRuleFileNames ( ) { List < String > ruleFileNames = super . getRuleFileNames ( ) ; ResourceDataBroker dataBroker = JLanguageTool . getDataBroker ( ) ; String dirBase = dataBroker . getRulesDir ( ) + "/" + getShortName ( ) + "/" ; for ( String ruleFile : RULE_FILES ) { ruleFileNames . add ( dirBase + ruleFile ) ; } return ruleFileNames ; } }
package org . languagetool . synthesis . uk ; import org . languagetool . synthesis . BaseSynthesizer ; public class UkrainianSynthesizer extends BaseSynthesizer { private static final String RESOURCE_FILENAME = "/uk/ukrainian_synth.dict" ; private static final String TAGS_FILE_NAME = "/uk/ukrainian_tags.txt" ; public UkrainianSynthesizer ( ) { super ( RESOURCE_FILENAME , TAGS_FILE_NAME ) ; } }
package org . languagetool . rules . uk ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . Category ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public class HiddenCharacterRule extends Rule { private static final Character HIDDEN_CHAR = '\u00AD' ; public HiddenCharacterRule ( final ResourceBundle messages ) throws IOException { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } @ Override public final String getId ( ) { return "UK_HIDDEN_CHARS" ; } @ Override public String getDescription ( ) { return "Приховані символи: знак м’якого перенесення" ; } public String getShort ( ) { return "Приховані символи" ; } public String getSuggestion ( String word ) { String highlighted = word . replace ( HIDDEN_CHAR , '-' ) ; return " містить невидимий знак м’якого перенесення: «" + highlighted + "», виправлення: " ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) { List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; for ( AnalyzedTokenReadings tokenReadings : tokens ) { String tokenString = tokenReadings . getToken ( ) ; if ( tokenString . indexOf ( HIDDEN_CHAR ) != - 1 ) { RuleMatch potentialRuleMatch = createRuleMatch ( tokenReadings ) ; ruleMatches . add ( potentialRuleMatch ) ; } } return toRuleMatchArray ( ruleMatches ) ; } private RuleMatch createRuleMatch ( AnalyzedTokenReadings readings ) { String tokenString = readings . getToken ( ) ; String replacement = tokenString . replace ( HIDDEN_CHAR . toString ( ) , "" ) ; String msg = tokenString + getSuggestion ( tokenString ) + replacement ; RuleMatch potentialRuleMatch = new RuleMatch ( this , readings . getStartPos ( ) , readings . getEndPos ( ) , msg , getShort ( ) ) ; potentialRuleMatch . setSuggestedReplacements ( Arrays . asList ( replacement ) ) ; return potentialRuleMatch ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . uk ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . AbstractSimpleReplaceRule ; import java . io . IOException ; import java . util . List ; import java . util . Map ; import java . util . ResourceBundle ; public class SimpleReplaceSoftRule extends AbstractSimpleReplaceRule { private static final Map < String , List < String > > wrongWords = load ( "/uk/replace_soft.txt" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public SimpleReplaceSoftRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; } @ Override public final String getId ( ) { return "UK_SIMPLE_REPLACE_SOFT" ; } @ Override public String getDescription ( ) { return "Пошук нерекомендованих слів" ; } @ Override public String getShort ( ) { return "Нерекомендоване слово" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return tokenStr + " - нерекомендоване слово, кращий варіант: " + StringUtils . join ( replacements , ", " ) + "." ; } @ Override public boolean isCaseSensitive ( ) { return false ; } }
package org . languagetool . rules . ca ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class CatalanPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . uk ; import java . io . IOException ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; import org . languagetool . tagging . uk . IPOSTag ; public final class MorfologikUkrainianSpellerRule extends MorfologikSpellerRule { private static final String ABBREVIATION_CHAR = "." ; private static final String RESOURCE_FILENAME = "/uk/hunspell/uk_UA.dict" ; private static final Pattern UKRAINIAN_LETTERS = Pattern . compile ( ".*[а-яіїєґА-ЯІЇЄҐ].*" ) ; public MorfologikUkrainianSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_UK_UA" ; } @ Override protected boolean ignoreToken ( AnalyzedTokenReadings [ ] tokens , int idx ) throws IOException { String word = tokens [ idx ] . getToken ( ) ; if ( ! UKRAINIAN_LETTERS . matcher ( word ) . matches ( ) ) return true ; if ( super . ignoreToken ( tokens , idx ) ) return true ; if ( idx < tokens . length - 1 && tokens [ idx + 1 ] . getToken ( ) . equals ( ABBREVIATION_CHAR ) ) { if ( super . ignoreWord ( word + ABBREVIATION_CHAR ) ) { return true ; } if ( word . matches ( "[А-ЯІЇЄҐ]" ) ) { return true ; } } if ( word . contains ( "-" ) || word . endsWith ( "." ) ) { return hasGoodTag ( tokens [ idx ] ) ; } return false ; } private boolean hasGoodTag ( AnalyzedTokenReadings tokens ) { for ( AnalyzedToken analyzedToken : tokens ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag != null && ! posTag . equals ( JLanguageTool . SENTENCE_START_TAGNAME ) && ! posTag . equals ( JLanguageTool . SENTENCE_END_TAGNAME ) && ! posTag . contains ( IPOSTag . bad . getText ( ) ) ) return true ; } return false ; } }
package org . languagetool . rules . uk ; import java . io . IOException ; import java . text . MessageFormat ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collection ; import java . util . HashSet ; import java . util . List ; import java . util . ResourceBundle ; import java . util . Set ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . apache . commons . lang . StringUtils ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Ukrainian ; import org . languagetool . rules . Category ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . tagging . uk . IPOSTag ; import org . languagetool . tagging . uk . PosTagHelper ; public class TokenAgreementRule extends Rule { private static final String NO_VIDMINOK_SUBSTR = ":nv" ; private static final String REQUIRE_VIDMINOK_SUBSTR = ":rv_" ; private static final String VIDMINOK_SUBSTR = ":v_" ; private static final Pattern REQUIRE_VIDMINOK_REGEX = Pattern . compile ( ":r(v_[a-z]+)" ) ; private static final Pattern VIDMINOK_REGEX = Pattern . compile ( ":(v_[a-z]+)" ) ; private final Ukrainian ukrainian = new Ukrainian ( ) ; private static final Set < String > STREETS = new HashSet < > ( Arrays . asList ( "Штрассе" , "Авеню" , "Стріт" ) ) ; public TokenAgreementRule ( final ResourceBundle messages ) throws IOException { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } @ Override public final String getId ( ) { return "UK_TOKEN_AGREEMENT" ; } @ Override public String getDescription ( ) { return "Узгодження слів у реченні" ; } public String getShort ( ) { return "Узгодження слів у реченні" ; } public boolean isCaseSensitive ( ) { return false ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence text ) { List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; AnalyzedTokenReadings [ ] tokens = text . getTokensWithoutWhitespace ( ) ; boolean insideMultiword = false ; AnalyzedTokenReadings reqTokenReadings = null ; for ( int i = 0 ; i < tokens . length ; i ++ ) { AnalyzedTokenReadings tokenReadings = tokens [ i ] ; String posTag = tokenReadings . getAnalyzedToken ( 0 ) . getPOSTag ( ) ; if ( posTag == null || posTag . contains ( IPOSTag . unknown . getText ( ) ) || posTag . equals ( JLanguageTool . SENTENCE_START_TAGNAME ) ) { reqTokenReadings = null ; continue ; } String thisToken = tokenReadings . getToken ( ) ; if ( i > 1 && thisToken . length ( ) == 1 && Character . isUpperCase ( thisToken . charAt ( 0 ) ) && tokenReadings . isWhitespaceBefore ( ) && ! tokens [ i - 1 ] . getToken ( ) . matches ( "[:—–-]" ) ) { reqTokenReadings = null ; continue ; } AnalyzedToken multiwordReqToken = getMultiwordToken ( tokenReadings ) ; if ( multiwordReqToken != null ) { String mwPosTag = multiwordReqToken . getPOSTag ( ) ; if ( mwPosTag . startsWith ( "</" ) ) { insideMultiword = false ; } else { insideMultiword = true ; } if ( mwPosTag . startsWith ( "</" ) && mwPosTag . contains ( REQUIRE_VIDMINOK_SUBSTR ) ) { posTag = multiwordReqToken . getPOSTag ( ) ; reqTokenReadings = tokenReadings ; continue ; } else { if ( ! mwPosTag . contains ( "adv" ) && ! mwPosTag . contains ( "insert" ) ) { reqTokenReadings = null ; } continue ; } } if ( insideMultiword ) { continue ; } String token = tokenReadings . getAnalyzedToken ( 0 ) . getToken ( ) ; if ( posTag . contains ( REQUIRE_VIDMINOK_SUBSTR ) && tokenReadings . getReadingsLength ( ) == 1 ) { String prep = token ; if ( prep . equals ( "за" ) && reverseSearch ( tokens , i , "що" ) ) continue ; if ( prep . equalsIgnoreCase ( "понад" ) ) continue ; if ( ( prep . equalsIgnoreCase ( "окрім" ) || prep . equalsIgnoreCase ( "крім" ) ) && tokens . length > i + 1 && tokens [ i + 1 ] . getAnalyzedToken ( 0 ) . getToken ( ) . equalsIgnoreCase ( "як" ) ) { reqTokenReadings = null ; continue ; } reqTokenReadings = tokenReadings ; continue ; } if ( reqTokenReadings == null ) continue ; ArrayList < String > posTagsToFind = new ArrayList < > ( ) ; String reqPosTag = reqTokenReadings . getAnalyzedToken ( 0 ) . getPOSTag ( ) ; String prep = reqTokenReadings . getAnalyzedToken ( 0 ) . getLemma ( ) ; if ( prep . equalsIgnoreCase ( "понад" ) ) { posTagsToFind . add ( "v_naz" ) ; } else if ( prep . equalsIgnoreCase ( "замість" ) ) { posTagsToFind . add ( "v_naz" ) ; } Matcher matcher = REQUIRE_VIDMINOK_REGEX . matcher ( reqPosTag ) ; while ( matcher . find ( ) ) { posTagsToFind . add ( matcher . group ( 1 ) ) ; } for ( AnalyzedToken readingToken : tokenReadings ) { if ( IPOSTag . numr . match ( readingToken . getPOSTag ( ) ) ) { posTagsToFind . add ( "v_naz" ) ; break ; } } if ( ! getReadingWithVidmPosTag ( posTagsToFind , tokenReadings ) ) { if ( isTokenToSkip ( tokenReadings ) ) continue ; if ( prep . equalsIgnoreCase ( "в" ) || prep . equalsIgnoreCase ( "у" ) || prep . equals ( "межи" ) || prep . equals ( "між" ) ) { if ( PosTagHelper . hasPosTag ( tokenReadings , ".*p:v_naz[^&]*" ) ) { reqTokenReadings = null ; continue ; } } if ( prep . equalsIgnoreCase ( "на" ) && Character . isUpperCase ( token . charAt ( 0 ) ) && posTag . matches ( "noun:.:v_rod.*" ) ) { reqTokenReadings = null ; continue ; } if ( prep . equalsIgnoreCase ( "з" ) ) { if ( token . equals ( "рана" ) ) { reqTokenReadings = null ; continue ; } } if ( prep . equalsIgnoreCase ( "від" ) ) { if ( token . equalsIgnoreCase ( "а" ) || token . equals ( "рана" ) || token . equals ( "корки" ) || token . equals ( "мала" ) ) { reqTokenReadings = null ; continue ; } } else if ( prep . equalsIgnoreCase ( "до" ) ) { if ( token . equalsIgnoreCase ( "я" ) || token . equals ( "корки" ) || token . equals ( "велика" ) ) { reqTokenReadings = null ; continue ; } } if ( tokens . length > i + 1 ) { if ( isCapitalized ( token ) && STREETS . contains ( tokens [ i + 1 ] . getAnalyzedToken ( 0 ) . getToken ( ) ) ) { reqTokenReadings = null ; continue ; } if ( IPOSTag . isNum ( tokens [ i + 1 ] . getAnalyzedToken ( 0 ) . getPOSTag ( ) ) && ( token . equals ( "мінус" ) || token . equals ( "плюс" ) || token . equals ( "мінімум" ) || token . equals ( "максимум" ) ) ) { reqTokenReadings = null ; continue ; } if ( PosTagHelper . hasPosTag ( tokenReadings , "noun:.:v_oru.*" ) && tokens [ i + 1 ] . hasPartialPosTag ( "adjp" ) ) { continue ; } if ( ( prep . equalsIgnoreCase ( "через" ) || prep . equalsIgnoreCase ( "на" ) ) && ( posTag . startsWith ( "noun:p:v_naz" ) || posTag . startsWith ( "noun:p:v_rod" ) ) && IPOSTag . isNum ( tokens [ i + 1 ] . getAnalyzedToken ( 0 ) . getPOSTag ( ) ) ) { reqTokenReadings = null ; continue ; } if ( ( token . equals ( "вами" ) || token . equals ( "тобою" ) || token . equals ( "їми" ) ) && tokens [ i + 1 ] . getAnalyzedToken ( 0 ) . getToken ( ) . startsWith ( "ж" ) ) { continue ; } if ( ( token . equals ( "собі" ) || token . equals ( "йому" ) || token . equals ( "їм" ) ) && tokens [ i + 1 ] . getAnalyzedToken ( 0 ) . getToken ( ) . startsWith ( "подібн" ) ) { continue ; } if ( ( token . equals ( "усім" ) || token . equals ( "всім" ) ) && tokens [ i + 1 ] . getAnalyzedToken ( 0 ) . getToken ( ) . startsWith ( "відом" ) ) { continue ; } if ( prep . equalsIgnoreCase ( "до" ) && token . equals ( "схід" ) && tokens [ i + 1 ] . getAnalyzedToken ( 0 ) . getToken ( ) . equals ( "сонця" ) ) { reqTokenReadings = null ; continue ; } if ( tokens [ i + 1 ] . getAnalyzedToken ( 0 ) . getToken ( ) . equals ( "«" ) && tokens [ i ] . getAnalyzedToken ( 0 ) . getPOSTag ( ) . contains ( ":abbr" ) ) { reqTokenReadings = null ; continue ; } if ( tokens . length > i + 2 ) { if ( posTag . matches ( "adj.*:[mfn]:v_rod.*" ) ) { String gender = PosTagHelper . getGender ( posTag ) ; if ( gender == null ) { System . err . println ( "unknown gender for " + token ) ; } if ( PosTagHelper . hasPosTag ( tokens [ i + 1 ] , "noun.*:" + gender + ":v_rod.*" ) ) { i += 1 ; continue ; } } if ( ( token . equals ( "нікому" ) || token . equals ( "ніким" ) || token . equals ( "нічим" ) || token . equals ( "нічому" ) ) && tokens [ i + 1 ] . getAnalyzedToken ( 0 ) . getToken ( ) . equals ( "не" ) ) { continue ; } } } RuleMatch potentialRuleMatch = createRuleMatch ( tokenReadings , reqTokenReadings , posTagsToFind ) ; ruleMatches . add ( potentialRuleMatch ) ; } reqTokenReadings = null ; } return toRuleMatchArray ( ruleMatches ) ; } private static boolean isCapitalized ( String token ) { return token . length ( ) > 1 && Character . isUpperCase ( token . charAt ( 0 ) ) && Character . isLowerCase ( token . charAt ( 1 ) ) ; } private boolean reverseSearch ( AnalyzedTokenReadings [ ] tokens , int pos , String string ) { for ( int i = pos - 1 ; i >= 0 && i > pos - 4 ; i -- ) { if ( tokens [ i ] . getAnalyzedToken ( 0 ) . getToken ( ) . equalsIgnoreCase ( string ) ) return true ; } return false ; } private boolean forwardSearch ( AnalyzedTokenReadings [ ] tokens , int pos , String string , int maxSkip ) { for ( int i = pos + 1 ; i < tokens . length && i <= pos + maxSkip ; i ++ ) { if ( tokens [ i ] . getAnalyzedToken ( 0 ) . getToken ( ) . equalsIgnoreCase ( string ) ) return true ; } return false ; } private boolean isTokenToSkip ( AnalyzedTokenReadings tokenReadings ) { for ( AnalyzedToken token : tokenReadings ) { if ( IPOSTag . adv . match ( token . getPOSTag ( ) ) || IPOSTag . contains ( token . getPOSTag ( ) , "adv>" ) || IPOSTag . insert . match ( token . getPOSTag ( ) ) ) return true ; } return false ; } private boolean getReadingWithVidmPosTag ( Collection < String > posTagsToFind , AnalyzedTokenReadings tokenReadings ) { boolean vidminokFound = false ; for ( AnalyzedToken token : tokenReadings ) { String posTag = token . getPOSTag ( ) ; if ( posTag == null ) { if ( tokenReadings . getReadingsLength ( ) == 1 ) return true ; continue ; } if ( posTag . contains ( NO_VIDMINOK_SUBSTR ) ) return true ; if ( posTag . contains ( VIDMINOK_SUBSTR ) ) { vidminokFound = true ; for ( String posTagToFind : posTagsToFind ) { if ( posTag . contains ( posTagToFind ) ) return true ; } } } return ! vidminokFound ; } private RuleMatch createRuleMatch ( AnalyzedTokenReadings tokenReadings , AnalyzedTokenReadings reqTokenReadings , List < String > posTagsToFind ) { String tokenString = tokenReadings . getToken ( ) ; Synthesizer ukrainianSynthesizer = ukrainian . getSynthesizer ( ) ; ArrayList < String > suggestions = new ArrayList < > ( ) ; String oldPosTag = tokenReadings . getAnalyzedToken ( 0 ) . getPOSTag ( ) ; String requiredPostTagsRegEx = ":(" + StringUtils . join ( posTagsToFind , "|" ) + ")" ; String posTag = oldPosTag . replaceFirst ( ":v_[a-z]+" , requiredPostTagsRegEx ) ; try { String [ ] synthesized = ukrainianSynthesizer . synthesize ( tokenReadings . getAnalyzedToken ( 0 ) , posTag , true ) ; suggestions . addAll ( Arrays . asList ( synthesized ) ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } ArrayList < String > reqVidminkyNames = new ArrayList < > ( ) ; for ( String vidm : posTagsToFind ) { reqVidminkyNames . add ( PosTagHelper . VIDMINKY_MAP . get ( vidm ) ) ; } ArrayList < String > foundVidminkyNames = new ArrayList < > ( ) ; for ( AnalyzedToken token : tokenReadings ) { String posTag2 = token . getPOSTag ( ) ; if ( posTag2 != null && posTag2 . contains ( VIDMINOK_SUBSTR ) ) { String vidmName = PosTagHelper . VIDMINKY_MAP . get ( posTag2 . replaceFirst ( "^.*" + VIDMINOK_REGEX + ".*$" , "$1" ) ) ; if ( foundVidminkyNames . contains ( vidmName ) ) { if ( posTag2 . contains ( ":p:" ) ) { vidmName = vidmName + " (мн.)" ; foundVidminkyNames . add ( vidmName ) ; } } else { foundVidminkyNames . add ( vidmName ) ; } } } String msg = MessageFormat . format ( "Прийменник «{0}» вимагає іншого відмінка: {1}, а знайдено: {2}" , reqTokenReadings . getToken ( ) , StringUtils . join ( reqVidminkyNames , ", " ) , StringUtils . join ( foundVidminkyNames , ", " ) ) ; if ( tokenString . equals ( "їх" ) ) { msg += ". Можливо тут потрібно присвійний займенник «їхній»?" ; try { String newYihPostag = "adj:p" + requiredPostTagsRegEx + ".*" ; String [ ] synthesized = ukrainianSynthesizer . synthesize ( new AnalyzedToken ( "їхній" , "adj:m:v_naz:&pron:pos" , "їхній" ) , newYihPostag , true ) ; suggestions . addAll ( Arrays . asList ( synthesized ) ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } else if ( reqTokenReadings . getToken ( ) . equalsIgnoreCase ( "о" ) ) { for ( AnalyzedToken token : tokenReadings . getReadings ( ) ) { String posTag2 = token . getPOSTag ( ) ; if ( posTag2 . matches ( ".*:v_naz.*:anim.*" ) ) { msg += ". Можливо тут «о» — це вигук і потрібно кличний відмінок?" ; try { String newPostag = posTag2 . replace ( "v_naz" , "v_kly" ) ; String [ ] synthesized = ukrainianSynthesizer . synthesize ( token , newPostag , false ) ; for ( String string : synthesized ) { if ( ! string . equals ( token . getToken ( ) ) && ! suggestions . contains ( string ) ) { suggestions . add ( string ) ; } } break ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } } } RuleMatch potentialRuleMatch = new RuleMatch ( this , tokenReadings . getStartPos ( ) , tokenReadings . getEndPos ( ) , msg , getShort ( ) ) ; potentialRuleMatch . setSuggestedReplacements ( suggestions ) ; return potentialRuleMatch ; } @ Nullable private static AnalyzedToken getMultiwordToken ( AnalyzedTokenReadings analyzedTokenReadings ) { for ( AnalyzedToken analyzedToken : analyzedTokenReadings ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag != null && posTag . startsWith ( "<" ) ) return analyzedToken ; } return null ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . uk ; import java . util . ResourceBundle ; import org . languagetool . rules . AbstractPunctuationCheckRule ; public class PunctuationCheckRule extends AbstractPunctuationCheckRule { public PunctuationCheckRule ( final ResourceBundle messages ) { super ( messages ) ; } @ Override protected final boolean isPunctsJoinOk ( final String tokens ) { return tokens . matches ( "([,:] | *- |,- | ) *" ) || tokens . matches ( "([.!?]|!!!|\\?\\?\\?|\\?!!|!\\.\\.|\\?\\.\\.|\\.\\.\\.) *" ) ; } @ Override protected final boolean isPunctuation ( final String token ) { return token . matches ( "^[.,!?: -]$" ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . uk ; import java . util . * ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . WordRepeatRule ; import org . languagetool . tagging . uk . IPOSTag ; import org . languagetool . tagging . uk . PosTagHelper ; public class UkrainianWordRepeatRule extends WordRepeatRule { private static final HashSet < String > REPEAT_ALLOWED_SET = new HashSet < > ( Arrays . asList ( "що" , "ні" , "одне" , "ось" , "ст." ) ) ; private static final HashSet < String > REPEAT_ALLOWED_CAPS_SET = new HashSet < > ( Arrays . asList ( "ПРО" , "Джей" , "Ді" ) ) ; public UkrainianWordRepeatRule ( ResourceBundle messages , Language language ) { super ( messages , language ) ; } @ Override public String getId ( ) { return "UKRAINIAN_WORD_REPEAT_RULE" ; } @ Override public boolean ignore ( AnalyzedTokenReadings [ ] tokens , int position ) { AnalyzedTokenReadings analyzedTokenReadings = tokens [ position ] ; String token = analyzedTokenReadings . getToken ( ) ; if ( position > 1 && token . equals ( "добра" ) && tokens [ position - 2 ] . getToken ( ) . equalsIgnoreCase ( "від" ) ) return true ; if ( REPEAT_ALLOWED_SET . contains ( token . toLowerCase ( ) ) ) return true ; if ( REPEAT_ALLOWED_CAPS_SET . contains ( token ) ) return true ; if ( PosTagHelper . hasPosTag ( analyzedTokenReadings , "date|time|number" ) ) return true ; for ( AnalyzedToken analyzedToken : analyzedTokenReadings . getReadings ( ) ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag != null ) { if ( ! isInitial ( analyzedToken , tokens , position ) && ! posTag . equals ( JLanguageTool . SENTENCE_END_TAGNAME ) ) return false ; } } return true ; } private boolean isInitial ( AnalyzedToken analyzedToken , AnalyzedTokenReadings [ ] tokens , int position ) { return analyzedToken . getPOSTag ( ) . contains ( IPOSTag . abbr . getText ( ) ) || ( analyzedToken . getToken ( ) . length ( ) == 1 && Character . isUpperCase ( analyzedToken . getToken ( ) . charAt ( 0 ) ) && position < tokens . length - 1 && tokens [ position + 1 ] . getToken ( ) . equals ( "." ) ) ; } @ Override protected RuleMatch createRuleMatch ( String prevToken , String token , int prevPos , int pos , String msg ) { boolean doubleI = prevToken . equals ( "І" ) && token . equals ( "і" ) ; if ( doubleI ) { msg += " або, можливо, перша І має бути латинською." ; } RuleMatch ruleMatch = super . createRuleMatch ( prevToken , token , prevPos , pos , msg ) ; if ( doubleI ) { List < String > replacements = new ArrayList < > ( ruleMatch . getSuggestedReplacements ( ) ) ; replacements . add ( "I і" ) ; ruleMatch . setSuggestedReplacements ( replacements ) ; } return ruleMatch ; } }
package org . languagetool . rules . uk ; import java . io . IOException ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import org . apache . commons . lang . StringUtils ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . Category ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public class MixedAlphabetsRule extends Rule { private static final Pattern LIKELY_LATIN_NUMBER = Pattern . compile ( "[XVIХІ]{2,8}" ) ; private static final Pattern LATIN_NUMBER_WITH_CYRILLICS = Pattern . compile ( "Х{1,3}І{1,3}|І{1,3}Х{1,3}|Х{2,3}|І{2,3}" ) ; private static final Pattern MIXED_ALPHABETS = Pattern . compile ( ".*([a-zA-Z]'?[а-яіїєґА-ЯІЇЄҐ]|[а-яіїєґА-ЯІЇЄҐ]'?[a-zA-Z]).*" ) ; private static final Pattern CYRILLIC_ONLY = Pattern . compile ( ".*[бвгґдєжзйїлнпфцчшщьюяБГҐДЄЖЗИЙЇЛПФЦЧШЩЬЮЯ].*" ) ; private static final Pattern LATIN_ONLY = Pattern . compile ( ".*[bdfghjlqrsvzDFGLNQRSUVZ].*" ) ; private static final Pattern COMMON_CYR_LETTERS = Pattern . compile ( "[АВЕІКОРСТУХ]+" ) ; public MixedAlphabetsRule ( final ResourceBundle messages ) throws IOException { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } @ Override public final String getId ( ) { return "UK_MIXED_ALPHABETS" ; } @ Override public String getDescription ( ) { return "Змішування кирилиці й латиниці" ; } public String getShort ( ) { return "Мішанина розкладок" ; } public String getSuggestion ( String word ) { String highlighted = word . replaceAll ( "([a-zA-Z])([а-яіїєґА-ЯІЇЄҐ])" , "$1/$2" ) ; highlighted = highlighted . replaceAll ( "([а-яіїєґА-ЯІЇЄҐ])([a-zA-Z])" , "$1/$2" ) ; return " містить суміш кирилиці та латиниці: «" + highlighted + "», виправлення: " ; } public boolean isCaseSensitive ( ) { return true ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) { List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; int i = 0 ; for ( AnalyzedTokenReadings tokenReadings : tokens ) { String tokenString = tokenReadings . getToken ( ) ; if ( MIXED_ALPHABETS . matcher ( tokenString ) . matches ( ) ) { List < String > replacements = new ArrayList < > ( ) ; if ( ! LATIN_ONLY . matcher ( tokenString ) . matches ( ) && ! LIKELY_LATIN_NUMBER . matcher ( tokenString ) . matches ( ) ) { replacements . add ( toCyrillic ( tokenString ) ) ; } if ( ! CYRILLIC_ONLY . matcher ( tokenString ) . matches ( ) || LIKELY_LATIN_NUMBER . matcher ( tokenString ) . matches ( ) ) { replacements . add ( toLatin ( tokenString ) ) ; } if ( replacements . size ( ) > 0 ) { RuleMatch potentialRuleMatch = createRuleMatch ( tokenReadings , replacements ) ; ruleMatches . add ( potentialRuleMatch ) ; } } else if ( LATIN_NUMBER_WITH_CYRILLICS . matcher ( tokenString ) . matches ( ) ) { List < String > replacements = new ArrayList < > ( ) ; replacements . add ( toLatin ( tokenString ) ) ; RuleMatch potentialRuleMatch = createRuleMatch ( tokenReadings , replacements ) ; ruleMatches . add ( potentialRuleMatch ) ; } else if ( i > 1 && COMMON_CYR_LETTERS . matcher ( tokenString ) . matches ( ) ) { String prevLemma = tokens [ i - 1 ] . getAnalyzedToken ( 0 ) . getLemma ( ) ; if ( prevLemma != null && prevLemma . matches ( "гепатит|група|турнір" ) ) { List < String > replacements = new ArrayList < > ( ) ; replacements . add ( toLatin ( tokenString ) ) ; String msg = "Вжито кирилічну літеру замість латинської" ; RuleMatch potentialRuleMatch = new RuleMatch ( this , tokenReadings . getStartPos ( ) , tokenReadings . getEndPos ( ) , msg , getShort ( ) ) ; potentialRuleMatch . setSuggestedReplacements ( replacements ) ; ruleMatches . add ( potentialRuleMatch ) ; } } else if ( tokenString . endsWith ( "°С" ) ) { List < String > replacements = new ArrayList < > ( ) ; int length = tokenString . length ( ) ; replacements . add ( tokenString . substring ( 0 , length - 1 ) + toLatin ( tokenString . substring ( length - 1 , tokenString . length ( ) ) ) ) ; String msg = "Вжито кирилічну літеру замість латинської" ; RuleMatch potentialRuleMatch = new RuleMatch ( this , tokenReadings . getStartPos ( ) , tokenReadings . getEndPos ( ) , msg , getShort ( ) ) ; potentialRuleMatch . setSuggestedReplacements ( replacements ) ; ruleMatches . add ( potentialRuleMatch ) ; } i ++ ; } return toRuleMatchArray ( ruleMatches ) ; } private RuleMatch createRuleMatch ( AnalyzedTokenReadings readings , List < String > replacements ) { String tokenString = readings . getToken ( ) ; String msg = tokenString + getSuggestion ( tokenString ) + StringUtils . join ( replacements , ", " ) ; RuleMatch potentialRuleMatch = new RuleMatch ( this , readings . getStartPos ( ) , readings . getEndPos ( ) , msg , getShort ( ) ) ; potentialRuleMatch . setSuggestedReplacements ( replacements ) ; return potentialRuleMatch ; } @ Override public void reset ( ) { } private static final Map < Character , Character > toLatMap = new HashMap < > ( ) ; private static final Map < Character , Character > toCyrMap = new HashMap < > ( ) ; private static final String cyrChars = "аеікморстухАВЕІКМНОРСТУХ" ; private static final String latChars = "aeikmopctyxABEIKMHOPCTYX" ; static { for ( int i = 0 ; i < cyrChars . length ( ) ; i ++ ) { toLatMap . put ( cyrChars . charAt ( i ) , latChars . charAt ( i ) ) ; toCyrMap . put ( latChars . charAt ( i ) , cyrChars . charAt ( i ) ) ; } } private static String toCyrillic ( String word ) { for ( Map . Entry < Character , Character > entry : toCyrMap . entrySet ( ) ) { word = word . replace ( entry . getKey ( ) , entry . getValue ( ) ) ; } return word ; } private static String toLatin ( String word ) { for ( Map . Entry < Character , Character > entry : toLatMap . entrySet ( ) ) { word = word . replace ( entry . getKey ( ) , entry . getValue ( ) ) ; } return word ; } }
package org . languagetool . rules . uk ; import org . apache . commons . lang . StringUtils ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . rules . AbstractSimpleReplaceRule ; import org . languagetool . tagging . uk . IPOSTag ; import java . io . IOException ; import java . util . List ; import java . util . Map ; import java . util . ResourceBundle ; public class SimpleReplaceRule extends AbstractSimpleReplaceRule { private static final Map < String , List < String > > wrongWords = load ( "/uk/replace.txt" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public SimpleReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; setIgnoreTaggedWords ( ) ; } @ Override public final String getId ( ) { return "UK_SIMPLE_REPLACE" ; } @ Override public String getDescription ( ) { return "Пошук помилкових слів" ; } @ Override public String getShort ( ) { return "Помилка?" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return tokenStr + " - помилкове слово, виправлення: " + StringUtils . join ( replacements , ", " ) + "." ; } @ Override protected boolean isTagged ( AnalyzedTokenReadings tokenReadings ) { for ( AnalyzedToken token : tokenReadings . getReadings ( ) ) { String posTag = token . getPOSTag ( ) ; if ( isGoodPosTag ( posTag ) ) { return true ; } } return false ; } private boolean isGoodPosTag ( String posTag ) { return posTag != null && ! JLanguageTool . PARAGRAPH_END_TAGNAME . equals ( posTag ) && ! JLanguageTool . SENTENCE_END_TAGNAME . equals ( posTag ) && ! posTag . contains ( IPOSTag . bad . getText ( ) ) ; } @ Override public boolean isCaseSensitive ( ) { return false ; } }
package org . languagetool . rules . uk ; import org . languagetool . rules . AbstractDateCheckFilter ; import java . util . Calendar ; import java . util . Locale ; public class DateCheckFilter extends AbstractDateCheckFilter { @ Override protected Calendar getCalendar ( ) { return Calendar . getInstance ( Locale . forLanguageTag ( "uk" ) ) ; } @ Override protected int getDayOfWeek ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . startsWith ( "по" ) || day . equals ( "пн" ) ) return Calendar . MONDAY ; if ( day . startsWith ( "ві" ) || day . equals ( "вт" ) ) return Calendar . TUESDAY ; if ( day . startsWith ( "се" ) || day . equals ( "ср" ) ) return Calendar . WEDNESDAY ; if ( day . startsWith ( "че" ) || day . equals ( "чт" ) ) return Calendar . THURSDAY ; if ( day . startsWith ( "п'" ) || day . startsWith ( "п’" ) || day . equals ( "пт" ) ) return Calendar . FRIDAY ; if ( day . startsWith ( "су" ) || day . equals ( "сб" ) ) return Calendar . SATURDAY ; if ( day . startsWith ( "не" ) || day . equals ( "нд" ) ) return Calendar . SUNDAY ; throw new RuntimeException ( "Could not find day of week for '" + dayStr + "'" ) ; } @ Override protected String getDayOfWeek ( Calendar date ) { return date . getDisplayName ( Calendar . DAY_OF_WEEK , Calendar . LONG , Locale . forLanguageTag ( "uk" ) ) ; } @ Override protected int getMonth ( String monthStr ) { String mon = monthStr . toLowerCase ( ) ; if ( mon . startsWith ( "сі" ) ) return Calendar . JANUARY + 1 ; if ( mon . startsWith ( "лю" ) ) return Calendar . FEBRUARY + 1 ; if ( mon . startsWith ( "бе" ) ) return Calendar . MARCH + 1 ; if ( mon . startsWith ( "кв" ) ) return Calendar . APRIL + 1 ; if ( mon . startsWith ( "тр" ) ) return Calendar . MAY + 1 ; if ( mon . startsWith ( "че" ) ) return Calendar . JUNE + 1 ; if ( mon . startsWith ( "ли" ) ) return Calendar . JULY + 1 ; if ( mon . startsWith ( "се" ) ) return Calendar . AUGUST + 1 ; if ( mon . startsWith ( "ве" ) ) return Calendar . SEPTEMBER + 1 ; if ( mon . startsWith ( "жо" ) ) return Calendar . OCTOBER + 1 ; if ( mon . startsWith ( "ли" ) ) return Calendar . NOVEMBER + 1 ; if ( mon . startsWith ( "гр" ) ) return Calendar . DECEMBER + 1 ; throw new RuntimeException ( "Could not find month '" + monthStr + "'" ) ; } }
package org . languagetool . tagging . uk ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedToken ; import org . languagetool . tagging . BaseTagger ; import org . languagetool . tagging . TaggedWord ; import org . languagetool . tagging . WordTagger ; public class UkrainianTagger extends BaseTagger { static final Pattern NUMBER = Pattern . compile ( "[+-±]?[€₴\\$]?[0-9]+(,[0-9]+)?([-–—][0-9]+(,[0-9]+)?)?(%|°С?)?|(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})" ) ; private static final Pattern DATE = Pattern . compile ( "[\\d]{2}\\.[\\d]{2}\\.[\\d]{4}" ) ; private static final Pattern TIME = Pattern . compile ( "([01]?[0-9]|2[0-3])[.:][0-5][0-9]" ) ; private final CompoundTagger compoundTagger = new CompoundTagger ( this , wordTagger , conversionLocale ) ; @ Override public String getManualAdditionsFileName ( ) { return "/uk/added.txt" ; } public UkrainianTagger ( ) { super ( "/uk/ukrainian.dict" , new Locale ( "uk" , "UA" ) , false ) ; } @ Override public List < AnalyzedToken > additionalTags ( String word , WordTagger wordTagger ) { if ( NUMBER . matcher ( word ) . matches ( ) ) { List < AnalyzedToken > additionalTaggedTokens = new ArrayList < > ( ) ; additionalTaggedTokens . add ( new AnalyzedToken ( word , IPOSTag . number . getText ( ) , word ) ) ; return additionalTaggedTokens ; } if ( TIME . matcher ( word ) . matches ( ) ) { List < AnalyzedToken > additionalTaggedTokens = new ArrayList < > ( ) ; additionalTaggedTokens . add ( new AnalyzedToken ( word , IPOSTag . time . getText ( ) , word ) ) ; return additionalTaggedTokens ; } if ( DATE . matcher ( word ) . matches ( ) ) { List < AnalyzedToken > additionalTaggedTokens = new ArrayList < > ( ) ; additionalTaggedTokens . add ( new AnalyzedToken ( word , IPOSTag . date . getText ( ) , word ) ) ; return additionalTaggedTokens ; } if ( word . contains ( "-" ) ) { List < AnalyzedToken > guessedCompoundTags = compoundTagger . guessCompoundTag ( word ) ; return guessedCompoundTags ; } return null ; } @ Override protected List < AnalyzedToken > getAnalyzedTokens ( String word ) { List < AnalyzedToken > tokens = super . getAnalyzedTokens ( word ) ; if ( tokens . get ( 0 ) . getPOSTag ( ) == null ) { if ( ( word . indexOf ( '\u2013' ) != - 1 ) && word . matches ( ".*[а-яіїєґ][\u2013][а-яіїєґ].*" ) ) { String newWord = word . replace ( '\u2013' , '-' ) ; List < AnalyzedToken > newTokens = super . getAnalyzedTokens ( newWord ) ; for ( int i = 0 ; i < newTokens . size ( ) ; i ++ ) { AnalyzedToken analyzedToken = newTokens . get ( i ) ; if ( newWord . equals ( analyzedToken . getToken ( ) ) ) { String lemma = analyzedToken . getLemma ( ) ; if ( lemma != null ) { lemma = lemma . replace ( '-' , '\u2013' ) ; } AnalyzedToken newToken = new AnalyzedToken ( word , analyzedToken . getPOSTag ( ) , lemma ) ; newTokens . set ( i , newToken ) ; } } tokens = newTokens ; } } return tokens ; } List < AnalyzedToken > asAnalyzedTokenListForTaggedWordsInternal ( String word , List < TaggedWord > taggedWords ) { return super . asAnalyzedTokenListForTaggedWords ( word , taggedWords ) ; } }
package org . languagetool . tagging . uk ; public enum IPOSTag { noun ( "noun" ) , adj ( "adj" ) , verb ( "verb" ) , adv ( "adv" ) , part ( "part" ) , excl ( "excl" ) , numr ( "numr" ) , number ( "number" ) , date ( "date" ) , time ( "time" ) , advp ( "advp" ) , predic ( "predic" ) , insert ( "insert" ) , abbr ( "abbr" ) , bad ( "bad" ) , unknown ( "unknown" ) ; private final String text ; private IPOSTag ( String text ) { this . text = text ; } public String getText ( ) { return text ; } public boolean match ( String posTagPrefix ) { return posTagPrefix != null && posTagPrefix . startsWith ( this . name ( ) ) ; } public static boolean isNum ( String posTag ) { return numr . match ( posTag ) || number . match ( posTag ) ; } public static boolean contains ( String posTag , String postagMatch ) { return posTag != null && posTag . contains ( postagMatch ) ; } public static boolean startsWith ( String posTagPrefix , IPOSTag ... posTags ) { if ( posTagPrefix == null ) return false ; for ( IPOSTag posTag : posTags ) { if ( posTagPrefix . startsWith ( posTag . getText ( ) ) ) return true ; } return false ; } }
package org . languagetool . tagging . uk ; import java . io . BufferedWriter ; import java . io . IOException ; import java . io . InputStream ; import java . nio . charset . Charset ; import java . nio . file . Files ; import java . nio . file . Path ; import java . nio . file . Paths ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . HashMap ; import java . util . HashSet ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . Scanner ; import java . util . Set ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . JLanguageTool ; import org . languagetool . tagging . TaggedWord ; import org . languagetool . tagging . WordTagger ; class CompoundTagger { private static final String DEBUG_COMPOUNDS_PROPERTY = "org.languagetool.tagging.uk.UkrainianTagger.debugCompounds" ; private static final String TAG_ANIM = ":anim" ; private static final String NV_TAG = ":nv" ; private static final String COMPB_TAG = ":compb" ; private static final Pattern EXTRA_TAGS = Pattern . compile ( "(:(v-u|np|ns|bad|slang|rare))+" ) ; private static final Pattern NOUN_SING_V_ROD_REGEX = Pattern . compile ( "noun:[mfn]:v_rod.*" ) ; private static final Pattern NOUN_V_NAZ_REGEX = Pattern . compile ( "noun:.:v_naz.*" ) ; private static final Pattern SING_REGEX_F = Pattern . compile ( ":[mfn]:" ) ; private static final Pattern O_ADJ_PATTERN = Pattern . compile ( ".*(о|[чшщ]е)" ) ; private static final Pattern DASH_PREFIX_LAT_PATTERN = Pattern . compile ( "[a-zA-Z]{3,}" ) ; private static final Pattern MNP_NAZ_REGEX = Pattern . compile ( ".*:[mnp]:v_naz.*" ) ; private static final Pattern MNP_ZNA_REGEX = Pattern . compile ( ".*:[mnp]:v_zna.*" ) ; private static final Pattern MNP_ROD_REGEX = Pattern . compile ( ".*:[mnp]:v_rod.*" ) ; private static final String stdNounTag = IPOSTag . noun . getText ( ) + ":.:v_" ; private static final int stdNounTagLen = stdNounTag . length ( ) ; private static final Pattern stdNounTagRegex = Pattern . compile ( stdNounTag + ".*" ) ; private static final Set < String > dashPrefixes ; private static final Set < String > leftMasterSet ; private static final Set < String > cityAvenue = new HashSet < > ( Arrays . asList ( "сіті" , "авеню" , "стріт" , "штрассе" ) ) ; private static final Map < String , Pattern > rightPartsWithLeftTagMap = new HashMap < > ( ) ; private static final Set < String > slaveSet ; private static final Map < String , List < String > > NUMR_ENDING_MAP ; private static final String ADJ_TAG_FOR_PO_ADV_MIS = IPOSTag . adj . getText ( ) + ":m:v_mis" ; private static final String ADJ_TAG_FOR_PO_ADV_NAZ = IPOSTag . adj . getText ( ) + ":m:v_naz" ; private static final List < String > LEFT_O_ADJ = Arrays . asList ( "австро" , "адиго" , "американо" , "англо" , "афро" , "еко" , "етно" , "індо" , "іспано" , "києво" , "марокано" , "угро" ) ; static { Map < String , List < String > > map2 = new HashMap < > ( ) ; map2 . put ( "й" , Arrays . asList ( ":m:v_naz" , ":m:v_zna" ) ) ; map2 . put ( "го" , Arrays . asList ( ":m:v_rod" , ":m:v_zna" , ":n:v_rod" ) ) ; map2 . put ( "му" , Arrays . asList ( ":m:v_dav" , ":m:v_mis" , ":n:v_dav" , ":n:v_mis" , ":f:v_zna" ) ) ; map2 . put ( "м" , Arrays . asList ( ":m:v_oru" , ":n:v_oru" , ":p:v_dav" ) ) ; map2 . put ( "те" , Arrays . asList ( ":n:v_naz" , ":n:v_zna" ) ) ; map2 . put ( "ті" , Arrays . asList ( ":p:v_naz" , ":p:v_zna" ) ) ; map2 . put ( "х" , Arrays . asList ( ":p:v_rod" , ":p:v_zna" ) ) ; NUMR_ENDING_MAP = Collections . unmodifiableMap ( map2 ) ; rightPartsWithLeftTagMap . put ( "бо" , Pattern . compile ( "(verb(:rev)?:impr|.*pron|noun|adv|excl|part|predic).*" ) ) ; rightPartsWithLeftTagMap . put ( "но" , Pattern . compile ( "(verb(:rev)?:(impr|futr)|excl).*" ) ) ; rightPartsWithLeftTagMap . put ( "от" , Pattern . compile ( "(.*pron|adv|part).*" ) ) ; rightPartsWithLeftTagMap . put ( "то" , Pattern . compile ( "(.*pron|noun|adv|part|conj).*" ) ) ; rightPartsWithLeftTagMap . put ( "таки" , Pattern . compile ( "(verb(:rev)?:(futr|past|pres)|.*pron|noun|part|predic|insert).*" ) ) ; dashPrefixes = loadSet ( "/uk/dash_prefixes.txt" ) ; leftMasterSet = loadSet ( "/uk/dash_left_master.txt" ) ; slaveSet = loadSet ( "/uk/dash_slaves.txt" ) ; } private final WordTagger wordTagger ; private final Locale conversionLocale ; private final UkrainianTagger ukrainianTagger ; private BufferedWriter compoundUnknownDebugWriter ; private BufferedWriter compoundTaggedDebugWriter ; CompoundTagger ( UkrainianTagger ukrainianTagger , WordTagger wordTagger , Locale conversionLocale ) { this . ukrainianTagger = ukrainianTagger ; this . wordTagger = wordTagger ; this . conversionLocale = conversionLocale ; if ( Boolean . valueOf ( System . getProperty ( DEBUG_COMPOUNDS_PROPERTY ) ) ) { debugCompounds ( ) ; } } @ Nullable public List < AnalyzedToken > guessCompoundTag ( String word ) { List < AnalyzedToken > guessedCompoundTags = doGuessCompoundTag ( word ) ; debug_compound_tagged_write ( guessedCompoundTags ) ; return guessedCompoundTags ; } @ Nullable private List < AnalyzedToken > doGuessCompoundTag ( String word ) { int dashIdx = word . lastIndexOf ( '-' ) ; if ( dashIdx == 0 || dashIdx == word . length ( ) - 1 ) return null ; int firstDashIdx = word . indexOf ( '-' ) ; if ( dashIdx != firstDashIdx ) return null ; String leftWord = word . substring ( 0 , dashIdx ) ; String rightWord = word . substring ( dashIdx + 1 ) ; List < TaggedWord > leftWdList = tagBothCases ( leftWord ) ; if ( rightPartsWithLeftTagMap . containsKey ( rightWord ) ) { if ( leftWdList . isEmpty ( ) ) return null ; Pattern leftTagRegex = rightPartsWithLeftTagMap . get ( rightWord ) ; List < AnalyzedToken > leftAnalyzedTokens = ukrainianTagger . asAnalyzedTokenListForTaggedWordsInternal ( leftWord , leftWdList ) ; List < AnalyzedToken > newAnalyzedTokens = new ArrayList < > ( leftAnalyzedTokens . size ( ) ) ; for ( AnalyzedToken analyzedToken : leftAnalyzedTokens ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag != null && leftTagRegex . matcher ( posTag ) . matches ( ) ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , posTag , analyzedToken . getLemma ( ) ) ) ; } } return newAnalyzedTokens . isEmpty ( ) ? null : newAnalyzedTokens ; } if ( UkrainianTagger . NUMBER . matcher ( leftWord ) . matches ( ) ) { List < AnalyzedToken > newAnalyzedTokens = new ArrayList < > ( ) ; if ( NUMR_ENDING_MAP . containsKey ( rightWord ) ) { List < String > tags = NUMR_ENDING_MAP . get ( rightWord ) ; for ( String tag : tags ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , IPOSTag . adj . getText ( ) + tag , leftWord + "-" + "й" ) ) ; } } else { List < TaggedWord > rightWdList = wordTagger . tag ( rightWord ) ; if ( rightWdList . isEmpty ( ) ) return null ; List < AnalyzedToken > rightAnalyzedTokens = ukrainianTagger . asAnalyzedTokenListForTaggedWordsInternal ( rightWord , rightWdList ) ; for ( AnalyzedToken analyzedToken : rightAnalyzedTokens ) { if ( analyzedToken . getPOSTag ( ) . startsWith ( IPOSTag . adj . getText ( ) ) ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , analyzedToken . getPOSTag ( ) , leftWord + "-" + analyzedToken . getLemma ( ) ) ) ; } } } return newAnalyzedTokens . isEmpty ( ) ? null : newAnalyzedTokens ; } if ( leftWord . equalsIgnoreCase ( "по" ) && rightWord . endsWith ( "ськи" ) ) { rightWord += "й" ; } List < TaggedWord > rightWdList = wordTagger . tag ( rightWord ) ; if ( rightWdList . isEmpty ( ) ) return null ; List < AnalyzedToken > rightAnalyzedTokens = ukrainianTagger . asAnalyzedTokenListForTaggedWordsInternal ( rightWord , rightWdList ) ; if ( leftWord . equalsIgnoreCase ( "по" ) ) { if ( rightWord . endsWith ( "ому" ) ) { return poAdvMatch ( word , rightAnalyzedTokens , ADJ_TAG_FOR_PO_ADV_MIS ) ; } else if ( rightWord . endsWith ( "ський" ) ) { return poAdvMatch ( word , rightAnalyzedTokens , ADJ_TAG_FOR_PO_ADV_NAZ ) ; } return null ; } if ( dashPrefixes . contains ( leftWord ) || dashPrefixes . contains ( leftWord . toLowerCase ( ) ) || DASH_PREFIX_LAT_PATTERN . matcher ( leftWord ) . matches ( ) ) { return getNvPrefixNounMatch ( word , rightAnalyzedTokens , leftWord ) ; } if ( word . startsWith ( "пів-" ) && Character . isUpperCase ( word . charAt ( 4 ) ) ) { List < AnalyzedToken > newAnalyzedTokens = new ArrayList < > ( rightAnalyzedTokens . size ( ) ) ; for ( AnalyzedToken rightAnalyzedToken : rightAnalyzedTokens ) { String rightPosTag = rightAnalyzedToken . getPOSTag ( ) ; if ( rightPosTag == null ) continue ; if ( NOUN_SING_V_ROD_REGEX . matcher ( rightPosTag ) . matches ( ) ) { for ( String vid : PosTagHelper . VIDMINKY_MAP . keySet ( ) ) { if ( vid . equals ( "v_kly" ) ) continue ; String posTag = rightPosTag . replace ( "v_rod" , vid ) ; newAnalyzedTokens . add ( new AnalyzedToken ( word , posTag , word ) ) ; } } } return newAnalyzedTokens ; } if ( Character . isUpperCase ( leftWord . charAt ( 0 ) ) && cityAvenue . contains ( rightWord ) ) { if ( leftWdList . isEmpty ( ) ) return null ; List < AnalyzedToken > leftAnalyzedTokens = ukrainianTagger . asAnalyzedTokenListForTaggedWordsInternal ( leftWord , leftWdList ) ; return cityAvenueMatch ( word , leftAnalyzedTokens ) ; } if ( ! leftWdList . isEmpty ( ) ) { List < AnalyzedToken > leftAnalyzedTokens = ukrainianTagger . asAnalyzedTokenListForTaggedWordsInternal ( leftWord , leftWdList ) ; List < AnalyzedToken > tagMatch = tagMatch ( word , leftAnalyzedTokens , rightAnalyzedTokens ) ; if ( tagMatch != null ) { return tagMatch ; } } if ( O_ADJ_PATTERN . matcher ( leftWord ) . matches ( ) ) { return oAdjMatch ( word , rightAnalyzedTokens , leftWord ) ; } debug_compound_unknown_write ( word ) ; return null ; } @ Nullable private List < AnalyzedToken > cityAvenueMatch ( String word , List < AnalyzedToken > leftAnalyzedTokens ) { List < AnalyzedToken > newAnalyzedTokens = new ArrayList < > ( leftAnalyzedTokens . size ( ) ) ; for ( AnalyzedToken analyzedToken : leftAnalyzedTokens ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( NOUN_V_NAZ_REGEX . matcher ( posTag ) . matches ( ) ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , posTag . replaceFirst ( "v_naz" , "nv" ) , word ) ) ; } } return newAnalyzedTokens . isEmpty ( ) ? null : newAnalyzedTokens ; } @ Nullable private List < AnalyzedToken > tagMatch ( String word , List < AnalyzedToken > leftAnalyzedTokens , List < AnalyzedToken > rightAnalyzedTokens ) { List < AnalyzedToken > newAnalyzedTokens = new ArrayList < > ( ) ; List < AnalyzedToken > newAnalyzedTokensAnimInanim = new ArrayList < > ( ) ; String animInanimNotTagged = null ; for ( AnalyzedToken leftAnalyzedToken : leftAnalyzedTokens ) { String leftPosTag = leftAnalyzedToken . getPOSTag ( ) ; if ( leftPosTag == null ) continue ; String leftPosTagExtra = "" ; boolean leftNv = false ; if ( leftPosTag . contains ( NV_TAG ) ) { leftNv = true ; leftPosTag = leftPosTag . replace ( NV_TAG , "" ) ; } Matcher matcher = EXTRA_TAGS . matcher ( leftPosTag ) ; if ( matcher . find ( ) ) { leftPosTagExtra += matcher . group ( ) ; leftPosTag = matcher . replaceAll ( "" ) ; } if ( leftPosTag . contains ( COMPB_TAG ) ) { leftPosTag = leftPosTag . replace ( COMPB_TAG , "" ) ; } for ( AnalyzedToken rightAnalyzedToken : rightAnalyzedTokens ) { String rightPosTag = rightAnalyzedToken . getPOSTag ( ) ; if ( rightPosTag == null ) continue ; String extraNvTag = "" ; boolean rightNv = false ; if ( rightPosTag . contains ( NV_TAG ) ) { rightNv = true ; if ( leftNv ) { extraNvTag += NV_TAG ; } } Matcher matcherR = EXTRA_TAGS . matcher ( rightPosTag ) ; if ( matcherR . find ( ) ) { rightPosTag = matcherR . replaceAll ( "" ) ; } if ( rightPosTag . contains ( COMPB_TAG ) ) { rightPosTag = rightPosTag . replace ( COMPB_TAG , "" ) ; } if ( leftPosTag . equals ( rightPosTag ) && IPOSTag . startsWith ( leftPosTag , IPOSTag . numr , IPOSTag . adv , IPOSTag . adj , IPOSTag . excl , IPOSTag . verb ) ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , leftPosTag + extraNvTag + leftPosTagExtra , leftAnalyzedToken . getLemma ( ) + "-" + rightAnalyzedToken . getLemma ( ) ) ) ; } else if ( leftPosTag . startsWith ( IPOSTag . noun . getText ( ) ) && rightPosTag . startsWith ( IPOSTag . noun . getText ( ) ) ) { String agreedPosTag = getAgreedPosTag ( leftPosTag , rightPosTag , leftNv ) ; if ( agreedPosTag == null && rightPosTag . startsWith ( "noun:m:v_naz" ) && isMinMax ( rightAnalyzedToken . getToken ( ) ) ) { agreedPosTag = leftPosTag ; } if ( agreedPosTag == null && ! isSameAnimStatus ( leftPosTag , rightPosTag ) ) { agreedPosTag = tryAnimInanim ( leftPosTag , rightPosTag , leftAnalyzedToken . getLemma ( ) , rightAnalyzedToken . getLemma ( ) , leftNv , rightNv ) ; if ( agreedPosTag == null ) { animInanimNotTagged = leftPosTag . contains ( ":anim" ) ? "anim-inanim" : "inanim-anim" ; } else { newAnalyzedTokensAnimInanim . add ( new AnalyzedToken ( word , agreedPosTag + extraNvTag + leftPosTagExtra , leftAnalyzedToken . getLemma ( ) + "-" + rightAnalyzedToken . getLemma ( ) ) ) ; continue ; } } if ( agreedPosTag != null ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , agreedPosTag + extraNvTag + leftPosTagExtra , leftAnalyzedToken . getLemma ( ) + "-" + rightAnalyzedToken . getLemma ( ) ) ) ; } } else if ( leftPosTag . startsWith ( IPOSTag . numr . getText ( ) ) && rightPosTag . startsWith ( IPOSTag . numr . getText ( ) ) ) { String agreedPosTag = getNumAgreedPosTag ( leftPosTag , rightPosTag , leftNv ) ; if ( agreedPosTag != null ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , agreedPosTag + extraNvTag + leftPosTagExtra , leftAnalyzedToken . getLemma ( ) + "-" + rightAnalyzedToken . getLemma ( ) ) ) ; } } else if ( IPOSTag . startsWith ( leftPosTag , IPOSTag . noun ) && IPOSTag . startsWith ( rightPosTag , IPOSTag . numr ) ) { String leftGenderConj = PosTagHelper . getGenderConj ( leftPosTag ) ; if ( leftGenderConj != null && leftGenderConj . equals ( PosTagHelper . getGenderConj ( rightPosTag ) ) ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , leftPosTag + extraNvTag + leftPosTagExtra , leftAnalyzedToken . getLemma ( ) + "-" + rightAnalyzedToken . getLemma ( ) ) ) ; } else { String agreedPosTag = getNumAgreedPosTag ( leftPosTag , rightPosTag , leftNv ) ; if ( agreedPosTag != null ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , agreedPosTag + extraNvTag + leftPosTagExtra , leftAnalyzedToken . getLemma ( ) + "-" + rightAnalyzedToken . getLemma ( ) ) ) ; } } } else if ( leftPosTag . startsWith ( IPOSTag . noun . getText ( ) ) && IPOSTag . startsWith ( rightPosTag , IPOSTag . adj , IPOSTag . numr ) ) { String leftGenderConj = PosTagHelper . getGenderConj ( leftPosTag ) ; if ( leftGenderConj != null && leftGenderConj . equals ( PosTagHelper . getGenderConj ( rightPosTag ) ) ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , leftPosTag + extraNvTag + leftPosTagExtra , leftAnalyzedToken . getLemma ( ) + "-" + rightAnalyzedToken . getLemma ( ) ) ) ; } } } } if ( newAnalyzedTokens . isEmpty ( ) ) { newAnalyzedTokens = newAnalyzedTokensAnimInanim ; } if ( animInanimNotTagged != null && newAnalyzedTokens . isEmpty ( ) ) { debug_compound_unknown_write ( word + " " + animInanimNotTagged ) ; } return newAnalyzedTokens . isEmpty ( ) ? null : newAnalyzedTokens ; } @ Nullable private String getNumAgreedPosTag ( String leftPosTag , String rightPosTag , boolean leftNv ) { String agreedPosTag = null ; if ( leftPosTag . contains ( ":p:" ) && SING_REGEX_F . matcher ( rightPosTag ) . find ( ) || SING_REGEX_F . matcher ( leftPosTag ) . find ( ) && rightPosTag . contains ( ":p:" ) ) { String leftConj = PosTagHelper . getConj ( leftPosTag ) ; if ( leftConj != null && leftConj . equals ( PosTagHelper . getConj ( rightPosTag ) ) ) { agreedPosTag = leftPosTag ; } } return agreedPosTag ; } @ Nullable private String getAgreedPosTag ( String leftPosTag , String rightPosTag , boolean leftNv ) { if ( isPlural ( leftPosTag ) && ! isPlural ( rightPosTag ) || ! isPlural ( leftPosTag ) && isPlural ( rightPosTag ) ) return null ; if ( ! isSameAnimStatus ( leftPosTag , rightPosTag ) ) return null ; if ( stdNounTagRegex . matcher ( leftPosTag ) . matches ( ) ) { if ( stdNounTagRegex . matcher ( rightPosTag ) . matches ( ) ) { String substring1 = leftPosTag . substring ( stdNounTagLen , stdNounTagLen + 3 ) ; String substring2 = rightPosTag . substring ( stdNounTagLen , stdNounTagLen + 3 ) ; if ( substring1 . equals ( substring2 ) ) { if ( leftNv ) return rightPosTag ; return leftPosTag ; } } } return null ; } private static boolean isMinMax ( String rightToken ) { return rightToken . equals ( "максимум" ) || rightToken . equals ( "мінімум" ) ; } @ Nullable private String tryAnimInanim ( String leftPosTag , String rightPosTag , String leftLemma , String rightLemma , boolean leftNv , boolean rightNv ) { String agreedPosTag = null ; if ( leftMasterSet . contains ( leftLemma ) ) { if ( leftPosTag . contains ( TAG_ANIM ) ) { rightPosTag = rightPosTag + TAG_ANIM ; } else { rightPosTag = rightPosTag . replace ( TAG_ANIM , "" ) ; } agreedPosTag = getAgreedPosTag ( leftPosTag , rightPosTag , leftNv ) ; if ( agreedPosTag == null ) { if ( ! leftPosTag . contains ( TAG_ANIM ) ) { if ( MNP_ZNA_REGEX . matcher ( leftPosTag ) . matches ( ) && MNP_NAZ_REGEX . matcher ( rightPosTag ) . matches ( ) && ! leftNv && ! rightNv ) { agreedPosTag = leftPosTag ; } } else { if ( MNP_ZNA_REGEX . matcher ( leftPosTag ) . matches ( ) && MNP_ROD_REGEX . matcher ( rightPosTag ) . matches ( ) && ! leftNv && ! rightNv ) { agreedPosTag = leftPosTag ; } } } } else if ( slaveSet . contains ( rightLemma ) ) { rightPosTag = rightPosTag . replace ( ":anim" , "" ) ; agreedPosTag = getAgreedPosTag ( leftPosTag , rightPosTag , false ) ; if ( agreedPosTag == null ) { if ( ! leftPosTag . contains ( TAG_ANIM ) ) { if ( MNP_ZNA_REGEX . matcher ( leftPosTag ) . matches ( ) && MNP_NAZ_REGEX . matcher ( rightPosTag ) . matches ( ) && PosTagHelper . getNum ( leftPosTag ) . equals ( PosTagHelper . getNum ( rightPosTag ) ) && ! leftNv && ! rightNv ) { agreedPosTag = leftPosTag ; } } } } else if ( slaveSet . contains ( leftLemma ) ) { leftPosTag = leftPosTag . replace ( ":anim" , "" ) ; agreedPosTag = getAgreedPosTag ( rightPosTag , leftPosTag , false ) ; if ( agreedPosTag == null ) { if ( ! rightPosTag . contains ( TAG_ANIM ) ) { if ( MNP_ZNA_REGEX . matcher ( rightPosTag ) . matches ( ) && MNP_NAZ_REGEX . matcher ( leftPosTag ) . matches ( ) && PosTagHelper . getNum ( leftPosTag ) . equals ( PosTagHelper . getNum ( rightPosTag ) ) && ! leftNv && ! rightNv ) { agreedPosTag = rightPosTag ; } } } } return agreedPosTag ; } private static boolean isSameAnimStatus ( String leftPosTag , String rightPosTag ) { return leftPosTag . contains ( TAG_ANIM ) && rightPosTag . contains ( TAG_ANIM ) || ! leftPosTag . contains ( TAG_ANIM ) && ! rightPosTag . contains ( TAG_ANIM ) ; } private static boolean isPlural ( String posTag ) { return posTag . startsWith ( "noun:p:" ) ; } @ Nullable private List < AnalyzedToken > oAdjMatch ( String word , List < AnalyzedToken > analyzedTokens , String leftWord ) { List < AnalyzedToken > newAnalyzedTokens = new ArrayList < > ( analyzedTokens . size ( ) ) ; String leftBase = leftWord . substring ( 0 , leftWord . length ( ) - 1 ) ; if ( ! LEFT_O_ADJ . contains ( leftWord . toLowerCase ( conversionLocale ) ) && tagBothCases ( leftWord ) . isEmpty ( ) && tagBothCases ( oToYj ( leftWord ) ) . isEmpty ( ) && tagBothCases ( leftBase ) . isEmpty ( ) && tagBothCases ( leftBase + "а" ) . isEmpty ( ) ) return null ; for ( AnalyzedToken analyzedToken : analyzedTokens ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag . startsWith ( IPOSTag . adj . getText ( ) ) ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , posTag , leftWord + "-" + analyzedToken . getLemma ( ) ) ) ; } } return newAnalyzedTokens . isEmpty ( ) ? null : newAnalyzedTokens ; } private static String oToYj ( String leftWord ) { return leftWord . endsWith ( "ьо" ) ? leftWord . substring ( 0 , leftWord . length ( ) - 2 ) + "ій" : leftWord . substring ( 0 , leftWord . length ( ) - 1 ) + "ий" ; } @ Nullable private List < AnalyzedToken > getNvPrefixNounMatch ( String word , List < AnalyzedToken > analyzedTokens , String leftWord ) { List < AnalyzedToken > newAnalyzedTokens = new ArrayList < > ( analyzedTokens . size ( ) ) ; for ( AnalyzedToken analyzedToken : analyzedTokens ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag . startsWith ( IPOSTag . noun . getText ( ) ) ) { newAnalyzedTokens . add ( new AnalyzedToken ( word , posTag , leftWord + "-" + analyzedToken . getLemma ( ) ) ) ; } } return newAnalyzedTokens . isEmpty ( ) ? null : newAnalyzedTokens ; } @ Nullable private List < AnalyzedToken > poAdvMatch ( String word , List < AnalyzedToken > analyzedTokens , String adjTag ) { for ( AnalyzedToken analyzedToken : analyzedTokens ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag . startsWith ( adjTag ) ) { return Arrays . asList ( new AnalyzedToken ( word , IPOSTag . adv . getText ( ) , word ) ) ; } } return null ; } private String capitalize ( String word ) { return word . substring ( 0 , 1 ) . toUpperCase ( conversionLocale ) + word . substring ( 1 , word . length ( ) ) ; } private List < TaggedWord > tagBothCases ( String leftWord ) { List < TaggedWord > leftWdList = wordTagger . tag ( leftWord ) ; String leftLowerCase = leftWord . toLowerCase ( conversionLocale ) ; if ( ! leftWord . equals ( leftLowerCase ) ) { leftWdList . addAll ( wordTagger . tag ( leftLowerCase ) ) ; } else { String leftUpperCase = capitalize ( leftWord ) ; if ( ! leftWord . equals ( leftUpperCase ) ) { leftWdList . addAll ( wordTagger . tag ( leftUpperCase ) ) ; } } return leftWdList ; } private static Set < String > loadSet ( String path ) { Set < String > result = new HashSet < > ( ) ; try ( InputStream is = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( path ) ; Scanner scanner = new Scanner ( is , "UTF-8" ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; result . add ( line ) ; } return result ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } private void debugCompounds ( ) { try { Path unknownFile = Paths . get ( "compounds-unknown.txt" ) ; Files . deleteIfExists ( unknownFile ) ; unknownFile = Files . createFile ( unknownFile ) ; compoundUnknownDebugWriter = Files . newBufferedWriter ( unknownFile , Charset . defaultCharset ( ) ) ; Path taggedFile = Paths . get ( "compounds-tagged.txt" ) ; Files . deleteIfExists ( taggedFile ) ; taggedFile = Files . createFile ( taggedFile ) ; compoundTaggedDebugWriter = Files . newBufferedWriter ( taggedFile , Charset . defaultCharset ( ) ) ; } catch ( IOException ex ) { throw new RuntimeException ( ex ) ; } } private void debug_compound_tagged_write ( List < AnalyzedToken > guessedCompoundTags ) { if ( compoundTaggedDebugWriter == null || guessedCompoundTags == null ) return ; debug_tagged_write ( guessedCompoundTags , compoundTaggedDebugWriter ) ; } private void debug_compound_unknown_write ( String word ) { if ( compoundUnknownDebugWriter == null ) return ; try { compoundUnknownDebugWriter . append ( word ) ; compoundUnknownDebugWriter . newLine ( ) ; compoundUnknownDebugWriter . flush ( ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } private void debug_tagged_write ( List < AnalyzedToken > analyzedTokens , BufferedWriter writer ) { if ( analyzedTokens . get ( 0 ) . getLemma ( ) == null || analyzedTokens . get ( 0 ) . getToken ( ) . trim ( ) . isEmpty ( ) ) return ; try { String prevToken = "" ; String prevLemma = "" ; for ( AnalyzedToken analyzedToken : analyzedTokens ) { String token = analyzedToken . getToken ( ) ; boolean firstTag = false ; if ( ! prevToken . equals ( token ) ) { if ( prevToken . length ( ) > 0 ) { writer . append ( "; " ) ; prevLemma = "" ; } writer . append ( token ) . append ( " " ) ; prevToken = token ; firstTag = true ; } String lemma = analyzedToken . getLemma ( ) ; if ( ! prevLemma . equals ( lemma ) ) { if ( prevLemma . length ( ) > 0 ) { writer . append ( ", " ) ; } writer . append ( lemma ) ; prevLemma = lemma ; firstTag = true ; } writer . append ( firstTag ? " " : "|" ) . append ( analyzedToken . getPOSTag ( ) ) ; firstTag = false ; } writer . newLine ( ) ; writer . flush ( ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } }
package org . languagetool . tagging . ca ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; public class CatalanTaggerTest extends TestCase { private CatalanTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new CatalanTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Catalan ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "UPF" , "UPF/[UPF]NPFSO00" , tokenizer , tagger ) ; TestTools . myAssert ( "Sóc un home molt honrat." , "Sóc/[ser]VSIP1S00 -- un/[un]DI0MS0|un/[un]PI0MS000 -- home/[home]I|home/[home]NCMS000 -- molt/[molt]DI0MS0|molt/[molt]PI0MS000|molt/[molt]RG -- honrat/[honrar]VMP00SM0" , tokenizer , tagger ) ; TestTools . myAssert ( "blablabla" , "blablabla/[null]null" , tokenizer , tagger ) ; TestTools . myAssert ( "inajornablement" , "inajornablement/[inajornablement]RG" , tokenizer , tagger ) ; TestTools . myAssert ( "Acomplexadament" , "Acomplexadament/[acomplexadament]RG" , tokenizer , tagger ) ; } }
package org . languagetool . tagging . uk ; import java . util . Collections ; import java . util . LinkedHashMap ; import java . util . Map ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; public final class PosTagHelper { private static final Pattern NUM_REGEX = Pattern . compile ( "(noun|numr|adj|adjp.*):(.):v_.*" ) ; private static final Pattern CONJ_REGEX = Pattern . compile ( "(noun|numr|adj|adjp.*):[mfnp]:(v_...).*" ) ; private static final Pattern GENDER_REGEX = NUM_REGEX ; private static final Pattern GENDER_CONJ_REGEX = Pattern . compile ( "(noun|adj|numr|adjp.*):(.:v_...).*" ) ; public static final Map < String , String > VIDMINKY_MAP ; static { Map < String , String > map = new LinkedHashMap < > ( ) ; map . put ( "v_naz" , "називний" ) ; map . put ( "v_rod" , "родовий" ) ; map . put ( "v_dav" , "давальний" ) ; map . put ( "v_zna" , "знахідний" ) ; map . put ( "v_oru" , "орудний" ) ; map . put ( "v_mis" , "місцевий" ) ; map . put ( "v_kly" , "кличний" ) ; VIDMINKY_MAP = Collections . unmodifiableMap ( map ) ; } private PosTagHelper ( ) { } @ Nullable public static String getGender ( String posTag ) { Matcher pos4matcher = GENDER_REGEX . matcher ( posTag ) ; if ( pos4matcher . matches ( ) ) { return pos4matcher . group ( 2 ) ; } return null ; } @ Nullable public static String getNum ( String posTag ) { Matcher pos4matcher = NUM_REGEX . matcher ( posTag ) ; if ( pos4matcher . matches ( ) ) { String group = pos4matcher . group ( 2 ) ; if ( ! group . equals ( "p" ) ) { group = "s" ; } return group ; } return null ; } @ Nullable public static String getConj ( String posTag ) { Matcher pos4matcher = CONJ_REGEX . matcher ( posTag ) ; if ( pos4matcher . matches ( ) ) return pos4matcher . group ( 2 ) ; return null ; } @ Nullable public static String getGenderConj ( String posTag ) { Matcher pos4matcher = GENDER_CONJ_REGEX . matcher ( posTag ) ; if ( pos4matcher . matches ( ) ) return pos4matcher . group ( 2 ) ; return null ; } public static boolean hasPosTag ( AnalyzedTokenReadings analyzedTokenReadings , String posTagRegex ) { for ( AnalyzedToken analyzedToken : analyzedTokenReadings ) { if ( hasPosTag ( analyzedToken , posTagRegex ) ) return true ; } return false ; } public static boolean hasPosTag ( AnalyzedToken analyzedToken , String posTagRegex ) { String posTag = analyzedToken . getPOSTag ( ) ; return posTag != null && posTag . matches ( posTagRegex ) ; } }
package org . languagetool . tagging . disambiguation . uk ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . language . Ukrainian ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . MultiWordChunker ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; public class UkrainianHybridDisambiguator implements Disambiguator { private static final String LAST_NAME_TAG = ":lname" ; private static final Pattern INITIAL_REGEX = Pattern . compile ( "[А-ЯІЇЄҐ]" ) ; private final Disambiguator chunker = new MultiWordChunker ( "/uk/multiwords.txt" , true ) ; private final Disambiguator disambiguator = new XmlRuleDisambiguator ( new Ukrainian ( ) ) ; @ Override public final AnalyzedSentence disambiguate ( AnalyzedSentence input ) throws IOException { retagInitials ( input ) ; return disambiguator . disambiguate ( chunker . disambiguate ( input ) ) ; } private void retagInitials ( AnalyzedSentence input ) { AnalyzedTokenReadings [ ] tokens = input . getTokens ( ) ; for ( int i = 0 ; i < tokens . length - 2 ; i ++ ) { if ( isInitial ( tokens , i ) ) { boolean spaced = isSpace ( tokens [ i + 2 ] . getToken ( ) ) ; int spacedOffset = spaced ? 1 : 0 ; int nextPos = i + 2 + spacedOffset ; if ( nextPos + 2 + spacedOffset < tokens . length && isInitial ( tokens , nextPos ) && ( ! spaced || isSpace ( tokens [ nextPos + 2 ] . getToken ( ) ) ) && tokens [ nextPos + 2 + spacedOffset ] . hasPartialPosTag ( LAST_NAME_TAG ) ) { int currPos = nextPos ; nextPos += 2 + spacedOffset ; AnalyzedTokenReadings newReadings = getInitialReadings ( tokens [ currPos ] , tokens [ nextPos ] , "patr" ) ; tokens [ currPos ] = newReadings ; } if ( nextPos < tokens . length && tokens [ nextPos ] . hasPartialPosTag ( LAST_NAME_TAG ) ) { AnalyzedTokenReadings newReadings = getInitialReadings ( tokens [ i ] , tokens [ nextPos ] , "fname" ) ; tokens [ i ] = newReadings ; i = nextPos ; } } } } private static AnalyzedTokenReadings getInitialReadings ( AnalyzedTokenReadings initialsReadings , AnalyzedTokenReadings lnameTokens , String initialType ) { List < AnalyzedToken > newTokens = new ArrayList < > ( ) ; for ( AnalyzedToken lnameToken : lnameTokens . getReadings ( ) ) { String lnamePosTag = lnameToken . getPOSTag ( ) ; if ( lnamePosTag == null || ! lnamePosTag . contains ( LAST_NAME_TAG ) ) continue ; String initialsToken = initialsReadings . getAnalyzedToken ( 0 ) . getToken ( ) ; AnalyzedToken newToken = new AnalyzedToken ( initialsToken , lnamePosTag . replace ( LAST_NAME_TAG , ":" + initialType + ":abbr" ) , initialsToken ) ; newTokens . add ( newToken ) ; } return new AnalyzedTokenReadings ( newTokens , initialsReadings . getStartPos ( ) ) ; } private static boolean isInitial ( AnalyzedTokenReadings [ ] tokens , int pos ) { return pos < tokens . length - 2 && tokens [ pos + 1 ] . getToken ( ) . equals ( "." ) && INITIAL_REGEX . matcher ( tokens [ pos ] . getToken ( ) ) . matches ( ) ; } private static boolean isSpace ( String str ) { return str != null && ( str . equals ( " " ) || str . equals ( "\u00A0" ) ) ; } }
package org . languagetool . tokenizers . uk ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Map . Entry ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import java . util . StringTokenizer ; import org . languagetool . tokenizers . Tokenizer ; public class UkrainianWordTokenizer implements Tokenizer { private static final String SPLIT_CHARS = "\u0020\u00A0\u115f\u1160\u1680" + "\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007" + "\u2008\u2009\u200A\u200B\u200c\u200d\u200e\u200f" + "\u2028\u2029\u202a\u202b\u202c\u202d\u202e\u202f" + "\u205F\u2060\u2061\u2062\u2063\u206A\u206b\u206c\u206d" + "\u206E\u206F\u3000\u3164\ufeff\uffa0\ufff9\ufffa\ufffb" + ",.;()[]{}<>!?:/|\\\"«»„”“`´‘‛′…¿¡\t\n\r\uE100\uE101\uE102\uE110" ; private static final Pattern DECIMAL_COMMA_PATTERN = Pattern . compile ( "([\\d]),([\\d])" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final char DECIMAL_COMMA_SUBST = '\uE001' ; private static final Pattern DOTTED_NUMBERS_PATTERN = Pattern . compile ( "([\\d])\\.([\\d])" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final char NUMBER_DOT_SUBST = '\uE002' ; private static final Pattern COLON_NUMBERS_PATTERN = Pattern . compile ( "([\\d]):([\\d])" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final char COLON_DOT_SUBST = '\uE003' ; private static final Pattern DATE_PATTERN = Pattern . compile ( "([\\d]{2})\\.([\\d]{2})\\.([\\d]{4})|([\\d]{4})\\.([\\d]{2})\\.([\\d]{2})|([\\d]{4})-([\\d]{2})-([\\d]{2})" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final char DATE_DOT_SUBST = '\uE004' ; private static final Pattern BRACE_IN_WORD_PATTERN = Pattern . compile ( "([а-яіїєґ'])\\(([а-яіїєґ']+)\\)" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final char LEFT_BRACE_SUBST = '\uE005' ; private static final char RIGHT_BRACE_SUBST = '\uE006' ; private static final Pattern ABBR_DOT_PATTERN = Pattern . compile ( "(тис)\\.([ \u00A0]+[а-яіїєґ])" ) ; private static final Pattern ABBR_DOT_PATTERN1 = Pattern . compile ( "([^а-яіїєґА-ЯІЇЄҐ'-]лат)\\.([ \u00A0]+[a-zA-Z])" ) ; private static final Pattern ABBR_DOT_PATTERN2 = Pattern . compile ( "([Аа]кад|[Пп]роф|[Дд]оц|[Аа]сист|вул|о|р|ім)\\.([\\s\u00A0]+[А-ЯІЇЄҐ])" ) ; private static final Pattern ABBR_DOT_PATTERN5 = Pattern . compile ( "((?:[0-9]|кв\\.?|куб\\.?)[\\s\u00A0]+[см])\\." ) ; private static final Pattern ABBR_DOT_PATTERN3 = Pattern . compile ( "(с)\\.(-г)\\." ) ; private static final Pattern ABBR_DOT_PATTERN4 = Pattern . compile ( "([^а-яіїєґ'-][векнпрстцч]{1,2})\\.([екмнпрстч]{1,2})\\." ) ; private static final Pattern ABBR_DOT_PATTERN6 = Pattern . compile ( "([^а-яіїєґА-ЯІЇЄҐ'-]((та|й) ін|амер|англ|бл(изьк)?|вірм|грец(ьк)|див|дол|досл|доц|е|ел|жін|заст|зв|ім|івр|ісп|італ|к|кв|[1-9]-кімн|кімн|кл|коп|м|н|напр|обл|п|пен|перекл|пл|пор|поч|прибл|пров|просп|р|[Рр]ед|[Рр]еж|рр|рт|руб|с|[Сс]в|соц|співавт|ст|стол|стор|табл|тел|укр|філол|фр|франц|ч|чайн|чол|ц|шт))\\." ) ; private static final Pattern ABBR_DOT_PATTERN7 = Pattern . compile ( "([ій][ \u00A0]+т)\\.([ \u00A0]*(д|п|ін))\\." ) ; private static final char ABBR_DOT_SUBST = '\uE007' ; private static final String BREAKING_PLACEHOLDER = "\uE110" ; private static final String ELLIPSIS = "..." ; private static final String ELLIPSIS_SUBST = "\uE100" ; private static final String ELLIPSIS2 = "!.." ; private static final String ELLIPSIS2_SUBST = "\uE101" ; private static final String ELLIPSIS3 = "?.." ; private static final String ELLIPSIS3_SUBST = "\uE102" ; private static final Pattern URL_PATTERN = Pattern . compile ( "^(https?|ftp)://[^\\s/$.?#].[^\\s]*$" , Pattern . CASE_INSENSITIVE ) ; private static final int URL_START_REPLACE_CHAR = 0xE300 ; public UkrainianWordTokenizer ( ) { } @ Override public List < String > tokenize ( String text ) { HashMap < String , String > urls = new HashMap < > ( ) ; text = cleanup ( text ) ; if ( text . contains ( "," ) ) { text = DECIMAL_COMMA_PATTERN . matcher ( text ) . replaceAll ( "$1" + DECIMAL_COMMA_SUBST + "$2" ) ; } if ( text . contains ( "tp" ) ) { Matcher matcher = URL_PATTERN . matcher ( text ) ; int urlReplaceChar = URL_START_REPLACE_CHAR ; while ( matcher . find ( ) ) { String urlGroup = matcher . group ( ) ; String replaceChar = String . valueOf ( ( char ) urlReplaceChar ) ; urls . put ( replaceChar , urlGroup ) ; text = matcher . replaceAll ( replaceChar ) ; urlReplaceChar ++ ; } } if ( text . contains ( ELLIPSIS ) ) { text = text . replace ( ELLIPSIS , ELLIPSIS_SUBST ) ; } if ( text . contains ( ELLIPSIS2 ) ) { text = text . replace ( ELLIPSIS2 , ELLIPSIS2_SUBST ) ; } if ( text . contains ( ELLIPSIS3 ) ) { text = text . replace ( ELLIPSIS3 , ELLIPSIS3_SUBST ) ; } if ( text . contains ( "." ) ) { text = DATE_PATTERN . matcher ( text ) . replaceAll ( "$1" + DATE_DOT_SUBST + "$2" + DATE_DOT_SUBST + "$3" ) ; text = DOTTED_NUMBERS_PATTERN . matcher ( text ) . replaceAll ( "$1" + NUMBER_DOT_SUBST + "$2" ) ; text = ABBR_DOT_PATTERN4 . matcher ( text ) . replaceAll ( "$1" + ABBR_DOT_SUBST + BREAKING_PLACEHOLDER + "$2" + ABBR_DOT_SUBST ) ; text = ABBR_DOT_PATTERN . matcher ( text ) . replaceAll ( "$1" + ABBR_DOT_SUBST + "$2" ) ; text = ABBR_DOT_PATTERN1 . matcher ( text ) . replaceAll ( "$1" + ABBR_DOT_SUBST + "$2" ) ; text = ABBR_DOT_PATTERN2 . matcher ( text ) . replaceAll ( "$1" + ABBR_DOT_SUBST + "$2" ) ; text = ABBR_DOT_PATTERN5 . matcher ( text ) . replaceAll ( "$1" + BREAKING_PLACEHOLDER + ABBR_DOT_SUBST ) ; text = ABBR_DOT_PATTERN3 . matcher ( text ) . replaceAll ( "$1" + ABBR_DOT_SUBST + "$2" + ABBR_DOT_SUBST ) ; text = ABBR_DOT_PATTERN6 . matcher ( text ) . replaceAll ( "$1" + ABBR_DOT_SUBST ) ; text = ABBR_DOT_PATTERN7 . matcher ( text ) . replaceAll ( "$1" + ABBR_DOT_SUBST + "$2" + ABBR_DOT_SUBST ) ; } if ( text . contains ( ":" ) ) { text = COLON_NUMBERS_PATTERN . matcher ( text ) . replaceAll ( "$1" + COLON_DOT_SUBST + "$2" ) ; } if ( text . contains ( "(" ) ) { text = BRACE_IN_WORD_PATTERN . matcher ( text ) . replaceAll ( "$1" + LEFT_BRACE_SUBST + "$2" + RIGHT_BRACE_SUBST ) ; } List < String > tokenList = new ArrayList < > ( ) ; StringTokenizer st = new StringTokenizer ( text , SPLIT_CHARS , true ) ; while ( st . hasMoreElements ( ) ) { String token = st . nextToken ( ) ; if ( token . equals ( BREAKING_PLACEHOLDER ) ) continue ; token = token . replace ( DECIMAL_COMMA_SUBST , ',' ) ; token = token . replace ( DATE_DOT_SUBST , '.' ) ; token = token . replace ( NUMBER_DOT_SUBST , '.' ) ; token = token . replace ( ABBR_DOT_SUBST , '.' ) ; token = token . replace ( COLON_DOT_SUBST , ':' ) ; token = token . replace ( LEFT_BRACE_SUBST , '(' ) ; token = token . replace ( RIGHT_BRACE_SUBST , ')' ) ; token = token . replaceAll ( ELLIPSIS_SUBST , ELLIPSIS ) ; token = token . replaceAll ( ELLIPSIS2_SUBST , ELLIPSIS2 ) ; token = token . replaceAll ( ELLIPSIS3_SUBST , ELLIPSIS3 ) ; if ( ! urls . isEmpty ( ) ) { for ( Entry < String , String > entry : urls . entrySet ( ) ) { token = token . replace ( entry . getKey ( ) , entry . getValue ( ) ) ; } } tokenList . add ( token ) ; } return tokenList ; } private static String cleanup ( String text ) { text = text . replace ( '’' , '\'' ) . replace ( 'ʼ' , '\'' ) ; return text ; } }
package org . languagetool ; import junit . framework . TestCase ; import org . languagetool . language . Japanese ; import java . io . IOException ; public class JLanguageToolTest extends TestCase { public void testJapanese ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new Japanese ( ) ) ; assertEquals ( 0 , tool . check ( "エラーを含まないテスト文です。" ) . size ( ) ) ; assertEquals ( 1 , tool . check ( "エラーお含むテスト文です。" ) . size ( ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Japanese ; public class JapaneseConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Japanese ( ) ; } @ Override protected String createSampleText ( ) { return "私はガラスを食べられます。それは私を傷つけませ" ; } }
package org . languagetool . rules . ja ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class JapanesePatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . tagging . ja ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . tokenizers . ja . JapaneseWordTokenizer ; public class JapaneseTaggerTest extends TestCase { private JapaneseTagger tagger ; private JapaneseWordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new JapaneseTagger ( ) ; tokenizer = new JapaneseWordTokenizer ( ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "これは簡単なテストです。" , "これ/[これ]名詞-代名詞-一般 -- は/[は]助詞-係助詞 -- 簡単/[簡単]名詞-形容動詞語幹 -- な/[だ]助動詞 -- テスト/[テスト]名詞-サ変接続 -- です/[です]助動詞 -- 。/[。]記号-句点" , tokenizer , tagger ) ; TestTools . myAssert ( "私は眠い。" , "私/[私]名詞-代名詞-一般 -- は/[は]助詞-係助詞 -- 眠い/[眠い]形容詞-自立 -- 。/[。]記号-句点" , tokenizer , tagger ) ; TestTools . myAssert ( "とても冷たい飲み物。" , "とても/[とても]副詞-助詞類接続 -- 冷たい/[冷たい]形容詞-自立 -- 飲み物/[飲み物]名詞-一般 -- 。/[。]記号-句点" , tokenizer , tagger ) ; } }
package org . languagetool . tokenizers . ja ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Japanese ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class JapaneseSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Japanese ( ) ) ; public void testTokenize ( ) { testSplit ( "これはテスト用の文です。" ) ; testSplit ( "これはテスト用の文です。" , "追加のテスト用の文です。" ) ; testSplit ( "これは、テスト用の文です。" ) ; testSplit ( "テスト用の文です！" , "追加のテスト用の文です。" ) ; testSplit ( "テスト用の文です... " , "追加のテスト用の文です。" ) ; testSplit ( "アドレスはhttp://www.test.deです。" ) ; testSplit ( "これは(!)の文です。" ) ; testSplit ( "これは(!!)の文です。" ) ; testSplit ( "これは(?)の文です。" ) ; testSplit ( "これは(??)の文です。" ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . tokenizers . ja ; import junit . framework . TestCase ; import java . util . List ; public class JapaneseWordTokenizerTest extends TestCase { public void testTokenize ( ) { JapaneseWordTokenizer w = new JapaneseWordTokenizer ( ) ; List < String > testList = w . tokenize ( "これはペンです。" ) ; assertEquals ( testList . size ( ) , 5 ) ; assertEquals ( "[これ 名詞-代名詞-一般 これ, は 助詞-係助詞 は, ペン 名詞-一般 ペン, です 助動詞 です, 。 記号-句点 。]" , testList . toString ( ) ) ; testList = w . tokenize ( "私は「うん、そうだ」と答えた。" ) ; assertEquals ( testList . size ( ) , 12 ) ; assertEquals ( "[私 名詞-代名詞-一般 私, は 助詞-係助詞 は, 「 記号-括弧開 「, うん 感動詞 うん, 、 記号-読点 、, そう 副詞-助詞類接続 そう, だ 助動詞 だ, 」 記号-括弧閉 」, と 助詞-格助詞-引用 と, 答え 動詞-自立 答える, た 助動詞 た, 。 記号-句点 。]" , testList . toString ( ) ) ; } }
package org . languagetool . language ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . DoublePunctuationRule ; import org . languagetool . rules . MultipleWhitespaceRule ; import org . languagetool . rules . Rule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . ja . JapaneseTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . ja . JapaneseWordTokenizer ; public class Japanese extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; @ Override public String getShortName ( ) { return "ja" ; } @ Override public String getName ( ) { return "Japanese" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "JP" } ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Takahiro Shinkai" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Arrays . asList ( new DoublePunctuationRule ( messages ) , new MultipleWhitespaceRule ( messages , this ) ) ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new JapaneseTagger ( ) ; } return tagger ; } @ Override public Tokenizer getWordTokenizer ( ) { return new JapaneseWordTokenizer ( ) ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } }
package org . languagetool . tagging . disambiguation ; import java . io . IOException ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . tagging . disambiguation . rules . DisambiguationRuleTest ; import org . languagetool . tagging . ca . CatalanTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . ca . CatalanWordTokenizer ; public class CatalanDisambiguationRuleTest extends DisambiguationRuleTest { private CatalanTagger tagger ; private CatalanWordTokenizer tokenizer ; private SentenceTokenizer sentenceTokenizer ; private MultiWordChunker disambiguator ; @ Override public void setUp ( ) { tagger = new CatalanTagger ( ) ; tokenizer = new CatalanWordTokenizer ( ) ; sentenceTokenizer = new SRXSentenceTokenizer ( new Catalan ( ) ) ; disambiguator = new MultiWordChunker ( "/ca/multiwords.txt" , true ) ; } public void testChunker ( ) throws IOException { TestTools . myAssert ( "et al." , "/[null]SENT_START et/[et al.]<LOC_ADV>|et/[tu]P020S000|et/[tu]PP2CS000 /[null]null a/[a]NCFS000|a/[a]SPS00 l/[litre]Y ./[et al.]</LOC_ADV>" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Al marge d'aquells" , "/[null]SENT_START A/[a]NCFS000|A/[a]SPS00|A/[al marge d']<LOC_PREP> l/[litre]Y /[null]null marge/[marge]NCMS000 /[null]null d'/[al marge d']</LOC_PREP>|d'/[de]SPS00 aquells/[aquell]DD0MP0|aquells/[aquell]PD0MP000" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "L'Aquila" , "/[null]SENT_START L'/[L'Aquila]<NPFSG00>|L'/[el]DA0CS0|L'/[ell]PP3CSA00 Aquila/[L'Aquila]</NPFSG00>" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Al després-dinar" , "/[null]SENT_START A/[a]NCFS000|A/[a]SPS00|A/[al després-dinar]<LOC_ADV> l/[litre]Y /[null]null després/[desprendre]VMP00SM0|després/[després]RG -/[null]null dinar/[al després-dinar]</LOC_ADV>|dinar/[dinar]NCMS000|dinar/[dinar]VMN00000" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "d'una vegada" , "/[null]SENT_START d'/[d'una vegada]<LOC_ADV>|d'/[de]SPS00 una/[un]DI0FS0|una/[un]PI0FS000 /[null]null vegada/[d'una vegada]</LOC_ADV>|vegada/[vegada]NCFS000" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "D'una vegada" , "/[null]SENT_START D'/[d'una vegada]<LOC_ADV>|D'/[de]SPS00 una/[un]DI0FS0|una/[un]PI0FS000 /[null]null vegada/[d'una vegada]</LOC_ADV>|vegada/[vegada]NCFS000" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Puerta del Sol" , "/[null]SENT_START Puerta/[Puerta del Sol]<NPFSG00> /[null]null de/[de]NCFS000|de/[de]SPS00 l/[litre]Y /[null]null Sol/[Puerta del Sol]</NPFSG00>|Sol/[Sol]NPCNSP0|Sol/[Sol]NPMSSP0|Sol/[sol]AQ0MS0|Sol/[sol]NCMS000|Sol/[solar]VMIP1S0B|Sol/[soler]VMIP3S00|Sol/[soler]VMM02S00" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "A costa d'ell" , "/[null]SENT_START A/[a costa d']<LOC_PREP>|A/[a]NCFS000|A/[a]SPS00 /[null]null costa/[costa]NCFS000|costa/[costar]VMIP3S00|costa/[costar]VMM02S00 /[null]null d'/[a costa d']</LOC_PREP>|d'/[de]SPS00 ell/[ell]PP3MS000" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "A costa d’ell" , "/[null]SENT_START A/[a costa d']<LOC_PREP>|A/[a]NCFS000|A/[a]SPS00 /[null]null costa/[costa]NCFS000|costa/[costar]VMIP3S00|costa/[costar]VMM02S00 /[null]null d'/[a costa d']</LOC_PREP>|d'/[de]SPS00 ell/[ell]PP3MS000" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; } }
package org . languagetool . tagging . ja ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tagging . Tagger ; public class JapaneseTagger implements Tagger { @ Override public List < AnalyzedTokenReadings > tag ( List < String > sentenceTokens ) throws IOException { final List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( sentenceTokens . size ( ) ) ; int pos = 0 ; for ( String word : sentenceTokens ) { AnalyzedToken at = asAnalyzedToken ( word ) ; tokenReadings . add ( new AnalyzedTokenReadings ( at , pos ) ) ; pos += at . getToken ( ) . length ( ) ; } return tokenReadings ; } @ Override public final AnalyzedTokenReadings createNullToken ( final String token , final int startPos ) { return new AnalyzedTokenReadings ( new AnalyzedToken ( token , null , null ) , startPos ) ; } @ Override public AnalyzedToken createToken ( String token , String posTag ) { return new AnalyzedToken ( token , posTag , null ) ; } private AnalyzedToken asAnalyzedToken ( final String word ) { String [ ] parts = word . split ( " " ) ; if ( parts . length != 3 ) { return new AnalyzedToken ( " " , null , null ) ; } return new AnalyzedToken ( parts [ 0 ] , parts [ 1 ] , parts [ 2 ] ) ; } }
package org . languagetool . tokenizers . ja ; import java . util . ArrayList ; import java . util . List ; import net . java . sen . * ; import net . java . sen . dictionary . Token ; import org . languagetool . tokenizers . Tokenizer ; public class JapaneseWordTokenizer implements Tokenizer { private final StringTagger stringTagger ; public JapaneseWordTokenizer ( ) { stringTagger = SenFactory . getStringTagger ( null ) ; } @ Override public List < String > tokenize ( String text ) { final List < String > ret = new ArrayList < > ( ) ; List < Token > tokens = new ArrayList < > ( ) ; try { stringTagger . analyze ( text , tokens ) ; } catch ( Exception e ) { return ret ; } for ( Token token : tokens ) { String basicForm ; if ( token . getMorpheme ( ) . getBasicForm ( ) . equalsIgnoreCase ( "*" ) ) { basicForm = token . getSurface ( ) ; } else { basicForm = token . getMorpheme ( ) . getBasicForm ( ) ; } ret . add ( token . getSurface ( ) + " " + token . getMorpheme ( ) . getPartOfSpeech ( ) + " " + basicForm ) ; } return ret ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Icelandic ; public class IcelandicConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Icelandic ( ) ; } @ Override protected String createSampleText ( ) { return "Enginn texti er á þessari síðu enn sem komið er. Þú getur leitað í öðrum síðum, leitað í tengdum skrám, eða breytt henni sjálfur." ; } }
package org . languagetool . rules . is ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class IcelandicPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . language ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . spelling . hunspell . HunspellNoSuggestionRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . xx . DemoTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Icelandic extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; @ Override public String getName ( ) { return "Icelandic" ; } @ Override public String getShortName ( ) { return "is" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "IS" } ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Anton Karl Ingason" ) } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new DemoTagger ( ) ; } return tagger ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages ) , new HunspellNoSuggestionRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new WordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . PortugalPortuguese ; public class PortugalPortugueseConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new PortugalPortuguese ( ) ; } @ Override protected String createSampleText ( ) { return "Outras razões pelas quais esta mensagem pode aparecer" ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . BrazilianPortuguese ; public class BrazilianPortugueseConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new BrazilianPortuguese ( ) ; } @ Override protected String createSampleText ( ) { return "Outras razões pelas quais esta mensagem pode aparecer" ; } }
package org . languagetool . rules . pt ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class PortuguesePatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . tagging . pt ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Portuguese ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; public class PortugueseTaggerTest extends TestCase { private PortugueseTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new PortugueseTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Portuguese ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "Estes são os meus amigos." , "Estes/[este]DD0MP0|Estes/[este]PD0MP000 -- " + "são/[ser]VMIP3P0|são/[são]AQ0MS0|são/[são]NCMS000 -- " + "os/[o]DA0MP0|os/[o]PD0MP000|os/[o]PP3MPA00 -- " + "meus/[meu]DP1MPS|meus/[meu]PX1MP0S0 -- " + "amigos/[amigo]AQ0MP0|amigos/[amigo]NCMP000" , tokenizer , tagger ) ; } }
package org . languagetool . tokenizers . pt ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Portuguese ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class PortugueseSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer tokenizer = new SRXSentenceTokenizer ( new Portuguese ( ) ) ; public void testTokenize ( ) { testSplit ( "Cola o teu próprio texto aqui." ) ; testSplit ( "Cola o teu próprio texto aqui. " , "Ou verifica este texto." ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , tokenizer ) ; } }
package org . languagetool . tokenizers . ca ; import java . util . List ; import junit . framework . TestCase ; public class CatalanWordTokenizerTest extends TestCase { public void testTokenize ( ) { CatalanWordTokenizer wordTokenizer = new CatalanWordTokenizer ( ) ; List < String > tokens ; tokens = wordTokenizer . tokenize ( "L'\"ala bastarda\"." ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[L', \", ala, , bastarda, \", .]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "d'\"ala bastarda\"." ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[d', \", ala, , bastarda, \", .]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "Emporta-te'ls a l'observatori dels mars" ) ; assertEquals ( tokens . size ( ) , 13 ) ; assertEquals ( "[Emporta, -te, 'ls, , a, , l', observatori, , de, ls, , mars]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "Emporta-te’ls a l’observatori dels mars" ) ; assertEquals ( tokens . size ( ) , 13 ) ; assertEquals ( "[Emporta, -te, ’ls, , a, , l’, observatori, , de, ls, , mars]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "‘El tren Barcelona-València’" ) ; assertEquals ( tokens . size ( ) , 9 ) ; assertEquals ( "[‘, El, , tren, , Barcelona, -, València, ’]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "El tren Barcelona-València" ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[El, , tren, , Barcelona, -, València]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "No acabava d’entendre’l bé" ) ; assertEquals ( tokens . size ( ) , 9 ) ; assertEquals ( "[No, , acabava, , d’, entendre, ’l, , bé]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "N'hi ha vint-i-quatre" ) ; assertEquals ( tokens . size ( ) , 6 ) ; assertEquals ( "[N', hi, , ha, , vint-i-quatre]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "Mont-ras" ) ; assertEquals ( tokens . size ( ) , 1 ) ; assertEquals ( "[Mont-ras]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "És d'1 km." ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[És, , d', 1, , km, .]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "És d'1,5 km." ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[És, , d', 1,5, , km, .]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "És d'5 km." ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[És, , d', 5, , km, .]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "la direcció E-SE" ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[la, , direcció, , E, -, SE]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "la direcció NW-SE" ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[la, , direcció, , NW, -, SE]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "Se'n dóna vergonya" ) ; assertEquals ( tokens . size ( ) , 6 ) ; assertEquals ( "[Se, 'n, , dóna, , vergonya]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "Emília-Romanya" ) ; assertEquals ( tokens . size ( ) , 3 ) ; assertEquals ( "[Emília, -, Romanya]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "L'Emília-Romanya" ) ; assertEquals ( tokens . size ( ) , 4 ) ; assertEquals ( "[L', Emília, -, Romanya]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "col·laboració" ) ; assertEquals ( tokens . size ( ) , 1 ) ; tokens = wordTokenizer . tokenize ( "col.laboració" ) ; assertEquals ( tokens . size ( ) , 1 ) ; tokens = wordTokenizer . tokenize ( "col•laboració" ) ; assertEquals ( tokens . size ( ) , 1 ) ; tokens = wordTokenizer . tokenize ( "col·Laboració" ) ; assertEquals ( tokens . size ( ) , 1 ) ; tokens = wordTokenizer . tokenize ( "Sud-Est" ) ; assertEquals ( tokens . size ( ) , 3 ) ; assertEquals ( "[Sud, -, Est]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "Sud-est" ) ; assertEquals ( tokens . size ( ) , 1 ) ; } }
package org . languagetool . language ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . pt . PreReformPortugueseCompoundRule ; import org . languagetool . rules . spelling . hunspell . HunspellNoSuggestionRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . pt . PortugueseTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; public class Portuguese extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; @ Override public String getName ( ) { return "Portuguese" ; } @ Override public String getShortName ( ) { return "pt" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "AO" , "MZ" } ; } @ Override public Language getDefaultLanguageVariant ( ) { return new PortugalPortuguese ( ) ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Marco A.G. Pinto" , "http://www.marcoagpinto.com/" ) } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new PortugueseTagger ( ) ; } return tagger ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages ) , new HunspellNoSuggestionRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new WordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new SentenceWhitespaceRule ( messages ) , new PreReformPortugueseCompoundRule ( messages ) ) ; } }
package org . languagetool . language ; public class PortugalPortuguese extends Portuguese { @ Override public String getName ( ) { return "Portuguese (Portugal)" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "PT" } ; } }
package org . languagetool . language ; import org . languagetool . rules . Rule ; import org . languagetool . rules . pt . PostReformPortugueseCompoundRule ; import org . languagetool . rules . pt . PreReformPortugueseCompoundRule ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; public class PostReformPortugalPortuguese extends PortugalPortuguese { @ Override public String getName ( ) { return "Portuguese (Portugal, post-reform)" ; } @ Override public String getVariant ( ) { return "post-reform" ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { final List < Rule > filteredRules = new ArrayList < > ( ) ; for ( Rule rule : super . getRelevantRules ( messages ) ) { if ( rule . getClass ( ) != PreReformPortugueseCompoundRule . class ) { filteredRules . add ( rule ) ; } } filteredRules . add ( new PostReformPortugueseCompoundRule ( messages ) ) ; return filteredRules ; } }
package org . languagetool . language ; public class BrazilianPortuguese extends Portuguese { @ Override public String getName ( ) { return "Portuguese (Brazil)" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "BR" } ; } }
package org . languagetool . rules . pt ; import org . languagetool . rules . Rule ; public abstract class PortugueseRule extends Rule { }
package org . languagetool . rules . pt ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; import java . io . IOException ; import java . util . ResourceBundle ; public class PreReformPortugueseCompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/pt/pre-reform-compounds.txt" ) ; public PreReformPortugueseCompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "Esta palavra é hifenizada." , "Esta palavra é escrita em conjunto." , "Esta palavra é uma palavra ou com um hífen." , "Juntos grafias de palavras" ) ; } @ Override public String getId ( ) { return "PT_COMPOUNDS_POST_REFORM" ; } @ Override public String getDescription ( ) { return "Juntos ortografia de palavras, por exemplo 'CD-ROM' em vez de 'CD ROM'" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . rules . pt ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; import java . io . IOException ; import java . util . ResourceBundle ; public class PostReformPortugueseCompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/pt/post-reform-compounds.txt" ) ; public PostReformPortugueseCompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "Esta palavra é hifenizada." , "Esta palavra é escrita em conjunto." , "Esta palavra é uma palavra ou com um hífen." , "Juntos grafias de palavras" ) ; } @ Override public String getId ( ) { return "PT_COMPOUNDS_PRE_REFORM" ; } @ Override public String getDescription ( ) { return "Juntos ortografia de palavras, por exemplo 'CD-ROM' em vez de 'CD ROM'" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . tagging . pt ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class PortugueseTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/pt/added.txt" ; } public PortugueseTagger ( ) { super ( "/pt/portuguese.dict" , new Locale ( "pt" ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Lithuanian ; public class LithuanianConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Lithuanian ( ) ; } @ Override protected String createSampleText ( ) { return "Vikipedijoje nėra straipsnio norimu pavadinimu." ; } }
package org . languagetool . rules . lt ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class LithuanianPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . tokenizers . ca ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class CatalanSentenceTokenizerTest extends TestCase { private final SentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Catalan ( ) ) ; public final void testTokenize ( ) { testSplit ( "Això és una frase. " , "Això és una altra frase." ) ; testSplit ( "Aquesta és l'egua. " , "Aquell és el cavall." ) ; testSplit ( "Aquesta és l'egua? " , "Aquell és el cavall." ) ; testSplit ( "Vols col·laborar? " , "Sí, i tant." ) ; testSplit ( "Com vas d'il·lusió? " , "Bé, bé." ) ; testSplit ( "Com vas d’il·lusió? " , "Bé, bé." ) ; testSplit ( "És d’abans-d’ahir? " , "Bé, bé." ) ; testSplit ( "És d’abans-d’ahir! " , "Bé, bé." ) ; testSplit ( "Què vols dir? " , "Ja ho tinc!" ) ; testSplit ( "Ja ho tinc! " , "Què vols dir?" ) ; testSplit ( "Us explicaré com va anar: " , "»La Maria va engegar el cotxe" ) ; testSplit ( "diu que va dir. " , "A mi em feia estrany." ) ; testSplit ( "Vés-te’n. " , "A mi em feia estrany." ) ; testSplit ( "Vés-te'n. " , "A mi em feia estrany." ) ; testSplit ( "VÉS-TE'N. " , "A mi em feia estrany." ) ; testSplit ( "Canten. " , "A mi em feia estrany." ) ; testSplit ( "Desprèn. " , "A mi em feia estrany." ) ; testSplit ( "(n. 3)." ) ; testSplit ( " n. 3" ) ; testSplit ( "n. 3" ) ; testSplit ( "(\"n. 3\"." ) ; testSplit ( "A l'atenció d'A. Comes." ) ; testSplit ( "A l'atenció d'À. Comes." ) ; testSplit ( "Núm. operació 220130000138." ) ; testSplit ( "el vi no és gens propi de monjos, amb tot...\" vetllant, això sí" ) ; testSplit ( "Desenganyeu-vos… " , "L’únic problema seriós de l'home en aquest món és el de subsistir." ) ; testSplit ( "és clar… traduir és una feina endimoniada" ) ; testSplit ( "«El cordó del frare…» surt d'una manera desguitarrada" ) ; testSplit ( "convidar el seu heroi –del ram que sigui–… a prendre cafè." ) ; testSplit ( "No Mr. Spock sinó un altre." ) ; testSplit ( "Vegeu el cap. 24 del llibre." ) ; testSplit ( "Vegeu el cap. IX del llibre." ) ; testSplit ( "Viu al núm. 24 del carrer de l'Hort." ) ; testSplit ( "El Dr. Joan no vindrà." ) ; testSplit ( "Distingit Sr. Joan," ) ; testSplit ( "Molt Hble. Sr. President" ) ; testSplit ( "de Sant Nicolau (del s. XII; cor gòtic del s. XIV) i de Sant " ) ; testSplit ( "Va ser el 5è. classificat." ) ; testSplit ( "Va ser el 5è. " , "I l'altre el 4t." ) ; testSplit ( "Art. 2.1: Són obligats els..." ) ; testSplit ( "Arriba fins a les pp. 50-52." ) ; testSplit ( "Arriba fins a les pp. XI-XII." ) ; testSplit ( "i no ho vol. " , "Malgrat que és així." ) ; testSplit ( "i és del vol. 3 de la col·lecció" ) ; testSplit ( "Ell és el número u. " , "Jo el dos." ) ; testSplit ( "Té un trau al cap. " , "Cal portar-lo a l'hospital." ) ; testSplit ( "Això passa en el PP. " , "Però, per altra banda," ) ; testSplit ( "1 500 m/s. " , "Neix a" ) ; testSplit ( "Són d'1 g. " , "Han estat condicionades." ) ; testSplit ( "Són d'1 m. " , "Han estat condicionades." ) ; testSplit ( "Hi vivien 50 h. " , "Després el poble va créixer." ) ; testSplit ( "L'acte serà a les 15.30 h. de la vesprada." ) ; testSplit ( "s'hi enfrontà quan G.Oueddei n'esdevingué líder" ) ; testSplit ( "el jesuïta alemany J.E. Nithard" ) ; } private void testSplit ( final String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . tokenizers . lt ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Lithuanian ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class LithuanianSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Lithuanian ( ) ) ; public void testTokenize ( ) { testSplit ( "Linux – laisvos operacinės sistemos branduolio (kernel) pavadinimas. " , "Dažnai taip sutrumpintai vadinama ir bendrai visa Unix-tipo operacinė sistema naudojanti Linux branduolį kartu su sisteminėmis programomis bei bibliotekomis iš GNU projekto." ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . lt . MorfologikLithuanianSpellerRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . xx . DemoTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Lithuanian extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; @ Override public String getName ( ) { return "Lithuanian" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "LT" } ; } @ Override public String getShortName ( ) { return "lt" ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new DemoTagger ( ) ; } return tagger ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Mantas Kriaučiūnas" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages ) , new MorfologikLithuanianSpellerRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) ) ; } }
package org . languagetool . rules . lt ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikLithuanianSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/lt/hunspell/lt_LT.dict" ; public MorfologikLithuanianSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_LT_LT" ; } }
package org . languagetool ; import junit . framework . TestCase ; import org . languagetool . language . Slovenian ; import java . io . IOException ; public class JLanguageToolTest extends TestCase { public void testSlovenian ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new Slovenian ( ) ) ; assertEquals ( 1 , tool . check ( "Kupil je npr. jajca, moko in mleko." ) . size ( ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Slovenian ; public class SlovenianConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Slovenian ( ) ; } @ Override protected String createSampleText ( ) { return "Iz Wikipedije, proste enciklopedije" ; } }
package org . languagetool . rules . sl ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class SlovenianPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . sl . MorfologikSlovenianSpellerRule ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Slovenian extends Language { private SentenceTokenizer sentenceTokenizer ; @ Override public String getName ( ) { return "Slovenian" ; } @ Override public String getShortName ( ) { return "sl" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "SI" } ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Martin Srebotnjak" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages , Arrays . asList ( "[" , "(" , "{" , "„" , "»" , "«" , "\"" ) , Arrays . asList ( "]" , ")" , "}" , "”" , "«" , "»" , "\"" ) ) , new MorfologikSlovenianSpellerRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new WordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) ) ; } }
package org . languagetool . rules . sl ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikSlovenianSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/sl/hunspell/sl_SI.dict" ; public MorfologikSlovenianSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_SL_SI" ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Swedish ; public class SwedishConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Swedish ( ) ; } @ Override protected String createSampleText ( ) { return "Om sidan har raderats, se då i raderingsloggen eller se om det finns någon diskussion om att sidan ska raderas." ; } }
package org . languagetool . rules . sv ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Swedish ; import org . languagetool . rules . AbstractCompoundRuleTest ; import java . io . IOException ; public class CompoundRuleTest extends AbstractCompoundRuleTest { @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; langTool = new JLanguageTool ( new Swedish ( ) ) ; rule = new CompoundRule ( TestTools . getEnglishMessages ( ) ) ; } public void testRule ( ) throws IOException { check ( 0 , "skit-bra" ) ; check ( 0 , "IP-Adress" ) ; check ( 0 , "moll-tonart" ) ; check ( 0 , "e-mail" ) ; check ( 1 , "skit bra" , new String [ ] { "skitbra" } ) ; check ( 1 , "IP Adress" , new String [ ] { "IP-Adress" } ) ; check ( 1 , "moll tonart" , new String [ ] { "moll-tonart" , "molltonart" } ) ; check ( 1 , "e mail" , new String [ ] { "e-mail" } ) ; } }
package org . languagetool . language ; public class GeneralCatalan extends Catalan { @ Override public String getName ( ) { return "Catalan" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "ES" } ; } @ Override public String getShortName ( ) { return "ca" ; } }
package org . languagetool . rules . sv ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class SwedishPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . tagging . sv ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Swedish ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; public class SwedishTaggerTest extends TestCase { private SwedishTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new SwedishTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Swedish ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "Det är nog bäst att du får en klubba till" , "Det/[det]PN -- är/[vara]VB:PRS -- nog/[nog]AB -- bäst/[bra]JJ:S|bäst/[bäst]AB|bäst/[god]JJ:S -- att/[att]KN -- du/[du]PN -- får/[få]VB:PRS|får/[får]NN:OF:PLU:NOM:NEU|får/[får]NN:OF:SIN:NOM:NEU -- en/[en]NN:OF:SIN:NOM:UTR|en/[en]PN|en/[passant]en passant NN:OF:SIN:NOM:UTR|en/[passanten]en passant NN:BF:SIN:NOM:UTR|en/[passantens]en passant NN:BF:SIN:GEN:UTR|en/[passanter]en passant NN:OF:PLU:NOM:UTR|en/[passanterna]en passant NN:BF:PLU:NOM:UTR|en/[passanternas]en passant NN:BF:PLU:GEN:UTR|en/[passanters]en passant NN:OF:PLU:GEN:UTR|en/[passants]en passant NN:OF:SIN:GEN:UTR -- klubba/[klubba]NN:OF:SIN:NOM:UTR|klubba/[klubba]VB:IMP|klubba/[klubba]VB:INF -- till/[till]AB|till/[till]PP" , tokenizer , tagger ) ; TestTools . myAssert ( "Du menar sannolikt \"massera\" om du inte skriver om masarnas era förstås." , "Du/[du]PN -- menar/[mena]VB:PRS -- sannolikt/[sannolik]JJ:PN|sannolikt/[sannolikt]AB -- massera/[massera]VB:IMP|massera/[massera]VB:INF -- om/[om]AB|om/[om]KN|om/[om]PP -- du/[du]PN -- inte/[inte]AB -- skriver/[skriva]VB:PRS -- om/[om]AB|om/[om]KN|om/[om]PP -- masarnas/[mas]NN:BF:PLU:GEN:UTR -- era/[era]NN:OF:SIN:NOM:UTR|era/[era]PN -- förstås/[förstå]VB:INF:PF|förstås/[förstå]VB:PRS:PF|förstås/[förstås]AB" , tokenizer , tagger ) ; } }
package org . languagetool . tokenizers . sv ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Swedish ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class SwedishSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Swedish ( ) ) ; public void testTokenize ( ) { testSplit ( "Onkel Toms stuga är en roman skriven av Harriet Beecher Stowe, publicerad den 1852. " , "Den handlar om slaveriet i USA sett ur slavarnas perspektiv och bidrog starkt till att slaveriet avskaffades 1865 efter amerikanska inbördeskriget." ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . spelling . hunspell . HunspellRule ; import org . languagetool . rules . sv . CompoundRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . sv . SwedishTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Swedish extends Language { private SentenceTokenizer sentenceTokenizer ; private Tagger tagger ; @ Override public String getName ( ) { return "Swedish" ; } @ Override public String getShortName ( ) { return "sv" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "SE" , "FI" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new SwedishTagger ( ) ; } return tagger ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Niklas Johansson" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages ) , new HunspellRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new WordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new CompoundRule ( messages ) ) ; } }
package org . languagetool . rules . sv ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; public class CompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/sv/compounds.txt" ) ; public CompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "Dessa ord skrivs samman med bindestreck." , "Dessa ord skrivs samman." , "Dessa ord skrivs samman med eller utan bindestreck." ) ; } @ Override public String getId ( ) { return "SV_COMPOUNDS" ; } @ Override public String getDescription ( ) { return "Särskrivningar, t.ex. 'e mail' bör skrivas 'e-mail'" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . rules . sv ; import org . languagetool . rules . Rule ; public abstract class SwedishRule extends Rule { }
package org . languagetool . tagging . sv ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class SwedishTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/sv/added.txt" ; } public SwedishTagger ( ) { super ( "/sv/swedish.dict" , new Locale ( "sv" ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Breton ; public class BretonConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Breton ( ) ; } @ Override protected String createSampleText ( ) { return "Ma oa bet krouet ar pennad-mañ ganeoc'h pellik zo, marteze eo bet diverketabaoe." ; } }
package org . languagetool . rules . br ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Breton ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import static org . junit . Assert . assertEquals ; public class MorfologikBretonSpellerRuleTest { @ Test public void testMorfologikSpeller ( ) throws IOException { final MorfologikBretonSpellerRule rule = new MorfologikBretonSpellerRule ( TestTools . getMessages ( "br" ) , new Breton ( ) ) ; RuleMatch [ ] matches ; final JLanguageTool langTool = new JLanguageTool ( new Breton ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Penaos emañ kont ganit?" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "C'hwerc'h merc'h gwerc'h war c'hwerc'h marc'h kalloc'h" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "C’hwerc’h merc’h gwerc‘h war c‘hwerc‘h marc'h kalloc‘h" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Evel-just" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Barrek-tre eo LanguageTool" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "C'hwerc'h merc'h gwerc'h war c'hwerc'h marc'h kalloc'h" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "C’hwerc’h merc’h gwerc‘h war c‘hwerc‘h marc'h kalloc‘h" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Evel-just" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Evel-juste" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Barrek-tre eo LanguageTool" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "LanguageTool!" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Evel-juste" ) ) . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Evel-juste" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 5 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 10 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "C’hreizhig-don" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 10 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "aõh" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "a" ) ) . length ) ; } }
package org . languagetool . rules . br ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Breton ; import java . io . IOException ; public class TopoReplaceRuleTest extends TestCase { public void testRule ( ) throws IOException { TopoReplaceRule rule = new TopoReplaceRule ( TestTools . getEnglishMessages ( ) ) ; JLanguageTool langTool = new JLanguageTool ( new Breton ( ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "France a zo ur vro." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "France 3 a zo ur chadenn skinwel." ) ) . length ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . ca . AccentuationCheckRule ; import org . languagetool . rules . ca . CatalanUnpairedBracketsRule ; import org . languagetool . rules . ca . CatalanUnpairedExclamationMarksRule ; import org . languagetool . rules . ca . CatalanUnpairedQuestionMarksRule ; import org . languagetool . rules . ca . CatalanWordRepeatRule ; import org . languagetool . rules . ca . CatalanWrongWordInContextRule ; import org . languagetool . rules . ca . ComplexAdjectiveConcordanceRule ; import org . languagetool . rules . ca . MorfologikCatalanSpellerRule ; import org . languagetool . rules . ca . ReflexiveVerbsRule ; import org . languagetool . rules . ca . ReplaceOperationNamesRule ; import org . languagetool . rules . ca . SimpleReplaceRule ; import org . languagetool . rules . ca . SimpleReplaceVerbsRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . ca . CatalanSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . ca . CatalanTagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . ca . CatalanHybridDisambiguator ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . ca . CatalanWordTokenizer ; public class Catalan extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; private Tokenizer wordTokenizer ; private Synthesizer synthesizer ; private Disambiguator disambiguator ; private static final Language GENERAL_CATALAN = new GeneralCatalan ( ) ; @ Override public String getName ( ) { return "Catalan" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { } ; } @ Override public String getShortName ( ) { return "ca" ; } @ Override public Language getDefaultLanguageVariant ( ) { return GENERAL_CATALAN ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Ricard Roca" ) , new Contributor ( "Jaume Ortolà" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new CatalanUnpairedBracketsRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new LongSentenceRule ( messages ) , new CatalanWordRepeatRule ( messages , this ) , new MorfologikCatalanSpellerRule ( messages , this ) , new CatalanUnpairedQuestionMarksRule ( messages , this ) , new CatalanUnpairedExclamationMarksRule ( messages , this ) , new AccentuationCheckRule ( messages ) , new ComplexAdjectiveConcordanceRule ( messages ) , new CatalanWrongWordInContextRule ( messages ) , new ReflexiveVerbsRule ( messages ) , new SimpleReplaceVerbsRule ( messages ) , new SimpleReplaceRule ( messages ) , new ReplaceOperationNamesRule ( messages ) ) ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new CatalanTagger ( ) ; } return tagger ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new CatalanSynthesizer ( ) ; } return synthesizer ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new CatalanHybridDisambiguator ( ) ; } return disambiguator ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new CatalanWordTokenizer ( ) ; } return wordTokenizer ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . ValencianCatalan ; public class ValencianCatalanConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new ValencianCatalan ( ) ; } @ Override protected String createSampleText ( ) { return "Si tot i així encara no apareix, potser la pàgina ha estat suprimida." ; } }
package org . languagetool . rules . br ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class BretonPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . tokenizers . br ; import java . util . List ; import junit . framework . TestCase ; public class BretonWordTokenizerTest extends TestCase { public void testTokenize ( ) { final BretonWordTokenizer wordTokenizer = new BretonWordTokenizer ( ) ; List < String > tokens = wordTokenizer . tokenize ( "Test c'h" ) ; assertEquals ( 3 , tokens . size ( ) ) ; assertEquals ( "[Test, , c’h]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "Test c’h" ) ; assertEquals ( 3 , tokens . size ( ) ) ; assertEquals ( "[Test, , c’h]" , tokens . toString ( ) ) ; tokens = wordTokenizer . tokenize ( "C'hwerc'h merc'h gwerc'h war c'hwerc'h marc'h kalloc'h" ) ; assertEquals ( 13 , tokens . size ( ) ) ; assertEquals ( "[C’hwerc’h, , merc’h, , gwerc’h, , war, , c’hwerc’h, , marc’h, , kalloc’h]" , tokens . toString ( ) ) ; final List < String > tokens2 = wordTokenizer . tokenize ( "Test n’eo" ) ; assertEquals ( 4 , tokens2 . size ( ) ) ; assertEquals ( "[Test, , n’, eo]" , tokens2 . toString ( ) ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . br . TopoReplaceRule ; import org . languagetool . rules . br . MorfologikBretonSpellerRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . br . BretonTagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . br . BretonWordTokenizer ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Breton extends Language { private SentenceTokenizer sentenceTokenizer ; private Tagger tagger ; private Tokenizer wordTokenizer ; private Disambiguator disambiguator ; @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new BretonWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public String getName ( ) { return "Breton" ; } @ Override public String getShortName ( ) { return "br" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "FR" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new BretonTagger ( ) ; } return tagger ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new XmlRuleDisambiguator ( new Breton ( ) ) ; } return disambiguator ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { Contributors . DOMINIQUE_PELLE , new Contributor ( "Fulup Jakez" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new MorfologikBretonSpellerRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new SentenceWhitespaceRule ( messages ) , new TopoReplaceRule ( messages ) ) ; } }
package org . languagetool . rules . br ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Breton ; import org . languagetool . rules . AbstractSimpleReplaceRule ; import org . languagetool . rules . Category ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tools . StringTools ; import java . io . BufferedReader ; import java . io . IOException ; import java . io . InputStream ; import java . io . InputStreamReader ; import java . util . * ; import java . util . concurrent . ArrayBlockingQueue ; public class TopoReplaceRule extends Rule { public static final String BRETON_TOPO = "BR_TOPO" ; private static final String FILE_NAME = "/br/topo.txt" ; private static final String FILE_ENCODING = "utf-8" ; private static final Locale BR_LOCALE = new Locale ( "br" ) ; private final List < Map < String , String > > wrongWords ; private final Tokenizer wordTokenizer = new Breton ( ) . getWordTokenizer ( ) ; public final String getFileName ( ) { return FILE_NAME ; } public TopoReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; wrongWords = loadWords ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( getFileName ( ) ) ) ; } @ Override public final String getId ( ) { return BRETON_TOPO ; } @ Override public String getDescription ( ) { return "anvioù-lec’h e brezhoneg" ; } public String getShort ( ) { return "anvioù lec’h" ; } public String getSuggestion ( ) { return " zo un anv lec’h gallek. Ha fellout a rae deoc’h skrivañ " ; } public String getSuggestionsSeparator ( ) { return " pe " ; } public boolean isCaseSensitive ( ) { return true ; } public Locale getLocale ( ) { return BR_LOCALE ; } public String getEncoding ( ) { return FILE_ENCODING ; } protected Tokenizer getWordTokenizer ( ) { return wordTokenizer ; } public List < Map < String , String > > getWrongWords ( ) { return wrongWords ; } private List < Map < String , String > > loadWords ( final InputStream stream ) throws IOException { final List < Map < String , String > > list = new ArrayList < > ( ) ; try ( InputStreamReader isr = new InputStreamReader ( stream , getEncoding ( ) ) ; BufferedReader br = new BufferedReader ( isr ) ; ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { line = line . trim ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } final String [ ] parts = line . split ( "=" ) ; if ( parts . length != 2 ) { throw new IOException ( "Format error in file " + JLanguageTool . getDataBroker ( ) . getFromRulesDirAsUrl ( getFileName ( ) ) + ", line: " + line ) ; } final String [ ] wrongForms = parts [ 0 ] . split ( "\\|" ) ; for ( String wrongForm : wrongForms ) { int wordCount = 0 ; final List < String > tokens = getWordTokenizer ( ) . tokenize ( wrongForm ) ; for ( String token : tokens ) { if ( ! StringTools . isWhitespace ( token ) ) { wordCount ++ ; } } for ( int i = list . size ( ) ; i < wordCount ; i ++ ) { list . add ( new HashMap < String , String > ( ) ) ; } list . get ( wordCount - 1 ) . put ( wrongForm , parts [ 1 ] ) ; } } } final List < Map < String , String > > result = new ArrayList < > ( ) ; for ( Map < String , String > map : list ) { result . add ( Collections . unmodifiableMap ( map ) ) ; } return Collections . unmodifiableList ( result ) ; } private void addToQueue ( AnalyzedTokenReadings token , Queue < AnalyzedTokenReadings > prevTokens ) { final boolean inserted = prevTokens . offer ( token ) ; if ( ! inserted ) { prevTokens . poll ( ) ; prevTokens . offer ( token ) ; } } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; final Queue < AnalyzedTokenReadings > prevTokens = new ArrayBlockingQueue < > ( wrongWords . size ( ) ) ; for ( int i = 1 ; i < tokens . length ; i ++ ) { addToQueue ( tokens [ i ] , prevTokens ) ; final StringBuilder sb = new StringBuilder ( ) ; final List < String > variants = new ArrayList < > ( ) ; final List < AnalyzedTokenReadings > prevTokensList = new ArrayList < > ( prevTokens ) ; for ( int j = prevTokensList . size ( ) - 1 ; j >= 0 ; j -- ) { if ( j != prevTokensList . size ( ) - 1 && prevTokensList . get ( j + 1 ) . isWhitespaceBefore ( ) ) { sb . insert ( 0 , " " ) ; } sb . insert ( 0 , prevTokensList . get ( j ) . getToken ( ) ) ; variants . add ( 0 , sb . toString ( ) ) ; } final int len = variants . size ( ) ; for ( int j = 0 ; j < len ; j ++ ) { final int crtWordCount = len - j ; if ( prevTokensList . get ( len - crtWordCount ) . isImmunized ( ) ) { continue ; } final String crt = variants . get ( j ) ; final String crtMatch = isCaseSensitive ( ) ? wrongWords . get ( crtWordCount - 1 ) . get ( crt ) : wrongWords . get ( crtWordCount - 1 ) . get ( crt . toLowerCase ( getLocale ( ) ) ) ; if ( crtMatch != null ) { final List < String > replacements = Arrays . asList ( crtMatch . split ( "\\|" ) ) ; String msg = crt + getSuggestion ( ) ; for ( int k = 0 ; k < replacements . size ( ) ; k ++ ) { if ( k > 0 ) { msg = msg + ( k == replacements . size ( ) - 1 ? getSuggestionsSeparator ( ) : ", " ) ; } msg += "<suggestion>" + replacements . get ( k ) + "</suggestion>" ; } msg += "?" ; final int startPos = prevTokensList . get ( len - crtWordCount ) . getStartPos ( ) ; final int endPos = prevTokensList . get ( len - 1 ) . getEndPos ( ) ; final RuleMatch potentialRuleMatch = new RuleMatch ( this , startPos , endPos , msg , getShort ( ) ) ; if ( ! isCaseSensitive ( ) && StringTools . startsWithUppercase ( crt ) ) { for ( int k = 0 ; k < replacements . size ( ) ; k ++ ) { replacements . set ( k , StringTools . uppercaseFirstChar ( replacements . get ( k ) ) ) ; } } potentialRuleMatch . setSuggestedReplacements ( replacements ) ; ruleMatches . add ( potentialRuleMatch ) ; break ; } } } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . br ; import java . io . IOException ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikBretonSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/br/hunspell/br_FR.dict" ; private static final Pattern BRETON_TOKENIZING_CHARS = Pattern . compile ( "-" ) ; public MorfologikBretonSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; this . setIgnoreTaggedWords ( ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_BR_FR" ; } @ Override public Pattern tokenizingPattern ( ) { return BRETON_TOKENIZING_CHARS ; } }
package org . languagetool . rules . br ; import org . languagetool . rules . AbstractDateCheckFilter ; import java . util . Calendar ; import java . util . Locale ; public class DateCheckFilter extends AbstractDateCheckFilter { @ Override protected Calendar getCalendar ( ) { return Calendar . getInstance ( Locale . UK ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfMonth ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . charAt ( 0 ) == 't' ) day = 'd' + day . substring ( 1 ) ; if ( day . charAt ( 0 ) == 'p' ) day = 'b' + day . substring ( 1 ) ; if ( day . endsWith ( "vet" ) ) { day = day . substring ( 0 , day . length ( ) - 3 ) ; } if ( day . equals ( "c’hentañ" ) || day . equals ( "unan" ) ) return 1 ; if ( day . equals ( "daou" ) || day . equals ( "eil" ) ) return 2 ; if ( day . equals ( "dri" ) || day . equals ( "drede" ) || day . equals ( "deir" ) ) return 3 ; if ( day . equals ( "bevar" ) ) return 4 ; if ( day . equals ( "bemp" ) || day . equals ( "bem" ) ) return 5 ; if ( day . equals ( "c’hwerc’h" ) ) return 6 ; if ( day . equals ( "seizh" ) ) return 7 ; if ( day . equals ( "eizh" ) ) return 8 ; if ( day . equals ( "nav" ) || day . equals ( "na" ) ) return 9 ; if ( day . equals ( "dek" ) ) return 10 ; if ( day . equals ( "unnek" ) ) return 11 ; if ( day . equals ( "daouzek" ) ) return 12 ; if ( day . equals ( "drizek" ) ) return 13 ; if ( day . equals ( "bevarzek" ) ) return 14 ; if ( day . equals ( "bemzek" ) ) return 15 ; if ( day . equals ( "c’hwezek" ) ) return 16 ; if ( day . equals ( "seitek" ) ) return 17 ; if ( day . equals ( "driwec’h" ) ) return 18 ; if ( day . equals ( "naontek" ) ) return 19 ; if ( day . equals ( "ugent" ) ) return 20 ; if ( day . equals ( "dregont" ) ) return 30 ; return 0 ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfWeek ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . endsWith ( "sul" ) ) return Calendar . SUNDAY ; if ( day . endsWith ( "lun" ) ) return Calendar . MONDAY ; if ( day . endsWith ( "meurzh" ) ) return Calendar . TUESDAY ; if ( day . endsWith ( "merc’her" ) ) return Calendar . WEDNESDAY ; if ( day . equals ( "yaou" ) ) return Calendar . THURSDAY ; if ( day . equals ( "diriaou" ) ) return Calendar . THURSDAY ; if ( day . endsWith ( "gwener" ) ) return Calendar . FRIDAY ; if ( day . endsWith ( "sadorn" ) ) return Calendar . SATURDAY ; throw new RuntimeException ( "Could not find day of week for '" + dayStr + "'" ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected String getDayOfWeek ( Calendar date ) { String englishDay = date . getDisplayName ( Calendar . DAY_OF_WEEK , Calendar . LONG , Locale . UK ) ; if ( englishDay . equals ( "Sunday" ) ) return "Sul" ; if ( englishDay . equals ( "Monday" ) ) return "Lun" ; if ( englishDay . equals ( "Tuesday" ) ) return "Meurzh" ; if ( englishDay . equals ( "Wednesday" ) ) return "Merc’her" ; if ( englishDay . equals ( "Thursday" ) ) return "Yaou" ; if ( englishDay . equals ( "Friday" ) ) return "Gwener" ; if ( englishDay . equals ( "Saturday" ) ) return "Sadorn" ; return "" ; } @ SuppressWarnings ( { "ControlFlowStatementWithoutBraces" , "MagicNumber" } ) @ Override protected int getMonth ( String monthStr ) { String mon = monthStr . toLowerCase ( ) ; if ( mon . equals ( "genver" ) ) return 1 ; if ( mon . equals ( "c’hwevrer" ) ) return 2 ; if ( mon . equals ( "meurzh" ) ) return 3 ; if ( mon . equals ( "ebrel" ) ) return 4 ; if ( mon . equals ( "mae" ) ) return 5 ; if ( mon . equals ( "mezheven" ) || mon . equals ( "even" ) ) return 6 ; if ( mon . equals ( "gouere" ) || mon . equals ( "gouhere" ) ) return 7 ; if ( mon . equals ( "eost" ) ) return 8 ; if ( mon . equals ( "gwengolo" ) ) return 9 ; if ( mon . equals ( "here" ) ) return 10 ; if ( mon . equals ( "du" ) ) return 11 ; if ( mon . equals ( "kerzu" ) ) return 12 ; throw new RuntimeException ( "Could not find month '" + monthStr + "'" ) ; } }
package org . languagetool . tagging . br ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tagging . BaseTagger ; import org . languagetool . tools . StringTools ; public class BretonTagger extends BaseTagger { private static final Pattern patternSuffix = Pattern . compile ( "(?iu)(..+)-(mañ|se|hont)$" ) ; private final Locale conversionLocale = Locale . getDefault ( ) ; @ Override public String getManualAdditionsFileName ( ) { return "/br/added.txt" ; } public BretonTagger ( ) { super ( "/br/breton.dict" , new Locale ( "br" ) ) ; } @ Override public List < AnalyzedTokenReadings > tag ( final List < String > sentenceTokens ) throws IOException { List < AnalyzedToken > taggerTokens ; List < AnalyzedToken > lowerTaggerTokens ; List < AnalyzedToken > upperTaggerTokens ; final List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; int pos = 0 ; Matcher matcher ; for ( String word : sentenceTokens ) { String probeWord = word ; for ( ; ; ) { final List < AnalyzedToken > l = new ArrayList < > ( ) ; final String lowerWord = probeWord . toLowerCase ( conversionLocale ) ; taggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( probeWord ) ) ; lowerTaggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( lowerWord ) ) ; final boolean isLowercase = probeWord . equals ( lowerWord ) ; addTokens ( taggerTokens , l ) ; if ( ! isLowercase ) { addTokens ( lowerTaggerTokens , l ) ; } if ( lowerTaggerTokens . isEmpty ( ) && taggerTokens . isEmpty ( ) ) { if ( isLowercase ) { upperTaggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( StringTools . uppercaseFirstChar ( probeWord ) ) ) ; if ( ! upperTaggerTokens . isEmpty ( ) ) { addTokens ( upperTaggerTokens , l ) ; } } if ( l . isEmpty ( ) ) { if ( ( matcher = patternSuffix . matcher ( probeWord ) ) . find ( ) ) { probeWord = matcher . group ( 1 ) ; continue ; } l . add ( new AnalyzedToken ( word , null , null ) ) ; } } tokenReadings . add ( new AnalyzedTokenReadings ( l , pos ) ) ; pos += word . length ( ) ; break ; } } return tokenReadings ; } private void addTokens ( final List < AnalyzedToken > taggedTokens , final List < AnalyzedToken > l ) { if ( taggedTokens != null ) { for ( AnalyzedToken at : taggedTokens ) { l . add ( at ) ; } } } }
package org . languagetool . tokenizers . br ; import java . util . ArrayList ; import java . util . Iterator ; import java . util . List ; import org . languagetool . tokenizers . WordTokenizer ; public class BretonWordTokenizer extends WordTokenizer { public BretonWordTokenizer ( ) { } @ Override public List < String > tokenize ( final String text ) { String replaced = text . replaceAll ( "([Cc])['’‘ʼ]([Hh])" , "$1\u0001\u0001BR_APOS\u0001\u0001$2" ) . replaceAll ( "(\\p{L})['’‘ʼ]" , "$1\u0001\u0001BR_APOS\u0001\u0001 " ) ; final List < String > tokenList = super . tokenize ( replaced ) ; List < String > tokens = new ArrayList < > ( ) ; Iterator < String > itr = tokenList . iterator ( ) ; while ( itr . hasNext ( ) ) { String word = itr . next ( ) . replace ( "\u0001\u0001BR_APOS\u0001\u0001" , "’" ) ; tokens . add ( word ) ; if ( ! word . equals ( "’" ) && word . endsWith ( "’" ) ) { itr . next ( ) ; } } return tokens ; } }
package org . languagetool ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool . ParagraphHandling ; import org . languagetool . language . AmericanEnglish ; import org . languagetool . language . BritishEnglish ; import org . languagetool . language . English ; import org . languagetool . rules . Category ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . PatternRule ; public class JLanguageToolTest extends TestCase { public void demoCodeForHomepage ( ) throws IOException { JLanguageTool langTool = new JLanguageTool ( new BritishEnglish ( ) ) ; List < RuleMatch > matches = langTool . check ( "A sentence with a error in the Hitchhiker's Guide tot he Galaxy" ) ; for ( RuleMatch match : matches ) { System . out . println ( "Potential error at line " + match . getLine ( ) + ", column " + match . getColumn ( ) + ": " + match . getMessage ( ) ) ; System . out . println ( "Suggested correction: " + match . getSuggestedReplacements ( ) ) ; } } public void spellCheckerDemoCodeForHomepage ( ) throws IOException { JLanguageTool langTool = new JLanguageTool ( new BritishEnglish ( ) ) ; for ( Rule rule : langTool . getAllRules ( ) ) { if ( ! rule . isDictionaryBasedSpellingRule ( ) ) { langTool . disableRule ( rule . getId ( ) ) ; } } List < RuleMatch > matches = langTool . check ( "A speling error" ) ; for ( RuleMatch match : matches ) { System . out . println ( "Potential typo at line " + match . getLine ( ) + ", column " + match . getColumn ( ) + ": " + match . getMessage ( ) ) ; System . out . println ( "Suggested correction(s): " + match . getSuggestedReplacements ( ) ) ; } } public void testEnglish ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new English ( ) ) ; assertEquals ( 0 , tool . check ( "A test that should not give errors." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "As long as you have hope, a chance remains." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "A rolling stone gathers no moss." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "Hard work causes fitness." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "Gershwin overlays the slow blues theme from section B in the final “Grandioso.”" ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "Making ingroup membership more noticeable increases cooperativeness." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "Dog mushing is more of a sport than a true means of transportation." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "No one trusts him any more." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "A member of the United Nations since 1992, Azerbaijan was elected to membership in the newly established Human Rights Council by the United Nations General Assembly on May 9, 2006 (the term of office began on June 19, 2006)." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "Anatomy and geometry are fused in one, and each does something to the other." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "Certain frogs that lay eggs underground have unpigmented eggs." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "It's a kind of agreement in which each party gives something to the other, Jack said." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "Later, you shall know it better." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "And the few must win what the many lose, for the opposite arrangement would not support markets as we know them at all, and is, in fact, unimaginable." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "He explained his errand, but without bothering much to make it plausible, for he felt something well up in him which was the reason why he had fled the army." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "I think it's better, and it's not a big deal." ) . size ( ) ) ; assertEquals ( 1 , tool . check ( "A test test that should give errors." ) . size ( ) ) ; assertEquals ( 1 , tool . check ( "I can give you more a detailed description." ) . size ( ) ) ; assertTrue ( tool . getAllRules ( ) . size ( ) > 1000 ) ; assertEquals ( 0 , tool . check ( "The sea ice is highly variable - frozen solid during cold, calm weather and broke..." ) . size ( ) ) ; assertTrue ( tool . getAllRules ( ) . size ( ) > 3 ) ; assertEquals ( 1 , tool . check ( "I can give you more a detailed description." ) . size ( ) ) ; tool . disableRule ( "MORE_A_JJ" ) ; assertEquals ( 0 , tool . check ( "I can give you more a detailed description." ) . size ( ) ) ; assertEquals ( 1 , tool . check ( "I've go to go." ) . size ( ) ) ; tool . disableCategory ( "Possible Typo" ) ; assertEquals ( 0 , tool . check ( "I've go to go." ) . size ( ) ) ; } public void testPositionsWithEnglish ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new AmericanEnglish ( ) ) ; final List < RuleMatch > matches = tool . check ( "A sentence with no period\n" + "A sentence. A typoh." ) ; assertEquals ( 1 , matches . size ( ) ) ; final RuleMatch match = matches . get ( 0 ) ; assertEquals ( 1 , match . getLine ( ) ) ; assertEquals ( 15 , match . getColumn ( ) ) ; } public void testPositionsWithEnglishTwoLineBreaks ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new AmericanEnglish ( ) ) ; final List < RuleMatch > matches = tool . check ( "This sentence.\n\n" + "A sentence. A typoh." ) ; assertEquals ( 1 , matches . size ( ) ) ; final RuleMatch match = matches . get ( 0 ) ; assertEquals ( 2 , match . getLine ( ) ) ; assertEquals ( 14 , match . getColumn ( ) ) ; } public void testAnalyzedSentence ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new English ( ) ) ; assertEquals ( "<S> This[this/DT,B-NP-singular|E-NP-singular] " + "is[be/VBZ,B-VP] a[a/DT,B-NP-singular] " + "test­ed[tested/JJ,test/VBD,test/VBN,test­ed/null,I-NP-singular] " + "sentence[sentence/NN,E-NP-singular].[./.,</S>,O]" , tool . getAnalyzedSentence ( "This is a test\u00aded sentence." ) . toString ( ) ) ; assertEquals ( "<S> </S><P/> " , tool . getAnalyzedSentence ( "\n" ) . toString ( ) ) ; } public void testParagraphRules ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new English ( ) ) ; List < RuleMatch > matches1 = tool . check ( "(This is an quote.\n It ends in the second sentence." ) ; assertEquals ( 2 , matches1 . size ( ) ) ; assertEquals ( 2 , tool . getSentenceCount ( ) ) ; List < RuleMatch > matches2 = tool . check ( "(This is an quote.\n It ends in the second sentence." , false , ParagraphHandling . ONLYNONPARA ) ; assertEquals ( 1 , matches2 . size ( ) ) ; assertEquals ( "EN_A_VS_AN" , matches2 . get ( 0 ) . getRule ( ) . getId ( ) ) ; assertEquals ( 1 , tool . getSentenceCount ( ) ) ; List < RuleMatch > matches3 = tool . check ( "(This is an quote.\n It ends in the second sentence." , false , ParagraphHandling . ONLYPARA ) ; assertEquals ( 1 , matches3 . size ( ) ) ; assertEquals ( "EN_UNPAIRED_BRACKETS" , matches3 . get ( 0 ) . getRule ( ) . getId ( ) ) ; assertEquals ( 1 , tool . getSentenceCount ( ) ) ; List < RuleMatch > matches4 = tool . check ( "(This is an quote.\n It ends in the second sentence." , true , ParagraphHandling . ONLYPARA ) ; assertEquals ( 1 , matches4 . size ( ) ) ; assertEquals ( "EN_UNPAIRED_BRACKETS" , matches4 . get ( 0 ) . getRule ( ) . getId ( ) ) ; assertEquals ( 2 , tool . getSentenceCount ( ) ) ; } public void testWhitespace ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new English ( ) ) ; final AnalyzedSentence raw = tool . getRawAnalyzedSentence ( "Let's do a \"test\", do you understand?" ) ; final AnalyzedSentence cooked = tool . getAnalyzedSentence ( "Let's do a \"test\", do you understand?" ) ; assertFalse ( raw . equals ( cooked ) ) ; assertEquals ( raw . getTokens ( ) . length , cooked . getTokens ( ) . length ) ; int i = 0 ; for ( final AnalyzedTokenReadings atr : raw . getTokens ( ) ) { assertEquals ( atr . isWhitespaceBefore ( ) , cooked . getTokens ( ) [ i ] . isWhitespaceBefore ( ) ) ; i ++ ; } } public void testOverlapFilter ( ) throws IOException { final Category category = new Category ( "test category" ) ; final List < PatternToken > elements1 = Arrays . asList ( new PatternToken ( "one" , true , false , false ) ) ; final PatternRule rule1 = new PatternRule ( "id1" , new English ( ) , elements1 , "desc1" , "msg1" , "shortMsg1" ) ; rule1 . setSubId ( "1" ) ; rule1 . setCategory ( category ) ; final List < PatternToken > elements2 = Arrays . asList ( new PatternToken ( "one" , true , false , false ) , new PatternToken ( "two" , true , false , false ) ) ; final PatternRule rule2 = new PatternRule ( "id1" , new English ( ) , elements2 , "desc2" , "msg2" , "shortMsg2" ) ; rule2 . setSubId ( "2" ) ; rule2 . setCategory ( category ) ; final JLanguageTool tool = new JLanguageTool ( new English ( ) ) ; tool . addRule ( rule1 ) ; tool . addRule ( rule2 ) ; final List < RuleMatch > ruleMatches1 = tool . check ( "And one two three." ) ; assertEquals ( "one overlapping rule must be filtered out" , 1 , ruleMatches1 . size ( ) ) ; assertEquals ( "msg1" , ruleMatches1 . get ( 0 ) . getMessage ( ) ) ; final String sentence = "And one two three." ; final AnalyzedSentence analyzedSentence = tool . getAnalyzedSentence ( sentence ) ; final List < Rule > bothRules = new ArrayList < Rule > ( Arrays . asList ( rule1 , rule2 ) ) ; final List < RuleMatch > ruleMatches2 = tool . checkAnalyzedSentence ( ParagraphHandling . NORMAL , bothRules , 0 , 0 , 0 , sentence , analyzedSentence ) ; assertEquals ( "one overlapping rule must be filtered out" , 1 , ruleMatches2 . size ( ) ) ; assertEquals ( "msg1" , ruleMatches2 . get ( 0 ) . getMessage ( ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . SouthAfricanEnglish ; public class SouthAfricanEnglishConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new SouthAfricanEnglish ( ) ; } @ Override protected String createSampleText ( ) { return "A sentence with a error in the Hitchhiker's Guide tot he Galaxy" ; } }
package org . languagetool . language ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; public class ValencianCatalan extends Catalan { @ Override public String getName ( ) { return "Catalan (Valencian)" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "ES" } ; } @ Override public String getVariant ( ) { return "valencia" ; } @ Override public String getShortName ( ) { return "ca" ; } @ Override public List < String > getDefaultEnabledRulesForVariant ( ) { List < String > rules = Arrays . asList ( "EXIGEIX_VERBS_VALENCIANS" , "EXIGEIX_ACCENTUACIO_VALENCIANA" , "EXIGEIX_POSSESSIUS_U" , "EXIGEIX_VERBS_EIX" , "EXIGEIX_VERBS_ISC" , "SERVIR_PER_TALLAR" ) ; return Collections . unmodifiableList ( rules ) ; } @ Override public List < String > getDefaultDisabledRulesForVariant ( ) { List < String > rules = Arrays . asList ( "EXIGEIX_VERBS_CENTRAL" , "EXIGEIX_ACCENTUACIO_GENERAL" , "EXIGEIX_POSSESSIUS_V" , "EVITA_PRONOMS_VALENCIANS" , "EVITA_DEMOSTRATIUS_EIXE" , "VOCABULARI_VALENCIA" ) ; return Collections . unmodifiableList ( rules ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . AustralianEnglish ; public class AustralianEnglishConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new AustralianEnglish ( ) ; } @ Override protected String createSampleText ( ) { return "A sentence with a error in the Hitchhiker's Guide tot he Galaxy" ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . NewZealandEnglish ; public class NewZealandEnglishConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new NewZealandEnglish ( ) ; } @ Override protected String createSampleText ( ) { return "A sentence with a error in the Hitchhiker's Guide tot he Galaxy" ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . AmericanEnglish ; public class AmericanEnglishConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new AmericanEnglish ( ) ; } @ Override protected String createSampleText ( ) { return "A sentence with a error in the Hitchhiker's Guide tot he Galaxy" ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . CanadianEnglish ; public class CanadianEnglishConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new CanadianEnglish ( ) ; } @ Override protected String createSampleText ( ) { return "A sentence with a error in the Hitchhiker's Guide tot he Galaxy" ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . BritishEnglish ; public class BritishEnglishConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new BritishEnglish ( ) ; } @ Override protected String createSampleText ( ) { return "A sentence with a error in the Hitchhiker's Guide tot he Galaxy" ; } }
package org . languagetool . chunking ; import org . junit . Test ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . language . English ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import java . util . StringTokenizer ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class EnglishChunkerTest { @ Test public void testAddChunkTags ( ) throws Exception { EnglishChunker chunker = new EnglishChunker ( ) ; List < AnalyzedTokenReadings > readingsList = createReadingsList ( "A short test of the bicycle is needed" ) ; chunker . addChunkTags ( readingsList ) ; assertThat ( readingsList . size ( ) , is ( 15 ) ) ; assertThat ( readingsList . get ( 0 ) . getChunkTags ( ) . toString ( ) , is ( "[B-NP-singular]" ) ) ; assertThat ( readingsList . get ( 2 ) . getChunkTags ( ) . toString ( ) , is ( "[I-NP-singular]" ) ) ; assertThat ( readingsList . get ( 4 ) . getChunkTags ( ) . toString ( ) , is ( "[E-NP-singular]" ) ) ; assertThat ( readingsList . get ( 8 ) . getChunkTags ( ) . toString ( ) , is ( "[B-NP-singular]" ) ) ; assertThat ( readingsList . get ( 10 ) . getChunkTags ( ) . toString ( ) , is ( "[E-NP-singular]" ) ) ; assertThat ( readingsList . get ( 12 ) . getChunkTags ( ) . toString ( ) , is ( "[B-VP]" ) ) ; assertThat ( readingsList . get ( 14 ) . getChunkTags ( ) . toString ( ) , is ( "[I-VP]" ) ) ; } @ Test public void testContractions ( ) throws Exception { JLanguageTool langTool = new JLanguageTool ( new English ( ) ) ; AnalyzedSentence analyzedSentence = langTool . getAnalyzedSentence ( "I'll be there" ) ; AnalyzedTokenReadings [ ] tokens = analyzedSentence . getTokens ( ) ; assertThat ( tokens [ 1 ] . getChunkTags ( ) . get ( 0 ) , is ( new ChunkTag ( "B-NP-singular" ) ) ) ; assertThat ( tokens [ 2 ] . getChunkTags ( ) . size ( ) , is ( 0 ) ) ; assertThat ( tokens [ 3 ] . getChunkTags ( ) . size ( ) , is ( 0 ) ) ; assertThat ( tokens [ 5 ] . getChunkTags ( ) . get ( 0 ) , is ( new ChunkTag ( "I-VP" ) ) ) ; } @ Test public void testTokenize ( ) throws Exception { EnglishChunker chunker = new EnglishChunker ( ) ; String expected = "[I, 'm, going, to, London]" ; assertThat ( Arrays . toString ( chunker . tokenize ( "I'm going to London" ) ) , is ( expected ) ) ; assertThat ( Arrays . toString ( chunker . tokenize ( "I’m going to London" ) ) , is ( expected ) ) ; } private List < AnalyzedTokenReadings > createReadingsList ( String sentence ) { StringTokenizer tokenizer = new StringTokenizer ( sentence , " " , true ) ; List < AnalyzedTokenReadings > result = new ArrayList < > ( ) ; int pos = 0 ; while ( tokenizer . hasMoreTokens ( ) ) { String token = tokenizer . nextToken ( ) ; if ( token . trim ( ) . isEmpty ( ) ) { result . add ( new AnalyzedTokenReadings ( new AnalyzedToken ( token , null , null ) , pos ) ) ; } else { result . add ( new AnalyzedTokenReadings ( new AnalyzedToken ( token , "fake" , "fake" ) , pos ) ) ; } pos += token . length ( ) ; } return result ; } }
package org . languagetool . chunking ; import org . apache . commons . lang . StringUtils ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class EnglishChunkFilterTest { @ Test public void testSingular ( ) { assertChunks ( "He/B-NP owns/B-VP a/B-NP nice/I-NP house/I-NP in/X Berlin/B-NP ./." , "He/B-NP-singular,E-NP-singular owns/B-VP a/B-NP-singular nice/I-NP-singular house/E-NP-singular in/X Berlin/B-NP-singular,E-NP-singular ./." ) ; } @ Test @ Ignore ( "fails..." ) public void testPluralByAnd ( ) { assertChunks ( "He/B-NP owns/B-VP a/B-NP large/I-NP house/I-NP and/I-NP a/I-NP ship/I-NP in/X Berlin/B-NP ./." , "He/B-NP-singular owns/B-VP a/B-NP-plural large/I-NP-plural house/I-NP-plural and/I-NP-plural a/I-NP-plural ship/I-NP-plural in/X Berlin/B-NP-singular ./." ) ; } @ Test public void testPluralByPluralNoun ( ) throws IOException { String input = "I/X have/N-VP ten/B-NP books/I-NP ./." ; List < ChunkTaggedToken > tokens = makeTokens ( input ) ; tokens . remove ( 3 ) ; AnalyzedTokenReadings readings = new AnalyzedTokenReadings ( Arrays . asList ( new AnalyzedToken ( "books" , "NNS" , "book" ) , new AnalyzedToken ( "books" , "VBZ" , "book" ) ) , 0 ) ; tokens . add ( 3 , new ChunkTaggedToken ( "books" , Collections . singletonList ( new ChunkTag ( "I-NP" ) ) , readings ) ) ; assertChunks ( tokens , "I/X have/N-VP ten/B-NP-plural books/E-NP-plural ./." ) ; } private void assertChunks ( String input , String expected ) { List < ChunkTaggedToken > tokens = makeTokens ( input ) ; assertChunks ( tokens , expected ) ; } private void assertChunks ( List < ChunkTaggedToken > tokens , String expected ) { EnglishChunkFilter filter = new EnglishChunkFilter ( ) ; List < ChunkTaggedToken > result = filter . filter ( tokens ) ; assertThat ( StringUtils . join ( result , " " ) , is ( expected ) ) ; } private List < ChunkTaggedToken > makeTokens ( String tokensAsString ) { List < ChunkTaggedToken > result = new ArrayList < > ( ) ; for ( String token : tokensAsString . split ( " " ) ) { String [ ] parts = token . split ( "/" ) ; if ( parts . length != 2 ) { throw new RuntimeException ( "Invalid token, form 'x/y' required: " + token ) ; } ChunkTag chunkTag = new ChunkTag ( parts [ 1 ] ) ; result . add ( new ChunkTaggedToken ( parts [ 0 ] , Collections . singletonList ( chunkTag ) , null ) ) ; } return result ; } }
package org . languagetool . synthesis . en ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; public class EnglishSynthesizerTest extends TestCase { private AnalyzedToken dummyToken ( String tokenStr , String tokenLemma ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenLemma ) ; } private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } public final void testSynthesizeStringString ( ) throws IOException { EnglishSynthesizer synth = new EnglishSynthesizer ( ) ; assertEquals ( synth . synthesize ( dummyToken ( "blablabla" ) , "blablabla" ) . length , 0 ) ; assertEquals ( "[was, were]" , Arrays . toString ( synth . synthesize ( dummyToken ( "be" ) , "VBD" ) ) ) ; assertEquals ( "[presidents]" , Arrays . toString ( synth . synthesize ( dummyToken ( "president" ) , "NNS" ) ) ) ; assertEquals ( "[tested]" , Arrays . toString ( synth . synthesize ( dummyToken ( "test" ) , "VBD" ) ) ) ; assertEquals ( "[tested]" , Arrays . toString ( synth . synthesize ( dummyToken ( "test" ) , "VBD" , false ) ) ) ; assertEquals ( "[tested]" , Arrays . toString ( synth . synthesize ( dummyToken ( "test" ) , "VBD" , true ) ) ) ; assertEquals ( "[tested, testing]" , Arrays . toString ( synth . synthesize ( dummyToken ( "test" ) , "VBD|VBG" , true ) ) ) ; assertEquals ( "[a university, the university]" , Arrays . toString ( synth . synthesize ( dummyToken ( "university" ) , "+DT" , false ) ) ) ; assertEquals ( "[an hour, the hour]" , Arrays . toString ( synth . synthesize ( dummyToken ( "hour" ) , "+DT" , false ) ) ) ; assertEquals ( "[an hour]" , Arrays . toString ( synth . synthesize ( dummyToken ( "hour" ) , "+INDT" , false ) ) ) ; assertEquals ( "[an hour]" , Arrays . toString ( synth . synthesize ( dummyToken ( "hours" , "hour" ) , "NN\\+INDT" , true ) ) ) ; assertEquals ( "[the hour]" , Arrays . toString ( synth . synthesize ( dummyToken ( "hours" , "hour" ) , "NN\\+DT" , true ) ) ) ; } }
package org . languagetool . tools ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . English ; import org . xml . sax . SAXException ; import javax . xml . parsers . ParserConfigurationException ; import java . io . IOException ; public class ToolsTest extends TestCase { public void testCorrect ( ) throws IOException , ParserConfigurationException , SAXException { final JLanguageTool tool = new JLanguageTool ( new English ( ) ) ; assertEquals ( "This is a test." , Tools . correctText ( "This is an test." , tool ) ) ; } }
package org . languagetool . rules . en ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . BritishEnglish ; import org . languagetool . rules . RuleMatch ; public class BritishReplaceRuleTest extends TestCase { private BritishReplaceRule rule ; private JLanguageTool langTool ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; rule = new BritishReplaceRule ( TestTools . getMessages ( "en" ) ) ; langTool = new JLanguageTool ( new BritishEnglish ( ) ) ; } public void testRule ( ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Buy some petrol." ) ) . length ) ; checkSimpleReplaceRule ( "Diapers for sale!" , "Nappies" ) ; checkSimpleReplaceRule ( "We have some diapers for sale." , "nappies" ) ; } private void checkSimpleReplaceRule ( String sentence , String word ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( "Invalid matches.length while checking sentence: " + sentence , 1 , matches . length ) ; assertEquals ( "Invalid replacement count wile checking sentence: " + sentence , 1 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( "Invalid suggested replacement while checking sentence: " + sentence , word , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . synthesis . ca ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import morfologik . stemming . IStemmer ; import morfologik . stemming . WordData ; import org . languagetool . AnalyzedToken ; import org . languagetool . synthesis . BaseSynthesizer ; public class CatalanSynthesizer extends BaseSynthesizer { private static final String RESOURCE_FILENAME = "/ca/catalan_synth.dict" ; private static final String TAGS_FILE_NAME = "/ca/catalan_tags.txt" ; private static final Pattern pMS = Pattern . compile ( "(N|A.).[MC][SN].*|V.P.*SM.?" ) ; private static final Pattern pFS = Pattern . compile ( "(N|A.).[FC][SN].*|V.P.*SF.?" ) ; private static final Pattern pMP = Pattern . compile ( "(N|A.).[MC][PN].*|V.P.*PM.?" ) ; private static final Pattern pFP = Pattern . compile ( "(N|A.).[FC][PN].*|V.P.*PF.?" ) ; private static final Pattern pPrep = Pattern . compile ( "(DT)(.*)" ) ; private static final Pattern pMascYes = Pattern . compile ( "h?[aeiouàèéíòóú].*" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern pMascNo = Pattern . compile ( "h?[ui][aeioàèéóò].+" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern pFemYes = Pattern . compile ( "h?[aeoàèéíòóú].*|h?[ui][^aeiouàèéíòóúüï]+[aeiou][ns]?|urbs" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern pFemNo = Pattern . compile ( "host|ira|inxa" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern pVerb = Pattern . compile ( "V.*[CVBXYZ0123456]" ) ; public CatalanSynthesizer ( ) { super ( RESOURCE_FILENAME , TAGS_FILE_NAME ) ; } @ Override public String [ ] synthesize ( final AnalyzedToken token , final String posTag ) throws IOException { initPossibleTags ( ) ; Pattern p ; boolean addDt = false ; String prep = "" ; final Matcher mPrep = pPrep . matcher ( posTag ) ; if ( mPrep . matches ( ) ) { addDt = true ; if ( mPrep . groupCount ( ) > 1 ) { prep = mPrep . group ( 2 ) ; } } if ( addDt ) { p = Pattern . compile ( "N.*|A.*|V.P.*|PX." ) ; } else { p = Pattern . compile ( posTag ) ; } final List < String > results = new ArrayList < > ( ) ; final IStemmer synthesizer = createStemmer ( ) ; for ( final String tag : possibleTags ) { final Matcher m = p . matcher ( tag ) ; if ( m . matches ( ) ) { if ( addDt ) { lookupWithEl ( token . getLemma ( ) , tag , prep , results , synthesizer ) ; } else { lookup ( token . getLemma ( ) , tag , results ) ; } } } if ( ( results . size ( ) == 0 ) && posTag . startsWith ( "V" ) ) { if ( ! posTag . endsWith ( "0" ) ) { lookup ( token . getLemma ( ) , posTag . substring ( 0 , posTag . length ( ) - 1 ) . concat ( "0" ) , results ) ; } if ( results . size ( ) == 0 ) { return synthesize ( token , posTag . substring ( 0 , posTag . length ( ) - 1 ) . concat ( "." ) , true ) ; } } return results . toArray ( new String [ results . size ( ) ] ) ; } @ Override public String [ ] synthesize ( final AnalyzedToken token , final String posTag , final boolean posTagRegExp ) throws IOException { if ( posTagRegExp ) { initPossibleTags ( ) ; Pattern p = Pattern . compile ( posTag ) ; final List < String > results = new ArrayList < > ( ) ; for ( final String tag : possibleTags ) { final Matcher m = p . matcher ( tag ) ; if ( m . matches ( ) ) { lookup ( token . getLemma ( ) , tag , results ) ; } } if ( ( results . size ( ) == 0 ) ) { final Matcher mVerb = pVerb . matcher ( posTag ) ; if ( mVerb . matches ( ) ) { if ( ! posTag . endsWith ( "0" ) ) { p = Pattern . compile ( posTag . substring ( 0 , posTag . length ( ) - 1 ) . concat ( "0" ) ) ; for ( final String tag : possibleTags ) { final Matcher m = p . matcher ( tag ) ; if ( m . matches ( ) ) { lookup ( token . getLemma ( ) , tag , results ) ; } } } if ( results . size ( ) == 0 ) { p = Pattern . compile ( posTag . substring ( 0 , posTag . length ( ) - 1 ) . concat ( "." ) ) ; for ( final String tag : possibleTags ) { final Matcher m = p . matcher ( tag ) ; if ( m . matches ( ) ) { lookup ( token . getLemma ( ) , tag , results ) ; } } } } } return results . toArray ( new String [ results . size ( ) ] ) ; } return synthesize ( token , posTag ) ; } private void lookupWithEl ( String lemma , String posTag , String prep , List < String > results , IStemmer synthesizer ) { final List < WordData > wordForms = synthesizer . lookup ( lemma + "|" + posTag ) ; final Matcher mMS = pMS . matcher ( posTag ) ; final Matcher mFS = pFS . matcher ( posTag ) ; final Matcher mMP = pMP . matcher ( posTag ) ; final Matcher mFP = pFP . matcher ( posTag ) ; for ( WordData wd : wordForms ) { final String word = wd . getStem ( ) . toString ( ) ; if ( mMS . matches ( ) ) { final Matcher mMascYes = pMascYes . matcher ( word ) ; final Matcher mMascNo = pMascNo . matcher ( word ) ; if ( prep . equals ( "per" ) ) { if ( mMascYes . matches ( ) && ! mMascNo . matches ( ) ) { results . add ( "per l'" + word ) ; } else { results . add ( "pel " + word ) ; } } else if ( prep . isEmpty ( ) ) { if ( mMascYes . matches ( ) && ! mMascNo . matches ( ) ) { results . add ( "l'" + word ) ; } else { results . add ( "el " + word ) ; } } else { if ( mMascYes . matches ( ) && ! mMascNo . matches ( ) ) { results . add ( prep + " l'" + word ) ; } else { results . add ( prep + "l " + word ) ; } } } if ( mFS . matches ( ) ) { final Matcher mFemYes = pFemYes . matcher ( word ) ; final Matcher mFemNo = pFemNo . matcher ( word ) ; if ( prep . equals ( "per" ) ) { if ( mFemYes . matches ( ) && ! mFemNo . matches ( ) ) { results . add ( "per l'" + word ) ; } else { results . add ( "per la " + word ) ; } } else if ( prep . isEmpty ( ) ) { if ( mFemYes . matches ( ) && ! mFemNo . matches ( ) ) { results . add ( "l'" + word ) ; } else { results . add ( "la " + word ) ; } } else { if ( mFemYes . matches ( ) && ! mFemNo . matches ( ) ) { results . add ( prep + " l'" + word ) ; } else { results . add ( prep + " la " + word ) ; } } } if ( mMP . matches ( ) ) { if ( prep . equals ( "per" ) ) { results . add ( "pels " + word ) ; } else if ( prep . isEmpty ( ) ) { results . add ( "els " + word ) ; } else { results . add ( prep + "ls " + word ) ; } } if ( mFP . matches ( ) ) { if ( prep . isEmpty ( ) ) { results . add ( "les " + word ) ; } else { results . add ( prep + " les " + word ) ; } } } } }
package org . languagetool . rules . en ; import java . io . IOException ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . English ; import org . languagetool . rules . AbstractCompoundRuleTest ; public class CompoundRuleTest extends AbstractCompoundRuleTest { @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; langTool = new JLanguageTool ( new English ( ) ) ; rule = new CompoundRule ( TestTools . getEnglishMessages ( ) ) ; } public void testRule ( ) throws IOException { check ( 0 , "The software supports case-sensitive search." ) ; check ( 0 , "He is one-year-old." ) ; check ( 1 , "case sensitive" , new String [ ] { "case-sensitive" } ) ; } }
package org . languagetool . rules . en ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . English ; import org . languagetool . languagemodel . LuceneLanguageModel ; import org . languagetool . rules . RuleMatch ; import java . io . File ; import java . io . IOException ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . * ; public class EnglishConfusionProbabilityRuleTest { private final English english = new English ( ) ; private final JLanguageTool lt = new JLanguageTool ( english ) ; private EnglishConfusionProbabilityRule rule ; @ Test @ Ignore public void testRule ( ) throws IOException { File indexDir = new File ( "/data/google-ngram-index" ) ; if ( ! indexDir . exists ( ) ) { throw new RuntimeException ( "ngram data not found at " + indexDir + ", get it at http://wiki.languagetool.org/finding-errors-using-big-data" ) ; } rule = new EnglishConfusionProbabilityRule ( TestTools . getEnglishMessages ( ) , new LuceneLanguageModel ( indexDir ) , english ) ; Replacement theirThere = new Replacement ( "there" , "their" ) ; assertMatch ( "Is their a telephone anywhere?" , theirThere ) ; assertMatch ( "I can't remember how to go their." , theirThere ) ; assertMatch ( "Can you please tell me why their seems to be two churches in every village?" , theirThere ) ; assertMatch ( "Why do American parents praise there children?" , theirThere ) ; assertMatch ( "The British supplied there native allies with muskets, gunpowder and advice." , theirThere ) ; Replacement knowNow = new Replacement ( "know" , "now" ) ; assertMatch ( "From know on let us study in the morning." , knowNow ) ; assertMatch ( "I am from Hiroshima, but know I live in Tokyo." , knowNow ) ; assertMatch ( "I didn't now where it came from." , knowNow ) ; assertMatch ( "Let me now if I need to make any changes." , knowNow ) ; Replacement fourFor = new Replacement ( "four" , "for" ) ; assertMatch ( "This gives us a minimum date four the age of Afroasiatic." , fourFor ) ; assertMatch ( "Agassi admitted that he used and tested positive four methamphetamine in 1997." , fourFor ) ; assertMatch ( "Alabama has for of the world's largest stadiums." , fourFor ) ; assertMatch ( "There are no male actors and the for leading actresses dubbed themselves in the Castilian version." , fourFor ) ; } private void assertMatch ( String errorInput , Replacement rep ) throws IOException { assertMatch ( errorInput , 1 ) ; String fixedInput ; if ( errorInput . matches ( ".*\\b" + rep . newsString + "\\b.*" ) ) { fixedInput = errorInput . replaceFirst ( "\\b" + rep . newsString + "\\b" , rep . oldString ) ; } else { fixedInput = errorInput . replaceFirst ( "\\b" + rep . oldString + "\\b" , rep . newsString ) ; } if ( fixedInput . equals ( errorInput ) ) { throw new RuntimeException ( "Could not fix sentence: '" + errorInput + "' with " + rep ) ; } assertMatch ( fixedInput , 0 ) ; } private void assertMatch ( String input , int expectedMatches ) throws IOException { AnalyzedSentence errorSentence = lt . getAnalyzedSentence ( input ) ; RuleMatch [ ] matches = rule . match ( errorSentence ) ; assertThat ( "Got " + matches . length + " match(es) for: " + input , matches . length , is ( expectedMatches ) ) ; } static class Replacement { String oldString ; String newsString ; Replacement ( String oldString , String newsString ) { this . oldString = oldString ; this . newsString = newsString ; } @ Override public String toString ( ) { return oldString + "/" + newsString ; } } }
package org . languagetool . rules . en ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . NewZealandEnglish ; import org . languagetool . rules . RuleMatch ; public class NewZealandReplaceRuleTest extends TestCase { private NewZealandReplaceRule rule ; private JLanguageTool langTool ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; rule = new NewZealandReplaceRule ( TestTools . getMessages ( "en" ) ) ; langTool = new JLanguageTool ( new NewZealandEnglish ( ) ) ; } public void testRule ( ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Walk on the footpath." ) ) . length ) ; checkSimpleReplaceRule ( "I walked on the sidewalk" , "footpath" ) ; } private void checkSimpleReplaceRule ( String sentence , String word ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( "Invalid matches.length while checking sentence: " + sentence , 1 , matches . length ) ; assertEquals ( "Invalid replacement count wile checking sentence: " + sentence , 1 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( "Invalid suggested replacement while checking sentence: " + sentence , word , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . en ; import static org . junit . Assert . assertEquals ; import java . io . IOException ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . language . AustralianEnglish ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public class MorfologikAustralianSpellerRuleTest extends AbstractEnglishSpellerRuleTest { @ Test public void testSuggestions ( ) throws IOException { Language language = new AustralianEnglish ( ) ; Rule rule = new MorfologikAustralianSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; super . testNonVariantSpecificSuggestions ( rule , language ) ; } @ Test public void testMorfologikSpeller ( ) throws IOException { final AustralianEnglish language = new AustralianEnglish ( ) ; final MorfologikAustralianSpellerRule rule = new MorfologikAustralianSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; final JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "This is an example: we get behaviour as a dictionary word." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Why don't we speak today." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "He doesn't know what to do." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Agnathia" ) ) . length ) ; RuleMatch [ ] matches1 = rule . match ( langTool . getAnalyzedSentence ( "behavior" ) ) ; assertEquals ( 1 , matches1 . length ) ; assertEquals ( 0 , matches1 [ 0 ] . getFromPos ( ) ) ; assertEquals ( 8 , matches1 [ 0 ] . getToPos ( ) ) ; assertEquals ( "behaviour" , matches1 [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "aõh" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "a" ) ) . length ) ; RuleMatch [ ] matches2 = rule . match ( langTool . getAnalyzedSentence ( "He teached us." ) ) ; assertEquals ( 1 , matches2 . length ) ; assertEquals ( 3 , matches2 [ 0 ] . getFromPos ( ) ) ; assertEquals ( 10 , matches2 [ 0 ] . getToPos ( ) ) ; assertEquals ( "taught" , matches2 [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . en ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . List ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class AbstractEnglishSpellerRuleTest { private JLanguageTool lt ; private Rule rule ; public void testNonVariantSpecificSuggestions ( Rule rule , Language language ) throws IOException { this . lt = new JLanguageTool ( language ) ; this . rule = rule ; assertFirstMatch ( "teh" , "the" ) ; assertFirstMatch ( "transexual" , "transsexual" ) ; assertFirstMatch ( "seperate" , "separate" ) ; assertFirstMatch ( "definately" , "definitely" ) ; assertFirstMatch ( "recieve" , "receive" ) ; assertFirstMatch ( "offical" , "official" ) ; assertFirstMatch ( "managment" , "management" ) ; assertFirstMatch ( "goverment " , "government" ) ; assertFirstMatch ( "commerical" , "commercial" ) ; assertFirstMatch ( "Febuary" , "February" ) ; assertFirstMatch ( "enviroment" , "environment" ) ; assertFirstMatch ( "occurence" , "occurrence" ) ; assertFirstMatch ( "commision" , "commission" ) ; assertFirstMatch ( "assocation" , "association" ) ; assertFirstMatch ( "Cincinatti" , "Cincinnati" ) ; assertFirstMatch ( "milennium" , "millennium" ) ; assertFirstMatch ( "accomodation" , "accommodation" ) ; assertFirstMatch ( "foriegn" , "foreign" ) ; assertFirstMatch ( "chemcial" , "chemical" ) ; assertFirstMatch ( "developement" , "development" ) ; assertFirstMatch ( "maintainance" , "maintenance" ) ; assertFirstMatch ( "restaraunt" , "restaurant" ) ; assertFirstMatch ( "garentee" , "guarantee" ) ; assertFirstMatch ( "greatful" , "grateful" ) ; assertFirstMatch ( "hipocrit" , "hypocrite" ) ; assertFirstMatch ( "mischevious" , "mischievous" ) ; assertFirstMatch ( "hygeine" , "hygiene" ) ; assertFirstMatch ( "vehical" , "medical" , "vehicle" ) ; assertFirstMatch ( "alot" , "a lot" ) ; assertFirstMatch ( "speach" , "speech" ) ; assertFirstMatch ( "rythem" , "them" , "rather" , "rhythm" ) ; assertFirstMatch ( "vacume" , "value" , "volume" , "acute" , "vacuum" ) ; } private void assertFirstMatch ( String text , String ... expectedSuggestions ) throws IOException { RuleMatch [ ] matches = rule . match ( lt . getAnalyzedSentence ( text ) ) ; assertTrue ( "Expected 1 match for '" + text + "', got " + matches . length , matches . length == 1 ) ; List < String > suggestions = matches [ 0 ] . getSuggestedReplacements ( ) ; assertTrue ( "Expected at least one suggestion for '" + text + "'" , suggestions . size ( ) > 0 ) ; int i = 0 ; for ( String expectedSuggestion : expectedSuggestions ) { assertThat ( "Expected suggestion '" + expectedSuggestion + "' not found in suggestions" + suggestions , suggestions . get ( i ) , is ( expectedSuggestion ) ) ; i ++ ; } } }
package org . languagetool . rules . en ; import org . junit . Test ; import org . languagetool . * ; import java . io . IOException ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; public class EnglishWordRepeatRuleTest { private final Language english = Languages . getLanguageForShortName ( "en" ) ; private final EnglishWordRepeatRule rule = new EnglishWordRepeatRule ( TestTools . getEnglishMessages ( ) , english ) ; private JLanguageTool langTool ; @ Test public void testRepeatRule ( ) throws IOException { langTool = new JLanguageTool ( english ) ; assertGood ( "This is a test." ) ; assertGood ( "If I had had time, I would have gone to see him." ) ; assertGood ( "I don't think that that is a problem." ) ; assertGood ( "He also said that Azerbaijan had fulfilled a task he set, which was that that their defense budget should exceed the entire state budget of Armenia." ) ; assertGood ( "Just as if that was proof that that English was correct." ) ; assertGood ( "It was noticed after more than a month that that promise had not been carried out." ) ; assertGood ( "It was said that that lady was an actress." ) ; assertGood ( "Kurosawa's three consecutive movies after Seven Samurai had not managed to capture Japanese audiences in the way that that film had." ) ; assertGood ( "The can can hold the water." ) ; assertBad ( "I can can hold the ladder." ) ; assertBad ( "You can feel confident that that this administration will continue to support a free and open Internet." ) ; assertBad ( "This is is a test." ) ; } private void assertGood ( String sentence ) throws IOException { assertMatches ( sentence , 0 ) ; } private void assertBad ( String sentence ) throws IOException { assertMatches ( sentence , 1 ) ; } private void assertMatches ( String sentence , int expectedMatches ) throws IOException { AnalyzedSentence aSentence = langTool . getAnalyzedSentence ( sentence ) ; assertThat ( rule . match ( aSentence ) . length , is ( expectedMatches ) ) ; } }
package org . languagetool . rules . en ; import static org . junit . Assert . assertEquals ; import java . io . IOException ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . language . NewZealandEnglish ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public class MorfologikNewZealandSpellerRuleTest extends AbstractEnglishSpellerRuleTest { @ Test public void testSuggestions ( ) throws IOException { Language language = new NewZealandEnglish ( ) ; Rule rule = new MorfologikNewZealandSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; super . testNonVariantSpecificSuggestions ( rule , language ) ; } @ Test public void testMorfologikSpeller ( ) throws IOException { final NewZealandEnglish language = new NewZealandEnglish ( ) ; final MorfologikNewZealandSpellerRule rule = new MorfologikNewZealandSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; final JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "This is an example: we get behaviour as a dictionary word." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Why don't we speak today." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "He doesn't know what to do." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Abercrombie" ) ) . length ) ; RuleMatch [ ] matches1 = rule . match ( langTool . getAnalyzedSentence ( "behavior" ) ) ; assertEquals ( 1 , matches1 . length ) ; assertEquals ( 0 , matches1 [ 0 ] . getFromPos ( ) ) ; assertEquals ( 8 , matches1 [ 0 ] . getToPos ( ) ) ; assertEquals ( "behaviour" , matches1 [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "aõh" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "a" ) ) . length ) ; RuleMatch [ ] matches2 = rule . match ( langTool . getAnalyzedSentence ( "He teached us." ) ) ; assertEquals ( 1 , matches2 . length ) ; assertEquals ( 3 , matches2 [ 0 ] . getFromPos ( ) ) ; assertEquals ( 10 , matches2 [ 0 ] . getToPos ( ) ) ; assertEquals ( "taught" , matches2 [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . en ; import static org . junit . Assert . assertEquals ; import java . io . IOException ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . language . SouthAfricanEnglish ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public class MorfologikSouthAfricanSpellerRuleTest extends AbstractEnglishSpellerRuleTest { @ Test public void testSuggestions ( ) throws IOException { Language language = new SouthAfricanEnglish ( ) ; Rule rule = new MorfologikSouthAfricanSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; super . testNonVariantSpecificSuggestions ( rule , language ) ; } @ Test public void testMorfologikSpeller ( ) throws IOException { final SouthAfricanEnglish language = new SouthAfricanEnglish ( ) ; final MorfologikSouthAfricanSpellerRule rule = new MorfologikSouthAfricanSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; final JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "This is an example: we get behaviour as a dictionary word." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Why don't we speak today." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "He doesn't know what to do." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Amanzimnyama" ) ) . length ) ; RuleMatch [ ] matches1 = rule . match ( langTool . getAnalyzedSentence ( "behavior" ) ) ; assertEquals ( 1 , matches1 . length ) ; assertEquals ( 0 , matches1 [ 0 ] . getFromPos ( ) ) ; assertEquals ( 8 , matches1 [ 0 ] . getToPos ( ) ) ; assertEquals ( "behaviour" , matches1 [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "aõh" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "a" ) ) . length ) ; RuleMatch [ ] matches2 = rule . match ( langTool . getAnalyzedSentence ( "He teached us." ) ) ; assertEquals ( 1 , matches2 . length ) ; assertEquals ( 3 , matches2 [ 0 ] . getFromPos ( ) ) ; assertEquals ( 10 , matches2 [ 0 ] . getToPos ( ) ) ; assertEquals ( "taught" , matches2 [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . en ; import static org . junit . Assert . assertEquals ; import java . io . IOException ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . language . BritishEnglish ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public class MorfologikBritishSpellerRuleTest extends AbstractEnglishSpellerRuleTest { @ Test public void testSuggestions ( ) throws IOException { Language language = new BritishEnglish ( ) ; Rule rule = new MorfologikBritishSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; super . testNonVariantSpecificSuggestions ( rule , language ) ; } @ Test public void testMorfologikSpeller ( ) throws IOException { final BritishEnglish language = new BritishEnglish ( ) ; final MorfologikBritishSpellerRule rule = new MorfologikBritishSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; final JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "This is an example: we get behaviour as a dictionary word." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Why don't we speak today." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "He doesn't know what to do." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "This is my Ph.D. thesis." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; RuleMatch [ ] matches1 = rule . match ( langTool . getAnalyzedSentence ( "Behavior" ) ) ; assertEquals ( 1 , matches1 . length ) ; assertEquals ( 0 , matches1 [ 0 ] . getFromPos ( ) ) ; assertEquals ( 8 , matches1 [ 0 ] . getToPos ( ) ) ; assertEquals ( "Behaviour" , matches1 [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "aõh" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "a" ) ) . length ) ; RuleMatch [ ] matches2 = rule . match ( langTool . getAnalyzedSentence ( "He teached us." ) ) ; assertEquals ( 1 , matches2 . length ) ; assertEquals ( 3 , matches2 [ 0 ] . getFromPos ( ) ) ; assertEquals ( 10 , matches2 [ 0 ] . getToPos ( ) ) ; assertEquals ( "taught" , matches2 [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . en ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . English ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . TextLevelRule ; import java . io . IOException ; import java . util . Collections ; public class EnglishUnpairedBracketsRuleTest extends TestCase { private TextLevelRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new EnglishUnpairedBracketsRule ( TestTools . getEnglishMessages ( ) , new English ( ) ) ; langTool = new JLanguageTool ( new English ( ) ) ; } public void testRule ( ) throws IOException { assertCorrect ( "(This is a test sentence)." ) ; assertCorrect ( "This is a word 'test'." ) ; assertCorrect ( "This is a sentence with a smiley :-)" ) ; assertCorrect ( "This is a sentence with a smiley ;-) and so on..." ) ; assertCorrect ( "I don't know." ) ; assertCorrect ( "This is the joint presidents' declaration." ) ; assertCorrect ( "The screen is 20\" wide." ) ; assertCorrect ( "This is a [test] sentence..." ) ; assertCorrect ( "The plight of Tamil refugees caused a surge of support from most of the Tamil political parties.[90]" ) ; assertCorrect ( "This is what he said: \"We believe in freedom. This is what we do.\"" ) ; assertCorrect ( "(([20] [20] [20]))" ) ; assertCorrect ( "This is a \"special test\", right?" ) ; assertCorrect ( "We discussed this in Chapter 1)." ) ; assertCorrect ( "The jury recommended that: (1) Four additional deputies be employed." ) ; assertCorrect ( "We discussed this in section 1a)." ) ; assertCorrect ( "We discussed this in section iv)." ) ; assertCorrect ( "In addition, the government would pay a $1,000 \"cost of education\" grant to the schools." ) ; assertCorrect ( "Paradise lost to the alleged water needs of Texas' big cities Thursday." ) ; assertCorrect ( "Kill 'em all!" ) ; assertCorrect ( "Puttin' on the Ritz" ) ; assertCorrect ( "(Ketab fi Isti'mal al-'Adad al-Hindi)" ) ; assertCorrect ( "On their 'host' societies." ) ; assertCorrect ( "On their 'host society'." ) ; assertCorrect ( "Burke-rostagno the Richard S. Burkes' home in Wayne may be the setting for the wedding reception for their daughter." ) ; assertCorrect ( "The '49 team was off to a so-so 5-5 beginning" ) ; assertCorrect ( "The best reason that can be advanced for the state adopting the practice was the advent of expanded highway construction during the 1920s and '30s." ) ; assertCorrect ( "A Republican survey says Kennedy won the '60 election on the religious issue." ) ; assertCorrect ( "Economy class seats have a seat pitch of 31-33\", with newer aircraft having thinner seats that have a 31\" pitch." ) ; assertCorrect ( "\"02\" will sort before \"10\" as expected so it will have size of 10\"." ) ; assertCorrect ( "\"02\" will sort before \"10\" as expected so it will have size of 10\"" ) ; assertCorrect ( "\"02\" will sort before \"10\"" ) ; assertCorrect ( "On their 'host societies'." ) ; assertIncorrect ( "(This is a test sentence." ) ; assertIncorrect ( "This is a test with an apostrophe &'." ) ; assertIncorrect ( "&'" ) ; assertIncorrect ( "!'" ) ; assertIncorrect ( "What?'" ) ; assertIncorrect ( "Some text (and some funny remark :-) with more text to follow" ) ; RuleMatch [ ] matches ; matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( "(This is a test” sentence." ) ) ) ; assertEquals ( 2 , matches . length ) ; matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( "This [is (a test} sentence." ) ) ) ; assertEquals ( 3 , matches . length ) ; } private void assertCorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( sentence ) ) ) ; assertEquals ( 0 , matches . length ) ; } private void assertIncorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( sentence ) ) ) ; assertEquals ( 1 , matches . length ) ; } public void testMultipleSentences ( ) throws IOException { final JLanguageTool lt = new JLanguageTool ( new English ( ) ) ; assertEquals ( 0 , getMatches ( "This is multiple sentence text that contains a bracket: " + "[This is bracket. With some text.] and this continues.\n" , lt ) ) ; assertEquals ( 0 , getMatches ( "This is multiple sentence text that contains a bracket. " + "(This is bracket. \n\n With some text.) and this continues." , lt ) ) ; assertEquals ( 1 , getMatches ( "This is multiple sentence text that contains a bracket: " + "[This is bracket. With some text. And this continues.\n\n" , lt ) ) ; } private int getMatches ( String input , JLanguageTool lt ) throws IOException { return lt . check ( input ) . size ( ) ; } }
package org . languagetool . rules . ca ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . GenericUnpairedBracketsRule ; import org . languagetool . rules . ITSIssueType ; public class CatalanUnpairedQuestionMarksRule extends GenericUnpairedBracketsRule { private static final List < String > CA_START_SYMBOLS = Arrays . asList ( "¿" ) ; private static final List < String > CA_END_SYMBOLS = Arrays . asList ( "?" ) ; public CatalanUnpairedQuestionMarksRule ( final ResourceBundle messages , final Language language ) { super ( messages , CA_START_SYMBOLS , CA_END_SYMBOLS ) ; setLocQualityIssueType ( ITSIssueType . Style ) ; setDefaultOff ( ) ; } @ Override public String getId ( ) { return "CA_UNPAIRED_QUESTION" ; } @ Override public String getDescription ( ) { return "Exigeix signe d'interrogació inicial" ; } }
package org . languagetool . rules . en ; import org . junit . BeforeClass ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . language . AmericanEnglish ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; import static org . junit . Assert . assertEquals ; public class MorfologikAmericanSpellerRuleTest extends AbstractEnglishSpellerRuleTest { private static final AmericanEnglish language = new AmericanEnglish ( ) ; private static MorfologikAmericanSpellerRule rule ; private static JLanguageTool langTool ; @ BeforeClass public static void setup ( ) throws IOException { rule = new MorfologikAmericanSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; langTool = new JLanguageTool ( language ) ; } @ Test public void testSuggestions ( ) throws IOException { Language language = new AmericanEnglish ( ) ; Rule rule = new MorfologikAmericanSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; super . testNonVariantSpecificSuggestions ( rule , language ) ; } @ Test public void testMorfologikSpeller ( ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "This is an example: we get behavior as a dictionary word." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Why don't we speak today." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "An URL like http://sdaasdwe.com is no error." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "He doesn't know what to do." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; RuleMatch [ ] matches1 = rule . match ( langTool . getAnalyzedSentence ( "behaviour" ) ) ; assertEquals ( 1 , matches1 . length ) ; assertEquals ( 0 , matches1 [ 0 ] . getFromPos ( ) ) ; assertEquals ( 9 , matches1 [ 0 ] . getToPos ( ) ) ; assertEquals ( "behavior" , matches1 [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "aõh" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "a" ) ) . length ) ; RuleMatch [ ] matches2 = rule . match ( langTool . getAnalyzedSentence ( "He teached us." ) ) ; assertEquals ( 1 , matches2 . length ) ; assertEquals ( 3 , matches2 [ 0 ] . getFromPos ( ) ) ; assertEquals ( 10 , matches2 [ 0 ] . getToPos ( ) ) ; assertEquals ( "taught" , matches2 [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "A web-based software." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "A wxeb-based software." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "A web-baxsed software." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "A web-feature-driven-car software." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "A web-feature-drivenx-car software." ) ) . length ) ; } @ Test public void testIgnoredChars ( ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "software" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "soft\u00ADware" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "A software" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "A soft\u00ADware" ) ) . length ) ; } @ Test public void testSuggestionForIrregularWords ( ) throws IOException { assertSuggestion ( "He teached us." , "taught" ) ; assertSuggestion ( "He buyed the wrong brand" , "bought" ) ; assertSuggestion ( "I thinked so." , "thought" ) ; assertSuggestion ( "She awaked" , "awoke" ) ; assertSuggestion ( "She becomed" , "became" ) ; assertSuggestion ( "It begined" , "began" ) ; assertSuggestion ( "It bited" , "bit" ) ; assertSuggestion ( "She dealed" , "dealt" ) ; assertSuggestion ( "She drived" , "drove" ) ; assertSuggestion ( "He drawed" , "drew" ) ; assertSuggestion ( "She finded" , "found" ) ; assertSuggestion ( "It hurted" , "hurt" ) ; assertSuggestion ( "It was keeped" , "kept" ) ; assertSuggestion ( "He maked" , "made" ) ; assertSuggestion ( "She runed" , "ran" ) ; assertSuggestion ( "She selled" , "sold" ) ; assertSuggestion ( "He speaked" , "spoke" ) ; assertSuggestion ( "auditory stimuluses" , "stimuli" ) ; assertSuggestion ( "analysises" , "analyses" ) ; assertSuggestion ( "parenthesises" , "parentheses" ) ; assertSuggestion ( "childs" , "children" ) ; assertSuggestion ( "womans" , "women" ) ; assertSuggestion ( "criterions" , "criteria" ) ; assertSuggestion ( "gooder" , "better" ) ; assertSuggestion ( "bader" , "worse" ) ; assertSuggestion ( "farer" , "further" , "farther" ) ; assertSuggestion ( "goodest" , "best" ) ; assertSuggestion ( "badest" , "worst" ) ; assertSuggestion ( "farest" , "furthest" , "farthest" ) ; } private void assertSuggestion ( String input , String ... expectedSuggestions ) throws IOException { RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( input ) ) ; assertThat ( matches . length , is ( 1 ) ) ; assertTrue ( "Expected >= " + expectedSuggestions . length + ", got: " + matches [ 0 ] . getSuggestedReplacements ( ) , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) >= expectedSuggestions . length ) ; for ( String expectedSuggestion : expectedSuggestions ) { assertTrue ( matches [ 0 ] . getSuggestedReplacements ( ) . contains ( expectedSuggestion ) ) ; } } }
package org . languagetool . rules . en ; import static org . junit . Assert . assertEquals ; import java . io . IOException ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . language . CanadianEnglish ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public class MorfologikCanadianSpellerRuleTest extends AbstractEnglishSpellerRuleTest { @ Test public void testSuggestions ( ) throws IOException { Language language = new CanadianEnglish ( ) ; Rule rule = new MorfologikCanadianSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; super . testNonVariantSpecificSuggestions ( rule , language ) ; } @ Test public void testMorfologikSpeller ( ) throws IOException { final CanadianEnglish language = new CanadianEnglish ( ) ; final MorfologikBritishSpellerRule rule = new MorfologikBritishSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; final JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "This is an example: we get behaviour as a dictionary word." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Why don't we speak today." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "He doesn't know what to do." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "arbor" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 5 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( "arbour" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "aõh" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "a" ) ) . length ) ; } }
package org . languagetool . rules . en ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . English ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . WordRepeatRule ; import java . io . IOException ; public class WordRepeatRuleTest extends TestCase { private final English english = new English ( ) ; private final WordRepeatRule rule = new WordRepeatRule ( TestTools . getEnglishMessages ( ) , english ) ; private final JLanguageTool langTool = new JLanguageTool ( english ) ; public void testRule ( ) throws IOException { assertMatches ( "This is a test sentence." , 0 ) ; assertMatches ( "This is a test sentence..." , 0 ) ; assertMatches ( "This this is a test sentence." , 1 ) ; assertMatches ( "This is a test sentence sentence." , 1 ) ; assertMatches ( "This is is a a test sentence sentence." , 3 ) ; } private void assertMatches ( String input , int expectedMatches ) throws IOException { RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( input ) ) ; assertEquals ( expectedMatches , matches . length ) ; } }
package org . languagetool . rules . en ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . English ; import org . languagetool . rules . RuleMatch ; public class ContractionSpellingRuleTest extends TestCase { private ContractionSpellingRule rule ; private JLanguageTool langTool ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; rule = new ContractionSpellingRule ( TestTools . getMessages ( "en" ) ) ; langTool = new JLanguageTool ( new English ( ) ) ; } public void testRule ( ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "It wasn't me." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "I'm ill." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Staatszerfall im südlichen Afrika." ) ) . length ) ; checkSimpleReplaceRule ( "Wasnt this great" , "Wasn't" ) ; checkSimpleReplaceRule ( "YOURE WRONG" , "YOU'RE" ) ; checkSimpleReplaceRule ( "Dont do this" , "Don't" ) ; checkSimpleReplaceRule ( "It wasnt me" , "wasn't" ) ; checkSimpleReplaceRule ( "You neednt do this" , "needn't" ) ; checkSimpleReplaceRule ( "I know Im wrong" , "I'm" ) ; final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "Whereve you are" ) ) ; assertEquals ( 2 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( "Where've" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "Wherever" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; } private void checkSimpleReplaceRule ( String sentence , String word ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( "Invalid matches.length while checking sentence: " + sentence , 1 , matches . length ) ; assertEquals ( "Invalid replacement count wile checking sentence: " + sentence , 1 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( "Invalid suggested replacement while checking sentence: " + sentence , word , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . en ; import org . junit . Test ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . AmericanEnglish ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . spelling . SpellingCheckRule ; import java . io . IOException ; import java . util . List ; import static junit . framework . TestCase . assertTrue ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertFalse ; public class SpellingCheckRuleTest { @ Test public void testIgnoreSuggestionsWithMorfologik ( ) throws IOException { final JLanguageTool langTool = new JLanguageTool ( new AmericanEnglish ( ) ) ; final List < RuleMatch > matches = langTool . check ( "This is anArtificialTestWordForLanguageTool." ) ; assertEquals ( 0 , matches . size ( ) ) ; final List < RuleMatch > matches2 = langTool . check ( "This is a real typoh." ) ; assertEquals ( 1 , matches2 . size ( ) ) ; assertEquals ( "MORFOLOGIK_RULE_EN_US" , matches2 . get ( 0 ) . getRule ( ) . getId ( ) ) ; final List < RuleMatch > matches3 = langTool . check ( "This is anotherArtificialTestWordForLanguageTol." ) ; assertEquals ( 1 , matches3 . size ( ) ) ; assertEquals ( "[anotherArtificialTestWordForLanguageTool]" , matches3 . get ( 0 ) . getSuggestedReplacements ( ) . toString ( ) ) ; } @ Test public void testIsUrl ( ) throws IOException { MySpellCheckingRule rule = new MySpellCheckingRule ( ) ; rule . test ( ) ; } static class MySpellCheckingRule extends SpellingCheckRule { MySpellCheckingRule ( ) { super ( TestTools . getEnglishMessages ( ) , new AmericanEnglish ( ) ) ; } @ Override public String getId ( ) { return null ; } @ Override public String getDescription ( ) { return null ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { return null ; } void test ( ) throws IOException { assertTrue ( isUrl ( "http://www.test.de" ) ) ; assertTrue ( isUrl ( "http://www.test-dash.com" ) ) ; assertTrue ( isUrl ( "https://www.test-dash.com" ) ) ; assertTrue ( isUrl ( "ftp://www.test-dash.com" ) ) ; assertTrue ( isUrl ( "http://www.test-dash.com/foo/path-dash" ) ) ; assertTrue ( isUrl ( "http://www.test-dash.com/foo/öäü-dash" ) ) ; assertTrue ( isUrl ( "http://www.test-dash.com/foo/%C3%B-dash" ) ) ; assertFalse ( isUrl ( "www.languagetool.org" ) ) ; } } }
package org . languagetool . rules . en ; import org . languagetool . JLanguageTool ; import org . languagetool . language . English ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class EnglishPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } public void testBug ( ) throws Exception { JLanguageTool langTool = new JLanguageTool ( new English ( ) ) ; langTool . check ( "Alexander between 369 and 358 BC\n\nAlexander" ) ; } }
package org . languagetool . rules . en ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . English ; import org . languagetool . rules . RuleMatch ; import static org . languagetool . rules . en . AvsAnRule . * ; public class AvsAnRuleTest extends TestCase { private AvsAnRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new AvsAnRule ( TestTools . getEnglishMessages ( ) ) ; langTool = new JLanguageTool ( new English ( ) ) ; } public void testRule ( ) throws IOException { assertCorrect ( "This is a test sentence." ) ; assertCorrect ( "It was an hour ago." ) ; assertCorrect ( "A university is ..." ) ; assertCorrect ( "A one-way street ..." ) ; assertCorrect ( "An hour's work ..." ) ; assertCorrect ( "Going to an \"industry party\"." ) ; assertCorrect ( "An 8-year old boy ..." ) ; assertCorrect ( "An 18-year old boy ..." ) ; assertCorrect ( "The A-levels are ..." ) ; assertCorrect ( "An NOP check ..." ) ; assertCorrect ( "A USA-wide license ..." ) ; assertCorrect ( "...asked a UN member." ) ; assertCorrect ( "In an un-united Germany..." ) ; assertCorrect ( "Here, a and b are supplementary angles." ) ; assertCorrect ( "The Qur'an was translated into Polish." ) ; assertCorrect ( "See an:Grammatica" ) ; assertCorrect ( "See http://www.an.com" ) ; assertCorrect ( "Station A equals station B." ) ; assertIncorrect ( "It was a hour ago." ) ; assertIncorrect ( "It was an sentence that's long." ) ; assertIncorrect ( "It was a uninteresting talk." ) ; assertIncorrect ( "An university" ) ; assertIncorrect ( "A unintersting ..." ) ; assertIncorrect ( "A hour's work ..." ) ; assertIncorrect ( "Going to a \"industry party\"." ) ; final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "It was a uninteresting talk with an long sentence." ) ) ; assertEquals ( 2 , matches . length ) ; assertCorrect ( "A University" ) ; assertCorrect ( "A Europe wide something" ) ; assertIncorrect ( "then an University sdoj fixme sdoopsd" ) ; assertIncorrect ( "A 8-year old boy ..." ) ; assertIncorrect ( "A 18-year old boy ..." ) ; assertIncorrect ( "...asked an UN member." ) ; assertIncorrect ( "In a un-united Germany..." ) ; assertCorrect ( "A. R.J. Turgot" ) ; assertCorrect ( "Anyone for an MSc?" ) ; assertIncorrect ( "Anyone for a MSc?" ) ; assertCorrect ( "Anyone for an XMR-based writer?" ) ; assertCorrect ( "Its name in English is a[1] (), plural A's, As, as, or a's." ) ; assertCorrect ( "An historic event" ) ; assertCorrect ( "A historic event" ) ; } private void assertCorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( 0 , matches . length ) ; } private void assertIncorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( 1 , matches . length ) ; } public void testSuggestions ( ) throws IOException { assertEquals ( "a string" , rule . suggestAorAn ( "string" ) ) ; assertEquals ( "a university" , rule . suggestAorAn ( "university" ) ) ; assertEquals ( "an hour" , rule . suggestAorAn ( "hour" ) ) ; assertEquals ( "an all-terrain" , rule . suggestAorAn ( "all-terrain" ) ) ; assertEquals ( "a UNESCO" , rule . suggestAorAn ( "UNESCO" ) ) ; assertEquals ( "a historical" , rule . suggestAorAn ( "historical" ) ) ; } public void testGetCorrectDeterminerFor ( ) throws IOException { assertEquals ( Determiner . A , getDeterminerFor ( "string" ) ) ; assertEquals ( Determiner . A , getDeterminerFor ( "university" ) ) ; assertEquals ( Determiner . A , getDeterminerFor ( "UNESCO" ) ) ; assertEquals ( Determiner . A , getDeterminerFor ( "one-way" ) ) ; assertEquals ( Determiner . AN , getDeterminerFor ( "interesting" ) ) ; assertEquals ( Determiner . AN , getDeterminerFor ( "hour" ) ) ; assertEquals ( Determiner . AN , getDeterminerFor ( "all-terrain" ) ) ; assertEquals ( Determiner . A_OR_AN , getDeterminerFor ( "historical" ) ) ; assertEquals ( Determiner . UNKNOWN , getDeterminerFor ( "" ) ) ; assertEquals ( Determiner . UNKNOWN , getDeterminerFor ( "-way" ) ) ; assertEquals ( Determiner . UNKNOWN , getDeterminerFor ( "camelCase" ) ) ; } private Determiner getDeterminerFor ( String word ) { AnalyzedTokenReadings token = new AnalyzedTokenReadings ( new AnalyzedToken ( word , "fake-postag" , "fake-lemma" ) , 0 ) ; return rule . getCorrectDeterminerFor ( token ) ; } public void testGetCorrectDeterminerForException ( ) throws IOException { try { rule . getCorrectDeterminerFor ( null ) ; fail ( ) ; } catch ( NullPointerException ignored ) { } } public void testPositions ( ) throws IOException { RuleMatch [ ] matches ; final JLanguageTool langTool = new JLanguageTool ( new English ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "a industry standard." ) ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 1 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "a \"industry standard\"." ) ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 1 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "a - industry standard\"." ) ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 1 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a \"industry standard\"." ) ) ; assertEquals ( 8 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 9 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "\"a industry standard\"." ) ) ; assertEquals ( 1 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 2 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "\"Many say this is a industry standard\"." ) ) ; assertEquals ( 18 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 19 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Like many \"an desperado\" before him, Bart headed south into Mexico." ) ) ; assertEquals ( 11 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 13 , matches [ 0 ] . getToPos ( ) ) ; } }
package org . languagetool . rules . en ; import org . junit . Test ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class DateCheckFilterTest { @ Test public void testGetDayOfWeek ( ) throws Exception { DateCheckFilter filter = new DateCheckFilter ( ) ; assertThat ( filter . getDayOfWeek ( "Sun" ) , is ( 1 ) ) ; assertThat ( filter . getDayOfWeek ( "Mon" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "mon" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Mon." ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Monday" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "monday" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Tue" ) , is ( 3 ) ) ; assertThat ( filter . getDayOfWeek ( "Fri" ) , is ( 6 ) ) ; assertThat ( filter . getDayOfWeek ( "Fr" ) , is ( 6 ) ) ; assertThat ( filter . getDayOfWeek ( "Saturday" ) , is ( 7 ) ) ; } @ Test public void testMonth ( ) throws Exception { DateCheckFilter filter = new DateCheckFilter ( ) ; assertThat ( filter . getMonth ( "jan" ) , is ( 1 ) ) ; assertThat ( filter . getMonth ( "dec" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "december" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "December" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "DECEMBER" ) , is ( 12 ) ) ; } }
package org . languagetool . rules . en ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . English ; import java . io . IOException ; public class UppercaseSentenceStartRuleTest extends TestCase { public void testNonSentences ( ) throws IOException { final JLanguageTool lt = new JLanguageTool ( new English ( ) ) ; } public void testRule ( ) throws IOException { final JLanguageTool lt = new JLanguageTool ( new English ( ) ) ; assertEquals ( 0 , lt . check ( "In Nov. next year." ) . size ( ) ) ; } }
package org . languagetool . tagging . disambiguation . rules . en ; import java . io . IOException ; import org . languagetool . TestTools ; import org . languagetool . language . English ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . disambiguation . rules . DisambiguationRuleTest ; import org . languagetool . tagging . disambiguation . xx . DemoDisambiguator ; import org . languagetool . tagging . en . EnglishTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . WordTokenizer ; public class EnglishDisambiguationRuleTest extends DisambiguationRuleTest { private EnglishTagger tagger ; private WordTokenizer tokenizer ; private SentenceTokenizer sentenceTokenizer ; private XmlRuleDisambiguator disambiguator ; private DemoDisambiguator disamb2 ; @ Override public void setUp ( ) { tagger = new EnglishTagger ( ) ; tokenizer = new WordTokenizer ( ) ; sentenceTokenizer = new SRXSentenceTokenizer ( new English ( ) ) ; disambiguator = new XmlRuleDisambiguator ( new English ( ) ) ; disamb2 = new DemoDisambiguator ( ) ; } public void testChunker ( ) throws IOException { TestTools . myAssert ( "I cannot have it." , "/[null]SENT_START I/[I]PRP /[null]null cannot/[can]MD /[null]null have/[have]VB /[null]null it/[it]PRP ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "I cannot have it." , "/[null]SENT_START I/[I]PRP /[null]null cannot/[can]MD /[null]null have/[have]NN|have/[have]VB|have/[have]VBP /[null]null it/[it]PRP ./[null]null" , tokenizer , sentenceTokenizer , tagger , disamb2 ) ; TestTools . myAssert ( "He is to blame." , "/[null]SENT_START He/[he]PRP /[null]null is/[be]VBZ /[null]null to/[to]IN|to/[to]TO /[null]null blame/[blame]VB ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "He is to blame." , "/[null]SENT_START He/[he]PRP /[null]null is/[be]VBZ /[null]null to/[to]IN|to/[to]TO /[null]null blame/[blame]JJ|blame/[blame]NN:UN|blame/[blame]VB|blame/[blame]VBP ./[null]null" , tokenizer , sentenceTokenizer , tagger , disamb2 ) ; TestTools . myAssert ( "He is well known." , "/[null]SENT_START He/[he]PRP /[null]null is/[be]VBZ /[null]null well/[well]RB /[null]null known/[known]JJ ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "He is well known." , "/[null]SENT_START He/[he]PRP /[null]null is/[be]VBZ /[null]null well/[well]NN|well/[well]RB|well/[well]UH|well/[well]VB|well/[well]VBP /[null]null known/[know]VBN|known/[known]NN ./[null]null" , tokenizer , sentenceTokenizer , tagger , disamb2 ) ; } }
package org . languagetool . rules . ca ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . WrongWordInContextRule ; public class CatalanWrongWordInContextRule extends WrongWordInContextRule { public CatalanWrongWordInContextRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; setLocQualityIssueType ( ITSIssueType . Grammar ) ; } @ Override protected String getCategoryString ( ) { return "Z) Confusions" ; } @ Override public String getId ( ) { return "CATALAN_WRONG_WORD_IN_CONTEXT" ; } @ Override public String getDescription ( ) { return "Confusió segons el context (infligir/infringir, etc.)" ; } @ Override protected String getFilename ( ) { return "/ca/wrongWordInContext.txt" ; } @ Override protected String getMessageString ( ) { return "¿Volíeu dir <suggestion>$SUGGESTION</suggestion> en lloc de '$WRONGWORD'?" ; } @ Override protected String getShortMessageString ( ) { return "Possible confusió" ; } @ Override protected String getLongMessageString ( ) { return "¿Volíeu dir <suggestion>$SUGGESTION</suggestion> (= $EXPLANATION_SUGGESTION) en lloc de '$WRONGWORD' (= $EXPLANATION_WRONGWORD)?" ; } }
package org . languagetool . tagging . en ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import junit . framework . TestCase ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . TestTools ; import org . languagetool . language . English ; import org . languagetool . tokenizers . WordTokenizer ; public class EnglishTaggerTest extends TestCase { private EnglishTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new EnglishTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new English ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "This is a big house." , "This/[this]DT|This/[this]PDT -- is/[be]VBZ -- a/[a]DT -- big/[big]JJ|big/[big]RB -- house/[house]NN|house/[house]VB|house/[house]VBP" , tokenizer , tagger ) ; TestTools . myAssert ( "Marketing do a lot of trouble." , "Marketing/[market]VBG|Marketing/[marketing]NN:U -- do/[do]VB|do/[do]VBP -- a/[a]DT -- lot/[lot]NN -- of/[of]IN -- trouble/[trouble]NN:UN|trouble/[trouble]VB|trouble/[trouble]VBP" , tokenizer , tagger ) ; TestTools . myAssert ( "Manager use his laptop every day." , "Manager/[manager]NN -- use/[use]NN:UN|use/[use]VB|use/[use]VBP -- his/[hi]NNS|his/[his]PRP$ -- laptop/[laptop]NN -- every/[every]DT -- day/[day]NN:UN" , tokenizer , tagger ) ; TestTools . myAssert ( "This is a bigger house." , "This/[this]DT|This/[this]PDT -- is/[be]VBZ -- a/[a]DT -- bigger/[big]JJR -- house/[house]NN|house/[house]VB|house/[house]VBP" , tokenizer , tagger ) ; TestTools . myAssert ( "He doesn't believe me." , "He/[he]PRP -- doesn/[do]VBZ -- t/[null]null -- believe/[believe]VB|believe/[believe]VBP -- me/[I]PRP" , tokenizer , tagger ) ; TestTools . myAssert ( "It has become difficult." , "It/[it]PRP -- has/[have]VBZ -- become/[become]VB|become/[become]VBN|become/[become]VBP -- difficult/[difficult]JJ" , tokenizer , tagger ) ; } public void testLemma ( ) throws IOException { EnglishTagger tagger = new EnglishTagger ( ) ; List < String > words = new ArrayList < > ( ) ; words . add ( "Oliver" ) ; words . add ( "works" ) ; List < AnalyzedTokenReadings > aToken = tagger . tag ( words ) ; assertEquals ( 2 , aToken . size ( ) ) ; assertEquals ( 3 , aToken . get ( 0 ) . getReadings ( ) . size ( ) ) ; assertEquals ( 2 , aToken . get ( 1 ) . getReadings ( ) . size ( ) ) ; assertEquals ( "Oliver" , aToken . get ( 0 ) . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; assertEquals ( "oliver" , aToken . get ( 0 ) . getReadings ( ) . get ( 1 ) . getLemma ( ) ) ; assertEquals ( "olive" , aToken . get ( 0 ) . getReadings ( ) . get ( 2 ) . getLemma ( ) ) ; assertEquals ( "work" , aToken . get ( 1 ) . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; assertEquals ( "work" , aToken . get ( 1 ) . getReadings ( ) . get ( 1 ) . getLemma ( ) ) ; } }
package org . languagetool . tokenizers ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . English ; public class EnglishSRXSentenceTokenizerTest extends TestCase { private final SentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new English ( ) ) ; private final SentenceTokenizer stokenizer2 = new SRXSentenceTokenizer ( new English ( ) ) ; @ Override public void setUp ( ) { stokenizer . setSingleLineBreaksMarksParagraph ( true ) ; stokenizer2 . setSingleLineBreaksMarksParagraph ( false ) ; } public void testTokenize ( ) { testSplit ( "Here's a" ) ; testSplit ( "Here's a sentence. " , "And here's one that's not comp" ) ; testSplit ( "This is a sentence. " ) ; testSplit ( "This is a sentence. " , "And this is another one." ) ; testSplit ( "This is a sentence." , "Isn't it?" , "Yes, it is." ) ; testSplit ( "This is e.g. Mr. Smith, who talks slowly..." , "But this is another sentence." ) ; testSplit ( "Chanel no. 5 is blah." ) ; testSplit ( "Mrs. Jones gave Peter $4.5, to buy Chanel No 5." , "He never came back." ) ; testSplit ( "On p. 6 there's nothing. " , "Another sentence." ) ; testSplit ( "Leave me alone!, he yelled. " , "Another sentence." ) ; testSplit ( "\"Leave me alone!\", he yelled." ) ; testSplit ( "'Leave me alone!', he yelled. " , "Another sentence." ) ; testSplit ( "'Leave me alone!,' he yelled. " , "Another sentence." ) ; testSplit ( "This works on the phrase level, i.e. not on the word level." ) ; testSplit ( "Let's meet at 5 p.m. in the main street." ) ; testSplit ( "James comes from the U.K. where he worked as a programmer." ) ; testSplit ( "Don't split strings like U.S.A. please." ) ; testSplit ( "Don't split strings like U. S. A. either." ) ; testSplit ( "Don't split... " , "Well you know. " , "Here comes more text." ) ; testSplit ( "Don't split... well you know. " , "Here comes more text." ) ; testSplit ( "The \".\" should not be a delimiter in quotes." ) ; testSplit ( "\"Here he comes!\" she said." ) ; testSplit ( "\"Here he comes!\", she said." ) ; testSplit ( "\"Here he comes.\" " , "But this is another sentence." ) ; testSplit ( "\"Here he comes!\". " , "That's what he said." ) ; testSplit ( "The sentence ends here. " , "(Another sentence.)" ) ; testSplit ( "The sentence (...) ends here." ) ; testSplit ( "The sentence [...] ends here." ) ; testSplit ( "The sentence ends here (...). " , "Another sentence." ) ; testSplit ( "He won't. " , "Really." ) ; testSplit ( "He will not. " , "Really." ) ; testSplit ( "He won't go. " , "Really." ) ; testSplit ( "He won't say no." , "Not really." ) ; testSplit ( "He won't say No." , "Not really." ) ; testSplit ( "He won't say no. 5 is better. " , "Not really." ) ; testSplit ( "He won't say No. 5 is better. " , "Not really." ) ; testSplit ( "They met at 5 p.m. on Thursday." ) ; testSplit ( "They met at 5 p.m. " , "It was Thursday." ) ; testSplit ( "This is it: a test." ) ; testSplit ( "12) Make sure that the lamp is on. " , "12) Make sure that the lamp is on. " ) ; testSplit ( "He also offers a conversion table (see Cohen, 1988, p. 123). " ) ; TestTools . testSplit ( new String [ ] { "He won't\n\n" , "Really." } , stokenizer2 ) ; TestTools . testSplit ( new String [ ] { "He won't\n" , "Really." } , stokenizer ) ; TestTools . testSplit ( new String [ ] { "He won't\n\n" , "Really." } , stokenizer2 ) ; TestTools . testSplit ( new String [ ] { "He won't\nReally." } , stokenizer2 ) ; testSplit ( "James is from the Ireland!" , "He lives in Spain now." ) ; testSplit ( "Jones Bros. have built a successful company." ) ; testSplit ( "It (really!) works." ) ; testSplit ( "It [really!] works." ) ; testSplit ( "It works (really!). " , "No doubt." ) ; testSplit ( "It works [really!]. " , "No doubt." ) ; testSplit ( "It really(!) works well." ) ; testSplit ( "It really[!] works well." ) ; testSplit ( "This is a sentence.\u0002 " , "And this is another one." ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . tokenizers . en ; import java . util . List ; import junit . framework . TestCase ; public class EnglishWordTokenizerTest extends TestCase { public void testTokenize ( ) { final EnglishWordTokenizer wordTokenizer = new EnglishWordTokenizer ( ) ; final List < String > tokens = wordTokenizer . tokenize ( "This is\u00A0a test" ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[This, , is, \u00A0, a, , test]" , tokens . toString ( ) ) ; final List < String > tokens2 = wordTokenizer . tokenize ( "This\rbreaks" ) ; assertEquals ( 3 , tokens2 . size ( ) ) ; assertEquals ( "[This, \r, breaks]" , tokens2 . toString ( ) ) ; final List < String > tokens3 = wordTokenizer . tokenize ( "Now this is-really!-a test." ) ; assertEquals ( tokens3 . size ( ) , 10 ) ; assertEquals ( "[Now, , this, , is-really, !, -a, , test, .]" , tokens3 . toString ( ) ) ; final List < String > tokens4 = wordTokenizer . tokenize ( "Now this is- really!- a test." ) ; assertEquals ( tokens4 . size ( ) , 15 ) ; assertEquals ( "[Now, , this, , is, -, , really, !, -, , a, , test, .]" , tokens4 . toString ( ) ) ; final List < String > tokens5 = wordTokenizer . tokenize ( "Now this is—really!—a test." ) ; assertEquals ( tokens5 . size ( ) , 13 ) ; assertEquals ( "[Now, , this, , is, —, really, !, —, a, , test, .]" , tokens5 . toString ( ) ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . rules . Rule ; import org . languagetool . rules . en . BritishReplaceRule ; import org . languagetool . rules . en . MorfologikBritishSpellerRule ; public class BritishEnglish extends English { @ Override public String [ ] getCountries ( ) { return new String [ ] { "GB" } ; } @ Override public String getName ( ) { return "English (GB)" ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { List < Rule > rules = new ArrayList < > ( ) ; rules . addAll ( super . getRelevantRules ( messages ) ) ; rules . add ( new BritishReplaceRule ( messages ) ) ; rules . add ( new MorfologikBritishSpellerRule ( messages , this ) ) ; return rules ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . rules . Rule ; import org . languagetool . rules . en . MorfologikCanadianSpellerRule ; public class CanadianEnglish extends English { @ Override public String [ ] getCountries ( ) { return new String [ ] { "CA" } ; } @ Override public String getName ( ) { return "English (Canadian)" ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { List < Rule > rules = new ArrayList < > ( ) ; rules . addAll ( super . getRelevantRules ( messages ) ) ; rules . add ( new MorfologikCanadianSpellerRule ( messages , this ) ) ; return rules ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . rules . Rule ; import org . languagetool . rules . en . MorfologikSouthAfricanSpellerRule ; public class SouthAfricanEnglish extends English { @ Override public String [ ] getCountries ( ) { return new String [ ] { "ZA" } ; } @ Override public String getName ( ) { return "English (South African)" ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { List < Rule > rules = new ArrayList < > ( ) ; rules . addAll ( super . getRelevantRules ( messages ) ) ; rules . add ( new MorfologikSouthAfricanSpellerRule ( messages , this ) ) ; return rules ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . rules . Rule ; import org . languagetool . rules . en . MorfologikNewZealandSpellerRule ; import org . languagetool . rules . en . NewZealandReplaceRule ; public class NewZealandEnglish extends English { @ Override public String [ ] getCountries ( ) { return new String [ ] { "NZ" } ; } @ Override public String getName ( ) { return "English (New Zealand)" ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { List < Rule > rules = new ArrayList < > ( ) ; rules . addAll ( super . getRelevantRules ( messages ) ) ; rules . add ( new MorfologikNewZealandSpellerRule ( messages , this ) ) ; rules . add ( new NewZealandReplaceRule ( messages ) ) ; return rules ; } }
package org . languagetool . language ; import java . io . File ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . chunking . Chunker ; import org . languagetool . chunking . EnglishChunker ; import org . languagetool . languagemodel . LanguageModel ; import org . languagetool . languagemodel . LuceneLanguageModel ; import org . languagetool . rules . * ; import org . languagetool . rules . en . * ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . en . EnglishSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . en . EnglishTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . WordTokenizer ; import org . languagetool . tokenizers . en . EnglishWordTokenizer ; public class English extends Language implements AutoCloseable { private static final Language AMERICAN_ENGLISH = new AmericanEnglish ( ) ; private Tagger tagger ; private Chunker chunker ; private SentenceTokenizer sentenceTokenizer ; private Synthesizer synthesizer ; private Disambiguator disambiguator ; private WordTokenizer wordTokenizer ; private LuceneLanguageModel languageModel ; @ Override public Language getDefaultLanguageVariant ( ) { return AMERICAN_ENGLISH ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public String getName ( ) { return "English" ; } @ Override public String getShortName ( ) { return "en" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new EnglishTagger ( ) ; } return tagger ; } @ Override public Chunker getChunker ( ) { if ( chunker == null ) { chunker = new EnglishChunker ( ) ; } return chunker ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new EnglishSynthesizer ( ) ; } return synthesizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new XmlRuleDisambiguator ( new English ( ) ) ; } return disambiguator ; } @ Override public WordTokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new EnglishWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public synchronized LanguageModel getLanguageModel ( File indexDir ) throws IOException { if ( languageModel == null ) { languageModel = new LuceneLanguageModel ( indexDir ) ; } return languageModel ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { Contributors . MARCIN_MILKOWSKI , Contributors . DANIEL_NABER } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new LongSentenceRule ( messages ) , new SentenceWhitespaceRule ( messages ) , new EnglishUnpairedBracketsRule ( messages , this ) , new EnglishWordRepeatRule ( messages , this ) , new AvsAnRule ( messages ) , new EnglishWordRepeatBeginningRule ( messages , this ) , new CompoundRule ( messages ) , new ContractionSpellingRule ( messages ) ) ; } @ Override public List < Rule > getRelevantLanguageModelRules ( ResourceBundle messages , LanguageModel languageModel ) throws IOException { return Arrays . < Rule > asList ( new EnglishConfusionProbabilityRule ( messages , languageModel , this ) ) ; } @ Override public void close ( ) throws Exception { if ( languageModel != null ) { languageModel . close ( ) ; } } }
package org . languagetool . language ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . rules . Rule ; import org . languagetool . rules . en . MorfologikAustralianSpellerRule ; public class AustralianEnglish extends English { @ Override public String [ ] getCountries ( ) { return new String [ ] { "AU" } ; } @ Override public String getName ( ) { return "English (Australian)" ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { List < Rule > rules = new ArrayList < > ( ) ; rules . addAll ( super . getRelevantRules ( messages ) ) ; rules . add ( new MorfologikAustralianSpellerRule ( messages , this ) ) ; return rules ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . rules . Rule ; import org . languagetool . rules . en . MorfologikAmericanSpellerRule ; public class AmericanEnglish extends English { @ Override public String [ ] getCountries ( ) { return new String [ ] { "US" } ; } @ Override public String getName ( ) { return "English (US)" ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { List < Rule > rules = new ArrayList < > ( ) ; rules . addAll ( super . getRelevantRules ( messages ) ) ; rules . add ( new MorfologikAmericanSpellerRule ( messages , this ) ) ; return rules ; } }
package org . languagetool . rules . ca ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . WordRepeatRule ; public class CatalanWordRepeatRule extends WordRepeatRule { public CatalanWordRepeatRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; } @ Override public String getId ( ) { return "CATALAN_WORD_REPEAT_RULE" ; } @ Override public boolean ignore ( AnalyzedTokenReadings [ ] tokens , int position ) { if ( position > 0 && ( tokens [ position ] . hasPosTag ( "_allow_repeat" ) || tokens [ position - 1 ] . hasPosTag ( "_allow_repeat" ) ) ) { return true ; } return false ; } }
package org . languagetool . chunking ; import org . languagetool . AnalyzedToken ; import java . util . ArrayList ; import java . util . List ; class EnglishChunkFilter { private static final ChunkTag BEGIN_NOUN_PHRASE_TAG = new ChunkTag ( "B-NP" ) ; private static final ChunkTag IN_NOUN_PHRASE_TAG = new ChunkTag ( "I-NP" ) ; enum ChunkType { SINGULAR , PLURAL } List < ChunkTaggedToken > filter ( List < ChunkTaggedToken > tokens ) { List < ChunkTaggedToken > result = new ArrayList < > ( ) ; String newChunkTag = null ; int i = 0 ; for ( ChunkTaggedToken taggedToken : tokens ) { List < ChunkTag > chunkTags = new ArrayList < > ( ) ; if ( isBeginningOfNounPhrase ( taggedToken ) ) { ChunkType chunkType = getChunkType ( tokens , i ) ; if ( chunkType == ChunkType . SINGULAR ) { chunkTags . add ( new ChunkTag ( "B-NP-singular" ) ) ; newChunkTag = "NP-singular" ; } else if ( chunkType == ChunkType . PLURAL ) { chunkTags . add ( new ChunkTag ( "B-NP-plural" ) ) ; newChunkTag = "NP-plural" ; } else { throw new IllegalStateException ( "Unknown chunk type: " + chunkType ) ; } } if ( newChunkTag != null && isEndOfNounPhrase ( tokens , i ) ) { chunkTags . add ( new ChunkTag ( "E-" + newChunkTag ) ) ; newChunkTag = null ; } if ( newChunkTag != null && isContinuationOfNounPhrase ( taggedToken ) ) { chunkTags . add ( new ChunkTag ( "I-" + newChunkTag ) ) ; } if ( chunkTags . size ( ) > 0 ) { result . add ( new ChunkTaggedToken ( taggedToken . getToken ( ) , chunkTags , taggedToken . getReadings ( ) ) ) ; } else { result . add ( taggedToken ) ; } i ++ ; } return result ; } private boolean isBeginningOfNounPhrase ( ChunkTaggedToken taggedToken ) { return taggedToken . getChunkTags ( ) . contains ( BEGIN_NOUN_PHRASE_TAG ) ; } private boolean isEndOfNounPhrase ( List < ChunkTaggedToken > tokens , int i ) { if ( i > tokens . size ( ) - 2 ) { return true ; } if ( ! isContinuationOfNounPhrase ( tokens . get ( i + 1 ) ) ) { return true ; } return false ; } private boolean isContinuationOfNounPhrase ( ChunkTaggedToken taggedToken ) { return taggedToken . getChunkTags ( ) . contains ( IN_NOUN_PHRASE_TAG ) ; } private ChunkType getChunkType ( List < ChunkTaggedToken > tokens , int chunkStartPos ) { boolean isPlural = false ; for ( int i = chunkStartPos ; i < tokens . size ( ) ; i ++ ) { ChunkTaggedToken token = tokens . get ( i ) ; if ( false && "and" . equals ( token . getToken ( ) ) ) { isPlural = true ; } else if ( hasNounWithPluralReading ( token ) ) { isPlural = true ; } if ( ! isBeginningOfNounPhrase ( token ) && ! isContinuationOfNounPhrase ( token ) ) { break ; } } return isPlural ? ChunkType . PLURAL : ChunkType . SINGULAR ; } private boolean hasNounWithPluralReading ( ChunkTaggedToken token ) { if ( token . getReadings ( ) != null ) { for ( AnalyzedToken analyzedToken : token . getReadings ( ) . getReadings ( ) ) { if ( "NNS" . equals ( analyzedToken . getPOSTag ( ) ) ) { return true ; } } } return false ; } }
package org . languagetool . chunking ; import org . apache . commons . lang . StringUtils ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedTokenReadings ; import java . util . List ; import java . util . Objects ; class ChunkTaggedToken { private final String token ; private final List < ChunkTag > chunkTags ; private final AnalyzedTokenReadings readings ; ChunkTaggedToken ( String token , List < ChunkTag > chunkTags , AnalyzedTokenReadings readings ) { this . token = Objects . requireNonNull ( token ) ; this . chunkTags = Objects . requireNonNull ( chunkTags ) ; this . readings = readings ; } String getToken ( ) { return token ; } List < ChunkTag > getChunkTags ( ) { return chunkTags ; } @ Nullable AnalyzedTokenReadings getReadings ( ) { return readings ; } @ Override public String toString ( ) { return token + '/' + StringUtils . join ( chunkTags , "," ) ; } }
package org . languagetool . chunking ; import opennlp . tools . chunker . ChunkerME ; import opennlp . tools . chunker . ChunkerModel ; import opennlp . tools . postag . POSModel ; import opennlp . tools . postag . POSTaggerME ; import opennlp . tools . tokenize . TokenizerME ; import opennlp . tools . tokenize . TokenizerModel ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tools . Tools ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; public class EnglishChunker implements Chunker { private static final String TOKENIZER_MODEL = "/en-token.bin" ; private static final String POS_TAGGER_MODEL = "/en-pos-maxent.bin" ; private static final String CHUNKER_MODEL = "/en-chunker.bin" ; private static TokenizerModel tokenModel ; private static POSModel posModel ; private static ChunkerModel chunkerModel ; private final EnglishChunkFilter chunkFilter ; public EnglishChunker ( ) { try { if ( tokenModel == null ) { tokenModel = new TokenizerModel ( Tools . getStream ( TOKENIZER_MODEL ) ) ; } if ( posModel == null ) { posModel = new POSModel ( Tools . getStream ( POS_TAGGER_MODEL ) ) ; } if ( chunkerModel == null ) { chunkerModel = new ChunkerModel ( Tools . getStream ( CHUNKER_MODEL ) ) ; } chunkFilter = new EnglishChunkFilter ( ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not initialize English chunker" , e ) ; } } @ Override public void addChunkTags ( List < AnalyzedTokenReadings > tokenReadings ) { List < ChunkTaggedToken > origChunkTags = getChunkTagsForReadings ( tokenReadings ) ; List < ChunkTaggedToken > chunkTags = chunkFilter . filter ( origChunkTags ) ; assignChunksToReadings ( chunkTags ) ; } private List < ChunkTaggedToken > getChunkTagsForReadings ( List < AnalyzedTokenReadings > tokenReadings ) { String sentence = getSentence ( tokenReadings ) ; String [ ] tokens = tokenize ( sentence ) ; String [ ] posTags = posTag ( tokens ) ; String [ ] chunkTags = chunk ( tokens , posTags ) ; if ( tokens . length != posTags . length || tokens . length != chunkTags . length ) { throw new RuntimeException ( "Length of results must be the same: " + tokens . length + ", " + posTags . length + ", " + chunkTags . length ) ; } return getTokensWithTokenReadings ( tokenReadings , tokens , chunkTags ) ; } String [ ] tokenize ( String sentence ) { TokenizerME tokenizer = new TokenizerME ( tokenModel ) ; String cleanString = sentence . replace ( '’' , '\'' ) ; return tokenizer . tokenize ( cleanString ) ; } private String [ ] posTag ( String [ ] tokens ) { POSTaggerME posTagger = new POSTaggerME ( posModel ) ; return posTagger . tag ( tokens ) ; } private String [ ] chunk ( String [ ] tokens , String [ ] posTags ) { ChunkerME chunker = new ChunkerME ( chunkerModel ) ; return chunker . chunk ( tokens , posTags ) ; } private List < ChunkTaggedToken > getTokensWithTokenReadings ( List < AnalyzedTokenReadings > tokenReadings , String [ ] tokens , String [ ] chunkTags ) { List < ChunkTaggedToken > result = new ArrayList < > ( ) ; int i = 0 ; int pos = 0 ; for ( String chunkTag : chunkTags ) { int startPos = pos ; int endPos = startPos + tokens [ i ] . length ( ) ; AnalyzedTokenReadings readings = getAnalyzedTokenReadingsFor ( startPos , endPos , tokenReadings ) ; result . add ( new ChunkTaggedToken ( tokens [ i ] , Collections . singletonList ( new ChunkTag ( chunkTag ) ) , readings ) ) ; pos = endPos ; i ++ ; } return result ; } private void assignChunksToReadings ( List < ChunkTaggedToken > chunkTaggedTokens ) { for ( ChunkTaggedToken taggedToken : chunkTaggedTokens ) { AnalyzedTokenReadings readings = taggedToken . getReadings ( ) ; if ( readings != null ) { readings . setChunkTags ( taggedToken . getChunkTags ( ) ) ; } } } private String getSentence ( List < AnalyzedTokenReadings > sentenceTokens ) { StringBuilder sb = new StringBuilder ( ) ; for ( AnalyzedTokenReadings token : sentenceTokens ) { sb . append ( token . getToken ( ) ) ; } return sb . toString ( ) ; } @ Nullable private AnalyzedTokenReadings getAnalyzedTokenReadingsFor ( int startPos , int endPos , List < AnalyzedTokenReadings > tokenReadings ) { int pos = 0 ; for ( AnalyzedTokenReadings tokenReading : tokenReadings ) { String token = tokenReading . getToken ( ) ; if ( token . trim ( ) . isEmpty ( ) ) { continue ; } int tokenStart = pos ; int tokenEnd = pos + token . length ( ) ; if ( tokenStart == startPos && tokenEnd == endPos ) { return tokenReading ; } pos = tokenEnd ; } return null ; } }
package org . languagetool . synthesis . en ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import morfologik . stemming . IStemmer ; import morfologik . stemming . WordData ; import org . languagetool . AnalyzedToken ; import org . languagetool . JLanguageTool ; import org . languagetool . Languages ; import org . languagetool . rules . en . AvsAnRule ; import org . languagetool . synthesis . BaseSynthesizer ; public class EnglishSynthesizer extends BaseSynthesizer { private static final String RESOURCE_FILENAME = "/en/english_synth.dict" ; private static final String TAGS_FILE_NAME = "/en/english_tags.txt" ; private static final String ADD_DETERMINER = "+DT" ; private static final String ADD_IND_DETERMINER = "+INDT" ; private final AvsAnRule aVsAnRule = new AvsAnRule ( JLanguageTool . getMessageBundle ( Languages . getLanguageForShortName ( "en" ) ) ) ; public EnglishSynthesizer ( ) { super ( RESOURCE_FILENAME , TAGS_FILE_NAME ) ; } @ Override public String [ ] synthesize ( final AnalyzedToken token , final String posTag ) throws IOException { String aOrAn = aVsAnRule . suggestAorAn ( token . getToken ( ) ) ; if ( ADD_DETERMINER . equals ( posTag ) ) { return new String [ ] { aOrAn , "the " + token . getToken ( ) } ; } else if ( ADD_IND_DETERMINER . equals ( posTag ) ) { return new String [ ] { aOrAn } ; } final IStemmer synthesizer = createStemmer ( ) ; final List < WordData > wordData = synthesizer . lookup ( token . getLemma ( ) + "|" + posTag ) ; final List < String > wordForms = new ArrayList < > ( ) ; for ( WordData wd : wordData ) { wordForms . add ( wd . getStem ( ) . toString ( ) ) ; } return wordForms . toArray ( new String [ wordForms . size ( ) ] ) ; } @ Override public String [ ] synthesize ( final AnalyzedToken token , final String posTag , final boolean posTagRegExp ) throws IOException { if ( posTag != null && posTagRegExp ) { String myPosTag = posTag ; String det = "" ; if ( posTag . endsWith ( ADD_IND_DETERMINER ) ) { myPosTag = myPosTag . substring ( 0 , myPosTag . indexOf ( ADD_IND_DETERMINER ) - "\\" . length ( ) ) ; det = aVsAnRule . suggestAorAn ( token . getLemma ( ) ) ; det = det . substring ( 0 , det . indexOf ( ' ' ) + " " . length ( ) ) ; } else if ( posTag . endsWith ( ADD_DETERMINER ) ) { myPosTag = myPosTag . substring ( 0 , myPosTag . indexOf ( ADD_DETERMINER ) - "\\" . length ( ) ) ; det = "the " ; } initPossibleTags ( ) ; final Pattern p = Pattern . compile ( myPosTag ) ; final List < String > results = new ArrayList < > ( ) ; for ( final String tag : possibleTags ) { final Matcher m = p . matcher ( tag ) ; if ( m . matches ( ) ) { lookup ( token . getLemma ( ) , tag , results , det ) ; } } return results . toArray ( new String [ results . size ( ) ] ) ; } return synthesize ( token , posTag ) ; } private void lookup ( String lemma , String posTag , List < String > results , String determiner ) { synchronized ( this ) { final List < WordData > wordForms = getStemmer ( ) . lookup ( lemma + "|" + posTag ) ; for ( WordData wd : wordForms ) { results . add ( determiner + wd . getStem ( ) ) ; } } } }
package org . languagetool . rules . en ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; import org . languagetool . rules . Example ; public class CompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/en/compounds.txt" ) ; public CompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "This word is normally spelled with hyphen." , "This word is normally spelled as one." , "This expression is normally spelled as one or with hyphen." , "Hyphenation problem" ) ; addExamplePair ( Example . wrong ( "I now have a <marker>part time</marker> job." ) , Example . fixed ( "I now have a <marker>part-time</marker> job." ) ) ; } @ Override public String getId ( ) { return "EN_COMPOUNDS" ; } @ Override public String getDescription ( ) { return "Hyphenated words, e.g., 'case-sensitive' instead of 'case sensitive'" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . rules . en ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . Example ; import org . languagetool . rules . GenericUnpairedBracketsRule ; public class EnglishUnpairedBracketsRule extends GenericUnpairedBracketsRule { private static final List < String > EN_START_SYMBOLS = Arrays . asList ( "[" , "(" , "{" , "“" , "\"" , "'" ) ; private static final List < String > EN_END_SYMBOLS = Arrays . asList ( "]" , ")" , "}" , "”" , "\"" , "'" ) ; private static final Pattern NUMBER = Pattern . compile ( "\\d+(?:-\\d+)?" ) ; private static final Pattern YEAR_NUMBER = Pattern . compile ( "\\d\\ds?" ) ; private static final Pattern ALPHA = Pattern . compile ( "\\p{L}+" ) ; public EnglishUnpairedBracketsRule ( final ResourceBundle messages , final Language language ) { super ( messages , EN_START_SYMBOLS , EN_END_SYMBOLS ) ; addExamplePair ( Example . wrong ( "<marker>\"</marker>I'm over here, she said." ) , Example . fixed ( "\"I'm over here,<marker>\"</marker> she said." ) ) ; } @ Override public String getId ( ) { return "EN_UNPAIRED_BRACKETS" ; } @ Override protected boolean isNoException ( final String tokenStr , final AnalyzedTokenReadings [ ] tokens , final int i , final int j , final boolean precSpace , final boolean follSpace ) { if ( i <= 1 ) { return true ; } if ( i > 2 ) { if ( "'" . equals ( tokens [ i ] . getToken ( ) ) ) { if ( "-" . equals ( tokens [ i - 1 ] . getToken ( ) ) && ! tokens [ i - 1 ] . isWhitespaceBefore ( ) && ALPHA . matcher ( tokens [ i - 2 ] . getToken ( ) ) . matches ( ) ) { return false ; } } } final boolean superException = ! super . isNoException ( tokenStr , tokens , i , j , precSpace , follSpace ) ; if ( superException ) { return false ; } if ( ! precSpace && follSpace || tokens [ i ] . isSentenceEnd ( ) ) { final AnalyzedTokenReadings prevToken = tokens [ i - 1 ] ; if ( "\"" . equals ( tokenStr ) ) { if ( ! symbolStack . empty ( ) && "\"" . equals ( symbolStack . peek ( ) . getSymbol ( ) ) ) { return true ; } else if ( NUMBER . matcher ( prevToken . getToken ( ) ) . matches ( ) ) { return false ; } } if ( ( "'" . equals ( tokenStr ) || "’" . equals ( tokenStr ) ) && tokens [ i ] . hasPosTag ( "POS" ) ) { return false ; } if ( "'" . equals ( tokenStr ) && prevToken . hasPosTag ( "VBG" ) && prevToken . getToken ( ) . endsWith ( "in" ) ) { return false ; } } if ( precSpace && ! follSpace ) { if ( "'" . equals ( tokenStr ) && i + 1 < tokens . length ) { if ( "em" . equals ( tokens [ i + 1 ] . getToken ( ) ) ) { return false ; } else if ( YEAR_NUMBER . matcher ( tokens [ i + 1 ] . getToken ( ) ) . matches ( ) ) { return false ; } } } return true ; } }
package org . languagetool . rules . en ; import org . languagetool . rules . Rule ; public abstract class EnglishRule extends Rule { }
package org . languagetool . rules . en ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; import org . languagetool . rules . * ; public class ContractionSpellingRule extends AbstractSimpleReplaceRule { public static final String CONTRACTION_SPELLING_RULE = "EN_CONTRACTION_SPELLING" ; private static final Map < String , List < String > > wrongWords = load ( "/en/contractions.txt" ) ; private static final Locale EN_LOCALE = new Locale ( "en" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public ContractionSpellingRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; super . setCategory ( new Category ( "Possible Typo" ) ) ; setLocQualityIssueType ( ITSIssueType . Misspelling ) ; addExamplePair ( Example . wrong ( "We <marker>havent</marker> earned anything." ) , Example . fixed ( "We <marker>haven't</marker> earned anything." ) ) ; } @ Override public final String getId ( ) { return CONTRACTION_SPELLING_RULE ; } @ Override public String getDescription ( ) { return "Spelling of English contractions" ; } @ Override public String getShort ( ) { return "Spelling mistake" ; } @ Override public boolean isDictionaryBasedSpellingRule ( ) { return false ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return "Possible spelling mistake found" ; } @ Override public boolean isCaseSensitive ( ) { return true ; } @ Override public Locale getLocale ( ) { return EN_LOCALE ; } }
package org . languagetool . rules . en ; import java . util . HashSet ; import java . util . ResourceBundle ; import java . util . Set ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . Example ; import org . languagetool . rules . WordRepeatBeginningRule ; public class EnglishWordRepeatBeginningRule extends WordRepeatBeginningRule { public EnglishWordRepeatBeginningRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; addExamplePair ( Example . wrong ( "Moreover, the street is almost entirely residential. <marker>Moreover</marker>, it was named after a poet." ) , Example . fixed ( "Moreover, the street is almost entirely residential. <marker>It</marker> was named after a poet." ) ) ; } @ Override public String getId ( ) { return "ENGLISH_WORD_REPEAT_BEGINNING_RULE" ; } private static final Set < String > ADVERBS = new HashSet < > ( ) ; static { ADVERBS . add ( "Additionally" ) ; ADVERBS . add ( "Besides" ) ; ADVERBS . add ( "Furthermore" ) ; ADVERBS . add ( "Moreover" ) ; } @ Override protected boolean isAdverb ( final AnalyzedTokenReadings token ) { return ADVERBS . contains ( token . getToken ( ) ) ; } }
package org . languagetool . rules . en ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; public final class MorfologikAustralianSpellerRule extends AbstractEnglishSpellerRule { private static final String RESOURCE_FILENAME = "/en/hunspell/en_AU.dict" ; public MorfologikAustralianSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_EN_AU" ; } }
package org . languagetool . rules . ca ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tools . StringTools ; public class ReflexiveVerbsRule extends CatalanRule { private static final List < String > verbsPronominals = Arrays . asList ( "arranxar" , "empitimar" , "enfillar" , "enseriar" , "enseriosir" , "esgroguissar" , "esmaperdre" , "ufanar" , "apoltronar" , "marfondir" , "rojar" , "personar" , "encaramallar" , "desomplir" , "delir" , "fugar" , "abacallanar" , "abalançar" , "ablenar" , "aborrallonar" , "abotifarrar" , "abrinar" , "abromar" , "abstenir" , "acagallonar" , "acanyar" , "acarcanyar" , "acarnissar" , "acatarrar" , "aciutadanar" , "aclocar" , "acopar" , "acorriolar" , "adir" , "adonar" , "adormissar" , "afal·lerar" , "afarrossar" , "afeccionar" , "aferrallar" , "aferrissar" , "aferrussar" , "agallinar" , "agarbir" , "agarrofar" , "agemolir" , "agenollar" , "agotzonar" , "aiguabarrejar" , "allocar" , "alçurar" , "amatinar" , "amelar" , "amigar" , "amoixir" , "amoltonar" , "amotar" , "amullerar" , "amunionar" , "antullar" , "aparroquianar" , "aparroquiar" , "aperduar" , "apergaminar" , "apiadar" , "aponentar" , "apropinquar" , "apugonar" , "arguellar" , "arrapinyar" , "arrasir" , "arravatar" , "arraïmar" , "arrepapar" , "arrepenjar" , "arrepetellar" , "arrigolar" , "arrodir" , "arrogar" , "arrossar" , "arruar" , "assemblar" , "assocarrar" , "atendar" , "atenir" , "atorrentar" , "atrafegar" , "atrevir" , "avencar" , "avidolar" , "avinençar" , "balbar" , "balcar" , "balir" , "balmar" , "bescomptar" , "boirar" , "boixar" , "botinflar" , "bromar" , "cagaferrar" , "candir" , "capbaixar" , "capmassar" , "captenir" , "cariar" , "carnificar" , "carpir" , "coalitzar" , "colltrencar" , "collvinclar" , "compenetrar" , "condoldre" , "condolir" , "congraciar" , "contorçar" , "contrapuntar" , "contòrcer" , "corcorcar" , "coresforçar" , "cornuar" , "corruixar" , "crisalidar" , "desafeccionar" , "desalenar" , "desamorar" , "desaparroquiar" , "desapassionar" , "desaplegar" , "desavenir" , "desbocar" , "descantar" , "descarar" , "descontrolar" , "descovar" , "desdubtar" , "desempallegar" , "desenrojolar" , "desentossudir" , "desfeinar" , "desmemoriar" , "desnodrir" , "despondre" , "despreocupar" , "dessolidaritzar" , "desteixinar" , "desvagar" , "desvergonyir" , "desviure" , "dignar" , "embarbussar" , "embascar" , "embessonar" , "embordeir" , "embordir" , "emborrascar" , "emborrossar" , "embotifarrar" , "embotzegar" , "embromallar" , "embromar" , "embroquerar" , "emmainadar" , "emmalurar" , "emmalurir" , "emmarar" , "emmarranar" , "emmatar" , "emmigranyar" , "emmorronar" , "emmurriar" , "empassar" , "empassolar" , "empegueir" , "empenyalar" , "empescar" , "empillocar" , "empinyar" , "empiocar" , "empitarrar" , "emplomissar" , "emplujar" , "emportar" , "encabotar" , "encabritar" , "encalmar" , "encalostrar" , "encelar" , "encinglar" , "encirar" , "encistar" , "enclaperar" , "encolerir" , "encordar" , "encruar" , "endoblir" , "endur" , "enfarfollar" , "enfaristolar" , "enfavar" , "enfereir" , "enferotgir" , "enferritjar" , "enfugir" , "enfurrunyar" , "enfutimar" , "enfutismar" , "engelabrir" , "engolfar" , "engorgar" , "engripar" , "enguerxinar" , "enllagrimar" , "enlleganyar" , "enlleir" , "ennavegar" , "enneguitar" , "enquistar" , "enrinxar" , "enseriosir" , "ensobecar" , "entonyinar" , "entossudir" , "entotsolar" , "entreabaltir" , "entrebadar" , "entrebatre" , "entrebesar" , "entrecavalcar" , "entredevorar" , "entreferir" , "entreforcar" , "entrematar" , "entremetre" , "entremirar" , "entrenyorar" , "entresaludar" , "entreseguir" , "entresoldar" , "entretocar" , "entretzenar" , "entrigar" , "envidreir" , "envidriar" , "envolar" , "enxautar" , "esbafar" , "esbafegar" , "esbatussar" , "esblamar" , "esbojarrar" , "esborneiar" , "esbromar" , "escabridar" , "escamotar" , "escanyellar" , "escanyolir" , "escanyussar" , "escapolar" , "escapolir" , "escarcanyar" , "escarramicar" , "escarrassar" , "escarxofar" , "escatifenyar" , "esconillar" , "escorporar" , "escullar" , "escunçar" , "esfarinar" , "esfetgegar" , "esforçar" , "esgargamellar" , "esgatinyar" , "esgolar" , "esguimbar" , "esllanguir" , "esllavissar" , "esperitar" , "espitellar" , "espitxar" , "espollinar" , "espoltrar" , "esporcellar" , "espotonar" , "esprimatxar" , "esquifir" , "esquitllar" , "estilar" , "estritllar" , "esvedellar" , "esventegar" , "esvomegar" , "etiolar" , "extralimitar" , "extravasar" , "extravenar" , "gamar" , "gaspar" , "gatinyar" , "gaubar" , "gloriar" , "grifar" , "immiscir" , "indigestar" , "industriar" , "innivar" , "insolentar" , "insurgir" , "inveterar" , "irèixer" , "jactar" , "juramentar" , "lateritzar" , "llufar" , "malfiar" , "malfixar" , "migrolar" , "mofar" , "mullerar" , "neulir" , "obstinar" , "octubrar" , "olivar" , "pellobrir" , "pellpartir" , "pelltrencar" , "penedir" , "penjolar" , "pollar" , "prosternar" , "queixar" , "querar" , "querellar" , "quillar" , "ramificar" , "rancurar" , "realegrar" , "rebel·lar" , "rebordeir" , "refiar" , "repanxolar" , "repapar" , "repetellar" , "reressagar" , "resclosir" , "ressagar" , "ressentir" , "revenjar" , "salinar" , "suïcidar" , "tinyar" , "tolir" , "transvestir" , "traspostar" , "vanagloriar" , "vanagloriejar" , "vanar" , "vantar" , "vergonyar" , "xautar" ) ; private static final Pattern VERB_AUTO = Pattern . compile ( "auto.+" ) ; private static final List < String > excepVerbsPronominals = Arrays . asList ( "amoixar" , "delirar" , "atendre" , "escollir" , "assolir" , "autografiar" , "automatitzar" , "autoritzar" ) ; private static final List < String > verbsNoPronominals = Arrays . asList ( "baixar" , "caure" , "callar" , "marxar" , "albergar" , "olorar" , "seure" , "saltar" , "créixer" ) ; private static final List < String > verbsNoPronominalsImpersonals = Arrays . asList ( "caure" , "callar" , "marxar" , "olorar" , "créixer" ) ; private static final List < String > verbsNoPronominalsImpersonals2 = Arrays . asList ( "témer" , "albergar" , "baixar" ) ; private static final List < String > excepVerbsNoPronominals = Arrays . asList ( "segar" ) ; private static final List < String > verbsMoviment = Arrays . asList ( "anar" , "pujar" , "venir" ) ; private static final List < String > excepVerbsMoviment = Arrays . asList ( "vendre" ) ; private static final List < String > verbsSovintAmbComplement = Arrays . asList ( "deixar" , "fer" , "veure" , "costar" ) ; private static final List < String > verbsDeixarFer = Arrays . asList ( "deixar" , "fer" ) ; private static final List < String > verbsPortarDur = Arrays . asList ( "portar" , "dur" ) ; private static final List < String > verbsPotencialmentPronominals = Arrays . asList ( "abaixar" , "abandonar" , "abarrocar" , "abellir" , "abismar" , "abissar" , "ablamar" , "ablanir" , "abocar" , "aboldronar" , "abonançar" , "abonar" , "abonir" , "abonyegar" , "abordar" , "abraonar" , "abraçar" , "abrivar" , "abroquerar" , "abrusar" , "absentar" , "abstraure" , "abstreure" , "aburgesar" , "acabar" , "acalar" , "acalorar" , "acantonar" , "acarrerar" , "acastellanar" , "acatalanar" , "accelerar" , "acetificar" , "acidificar" , "aclarir" , "aclimatar" , "aclivellar" , "aclucar" , "acoblar" , "acollir" , "acollonir" , "acomiadar" , "acomodar" , "acomplexar" , "acomplir" , "aconductar" , "aconsellar" , "acontentar" , "acopar" , "acoquinar" , "acordar" , "acorruar" , "acostar" , "acostumar" , "acotar" , "acotxar" , "acovardir" , "acreditar" , "acréixer" , "acubar" , "acubillar" , "acudir" , "acugular" , "acuitar" , "acular" , "acumular" , "acusar" , "adaptar" , "adargar" , "adherir" , "adjudicar" , "adollar" , "adolorir" , "adondar" , "adormir" , "adossar" , "adotzenar" , "adreçar" , "adscriure" , "adunar" , "afalconar" , "afanyar" , "afartar" , "afeblir" , "afectar" , "afermar" , "aferrar" , "afigurar" , "afilar" , "afilerar" , "afiliar" , "afillar" , "afinar" , "aflaquir" , "afligir" , "aflonjar" , "afluixar" , "afogar" , "afollar" , "afrancesar" , "afrevolir" , "afuar" , "afusar" , "agabellar" , "agafar" , "agarbar" , "agarbonar" , "agitar" , "aglomerar" , "aglutinar" , "agombolar" , "agostejar" , "agradar" , "agregar" , "agremiar" , "agreujar" , "agrir" , "agrisar" , "agrumar" , "aguantar" , "aguditzar" , "aigualir" , "airejar" , "aixecar" , "aixoplugar" , "ajaure" , "ajaçar" , "ajeure" , "ajornalar" , "ajudar" , "ajuntar" , "ajupir" , "ajustar" , "alabar" , "alarmar" , "alcalinitzar" , "alcoholitzar" , "alegrar" , "alentir" , "aliar" , "alimentar" , "alinear" , "allarar" , "allargar" , "allargassar" , "allerar" , "alleugerir" , "alleujar" , "alliberar" , "alligar" , "allistar" , "allitar" , "allotjar" , "allunyar" , "alterar" , "alzinar" , "alçar" , "amagar" , "amagrir" , "amanerar" , "amanir" , "amansar" , "amansir" , "amassar" , "ambientar" , "americanitzar" , "amistançar" , "amistar" , "amollar" , "amorar" , "amorosir" , "amorrar" , "amorriar" , "amotinar" , "amoïnar" , "amuntegar" , "anastomitzar" , "angoixar" , "anguniejar" , "animar" , "anomenar" , "anticipar" , "apagar" , "apaivagar" , "apanyar" , "aparellar" , "apariar" , "apartar" , "aparèixer" , "apassionar" , "apercebre" , "apilotar" , "apinyar" , "apitrar" , "aplanar" , "aplaçar" , "aplicar" , "apocar" , "apoderar" , "aposentar" , "apostar" , "apostemar" , "apregonar" , "aprendre" , "apressar" , "aprimar" , "aprofitar" , "apropar" , "apropiar" , "aprovisionar" , "aproximar" , "apujar" , "apuntalar" , "aquedar" , "aquietar" , "aquilotar" , "arborar" , "arbrar" , "arcar" , "argollar" , "aristocratitzar" , "armar" , "arquejar" , "arraconar" , "arramadar" , "arrambar" , "arramellar" , "arranjar" , "arrapar" , "arraulir" , "arrear" , "arrecerar" , "arredossar" , "arreglar" , "arrelar" , "arremangar" , "arremolinar" , "arremorar" , "arrenglerar" , "arreplegar" , "arrestar" , "arribar" , "arrimar" , "arriscar" , "arrissar" , "arrodonir" , "arromangar" , "arrombollar" , "arronsar" , "arrossegar" , "arrufar" , "arrugar" , "arruïnar" , "articular" , "asfixiar" , "assabentar" , "assaonar" , "assecar" , "assegurar" , "assentar" , "assenyalar" , "asserenar" , "assessorar" , "asseure" , "assimilar" , "associar" , "assolar" , "assolellar" , "assossegar" , "assotar" , "astorar" , "atabalar" , "ataconar" , "atalaiar" , "atandar" , "atansar" , "atapeir" , "atardar" , "atavellar" , "aterrir" , "aterrossar" , "atipar" , "atiplar" , "atonir" , "atorrollar" , "atracar" , "atribolar" , "atribuir" , "atrinxerar" , "atrofiar" , "atropellar" , "atrotinar" , "aturar" , "avalotar" , "avançar" , "avarar" , "avariar" , "avenir" , "aventurar" , "avergonyir" , "avesar" , "aviar" , "aviciar" , "avidar" , "avivar" , "avorrir" , "aïllar" , "aïrar" , "badar" , "balancejar" , "balandrejar" , "baldar" , "banyar" , "barallar" , "barrejar" , "basar" , "basquejar" , "bastar" , "batre" , "befar" , "bellugar" , "beneficiar" , "bleir" , "blocar" , "bolcar" , "bombar" , "bonificar" , "botir" , "brindar" , "brossar" , "bufar" , "buidar" , "burocratitzar" , "cabrejar" , "cabussar" , "cagar" , "calar" , "calmar" , "calçar" , "campar" , "cansar" , "cap" , "capalçar" , "capbussar" , "capficar" , "capgirar" , "captar" , "captrencar" , "caracteritzar" , "caragirar" , "carbonar" , "carbonatar" , "carbonitzar" , "cardar" , "cargolar" , "carregar" , "cartejar" , "casar" , "cascar" , "cenyir" , "cerciorar" , "cicatritzar" , "circumscriure" , "clamar" , "classificar" , "clavar" , "clivellar" , "cloure" , "coagular" , "cobrir" , "colar" , "colgar" , "colltorçar" , "colltòrcer" , "colrar" , "coltellejar" , "col·lapsar" , "col·legiar" , "col·locar" , "comanar" , "combinar" , "compadir" , "compaginar" , "compatir" , "compensar" , "complementar" , "complexificar" , "complicar" , "complir" , "complànyer" , "compondre" , "comportar" , "comprendre" , "comprimir" , "comprometre" , "compungir" , "comunicar" , "concentrar" , "concertar" , "conciliar" , "concordar" , "concretar" , "condemnar" , "condensar" , "conduir" , "confabular" , "confederar" , "confessar" , "confinar" , "confirmar" , "confitar" , "conformar" , "congelar" , "congestionar" , "conglomerar" , "conglutinar" , "congratular" , "congregar" , "congriar" , "conhortar" , "conjuminar" , "conjunyir" , "conjurar" , "connaturalitzar" , "consagrar" , "conscienciar" , "consentir" , "conservar" , "consolar" , "consolidar" , "constipar" , "consumir" , "contagiar" , "contaminar" , "contemperar" , "contenir" , "contorbar" , "contornar" , "contradir" , "contraposar" , "contreure" , "controlar" , "convertir" , "convèncer" , "corbar" , "corcar" , "cordar" , "coronar" , "corporificar" , "corregir" , "correspondre" , "corrompre" , "corsecar" , "cotitzar" , "covar" , "crebantar" , "cremar" , "creure" , "criar" , "crispar" , "cucar" , "cuidar" , "cuixatrencar" , "curar" , "curullar" , "damnar" , "debatre" , "decantar" , "decidir" , "declarar" , "decuplicar" , "decurvar" , "dedicar" , "defendre" , "defensar" , "definir" , "deformar" , "defugir" , "degradar" , "deixar" , "deixatar" , "deixondar" , "deixondir" , "deixuplinar" , "delectar" , "delir" , "delitar" , "denudar" , "departir" , "depauperar" , "depilar" , "deportar" , "depositar" , "depravar" , "deprimir" , "depurar" , "derivar" , "desabillar" , "desabonar" , "desabrigar" , "desacalorar" , "desacoblar" , "desaconductar" , "desaconduir" , "desacordar" , "desacostumar" , "desacreditar" , "desadherir" , "desaferrar" , "desafinar" , "desagafar" , "desagermanar" , "desagradar" , "desagregar" , "desajustar" , "desalinear" , "desamarrar" , "desamigar" , "desamistançar" , "desamorrar" , "desanar" , "desanimar" , "desaparellar" , "desapariar" , "desaparroquianar" , "desaplicar" , "desapropiar" , "desar" , "desarborar" , "desarmar" , "desarramadar" , "desarrambar" , "desarranjar" , "desarrapar" , "desarreglar" , "desarregussar" , "desarrelar" , "desarrengar" , "desarrenglar" , "desarrenglerar" , "desarrimar" , "desarrissar" , "desarromangar" , "desarrufar" , "desarrugar" , "desarticular" , "desassossegar" , "desatansar" , "desatapeir" , "desatendar" , "desavesar" , "desaveïnar" , "desballestar" , "desbaratar" , "desbarbar" , "desbarrar" , "desbordar" , "desbrancar" , "desbraonar" , "descabalar" , "descabdellar" , "descabellar" , "descalcificar" , "descalçar" , "descaminar" , "descantellar" , "descarbonatar" , "descarbonitzar" , "descarburar" , "descargolar" , "descarnar" , "descarregar" , "descarrerar" , "descartar" , "descastellanitzar" , "descatalanitzar" , "descelerar" , "descentrar" , "descenyir" , "desclassar" , "desclavar" , "descloure" , "descoagular" , "descobrir" , "descolgar" , "descollar" , "descolorar" , "descolorir" , "descol·locar" , "descompassar" , "descompensar" , "descompondre" , "descomprometre" , "descomptar" , "desconceptuar" , "desconcertar" , "desconfortar" , "descongelar" , "descongestionar" , "desconhortar" , "desconjuntar" , "desconnectar" , "descoratjar" , "descordar" , "descosir" , "descotxar" , "descrostar" , "descular" , "desdaurar" , "desdelitar" , "desdenyar" , "desdibuixar" , "desdinerar" , "desdir" , "desdoblar" , "desdoblegar" , "deseixir" , "deselectritzar" , "desembabaiar" , "desembadalir" , "desembadocar" , "desemballestar" , "desemboirar" , "desembolcallar" , "desembolcar" , "desembolicar" , "desembotir" , "desembotjar" , "desembotornar" , "desemboçar" , "desembravir" , "desembrocar" , "desembromallar" , "desembromar" , "desembullar" , "desembussar" , "desembutllofar" , "desemmandrir" , "desemmurriar" , "desempallar" , "desempastar" , "desemperesir" , "desempernar" , "desempipar" , "desempobrir" , "desempolainar" , "desempolsar" , "desempolvorar" , "desenamorar" , "desencadenar" , "desencaixar" , "desencalimar" , "desencalitjar" , "desencallar" , "desencaminar" , "desencantar" , "desencaparrar" , "desencapotar" , "desencaputxar" , "desencarar" , "desencarcarar" , "desencarranquinar" , "desencartonar" , "desencastar" , "desencaterinar" , "desencauar" , "desencavalcar" , "desencavallar" , "desencebar" , "desencerclar" , "desencercolar" , "desencimbellar" , "desencisar" , "desenclavar" , "desencoblar" , "desencolar" , "desencongir" , "desencoratjar" , "desencorbar" , "desencordillar" , "desencrespar" , "desencrostar" , "desendegar" , "desendeutar" , "desendogalar" , "desendolcir" , "desendollar" , "desendropir" , "desenfadar" , "desenfadeir" , "desenfarfegar" , "desenfellonir" , "desenferrissar" , "desenfetgegar" , "desenfilar" , "desenfitar" , "desenflocar" , "desenfocar" , "desenfrenar" , "desenfuriar" , "desenfurismar" , "desengandulir" , "desenganxar" , "desenganyar" , "desengatjar" , "desengavanyar" , "desengomar" , "desengormandir" , "desengorronir" , "desengreixar" , "desengrescar" , "desengruixir" , "desengrutar" , "desenguantar" , "desenguerxir" , "desenllaminir" , "desenllaçar" , "desenlleganyar" , "desenllepolir" , "desenllorar" , "desenlluernar" , "desenllustrar" , "desennuegar" , "desennuvolar" , "desenquadernar" , "desenquadrar" , "desenquimerar" , "desenrampar" , "desenredar" , "desenrederar" , "desenrolar" , "desenrotllar" , "desensabonar" , "desensenyorir" , "desensonyar" , "desensopir" , "desensuperbir" , "desentaular" , "desentelar" , "desentendre" , "desentenebrar" , "desentenebrir" , "desenterbolir" , "desenterrar" , "desentestar" , "desentortolligar" , "desentrampar" , "desentranyar" , "desentravessar" , "desentrecuixar" , "desentrenar" , "desentristir" , "desentumir" , "desentusiasmar" , "desenutjar" , "desenvelar" , "desenvernissar" , "desenvescar" , "desenvolupar" , "desenyorar" , "desequilibrar" , "desertitzar" , "desesmar" , "desesperançar" , "desesperar" , "desespessir" , "desestancar" , "desestanyar" , "desestovar" , "desfaixar" , "desfaiçonar" , "desfanatitzar" , "desfardar" , "desfasar" , "desfermar" , "desferrar" , "desficiar" , "desficiejar" , "desfigurar" , "desfilar" , "desflorir" , "desfocar" , "desfogar" , "desfonar" , "desfrarar" , "desfrenar" , "desfrunzir" , "desfullar" , "desganar" , "desgastar" , "desgavellar" , "desglaçar" , "desgraciar" , "desgranar" , "desgruixar" , "desguarnir" , "desguerxar" , "desguitarrar" , "deshabitar" , "deshabituar" , "deshidratar" , "deshumanitzar" , "desigualar" , "desil·lusionar" , "desimantar" , "desincorporar" , "desincrustar" , "desinfatuar" , "desinflamar" , "desinflar" , "desinhibir" , "desintegrar" , "desinteressar" , "desintoxicar" , "desionitzar" , "desjunyir" , "deslligar" , "deslliurar" , "desllodrigar" , "desllogar" , "deslloriguerar" , "deslluir" , "desllustrar" , "desmagnetitzar" , "desmaiar" , "desmallar" , "desmanegar" , "desmaquillar" , "desmarcar" , "desmembrar" , "desmillorar" , "desmoralitzar" , "desmorriar" , "desmudar" , "desmuntar" , "desnacionalitzar" , "desnaturar" , "desniar" , "desnierar" , "desnivellar" , "desnuar" , "desnucar" , "desobligar" , "desobstruir" , "desocupar" , "desorbitar" , "desordenar" , "desorganitzar" , "desorientar" , "despacientar" , "desparar" , "desparellar" , "despariar" , "despassar" , "despenjar" , "despentinar" , "despenyar" , "despersonalitzar" , "despertar" , "despintar" , "despistar" , "despitar" , "desplaçar" , "desplegar" , "desplomar" , "despoblar" , "despolir" , "desposseir" , "desprendre" , "desprestigiar" , "desprisar" , "despullar" , "despuntar" , "desrengar" , "desroentar" , "dessaborir" , "dessagnar" , "dessecar" , "dessolar" , "dessoldar" , "dessonillar" , "dessoterrar" , "dessuar" , "dessucar" , "destacar" , "destapar" , "destarotar" , "destemprar" , "destenyir" , "desteular" , "destintar" , "destorçar" , "destravar" , "destrempar" , "destrenar" , "destriar" , "destrossar" , "destòrcer" , "desunglar" , "desunir" , "desusar" , "desvariar" , "desvariejar" , "desvesar" , "desvestir" , "desvetllar" , "desviar" , "desvincular" , "desvitrificar" , "detenir" , "deteriorar" , "determinar" , "deturar" , "devaluar" , "dialitzar" , "dibuixar" , "diferenciar" , "difondre" , "diftongar" , "difuminar" , "dignificar" , "dilatar" , "diluir" , "dipositar" , "dirigir" , "disbauxar" , "disciplinar" , "disculpar" , "disfressar" , "disgregar" , "disgustar" , "dislocar" , "disparar" , "dispersar" , "disposar" , "disputar" , "disseminar" , "dissimilar" , "dissipar" , "dissociar" , "dissoldre" , "distanciar" , "distendre" , "distingir" , "distreure" , "distribuir" , "diversificar" , "divertir" , "dividir" , "divorciar" , "divulgar" , "doblar" , "doblegar" , "doctorar" , "documentar" , "doldre" , "domesticar" , "domiciliar" , "dominar" , "donar" , "dopar" , "dreçar" , "drogar" , "dubtar" , "dulcificar" , "duplicar" , "dutxar" , "eclipsar" , "efectuar" , "efeminar" , "eixamar" , "eixamenar" , "eixamorar" , "eixamplar" , "eixancar" , "eixancarrar" , "eixarrancar" , "eixarreir" , "eixorivir" , "eixugar" , "electritzar" , "electrocutar" , "elevar" , "elidir" , "emancipar" , "embabaiar" , "embadalir" , "embadocar" , "embajanir" , "embalar" , "embalbar" , "embalbir" , "embancar" , "embarbollar" , "embarcar" , "embardissar" , "embarracar" , "embarrancar" , "embarranquinar" , "embarrar" , "embarumar" , "embarzerar" , "embasardir" , "embassar" , "embastardir" , "embellir" , "embeure" , "embicar" , "emblanquir" , "emblavir" , "embofegar" , "embogir" , "emboirar" , "embolicar" , "emborbollar" , "emborratxar" , "emboscar" , "embossar" , "embotinar" , "embotir" , "emboçar" , "embrancar" , "embravir" , "embretolir" , "embriagar" , "embrocar" , "embrollar" , "embromar" , "embrossar" , "embrunir" , "embrutar" , "embrutir" , "embullar" , "embussar" , "embutllofar" , "embutxacar" , "emmagrir" , "emmalaltir" , "emmaleir" , "emmallar" , "emmandrir" , "emmarcir" , "emmaridar" , "emmascarar" , "emmatxucar" , "emmerdar" , "emmerdissar" , "emmetzinar" , "emmirallar" , "emmotllar" , "emmudir" , "emmusteir" , "emmustigar" , "emocionar" , "empadronar" , "empal·lidir" , "empantanar" , "empantanegar" , "empanxonar" , "empapatxar" , "emparar" , "emparaular" , "emparentar" , "emparrar" , "empastellar" , "empastifar" , "empastissar" , "empatxar" , "empedreir" , "empeguntar" , "empellar" , "empeltar" , "empenyorar" , "emperesir" , "emperlar" , "empernar" , "empetitir" , "empilar" , "empinar" , "empipar" , "empitjorar" , "empitrar" , "empixonar" , "emplenar" , "emplomallar" , "empobrir" , "empolainar" , "empolistrar" , "empolsar" , "empolsegar" , "empolsimar" , "empolsinar" , "empolvorar" , "empoquir" , "emporcar" , "emporprar" , "empotingar" , "emprendre" , "emprenyar" , "emprovar" , "enagrir" , "enamorar" , "enamoriscar" , "enarborar" , "enarbrar" , "enarcar" , "enardir" , "enasprar" , "enasprir" , "encabassar" , "encabir" , "encaboriar" , "encadarnar" , "encadenar" , "encaixar" , "encalbir" , "encalimar" , "encalitjar" , "encallar" , "encallir" , "encambrar" , "encamellar" , "encaminar" , "encamisar" , "encantar" , "encaparrar" , "encapellar" , "encaperonar" , "encaperullar" , "encaperutxar" , "encapirotar" , "encapotar" , "encapsular" , "encapullar" , "encaputxar" , "encaramel·lar" , "encarar" , "encarbonar" , "encarir" , "encarnar" , "encarranquinar" , "encarregar" , "encarrerar" , "encarrilar" , "encartonar" , "encasquetar" , "encastellar" , "encauar" , "encavallar" , "encegar" , "encendre" , "encepar" , "encertir" , "encetar" , "encimbellar" , "enciriar" , "enclaustrar" , "enclotar" , "encloure" , "encoblar" , "encofurnar" , "encoixir" , "encomanar" , "enconar" , "enconcar" , "encongir" , "encontrar" , "encoratjar" , "encorbar" , "encordar" , "encotillar" , "encotxar" , "encovar" , "encrespar" , "encreuar" , "encrostar" , "encrostimar" , "encrostissar" , "encruelir" , "endarreriar" , "endarrerir" , "endegar" , "endentar" , "endenyar" , "enderrocar" , "endeutar" , "endinsar" , "endogalar" , "endolcir" , "endolentir" , "endossar" , "endropir" , "endurir" , "enemistar" , "enervar" , "enfadar" , "enfadeir" , "enfangar" , "enfarfegar" , "enfarinar" , "enfastidir" , "enfastijar" , "enfellonir" , "enfervorir" , "enfetgegar" , "enfigassar" , "enfilar" , "enfistular" , "enfitar" , "enflocar" , "enflorar" , "enfondir" , "enfonsar" , "enfonyar" , "enforfoguir" , "enforinyar" , "enfortir" , "enfosquir" , "enfredar" , "enfredolicar" , "enfredorar" , "enfredorir" , "enfrontar" , "enfuriar" , "enfurir" , "enfurismar" , "engabiar" , "engalavernar" , "engallar" , "engallardir" , "engallir" , "engallofir" , "engalonar" , "engalvanir" , "enganar" , "engandulir" , "enganxar" , "enganyar" , "engatar" , "engatjar" , "engelosir" , "enginjolar" , "enginyar" , "engiponar" , "englotir" , "engolar" , "engolir" , "engordir" , "engorjar" , "engormandir" , "engorronir" , "engrandir" , "engreixar" , "engrescar" , "engrevir" , "engroguir" , "engronsar" , "engronyar" , "engrossir" , "engruixar" , "engruixir" , "engrutar" , "enguantar" , "enguerxir" , "enherbar" , "enjoiar" , "enjoiellar" , "enjoncar" , "enjullar" , "enlairar" , "enllacar" , "enllaminir" , "enllangorir" , "enllardar" , "enllardissar" , "enllaçar" , "enllefernar" , "enllefiscar" , "enllepissar" , "enllepolir" , "enllestir" , "enlletgir" , "enllistar" , "enllorar" , "enllordar" , "enllotar" , "enllustrar" , "ennegrir" , "ennoblir" , "ennovar" , "ennuegar" , "ennuvolar" , "enorgullar" , "enquadrar" , "enquibir" , "enquimerar" , "enrabiar" , "enramar" , "enrampar" , "enrancir" , "enrarir" , "enrasar" , "enravenar" , "enredar" , "enrederar" , "enrederir" , "enrellentir" , "enretirar" , "enrevenxinar" , "enriallar" , "enrigidir" , "enrinxolar" , "enriquir" , "enrobustir" , "enrocar" , "enrogir" , "enrolar" , "enronquir" , "enrosar" , "enrossir" , "enrotllar" , "enrullar" , "enrunar" , "ensabonar" , "ensagnar" , "ensalivar" , "ensangonar" , "enseguir" , "ensenyorir" , "ensonyar" , "ensopegar" , "ensopir" , "ensordir" , "ensorrar" , "ensotar" , "ensulsir" , "ensuperbir" , "entaforar" , "entatxonar" , "entaular" , "entebeir" , "entebionar" , "entelar" , "entendre" , "entendrir" , "entenebrar" , "entenebrir" , "enterbolir" , "enterrar" , "enterrossar" , "entestar" , "entollar" , "entonar" , "entornar" , "entortellar" , "entortolligar" , "entrampar" , "entrapar" , "entravessar" , "entrebancar" , "entregar" , "entregirar" , "entrellaçar" , "entrelligar" , "entremesclar" , "entrenar" , "entretenir" , "entreveure" , "entrevistar" , "entristar" , "entristir" , "entumir" , "enturar" , "entusiasmar" , "enutjar" , "envanir" , "envellir" , "envellutar" , "enverdir" , "enverinar" , "envermellir" , "envescar" , "enviar" , "envigorir" , "envilir" , "environar" , "enviscar" , "enviscolar" , "envitricollar" , "envoltar" , "enxarxar" , "enxiquir" , "enyorar" , "equilibrar" , "equivaler" , "equivocar" , "erigir" , "eriçar" , "errar" , "esbadiar" , "esbadinar" , "esbadocar" , "esbalair" , "esbaldir" , "esbaldregar" , "esbandir" , "esbardellar" , "esbargir" , "esbarriar" , "esbarzerar" , "esberlar" , "esbocinar" , "esboirar" , "esboldregar" , "esbombar" , "esbombolar" , "esborifar" , "esborrar" , "esborrifar" , "esborronar" , "esbotifarrar" , "esbotzar" , "esbrancar" , "esbraonar" , "esbraveir" , "esbullar" , "escabellar" , "escabellonar" , "escabotar" , "escaldar" , "escaldufar" , "escalfar" , "escalfeir" , "escalivar" , "escalonar" , "escamarlar" , "escamnar" , "escampar" , "escandalitzar" , "escantellar" , "escantonar" , "escanyar" , "escapar" , "escarmentar" , "escarrabillar" , "escarxar" , "escaure" , "escindir" , "esclafar" , "esclafassar" , "esclarir" , "esclerosar" , "escolar" , "escoltar" , "escometre" , "escondir" , "escotar" , "escridar" , "escridassar" , "escrostar" , "escrostissar" , "escrostonar" , "escruixir" , "escuar" , "escudar" , "escuixar" , "escular" , "escurçar" , "escórrer" , "esdernegar" , "esdevenir" , "esduir" , "esfacelar" , "esfereir" , "esfilagarsar" , "esfondrar" , "esfreixurar" , "esfullar" , "esfumar" , "esgallar" , "esgardissar" , "esgarrar" , "esgarrifar" , "esgarrinxar" , "esgarrinyar" , "esgarronar" , "esgavellar" , "esglaonar" , "esgotar" , "esgratinyar" , "esguardar" , "esguerrar" , "esllenegar" , "esllomar" , "esmadeixar" , "esmalucar" , "esmenar" , "esmicar" , "esmicolar" , "esmolar" , "esmorrellar" , "esmorronar" , "esmortir" , "esmunyir" , "esmussar" , "espalmar" , "espantar" , "espanyolitzar" , "espaordir" , "espargir" , "esparpallar" , "esparpillar" , "esparracar" , "esparverar" , "espassar" , "espatllar" , "espaventar" , "espavilar" , "especejar" , "especialitzar" , "espedaçar" , "espellifar" , "espellir" , "espellissar" , "espenyar" , "esperançar" , "esperar" , "espesseir" , "espessir" , "espicassar" , "espigar" , "espinar" , "espitrar" , "esplaiar" , "esplugar" , "espolsar" , "espoltrir" , "esponjar" , "esporuguir" , "esposar" , "esprémer" , "espuar" , "espuntar" , "espunyir" , "espuçar" , "esqueixar" , "esquerar" , "esquerdar" , "esquerdillar" , "esquerdissar" , "esquinçar" , "esquitxar" , "esquivar" , "est" , "estabilitzar" , "establir" , "estacionar" , "estalviar" , "estamordir" , "estancar" , "estandarditzar" , "estantolar" , "estanyar" , "estarrufar" , "estellar" , "estendre" , "estepitzar" , "estilitzar" , "estimbar" , "estintolar" , "estirar" , "estireganyar" , "estiuar" , "estontolar" , "estovar" , "estrangeritzar" , "estranyar" , "estratificar" , "estrenar" , "estressar" , "estretir" , "estrinxolar" , "estripar" , "estroncar" , "estropellar" , "estrènyer" , "estubar" , "estufar" , "esvair" , "esvalotar" , "esventar" , "esvorar" , "esvorellar" , "eternitzar" , "europeïtzar" , "evadir" , "evaporar" , "exacerbar" , "exaltar" , "examinar" , "exasperar" , "excedir" , "excitar" , "exclamar" , "excloure" , "exculpar" , "excusar" , "exercitar" , "exfoliar" , "exhalar" , "exhaurir" , "exhibir" , "exiliar" , "eximir" , "exornar" , "expandir" , "expatriar" , "explicar" , "exposar" , "expressar" , "extasiar" , "extenuar" , "exterioritzar" , "extingir" , "extraviar" , "extremar" , "faixar" , "familiaritzar" , "fanatitzar" , "fastiguejar" , "fatigar" , "federar" , "felicitar" , "feminitzar" , "ferir" , "fiar" , "ficar" , "figurar" , "filtrar" , "fingir" , "firar" , "fixar" , "flagel·lar" , "florir" , "folrar" , "foraviar" , "forcar" , "forjar" , "formalitzar" , "formar" , "fortificar" , "fossilitzar" , "fotre" , "fraccionar" , "fracturar" , "fragmentar" , "francesitzar" , "franquejar" , "fregar" , "fregir" , "frisar" , "fumar" , "fundar" , "gabar" , "gastar" , "gaudir" , "gelar" , "generalitzar" , "gestar" , "ginyar" , "girar" , "gitar" , "glaçar" , "gloriejar" , "governar" , "graduar" , "gramaticalitzar" , "gratar" , "gratular" , "gravar" , "grecitzar" , "grillar" , "gronxar" , "gronxejar" , "gronxolar" , "guanyar" , "guardar" , "guarir" , "guarnir" , "guerxar" , "guiar" , "guillar" , "habituar" , "hebraïtzar" , "hel·lenitzar" , "hemodialitzar" , "herniar" , "hibridar" , "hidratar" , "hissar" , "honorar" , "honrar" , "horripilar" , "horroritzar" , "hostatjar" , "humanitzar" , "humiliar" , "humitejar" , "identificar" , "igualar" , "il·luminar" , "il·lusionar" , "il·lustrar" , "imaginar" , "immergir" , "immolar" , "impacientar" , "implicar" , "imposar" , "impressionar" , "imprimir" , "impurificar" , "incarcerar" , "incendiar" , "inclinar" , "incomodar" , "incorporar" , "incrementar" , "incrustar" , "independitzar" , "indignar" , "indisposar" , "inebriar" , "infatuar" , "infectar" , "infestar" , "infiltrar" , "inflamar" , "inflar" , "informar" , "ingerir" , "inhabilitar" , "inhibir" , "iniciar" , "inquietar" , "inscriure" , "insinuar" , "inspirar" , "instal·lar" , "instruir" , "insubordinar" , "insultar" , "insurreccionar" , "integrar" , "intensificar" , "interessar" , "interferir" , "internar" , "interposar" , "interrompre" , "intranquil·litzar" , "introduir" , "inundar" , "invaginar" , "inventar" , "ionitzar" , "irritar" , "islamitzar" , "isolar" , "jubilar" , "jugar" , "junyir" , "justificar" , "lamentar" , "laxar" , "lignificar" , "limitar" , "llampar" , "llançar" , "llassar" , "llatinitzar" , "llepar" , "lletrejar" , "llevar" , "llicenciar" , "lligar" , "lliurar" , "llogar" , "lluir" , "localitzar" , "lucrar" , "macerar" , "malacostumar" , "malavesar" , "maliciar" , "mallar" , "malpensar" , "mamar" , "mancomunar" , "manegar" , "manejar" , "manifestar" , "mantenir" , "maquillar" , "marcir" , "marejar" , "marginar" , "maridar" , "marinejar" , "mascarar" , "massificar" , "masturbar" , "matar" , "materialitzar" , "matricular" , "matxucar" , "mecanitzar" , "mediumitzar" , "menar" , "menjar" , "mentalitzar" , "menysprear" , "meravellar" , "merèixer" , "mesclar" , "metal·litzar" , "metamorfosar" , "meteoritzar" , "migrar" , "millorar" , "mineralitzar" , "mirar" , "mobilitzar" , "mocar" , "moderar" , "modernitzar" , "modificar" , "molestar" , "morfondre" , "morir" , "morrejar" , "mortificar" , "mossegar" , "mostrar" , "moure" , "mudar" , "mullar" , "multiplicar" , "musteir" , "mustiar" , "mustigar" , "mutilar" , "nacionalitzar" , "naturalitzar" , "necrosar" , "negar" , "neguitejar" , "netejar" , "nonuplicar" , "normalitzar" , "nuar" , "oblidar" , "obligar" , "obnubilar" , "obscurir" , "occidentalitzar" , "occitanitzar" , "ocultar" , "ocupar" , "ofegar" , "oferir" , "ofuscar" , "ombrar" , "omplir" , "operar" , "oposar" , "ordenar" , "orejar" , "organitzar" , "orgullar" , "orientalitzar" , "orientar" , "originar" , "orinar" , "oscar" , "oxigenar" , "pacificar" , "paganitzar" , "pagar" , "pansir" , "parapetar" , "parar" , "parlar" , "particularitzar" , "partir" , "passar" , "passejar" , "pedregar" , "pedrejar" , "pellar" , "penjar" , "pensar" , "pentinar" , "percaçar" , "perfeccionar" , "perfilar" , "permetre" , "persignar" , "persuadir" , "pessigar" , "petar" , "picar" , "pintar" , "pirar" , "plantar" , "plantejar" , "plantificar" , "podrir" , "polaritzar" , "polir" , "pol·linitzar" , "pondre" , "popularitzar" , "portar" , "posar" , "possessionar" , "posticar" , "postrar" , "prear" , "precipitar" , "prendre" , "preocupar" , "preparar" , "presentar" , "prestar" , "prevaler" , "privar" , "proclamar" , "prodigar" , "produir" , "professionalitzar" , "proletaritzar" , "prometre" , "pronunciar" , "propagar" , "propalar" , "proposar" , "prostituir" , "prostrar" , "prou" , "proveir" , "pujar" , "punxar" , "purificar" , "putejar" , "quadrar" , "qualificar" , "quallar" , "quedar" , "quitar" , "rabejar" , "radicalitzar" , "rarificar" , "ratificar" , "reafirmar" , "realitzar" , "rebaixar" , "rebentar" , "reblir" , "rebolcar" , "rebullir" , "recargolar" , "reciclar" , "reciprocar" , "recloure" , "recobrar" , "recollir" , "recolzar" , "reconcentrar" , "reconciliar" , "reconstituir" , "recordar" , "recrear" , "recriminar" , "rectificar" , "reencarnar" , "reenganxar" , "refer" , "referir" , "refermar" , "reflectir" , "refocil·lar" , "reforçar" , "refractar" , "refredar" , "refrenar" , "refrescar" , "refringir" , "refugiar" , "refusar" , "regalar" , "regelar" , "regirar" , "rehabilitar" , "rehidratar" , "reincorporar" , "reinflar" , "reinstal·lar" , "reintegrar" , "rejovenir" , "relacionar" , "relaxar" , "rellentir" , "relligar" , "rellogar" , "remenar" , "remetre" , "remirar" , "remollir" , "remudar" , "remuntar" , "rendir" , "renovar" , "renovellar" , "rentar" , "repatriar" , "repenjar" , "repensar" , "repetir" , "repintar" , "replegar" , "replujar" , "repodrir" , "reportar" , "reposar" , "representar" , "reprimir" , "reproduir" , "repuntar" , "rescabalar" , "reservar" , "resguardar" , "resignar" , "resinificar" , "resistir" , "resoldre" , "responsabilitzar" , "resquitar" , "ressecar" , "ressobinar" , "restablir" , "retardar" , "retenir" , "retintar" , "retirar" , "retractar" , "retre" , "retreure" , "retrobar" , "reunir" , "reveixinar" , "revelar" , "revellir" , "revenxinar" , "revestir" , "revifar" , "reviscolar" , "revoltar" , "rifar" , "rinxolar" , "riure" , "romanitzar" , "rombollar" , "rompre" , "rostir" , "rovellar" , "ruboritzar" , "russificar" , "sacrificar" , "salmorrar" , "salsir" , "salvar" , "santificar" , "satel·litzar" , "secularitzar" , "sedimentar" , "segar" , "segregar" , "seguir" , "sentir" , "senyar" , "separar" , "significar" , "silicificar" , "sincerar" , "sindicar" , "singularitzar" , "sinitzar" , "situar" , "sobrealimentar" , "sobreexcitar" , "sobreposar" , "sobresaltar" , "sobresanar" , "sobresaturar" , "sobtar" , "socarrar" , "solapar" , "solar" , "solaçar" , "soldar" , "solidaritzar" , "solidificar" , "sollar" , "sollevar" , "solvatar" , "somorgollar" , "soplujar" , "sostreure" , "sotaplujar" , "sotmetre" , "suberificar" , "suberitzar" , "subestimar" , "submergir" , "subscriure" , "suggestionar" , "sulfatar" , "sulfurar" , "sumar" , "sumir" , "superar" , "tallar" , "tancar" , "tant" , "tapar" , "temperar" , "tenyir" , "terraplenar" , "tirar" , "titular" , "tocar" , "tombar" , "torbar" , "torejar" , "tornar" , "torrar" , "trabucar" , "tractar" , "tranquil·litzar" , "transfigurar" , "transformar" , "translimitar" , "transmetre" , "transmutar" , "transparentar" , "transvasar" , "trasmudar" , "trasplantar" , "trastocar" , "trastornar" , "triar" , "tribular" , "trifurcar" , "trobar" , "tòrcer" , "ulcerar" , "ullar" , "unir" , "universalitzar" , "untar" , "vaporitzar" , "velar" , "venjar" , "ventar" , "vessar" , "vestir" , "viciar" , "vinclar" , "vincular" , "vitrificar" , "volar" , "volatilitzar" , "xalar" , "xutar" ) ; private static final List < String > excepVerbsPotencialmentPronominals = Arrays . asList ( "voler" ) ; private static final List < String > verbHaver = Arrays . asList ( "haver" ) ; private static final Pattern NO_VERB = Pattern . compile ( "N.*|A.*|_GN_.*" ) ; private static final Pattern VERB = Pattern . compile ( "V.*" ) ; private static final Pattern VERB_INDSUBJ = Pattern . compile ( "V.[SI].*" ) ; private static final Pattern VERB_INDSUBJIMP = Pattern . compile ( "V.[MSI].*" ) ; private static final Pattern VERB_IMP = Pattern . compile ( "V.M.*" ) ; private static final Pattern VERB_INF = Pattern . compile ( "V.N.*" ) ; private static final Pattern VERB_INFGER = Pattern . compile ( "V.[NG].*" ) ; private static final Pattern VERB_GERUNDI = Pattern . compile ( "V.G.*" ) ; private static final Pattern VERB_PARTICIPI = Pattern . compile ( "V.P.*" ) ; private static final Pattern VERB_AUXILIAR = Pattern . compile ( "VA.*" ) ; private static final Pattern PREP_VERB_PRONOM = Pattern . compile ( "RN|SPS00|V.*|P0.{6}|PP3CN000|PP3NN000|PP3..A00|PP3CP000|PP3CSD00" ) ; private static final Pattern PREP_VERB_PRONOM_ADV = Pattern . compile ( "RG.*|.*LOC_ADV.*|SPS00|V.*|P0.{6}|PP3CN000|PP3NN000|PP3..A00|PP3CP000|PP3CSD00" ) ; private static final List < String > cometes = Arrays . asList ( "\"" , "'" , "‘" , "’" , "“" , "”" , "«" , "»" ) ; private static final Pattern VERB_PRONOM = Pattern . compile ( "V.*|P0.{6}|PP3CN000|PP3NN000|PP3..A00|PP3CP000|PP3CSD00" ) ; private static final Pattern VERB_1S = Pattern . compile ( "V...1S..?" ) ; private static final Pattern VERB_2S = Pattern . compile ( "V...2S..?" ) ; private static final Pattern VERB_3S = Pattern . compile ( "V...3S..?" ) ; private static final Pattern VERB_1P = Pattern . compile ( "V...1P..?" ) ; private static final Pattern VERB_2P = Pattern . compile ( "V...2P..?" ) ; private static final Pattern VERB_3P = Pattern . compile ( "V...3P..?" ) ; private static final Pattern PRONOM_FEBLE_1S = Pattern . compile ( "P010S000" ) ; private static final Pattern PRONOM_FEBLE_2S = Pattern . compile ( "P020S000" ) ; private static final Pattern PRONOM_FEBLE_3S = Pattern . compile ( "P0300000" ) ; private static final Pattern PRONOM_FEBLE_1P = Pattern . compile ( "P010P000" ) ; private static final Pattern PRONOM_FEBLE_2P = Pattern . compile ( "P020P000" ) ; private static final Pattern PRONOM_FEBLE_3P = Pattern . compile ( "P0300000" ) ; private static final Pattern PRONOM_FEBLE_13S = Pattern . compile ( "P010S000|P0300000" ) ; private static final Pattern PRONOM_FEBLE_23S = Pattern . compile ( "P020S000|P0300000" ) ; private static final Pattern PRONOM_FEBLE_3S_TOTS = Pattern . compile ( "P.3.[^PN].*" ) ; private static final Pattern PRONOM_FEBLE = Pattern . compile ( "P0.{6}|PP3CN000|PP3NN000|PP3..A00|PP3CP000|PP3CSD00" ) ; private static final Pattern PRONOM_REFLEXIU = Pattern . compile ( "P0.0.*" ) ; private static final Pattern LEMMA_EN = Pattern . compile ( "en" ) ; private static final Pattern POSTAG_EN = Pattern . compile ( "PP3CN000" ) ; private static final Pattern LEMMA_HI = Pattern . compile ( "hi" ) ; private static final Pattern POSTAG_HI = Pattern . compile ( "PP3CN000" ) ; private static final Pattern LEMMA_ES = Pattern . compile ( "es" ) ; private static final Pattern POSTAG_ES = Pattern . compile ( "P0300000" ) ; private static final Pattern LEMMA_PRONOM_CI = Pattern . compile ( "jo|tu|ell" ) ; private static final Pattern POSTAG_PRONOM_CI = Pattern . compile ( "P0.*|PP3CP000|PP3CSD00" ) ; private static final Pattern LEMMA_PRONOM_CD = Pattern . compile ( "jo|tu|ell" ) ; private static final Pattern POSTAG_PRONOM_CD = Pattern . compile ( "P0.*|PP3CP000|PP3..A00" ) ; private static final Pattern POSTAG_CD = Pattern . compile ( "_GN_.*|N.*|DI.*|P[DI].*" ) ; private static final Pattern LEMMA_DE = Pattern . compile ( "de" ) ; private static final Pattern POSTAG_DE = Pattern . compile ( "SPS00" ) ; private static final Pattern POSTAG_PREPOSICIO = Pattern . compile ( "SPS00" ) ; private static final Pattern LEMMA_PREP_A_PER = Pattern . compile ( "a|per" ) ; private static final Pattern POSTAG_ADVERBI = Pattern . compile ( "RG.*|.*LOC_ADV.*" ) ; private static final Pattern ANYMESDIA = Pattern . compile ( "any|mes|dia" ) ; private static final Pattern REFLEXIU_POSPOSAT = Pattern . compile ( "-[mts]|-[mts]e|'[mts]|-nos|'ns|-vos|-us" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern REFLEXIU_ANTEPOSAT = Pattern . compile ( "e[mts]|[mts]e|ens|us|vos|'[mts]|[mts]'|'ns" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern PRONOMFEBLE_POSPOSAT = Pattern . compile ( "['-].+" ) ; private static final Pattern SUBJECTE_PERSONAL_POSTAG = Pattern . compile ( "NC.*|NP.*|_GN_.*|PI.*|_possible_nompropi" ) ; private static final Pattern SUBJECTE_PERSONAL_NO_POSTAG = Pattern . compile ( "complement.*|D.*|PX.*" ) ; private static final Pattern SUBJECTE_PERSONAL_TOKEN = Pattern . compile ( "algú|algun|jo|mi|tu|ella?|nosaltres|vosaltres|elle?s|vost[èé]s?|vós" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern SUBJECTE_PERSONAL_NO_LEMMA = Pattern . compile ( "dia|any|mes|segle|dilluns|dimarts|dimecres|dijous|divendres|dissabte|diumenge|gener|febrer|març|abril|maig|juny|juliol|agost|setembre|octubre|novembre|desembre" ) ; private static final Pattern SUBJECTE_PERSONAL_SING_POSTAG = Pattern . compile ( "N..[SN].*|_GN_.S|PI..[SN].*|_possible_nompropi|UNKNOWN" ) ; private static final Pattern SUBJECTE_PERSONAL_SING_TOKEN = Pattern . compile ( "algú|algun|jo|mi|tu|ella?|vost[èé]|vós" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern SUBJECTE_PERSONAL_PL_POSTAG = Pattern . compile ( "N..[PN].*|_GN_.P|PI..[PN].*|_possible_nompropi|UNKNOWN" ) ; private static final Pattern SUBJECTE_PERSONAL_PL_TOKEN = Pattern . compile ( "alguns|nosaltres|vosaltres|elle?s|vost[èé]s" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern SUBJECTE_3S_POSTAG = Pattern . compile ( "N..[SN].*|_GN_.S|PI..[SN].*" ) ; private static final Pattern SUBJECTE_3S_TOKEN = Pattern . compile ( "algú|algun|ella?|vost[èé]|vós" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern SUBJECTE_3S_NO_POSTAG = Pattern . compile ( "complement.*" ) ; private static final Pattern SUBJECTE_3S_NO_TOKEN = Pattern . compile ( "jo|tu|mi|nosaltres|vosaltres|elle?s" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern TRENCA_COMPTE = Pattern . compile ( "PR.*|CS|CC|_PUNCT.*|.*LOC_CONJ.*" ) ; private static final Pattern TRENCA_COMPTE2 = Pattern . compile ( "SENT_START|CC|_PUNCT.*|.*LOC_CONJ.*" ) ; private static final List < String > partsCos = Arrays . asList ( "pit" , "galta" , "cap" , "cor" , "cara" , "ull" , "front" , "mà" , "peu" , "braç" , "colze" , "genoll" , "cabell" , "llavi" ) ; private static final List < String > contextBaixar = Arrays . asList ( "fitxer" , "arxiu" , "paquet" , "instal·lació" , "versió" , "programa" , "programari" , "software" , "virus" , "antivirus" , "URL" , "web" , "pàgina" , "instal·lar" , "IS_URL" , "imatge" , "pel·lícula" , "foto" , "fotografia" ) ; private static final List < String > pronomJo = Arrays . asList ( "jo" ) ; public ReflexiveVerbsRule ( ResourceBundle messages ) throws IOException { super . setCategory ( new Category ( "Verbs" ) ) ; setLocQualityIssueType ( ITSIssueType . Grammar ) ; } @ Override public String getId ( ) { return "VERBS_REFLEXIUS" ; } @ Override public String getDescription ( ) { return "Verbs reflexius: comproveu que porten el pronom adequat." ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; loop : for ( int i = 1 ; i < tokens . length ; i ++ ) { if ( i > 1 && StringTools . startsWithUppercase ( tokens [ i ] . getToken ( ) ) ) { continue loop ; } if ( ! matchPostagRegexp ( tokens [ i ] , VERB ) || matchPostagRegexp ( tokens [ i ] , NO_VERB ) ) continue loop ; final String token = tokens [ i ] . getToken ( ) . toLowerCase ( ) ; if ( i + 2 < tokens . length && tokens [ i ] . hasLemma ( "donar" ) && ( tokens [ i + 1 ] . getToken ( ) . equals ( "compte" ) || tokens [ i + 2 ] . getToken ( ) . equals ( "compte" ) ) ) { if ( ! isThereReflexivePronoun ( tokens , i ) ) continue loop ; if ( isPhraseImpersonalVerbS ( tokens , i ) ) continue loop ; final String msg = "Expressió incorrecta si equival a 'adonar-se', correcta si vol dir 'retre compte'." ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ i ] . getStartPos ( ) , tokens [ i ] . getEndPos ( ) , msg , "Possible error" ) ; ruleMatches . add ( ruleMatch ) ; } if ( i + 2 < tokens . length && matchLemmaList ( tokens [ i ] , verbsPortarDur ) && ! ( matchPostagRegexp ( tokens [ i ] , VERB_INF ) && isThereBefore ( tokens , i , LEMMA_PREP_A_PER , POSTAG_PREPOSICIO ) ) && ! hasVerbMultipleReadings ( tokens [ i ] ) && isThereReflexivePronoun ( tokens , i ) && isThereAfterWithoutPreposition ( tokens , i , POSTAG_CD ) && ! isThereVerbBeforeList ( tokens , i , verbsDeixarFer ) && ! ( isThereVerbBeforeList ( tokens , i , verbsPotencialmentPronominals ) && ! isThereVerbBeforeList ( tokens , i , excepVerbsPotencialmentPronominals ) ) && ! matchPostagRegexp ( tokens [ i + 1 ] , POSTAG_ADVERBI ) && ! matchPostagRegexp ( tokens [ i + 2 ] , POSTAG_ADVERBI ) && ! matchLemmaRegexp ( tokens [ i + 2 ] , ANYMESDIA ) && ! isPhraseImpersonalVerbSP ( tokens , i ) ) { if ( isVerbNumberPerson ( tokens , i , VERB_3S ) && ! isThereBefore ( tokens , i , LEMMA_ES , POSTAG_ES ) && isThereSubject3SBefore ( tokens , i , TRENCA_COMPTE ) ) continue loop ; if ( isThereNearLemma ( tokens , i , partsCos ) ) continue loop ; String suggestion ; if ( tokens [ i ] . hasLemma ( "portar" ) ) { suggestion = "em" + token ; } else if ( token . equalsIgnoreCase ( "du" ) ) { suggestion = "endú" ; } else { suggestion = "en" + token ; } final String msg = "¿Volíeu dir <suggestion>" + suggestion + "</suggestion>?" ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ i ] . getStartPos ( ) , tokens [ i ] . getEndPos ( ) , msg , "Possible error" ) ; ruleMatches . add ( ruleMatch ) ; continue loop ; } if ( i + 1 < tokens . length && matchPostagRegexp ( tokens [ i ] , VERB_INF ) && ! matchPostagRegexp ( tokens [ i - 1 ] , POSTAG_PREPOSICIO ) && isThereVerbBeforeListLimit ( tokens , i , verbsDeixarFer , 3 ) && isThereRedundantPronoun ( tokens , i ) && isThereBefore ( tokens , i , LEMMA_PRONOM_CD , POSTAG_PRONOM_CD ) && matchRegexp ( tokens [ i + 1 ] . getToken ( ) , REFLEXIU_POSPOSAT ) ) { final String msg = "En aquesta perífrasi verbal el pronom reflexiu posterior és redundant." ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ i + 1 ] . getStartPos ( ) , tokens [ i + 1 ] . getStartPos ( ) + tokens [ i + 1 ] . getToken ( ) . length ( ) , msg , "Pronom redundant" ) ; ruleMatches . add ( ruleMatch ) ; continue loop ; } if ( matchLemmaRegexp ( tokens [ i ] , VERB_AUTO ) || matchLemmaList ( tokens [ i ] , verbsPronominals ) ) { if ( matchLemmaList ( tokens [ i ] , excepVerbsPronominals ) ) continue loop ; if ( matchPostagRegexp ( tokens [ i ] , VERB_PARTICIPI ) && ! tokens [ i - 1 ] . hasLemma ( "haver" ) ) continue loop ; if ( isThereVerbBeforeList ( tokens , i , verbsDeixarFer ) && ( isThereBefore ( tokens , i , LEMMA_PRONOM_CD , POSTAG_PRONOM_CD ) || isThereBefore ( tokens , i , LEMMA_PRONOM_CI , POSTAG_PRONOM_CI ) || isThereAfterWithoutPreposition ( tokens , i , POSTAG_CD ) ) ) continue loop ; if ( isThereReflexivePronoun ( tokens , i ) ) continue loop ; final String msg = "Aquest verb és pronominal. Probablement falta un pronom." ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ i ] . getStartPos ( ) , tokens [ i ] . getEndPos ( ) , msg , "Verb pronominal: falta un pronom" ) ; ruleMatches . add ( ruleMatch ) ; continue loop ; } if ( matchLemmaList ( tokens [ i ] , verbsNoPronominals ) ) { if ( matchLemmaList ( tokens [ i ] , excepVerbsNoPronominals ) ) continue loop ; if ( ! isThereReflexivePronoun ( tokens , i ) ) continue loop ; if ( tokens [ i ] . hasLemma ( "baixar" ) && isThereNearLemma ( tokens , i , contextBaixar ) ) continue loop ; if ( matchLemmaList ( tokens [ i ] , verbsNoPronominalsImpersonals2 ) && isThereBefore ( tokens , i , LEMMA_ES , POSTAG_ES ) && isThereBefore ( tokens , i , LEMMA_DE , POSTAG_DE ) && isThereVerbBeforeList ( tokens , i , verbHaver ) ) continue loop ; if ( isThereVerbBeforeList ( tokens , i , verbsSovintAmbComplement ) || ( isThereVerbBeforeList ( tokens , i , verbsPotencialmentPronominals ) && ! isThereVerbBeforeList ( tokens , i , excepVerbsPotencialmentPronominals ) ) || isThereVerbBefore ( tokens , i , VERB_AUTO ) || isThereVerbBeforeList ( tokens , i , verbsPronominals ) ) continue loop ; if ( matchLemmaList ( tokens [ i ] , verbsNoPronominalsImpersonals ) && isPhraseImpersonalVerbS ( tokens , i ) ) continue loop ; if ( matchLemmaList ( tokens [ i ] , verbsNoPronominalsImpersonals2 ) && isPhraseImpersonalVerbSP ( tokens , i ) ) continue loop ; if ( tokens [ i ] . hasLemma ( "olorar" ) && isThereNearLemma ( tokens , i , partsCos ) ) continue loop ; final String msg = "Aquest verb no és pronominal. Probablement sobra un pronom." ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ i ] . getStartPos ( ) , tokens [ i ] . getEndPos ( ) , msg , "Verb no pronominal" ) ; if ( tokens [ i ] . hasLemma ( "créixer" ) ) { ArrayList < String > replacements = new ArrayList < > ( ) ; replacements . add ( "(encoratjar-se)" ) ; replacements . add ( "(animar-se)" ) ; replacements . add ( "(agafar ànim)" ) ; ruleMatch . setSuggestedReplacements ( replacements ) ; } ruleMatches . add ( ruleMatch ) ; } if ( matchLemmaList ( tokens [ i ] , verbsMoviment ) && ! matchPostagRegexp ( tokens [ i ] , VERB_AUXILIAR ) ) { if ( matchLemmaList ( tokens [ i ] , excepVerbsMoviment ) ) continue loop ; if ( isThereBefore ( tokens , i , LEMMA_ES , POSTAG_ES ) && isThereBefore ( tokens , i , LEMMA_DE , POSTAG_DE ) && isThereVerbBeforeList ( tokens , i , verbHaver ) ) continue loop ; if ( isThereVerbBeforeList ( tokens , i , verbsSovintAmbComplement ) || ( isThereVerbBeforeList ( tokens , i , verbsPotencialmentPronominals ) && ! isThereVerbBeforeList ( tokens , i , excepVerbsPotencialmentPronominals ) ) || isThereVerbBefore ( tokens , i , VERB_AUTO ) || isThereVerbBeforeList ( tokens , i , verbsPronominals ) ) continue loop ; if ( isVerbNumberPerson ( tokens , i , VERB_3S ) && ! isThereBefore ( tokens , i , LEMMA_ES , POSTAG_ES ) && isThereNearLemma ( tokens , i , partsCos ) ) continue loop ; if ( tokens [ i ] . hasLemma ( "venir" ) || tokens [ i ] . hasLemma ( "anar" ) ) { if ( i + 1 < tokens . length && isVerbNumberPerson ( tokens , i , VERB_3S ) && ! isThereBefore ( tokens , i , LEMMA_ES , POSTAG_ES ) && matchPostagRegexp ( tokens [ i + 1 ] , POSTAG_ADVERBI ) && ! isThereNearWord ( tokens , i , pronomJo ) ) continue loop ; } if ( tokens [ i ] . hasLemma ( "venir" ) ) { if ( i + 2 < tokens . length && tokens [ i + 1 ] . getToken ( ) . equals ( "de" ) && tokens [ i + 2 ] . getToken ( ) . equals ( "gust" ) ) continue loop ; if ( isVerbNumberPerson ( tokens , i , VERB_3S ) && ! isThereBefore ( tokens , i , LEMMA_ES , POSTAG_ES ) && isThereAfterWithoutPreposition ( tokens , i , POSTAG_CD ) && ! isThereNearWord ( tokens , i , pronomJo ) ) continue loop ; if ( isThereAfter ( tokens , i , VERB_INF ) ) continue loop ; } if ( tokens [ i ] . hasLemma ( "anar" ) ) { if ( isThereAfter ( tokens , i , VERB_GERUNDI ) ) continue loop ; if ( isThereVerbAfterList ( tokens , i , verbsPotencialmentPronominals ) || isThereVerbAfter ( tokens , i , VERB_AUTO ) || isThereVerbAfterList ( tokens , i , verbsPronominals ) ) continue loop ; if ( isVerbNumberPerson ( tokens , i , VERB_3S ) && ! isThereBefore ( tokens , i , LEMMA_ES , POSTAG_ES ) && isThereSubject3SBefore ( tokens , i , TRENCA_COMPTE ) ) continue loop ; if ( isPhraseImpersonalVerbS ( tokens , i ) ) continue loop ; } else { if ( isThereBefore ( tokens , i , LEMMA_ES , POSTAG_ES ) && ! isThereBefore ( tokens , i , LEMMA_PRONOM_CI , POSTAG_PRONOM_CI ) && ! isTherePersonalSubjectBefore ( tokens , i , TRENCA_COMPTE ) ) continue loop ; } if ( isThereReflexivePronoun ( tokens , i ) && ( ! isTherePronoun ( tokens , i , LEMMA_EN , POSTAG_EN ) ) ) { final String msg = "No useu com a pronominal aquest verb, o bé afegiu-hi el pronom 'en'." ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ i ] . getStartPos ( ) , tokens [ i ] . getEndPos ( ) , msg , "Falta el pronom 'en'" ) ; ruleMatches . add ( ruleMatch ) ; } } } return toRuleMatchArray ( ruleMatches ) ; } @ Nullable private Pattern pronomPattern ( AnalyzedTokenReadings aToken ) { if ( matchPostagRegexp ( aToken , VERB_1S ) && matchPostagRegexp ( aToken , VERB_3S ) ) return PRONOM_FEBLE_13S ; if ( matchPostagRegexp ( aToken , VERB_2S ) && matchPostagRegexp ( aToken , VERB_3S ) ) return PRONOM_FEBLE_23S ; else if ( matchPostagRegexp ( aToken , VERB_1S ) ) return PRONOM_FEBLE_1S ; else if ( matchPostagRegexp ( aToken , VERB_2S ) ) return PRONOM_FEBLE_2S ; else if ( matchPostagRegexp ( aToken , VERB_3S ) ) return PRONOM_FEBLE_3S ; else if ( matchPostagRegexp ( aToken , VERB_1P ) ) return PRONOM_FEBLE_1P ; else if ( matchPostagRegexp ( aToken , VERB_2P ) ) return PRONOM_FEBLE_2P ; else if ( matchPostagRegexp ( aToken , VERB_3P ) ) return PRONOM_FEBLE_3P ; else return null ; } private boolean hasVerbMultipleReadings ( AnalyzedTokenReadings aToken ) { return ( matchPostagRegexp ( aToken , VERB_1S ) && matchPostagRegexp ( aToken , VERB_3S ) ) || ( matchPostagRegexp ( aToken , VERB_2S ) && matchPostagRegexp ( aToken , VERB_3S ) ) ; } private boolean matchPostagRegexp ( AnalyzedTokenReadings aToken , Pattern pattern ) { boolean matches = false ; for ( AnalyzedToken analyzedToken : aToken ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag == null ) { posTag = "UNKNOWN" ; } final Matcher m = pattern . matcher ( posTag ) ; if ( m . matches ( ) ) { matches = true ; break ; } } return matches ; } private boolean matchLemmaRegexp ( AnalyzedTokenReadings aToken , Pattern pattern ) { boolean matches = false ; for ( AnalyzedToken analyzedToken : aToken ) { final String posTag = analyzedToken . getLemma ( ) ; if ( posTag != null ) { final Matcher m = pattern . matcher ( posTag ) ; if ( m . matches ( ) ) { matches = true ; break ; } } } return matches ; } private boolean matchLemmaList ( AnalyzedTokenReadings aToken , List < String > list ) { boolean matches = false ; for ( AnalyzedToken analyzedToken : aToken ) { if ( list . contains ( analyzedToken . getLemma ( ) ) ) { matches = true ; break ; } } return matches ; } private boolean matchRegexp ( String s , Pattern pattern ) { final Matcher m = pattern . matcher ( s ) ; return m . matches ( ) ; } private boolean isThereReflexivePronoun ( final AnalyzedTokenReadings [ ] tokens , int i ) { Pattern pPronomBuscat = null ; if ( matchPostagRegexp ( tokens [ i ] , VERB_INDSUBJ ) ) { pPronomBuscat = pronomPattern ( tokens [ i ] ) ; if ( pPronomBuscat != null ) { int j = 1 ; boolean keepCounting = true ; while ( i - j > 0 && j < 4 && keepCounting ) { if ( matchPostagRegexp ( tokens [ i - j ] , pPronomBuscat ) && matchRegexp ( tokens [ i - j ] . getToken ( ) , REFLEXIU_ANTEPOSAT ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PRONOM_FEBLE ) ; j ++ ; } } } if ( matchPostagRegexp ( tokens [ i ] , VERB_IMP ) ) { pPronomBuscat = pronomPattern ( tokens [ i ] ) ; if ( pPronomBuscat != null ) { if ( i + 1 < tokens . length && matchPostagRegexp ( tokens [ i + 1 ] , pPronomBuscat ) && matchRegexp ( tokens [ i + 1 ] . getToken ( ) , REFLEXIU_POSPOSAT ) ) return true ; } } if ( matchPostagRegexp ( tokens [ i ] , VERB_PARTICIPI ) ) { if ( tokens [ i - 1 ] . hasLemma ( "haver" ) ) { if ( matchPostagRegexp ( tokens [ i - 1 ] , VERB_INDSUBJ ) ) { pPronomBuscat = pronomPattern ( tokens [ i - 1 ] ) ; if ( pPronomBuscat != null ) { int j = 2 ; boolean keepCounting = true ; while ( i - j > 0 && j < 5 && keepCounting ) { if ( matchPostagRegexp ( tokens [ i - j ] , pPronomBuscat ) && matchRegexp ( tokens [ i - j ] . getToken ( ) , REFLEXIU_ANTEPOSAT ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PRONOM_FEBLE ) ; j ++ ; } } } else if ( matchPostagRegexp ( tokens [ i - 1 ] , VERB_INF ) && matchPostagRegexp ( tokens [ i - 2 ] , VERB_INDSUBJ ) ) { pPronomBuscat = pronomPattern ( tokens [ i - 2 ] ) ; if ( pPronomBuscat != null ) { int j = 3 ; boolean keepCounting = true ; while ( i - j > 0 && j < 5 && keepCounting ) { if ( matchPostagRegexp ( tokens [ i - j ] , pPronomBuscat ) && matchRegexp ( tokens [ i - j ] . getToken ( ) , REFLEXIU_ANTEPOSAT ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PRONOM_FEBLE ) ; j ++ ; } } } } } if ( matchPostagRegexp ( tokens [ i ] , VERB_INFGER ) ) { int k = 1 ; boolean keepCounting = true ; boolean foundVerb = false ; while ( i - k > 0 && keepCounting && ! foundVerb ) { foundVerb = matchPostagRegexp ( tokens [ i - k ] , VERB_INDSUBJIMP ) ; keepCounting = matchPostagRegexp ( tokens [ i - k ] , PREP_VERB_PRONOM ) ; if ( matchPostagRegexp ( tokens [ i - k ] , VERB_INDSUBJ ) && matchPostagRegexp ( tokens [ i - k + 1 ] , VERB_INFGER ) ) keepCounting = false ; if ( matchPostagRegexp ( tokens [ i - k ] , VERB_INFGER ) && matchPostagRegexp ( tokens [ i - k + 1 ] , PRONOM_FEBLE ) && ! matchRegexp ( tokens [ i - k + 1 ] . getToken ( ) , PRONOMFEBLE_POSPOSAT ) ) { keepCounting = false ; } k ++ ; } if ( foundVerb ) { k -- ; pPronomBuscat = pronomPattern ( tokens [ i - k ] ) ; if ( pPronomBuscat != null ) { if ( i + 1 < tokens . length && matchPostagRegexp ( tokens [ i + 1 ] , pPronomBuscat ) && matchRegexp ( tokens [ i + 1 ] . getToken ( ) , REFLEXIU_POSPOSAT ) ) return true ; int j = 1 ; keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( j == 1 && matchPostagRegexp ( tokens [ i - j ] , pPronomBuscat ) ) return true ; if ( j > 1 && matchPostagRegexp ( tokens [ i - j ] , pPronomBuscat ) && ! ( matchRegexp ( tokens [ i - j ] . getToken ( ) , REFLEXIU_POSPOSAT ) && j > k ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PREP_VERB_PRONOM ) && ! ( j > k - 1 && matchPostagRegexp ( tokens [ i - j ] , VERB_PARTICIPI ) ) && ! matchPostagRegexp ( tokens [ i - j ] , TRENCA_COMPTE2 ) ; if ( tokens [ i - j ] . getToken ( ) . equalsIgnoreCase ( "per" ) && tokens [ i - j + 1 ] . getToken ( ) . equalsIgnoreCase ( "a" ) ) { keepCounting = false ; } if ( matchPostagRegexp ( tokens [ i - j ] , VERB_INFGER ) && matchPostagRegexp ( tokens [ i - j + 1 ] , PRONOM_FEBLE ) && ! matchRegexp ( tokens [ i - j + 1 ] . getToken ( ) , PRONOMFEBLE_POSPOSAT ) ) { keepCounting = false ; } j ++ ; } } } else { if ( i + 1 < tokens . length && matchPostagRegexp ( tokens [ i + 1 ] , PRONOM_REFLEXIU ) && matchRegexp ( tokens [ i + 1 ] . getToken ( ) , REFLEXIU_POSPOSAT ) ) return true ; int j = 1 ; keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchPostagRegexp ( tokens [ i - j ] , PRONOM_REFLEXIU ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PREP_VERB_PRONOM ) ; if ( tokens [ i - j ] . getToken ( ) . equalsIgnoreCase ( "per" ) && tokens [ i - j + 1 ] . getToken ( ) . equalsIgnoreCase ( "a" ) ) { keepCounting = false ; } if ( matchPostagRegexp ( tokens [ i - j ] , VERB_INFGER ) && matchPostagRegexp ( tokens [ i - j + 1 ] , PRONOM_FEBLE ) && ! matchRegexp ( tokens [ i - j + 1 ] . getToken ( ) , PRONOMFEBLE_POSPOSAT ) ) { keepCounting = false ; } j ++ ; } } } return false ; } private boolean isTherePronoun ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern lemma , Pattern postag ) { int j = 1 ; boolean keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchPostagRegexp ( tokens [ i - j ] , postag ) && matchLemmaRegexp ( tokens [ i - j ] , lemma ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PREP_VERB_PRONOM ) ; j ++ ; } j = 1 ; keepCounting = true ; while ( i + j < tokens . length && keepCounting ) { if ( matchPostagRegexp ( tokens [ i + j ] , postag ) && matchLemmaRegexp ( tokens [ i + j ] , lemma ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i + j ] , PREP_VERB_PRONOM ) ; j ++ ; } return false ; } private boolean isThereBefore ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern lemma , Pattern postag ) { int j = 1 ; boolean keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchPostagRegexp ( tokens [ i - j ] , postag ) && matchLemmaRegexp ( tokens [ i - j ] , lemma ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PREP_VERB_PRONOM ) ; j ++ ; } return false ; } private boolean isThereBeforePostag ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern postag ) { int j = 1 ; boolean keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchPostagRegexp ( tokens [ i - j ] , postag ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PREP_VERB_PRONOM ) ; j ++ ; } return false ; } private boolean isThereAfter ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern postag ) { int j = 1 ; boolean keepCounting = true ; while ( i + j < tokens . length && keepCounting ) { if ( matchPostagRegexp ( tokens [ i + j ] , postag ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i + j ] , PREP_VERB_PRONOM_ADV ) || cometes . contains ( tokens [ i + j ] . getToken ( ) ) ; j ++ ; } return false ; } private boolean isThereAfterWithoutPreposition ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern postag ) { int j = 1 ; boolean keepCounting = true ; while ( i + j < tokens . length && keepCounting ) { if ( matchPostagRegexp ( tokens [ i + j ] , postag ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i + j ] , VERB_PRONOM ) || cometes . contains ( tokens [ i + j ] . getToken ( ) ) ; j ++ ; } return false ; } private boolean isThereVerbBefore ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern lemma ) { int j = 1 ; boolean keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchLemmaRegexp ( tokens [ i - j ] , lemma ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PREP_VERB_PRONOM ) ; if ( tokens [ i - j ] . getToken ( ) . equalsIgnoreCase ( "per" ) && tokens [ i - j + 1 ] . getToken ( ) . equalsIgnoreCase ( "a" ) ) keepCounting = false ; if ( matchPostagRegexp ( tokens [ i - j ] , VERB_INDSUBJ ) && matchPostagRegexp ( tokens [ i - j + 1 ] , VERB_INFGER ) ) keepCounting = false ; j ++ ; } return false ; } private boolean isThereVerbAfter ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern lemma ) { int j = 1 ; boolean keepCounting = true ; while ( i + j < tokens . length && keepCounting ) { if ( matchLemmaRegexp ( tokens [ i + j ] , lemma ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i + j ] , PREP_VERB_PRONOM ) ; j ++ ; } return false ; } private boolean isThereVerbBeforeList ( final AnalyzedTokenReadings [ ] tokens , int i , List < String > lemmas ) { return isThereVerbBeforeListLimit ( tokens , i , lemmas , 10 ) ; } private boolean isThereVerbBeforeListLimit ( final AnalyzedTokenReadings [ ] tokens , int i , List < String > lemmas , int limit ) { int j = 1 ; boolean keepCounting = true ; while ( i - j > 0 && keepCounting && j < limit ) { if ( matchLemmaList ( tokens [ i - j ] , lemmas ) && ! tokens [ i - j ] . hasPosTag ( "_possible_nompropi" ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PREP_VERB_PRONOM ) ; if ( tokens [ i - j ] . getToken ( ) . equalsIgnoreCase ( "per" ) && tokens [ i - j + 1 ] . getToken ( ) . equalsIgnoreCase ( "a" ) ) keepCounting = false ; if ( matchPostagRegexp ( tokens [ i - j ] , VERB_INDSUBJ ) && matchPostagRegexp ( tokens [ i - j + 1 ] , VERB_INFGER ) ) keepCounting = false ; j ++ ; } return false ; } private boolean isThereVerbAfterList ( final AnalyzedTokenReadings [ ] tokens , int i , List < String > lemmas ) { int j = 1 ; boolean keepCounting = true ; while ( i + j < tokens . length && keepCounting ) { if ( matchLemmaList ( tokens [ i + j ] , lemmas ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i + j ] , PREP_VERB_PRONOM ) ; j ++ ; } return false ; } private boolean isThereRedundantPronoun ( final AnalyzedTokenReadings [ ] tokens , int i ) { if ( ( isThereAfterWithoutPreposition ( tokens , i , PRONOM_FEBLE_1S ) && isThereBeforePostag ( tokens , i , PRONOM_FEBLE_1S ) ) || ( isThereAfterWithoutPreposition ( tokens , i , PRONOM_FEBLE_2S ) && isThereBeforePostag ( tokens , i , PRONOM_FEBLE_2S ) ) || ( isThereAfterWithoutPreposition ( tokens , i , PRONOM_FEBLE_3S_TOTS ) && isThereBeforePostag ( tokens , i , PRONOM_FEBLE_3S_TOTS ) ) || ( isThereAfterWithoutPreposition ( tokens , i , PRONOM_FEBLE_1P ) && isThereBeforePostag ( tokens , i , PRONOM_FEBLE_1P ) ) || ( isThereAfterWithoutPreposition ( tokens , i , PRONOM_FEBLE_2P ) && isThereBeforePostag ( tokens , i , PRONOM_FEBLE_2P ) ) || ( isThereAfterWithoutPreposition ( tokens , i , PRONOM_FEBLE_3P ) && isThereBeforePostag ( tokens , i , PRONOM_FEBLE_3P ) ) ) return true ; return false ; } private boolean isThereNearLemma ( final AnalyzedTokenReadings [ ] tokens , int i , List < String > lemmas ) { int j = 1 ; boolean keepCounting = true ; while ( i + j < tokens . length && keepCounting ) { if ( matchLemmaList ( tokens [ i + j ] , lemmas ) ) return true ; keepCounting = ! matchPostagRegexp ( tokens [ i + j ] , TRENCA_COMPTE ) ; j ++ ; } j = 1 ; keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchLemmaList ( tokens [ i - j ] , lemmas ) ) return true ; keepCounting = ! matchPostagRegexp ( tokens [ i - j ] , TRENCA_COMPTE ) ; j ++ ; } return false ; } private boolean isThereNearWord ( final AnalyzedTokenReadings [ ] tokens , int i , List < String > words ) { int j = 1 ; boolean keepCounting = true ; while ( i + j < tokens . length && keepCounting ) { if ( words . contains ( tokens [ i + j ] . getToken ( ) . toLowerCase ( ) ) ) return true ; keepCounting = ! matchPostagRegexp ( tokens [ i + j ] , TRENCA_COMPTE ) ; j ++ ; } j = 1 ; keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( words . contains ( tokens [ i - j ] . getToken ( ) . toLowerCase ( ) ) ) return true ; keepCounting = ! matchPostagRegexp ( tokens [ i - j ] , TRENCA_COMPTE ) ; j ++ ; } return false ; } private boolean isTherePersonalSubjectBefore ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern pTrenca ) { int j = 1 ; boolean keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchRegexp ( tokens [ i - j ] . getToken ( ) , SUBJECTE_PERSONAL_TOKEN ) || matchPostagRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_POSTAG ) && ! matchPostagRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_NO_POSTAG ) && ! matchLemmaRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_NO_LEMMA ) ) return true ; keepCounting = ! matchPostagRegexp ( tokens [ i - j ] , pTrenca ) ; j ++ ; } return false ; } private boolean isThereSingularPersonalSubjectBefore ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern pTrenca ) { int j = 1 ; boolean keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchRegexp ( tokens [ i - j ] . getToken ( ) , SUBJECTE_PERSONAL_SING_TOKEN ) || matchPostagRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_SING_POSTAG ) && ! matchPostagRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_NO_POSTAG ) && ! matchLemmaRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_NO_LEMMA ) ) return true ; keepCounting = ! matchPostagRegexp ( tokens [ i - j ] , pTrenca ) ; if ( matchLemmaRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_NO_LEMMA ) ) { keepCounting = false ; } j ++ ; } return false ; } private boolean isTherePluralPersonalSubjectBefore ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern pTrenca ) { int j = 1 ; boolean keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchRegexp ( tokens [ i - j ] . getToken ( ) , SUBJECTE_PERSONAL_PL_TOKEN ) || matchPostagRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_PL_POSTAG ) && ! matchPostagRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_NO_POSTAG ) && ! matchLemmaRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_NO_LEMMA ) ) return true ; keepCounting = ! matchPostagRegexp ( tokens [ i - j ] , pTrenca ) ; if ( matchLemmaRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_NO_LEMMA ) ) { keepCounting = false ; } j ++ ; } return false ; } private boolean isThereSubject3SBefore ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern pTrenca ) { int j = 1 ; boolean keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchRegexp ( tokens [ i - j ] . getToken ( ) , SUBJECTE_3S_TOKEN ) || matchPostagRegexp ( tokens [ i - j ] , SUBJECTE_3S_POSTAG ) && ! matchPostagRegexp ( tokens [ i - j ] , SUBJECTE_3S_NO_POSTAG ) && ! matchRegexp ( tokens [ i - j ] . getToken ( ) , SUBJECTE_3S_NO_TOKEN ) && ! matchLemmaRegexp ( tokens [ i - j ] , SUBJECTE_PERSONAL_NO_LEMMA ) ) return true ; keepCounting = ! matchPostagRegexp ( tokens [ i - j ] , pTrenca ) ; j ++ ; } return false ; } private boolean isVerbNumberPerson ( final AnalyzedTokenReadings [ ] tokens , int i , Pattern pVerb ) { int j = 0 ; boolean keepCounting = true ; while ( i - j > 0 && keepCounting ) { if ( matchPostagRegexp ( tokens [ i - j ] , pVerb ) ) return true ; keepCounting = matchPostagRegexp ( tokens [ i - j ] , PREP_VERB_PRONOM ) ; if ( tokens [ i - j ] . getToken ( ) . equalsIgnoreCase ( "per" ) && tokens [ i - j + 1 ] . getToken ( ) . equalsIgnoreCase ( "a" ) ) keepCounting = false ; j ++ ; } return false ; } private boolean isPhraseImpersonalVerbS ( final AnalyzedTokenReadings [ ] tokens , int i ) { return isThereBefore ( tokens , i , LEMMA_ES , POSTAG_ES ) && ! isThereBefore ( tokens , i , LEMMA_PRONOM_CI , POSTAG_PRONOM_CI ) && ( ! isThereSingularPersonalSubjectBefore ( tokens , i , TRENCA_COMPTE2 ) || isThereBefore ( tokens , i , LEMMA_HI , POSTAG_HI ) ) && isVerbNumberPerson ( tokens , i , VERB_3S ) ; } private boolean isPhraseImpersonalVerbSP ( final AnalyzedTokenReadings [ ] tokens , int i ) { return isThereBefore ( tokens , i , LEMMA_ES , POSTAG_ES ) && ! isThereBefore ( tokens , i , LEMMA_PRONOM_CI , POSTAG_PRONOM_CI ) && ( ( ( isVerbNumberPerson ( tokens , i , VERB_3S ) && ! isThereSingularPersonalSubjectBefore ( tokens , i , TRENCA_COMPTE ) ) || ( isVerbNumberPerson ( tokens , i , VERB_3P ) && ! isTherePluralPersonalSubjectBefore ( tokens , i , TRENCA_COMPTE ) ) ) || isThereBefore ( tokens , i , LEMMA_HI , POSTAG_HI ) ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . en ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; public final class MorfologikSouthAfricanSpellerRule extends AbstractEnglishSpellerRule { private static final String RESOURCE_FILENAME = "/en/hunspell/en_ZA.dict" ; public MorfologikSouthAfricanSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_EN_ZA" ; } }
package org . languagetool . rules . en ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . Example ; import org . languagetool . rules . WordRepeatRule ; public class EnglishWordRepeatRule extends WordRepeatRule { public EnglishWordRepeatRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; addExamplePair ( Example . wrong ( "This <marker>is is</marker> just an example sentence." ) , Example . fixed ( "This <marker>is</marker> just an example sentence." ) ) ; } @ Override public String getId ( ) { return "ENGLISH_WORD_REPEAT_RULE" ; } @ Override public boolean ignore ( AnalyzedTokenReadings [ ] tokens , int position ) { if ( wordRepetitionOf ( "had" , tokens , position ) && posIsIn ( tokens , position - 2 , "PRP" ) ) { return true ; } if ( wordRepetitionOf ( "that" , tokens , position ) && posIsIn ( tokens , position + 1 , "NN" , "PRP$" , "JJ" , "VBZ" , "VBD" ) ) { return true ; } if ( wordRepetitionOf ( "can" , tokens , position ) && posIsIn ( tokens , position - 1 , "NN" ) ) { return true ; } if ( wordRepetitionOf ( "Pago" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "Wagga" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "Duran" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "sapiens" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "tse" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "Li" , tokens , position ) ) { return true ; } return false ; } private boolean posIsIn ( AnalyzedTokenReadings [ ] tokens , int position , String ... posTags ) { if ( position >= 0 && position < tokens . length ) { for ( String posTag : posTags ) { if ( tokens [ position ] . hasPartialPosTag ( posTag ) ) { return true ; } } } return false ; } private boolean wordRepetitionOf ( String word , AnalyzedTokenReadings [ ] tokens , int position ) { return position > 0 && tokens [ position - 1 ] . getToken ( ) . equals ( word ) && tokens [ position ] . getToken ( ) . equals ( word ) ; } }
package org . languagetool . rules . en ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . AbstractSimpleReplaceRule ; import org . languagetool . rules . Example ; import org . languagetool . rules . ITSIssueType ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; public class NewZealandReplaceRule extends AbstractSimpleReplaceRule { public static final String NEW_ZEALAND_SIMPLE_REPLACE_RULE = "EN_NZ_SIMPLE_REPLACE" ; private static final Map < String , List < String > > wrongWords = load ( "/en/en-NZ/replace.txt" ) ; private static final Locale EN_NZ_LOCALE = new Locale ( "en-NZ" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public NewZealandReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; setLocQualityIssueType ( ITSIssueType . LocaleViolation ) ; addExamplePair ( Example . wrong ( "A <marker>sidewalk</marker> is a path along the side of a road." ) , Example . fixed ( "A <marker>footpath</marker> is a path along the side of a road." ) ) ; } @ Override public final String getId ( ) { return NEW_ZEALAND_SIMPLE_REPLACE_RULE ; } @ Override public String getDescription ( ) { return "English words easily confused in New Zealand English" ; } @ Override public String getShort ( ) { return "Not a New Zealand English word" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return tokenStr + " is a non-standard expression, in New Zealand English it is more common to use: " + StringUtils . join ( replacements , ", " ) + "." ; } @ Override public boolean isCaseSensitive ( ) { return false ; } @ Override public Locale getLocale ( ) { return EN_NZ_LOCALE ; } }
package org . languagetool . rules . en ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; public final class MorfologikBritishSpellerRule extends AbstractEnglishSpellerRule { public static final String RULE_ID = "MORFOLOGIK_RULE_EN_GB" ; private static final String RESOURCE_FILENAME = "/en/hunspell/en_GB.dict" ; public MorfologikBritishSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return RULE_ID ; } }
package org . languagetool . rules . en ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tools . StringTools ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import static org . languagetool . rules . en . AvsAnData . getWordsRequiringA ; import static org . languagetool . rules . en . AvsAnData . getWordsRequiringAn ; public class AvsAnRule extends EnglishRule { enum Determiner { A , AN , A_OR_AN , UNKNOWN } private static final Pattern cleanupPattern = Pattern . compile ( "[^αa-zA-Z0-9\\.;,:']" ) ; public AvsAnRule ( final ResourceBundle messages ) { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setLocQualityIssueType ( ITSIssueType . Misspelling ) ; addExamplePair ( Example . wrong ( "The train arrived <marker>a hour</marker> ago." ) , Example . fixed ( "The train arrived <marker>an hour</marker> ago." ) ) ; } @ Override public String getId ( ) { return "EN_A_VS_AN" ; } @ Override public String getDescription ( ) { return "Use of 'a' vs. 'an'" ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; int prevTokenIndex = 0 ; for ( int i = 1 ; i < tokens . length ; i ++ ) { AnalyzedTokenReadings token = tokens [ i ] ; String prevTokenStr = prevTokenIndex > 0 ? tokens [ prevTokenIndex ] . getToken ( ) : null ; boolean isSentenceStart = prevTokenIndex == 1 ; boolean equalsA = "a" . equalsIgnoreCase ( prevTokenStr ) ; boolean equalsAn = "an" . equalsIgnoreCase ( prevTokenStr ) ; if ( ! isSentenceStart ) { equalsA = "a" . equals ( prevTokenStr ) ; equalsAn = "an" . equals ( prevTokenStr ) ; } if ( equalsA || equalsAn ) { Determiner determiner = getCorrectDeterminerFor ( token ) ; String msg = null ; if ( equalsA && determiner == Determiner . AN ) { String replacement = StringTools . startsWithUppercase ( prevTokenStr ) ? "An" : "an" ; msg = "Use <suggestion>" + replacement + "</suggestion> instead of '" + prevTokenStr + "' if the following " + "word starts with a vowel sound, e.g. 'an article', 'an hour'" ; } else if ( equalsAn && determiner == Determiner . A ) { String replacement = StringTools . startsWithUppercase ( prevTokenStr ) ? "A" : "a" ; msg = "Use <suggestion>" + replacement + "</suggestion> instead of '" + prevTokenStr + "' if the following " + "word doesn't start with a vowel sound, e.g. 'a sentence', 'a university'" ; } if ( msg != null ) { RuleMatch match = new RuleMatch ( this , tokens [ prevTokenIndex ] . getStartPos ( ) , tokens [ prevTokenIndex ] . getEndPos ( ) , msg , "Wrong article" ) ; ruleMatches . add ( match ) ; } } if ( token . hasPosTag ( "DT" ) ) { prevTokenIndex = i ; } else if ( token . getToken ( ) . matches ( "[-\"()\\[\\]]+" ) ) { } else { prevTokenIndex = 0 ; } } return toRuleMatchArray ( ruleMatches ) ; } public String suggestAorAn ( final String origWord ) { AnalyzedTokenReadings token = new AnalyzedTokenReadings ( new AnalyzedToken ( origWord , null , null ) , 0 ) ; Determiner determiner = getCorrectDeterminerFor ( token ) ; if ( determiner == Determiner . A ) { return "a " + origWord ; } else if ( determiner == Determiner . AN ) { return "an " + origWord ; } else if ( determiner == Determiner . A_OR_AN ) { return "a " + origWord ; } else { return origWord ; } } Determiner getCorrectDeterminerFor ( AnalyzedTokenReadings token ) { String word = token . getToken ( ) ; Determiner determiner = Determiner . UNKNOWN ; String [ ] parts = word . split ( "[-']" ) ; if ( parts . length >= 1 && ! parts [ 0 ] . equalsIgnoreCase ( "a" ) ) { word = parts [ 0 ] ; } if ( token . isWhitespaceBefore ( ) || ! "-" . equals ( word ) ) { word = cleanupPattern . matcher ( word ) . replaceAll ( "" ) ; if ( StringTools . isEmpty ( word ) ) { return Determiner . UNKNOWN ; } } if ( getWordsRequiringA ( ) . contains ( word . toLowerCase ( ) ) || getWordsRequiringA ( ) . contains ( word ) ) { determiner = Determiner . A ; } if ( getWordsRequiringAn ( ) . contains ( word . toLowerCase ( ) ) || getWordsRequiringAn ( ) . contains ( word ) ) { if ( determiner == Determiner . A ) { determiner = Determiner . A_OR_AN ; } else { determiner = Determiner . AN ; } } if ( determiner == Determiner . UNKNOWN ) { char tokenFirstChar = word . charAt ( 0 ) ; if ( StringTools . isAllUppercase ( word ) || StringTools . isMixedCase ( word ) ) { determiner = Determiner . UNKNOWN ; } else if ( isVowel ( tokenFirstChar ) ) { determiner = Determiner . AN ; } else { determiner = Determiner . A ; } } return determiner ; } private boolean isVowel ( char c ) { char lc = Character . toLowerCase ( c ) ; return lc == 'a' || lc == 'e' || lc == 'i' || lc == 'o' || lc == 'u' ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . en ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; public final class MorfologikCanadianSpellerRule extends AbstractEnglishSpellerRule { private static final String RESOURCE_FILENAME = "/en/hunspell/en_CA.dict" ; public MorfologikCanadianSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_EN_CA" ; } }
package org . languagetool . rules . en ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . Language ; import org . languagetool . rules . Example ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; import org . languagetool . synthesis . en . EnglishSynthesizer ; import java . io . IOException ; import java . util . * ; public abstract class AbstractEnglishSpellerRule extends MorfologikSpellerRule { private final EnglishSynthesizer synthesizer = new EnglishSynthesizer ( ) ; public AbstractEnglishSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; setCheckCompound ( true ) ; addExamplePair ( Example . wrong ( "This <marker>sentenc</marker> contains a spelling mistake." ) , Example . fixed ( "This <marker>sentence</marker> contains a spelling mistake." ) ) ; } @ Override protected List < RuleMatch > getRuleMatches ( String word , int startPos ) throws IOException { List < RuleMatch > ruleMatches = super . getRuleMatches ( word , startPos ) ; if ( ruleMatches . size ( ) > 0 ) { IrregularForms forms = getIrregularFormsOrNull ( word ) ; if ( forms != null ) { RuleMatch oldMatch = ruleMatches . get ( 0 ) ; RuleMatch newMatch = new RuleMatch ( this , oldMatch . getFromPos ( ) , oldMatch . getToPos ( ) , "Possible spelling mistake. Did you mean <suggestion>" + forms . forms . get ( 0 ) + "</suggestion>, the irregular " + forms . formName + " form of the " + forms . posName + " '" + forms . baseform + "'?" ) ; List < String > allSuggestions = new ArrayList < > ( ) ; allSuggestions . addAll ( forms . forms ) ; for ( String repl : oldMatch . getSuggestedReplacements ( ) ) { if ( ! allSuggestions . contains ( repl ) ) { allSuggestions . add ( repl ) ; } } newMatch . setSuggestedReplacements ( allSuggestions ) ; ruleMatches . set ( 0 , newMatch ) ; } } return ruleMatches ; } @ SuppressWarnings ( { "ReuseOfLocalVariable" , "ControlFlowStatementWithoutBraces" } ) @ Nullable private IrregularForms getIrregularFormsOrNull ( String word ) { IrregularForms irregularFormsOrNull = getIrregularFormsOrNull ( word , "ed" , Arrays . asList ( "ed" ) , "VBD" , "verb" , "past tense" ) ; if ( irregularFormsOrNull != null ) return irregularFormsOrNull ; irregularFormsOrNull = getIrregularFormsOrNull ( word , "ed" , Arrays . asList ( "d" ) , "VBD" , "verb" , "past tense" ) ; if ( irregularFormsOrNull != null ) return irregularFormsOrNull ; irregularFormsOrNull = getIrregularFormsOrNull ( word , "s" , Arrays . asList ( "s" ) , "NNS" , "noun" , "plural" ) ; if ( irregularFormsOrNull != null ) return irregularFormsOrNull ; irregularFormsOrNull = getIrregularFormsOrNull ( word , "es" , Arrays . asList ( "es" ) , "NNS" , "noun" , "plural" ) ; if ( irregularFormsOrNull != null ) return irregularFormsOrNull ; irregularFormsOrNull = getIrregularFormsOrNull ( word , "er" , Arrays . asList ( "er" ) , "JJR" , "adjective" , "comparative" ) ; if ( irregularFormsOrNull != null ) return irregularFormsOrNull ; irregularFormsOrNull = getIrregularFormsOrNull ( word , "est" , Arrays . asList ( "est" ) , "JJS" , "adjective" , "superlative" ) ; return irregularFormsOrNull ; } @ Nullable private IrregularForms getIrregularFormsOrNull ( String word , String wordSuffix , List < String > suffixes , String posTag , String posName , String formName ) { try { for ( String suffix : suffixes ) { if ( word . endsWith ( wordSuffix ) ) { String baseForm = word . substring ( 0 , word . length ( ) - suffix . length ( ) ) ; String [ ] forms = synthesizer . synthesize ( new AnalyzedToken ( word , null , baseForm ) , posTag ) ; List < String > result = new ArrayList < > ( ) ; for ( String form : forms ) { if ( ! speller1 . isMisspelled ( form ) ) { result . add ( form ) ; } } result . remove ( word ) ; result . remove ( "badder" ) ; result . remove ( "baddest" ) ; result . remove ( "spake" ) ; if ( result . size ( ) > 0 ) { return new IrregularForms ( baseForm , posName , formName , result ) ; } } } return null ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } @ Override protected List < String > getAdditionalTopSuggestions ( List < String > suggestions , String word ) throws IOException { if ( "Alot" . equals ( word ) ) { return Arrays . asList ( "A lot" ) ; } else if ( "alot" . equals ( word ) ) { return Arrays . asList ( "a lot" ) ; } else if ( "thru" . equals ( word ) ) { return Arrays . asList ( "through" ) ; } else if ( "speach" . equals ( word ) ) { return Arrays . asList ( "speech" ) ; } return super . getAdditionalTopSuggestions ( suggestions , word ) ; } private static class IrregularForms { final String baseform ; final String posName ; final String formName ; final List < String > forms ; private IrregularForms ( String baseform , String posName , String formName , List < String > forms ) { this . baseform = baseform ; this . posName = posName ; this . formName = formName ; this . forms = forms ; } } }
package org . languagetool . rules . en ; import org . languagetool . Language ; import org . languagetool . languagemodel . LanguageModel ; import org . languagetool . rules . ConfusionProbabilityRule ; import org . languagetool . rules . Example ; import org . languagetool . tokenizers . WordTokenizer ; import org . languagetool . tokenizers . en . EnglishWordTokenizer ; import java . util . * ; public class EnglishConfusionProbabilityRule extends ConfusionProbabilityRule { private final EnglishWordTokenizer tokenizer = new EnglishWordTokenizer ( ) { @ Override public String getTokenizingCharacters ( ) { return super . getTokenizingCharacters ( ) + "-" ; } @ Override public List < String > tokenize ( final String text ) { List < String > tokens = super . tokenize ( text ) ; String prev = null ; final Stack < String > l = new Stack < > ( ) ; for ( String token : tokens ) { if ( "'" . equals ( prev ) ) { if ( token . equals ( "m" ) ) { l . pop ( ) ; l . push ( "'m" ) ; } else if ( token . equals ( "re" ) ) { l . pop ( ) ; l . push ( "'re" ) ; } else if ( token . equals ( "ve" ) ) { l . pop ( ) ; l . push ( "'ve" ) ; } else if ( token . equals ( "ll" ) ) { l . pop ( ) ; l . push ( "'ll" ) ; } else { l . push ( token ) ; } } else { l . push ( token ) ; } prev = token ; } return l ; } } ; public EnglishConfusionProbabilityRule ( ResourceBundle messages , LanguageModel languageModel , Language language ) { this ( messages , languageModel , language , 3 ) ; } public EnglishConfusionProbabilityRule ( ResourceBundle messages , LanguageModel languageModel , Language language , int grams ) { super ( messages , languageModel , language , grams ) ; addExamplePair ( Example . wrong ( "I didn't <marker>now</marker> where it came from." ) , Example . fixed ( "I didn't <marker>know</marker> where it came from." ) ) ; } @ Override public String getDescription ( ) { return "Statistically detect wrong use of words that are easily confused" ; } @ Override public String getMessage ( String suggestion , String description ) { if ( description != null ) { return "Statistic suggests that '" + suggestion + "' (" + description + ") might be the correct word here. Please check." ; } else { return "Statistic suggests that '" + suggestion + "' might be the correct word here. Please check." ; } } @ Override protected WordTokenizer getTokenizer ( ) { return tokenizer ; } }
package org . languagetool . rules . en ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . language . English ; import org . languagetool . rules . PartialPosTagFilter ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import java . io . IOException ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; public class EnglishPartialPosTagFilter extends PartialPosTagFilter { private final Tagger tagger = new English ( ) . getTagger ( ) ; private final Disambiguator disambiguator = new English ( ) . getDisambiguator ( ) ; @ Override protected List < AnalyzedTokenReadings > tag ( String token ) { try { List < AnalyzedTokenReadings > tags = tagger . tag ( Collections . singletonList ( token ) ) ; AnalyzedTokenReadings [ ] atr = tags . toArray ( new AnalyzedTokenReadings [ tags . size ( ) ] ) ; AnalyzedSentence disambiguated = disambiguator . disambiguate ( new AnalyzedSentence ( atr ) ) ; return Arrays . asList ( disambiguated . getTokens ( ) ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not tag and disambiguate '" + token + "'" , e ) ; } } }
package org . languagetool . rules . en ; import org . languagetool . JLanguageTool ; import java . io . InputStream ; import java . util . * ; final class AvsAnData { private static final Set < String > requiresA = loadWords ( "/en/det_a.txt" ) ; private static final Set < String > requiresAn = loadWords ( "/en/det_an.txt" ) ; private AvsAnData ( ) { } static Set < String > getWordsRequiringA ( ) { return requiresA ; } static Set < String > getWordsRequiringAn ( ) { return requiresAn ; } private static Set < String > loadWords ( String path ) { Set < String > set = new HashSet < > ( ) ; InputStream stream = JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( path ) ; try ( Scanner scanner = new Scanner ( stream , "utf-8" ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) . trim ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } if ( line . charAt ( 0 ) == '*' ) { set . add ( line . substring ( 1 ) ) ; } else { set . add ( line . toLowerCase ( ) ) ; } } } return Collections . unmodifiableSet ( set ) ; } }
package org . languagetool . rules . ca ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . RuleMatch ; public class ComplexAdjectiveConcordanceRule extends CatalanRule { private static final Pattern NOM = Pattern . compile ( "N.*" ) ; private static final Pattern NOM_MS = Pattern . compile ( "N.MS.*" ) ; private static final Pattern NOM_FS = Pattern . compile ( "N.FS.*" ) ; private static final Pattern NOM_MP = Pattern . compile ( "N.MP.*" ) ; private static final Pattern NOM_FP = Pattern . compile ( "N.FP.*" ) ; private static final Pattern NOM_CS = Pattern . compile ( "N.CS.*" ) ; private static final Pattern NOM_CP = Pattern . compile ( "N.CP.*" ) ; private static final Pattern NOM_DET = Pattern . compile ( "N.*|D[NDA0I].*" ) ; private static final Pattern _GN_ = Pattern . compile ( "_GN_.*" ) ; private static final Pattern _GN_MS = Pattern . compile ( "_GN_MS" ) ; private static final Pattern _GN_FS = Pattern . compile ( "_GN_FS" ) ; private static final Pattern _GN_MP = Pattern . compile ( "_GN_MP" ) ; private static final Pattern _GN_FP = Pattern . compile ( "_GN_FP" ) ; private static final Pattern _GN_CS = Pattern . compile ( "_GN_[MF]S" ) ; private static final Pattern _GN_CP = Pattern . compile ( "_GN_[MF]P" ) ; private static final Pattern DET = Pattern . compile ( "D[NDA0IP].*" ) ; private static final Pattern DET_CS = Pattern . compile ( "D[NDA0IP]0CS0" ) ; private static final Pattern DET_MS = Pattern . compile ( "D[NDA0IP]0MS0" ) ; private static final Pattern DET_FS = Pattern . compile ( "D[NDA0IP]0FS0" ) ; private static final Pattern DET_MP = Pattern . compile ( "D[NDA0IP]0MP0" ) ; private static final Pattern DET_FP = Pattern . compile ( "D[NDA0IP]0FP0" ) ; private static final Pattern GN_MS = Pattern . compile ( "N.[MC][SN].*|A..[MC][SN].*|V.P..SM.?|PX.MS.*|D[NDA0I]0MS0" ) ; private static final Pattern GN_FS = Pattern . compile ( "N.[FC][SN].*|A..[FC][SN].*|V.P..SF.?|PX.FS.*|D[NDA0I]0FS0" ) ; private static final Pattern GN_MP = Pattern . compile ( "N.[MC][PN].*|A..[MC][PN].*|V.P..PM.?|PX.MP.*|D[NDA0I]0MP0" ) ; private static final Pattern GN_FP = Pattern . compile ( "N.[FC][PN].*|A..[FC][PN].*|V.P..PF.?|PX.FP.*|D[NDA0I]0FP0" ) ; private static final Pattern GN_CP = Pattern . compile ( "N.[FMC][PN].*|A..[FMC][PN].*|D[NDA0I]0[FM]P0" ) ; private static final Pattern GN_CS = Pattern . compile ( "N.[FMC][SN].*|A..[FMC][SN].*|D[NDA0I]0[FM]S0" ) ; private static final Pattern ADJECTIU = Pattern . compile ( "AQ.*|V.P.*|PX.*|.*LOC_ADJ.*" ) ; private static final Pattern ADJECTIU_MS = Pattern . compile ( "A..[MC][SN].*|V.P..SM.?|PX.MS.*" ) ; private static final Pattern ADJECTIU_FS = Pattern . compile ( "A..[FC][SN].*|V.P..SF.?|PX.FS.*" ) ; private static final Pattern ADJECTIU_MP = Pattern . compile ( "A..[MC][PN].*|V.P..PM.?|PX.MP.*" ) ; private static final Pattern ADJECTIU_FP = Pattern . compile ( "A..[FC][PN].*|V.P..PF.?|PX.FP.*" ) ; private static final Pattern ADJECTIU_CP = Pattern . compile ( "A..C[PN].*" ) ; private static final Pattern ADJECTIU_CS = Pattern . compile ( "A..C[SN].*" ) ; private static final Pattern ADJECTIU_S = Pattern . compile ( "A...[SN].*|V.P..S..?|PX..S.*" ) ; private static final Pattern ADJECTIU_P = Pattern . compile ( "A...[PN].*|V.P..P..?|PX..P.*" ) ; private static final Pattern ADVERBI = Pattern . compile ( "R.|.*LOC_ADV.*" ) ; private static final Pattern CONJUNCIO = Pattern . compile ( "C.|.*LOC_CONJ.*" ) ; private static final Pattern PUNTUACIO = Pattern . compile ( "_PUNCT.*" ) ; private static final Pattern LOC_ADV = Pattern . compile ( ".*LOC_ADV.*" ) ; private static final Pattern ADVERBIS_ACCEPTATS = Pattern . compile ( "RG_anteposat" ) ; private static final Pattern CONCORDA = Pattern . compile ( "_GN_.*|ignore_concordance|AQ.CN." ) ; private static final Pattern UPPERCASE = Pattern . compile ( "\\p{Lu}[\\p{Ll}\u00B7]*" ) ; private static final Pattern COORDINACIO = Pattern . compile ( ",|i|o" ) ; private static final Pattern COORDINACIO_IONI = Pattern . compile ( "i|o|ni" ) ; private static final Pattern KEEP_COUNT = Pattern . compile ( "A.*|N.*|D[NAIDP].*|SPS.*|.*LOC_ADV.*|V.P.*|_PUNCT.*|.*LOC_ADJ.*|PX.*" ) ; private static final Pattern KEEP_COUNT2 = Pattern . compile ( ",|i|o|ni" ) ; private static final Pattern STOP_COUNT = Pattern . compile ( ";" ) ; private static final Pattern PREPOSICIONS = Pattern . compile ( "SPS.*" ) ; private static final Pattern PREPOSICIO_CANVI_NIVELL = Pattern . compile ( "de|d'|en|sobre|a|entre|per|pe|amb|sense|contra" ) ; private static final Pattern VERB = Pattern . compile ( "V.[^P].*|_GV_" ) ; private static final Pattern GV = Pattern . compile ( "_GV_" ) ; private static final Pattern EXCEPCIONS_PARTICIPI = Pattern . compile ( "atès|atés|atesa|atesos|ateses|donat|donats|donada|donades" ) ; private static final Pattern EXCEPCIONS_PREVIA = Pattern . compile ( "termes?|paraul(a|es)|mots?|vocables?|expressi(ó|ons)|noms?|tipus|denominaci(ó|ons)" ) ; private static final Pattern EXCEPCIONS_PREVIA_POSTAG = Pattern . compile ( "_loc_meitat" ) ; private static final Pattern TOPONIM = Pattern . compile ( "NP..G.." ) ; private static final Pattern ORDINAL = Pattern . compile ( "AO.*" ) ; boolean adverbAppeared = false ; boolean conjunctionAppeared = false ; boolean punctuationAppeared = false ; public ComplexAdjectiveConcordanceRule ( ResourceBundle messages ) throws IOException { super . setCategory ( new Category ( "Z) Concordances en grups nominals" ) ) ; setLocQualityIssueType ( ITSIssueType . Grammar ) ; } @ Override public String getId ( ) { return "CONCORDANCES_ADJECTIU_POSPOSAT" ; } @ Override public String getDescription ( ) { return "Comprova si un adjectiu concorda amb els noms previs." ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; goToNextToken : for ( int i = 1 ; i < tokens . length ; i ++ ) { if ( matchPostagRegexp ( tokens [ i ] , ADJECTIU ) && ! matchPostagRegexp ( tokens [ i ] , CONCORDA ) && ! matchPostagRegexp ( tokens [ i ] , GV ) ) { final String token = tokens [ i ] . getToken ( ) ; final String prevToken = tokens [ i - 1 ] . getToken ( ) ; String prevPrevToken = "" ; if ( i > 2 ) { prevPrevToken = tokens [ i - 2 ] . getToken ( ) ; } String nextToken = "" ; if ( i < tokens . length - 1 ) { nextToken = tokens [ i + 1 ] . getToken ( ) ; } int j ; boolean isPlural = true ; boolean isPrevNoun = false ; Pattern substPattern = null ; Pattern gnPattern = null ; Pattern adjPattern = null ; Matcher isUpperCase = UPPERCASE . matcher ( token ) ; if ( prevPrevToken . equals ( "per" ) && prevToken . equals ( "molt" ) ) { continue goToNextToken ; } if ( i < tokens . length - 2 && token . equalsIgnoreCase ( "esquerra" ) && ( nextToken . equals ( "-" ) || nextToken . equals ( "/" ) ) && tokens [ i + 2 ] . getToken ( ) . equalsIgnoreCase ( "dreta" ) ) { continue goToNextToken ; } if ( i < tokens . length - 2 ) { Matcher pCoordina = COORDINACIO . matcher ( nextToken ) ; if ( pCoordina . matches ( ) ) { if ( ( ( matchPostagRegexp ( tokens [ i - 1 ] , NOM_MP ) || matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_MP ) ) && matchPostagRegexp ( tokens [ i ] , ADJECTIU_MS ) && matchPostagRegexp ( tokens [ i + 2 ] , ADJECTIU_MS ) ) || ( ( matchPostagRegexp ( tokens [ i - 1 ] , NOM_MP ) || matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_MP ) ) && matchPostagRegexp ( tokens [ i ] , ADJECTIU_MP ) && matchPostagRegexp ( tokens [ i + 2 ] , ADJECTIU_MP ) ) || ( ( matchPostagRegexp ( tokens [ i - 1 ] , NOM_FP ) || matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_FP ) ) && matchPostagRegexp ( tokens [ i ] , ADJECTIU_FS ) && matchPostagRegexp ( tokens [ i + 2 ] , ADJECTIU_FS ) ) || ( ( matchPostagRegexp ( tokens [ i - 1 ] , NOM_FP ) || matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_FP ) ) && matchPostagRegexp ( tokens [ i ] , ADJECTIU_FP ) && matchPostagRegexp ( tokens [ i + 2 ] , ADJECTIU_FP ) ) ) { continue goToNextToken ; } } } if ( matchRegexp ( prevToken , EXCEPCIONS_PREVIA ) ) { continue goToNextToken ; } if ( matchPostagRegexp ( tokens [ i - 1 ] , EXCEPCIONS_PREVIA_POSTAG ) ) { continue goToNextToken ; } if ( ( ( ( token . equals ( "tret" ) || token . equals ( "llevat" ) ) && ( nextToken . equals ( "de" ) || nextToken . equals ( "que" ) ) ) || token . equals ( "primer" ) || token . equals ( "junts" ) || token . equals ( "plegats" ) || isUpperCase . matches ( ) ) ) { continue goToNextToken ; } if ( matchRegexp ( token , EXCEPCIONS_PARTICIPI ) ) { continue goToNextToken ; } if ( ( ( ( prevPrevToken . equals ( "un" ) || prevPrevToken . equals ( "altre" ) ) && ( prevToken . equals ( "cop" ) || prevToken . equals ( "colp" ) ) ) || ( ( prevPrevToken . equals ( "una" ) || prevPrevToken . equals ( "altra" ) || prevPrevToken . equals ( "aquesta" ) ) && ( prevToken . equals ( "volta" ) || prevToken . equals ( "vegada" ) ) ) ) ) { continue goToNextToken ; } if ( i > 2 && tokens [ i - 2 ] . getToken ( ) . equalsIgnoreCase ( "per" ) && matchPostagRegexp ( tokens [ i - 1 ] , ORDINAL ) && ( prevToken . equals ( "volta" ) || prevToken . equals ( "vegada" ) || prevToken . equals ( "cop" ) || prevToken . equals ( "colp" ) ) ) { continue goToNextToken ; } if ( i < tokens . length - 1 ) { if ( ( token . equals ( "segur" ) || token . equals ( "major" ) || token . equals ( "menor" ) ) && nextToken . equals ( "que" ) ) { continue goToNextToken ; } } if ( token . equals ( "mateix" ) && matchPostagRegexp ( tokens [ i - 1 ] , ADVERBI ) ) { continue goToNextToken ; } if ( token . equals ( "mateix" ) && matchPostagRegexp ( tokens [ i - 1 ] , TOPONIM ) && prevPrevToken . equals ( "a" ) ) { continue goToNextToken ; } int maxLevels = 4 ; int [ ] cNt = new int [ maxLevels ] ; int [ ] cNMS = new int [ maxLevels ] ; int [ ] cNFS = new int [ maxLevels ] ; int [ ] cNMP = new int [ maxLevels ] ; int [ ] cNFP = new int [ maxLevels ] ; int [ ] cNCS = new int [ maxLevels ] ; int [ ] cNCP = new int [ maxLevels ] ; int [ ] cDMS = new int [ maxLevels ] ; int [ ] cDFS = new int [ maxLevels ] ; int [ ] cDMP = new int [ maxLevels ] ; int [ ] cDFP = new int [ maxLevels ] ; int [ ] cN = new int [ maxLevels ] ; int [ ] cD = new int [ maxLevels ] ; int level = 0 ; j = 1 ; initializeApparitions ( ) ; while ( i - j > 0 && keepCounting ( tokens [ i - j ] ) && level < maxLevels ) { if ( ! isPrevNoun ) { if ( matchPostagRegexp ( tokens [ i - j ] , NOM ) || ( i - j - 1 > 0 && ! matchPostagRegexp ( tokens [ i - j ] , NOM ) && matchPostagRegexp ( tokens [ i - j ] , ADJECTIU ) && matchPostagRegexp ( tokens [ i - j - 1 ] , DET ) ) ) { if ( matchPostagRegexp ( tokens [ i - j ] , _GN_MS ) ) { cNMS [ level ] ++ ; } if ( matchPostagRegexp ( tokens [ i - j ] , _GN_FS ) ) { cNFS [ level ] ++ ; } if ( matchPostagRegexp ( tokens [ i - j ] , _GN_MP ) ) { cNMP [ level ] ++ ; } if ( matchPostagRegexp ( tokens [ i - j ] , _GN_FP ) ) { cNFP [ level ] ++ ; } } if ( ! matchPostagRegexp ( tokens [ i - j ] , _GN_ ) ) { if ( matchPostagRegexp ( tokens [ i - j ] , NOM_MS ) ) { cNMS [ level ] ++ ; } else if ( matchPostagRegexp ( tokens [ i - j ] , NOM_FS ) ) { cNFS [ level ] ++ ; } else if ( matchPostagRegexp ( tokens [ i - j ] , NOM_MP ) ) { cNMP [ level ] ++ ; } else if ( matchPostagRegexp ( tokens [ i - j ] , NOM_FP ) ) { cNFP [ level ] ++ ; } else if ( matchPostagRegexp ( tokens [ i - j ] , NOM_CS ) ) { cNCS [ level ] ++ ; } else if ( matchPostagRegexp ( tokens [ i - j ] , NOM_CP ) ) { cNCP [ level ] ++ ; } } } if ( matchPostagRegexp ( tokens [ i - j ] , NOM ) ) { cNt [ level ] ++ ; isPrevNoun = true ; } else { isPrevNoun = false ; } if ( matchPostagRegexp ( tokens [ i - j ] , DET_CS ) ) { if ( matchPostagRegexp ( tokens [ i - j + 1 ] , NOM_MS ) ) { cDMS [ level ] ++ ; } if ( matchPostagRegexp ( tokens [ i - j + 1 ] , NOM_FS ) ) { cDFS [ level ] ++ ; } } if ( ! matchPostagRegexp ( tokens [ i - j ] , ADVERBI ) ) { if ( matchPostagRegexp ( tokens [ i - j ] , DET_MS ) ) { cDMS [ level ] ++ ; } if ( matchPostagRegexp ( tokens [ i - j ] , DET_FS ) ) { cDFS [ level ] ++ ; } if ( matchPostagRegexp ( tokens [ i - j ] , DET_MP ) ) { cDMP [ level ] ++ ; } if ( matchPostagRegexp ( tokens [ i - j ] , DET_FP ) ) { cDFP [ level ] ++ ; } } if ( i - j > 0 ) { if ( matchRegexp ( tokens [ i - j ] . getToken ( ) , PREPOSICIO_CANVI_NIVELL ) && ! matchRegexp ( tokens [ i - j - 1 ] . getToken ( ) , COORDINACIO_IONI ) && ! matchPostagRegexp ( tokens [ i - j + 1 ] , ADVERBI ) ) { level ++ ; } } if ( level > 0 && matchRegexp ( tokens [ i - j ] . getToken ( ) , COORDINACIO_IONI ) ) { int k = 1 ; while ( k < 4 && i - j - k > 0 && ( matchPostagRegexp ( tokens [ i - j - k ] , KEEP_COUNT ) || matchRegexp ( tokens [ i - j - k ] . getToken ( ) , KEEP_COUNT2 ) || matchPostagRegexp ( tokens [ i - j - k ] , ADVERBIS_ACCEPTATS ) ) && ( ! matchRegexp ( tokens [ i - j - k ] . getToken ( ) , STOP_COUNT ) ) ) { if ( matchPostagRegexp ( tokens [ i - j - k ] , PREPOSICIONS ) ) { j = j + k ; break ; } k ++ ; } } updateApparitions ( tokens [ i - j ] ) ; j ++ ; } level ++ ; if ( level > maxLevels ) { level = maxLevels ; } j = 0 ; int cNtotal = 0 ; int cDtotal = 0 ; while ( j < level ) { cN [ j ] = cNMS [ j ] + cNFS [ j ] + cNMP [ j ] + cNFP [ j ] + cNCS [ j ] + cNCP [ j ] ; cD [ j ] = cDMS [ j ] + cDFS [ j ] + cDMP [ j ] + cDFP [ j ] ; cNtotal += cN [ j ] ; cDtotal += cD [ j ] ; if ( matchPostagRegexp ( tokens [ i ] , ADJECTIU_MP ) && ( cN [ j ] > 1 || cD [ j ] > 1 ) && ( cNMS [ j ] + cNMP [ j ] + cNCS [ j ] + cNCP [ j ] + cDMS [ j ] + cDMP [ j ] ) > 0 && ( cNFS [ j ] + cNFP [ j ] <= cNt [ j ] ) ) { continue goToNextToken ; } if ( matchPostagRegexp ( tokens [ i ] , ADJECTIU_FP ) && ( cN [ j ] > 1 || cD [ j ] > 1 ) && ( ( cNMS [ j ] + cNMP [ j ] + cDMS [ j ] + cDMP [ j ] ) == 0 || ( cNt [ j ] > 0 && cNFS [ j ] + cNFP [ j ] >= cNt [ j ] ) ) ) { continue goToNextToken ; } if ( cN [ j ] + cD [ j ] > 0 ) { isPlural = isPlural && cD [ j ] > 1 ; } j ++ ; } if ( cNtotal == 0 && cDtotal == 0 ) { continue goToNextToken ; } if ( matchPostagRegexp ( tokens [ i ] , ADJECTIU_CS ) ) { substPattern = GN_CS ; adjPattern = ADJECTIU_S ; gnPattern = _GN_CS ; } else if ( matchPostagRegexp ( tokens [ i ] , ADJECTIU_CP ) ) { substPattern = GN_CP ; adjPattern = ADJECTIU_P ; gnPattern = _GN_CP ; } else if ( matchPostagRegexp ( tokens [ i ] , ADJECTIU_MS ) ) { substPattern = GN_MS ; adjPattern = ADJECTIU_MS ; gnPattern = _GN_MS ; } else if ( matchPostagRegexp ( tokens [ i ] , ADJECTIU_FS ) ) { substPattern = GN_FS ; adjPattern = ADJECTIU_FS ; gnPattern = _GN_FS ; } else if ( matchPostagRegexp ( tokens [ i ] , ADJECTIU_MP ) ) { substPattern = GN_MP ; adjPattern = ADJECTIU_MP ; gnPattern = _GN_MP ; } else if ( matchPostagRegexp ( tokens [ i ] , ADJECTIU_FP ) ) { substPattern = GN_FP ; adjPattern = ADJECTIU_FP ; gnPattern = _GN_FP ; } if ( substPattern == null || gnPattern == null || adjPattern == null ) { continue goToNextToken ; } j = 1 ; boolean keepCount = true ; while ( i - j > 0 && keepCount ) { if ( matchPostagRegexp ( tokens [ i - j ] , NOM_DET ) && matchPostagRegexp ( tokens [ i - j ] , gnPattern ) ) { continue goToNextToken ; } else if ( ! matchPostagRegexp ( tokens [ i - j ] , _GN_ ) && matchPostagRegexp ( tokens [ i - j ] , substPattern ) ) { continue goToNextToken ; } keepCount = ! matchPostagRegexp ( tokens [ i - j ] , NOM_DET ) ; j ++ ; } if ( ( matchPostagRegexp ( tokens [ i - 1 ] , NOM ) && ! matchPostagRegexp ( tokens [ i - 1 ] , substPattern ) ) || ( matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU ) && ! matchPostagRegexp ( tokens [ i - 1 ] , gnPattern ) ) || ( matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU ) && ! matchPostagRegexp ( tokens [ i - 1 ] , adjPattern ) ) || ( i > 2 && matchPostagRegexp ( tokens [ i - 1 ] , ADVERBIS_ACCEPTATS ) && ! matchPostagRegexp ( tokens [ i - 2 ] , VERB ) && ! matchPostagRegexp ( tokens [ i - 2 ] , PREPOSICIONS ) ) || ( i > 3 && matchPostagRegexp ( tokens [ i - 1 ] , LOC_ADV ) && matchPostagRegexp ( tokens [ i - 2 ] , LOC_ADV ) && ! matchPostagRegexp ( tokens [ i - 3 ] , VERB ) && ! matchPostagRegexp ( tokens [ i - 3 ] , PREPOSICIONS ) ) ) { } else { continue goToNextToken ; } if ( ! ( isPlural && matchPostagRegexp ( tokens [ i ] , ADJECTIU_S ) ) ) { j = 1 ; initializeApparitions ( ) ; while ( i - j > 0 && keepCounting ( tokens [ i - j ] ) ) { if ( ! matchPostagRegexp ( tokens [ i - j ] , _GN_ ) && matchPostagRegexp ( tokens [ i - j ] , NOM_DET ) && matchPostagRegexp ( tokens [ i - j ] , substPattern ) ) { continue goToNextToken ; } else if ( matchPostagRegexp ( tokens [ i - j ] , gnPattern ) ) { continue goToNextToken ; } updateApparitions ( tokens [ i - j ] ) ; j ++ ; } } final String msg = "Reviseu la concordança de la paraula \u00AB" + token + "\u00BB." ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ i ] . getStartPos ( ) , tokens [ i ] . getEndPos ( ) , msg , "Reviseu la concordança." ) ; ruleMatches . add ( ruleMatch ) ; } } return toRuleMatchArray ( ruleMatches ) ; } private boolean keepCounting ( AnalyzedTokenReadings aTr ) { if ( ( adverbAppeared && conjunctionAppeared ) || ( adverbAppeared && punctuationAppeared ) || ( conjunctionAppeared && punctuationAppeared ) || ( punctuationAppeared && matchPostagRegexp ( aTr , PUNTUACIO ) ) ) { return false ; } return ( matchPostagRegexp ( aTr , KEEP_COUNT ) || matchRegexp ( aTr . getToken ( ) , KEEP_COUNT2 ) || matchPostagRegexp ( aTr , ADVERBIS_ACCEPTATS ) ) && ! matchRegexp ( aTr . getToken ( ) , STOP_COUNT ) && ( ! matchPostagRegexp ( aTr , GV ) || matchPostagRegexp ( aTr , _GN_ ) ) ; } private void initializeApparitions ( ) { adverbAppeared = false ; conjunctionAppeared = false ; punctuationAppeared = false ; } private void updateApparitions ( AnalyzedTokenReadings aTr ) { if ( matchPostagRegexp ( aTr , NOM ) || matchPostagRegexp ( aTr , ADJECTIU ) ) { initializeApparitions ( ) ; return ; } adverbAppeared |= matchPostagRegexp ( aTr , ADVERBI ) ; conjunctionAppeared |= matchPostagRegexp ( aTr , CONJUNCIO ) ; punctuationAppeared |= matchPostagRegexp ( aTr , PUNTUACIO ) ; } private boolean matchPostagRegexp ( AnalyzedTokenReadings aToken , Pattern pattern ) { boolean matches = false ; for ( AnalyzedToken analyzedToken : aToken ) { final String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag != null ) { final Matcher m = pattern . matcher ( posTag ) ; if ( m . matches ( ) ) { matches = true ; break ; } } } return matches ; } private boolean matchRegexp ( String s , Pattern pattern ) { final Matcher m = pattern . matcher ( s ) ; return m . matches ( ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . en ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . AbstractSimpleReplaceRule ; import org . languagetool . rules . Example ; import org . languagetool . rules . ITSIssueType ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; public class BritishReplaceRule extends AbstractSimpleReplaceRule { public static final String BRITISH_SIMPLE_REPLACE_RULE = "EN_GB_SIMPLE_REPLACE" ; private static final Map < String , List < String > > wrongWords = load ( "/en/en-GB/replace.txt" ) ; private static final Locale EN_GB_LOCALE = new Locale ( "en-GB" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public BritishReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; setLocQualityIssueType ( ITSIssueType . LocaleViolation ) ; addExamplePair ( Example . wrong ( "Where's the <marker>bathroom</marker> on the Enterprise?" ) , Example . fixed ( "Where's the <marker>toilet</marker> on the Enterprise?" ) ) ; } @ Override public final String getId ( ) { return BRITISH_SIMPLE_REPLACE_RULE ; } @ Override public String getDescription ( ) { return "American words easily confused in British English" ; } @ Override public String getShort ( ) { return "American word" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return tokenStr + " is a common American expression, in British English it is more common to use: " + StringUtils . join ( replacements , ", " ) + "." ; } @ Override public boolean isCaseSensitive ( ) { return false ; } @ Override public Locale getLocale ( ) { return EN_GB_LOCALE ; } }
package org . languagetool . rules . en ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; public final class MorfologikNewZealandSpellerRule extends AbstractEnglishSpellerRule { private static final String RESOURCE_FILENAME = "/en/hunspell/en_NZ.dict" ; public MorfologikNewZealandSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_EN_NZ" ; } }
package org . languagetool . rules . en ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; public final class MorfologikAmericanSpellerRule extends AbstractEnglishSpellerRule { public static final String RULE_ID = "MORFOLOGIK_RULE_EN_US" ; private static final String RESOURCE_FILENAME = "/en/hunspell/en_US.dict" ; public MorfologikAmericanSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return RULE_ID ; } }
package org . languagetool . rules . en ; import org . languagetool . rules . AbstractDateCheckFilter ; import java . util . Calendar ; import java . util . Locale ; public class DateCheckFilter extends AbstractDateCheckFilter { @ Override protected Calendar getCalendar ( ) { return Calendar . getInstance ( Locale . UK ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfWeek ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . startsWith ( "su" ) ) return Calendar . SUNDAY ; if ( day . startsWith ( "mo" ) ) return Calendar . MONDAY ; if ( day . startsWith ( "tu" ) ) return Calendar . TUESDAY ; if ( day . startsWith ( "we" ) ) return Calendar . WEDNESDAY ; if ( day . startsWith ( "th" ) ) return Calendar . THURSDAY ; if ( day . startsWith ( "fr" ) ) return Calendar . FRIDAY ; if ( day . startsWith ( "sa" ) ) return Calendar . SATURDAY ; throw new RuntimeException ( "Could not find day of week for '" + dayStr + "'" ) ; } @ Override protected String getDayOfWeek ( Calendar date ) { return date . getDisplayName ( Calendar . DAY_OF_WEEK , Calendar . LONG , Locale . UK ) ; } @ SuppressWarnings ( { "ControlFlowStatementWithoutBraces" , "MagicNumber" } ) @ Override protected int getMonth ( String monthStr ) { String mon = monthStr . toLowerCase ( ) ; if ( mon . startsWith ( "jan" ) ) return 1 ; if ( mon . startsWith ( "feb" ) ) return 2 ; if ( mon . startsWith ( "mar" ) ) return 3 ; if ( mon . startsWith ( "apr" ) ) return 4 ; if ( mon . startsWith ( "may" ) ) return 5 ; if ( mon . startsWith ( "jun" ) ) return 6 ; if ( mon . startsWith ( "jul" ) ) return 7 ; if ( mon . startsWith ( "aug" ) ) return 8 ; if ( mon . startsWith ( "sep" ) ) return 9 ; if ( mon . startsWith ( "oct" ) ) return 10 ; if ( mon . startsWith ( "nov" ) ) return 11 ; if ( mon . startsWith ( "dec" ) ) return 12 ; throw new RuntimeException ( "Could not find month '" + monthStr + "'" ) ; } }
package org . languagetool . tagging . en ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class EnglishTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/en/added.txt" ; } public EnglishTagger ( ) { super ( "/en/english.dict" , Locale . ENGLISH ) ; } }
package org . languagetool . tokenizers . en ; import java . util . ArrayList ; import java . util . List ; import java . util . StringTokenizer ; import org . languagetool . tokenizers . WordTokenizer ; public class EnglishWordTokenizer extends WordTokenizer { public EnglishWordTokenizer ( ) { } @ Override public String getTokenizingCharacters ( ) { return super . getTokenizingCharacters ( ) + "–" ; } @ Override public List < String > tokenize ( final String text ) { final List < String > l = new ArrayList < > ( ) ; final StringTokenizer st = new StringTokenizer ( text , getTokenizingCharacters ( ) , true ) ; while ( st . hasMoreElements ( ) ) { final String token = st . nextToken ( ) ; if ( token . length ( ) > 1 && token . endsWith ( "-" ) ) { l . add ( token . substring ( 0 , token . length ( ) - 1 ) ) ; l . add ( "-" ) ; } else { l . add ( token ) ; } } return joinUrls ( l ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Galician ; public class GalicianConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Galician ( ) ; } @ Override protected String createSampleText ( ) { return "Olle as páxinas da Galipedia que ligan con este título." ; } }
package org . languagetool . rules . gl ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class GalicianPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . tagging . gl ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . tokenizers . WordTokenizer ; public class GalicianTaggerTest extends TestCase { private GalicianTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new GalicianTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "Todo vai mudar" , "Todo/[todo]DI0MS0|Todo/[todo]PI0MS000 -- vai/[ir]VMIP3S0|vai/[ir]VMM02S0 -- mudar/[mudar]VMN0000|mudar/[mudar]VMN01S0|mudar/[mudar]VMN03S0|mudar/[mudar]VMSF1S0|mudar/[mudar]VMSF3S0" , tokenizer , tagger ) ; TestTools . myAssert ( "Se aínda somos galegos é por obra e graza do idioma" , "Se/[se]CS|Se/[se]PP3PN000|Se/[se]PP3SN000 -- aínda/[aínda]CS|aínda/[aínda]RG -- somos/[ser]VSIP1P0 -- galegos/[galego]AQ0MP0|galegos/[galego]NCMP000 -- é/[ser]VSIP3S0 -- por/[por]SPS00 -- obra/[obra]NCFS000|obra/[obrar]VMIP3S0|obra/[obrar]VMM02S0 -- e/[e]CC|e/[e]NCMS000 -- graza/[graza]NCFS000 -- do/[de]SPS00:DA -- idioma/[idioma]NCMS000" , tokenizer , tagger ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . gl . CastWordsRule ; import org . languagetool . rules . gl . SimpleReplaceRule ; import org . languagetool . rules . spelling . hunspell . HunspellRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . gl . GalicianSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . gl . GalicianTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . gl . GalicianWordTokenizer ; public class Galician extends Language { private Tagger tagger ; private Tokenizer wordTokenizer ; private SentenceTokenizer sentenceTokenizer ; private Synthesizer synthesizer ; private Disambiguator disambiguator ; @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public String getName ( ) { return "Galician" ; } @ Override public String getShortName ( ) { return "gl" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "ES" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new GalicianTagger ( ) ; } return tagger ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new GalicianWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new GalicianSynthesizer ( ) ; } return synthesizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new XmlRuleDisambiguator ( new Galician ( ) ) ; } return disambiguator ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Susana Sotelo Docío" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages , Arrays . asList ( "[" , "(" , "{" , "“" , "«" , "»" , "‘" , "\"" , "'" ) , Arrays . asList ( "]" , ")" , "}" , "”" , "»" , "«" , "’" , "\"" , "'" ) ) , new HunspellRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new SimpleReplaceRule ( messages ) , new CastWordsRule ( messages ) ) ; } }
package org . languagetool . rules . ca ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . GenericUnpairedBracketsRule ; public class CatalanUnpairedBracketsRule extends GenericUnpairedBracketsRule { private static final List < String > CA_START_SYMBOLS = Arrays . asList ( "[" , "(" , "{" , "“" , "«" , "\"" , "'" , "‘" ) ; private static final List < String > CA_END_SYMBOLS = Arrays . asList ( "]" , ")" , "}" , "”" , "»" , "\"" , "'" , "’" ) ; private static final Pattern VALID_BEFORE_CLOSING_PARENTHESIS = Pattern . compile ( "\\d+|[a-zA-Z]" , Pattern . UNICODE_CASE ) ; private static final Pattern NUMBER = Pattern . compile ( "\\d[\\d., ]+\\d|\\d{1,2}" , Pattern . UNICODE_CASE ) ; public CatalanUnpairedBracketsRule ( final ResourceBundle messages , final Language language ) { super ( messages , CA_START_SYMBOLS , CA_END_SYMBOLS ) ; } @ Override public String getId ( ) { return "CA_UNPAIRED_BRACKETS" ; } @ Override protected boolean isNoException ( final String tokenStr , final AnalyzedTokenReadings [ ] tokens , final int i , final int j , final boolean precSpace , final boolean follSpace ) { if ( i < 1 ) { return true ; } final boolean superException = ! super . isNoException ( tokenStr , tokens , i , j , precSpace , follSpace ) ; if ( superException ) { return false ; } if ( ( "\"" . equals ( tokenStr ) || "'" . equals ( tokenStr ) ) && NUMBER . matcher ( tokens [ i - 1 ] . getToken ( ) ) . matches ( ) && ! tokens [ i ] . isWhitespaceBefore ( ) && ( ( i > 2 && ( tokens [ i - 2 ] . getToken ( ) . contains ( "º" ) || tokens [ i - 2 ] . getToken ( ) . contains ( "°" ) ) ) || ( i > 4 && ( tokens [ i - 4 ] . getToken ( ) . contains ( "º" ) || tokens [ i - 4 ] . getToken ( ) . contains ( "°" ) ) ) ) ) { return false ; } if ( i == 1 && tokenStr . equals ( "»" ) ) return false ; if ( i > 1 && tokenStr . equals ( ")" ) ) { boolean isThereOpeningParenthesis = false ; int k = 1 ; while ( i - k > 0 ) { if ( tokens [ i - k ] . getToken ( ) . equals ( ")" ) ) break ; if ( tokens [ i - k ] . getToken ( ) . equals ( "(" ) ) { isThereOpeningParenthesis = true ; break ; } k ++ ; } if ( ! isThereOpeningParenthesis ) { final Matcher mValidBeforeClosingParenthesis = VALID_BEFORE_CLOSING_PARENTHESIS . matcher ( tokens [ i - 1 ] . getToken ( ) ) ; if ( mValidBeforeClosingParenthesis . matches ( ) ) return false ; } } return true ; } }
package org . languagetool . synthesis . gl ; import org . languagetool . synthesis . BaseSynthesizer ; public class GalicianSynthesizer extends BaseSynthesizer { private static final String RESOURCE_FILENAME = "/gl/galician_synth.dict" ; private static final String TAGS_FILE_NAME = "/gl/galician_tags.txt" ; public GalicianSynthesizer ( ) { super ( RESOURCE_FILENAME , TAGS_FILE_NAME ) ; } }
package org . languagetool . rules . gl ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . AbstractSimpleReplaceRule ; public class SimpleReplaceRule extends AbstractSimpleReplaceRule { public static final String GL_SIMPLE_REPLACE_RULE = "GL_SIMPLE_REPLACE" ; private static final Map < String , List < String > > wrongWords = load ( "/gl/words.txt" ) ; private static final Locale GL_LOCALE = new Locale ( "gl" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public SimpleReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; } @ Override public final String getId ( ) { return GL_SIMPLE_REPLACE_RULE ; } @ Override public String getDescription ( ) { return "Corrección de erros léxicos (barbarismos)." ; } @ Override public String getShort ( ) { return "Erros léxicos" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return tokenStr + " non existe en galego. Talvez quería vostede dicir: " + StringUtils . join ( replacements , ", " ) + "." ; } @ Override public boolean isCaseSensitive ( ) { return false ; } @ Override public Locale getLocale ( ) { return GL_LOCALE ; } }
package org . languagetool . rules . gl ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . AbstractSimpleReplaceRule ; public class CastWordsRule extends AbstractSimpleReplaceRule { public static final String GL_CAST_WORDS_RULE = "GL_CAST_WORDS" ; private static final Map < String , List < String > > wrongWords = load ( "/gl/spanish.txt" ) ; private static final Locale GL_LOCALE = new Locale ( "gl" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public CastWordsRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; } @ Override public final String getId ( ) { return GL_CAST_WORDS_RULE ; } @ Override public String getDescription ( ) { return "Corrección de erros léxicos (castelanismos)." ; } @ Override public String getShort ( ) { return "Castelanismos léxicos" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return tokenStr + " é un castelanismo. Empregue no seu sitio: " + StringUtils . join ( replacements , ", " ) + "." ; } @ Override public boolean isCaseSensitive ( ) { return false ; } @ Override public Locale getLocale ( ) { return GL_LOCALE ; } }
package org . languagetool . tagging . gl ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class GalicianTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/gl/added.txt" ; } public GalicianTagger ( ) { super ( "/gl/galician.dict" , new Locale ( "gl" ) ) ; } }
package org . languagetool . tokenizers . gl ; import java . util . ArrayList ; import java . util . List ; import java . util . StringTokenizer ; import org . languagetool . tokenizers . Tokenizer ; public class GalicianWordTokenizer implements Tokenizer { public GalicianWordTokenizer ( ) { } @ Override public List < String > tokenize ( final String text ) { final List < String > tokens = new ArrayList < > ( ) ; final StringTokenizer st = new StringTokenizer ( text , "\u0020\u00A0\u115f\u1160\u1680" + "\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007\u2008" + "\u2009\u2013\u2014\u2015\u200A\u200B\u200c\u200d\u200e" + "\u200f\u2028\u2029\u202a\u202b\u202c\u202d\u202e\u202f" + "\u205F\u2060\u2061\u2062\u2063\u206A\u206b\u206c\u206d" + "\u206E\u206F\u3000\u3164\ufeff\uffa0\ufff9\ufffa\ufffb" + ",.;<>()[]{}¿¡!?:\"«»`'’‘„“”…\\/\t\r\n" , true ) ; while ( st . hasMoreElements ( ) ) { tokens . add ( st . nextToken ( ) ) ; } return tokens ; } }
package org . languagetool . rules . ta ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class TamilPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . language ; import org . languagetool . Language ; import org . languagetool . language . tagging . TamilTagger ; import org . languagetool . rules . * ; import org . languagetool . tagging . Tagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; public class Tamil extends Language { private SentenceTokenizer sentenceTokenizer ; private Tagger tagger ; @ Override public String getName ( ) { return "Tamil" ; } @ Override public String getShortName ( ) { return "ta" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "IN" } ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new TamilTagger ( ) ; } return tagger ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Elanjelian Venugopal" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new MultipleWhitespaceRule ( messages , this ) , new LongSentenceRule ( messages ) , new SentenceWhitespaceRule ( messages ) ) ; } }
package org . languagetool . language . tagging ; import org . languagetool . tagging . BaseTagger ; public class TamilTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/ta/added.txt" ; } public TamilTagger ( ) { super ( "/ta/tamil.dict" ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Chinese ; public class ChineseConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Chinese ( ) ; } @ Override protected String createSampleText ( ) { return "维基百科，自由的百科全书" ; } }
package org . languagetool . rules . zh ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class ChinesePatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . ca ; import java . io . IOException ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . HashMap ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; import java . util . Scanner ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . synthesis . ca . CatalanSynthesizer ; import org . languagetool . tagging . ca . CatalanTagger ; import org . languagetool . tools . StringTools ; public class SimpleReplaceVerbsRule extends Rule { private static final String FILE_NAME = "/ca/replace_verbs.txt" ; private static final Locale CA_LOCALE = new Locale ( "CA" ) ; private static final String FILE_ENCODING = "utf-8" ; protected final Map < String , List < String > > wrongWords ; protected boolean ignoreTaggedWords = true ; private static final Pattern [ ] desinencies_1conj = new Pattern [ 2 ] ; private final CatalanTagger tagger ; private final CatalanSynthesizer synth ; public final String getFileName ( ) { return FILE_NAME ; } public String getEncoding ( ) { return FILE_ENCODING ; } public SimpleReplaceVerbsRule ( final ResourceBundle messages ) throws IOException { super . setLocQualityIssueType ( ITSIssueType . Misspelling ) ; super . setCategory ( new Category ( "Errors ortogràfics" ) ) ; wrongWords = loadWords ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( getFileName ( ) ) ) ; tagger = new CatalanTagger ( ) ; synth = new CatalanSynthesizer ( ) ; desinencies_1conj [ 0 ] = Pattern . compile ( "(.+?)(a|à|ada|ades|am|ant|ar|ara|arà|aran|aràs|aré|arem|àrem|aren|ares|areu|àreu|aria|aríem|arien|aries|aríeu|às|àssem|assen|asses|àsseu|àssim|assin|assis|àssiu|at|ats|au|ava|àvem|aven|aves|àveu|e|em|en|es|és|éssem|essen|esses|ésseu|éssim|essin|essis|éssiu|eu|i|í|in|is|o|ïs)" ) ; desinencies_1conj [ 1 ] = Pattern . compile ( "(.+)(a|à|ada|ades|am|ant|ar|ara|arà|aran|aràs|aré|arem|àrem|aren|ares|areu|àreu|aria|aríem|arien|aries|aríeu|às|àssem|assen|asses|àsseu|àssim|assin|assis|àssiu|at|ats|au|ava|àvem|aven|aves|àveu|e|em|en|es|és|éssem|essen|esses|ésseu|éssim|essin|essis|éssiu|eu|i|í|in|is|o|ïs)" ) ; } @ Override public final String getId ( ) { return "CA_SIMPLE_REPLACE_VERBS" ; } @ Override public String getDescription ( ) { return "Detecta verbs incorrectes i proposa suggeriments de canvi" ; } public String getShort ( ) { return "Verb incorrecte" ; } public String getMessage ( String tokenStr , List < String > replacements ) { return "Verb incorrecte." ; } public Locale getLocale ( ) { return CA_LOCALE ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) throws IOException { List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; for ( AnalyzedTokenReadings tokenReadings : tokens ) { String originalTokenStr = tokenReadings . getToken ( ) ; if ( ignoreTaggedWords && tokenReadings . isTagged ( ) ) { continue ; } String tokenString = originalTokenStr . toLowerCase ( getLocale ( ) ) ; AnalyzedTokenReadings analyzedTokenReadings = null ; String infinitive = null ; int i = 0 ; while ( i < 2 && analyzedTokenReadings == null ) { Matcher m = desinencies_1conj [ i ] . matcher ( tokenString ) ; if ( m . matches ( ) ) { String lexeme = m . group ( 1 ) ; String desinence = m . group ( 2 ) ; if ( desinence . startsWith ( "e" ) || desinence . startsWith ( "é" ) || desinence . startsWith ( "i" ) || desinence . startsWith ( "ï" ) ) { if ( lexeme . endsWith ( "c" ) ) { lexeme = lexeme . substring ( 0 , lexeme . length ( ) - 1 ) . concat ( "ç" ) ; } else if ( lexeme . endsWith ( "qu" ) ) { lexeme = lexeme . substring ( 0 , lexeme . length ( ) - 2 ) . concat ( "c" ) ; } else if ( lexeme . endsWith ( "g" ) ) { lexeme = lexeme . substring ( 0 , lexeme . length ( ) - 1 ) . concat ( "j" ) ; } else if ( lexeme . endsWith ( "gü" ) ) { lexeme = lexeme . substring ( 0 , lexeme . length ( ) - 2 ) . concat ( "gu" ) ; } else if ( lexeme . endsWith ( "gu" ) ) { lexeme = lexeme . substring ( 0 , lexeme . length ( ) - 2 ) . concat ( "g" ) ; } } if ( desinence . startsWith ( "ï" ) ) { desinence = "i" + desinence . substring ( 1 , desinence . length ( ) ) ; } infinitive = lexeme . concat ( "ar" ) ; if ( wrongWords . containsKey ( infinitive ) ) { List < String > wordAsArray = Arrays . asList ( "cant" . concat ( desinence ) ) ; List < AnalyzedTokenReadings > analyzedTokenReadingsList = tagger . tag ( wordAsArray ) ; if ( analyzedTokenReadingsList != null ) { analyzedTokenReadings = analyzedTokenReadingsList . get ( 0 ) ; } } } i ++ ; } if ( analyzedTokenReadings != null ) { List < String > possibleReplacements = new ArrayList < > ( ) ; String [ ] synthesized = null ; List < String > replacementInfinitives = wrongWords . get ( infinitive ) ; for ( String replacementInfinitive : replacementInfinitives ) { if ( replacementInfinitive . startsWith ( "(" ) ) { possibleReplacements . add ( replacementInfinitive ) ; } else { String [ ] parts = replacementInfinitive . split ( " " ) ; AnalyzedToken infinitiveAsAnTkn = new AnalyzedToken ( parts [ 0 ] , "V.*" , parts [ 0 ] ) ; for ( AnalyzedToken analyzedToken : analyzedTokenReadings ) { synthesized = synth . synthesize ( infinitiveAsAnTkn , analyzedToken . getPOSTag ( ) ) ; for ( String s : synthesized ) { for ( int j = 1 ; j < parts . length ; j ++ ) { s = s . concat ( " " ) . concat ( parts [ j ] ) ; } if ( ! possibleReplacements . contains ( s ) ) { possibleReplacements . add ( s ) ; } } } } } if ( possibleReplacements . size ( ) > 0 ) { RuleMatch potentialRuleMatch = createRuleMatch ( tokenReadings , possibleReplacements ) ; ruleMatches . add ( potentialRuleMatch ) ; } } } return toRuleMatchArray ( ruleMatches ) ; } private RuleMatch createRuleMatch ( AnalyzedTokenReadings tokenReadings , List < String > replacements ) { String tokenString = tokenReadings . getToken ( ) ; int pos = tokenReadings . getStartPos ( ) ; RuleMatch potentialRuleMatch = new RuleMatch ( this , pos , pos + tokenString . length ( ) , getMessage ( tokenString , replacements ) , getShort ( ) ) ; if ( StringTools . startsWithUppercase ( tokenString ) ) { for ( int i = 0 ; i < replacements . size ( ) ; i ++ ) { replacements . set ( i , StringTools . uppercaseFirstChar ( replacements . get ( i ) ) ) ; } } potentialRuleMatch . setSuggestedReplacements ( replacements ) ; return potentialRuleMatch ; } private Map < String , List < String > > loadWords ( final InputStream stream ) throws IOException { Map < String , List < String > > map = new HashMap < > ( ) ; try ( Scanner scanner = new Scanner ( stream , getEncoding ( ) ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } String [ ] parts = line . split ( "=" ) ; if ( parts . length != 2 ) { throw new IOException ( "Format error in file " + JLanguageTool . getDataBroker ( ) . getFromRulesDirAsUrl ( getFileName ( ) ) + ", line: " + line ) ; } String [ ] replacements = parts [ 1 ] . split ( "\\|" ) ; final String [ ] wrongForms = parts [ 0 ] . split ( "\\|" ) ; for ( String wrongForm : wrongForms ) { map . put ( wrongForm , Arrays . asList ( replacements ) ) ; } } } return map ; } @ Override public void reset ( ) { } }
package org . languagetool . tagging . zh ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . tokenizers . zh . ChineseWordTokenizer ; public class ChineseTaggerTest extends TestCase { private ChineseTagger tagger ; private ChineseWordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new ChineseTagger ( ) ; tokenizer = new ChineseWordTokenizer ( ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "主任强调指出错误的地方。" , "主任/[null]n -- 强调/[null]vd -- 指出/[null]v -- 错误/[null]a -- 的/[null]u -- 地方/[null]n -- 。/[null]w" , tokenizer , tagger ) ; TestTools . myAssert ( "她胸前挂着一块碧绿的玉。" , "她/[null]r -- 胸前/[null]s -- 挂/[null]v -- 着/[null]u -- 一/[null]m -- 块/[null]q -- 碧绿/[null]z -- 的/[null]u -- 玉/[null]n -- 。/[null]w" , tokenizer , tagger ) ; TestTools . myAssert ( "“鲯鳅”的研究结果有什么奥妙？" , "“/[null]w -- 鲯/[null]x -- 鳅/[null]x -- ”/[null]w -- 的/[null]u -- 研究/[null]vn -- 结果/[null]n -- 有/[null]v -- 什么/[null]r -- 奥妙/[null]an -- ？/[null]w" , tokenizer , tagger ) ; TestTools . myAssert ( "我们的女组长真是尺竿头更进一步。" , "我们/[null]r -- 的/[null]u -- 女/[null]b -- 组长/[null]n -- 真/[null]d -- 是/[null]v -- 尺/[null]ng -- 竿/[null]ng -- 头/[null]n -- 更进一步/[null]l -- 。/[null]w" , tokenizer , tagger ) ; TestTools . myAssert ( "国务院，非国家工作人员不能随便进去的地方。" , "国务院/[null]nt -- ，/[null]w -- 非/[null]h -- 国家/[null]n -- 工作/[null]vn -- 人员/[null]n -- 不能/[null]v -- 随便/[null]ad -- 进去/[null]v -- 的/[null]u -- 地方/[null]n -- 。/[null]w" , tokenizer , tagger ) ; TestTools . myAssert ( "“哇……”珠海北师大操场上的师生大吃一惊！" , "“/[null]w -- 哇/[null]y -- …/[null]w -- …/[null]w -- ”/[null]w -- 珠海/[null]ns -- 北师大/[null]j -- 操场/[null]n -- 上/[null]f -- 的/[null]u -- 师生/[null]n -- 大吃一惊/[null]i -- ！/[null]w" , tokenizer , tagger ) ; TestTools . myAssert ( "在炎热的暑假里，我和其他同学们参加了姜老师的一个项目。" , "在/[null]p -- 炎热/[null]a -- 的/[null]u -- 暑假/[null]t -- 里/[null]f -- ，/[null]w -- 我/[null]r -- 和/[null]c -- 其他/[null]r -- 同学/[null]n -- 们/[null]k -- 参加/[null]v -- 了/[null]u -- 姜/[null]n -- 老师/[null]n -- 的/[null]u -- 一个/[null]m -- 项目/[null]n -- 。/[null]w" , tokenizer , tagger ) ; TestTools . myAssert ( "“咕咚，”一台联想ThinkPad T系列电脑从关羽的宿舍飞了下来。" , "“/[null]w -- 咕咚/[null]o -- ，/[null]w -- ”/[null]w -- 一/[null]m -- 台/[null]q -- 联想/[null]nz -- ThinkPad/[null]nx -- T/[null]nx -- 系列/[null]q -- 电脑/[null]n -- 从/[null]p -- 关羽/[null]nr -- 的/[null]u -- 宿舍/[null]n -- 飞/[null]v -- 了/[null]u -- 下来/[null]v -- 。/[null]w" , tokenizer , tagger ) ; } }
package org . languagetool . tokenizers . zh ; import java . util . List ; import junit . framework . TestCase ; public class ChineseWordTokenizerTest extends TestCase { public void testTokenize ( ) { ChineseWordTokenizer wordTokenizer = new ChineseWordTokenizer ( ) ; List < String > tokens = wordTokenizer . tokenize ( "主任强调指出错误的地方。" ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[主任/n, 强调/vd, 指出/v, 错误/a, 的/u, 地方/n, 。/w]" , tokens . toString ( ) ) ; List < String > tokens2 = wordTokenizer . tokenize ( "她胸前挂着一块碧绿的玉。" ) ; assertEquals ( tokens2 . size ( ) , 10 ) ; assertEquals ( "[她/r, 胸前/s, 挂/v, 着/u, 一/m, 块/q, 碧绿/z, 的/u, 玉/n, 。/w]" , tokens2 . toString ( ) ) ; List < String > tokens3 = wordTokenizer . tokenize ( "“鲯鳅”的研究结果有什么奥妙？" ) ; assertEquals ( tokens3 . size ( ) , 11 ) ; assertEquals ( "[“/w, 鲯/x, 鳅/x, ”/w, 的/u, 研究/vn, 结果/n, 有/v, 什么/r, 奥妙/an, ？/w]" , tokens3 . toString ( ) ) ; List < String > tokens4 = wordTokenizer . tokenize ( "我们的女组长真是尺竿头更进一步。" ) ; assertEquals ( tokens4 . size ( ) , 11 ) ; assertEquals ( "[我们/r, 的/u, 女/b, 组长/n, 真/d, 是/v, 尺/ng, 竿/ng, 头/n, 更进一步/l, 。/w]" , tokens4 . toString ( ) ) ; List < String > tokens5 = wordTokenizer . tokenize ( "国务院，非国家工作人员不能随便进去的地方。" ) ; assertEquals ( tokens5 . size ( ) , 12 ) ; assertEquals ( "[国务院/nt, ，/w, 非/h, 国家/n, 工作/vn, 人员/n, 不能/v, 随便/ad, 进去/v, 的/u, 地方/n, 。/w]" , tokens5 . toString ( ) ) ; List < String > tokens6 = wordTokenizer . tokenize ( "“哇……”珠海北师大操场上的师生大吃一惊！" ) ; assertEquals ( tokens6 . size ( ) , 13 ) ; assertEquals ( "[“/w, 哇/y, …/w, …/w, ”/w, 珠海/ns, 北师大/j, 操场/n, 上/f, 的/u, 师生/n, 大吃一惊/i, ！/w]" , tokens6 . toString ( ) ) ; List < String > tokens7 = wordTokenizer . tokenize ( "在炎热的暑假里，我和其他同学们参加了姜老师的一个项目。" ) ; assertEquals ( tokens7 . size ( ) , 19 ) ; assertEquals ( "[在/p, 炎热/a, 的/u, 暑假/t, 里/f, ，/w, 我/r, 和/c, 其他/r, 同学/n, 们/k, 参加/v, 了/u, 姜/n, 老师/n, 的/u, 一个/m, 项目/n, 。/w]" , tokens7 . toString ( ) ) ; List < String > tokens8 = wordTokenizer . tokenize ( "“咕咚，”一台联想ThinkPad T系列电脑从关羽的宿舍飞了下来。" ) ; assertEquals ( tokens8 . size ( ) , 20 ) ; assertEquals ( "[“/w, 咕咚/o, ，/w, ”/w, 一/m, 台/q, 联想/nz, ThinkPad/nx, , T/nx, 系列/q, 电脑/n, 从/p, 关羽/nr, 的/u, 宿舍/n, 飞/v, 了/u, 下来/v, 。/w]" , tokens8 . toString ( ) ) ; } }
package org . languagetool . tokenizers . zh ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . tokenizers . SentenceTokenizer ; public class ChineseSentenceTokenizerTest extends TestCase { private final SentenceTokenizer stokenizer = new ChineseSentenceTokenizer ( ) ; public void testTokenize ( ) { String t1 = "他说：" ; String t2 = "我们是中国人" ; String t3 = "中国人很好" ; char [ ] punctuation1 = { '_' , '/' , ';' , ':' , '!' , '@' , '#' , '$' , '%' , '^' , '&' , '.' , '+' , '*' , '?' } ; for ( char i : punctuation1 ) { testSplit ( t2 + i + t3 ) ; } char [ ] punctuation2 = { '\uff0c' , '\uff1a' , '\u2026' , '\uff01' , '\uff1f' , '\u3001' , '\uff1b' , '\u3002' } ; for ( char i : punctuation2 ) { testSplit ( t2 + i , t3 ) ; } String [ ] punctuation3 = { "\"" , "\'" , "‘" , "(" , "（" , "“" , "”" , "）" , ")" , "’" , "\'" , "\"" } ; for ( int i = 0 ; i < punctuation3 . length / 2 ; i ++ ) { testSplit ( t1 , punctuation3 [ i ] , t2 + "，" , t3 + punctuation3 [ punctuation2 . length - 1 - i ] ) ; } String [ ] punctuation4 = { "〝" , "『" , "«" , "「" , "〖" , "{" , "【" , "[" , "<" , "《" , "》" , ">" , "]" , "】" , "}" , "〗" , "」" , "»" , "』" , "〞" } ; for ( int i = 0 ; i < punctuation4 . length / 2 ; i ++ ) { testSplit ( t1 , punctuation4 [ i ] + t2 + "，" , t3 + punctuation4 [ punctuation4 . length - 1 - i ] ) ; } } public void testTokenize2 ( ) { testSplit ( "Linux是一種自由和開放源碼的類UNIX操作系統。" , "该操作系统的内核由林纳斯·托瓦兹在1991年10月5日首次发布。" , "在加上使用者空間的應用程式之後，" , "成為Linux作業系統。" ) ; } private void testSplit ( final String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . DoublePunctuationRule ; import org . languagetool . rules . MultipleWhitespaceRule ; import org . languagetool . rules . Rule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . zh . ChineseTagger ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . zh . ChineseSentenceTokenizer ; import org . languagetool . tokenizers . zh . ChineseWordTokenizer ; public class Chinese extends Language { private Tagger tagger ; private Tokenizer wordTokenizer ; private SentenceTokenizer sentenceTokenizer ; @ Override public String getShortName ( ) { return "zh" ; } @ Override public String getName ( ) { return "Chinese" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "CN" } ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Tao Lin" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Arrays . asList ( new DoublePunctuationRule ( messages ) , new MultipleWhitespaceRule ( messages , this ) ) ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new ChineseTagger ( ) ; } return tagger ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new ChineseWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new ChineseSentenceTokenizer ( ) ; } return sentenceTokenizer ; } }
package org . languagetool . tagging . zh ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tagging . Tagger ; public class ChineseTagger implements Tagger { @ Override public List < AnalyzedTokenReadings > tag ( List < String > sentenceTokens ) throws IOException { final List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; int pos = 0 ; for ( String word : sentenceTokens ) { final List < AnalyzedToken > l = new ArrayList < > ( ) ; AnalyzedToken at = asAnalyzedToken ( word ) ; l . add ( at ) ; tokenReadings . add ( new AnalyzedTokenReadings ( l , pos ) ) ; pos += at . getToken ( ) . length ( ) ; } return tokenReadings ; } @ Override public final AnalyzedTokenReadings createNullToken ( final String token , final int startPos ) { return new AnalyzedTokenReadings ( new AnalyzedToken ( token , null , null ) , startPos ) ; } @ Override public AnalyzedToken createToken ( String token , String posTag ) { return new AnalyzedToken ( token , posTag , null ) ; } private AnalyzedToken asAnalyzedToken ( final String word ) { if ( ! word . contains ( "/" ) ) { return new AnalyzedToken ( " " , null , null ) ; } String [ ] parts = word . split ( "/" ) ; return new AnalyzedToken ( parts [ 0 ] , parts [ 1 ] , null ) ; } }
package org . languagetool . tokenizers . zh ; import java . util . ArrayList ; import java . util . List ; import org . ictclas4j . bean . Sentence ; import org . ictclas4j . segment . SentenceSeg ; import org . ictclas4j . utility . Utility ; import org . languagetool . tokenizers . SentenceTokenizer ; public class ChineseSentenceTokenizer implements SentenceTokenizer { @ Override public List < String > tokenize ( String text ) { final SentenceSeg ss = new SentenceSeg ( text ) ; final List < Sentence > sens = ss . getSens ( ) ; final List < String > list = new ArrayList < > ( ) ; for ( Sentence sen : sens ) { String str = sen . getContent ( ) ; if ( str . contains ( Utility . SENTENCE_BEGIN ) ) { str = str . substring ( Utility . SENTENCE_BEGIN . length ( ) ) ; } if ( str . contains ( Utility . SENTENCE_END ) ) { str = str . substring ( 0 , str . length ( ) - Utility . SENTENCE_BEGIN . length ( ) ) ; } list . add ( str ) ; } return list ; } @ Override public void setSingleLineBreaksMarksParagraph ( boolean lineBreakParagraphs ) { } @ Override public boolean singleLineBreaksMarksPara ( ) { return false ; } }
package org . languagetool . tokenizers . zh ; import java . io . IOException ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import org . ictclas4j . segment . SegTag ; import org . languagetool . JLanguageTool ; import org . languagetool . databroker . ResourceDataBroker ; import org . languagetool . tokenizers . Tokenizer ; import cn . com . cjf . CJFBeanFactory ; import cn . com . cjf . ChineseJF ; public class ChineseWordTokenizer implements Tokenizer { private SegTag seg ; private ChineseJF chinesdJF ; private void init ( ) { if ( chinesdJF == null ) { chinesdJF = CJFBeanFactory . getChineseJF ( ) ; } if ( seg == null ) { final ResourceDataBroker dataBroker = JLanguageTool . getDataBroker ( ) ; try ( InputStream coreDictIn = dataBroker . getFromResourceDirAsStream ( "/zh/coreDict.dct" ) ; InputStream bigramDictIn = dataBroker . getFromResourceDirAsStream ( "/zh/BigramDict.dct" ) ; InputStream personTaggerDctIn = dataBroker . getFromResourceDirAsStream ( "/zh/nr.dct" ) ; InputStream personTaggerCtxIn = dataBroker . getFromResourceDirAsStream ( "/zh/nr.ctx" ) ; InputStream transPersonTaggerDctIn = dataBroker . getFromResourceDirAsStream ( "/zh/tr.dct" ) ; InputStream transPersonTaggerCtxIn = dataBroker . getFromResourceDirAsStream ( "/zh/tr.ctx" ) ; InputStream placeTaggerDctIn = dataBroker . getFromResourceDirAsStream ( "/zh/ns.dct" ) ; InputStream placeTaggerCtxIn = dataBroker . getFromResourceDirAsStream ( "/zh/ns.ctx" ) ; InputStream lexTaggerCtxIn = dataBroker . getFromResourceDirAsStream ( "/zh/lexical.ctx" ) ) { seg = new SegTag ( 1 , coreDictIn , bigramDictIn , personTaggerDctIn , personTaggerCtxIn , transPersonTaggerDctIn , transPersonTaggerCtxIn , placeTaggerDctIn , placeTaggerCtxIn , lexTaggerCtxIn ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } } @ Override public List < String > tokenize ( String text ) { init ( ) ; String result ; try { result = seg . split ( chinesdJF . chineseFan2Jan ( text ) ) . getFinalResult ( ) ; result = result . replace ( "始##始年/t" , "年/t" ) ; } catch ( Exception e ) { return new ArrayList < > ( ) ; } final String [ ] list = result . split ( " " ) ; return Arrays . asList ( list ) ; } }
package org . languagetool ; import org . junit . Test ; import org . languagetool . language . Esperanto ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . List ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class EsperantoTest { @ Test public void test ( ) throws IOException { Esperanto language = new Esperanto ( ) ; assertThat ( language . getCountries ( ) . length , is ( 0 ) ) ; JLanguageTool languageTool = new JLanguageTool ( language ) ; String input = "La Mondaj Ludoj de 2013 estis plur-sporta evento..." ; List < RuleMatch > ruleMatches = languageTool . check ( input ) ; assertThat ( ruleMatches . size ( ) , is ( 1 ) ) ; assertThat ( ruleMatches . get ( 0 ) . getRule ( ) . getId ( ) , is ( "HUNSPELL_NO_SUGGEST_RULE" ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Esperanto ; public class EsperantoConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Esperanto ( ) ; } @ Override protected String createSampleText ( ) { return "Kreu la artikolon Enriched text aŭ aldonu peton pri ĝi." ; } }
package org . languagetool . rules . eo ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class EsperantoPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . ca ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; import org . languagetool . tagging . ca . CatalanTagger ; public final class MorfologikCatalanSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/ca/catalan.dict" ; private static final String SPELLING_FILE = "/ca/spelling.txt" ; private static final Pattern PARTICULA_INICIAL = Pattern . compile ( "^(els?|als?|pels?|dels?|de|per|uns?|una|unes|la|les|[tms]eus?) (..+)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern APOSTROF_INICI_VERBS = Pattern . compile ( "^([lnmts])(h?[aeiouàéèíòóú].*)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern APOSTROF_INICI_NOM_SING = Pattern . compile ( "^([ld])(h?[aeiouàéèíòóú].+)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern APOSTROF_INICI_NOM_PLURAL = Pattern . compile ( "^(d)(h?[aeiouàéèíòóú].+)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern APOSTROF_FINAL = Pattern . compile ( "^(.+[aei])(l|ls|m|n|ns|s|t)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern GUIONET_FINAL = Pattern . compile ( "^([\\p{L}·]+)[’']?(hi|ho|la|les|li|lo|los|me|ne|nos|se|te|vos)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern VERB_INDSUBJ = Pattern . compile ( "V.[SI].*" ) ; private static final Pattern NOM_SING = Pattern . compile ( "V.[NG].*|V.P..S..|N..[SN].*|A...[SN].|PX..S...|DD..S." ) ; private static final Pattern NOM_PLURAL = Pattern . compile ( "V.P..P..|N..[PN].*|A...[PN].|PX..P...|DD..P." ) ; private static final Pattern VERB_INFGERIMP = Pattern . compile ( "V.[NGM].*" ) ; private static final CatalanTagger tagger = new CatalanTagger ( ) ; public MorfologikCatalanSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; this . setIgnoreTaggedWords ( ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override protected String getSpellingFileName ( ) { return SPELLING_FILE ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_CA_ES" ; } @ Override public boolean useInOffice ( ) { return true ; } @ Override protected List < String > orderSuggestions ( List < String > suggestions , String word ) { List < String > newSuggestions = new ArrayList < > ( ) ; for ( String suggestion : suggestions ) { if ( PARTICULA_INICIAL . matcher ( suggestion ) . matches ( ) ) { newSuggestions . add ( 0 , suggestion ) ; } else { newSuggestions . add ( suggestion ) ; } } return newSuggestions ; } @ Override protected List < String > getAdditionalTopSuggestions ( List < String > suggestions , String word ) throws IOException { String suggestion = "" ; suggestion = findSuggestion ( suggestion , word , APOSTROF_INICI_VERBS , VERB_INDSUBJ , 2 , "'" ) ; suggestion = findSuggestion ( suggestion , word , APOSTROF_INICI_NOM_SING , NOM_SING , 2 , "'" ) ; suggestion = findSuggestion ( suggestion , word , APOSTROF_INICI_NOM_PLURAL , NOM_PLURAL , 2 , "'" ) ; if ( ! word . endsWith ( "as" ) && ! word . endsWith ( "et" ) ) { suggestion = findSuggestion ( suggestion , word , APOSTROF_FINAL , VERB_INFGERIMP , 1 , "'" ) ; } suggestion = findSuggestion ( suggestion , word , GUIONET_FINAL , VERB_INFGERIMP , 1 , "-" ) ; if ( ! suggestion . isEmpty ( ) ) { return Collections . singletonList ( suggestion ) ; } return Collections . emptyList ( ) ; } private String findSuggestion ( String suggestion , String word , Pattern wordPattern , Pattern postagPattern , int suggestionPosition , String separator ) throws IOException { if ( ! suggestion . isEmpty ( ) ) { return suggestion ; } Matcher matcher = wordPattern . matcher ( word ) ; if ( matcher . matches ( ) ) { String newSuggestion = matcher . group ( suggestionPosition ) ; if ( matchPostagRegexp ( tagger . tag ( Arrays . asList ( newSuggestion ) ) . get ( 0 ) , postagPattern ) ) { return matcher . group ( 1 ) + separator + matcher . group ( 2 ) ; } } return "" ; } private boolean matchPostagRegexp ( AnalyzedTokenReadings aToken , Pattern pattern ) { for ( AnalyzedToken analyzedToken : aToken ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag == null ) { posTag = "UNKNOWN" ; } final Matcher m = pattern . matcher ( posTag ) ; if ( m . matches ( ) ) { return true ; } } return false ; } }
package org . languagetool . synthesis . ca ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; public class CatalanSynthesizerTest extends TestCase { private final CatalanSynthesizer synth = new CatalanSynthesizer ( ) ; public final void testSynthesizeStringString ( ) throws IOException { assertEquals ( 0 , synth . synthesize ( dummyToken ( "blablabla" ) , "blablabla" ) . length ) ; assertEquals ( "[nostres]" , synth ( "nostre" , "PX1CP0P0" ) ) ; assertEquals ( "[presidents]" , synth ( "president" , "NCMP000" ) ) ; assertEquals ( "[comprovat]" , synth ( "comprovar" , "VMP00SM.?" ) ) ; assertEquals ( "[arribe, arribi]" , synth ( "arribar" , "VMSP3S00" ) ) ; assertEquals ( "[arribe, arribi]" , synthRegex ( "arribar" , "VMSP3S.0" ) ) ; assertEquals ( "[comprovades, comprovats, comprovada, comprovat]" , synthRegex ( "comprovar" , "V.P.*" ) ) ; assertEquals ( "[contestant, contestar]" , synthRegex ( "contestar" , "VM[GN]0000.?" ) ) ; assertEquals ( "[les universitats, la universitat]" , synthNonRegex ( "universitat" , "DT" ) ) ; assertEquals ( "[les úniques, l'única, els únics, l'únic]" , synthNonRegex ( "únic" , "DT" ) ) ; assertEquals ( "[per les úniques, per l'única, pels únics, per l'únic]" , synthNonRegex ( "únic" , "DTper" ) ) ; } private String synth ( String word , String pos ) throws IOException { return Arrays . toString ( synth . synthesize ( dummyToken ( word ) , pos ) ) ; } private String synthRegex ( String word , String pos ) throws IOException { return Arrays . toString ( synth . synthesize ( dummyToken ( word ) , pos , true ) ) ; } private String synthNonRegex ( String word , String pos ) throws IOException { return Arrays . toString ( synth . synthesize ( dummyToken ( word ) , pos , false ) ) ; } private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } }
package org . languagetool . tagging . eo ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . tokenizers . WordTokenizer ; public class EsperantoTaggerTest extends TestCase { private EsperantoTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new EsperantoTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "Tio estas simpla testo" , "Tio/[null]T nak np t o -- estas/[esti]V nt as -- simpla/[simpla]A nak np -- testo/[testo]O nak np" , tokenizer , tagger ) ; TestTools . myAssert ( "Mi malsategas" , "Mi/[mi]R nak np -- malsategas/[malsategi]V nt as" , tokenizer , tagger ) ; TestTools . myAssert ( "Li malŝategas sin" , "Li/[li]R nak np -- malŝategas/[malŝategi]V tr as -- sin/[si]R akz np" , tokenizer , tagger ) ; } }
package org . languagetool . tokenizers . eo ; import java . util . List ; import junit . framework . TestCase ; public class EsperantoWordTokenizerTest extends TestCase { public void testTokenize ( ) { EsperantoWordTokenizer wordTokenizer = new EsperantoWordTokenizer ( ) ; List < String > testList = wordTokenizer . tokenize ( "Tio estas\u00A0testo" ) ; assertEquals ( testList . size ( ) , 5 ) ; assertEquals ( "[Tio, , estas, \u00A0, testo]" , testList . toString ( ) ) ; testList = wordTokenizer . tokenize ( "dank' al 'tio'" ) ; assertEquals ( testList . size ( ) , 7 ) ; assertEquals ( "[dank', , al, , ', tio, ']" , testList . toString ( ) ) ; } }
package org . languagetool . language ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . spelling . hunspell . HunspellNoSuggestionRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . eo . EsperantoTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . eo . EsperantoWordTokenizer ; public class Esperanto extends Language { private SentenceTokenizer sentenceTokenizer ; private Tokenizer wordTokenizer ; private Disambiguator disambiguator ; @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new EsperantoWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public String getName ( ) { return "Esperanto" ; } @ Override public String getShortName ( ) { return "eo" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { } ; } @ Override public Tagger getTagger ( ) { return new EsperantoTagger ( ) ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new XmlRuleDisambiguator ( new Esperanto ( ) ) ; } return disambiguator ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { Contributors . DOMINIQUE_PELLE } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages ) , new HunspellNoSuggestionRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new WordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new SentenceWhitespaceRule ( messages ) ) ; } }
package org . languagetool . rules . eo ; import org . languagetool . rules . AbstractDateCheckFilter ; import java . util . Calendar ; import java . util . Locale ; public class DateCheckFilter extends AbstractDateCheckFilter { @ Override protected Calendar getCalendar ( ) { return Calendar . getInstance ( Locale . UK ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfMonth ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . endsWith ( "n" ) ) { day = day . substring ( 0 , day . length ( ) - 1 ) ; } int n = 0 ; if ( day . startsWith ( "dek" ) ) { n = 10 ; day = day . substring ( 3 , day . length ( ) ) ; } else if ( day . startsWith ( "dudek" ) ) { n = 20 ; day = day . substring ( 5 , day . length ( ) ) ; } else if ( day . startsWith ( "tridek" ) ) { n = 30 ; day = day . substring ( 6 , day . length ( ) ) ; } if ( n > 0 && day . startsWith ( "-" ) ) { day = day . substring ( 1 , day . length ( ) ) ; } if ( day . equals ( "unua" ) ) n += 1 ; if ( day . equals ( "dua" ) ) n += 2 ; if ( day . equals ( "tria" ) ) n += 3 ; if ( day . equals ( "kvara" ) ) n += 4 ; if ( day . equals ( "kvina" ) ) n += 5 ; if ( day . equals ( "sesa" ) ) n += 6 ; if ( day . equals ( "sepa" ) ) n += 7 ; if ( day . equals ( "oka" ) ) n += 8 ; if ( day . equals ( "naŭa" ) ) n += 9 ; return n ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfWeek ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . startsWith ( "dim" ) ) return Calendar . SUNDAY ; if ( day . startsWith ( "lun" ) ) return Calendar . MONDAY ; if ( day . startsWith ( "mar" ) ) return Calendar . TUESDAY ; if ( day . startsWith ( "mer" ) ) return Calendar . WEDNESDAY ; if ( day . startsWith ( "ĵaŭ" ) ) return Calendar . THURSDAY ; if ( day . startsWith ( "ven" ) ) return Calendar . FRIDAY ; if ( day . startsWith ( "sab" ) ) return Calendar . SATURDAY ; throw new RuntimeException ( "Could not find day of week for '" + dayStr + "'" ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected String getDayOfWeek ( Calendar date ) { String englishDay = date . getDisplayName ( Calendar . DAY_OF_WEEK , Calendar . LONG , Locale . UK ) ; if ( englishDay . equals ( "Sunday" ) ) return "dimanĉo" ; if ( englishDay . equals ( "Monday" ) ) return "lundo" ; if ( englishDay . equals ( "Tuesday" ) ) return "mardo" ; if ( englishDay . equals ( "Wednesday" ) ) return "merkredo" ; if ( englishDay . equals ( "Thursday" ) ) return "jaŭdo" ; if ( englishDay . equals ( "Friday" ) ) return "vendredo" ; if ( englishDay . equals ( "Saturday" ) ) return "sabato" ; return "" ; } @ SuppressWarnings ( { "ControlFlowStatementWithoutBraces" , "MagicNumber" } ) @ Override protected int getMonth ( String monthStr ) { String mon = monthStr . toLowerCase ( ) ; if ( mon . startsWith ( "jan" ) ) return 1 ; if ( mon . startsWith ( "feb" ) ) return 2 ; if ( mon . startsWith ( "mar" ) ) return 3 ; if ( mon . startsWith ( "apr" ) ) return 4 ; if ( mon . startsWith ( "maj" ) ) return 5 ; if ( mon . startsWith ( "jun" ) ) return 6 ; if ( mon . startsWith ( "jul" ) ) return 7 ; if ( mon . startsWith ( "aŭg" ) ) return 8 ; if ( mon . startsWith ( "sep" ) ) return 9 ; if ( mon . startsWith ( "okt" ) ) return 10 ; if ( mon . startsWith ( "nov" ) ) return 11 ; if ( mon . startsWith ( "dec" ) ) return 12 ; throw new RuntimeException ( "Could not find month '" + monthStr + "'" ) ; } }
package org . languagetool . tagging . eo ; import java . io . BufferedReader ; import java . io . IOException ; import java . io . InputStream ; import java . io . InputStreamReader ; import java . util . ArrayList ; import java . util . HashSet ; import java . util . List ; import java . util . Set ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . tagging . ManualTagger ; import org . languagetool . tagging . TaggedWord ; import org . languagetool . tagging . Tagger ; public class EsperantoTagger implements Tagger { private ManualTagger manualTagger = null ; private Set < String > setTransitiveVerbs = null ; private Set < String > setIntransitiveVerbs = null ; private static final Pattern patternVerb = Pattern . compile ( "(..+)(as|os|is|us|u|i)$" ) ; private static final Pattern patternPrefix = Pattern . compile ( "^(?:mal|mis|ek|re|fi|ne)(.*)" ) ; private static final Pattern patternSuffix = Pattern . compile ( "(.*)(?:ad|aĉ|eg|et)i$" ) ; private static final Pattern patternParticiple = Pattern . compile ( "((..+)([aio])(n?)t)([aoe])(j?)(n?)$" ) ; private Set < String > setNonParticiple ; private static final Pattern patternTabelvorto = Pattern . compile ( "^(i|ti|ki|ĉi|neni)(?:(?:([uoae])(j?)(n?))|(am|al|es|el|om))$" ) ; private static final Pattern patternTabelvortoAdverb = Pattern . compile ( "^(?:ti|i|ĉi|neni)(?:am|om|el|e)$" ) ; private Set < String > loadWords ( final InputStream stream ) throws IOException { final Set < String > words = new HashSet < > ( ) ; try ( InputStreamReader isr = new InputStreamReader ( stream , "UTF-8" ) ; BufferedReader br = new BufferedReader ( isr ) ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { line = line . trim ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } words . add ( line ) ; } } return words ; } private void lazyInit ( ) throws IOException { if ( manualTagger != null ) { return ; } try ( InputStream stream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( "/eo/manual-tagger.txt" ) ) { manualTagger = new ManualTagger ( stream ) ; } setTransitiveVerbs = loadWords ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( "/eo/verb-tr.txt" ) ) ; setIntransitiveVerbs = loadWords ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( "/eo/verb-ntr.txt" ) ) ; setNonParticiple = loadWords ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( "/eo/root-ant-at.txt" ) ) ; } private String findTransitivity ( String verb ) { if ( verb . endsWith ( "iĝi" ) ) { return "nt" ; } else if ( verb . endsWith ( "igi" ) ) { return verb . equals ( "memmortigi" ) ? "nt" : "tr" ; } for ( ; ; ) { final boolean isTransitive = setTransitiveVerbs . contains ( verb ) ; final boolean isIntransitive = setIntransitiveVerbs . contains ( verb ) ; if ( isTransitive ) { return isIntransitive ? "tn" : "tr" ; } else if ( isIntransitive ) { return "nt" ; } final Matcher matcherPrefix = patternPrefix . matcher ( verb ) ; if ( matcherPrefix . find ( ) ) { verb = matcherPrefix . group ( 1 ) ; continue ; } final Matcher matcherSuffix = patternSuffix . matcher ( verb ) ; if ( matcherSuffix . find ( ) ) { verb = matcherSuffix . group ( 1 ) + "i" ; continue ; } break ; } return "xx" ; } @ Override public List < AnalyzedTokenReadings > tag ( final List < String > sentenceTokens ) throws IOException { lazyInit ( ) ; Matcher matcher ; final List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; for ( String word : sentenceTokens ) { final List < AnalyzedToken > l = new ArrayList < > ( ) ; if ( word . length ( ) > 1 ) { final String lWord = word . toLowerCase ( ) ; final List < TaggedWord > manualTags = manualTagger . tag ( lWord ) ; if ( manualTags . size ( ) > 0 ) { for ( TaggedWord manualTag : manualTags ) { l . add ( new AnalyzedToken ( word , manualTag . getPosTag ( ) , manualTag . getLemma ( ) ) ) ; } } else { if ( ( matcher = patternTabelvorto . matcher ( lWord ) ) . find ( ) ) { final String type1Group = matcher . group ( 1 ) . substring ( 0 , 1 ) . toLowerCase ( ) ; final String type2Group = matcher . group ( 2 ) ; final String plGroup = matcher . group ( 3 ) ; final String accGroup = matcher . group ( 4 ) ; final String type3Group = matcher . group ( 5 ) ; final String type ; final String plural ; final String accusative ; if ( accGroup == null ) { accusative = "xxx" ; } else { accusative = accGroup . equalsIgnoreCase ( "n" ) ? "akz" : "nak" ; } if ( plGroup == null ) { plural = " pn " ; } else { plural = plGroup . equalsIgnoreCase ( "j" ) ? " pl " : " np " ; } type = ( ( type2Group == null ) ? type3Group : type2Group ) . toLowerCase ( ) ; l . add ( new AnalyzedToken ( word , "T " + accusative + plural + type1Group + " " + type , null ) ) ; if ( ( matcher = patternTabelvortoAdverb . matcher ( lWord ) ) . find ( ) ) { l . add ( new AnalyzedToken ( word , "E nak" , lWord ) ) ; } } else if ( lWord . endsWith ( "o" ) ) { l . add ( new AnalyzedToken ( word , "O nak np" , lWord ) ) ; } else if ( lWord . length ( ) >= 2 && lWord . endsWith ( "'" ) ) { l . add ( new AnalyzedToken ( word , "O nak np" , lWord . substring ( 0 , lWord . length ( ) - 1 ) + "o" ) ) ; } else if ( lWord . endsWith ( "oj" ) ) { l . add ( new AnalyzedToken ( word , "O nak pl" , lWord . substring ( 0 , lWord . length ( ) - 1 ) ) ) ; } else if ( lWord . endsWith ( "on" ) ) { l . add ( new AnalyzedToken ( word , "O akz np" , lWord . substring ( 0 , lWord . length ( ) - 1 ) ) ) ; } else if ( lWord . endsWith ( "ojn" ) ) { l . add ( new AnalyzedToken ( word , "O akz pl" , lWord . substring ( 0 , lWord . length ( ) - 2 ) ) ) ; } else if ( lWord . endsWith ( "a" ) ) { l . add ( new AnalyzedToken ( word , "A nak np" , lWord ) ) ; } else if ( lWord . endsWith ( "aj" ) ) { l . add ( new AnalyzedToken ( word , "A nak pl" , lWord . substring ( 0 , lWord . length ( ) - 1 ) ) ) ; } else if ( lWord . endsWith ( "an" ) ) { l . add ( new AnalyzedToken ( word , "A akz np" , lWord . substring ( 0 , lWord . length ( ) - 1 ) ) ) ; } else if ( lWord . endsWith ( "ajn" ) ) { l . add ( new AnalyzedToken ( word , "A akz pl" , lWord . substring ( 0 , lWord . length ( ) - 2 ) ) ) ; } else if ( lWord . endsWith ( "e" ) ) { l . add ( new AnalyzedToken ( word , "E nak" , lWord ) ) ; } else if ( lWord . endsWith ( "en" ) ) { l . add ( new AnalyzedToken ( word , "E akz" , lWord . substring ( 0 , lWord . length ( ) - 1 ) ) ) ; } else if ( ( matcher = patternVerb . matcher ( lWord ) ) . find ( ) ) { final String verb = matcher . group ( 1 ) + "i" ; final String tense = matcher . group ( 2 ) ; final String transitive = findTransitivity ( verb ) ; l . add ( new AnalyzedToken ( word , "V " + transitive + " " + tense , verb ) ) ; } else { l . add ( new AnalyzedToken ( word , null , null ) ) ; } if ( ( matcher = patternParticiple . matcher ( lWord ) ) . find ( ) ) { if ( ! setNonParticiple . contains ( matcher . group ( 1 ) ) ) { final String verb = matcher . group ( 2 ) + "i" ; final String aio = matcher . group ( 3 ) ; final String antAt = matcher . group ( 4 ) . equals ( "n" ) ? "n" : "-" ; final String aoe = matcher . group ( 5 ) ; final String plural = matcher . group ( 6 ) . equals ( "j" ) ? "pl" : "np" ; final String accusative = matcher . group ( 7 ) . equals ( "n" ) ? "akz" : "nak" ; final String transitive = findTransitivity ( verb ) ; l . add ( new AnalyzedToken ( word , "C " + accusative + " " + plural + " " + transitive + " " + aio + " " + antAt + " " + aoe , verb ) ) ; } } } } else { l . add ( new AnalyzedToken ( word , null , null ) ) ; } tokenReadings . add ( new AnalyzedTokenReadings ( l , 0 ) ) ; } return tokenReadings ; } @ Override public AnalyzedTokenReadings createNullToken ( String token , int startPos ) { return new AnalyzedTokenReadings ( new AnalyzedToken ( token , null , null ) , startPos ) ; } @ Override public AnalyzedToken createToken ( String token , String posTag ) { return new AnalyzedToken ( token , posTag , null ) ; } }
package org . languagetool . tokenizers . eo ; import java . util . ArrayList ; import java . util . Iterator ; import java . util . List ; import org . languagetool . tokenizers . WordTokenizer ; public class EsperantoWordTokenizer extends WordTokenizer { public EsperantoWordTokenizer ( ) { } @ Override public List < String > tokenize ( final String text ) { String replaced = text . replaceAll ( "(?<!')\\b([a-zA-ZĉĝĥĵŝŭĈĜĤĴŜŬ]+)'(?![a-zA-ZĉĝĥĵŝŭĈĜĤĴŜŬ-])" , "$1\u0001\u0001EO_APOS1\u0001\u0001" ) . replaceAll ( "(?<!')\\b([a-zA-ZĉĝĥĵŝŭĈĜĤĴŜŬ]+)'(?=[a-zA-ZĉĝĥĵŝŭĈĜĤĴŜŬ-])" , "$1\u0001\u0001EO_APOS2\u0001\u0001 " ) ; final List < String > tokenList = super . tokenize ( replaced ) ; List < String > tokens = new ArrayList < > ( ) ; Iterator < String > itr = tokenList . iterator ( ) ; while ( itr . hasNext ( ) ) { String word = itr . next ( ) ; if ( word . endsWith ( "\u0001\u0001EO_APOS2\u0001\u0001" ) ) { itr . next ( ) ; } word = word . replace ( "\u0001\u0001EO_APOS1\u0001\u0001" , "'" ) . replace ( "\u0001\u0001EO_APOS2\u0001\u0001" , "'" ) ; tokens . add ( word ) ; } return tokens ; } }
package org . languagetool ; import java . io . IOException ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import junit . framework . TestCase ; import org . languagetool . language . Polish ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternRule ; public class JLanguageToolTest extends TestCase { public void testPolish ( ) throws IOException { final Polish noXmlRulesPolish = new Polish ( ) { @ Override public List < PatternRule > getPatternRules ( ) { return Collections . emptyList ( ) ; } } ; final Polish polish = new Polish ( ) ; JLanguageTool tool = new JLanguageTool ( new Polish ( ) ) ; JLanguageTool noRulesTool = new JLanguageTool ( noXmlRulesPolish ) ; assertEquals ( "[PL]" , Arrays . toString ( polish . getCountries ( ) ) ) ; List < RuleMatch > matches = noRulesTool . check ( "To jest całkowicie prawidłowe zdanie." ) ; assertEquals ( 0 , matches . size ( ) ) ; matches = noRulesTool . check ( "To jest jest problem." ) ; assertEquals ( 1 , matches . size ( ) ) ; assertEquals ( 0 , noRulesTool . check ( "Mają one niemałe znaczenie." ) . size ( ) ) ; assertEquals ( 0 , noRulesTool . check ( "Często wystarczy obrócić na wspak wyroki świata, aby trafnie osądzić jakąś osobę." ) . size ( ) ) ; assertEquals ( 0 , noRulesTool . check ( "A teraz każcie mi dać jaki bądź posiłek." ) . size ( ) ) ; assertEquals ( 0 , noRulesTool . check ( "Kiedym wóz zobaczył, byłbym przysiągł, że wielka przygoda mnie czeka." ) . size ( ) ) ; assertEquals ( 0 , noRulesTool . check ( "Jurek wygląda wypisz wymaluj babcia." ) . size ( ) ) ; assertEquals ( 1 , noRulesTool . check ( "Jurek wygląda wypisz wypisz wymaluj babcia." ) . size ( ) ) ; assertEquals ( 1 , noRulesTool . check ( "Jurek wygląda wypisz wymaluj wymaluj babcia." ) . size ( ) ) ; assertEquals ( 0 , noRulesTool . check ( "Zawarł w niej, oprócz swojej twórczości, wybrane epigramaty czterdziestu ośmiu innych greckich poetów i poetek." ) . size ( ) ) ; assertEquals ( 0 , tool . check ( "Nudne brednie tak zamąciły głowę chłopu, że klął na czym ziemia stoi, zmuszonym będąc słuchać tego wszystkiego." ) . size ( ) ) ; assertEquals ( 1 , tool . check ( "Chcąc, nie chcąc zjadłem pstrąga." ) . size ( ) ) ; matches = tool . check ( "Był on bowiem pięknym strzelcem bowiem." ) ; assertEquals ( 0 , matches . size ( ) ) ; tool . enableDefaultOffRule ( "PL_WORD_REPEAT" ) ; matches = tool . check ( "Był on bowiem pięknym strzelcem bowiem." ) ; assertEquals ( 1 , matches . size ( ) ) ; matches = tool . check ( "Premier drapie się w ucho co i rusz." ) ; assertEquals ( 1 , matches . size ( ) ) ; matches = tool . check ( "I can give you more a detailed description" ) ; assertEquals ( 6 , matches . size ( ) ) ; tool . setListUnknownWords ( true ) ; matches = tool . check ( "This is not a Polish text." ) ; assertEquals ( 3 , matches . size ( ) ) ; assertEquals ( "[., Polish, This, is, text]" , tool . getUnknownWords ( ) . toString ( ) ) ; matches = tool . check ( "To jest tekst.\nTest 1. To jest linia w której nie ma przecinka." ) ; assertEquals ( 17 , matches . get ( 0 ) . getColumn ( ) ) ; matches = tool . check ( "To jest tekst. \nTest 1. To jest linia w której nie ma przecinka." ) ; assertEquals ( 16 , matches . get ( 0 ) . getColumn ( ) ) ; matches = tool . check ( "To jest tekst. Test 1. To jest linia w której nie ma przecinka." ) ; assertEquals ( 32 , matches . get ( 0 ) . getColumn ( ) ) ; polish . getSentenceTokenizer ( ) . setSingleLineBreaksMarksParagraph ( true ) ; tool = new JLanguageTool ( polish ) ; matches = tool . check ( "To jest tekst.\nTest 1. To jest linia w której nie ma przecinka." ) ; assertEquals ( 17 , matches . get ( 0 ) . getColumn ( ) ) ; matches = tool . check ( "To jest tekst. \nTest 1. To jest linia w której nie ma przecinka." ) ; assertEquals ( 17 , matches . get ( 0 ) . getColumn ( ) ) ; matches = tool . check ( "To jest tekst. To jest linia w której nie ma przecinka." ) ; assertEquals ( 24 , matches . get ( 0 ) . getColumn ( ) ) ; AnalyzedSentence sent = tool . getAnalyzedSentence ( "Z powodu pogody dobre buty są wskazane." ) ; assertEquals ( "Disambiguator log: \n\n" + "prep_verb:2 Z[z/prep:acc:nwok*,z/prep:gen:nwok*,z/prep:inst:nwok*] -> Z[z/prep:gen:nwok*]\n" + "PREP_SUBST:1 Z[z/prep:gen:nwok*] -> Z[z/prep:gen:nwok*]\n" + "PREP_SUBST_2:1 Z[z/prep:gen:nwok*] -> Z[z/prep:gen:nwok*]\n" + "MULTIWORD_CHUNKER: Z[z/prep:gen:nwok*] -> Z[z/prep:gen:nwok*,Z powodu/<PREP:GEN>*]\n\n" + "prep_verb:2 powodu[powód/subst:sg:gen:m3] -> powodu[powód/subst:sg:gen:m3]\n" + "PREP_SUBST:1 powodu[powód/subst:sg:gen:m3] -> powodu[powód/subst:sg:gen:m3]\n" + "PREP_SUBST_2:1 powodu[powód/subst:sg:gen:m3] -> powodu[powód/subst:sg:gen:m3]\n" + "MULTIWORD_CHUNKER: powodu[powód/subst:sg:gen:m3] -> powodu[powód/subst:sg:gen:m3,Z powodu/</PREP:GEN>]\n" + "\n" + "PREP_SUBST:8 pogody[pogoda/subst:pl:acc:f,pogoda/subst:pl:nom:f,pogoda/subst:pl:voc:f,pogoda/subst:sg:gen:f] -> pogody[pogoda/subst:sg:gen:f]\n" + "\n" + "WIELKI_SWOJ_ADJ:1 dobre[dobre/subst:pl:acc:n2,dobre/subst:pl:nom:n2,dobre/subst:pl:voc:n2,dobre/subst:sg:acc:n2,dobre/subst:sg:nom:n2,dobre/subst:sg:voc:n2,dobry/adj:pl:acc:m2.m3.f.n1.n2.p2.p3:pos,dobry/adj:pl:nom.voc:m2.m3.f.n1.n2.p2.p3:pos,dobry/adj:sg:acc:n1.n2:pos,dobry/adj:sg:nom.voc:n1.n2:pos,dobry/depr:pl:nom:m2,dobry/depr:pl:voc:m2,dobry/subst:pl:acc:m3,dobry/subst:pl:nom:m3,dobry/subst:pl:voc:m3] -> dobre[dobry/adj:pl:acc:m2.m3.f.n1.n2.p2.p3:pos,dobry/adj:pl:nom.voc:m2.m3.f.n1.n2.p2.p3:pos,dobry/adj:sg:acc:n1.n2:pos,dobry/adj:sg:nom.voc:n1.n2:pos]\n" + "unify_adj_subst:2 dobre[dobry/adj:pl:acc:m2.m3.f.n1.n2.p2.p3:pos,dobry/adj:pl:nom.voc:m2.m3.f.n1.n2.p2.p3:pos,dobry/adj:sg:acc:n1.n2:pos,dobry/adj:sg:nom.voc:n1.n2:pos] -> dobre[dobry/adj:pl:acc:m2.m3.f.n1.n2.p2.p3:pos,dobry/adj:pl:nom.voc:m2.m3.f.n1.n2.p2.p3:pos]\n" + "\n" + "unify_adj_subst:2 buty[but/subst:pl:acc:m2,but/subst:pl:acc:m3,but/subst:pl:nom:m2,but/subst:pl:nom:m3,but/subst:pl:voc:m2,but/subst:pl:voc:m3,buta/subst:pl:acc:f,buta/subst:pl:nom:f,buta/subst:pl:voc:f,buta/subst:sg:gen:f] -> buty[but/subst:pl:acc:m2,but/subst:pl:acc:m3,but/subst:pl:nom:m2,but/subst:pl:nom:m3,but/subst:pl:voc:m2,but/subst:pl:voc:m3,buta/subst:pl:acc:f,buta/subst:pl:nom:f,buta/subst:pl:voc:f]\n" + "SUBST_NOM_VOC_VERB:5 buty[but/subst:pl:acc:m2,but/subst:pl:acc:m3,but/subst:pl:nom:m2,but/subst:pl:nom:m3,but/subst:pl:voc:m2,but/subst:pl:voc:m3,buta/subst:pl:acc:f,buta/subst:pl:nom:f,buta/subst:pl:voc:f] -> buty[but/subst:pl:nom:m2,but/subst:pl:nom:m3,buta/subst:pl:nom:f]\n" + "\n" + "ppas_jest:1 są[być/verb:fin:pl:ter:imperf:nonrefl] -> są[być/verb:fin:pl:ter:imperf:nonrefl]\n" + "SUBST_NOM_VOC_VERB:5 są[być/verb:fin:pl:ter:imperf:nonrefl] -> są[być/verb:fin:pl:ter:imperf:nonrefl]\n" + "BYC_ADJ_ACC_NOM:1 są[być/verb:fin:pl:ter:imperf:nonrefl] -> są[być/verb:fin:pl:ter:imperf:nonrefl]\n" + "\n" + "ppas_jest:1 wskazane[wskazany/adj:pl:acc:m2.m3.f.n1.n2.p2.p3:pos,wskazany/adj:pl:nom.voc:m2.m3.f.n1.n2.p2.p3:pos,wskazany/adj:sg:acc:n1.n2:pos,wskazany/adj:sg:nom.voc:n1.n2:pos,wskazać/ppas:pl:nom.acc.voc:m2.m3.f.n1.n2.p2.p3:perf:aff,wskazać/ppas:sg:nom.acc.voc:n1.n2:perf:aff] -> wskazane[wskazać/ppas:pl:nom.acc.voc:m2.m3.f.n1.n2.p2.p3:perf:aff]\n" + "BYC_ADJ_ACC_NOM:1 wskazane[wskazać/ppas:pl:nom.acc.voc:m2.m3.f.n1.n2.p2.p3:perf:aff] -> wskazane[wskazać/ppas:pl:nom.acc.voc:m2.m3.f.n1.n2.p2.p3:perf:aff]\n" , sent . getAnnotations ( ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Polish ; public class PolishConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Polish ( ) ; } @ Override protected String createSampleText ( ) { return "Wiedźmin – postać stworzona przez polskiego pisarza fantasy Andrzeja Sapkowskiego." ; } }
package org . languagetool . synthesis . pl ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; public class PolishSynthesizerTest extends TestCase { public final void testSynthesizeString ( ) throws IOException { PolishSynthesizer synth = new PolishSynthesizer ( ) ; assertEquals ( synth . synthesize ( dummyToken ( "blablabla" ) , "blablabla" ) . length , 0 ) ; assertEquals ( "[Aarona]" , Arrays . toString ( synth . synthesize ( dummyToken ( "Aaron" ) , "subst:sg:gen:m1" ) ) ) ; assertEquals ( "[Abchazem]" , Arrays . toString ( synth . synthesize ( dummyToken ( "Abchaz" ) , "subst:sg:inst:m1" ) ) ) ; assertEquals ( "[miała]" , Arrays . toString ( synth . synthesize ( dummyToken ( "mieć" ) , "verb:praet:sg:f:ter:imperf:refl.nonrefl" ) ) ) ; assertEquals ( "[brzydziej]" , Arrays . toString ( synth . synthesize ( dummyToken ( "brzydko" ) , "adv:com" ) ) ) ; assertEquals ( "[tonera]" , Arrays . toString ( getSortedArray ( synth . synthesize ( dummyToken ( "toner" ) , "subst:sg:gen:m.*" , true ) ) ) ) ; assertEquals ( "[niedużego, nieduży]" , Arrays . toString ( getSortedArray ( synth . synthesize ( dummyToken ( "nieduży" ) , "adj:sg.*(m[0-9]?|m.n):pos" , true ) ) ) ) ; assertEquals ( "[miał, miała, miałam, miałaś, miałem, miałeś, miało, miałom, miałoś]" , Arrays . toString ( getSortedArray ( synth . synthesize ( dummyToken ( "mieć" ) , ".*praet:sg.*" , true ) ) ) ) ; } private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } private String [ ] getSortedArray ( String ... ar ) { String [ ] newAr = ar . clone ( ) ; Arrays . sort ( newAr ) ; return newAr ; } }
package org . languagetool . tools ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Polish ; import org . languagetool . rules . RuleMatch ; import org . xml . sax . SAXException ; import javax . xml . parsers . ParserConfigurationException ; import java . io . IOException ; import java . util . List ; public class ToolsTest extends TestCase { public void testCheck ( ) throws IOException , ParserConfigurationException , SAXException { final JLanguageTool tool = new JLanguageTool ( new Polish ( ) ) ; List < RuleMatch > matches = tool . check ( "To jest całkowicie prawidłowe zdanie." ) ; assertEquals ( 0 , matches . size ( ) ) ; List < RuleMatch > matches2 = tool . check ( "To jest problem problem." ) ; assertEquals ( 1 , matches2 . size ( ) ) ; assertEquals ( "WORD_REPEAT_RULE" , matches2 . get ( 0 ) . getRule ( ) . getId ( ) ) ; } public void testCorrect ( ) throws IOException , ParserConfigurationException , SAXException { JLanguageTool tool = new JLanguageTool ( new Polish ( ) ) ; String correct = Tools . correctText ( "To jest całkowicie prawidłowe zdanie." , tool ) ; assertEquals ( "To jest całkowicie prawidłowe zdanie." , correct ) ; correct = Tools . correctText ( "To jest jest problem." , tool ) ; assertEquals ( "To jest problem." , correct ) ; correct = Tools . correctText ( "To jest jest problem. Ale to już już nie jest problem." , tool ) ; assertEquals ( "To jest problem. Ale to już nie jest problem." , correct ) ; correct = Tools . correctText ( "To jest jest problem. Ale to już już nie jest problem. Tak sie nie robi. W tym zdaniu brakuje przecinka bo go zapomniałem." , tool ) ; assertEquals ( "To jest problem. Ale to już nie jest problem. Tak się nie robi. W tym zdaniu brakuje przecinka, bo go zapomniałem." , correct ) ; } }
package org . languagetool . rules . ca ; import org . languagetool . rules . Rule ; public abstract class CatalanRule extends Rule { }
package org . languagetool . rules . pl ; import java . io . IOException ; import java . io . InputStream ; import java . util . Scanner ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Polish ; import org . languagetool . rules . AbstractCompoundRuleTest ; import org . languagetool . rules . RuleMatch ; public class CompoundRuleTest extends AbstractCompoundRuleTest { @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; langTool = new JLanguageTool ( new Polish ( ) ) ; rule = new CompoundRule ( TestTools . getEnglishMessages ( ) ) ; } public void testRule ( ) throws IOException { check ( 0 , "Nie róbmy nic na łapu-capu." ) ; check ( 0 , "Jedzmy kogel-mogel." ) ; check ( 1 , "bim bom" , new String [ ] { "bim-bom" } ) ; } public void testCompoundFile ( ) throws IOException { final MorfologikPolishSpellerRule spellRule = new MorfologikPolishSpellerRule ( TestTools . getMessages ( "pl" ) , new Polish ( ) ) ; final InputStream file = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( "/pl/compounds.txt" ) ; try ( Scanner scanner = new Scanner ( file , "UTF-8" ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) . trim ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } if ( line . endsWith ( "+" ) ) { line = removeLastCharacter ( line ) ; line = line . replace ( '-' , ' ' ) ; final RuleMatch [ ] ruleMatches = spellRule . match ( langTool . getAnalyzedSentence ( line ) ) ; assertEquals ( "The entry: " + line + " is not found in the spelling dictionary!" , 0 , ruleMatches . length ) ; } else if ( line . endsWith ( "*" ) ) { line = removeLastCharacter ( line ) ; final RuleMatch [ ] ruleMatches = spellRule . match ( langTool . getAnalyzedSentence ( line ) ) ; assertEquals ( "The entry: " + line + " is not found in the spelling dictionary!" , 0 , ruleMatches . length ) ; } else { assertEquals ( "The entry: " + line + " is not found in the spelling dictionary!" , 0 , spellRule . match ( langTool . getAnalyzedSentence ( line ) ) . length ) ; assertEquals ( "The entry: " + line . replace ( "-" , "" ) + " is not found in the spelling dictionary!" , 0 , spellRule . match ( langTool . getAnalyzedSentence ( line . replace ( "-" , "" ) ) ) . length ) ; } } } } private String removeLastCharacter ( String str ) { return str . substring ( 0 , str . length ( ) - 1 ) ; } }
package org . languagetool . rules . pl ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class PolishPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . pl ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Polish ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class PolishWordRepeatRuleTest extends TestCase { public void testRule ( ) throws IOException { final PolishWordRepeatRule rule = new PolishWordRepeatRule ( TestTools . getEnglishMessages ( ) ) ; RuleMatch [ ] matches ; JLanguageTool langTool = new JLanguageTool ( new Polish ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "To jest zdanie próbne." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "On tak się bardzo nie martwił, bo przecież musiał się umyć." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Na dyskotece tańczył jeszcze, choć był na bani." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Żadnych „ale”." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Był on bowiem pięknym strzelcem bowiem." ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Mówiła długo, żeby tylko mówić długo." ) ) ; assertEquals ( 2 , matches . length ) ; } }
package org . languagetool . rules . pl ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Polish ; import org . languagetool . rules . RuleMatch ; public class SimpleReplaceRuleTest extends TestCase { private SimpleReplaceRule rule ; private JLanguageTool langTool ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; rule = new SimpleReplaceRule ( TestTools . getMessages ( "pl" ) ) ; langTool = new JLanguageTool ( new Polish ( ) ) ; } public void testRule ( ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Wszystko w porządku." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Pola lodowe" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Witamy prez. Komorowskiego!" ) ) . length ) ; checkSimpleReplaceRule ( "Piaty przypadek." , "Piąty" ) ; checkSimpleReplaceRule ( "To piaty przypadek." , "piąty" ) ; } private void checkSimpleReplaceRule ( String sentence , String word ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( "Invalid matches.length while checking sentence: " + sentence , 1 , matches . length ) ; assertEquals ( "Invalid replacement count wile checking sentence: " + sentence , 1 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( "Invalid suggested replacement while checking sentence: " + sentence , word , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . pl ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Polish ; import java . io . IOException ; import java . util . Collections ; public class PolishUnpairedBracketsRuleTest extends TestCase { public void testRulePolish ( ) throws IOException { Polish language = new Polish ( ) ; PolishUnpairedBracketsRule rule = new PolishUnpairedBracketsRule ( TestTools . getEnglishMessages ( ) , language ) ; JLanguageTool lt = new JLanguageTool ( language ) ; assertEquals ( 0 , getMatches ( "(To jest zdanie do testowania)." , rule , lt ) ) ; assertEquals ( 0 , getMatches ( "Piosenka ta trafiła na wiele list \"Best of...\", włączając w to te, które zostały utworzone przez magazyn Rolling Stone." , rule , lt ) ) ; assertEquals ( 0 , getMatches ( "A \"B\" C." , rule , lt ) ) ; assertEquals ( 0 , getMatches ( "\"A\" B \"C\"." , rule , lt ) ) ; assertEquals ( 1 , getMatches ( "W tym zdaniu jest niesparowany „cudzysłów." , rule , lt ) ) ; } private int getMatches ( String input , PolishUnpairedBracketsRule rule , JLanguageTool lt ) throws IOException { return rule . match ( Collections . singletonList ( lt . getAnalyzedSentence ( input ) ) ) . length ; } }
package org . languagetool . rules . pl ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Polish ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import static org . junit . Assert . assertEquals ; public class MorfologikPolishSpellerRuleTest { @ Test public void testMorfologikSpeller ( ) throws IOException { final MorfologikPolishSpellerRule rule = new MorfologikPolishSpellerRule ( TestTools . getMessages ( "pl" ) , new Polish ( ) ) ; final JLanguageTool langTool = new JLanguageTool ( new Polish ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "To jest test bez jakiegokolwiek błędu." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Żółw na starość wydziela dziwną woń." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "LanguageTool jest świetny!" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Gdym to zobaczył, zdębiałem." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Bogactwo nie rośnie proporcjonalnie do jej rozwoju techniczno-terytorialnego." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Antypostmodernistyczna batalia hiperfilozofów" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Trzynastobitowe przystawki w kolorze zgniłożółtym" ) ) . length ) ; final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "Zolw" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 4 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( "Żółw" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "aõh" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Niby-artysta spotkał się z quasi-opiekunem i niby-Francuzem." ) ) . length ) ; final RuleMatch [ ] prunedMatches = rule . match ( langTool . getAnalyzedSentence ( "Clarkem" ) ) ; assertEquals ( 1 , prunedMatches . length ) ; assertEquals ( 5 , prunedMatches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( "Clarke" , prunedMatches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "Clarkiem" , prunedMatches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "Ciarkę" , prunedMatches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; assertEquals ( "Clarkom" , prunedMatches [ 0 ] . getSuggestedReplacements ( ) . get ( 3 ) ) ; assertEquals ( "Czarkę" , prunedMatches [ 0 ] . getSuggestedReplacements ( ) . get ( 4 ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "premoc" ) ) . length ) ; } }
package org . languagetool . rules . pl ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Polish ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . WordRepeatRule ; public class WordRepeatRuleTest extends TestCase { public void testRulePolish ( ) throws IOException { final Polish polish = new Polish ( ) ; final WordRepeatRule rule = new WordRepeatRule ( TestTools . getEnglishMessages ( ) , polish ) ; RuleMatch [ ] matches ; final JLanguageTool langTool = new JLanguageTool ( polish ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "To jest zdanie." ) ) ; assertEquals ( 0 , matches . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "W w. XVI język jest jak kipiący kocioł." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Co jeszcze było smutniejsze, to to, że im się jeść chciało potężnie." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Tra ta ta!" ) ) . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "To jest jest zdanie." ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . rules . pl ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . language . Polish ; import org . languagetool . rules . patterns . Match ; import org . languagetool . rules . patterns . Match . CaseConversion ; import org . languagetool . rules . patterns . Match . IncludeRange ; import org . languagetool . rules . patterns . MatchState ; public class MatchTest extends TestCase { private AnalyzedTokenReadings getAnalyzedTokenReadings ( String token , String posTag , String lemma ) { return new AnalyzedTokenReadings ( new AnalyzedToken ( token , posTag , lemma ) , 0 ) ; } private Match getMatch ( String posTag , String posTagReplace , boolean spell ) { final Match match = new Match ( posTag , posTagReplace , true , null , null , CaseConversion . NONE , false , spell , IncludeRange . NONE ) ; return match ; } private Match getTextMatch ( String regexMatch , String regexpReplace , boolean spell ) { final Match match = new Match ( null , null , false , regexMatch , regexpReplace , CaseConversion . NONE , false , spell , IncludeRange . NONE ) ; return match ; } public void testSpeller ( ) throws Exception { Match match = getMatch ( "POS1" , "POS2" , true ) ; final Polish polish = new Polish ( ) ; MatchState matchState = new MatchState ( match , polish . getSynthesizer ( ) ) ; matchState . setToken ( getAnalyzedTokenReadings ( "inflectedform11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[]" , Arrays . toString ( matchState . toFinalString ( polish ) ) ) ; match = getMatch ( "POS1" , "POS2" , false ) ; matchState = new MatchState ( match , polish . getSynthesizer ( ) ) ; matchState . setToken ( getAnalyzedTokenReadings ( "inflectedform11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[(inflectedform11)]" , Arrays . toString ( matchState . toFinalString ( polish ) ) ) ; match = getMatch ( "subst:sg:acc.nom:m3" , "subst:sg:gen:m3" , true ) ; matchState = new MatchState ( match , polish . getSynthesizer ( ) ) ; matchState . setToken ( getAnalyzedTokenReadings ( "AON" , "subst:sg:acc.nom:m3" , "AON" ) ) ; assertEquals ( "[AON-u]" , Arrays . toString ( matchState . toFinalString ( polish ) ) ) ; match = getTextMatch ( "^(.*)$" , "$0-u" , true ) ; match . setLemmaString ( "AON" ) ; matchState = new MatchState ( match , polish . getSynthesizer ( ) ) ; assertEquals ( "[AON-u]" , Arrays . toString ( matchState . toFinalString ( polish ) ) ) ; match . setLemmaString ( "batalion" ) ; matchState = new MatchState ( match , polish . getSynthesizer ( ) ) ; assertEquals ( "[]" , Arrays . toString ( matchState . toFinalString ( polish ) ) ) ; match . setLemmaString ( "ASEAN" ) ; matchState = new MatchState ( match , polish . getSynthesizer ( ) ) ; assertEquals ( "[ASEAN-u]" , Arrays . toString ( matchState . toFinalString ( polish ) ) ) ; } }
package org . languagetool . rules . pl ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Polish ; import org . languagetool . rules . MultipleWhitespaceRule ; import java . io . IOException ; public class MultipleWhitespaceRuleTest extends TestCase { public void testRule ( ) throws IOException { final MultipleWhitespaceRule rule = new MultipleWhitespaceRule ( TestTools . getEnglishMessages ( ) , new Polish ( ) ) ; final JLanguageTool langTool = new JLanguageTool ( new Polish ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "To jest test." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "To jest test." ) ) . length ) ; } }
package org . languagetool . rules . pl ; import org . junit . Test ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class DateCheckFilterTest { @ Test public void testGetDayOfWeek ( ) throws Exception { DateCheckFilter filter = new DateCheckFilter ( ) ; assertThat ( filter . getDayOfWeek ( "niedz" ) , is ( 1 ) ) ; assertThat ( filter . getDayOfWeek ( "pon" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Pon" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "pon." ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "poniedziałek" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Poniedziałek" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "wtorek" ) , is ( 3 ) ) ; assertThat ( filter . getDayOfWeek ( "pt" ) , is ( 6 ) ) ; assertThat ( filter . getDayOfWeek ( "piątek" ) , is ( 6 ) ) ; } @ Test public void testMonth ( ) throws Exception { DateCheckFilter filter = new DateCheckFilter ( ) ; assertThat ( filter . getMonth ( "I" ) , is ( 1 ) ) ; assertThat ( filter . getMonth ( "XII" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "grudnia" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "Grudnia" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "GRUDNIA" ) , is ( 12 ) ) ; } }
package org . languagetool . rules . ca ; import java . io . IOException ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import java . util . ResourceBundle ; import java . util . Scanner ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tools . StringTools ; public class AccentuationCheckRule extends CatalanRule { private static final String FILE_NAME = "/ca/verb_senseaccent_nom_ambaccent.txt" ; private static final String FILE_NAME2 = "/ca/verb_senseaccent_adj_ambaccent.txt" ; private static final String FILE_ENCODING = "utf-8" ; private static final Pattern PREPOSICIO_DE = Pattern . compile ( "de|d'|del|dels" ) ; private static final Pattern ARTICLE_EL_MS = Pattern . compile ( "el|l'|El|L'" ) ; private static final Pattern ARTICLE_EL_FS = Pattern . compile ( "la|l'|La|L'" ) ; private static final Pattern ARTICLE_EL_MP = Pattern . compile ( "els|Els" ) ; private static final Pattern ARTICLE_EL_FP = Pattern . compile ( "les|Les" ) ; private static final Pattern DETERMINANT = Pattern . compile ( "D[^R].*" ) ; private static final Pattern DETERMINANT_MS = Pattern . compile ( "D[^R].[MC][SN].*" ) ; private static final Pattern DETERMINANT_FS = Pattern . compile ( "D[^R].[FC][SN].*" ) ; private static final Pattern DETERMINANT_MP = Pattern . compile ( "D[^R].[MC][PN].*" ) ; private static final Pattern DETERMINANT_FP = Pattern . compile ( "D[^R].[FC][PN].*" ) ; private static final Pattern NOM_MS = Pattern . compile ( "NC[MC][SN].*" ) ; private static final Pattern NOM_FS = Pattern . compile ( "NC[FC][SN].*" ) ; private static final Pattern NOM_MP = Pattern . compile ( "NC[MC][PN].*" ) ; private static final Pattern NOM_FP = Pattern . compile ( "NC[FC][PN].*" ) ; private static final Pattern ADJECTIU_MS = Pattern . compile ( "AQ.[MC][SN].*|V.P..SM.?|PX.MS.*" ) ; private static final Pattern ADJECTIU_FS = Pattern . compile ( "AQ.[FC][SN].*|V.P..SF.?|PX.FS.*" ) ; private static final Pattern ADJECTIU_MP = Pattern . compile ( "AQ.[MC][PN].*|V.P..PM.?|PX.MP.*" ) ; private static final Pattern ADJECTIU_FP = Pattern . compile ( "AQ.[FC][PN].*|V.P..PF.?|PX.FP.*" ) ; private static final Pattern INFINITIU = Pattern . compile ( "V.N.*" ) ; private static final Pattern VERB_CONJUGAT = Pattern . compile ( "V.[^NGP].*|_GV_" ) ; private static final Pattern PARTICIPI_MS = Pattern . compile ( "V.P.*SM.?" ) ; private static final Pattern GRUP_VERBAL = Pattern . compile ( "_GV_" ) ; private static final Pattern VERB_3S = Pattern . compile ( "V...3S..?" ) ; private static final Pattern NOT_IN_PREV_TOKEN = Pattern . compile ( "VA.*|PP.*|P0.*|VSP.*" ) ; private static final Pattern BEFORE_ADJECTIVE_MS = Pattern . compile ( "SPS00|D[^R].[MC][SN].*|V.[^NGP].*|PX.*" ) ; private static final Pattern BEFORE_ADJECTIVE_FS = Pattern . compile ( "SPS00|D[^R].[FC][SN].*|V.[^NGP].*|PX.*" ) ; private static final Pattern BEFORE_ADJECTIVE_MP = Pattern . compile ( "SPS00|D[^R].[MC][PN].*|V.[^NGP].*|PX.*" ) ; private static final Pattern BEFORE_ADJECTIVE_FP = Pattern . compile ( "SPS00|D[^R].[FC][PN].*|V.[^NGP].*|PX.*" ) ; private static final Pattern GN = Pattern . compile ( ".*_GN_.*|<?/?N[CP].*" ) ; private static final Pattern EXCEPCIONS_DARRERE_DE = Pattern . compile ( "forma|manera|por|costat" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern LOCUCIONS = Pattern . compile ( ".*LOC.*" ) ; private static final Pattern PRONOM_FEBLE = Pattern . compile ( "P0.{6}|PP3CN000|PP3NN000|PP3CP000|PP3CSD00" ) ; private final Map < String , AnalyzedTokenReadings > relevantWords ; private final Map < String , AnalyzedTokenReadings > relevantWords2 ; public AccentuationCheckRule ( ResourceBundle messages ) throws IOException { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setLocQualityIssueType ( ITSIssueType . Grammar ) ; relevantWords = loadWords ( FILE_NAME ) ; relevantWords2 = loadWords ( FILE_NAME2 ) ; } @ Override public String getId ( ) { return "ACCENTUATION_CHECK" ; } @ Override public String getDescription ( ) { return "Comprova si la paraula ha de dur accent gr\u00E0fic." ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; for ( int i = 1 ; i < tokens . length ; i ++ ) { final String token ; if ( i == 1 ) { token = tokens [ i ] . getToken ( ) . toLowerCase ( ) ; } else { token = tokens [ i ] . getToken ( ) ; } final String prevToken = tokens [ i - 1 ] . getToken ( ) ; String prevPrevToken = "" ; if ( i > 2 ) { prevPrevToken = tokens [ i - 2 ] . getToken ( ) ; } String nextToken = "" ; if ( i < tokens . length - 1 ) { nextToken = tokens [ i + 1 ] . getToken ( ) ; } String nextNextToken = "" ; if ( i < tokens . length - 2 ) { nextNextToken = tokens [ i + 2 ] . getToken ( ) ; } boolean isRelevantWord = false ; boolean isRelevantWord2 = false ; if ( StringTools . isEmpty ( token ) ) { continue ; } if ( relevantWords . containsKey ( token ) ) { isRelevantWord = true ; } if ( relevantWords2 . containsKey ( token ) ) { isRelevantWord2 = true ; } if ( ! isRelevantWord && ! isRelevantWord2 ) { continue ; } if ( matchPostagRegexp ( tokens [ i - 1 ] , PRONOM_FEBLE ) && ! prevToken . startsWith ( "'" ) && ! prevToken . startsWith ( "-" ) ) { continue ; } String replacement = null ; final Matcher mPreposicioDE = PREPOSICIO_DE . matcher ( nextToken ) ; final Matcher mExcepcionsDE = EXCEPCIONS_DARRERE_DE . matcher ( nextNextToken ) ; final Matcher mArticleELMS = ARTICLE_EL_MS . matcher ( prevToken ) ; final Matcher mArticleELFS = ARTICLE_EL_FS . matcher ( prevToken ) ; final Matcher mArticleELMP = ARTICLE_EL_MP . matcher ( prevToken ) ; final Matcher mArticleELFP = ARTICLE_EL_FP . matcher ( prevToken ) ; if ( isRelevantWord && ! matchPostagRegexp ( tokens [ i ] , GN ) ) { if ( tokens [ i - 1 ] . hasPosTag ( "SPS00" ) && ! tokens [ i - 1 ] . hasPosTag ( "RG" ) && ! matchPostagRegexp ( tokens [ i - 1 ] , DETERMINANT ) && ! matchPostagRegexp ( tokens [ i ] , INFINITIU ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } else if ( ( ( matchPostagRegexp ( tokens [ i - 1 ] , DETERMINANT_MS ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_MS ) && ! token . equals ( "cantar" ) ) || ( matchPostagRegexp ( tokens [ i - 1 ] , DETERMINANT_MP ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_MP ) ) || ( matchPostagRegexp ( tokens [ i - 1 ] , DETERMINANT_FS ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_FS ) && ! token . equals ( "venia" ) && ! token . equals ( "tenia" ) && ! token . equals ( "continua" ) && ! token . equals ( "genera" ) && ! token . equals ( "faria" ) ) || ( matchPostagRegexp ( tokens [ i - 1 ] , DETERMINANT_FP ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_FP ) ) ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } else if ( i > 2 && matchPostagRegexp ( tokens [ i - 2 ] , VERB_CONJUGAT ) && ( ( matchPostagRegexp ( tokens [ i - 1 ] , DETERMINANT_MS ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_MS ) ) || ( matchPostagRegexp ( tokens [ i - 1 ] , DETERMINANT_MP ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_MP ) ) || ( matchPostagRegexp ( tokens [ i - 1 ] , DETERMINANT_FS ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_FS ) ) || ( matchPostagRegexp ( tokens [ i - 1 ] , DETERMINANT_FP ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_FP ) ) ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } else if ( i > 2 && matchPostagRegexp ( tokens [ i - 2 ] , VERB_CONJUGAT ) && ( ( mArticleELMS . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_MS ) ) || ( mArticleELMP . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_MP ) ) || ( mArticleELFS . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_FS ) ) || ( mArticleELFP . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_FP ) ) ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } else if ( ! matchPostagRegexp ( tokens [ i ] , PARTICIPI_MS ) && ! token . equals ( "venia" ) && ! token . equals ( "venies" ) && ! token . equals ( "tenia" ) && ! token . equals ( "tenies" ) && ! token . equals ( "faria" ) && ! token . equals ( "faries" ) && ! token . equals ( "espero" ) && ! token . equals ( "continua" ) && ! token . equals ( "continues" ) && ! token . equals ( "cantar" ) && ! prevToken . equals ( "que" ) && ! prevToken . equals ( "qui" ) && ! prevToken . equals ( "què" ) && mPreposicioDE . matches ( ) && ! matchPostagRegexp ( tokens [ i - 1 ] , NOT_IN_PREV_TOKEN ) && ! matchPostagRegexp ( tokens [ i + 1 ] , LOCUCIONS ) && ( i < tokens . length - 2 ) && ! matchPostagRegexp ( tokens [ i + 2 ] , INFINITIU ) && ! mExcepcionsDE . matches ( ) && ! tokens [ i - 1 ] . hasPosTag ( "RG" ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } else if ( ! token . equals ( "venia" ) && ! token . equals ( "venies" ) && ! token . equals ( "tenia" ) && ! token . equals ( "tenies" ) && ! token . equals ( "faria" ) && ! token . equals ( "faries" ) && ! token . equals ( "continua" ) && ! token . equals ( "continues" ) && ! token . equals ( "cantar" ) && ! token . equals ( "diferencia" ) && ! token . equals ( "diferencies" ) && ! token . equals ( "distancia" ) && ! token . equals ( "distancies" ) && ( ( mArticleELMS . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_MS ) ) || ( mArticleELFS . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_FS ) ) || ( mArticleELMP . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_MP ) ) || ( mArticleELFP . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_FP ) ) ) && mPreposicioDE . matches ( ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } else if ( ! token . equals ( "pronuncia" ) && ! token . equals ( "espero" ) && ! token . equals ( "pronuncies" ) && ! token . equals ( "venia" ) && ! token . equals ( "venies" ) && ! token . equals ( "tenia" ) && ! token . equals ( "tenies" ) && ! token . equals ( "continua" ) && ! token . equals ( "continues" ) && ! token . equals ( "faria" ) && ! token . equals ( "faries" ) && ! token . equals ( "genera" ) && ! token . equals ( "figuri" ) && ( i < tokens . length - 1 ) && ( ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_MS ) && matchPostagRegexp ( tokens [ i + 1 ] , ADJECTIU_MS ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_FS ) && matchPostagRegexp ( tokens [ i + 1 ] , ADJECTIU_FS ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_MP ) && matchPostagRegexp ( tokens [ i + 1 ] , ADJECTIU_MP ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_FP ) && matchPostagRegexp ( tokens [ i + 1 ] , ADJECTIU_FP ) ) ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } else if ( ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_MS ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_MS ) && ! matchPostagRegexp ( tokens [ i ] , VERB_3S ) && ! matchPostagRegexp ( tokens [ i ] , GRUP_VERBAL ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_FS ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_FS ) && ! matchPostagRegexp ( tokens [ i ] , VERB_3S ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_MP ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_MP ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_FP ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_FP ) ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } else if ( nextToken . equals ( "que" ) && i > 2 && ( ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_MS ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_MS ) && matchPostagRegexp ( tokens [ i - 2 ] , DETERMINANT_MS ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_FS ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_FS ) && matchPostagRegexp ( tokens [ i - 2 ] , DETERMINANT_FS ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_MP ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_MP ) && matchPostagRegexp ( tokens [ i - 2 ] , DETERMINANT_MP ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_FP ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_FP ) && matchPostagRegexp ( tokens [ i - 2 ] , DETERMINANT_FP ) ) ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } else if ( nextToken . equals ( "que" ) && ( ( mArticleELMS . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_MS ) ) || ( mArticleELFS . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_FS ) ) || ( mArticleELMP . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_MP ) ) || ( mArticleELFP . matches ( ) && matchPostagRegexp ( relevantWords . get ( token ) , NOM_FP ) ) ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } if ( ! token . equals ( "pronuncia" ) && ! token . equals ( "espero" ) && ! token . equals ( "pronuncies" ) && ! token . equals ( "venia" ) && ! token . equals ( "venies" ) && ! token . equals ( "tenia" ) && ! token . equals ( "tenies" ) && ! token . equals ( "continua" ) && ! token . equals ( "continues" ) && ! token . equals ( "faria" ) && ! token . equals ( "faries" ) && ! token . equals ( "genera" ) && ! token . equals ( "figuri" ) && i > 2 && tokens [ i - 2 ] . hasPosTag ( "SPS00" ) && ! tokens [ i - 2 ] . hasPosTag ( "RG" ) && ( ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_MS ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_MS ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_FS ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_FS ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_MP ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_MP ) ) || ( matchPostagRegexp ( relevantWords . get ( token ) , NOM_FP ) && matchPostagRegexp ( tokens [ i - 1 ] , ADJECTIU_FP ) ) ) ) { replacement = relevantWords . get ( token ) . getToken ( ) ; } } if ( isRelevantWord2 && ! matchPostagRegexp ( tokens [ i ] , GN ) ) { if ( ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_MS ) && matchPostagRegexp ( tokens [ i - 1 ] , NOM_MS ) && ! tokens [ i - 1 ] . hasPosTag ( "_GN_FS" ) && matchPostagRegexp ( tokens [ i ] , VERB_CONJUGAT ) && ! matchPostagRegexp ( tokens [ i ] , VERB_3S ) ) || ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_FS ) && prevPrevToken . equalsIgnoreCase ( "de" ) && ( prevToken . equals ( "manera" ) || prevToken . equals ( "forma" ) ) ) || ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_MP ) && matchPostagRegexp ( tokens [ i - 1 ] , NOM_MP ) ) || ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_FP ) && matchPostagRegexp ( tokens [ i - 1 ] , NOM_FP ) ) ) { replacement = relevantWords2 . get ( token ) . getToken ( ) ; } else if ( ( i < tokens . length - 1 ) && ! prevToken . equals ( "que" ) && ! matchPostagRegexp ( tokens [ i - 1 ] , NOT_IN_PREV_TOKEN ) && ( ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_MS ) && matchPostagRegexp ( tokens [ i + 1 ] , NOM_MS ) && matchPostagRegexp ( tokens [ i - 1 ] , BEFORE_ADJECTIVE_MS ) ) || ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_FS ) && matchPostagRegexp ( tokens [ i + 1 ] , NOM_FS ) && matchPostagRegexp ( tokens [ i - 1 ] , BEFORE_ADJECTIVE_FS ) ) || ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_MP ) && matchPostagRegexp ( tokens [ i + 1 ] , NOM_MP ) && matchPostagRegexp ( tokens [ i - 1 ] , BEFORE_ADJECTIVE_MP ) ) || ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_FP ) && matchPostagRegexp ( tokens [ i + 1 ] , NOM_FP ) && matchPostagRegexp ( tokens [ i - 1 ] , BEFORE_ADJECTIVE_FP ) ) ) ) { replacement = relevantWords2 . get ( token ) . getToken ( ) ; } else if ( ( i < tokens . length - 1 ) && ( ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_MS ) && matchPostagRegexp ( tokens [ i + 1 ] , NOM_MS ) && mArticleELMS . matches ( ) ) || ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_FS ) && matchPostagRegexp ( tokens [ i + 1 ] , NOM_FS ) && mArticleELFS . matches ( ) ) || ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_MP ) && matchPostagRegexp ( tokens [ i + 1 ] , NOM_MP ) && mArticleELMP . matches ( ) ) || ( matchPostagRegexp ( relevantWords2 . get ( token ) , ADJECTIU_FP ) && matchPostagRegexp ( tokens [ i + 1 ] , NOM_FP ) && mArticleELFP . matches ( ) ) ) ) { replacement = relevantWords2 . get ( token ) . getToken ( ) ; } } if ( replacement != null ) { final String msg = "Si \u00E9s un nom o un adjectiu, ha de portar accent." ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ i ] . getStartPos ( ) , tokens [ i ] . getEndPos ( ) , msg , "Falta un accent" ) ; ruleMatch . setSuggestedReplacement ( replacement ) ; ruleMatches . add ( ruleMatch ) ; } } return toRuleMatchArray ( ruleMatches ) ; } private boolean matchPostagRegexp ( AnalyzedTokenReadings aToken , Pattern pattern ) { boolean matches = false ; for ( AnalyzedToken analyzedToken : aToken ) { final String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag != null ) { final Matcher m = pattern . matcher ( posTag ) ; if ( m . matches ( ) ) { matches = true ; break ; } } } return matches ; } private Map < String , AnalyzedTokenReadings > loadWords ( String fileName ) throws IOException { final Map < String , AnalyzedTokenReadings > map = new HashMap < > ( ) ; final InputStream inputStream = JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( fileName ) ; try ( Scanner scanner = new Scanner ( inputStream , FILE_ENCODING ) ) { while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) . trim ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } final String [ ] parts = line . split ( ";" ) ; if ( parts . length != 3 ) { throw new IOException ( "Format error in file " + fileName + ", line: " + line + ", " + "expected 3 semicolon-separated parts, got " + parts . length ) ; } final AnalyzedToken analyzedToken = new AnalyzedToken ( parts [ 1 ] , parts [ 2 ] , null ) ; map . put ( parts [ 0 ] , new AnalyzedTokenReadings ( analyzedToken , 0 ) ) ; } } return map ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . pl ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Polish ; import java . io . IOException ; public class UppercaseSentenceStartRuleTest extends TestCase { public void testPolishSpecialCases ( ) throws IOException { final JLanguageTool lt = new JLanguageTool ( new Polish ( ) ) ; assertEquals ( 0 , lt . check ( "Zdanie." ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "To jest lista punktowana:\n\npunkt pierwszy,\n\npunkt drugi,\n\npunkt trzeci." ) . size ( ) ) ; } }
package org . languagetool . tagging . disambiguation ; import java . io . IOException ; import org . languagetool . TestTools ; import org . languagetool . language . Polish ; import org . languagetool . tagging . disambiguation . rules . DisambiguationRuleTest ; import org . languagetool . tagging . pl . PolishTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . WordTokenizer ; public class PolishDisambiguationRuleTest extends DisambiguationRuleTest { private PolishTagger tagger ; private WordTokenizer tokenizer ; private SentenceTokenizer sentenceTokenizer ; private MultiWordChunker disambiguator ; @ Override public void setUp ( ) { tagger = new PolishTagger ( ) ; tokenizer = new WordTokenizer ( ) ; sentenceTokenizer = new SRXSentenceTokenizer ( new Polish ( ) ) ; disambiguator = new MultiWordChunker ( "/pl/multiwords.txt" ) ; } public void testChunker ( ) throws IOException { TestTools . myAssert ( "To test... dezambiguacji" , "/[null]SENT_START To/[ten]adj:sg:acc:n1.n2:pos|To/[ten]adj:sg:nom.voc:n1.n2:pos|To/[to]conj|To/[to]qub|To/[to]subst:sg:acc:n2|To/[to]subst:sg:nom:n2 /[null]null test/[test]subst:sg:acc:m3|test/[test]subst:sg:nom:m3 ./[...]<ELLIPSIS> ./[null]null ./[...]</ELLIPSIS> /[null]null dezambiguacji/[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "On, to znaczy premier, jest niezbyt mądry" , "/[null]SENT_START On/[on]adj:sg:acc:m3:pos|On/[on]adj:sg:nom.voc:m1.m2.m3:pos|On/[on]ppron3:sg:nom:m1.m2.m3:ter:akc.nakc:praep.npraep ,/[null]null /[null]null to/[ten]adj:sg:acc:n1.n2:pos|to/[ten]adj:sg:nom.voc:n1.n2:pos|to/[to znaczy]<TO_ZNACZY>|to/[to]conj|to/[to]qub|to/[to]subst:sg:acc:n2|to/[to]subst:sg:nom:n2 /[null]null znaczy/[to znaczy]</TO_ZNACZY>|znaczy/[znaczyć]verb:fin:sg:ter:imperf:refl.nonrefl /[null]null premier/[premier]subst:sg:nom:m1|premier/[premiera]subst:pl:gen:f ,/[null]null /[null]null jest/[być]verb:fin:sg:ter:imperf:nonrefl /[null]null niezbyt/[niezbyt]adv /[null]null mądry/[mądry]adj:sg:acc:m3:pos|mądry/[mądry]adj:sg:nom.voc:m1.m2.m3:pos|mądry/[mądry]subst:sg:nom:m1|mądry/[mądry]subst:sg:voc:m1" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Lubię go z uwagi na krótkie włosy." , "/[null]SENT_START Lubię/[lubić]verb:fin:sg:pri:imperf:nonrefl|Lubię/[lubić]verb:fin:sg:pri:imperf:refl.nonrefl /[null]null go/[go]subst:pl:acc:n2|go/[go]subst:pl:dat:n2|go/[go]subst:pl:gen:n2|go/[go]subst:pl:inst:n2|go/[go]subst:pl:loc:n2|go/[go]subst:pl:nom:n2|go/[go]subst:pl:voc:n2|go/[go]subst:sg:acc:n2|go/[go]subst:sg:dat:n2|go/[go]subst:sg:gen:n2|go/[go]subst:sg:inst:n2|go/[go]subst:sg:loc:n2|go/[go]subst:sg:nom:n2|go/[go]subst:sg:voc:n2|go/[on]ppron3:sg:acc:m1.m2.m3:ter:nakc:npraep|go/[on]ppron3:sg:gen:m1.m2.m3:ter:nakc:npraep|go/[on]ppron3:sg:gen:n1.n2:ter:nakc:npraep /[null]null z/[z uwagi na]<PREP:ACC>|z/[z]prep:acc:nwok|z/[z]prep:gen:nwok|z/[z]prep:inst:nwok /[null]null uwagi/[uwaga]subst:pl:acc:f|uwagi/[uwaga]subst:pl:nom:f|uwagi/[uwaga]subst:pl:voc:f|uwagi/[uwaga]subst:sg:gen:f /[null]null na/[na]interj|na/[na]prep:acc|na/[na]prep:loc|na/[z uwagi na]</PREP:ACC> /[null]null krótkie/[krótki]adj:pl:acc:m2.m3.f.n1.n2.p2.p3:pos|krótkie/[krótki]adj:pl:nom.voc:m2.m3.f.n1.n2.p2.p3:pos|krótkie/[krótki]adj:sg:acc:n1.n2:pos|krótkie/[krótki]adj:sg:nom.voc:n1.n2:pos /[null]null włosy/[włos]subst:pl:acc:m3|włosy/[włos]subst:pl:nom:m3|włosy/[włos]subst:pl:voc:m3|włosy/[włosy]subst:pl:acc:p3|włosy/[włosy]subst:pl:nom:p3|włosy/[włosy]subst:pl:voc:p3 ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Test..." , "/[null]SENT_START Test/[test]subst:sg:acc:m3|Test/[test]subst:sg:nom:m3 ./[...]<ELLIPSIS> ./[null]null ./[...]</ELLIPSIS>" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Test... " , "/[null]SENT_START Test/[test]subst:sg:acc:m3|Test/[test]subst:sg:nom:m3 ./[...]<ELLIPSIS> ./[null]null ./[...]</ELLIPSIS> /[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; } }
package org . languagetool . tagging . pl ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Polish ; import org . languagetool . tokenizers . WordTokenizer ; public class PolishTaggerTest extends TestCase { private PolishTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new PolishTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Polish ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "To jest duży dom." , "To/[ten]adj:sg:acc:n1.n2:pos|To/[ten]adj:sg:nom.voc:n1.n2:pos|To/[to]conj|To/[to]qub|To/[to]subst:sg:acc:n2|To/[to]subst:sg:nom:n2 -- jest/[być]verb:fin:sg:ter:imperf:nonrefl -- duży/[duży]adj:sg:acc:m3:pos|duży/[duży]adj:sg:nom.voc:m1.m2.m3:pos -- dom/[dom]subst:sg:acc:m3|dom/[dom]subst:sg:nom:m3" , tokenizer , tagger ) ; TestTools . myAssert ( "Krowa pasie się na pastwisku." , "Krowa/[krowa]subst:sg:nom:f -- pasie/[pas]subst:sg:loc:m3|pasie/[pas]subst:sg:voc:m3|pasie/[paść]verb:fin:sg:ter:imperf:refl.nonrefl -- się/[się]qub|się/[się]siebie:acc:nakc|się/[się]siebie:gen:nakc -- na/[na]interj|na/[na]prep:acc|na/[na]prep:loc -- pastwisku/[pastwisko]subst:sg:dat:n2|pastwisku/[pastwisko]subst:sg:loc:n2" , tokenizer , tagger ) ; TestTools . myAssert ( "blablabla" , "blablabla/[null]null" , tokenizer , tagger ) ; } }
package org . languagetool . tokenizers . pl ; import java . util . List ; import junit . framework . TestCase ; import org . languagetool . Language ; import org . languagetool . language . Polish ; public class PolishWordTokenizerTest extends TestCase { public void testTokenize ( ) { final PolishWordTokenizer wordTokenizer = new PolishWordTokenizer ( ) ; final List < String > tokens = wordTokenizer . tokenize ( "To jest\u00A0 test" ) ; assertEquals ( tokens . size ( ) , 6 ) ; assertEquals ( "[To, , jest, \u00A0, , test]" , tokens . toString ( ) ) ; final List < String > tokens2 = wordTokenizer . tokenize ( "To\rłamie" ) ; assertEquals ( 3 , tokens2 . size ( ) ) ; assertEquals ( "[To, \r, łamie]" , tokens2 . toString ( ) ) ; final List < String > tokens3 = wordTokenizer . tokenize ( "A to jest-naprawdę-test!" ) ; assertEquals ( tokens3 . size ( ) , 6 ) ; assertEquals ( "[A, , to, , jest-naprawdę-test, !]" , tokens3 . toString ( ) ) ; final List < String > tokens4 = wordTokenizer . tokenize ( "Niemiecko- i angielsko-polski" ) ; assertEquals ( tokens4 . size ( ) , 6 ) ; assertEquals ( "[Niemiecko, -, , i, , angielsko-polski]" , tokens4 . toString ( ) ) ; final List < String > tokens5 = wordTokenizer . tokenize ( "Widzę krowę -i to dobrze!" ) ; assertEquals ( 11 , tokens5 . size ( ) ) ; assertEquals ( "[Widzę, , krowę, , -, i, , to, , dobrze, !]" , tokens5 . toString ( ) ) ; final List < String > tokens6 = wordTokenizer . tokenize ( "A to jest zdanie—rzeczywiście—z wtrąceniem." ) ; assertEquals ( tokens6 . size ( ) , 14 ) ; assertEquals ( "[A, , to, , jest, , zdanie, —, rzeczywiście, —, z, , wtrąceniem, .]" , tokens6 . toString ( ) ) ; final String compoundSentence = "To jest kobieta-wojownik w polsko-czeskim ubraniu, która wysłała dwa SMS-y." ; List < String > compoundTokens = wordTokenizer . tokenize ( compoundSentence ) ; assertEquals ( 21 , compoundTokens . size ( ) ) ; assertEquals ( "[To, , jest, , kobieta-wojownik, , w, , polsko-czeskim, , ubraniu, ,, , która, , wysłała, , dwa, , SMS-y, .]" , compoundTokens . toString ( ) ) ; Language pl = new Polish ( ) ; wordTokenizer . setTagger ( pl . getTagger ( ) ) ; compoundTokens = wordTokenizer . tokenize ( compoundSentence ) ; assertEquals ( 25 , compoundTokens . size ( ) ) ; assertEquals ( "[To, , jest, , kobieta, -, wojownik, , " + "w, , polsko, -, czeskim, , ubraniu, ,, " + ", która, , wysłała, , dwa, , SMS-y, .]" , compoundTokens . toString ( ) ) ; compoundTokens = wordTokenizer . tokenize ( "Miała osiemnaście-dwadzieścia lat." ) ; assertEquals ( 8 , compoundTokens . size ( ) ) ; assertEquals ( "[Miała, , osiemnaście, -, dwadzieścia, , lat, .]" , compoundTokens . toString ( ) ) ; compoundTokens = wordTokenizer . tokenize ( "Słownik polsko-niemiecko-indonezyjski" ) ; assertEquals ( 7 , compoundTokens . size ( ) ) ; assertEquals ( "[Słownik, , polsko, -, niemiecko, -, indonezyjski]" , compoundTokens . toString ( ) ) ; } }
package org . languagetool . tokenizers . pl ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Polish ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class PolishSentenceTokenizerTest extends TestCase { private final SentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Polish ( ) ) ; public final void testTokenize ( ) { testSplit ( "To się wydarzyło 3.10.2000 i mam na to dowody." ) ; testSplit ( "To było 13.12 - nikt nie zapomni tego przemówienia." ) ; testSplit ( "Heute ist der 13.12.2004." ) ; testSplit ( "To jest np. ten debil spod jedynki." ) ; testSplit ( "To jest 1. wydanie." ) ; testSplit ( "Dziś jest 13. rocznica powstania wąchockiego." ) ; testSplit ( "Das in Punkt 3.9.1 genannte Verhalten." ) ; testSplit ( "To jest tzw. premier." ) ; testSplit ( "Jarek kupił sobie kurteczkę, tj. strój Marka." ) ; testSplit ( "„Prezydent jest niemądry”. " , "Tak wyszło." ) ; testSplit ( "„Prezydent jest niemądry”, powiedział premier" ) ; testSplit ( "Temperatura wody w systemie wynosi 30°C." , "W skład obiegu otwartego wchodzi zbiornik i armatura." ) ; testSplit ( "Zabudowano kolumny o długości 45 m. " , "Woda z ujęcia jest dostarczana do zakładu." ) ; testSplit ( "Najlepszym polskim reżyserem był St. Różewicz. " , "Chodzi o brata wielkiego poety." ) ; testSplit ( "Ks. Jankowski jest prof. teologii." ) ; testSplit ( "To wydarzyło się w 1939 r." , "To był burzliwy rok." ) ; testSplit ( "Prezydent jest popierany przez 20 proc. społeczeństwa." ) ; testSplit ( "Moje wystąpienie ma na celu zmobilizowanie zarządu partii do działań, które umożliwią uzyskanie 40 proc." , "Nie widzę dziś na scenie politycznej formacji, która lepiej by łączyła różne poglądy" ) ; testSplit ( "To jest zmienna A." , "Zaś to jest zmienna B." ) ; testSplit ( "Mam już 20 mln." , "To powinno mi wystarczyć" ) ; testSplit ( "Mam już 20 mln. buraków." ) ; testSplit ( "Rytmem tej wiecznie przemijającej światowej egzystencji […] rytmem mesjańskiej natury jest szczęście." ) ; testSplit ( "W gazecie napisali, że pasy (sic!) pogryzły człowieka." ) ; testSplit ( "Mam w magazynie dwie skrzynie LMD20. " , "Jestem żołnierzem i wiem, jak można ich użyć" ) ; } private void testSplit ( final String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . pl . CompoundRule ; import org . languagetool . rules . pl . MorfologikPolishSpellerRule ; import org . languagetool . rules . pl . PolishUnpairedBracketsRule ; import org . languagetool . rules . pl . PolishWordRepeatRule ; import org . languagetool . rules . pl . SimpleReplaceRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . pl . PolishSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . pl . PolishHybridDisambiguator ; import org . languagetool . tagging . pl . PolishTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . WordTokenizer ; import org . languagetool . tokenizers . pl . PolishWordTokenizer ; public class Polish extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; private PolishWordTokenizer wordTokenizer ; private Disambiguator disambiguator ; private Synthesizer synthesizer ; @ Override public String getName ( ) { return "Polish" ; } @ Override public String getShortName ( ) { return "pl" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "PL" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new PolishTagger ( ) ; } return tagger ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public WordTokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new PolishWordTokenizer ( ) ; wordTokenizer . setTagger ( getTagger ( ) ) ; } return wordTokenizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new PolishHybridDisambiguator ( ) ; } return disambiguator ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new PolishSynthesizer ( ) ; } return synthesizer ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { Contributors . MARCIN_MILKOWSKI } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new UppercaseSentenceStartRule ( messages , this ) , new WordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new SentenceWhitespaceRule ( messages ) , new PolishUnpairedBracketsRule ( messages , this ) , new MorfologikPolishSpellerRule ( messages , this ) , new PolishWordRepeatRule ( messages ) , new CompoundRule ( messages ) , new SimpleReplaceRule ( messages ) ) ; } }
package org . languagetool . synthesis . pl ; import java . io . IOException ; import java . io . InputStream ; import java . net . URL ; import java . util . ArrayList ; import java . util . HashSet ; import java . util . List ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import morfologik . stemming . Dictionary ; import morfologik . stemming . DictionaryLookup ; import morfologik . stemming . IStemmer ; import morfologik . stemming . WordData ; import org . languagetool . AnalyzedToken ; import org . languagetool . JLanguageTool ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . SynthesizerTools ; public class PolishSynthesizer implements Synthesizer { private static final String RESOURCE_FILENAME = "/pl/polish_synth.dict" ; private static final String TAGS_FILE_NAME = "/pl/polish_tags.txt" ; private static final String POTENTIAL_NEGATION_TAG = ":aff" ; private static final String NEGATION_TAG = ":neg" ; private static final String COMP_TAG = "com" ; private static final String SUP_TAG = "sup" ; private volatile Dictionary dictionary ; private List < String > possibleTags ; private Dictionary getDictionary ( ) throws IOException { Dictionary result = this . dictionary ; if ( result == null ) { synchronized ( this ) { result = this . dictionary ; if ( result == null ) { final URL url = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( RESOURCE_FILENAME ) ; this . dictionary = result = Dictionary . read ( url ) ; } } } return result ; } @ Override public final String [ ] synthesize ( final AnalyzedToken token , final String posTag ) throws IOException { if ( posTag == null ) { return null ; } final IStemmer synthesizer = new DictionaryLookup ( getDictionary ( ) ) ; boolean isNegated = false ; if ( token . getPOSTag ( ) != null ) { isNegated = posTag . indexOf ( NEGATION_TAG ) > 0 || token . getPOSTag ( ) . indexOf ( NEGATION_TAG ) > 0 && ! ( posTag . indexOf ( COMP_TAG ) > 0 ) && ! ( posTag . indexOf ( SUP_TAG ) > 0 ) ; } if ( posTag . indexOf ( '+' ) > 0 ) { return synthesize ( token , posTag , true ) ; } final List < String > forms = getWordForms ( token , posTag , isNegated , synthesizer ) ; return forms . toArray ( new String [ forms . size ( ) ] ) ; } @ Override public final String [ ] synthesize ( final AnalyzedToken token , final String pos , final boolean posTagRegExp ) throws IOException { if ( pos == null ) { return null ; } String posTag = pos ; if ( posTagRegExp ) { if ( possibleTags == null ) { try ( InputStream stream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( TAGS_FILE_NAME ) ) { possibleTags = SynthesizerTools . loadWords ( stream ) ; } } final IStemmer synthesizer = new DictionaryLookup ( getDictionary ( ) ) ; final List < String > results = new ArrayList < > ( ) ; boolean isNegated = false ; if ( token . getPOSTag ( ) != null ) { isNegated = posTag . indexOf ( NEGATION_TAG ) > 0 || token . getPOSTag ( ) . indexOf ( NEGATION_TAG ) > 0 && ! ( posTag . indexOf ( COMP_TAG ) > 0 ) && ! ( posTag . indexOf ( SUP_TAG ) > 0 ) ; } if ( isNegated ) { posTag = posTag . replaceAll ( NEGATION_TAG , POTENTIAL_NEGATION_TAG + "?" ) ; } final Pattern p = Pattern . compile ( posTag . replace ( '+' , '|' ) ) ; for ( final String tag : possibleTags ) { final Matcher m = p . matcher ( tag ) ; if ( m . matches ( ) ) { final List < String > wordForms = getWordForms ( token , tag , isNegated , synthesizer ) ; if ( wordForms != null ) { results . addAll ( wordForms ) ; } } } HashSet < String > hs = new HashSet < > ( ) ; hs . addAll ( results ) ; results . clear ( ) ; results . addAll ( hs ) ; return results . toArray ( new String [ results . size ( ) ] ) ; } return synthesize ( token , posTag ) ; } @ Override public final String getPosTagCorrection ( final String posTag ) { if ( posTag . contains ( "." ) ) { final String [ ] tags = posTag . split ( ":" ) ; int pos = - 1 ; for ( int i = 0 ; i < tags . length ; i ++ ) { if ( tags [ i ] . matches ( ".*[a-z]\\.[a-z].*" ) ) { tags [ i ] = "(.*" + tags [ i ] . replace ( "." , ".*|.*" ) + ".*)" ; pos = i ; } } if ( pos == - 1 ) { return posTag ; } final StringBuilder sb = new StringBuilder ( ) ; sb . append ( tags [ 0 ] ) ; for ( int i = 1 ; i < tags . length ; i ++ ) { sb . append ( ':' ) ; sb . append ( tags [ i ] ) ; } return sb . toString ( ) ; } return posTag ; } private List < String > getWordForms ( final AnalyzedToken token , final String posTag , final boolean isNegated , final IStemmer synthesizer ) { final List < String > forms = new ArrayList < > ( ) ; final List < WordData > wordForms ; if ( isNegated ) { wordForms = synthesizer . lookup ( token . getLemma ( ) + "|" + posTag . replaceFirst ( NEGATION_TAG , POTENTIAL_NEGATION_TAG ) ) ; if ( wordForms != null ) { for ( WordData wd : wordForms ) { forms . add ( "nie" + wd . getStem ( ) ) ; } } } else { wordForms = synthesizer . lookup ( token . getLemma ( ) + "|" + posTag ) ; for ( WordData wd : wordForms ) { if ( wd . getStem ( ) != null ) { forms . add ( wd . getStem ( ) . toString ( ) ) ; } } } return forms ; } }
package org . languagetool . rules . pl ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; import org . languagetool . rules . Example ; public final class CompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/pl/compounds.txt" ) ; public CompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "Ten wyraz pisze się z łącznikiem." , "Ten wyraz pisze się razem (bez spacji ani łącznika)." , "Ten wyraz pisze się z łącznikiem lub bez niego." , "Brak łącznika lub zbędny łącznik" ) ; addExamplePair ( Example . wrong ( "Witamy w <marker>Rabce Zdroju</marker>." ) , Example . fixed ( "Witamy w <marker>Rabce-Zdroju</marker>." ) ) ; } @ Override public String getId ( ) { return "PL_COMPOUNDS" ; } @ Override public String getDescription ( ) { return "Sprawdza wyrazy z łącznikiem, np. „łapu capu” zamiast „łapu-capu”" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . rules . pl ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . Example ; import org . languagetool . rules . GenericUnpairedBracketsRule ; public class PolishUnpairedBracketsRule extends GenericUnpairedBracketsRule { private static final List < String > PL_START_SYMBOLS = Arrays . asList ( "[" , "(" , "{" , "„" , "»" , "\"" ) ; private static final List < String > PL_END_SYMBOLS = Arrays . asList ( "]" , ")" , "}" , "”" , "«" , "\"" ) ; public PolishUnpairedBracketsRule ( final ResourceBundle messages , final Language language ) { super ( messages , PL_START_SYMBOLS , PL_END_SYMBOLS ) ; addExamplePair ( Example . wrong ( "To jest zdanie z <marker>„</marker>cudzysłowem." ) , Example . fixed ( "To jest zdanie z <marker>„</marker>cudzysłowem”." ) ) ; } @ Override public String getId ( ) { return "PL_UNPAIRED_BRACKETS" ; } }
package org . languagetool . rules . pl ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . AbstractSimpleReplaceRule ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . ITSIssueType ; public class SimpleReplaceRule extends AbstractSimpleReplaceRule { public static final String POLISH_SIMPLE_REPLACE_RULE = "PL_SIMPLE_REPLACE" ; private static final Map < String , List < String > > wrongWords = load ( "/pl/replace.txt" ) ; private static final Locale PL_LOCALE = new Locale ( "pl" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public SimpleReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; setLocQualityIssueType ( ITSIssueType . Misspelling ) ; setCategory ( new Category ( "Prawdopodobne literówki" ) ) ; setCheckLemmas ( false ) ; addExamplePair ( Example . wrong ( "Uspokój <marker>sei</marker>." ) , Example . fixed ( "Uspokój <marker>się</marker>." ) ) ; } @ Override public final String getId ( ) { return POLISH_SIMPLE_REPLACE_RULE ; } @ Override public String getDescription ( ) { return "Typowe literówki i niepoprawne wyrazy (domowi, sie, niewiadomo, duh, cie…)" ; } @ Override public String getShort ( ) { return "Literówka" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return tokenStr + " to najczęściej błąd; poprawnie pisze się: " + StringUtils . join ( replacements , ", " ) + "." ; } @ Override public boolean isCaseSensitive ( ) { return false ; } @ Override public Locale getLocale ( ) { return PL_LOCALE ; } }
package org . languagetool . rules . ca ; import org . languagetool . rules . AbstractSimpleReplaceRule ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; public class SimpleReplaceRule extends AbstractSimpleReplaceRule { private static final Map < String , List < String > > wrongWords = load ( "/ca/replace.txt" ) ; private static final Locale CA_LOCALE = new Locale ( "CA" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public SimpleReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; super . setCategory ( new Category ( "Errors ortogràfics" ) ) ; super . setLocQualityIssueType ( ITSIssueType . Misspelling ) ; this . setIgnoreTaggedWords ( ) ; } @ Override public final String getId ( ) { return "CA_SIMPLE_REPLACE" ; } @ Override public String getDescription ( ) { return "Detecta paraules incorrectes i proposa suggeriments de canvi" ; } @ Override public String getShort ( ) { return "Paraula incorrecta" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return "Paraula incorrecta." ; } @ Override public boolean isCaseSensitive ( ) { return false ; } @ Override public Locale getLocale ( ) { return CA_LOCALE ; } }
package org . languagetool . rules . pl ; import java . util . Collections ; import java . util . HashSet ; import java . util . ResourceBundle ; import java . util . Set ; import java . util . regex . Pattern ; import org . languagetool . rules . AdvancedWordRepeatRule ; import org . languagetool . rules . Example ; public class PolishWordRepeatRule extends AdvancedWordRepeatRule { private static final Set < String > EXC_WORDS ; static { final Set < String > tempSet = new HashSet < > ( ) ; tempSet . add ( "nie" ) ; tempSet . add ( "tuż" ) ; tempSet . add ( "aż" ) ; tempSet . add ( "to" ) ; tempSet . add ( "siebie" ) ; tempSet . add ( "być" ) ; tempSet . add ( "ani" ) ; tempSet . add ( "ni" ) ; tempSet . add ( "albo" ) ; tempSet . add ( "lub" ) ; tempSet . add ( "czy" ) ; tempSet . add ( "bądź" ) ; tempSet . add ( "jako" ) ; tempSet . add ( "zł" ) ; tempSet . add ( "np" ) ; tempSet . add ( "coraz" ) ; tempSet . add ( "bardzo" ) ; tempSet . add ( "bardziej" ) ; tempSet . add ( "proc" ) ; tempSet . add ( "ten" ) ; tempSet . add ( "jak" ) ; tempSet . add ( "mln" ) ; tempSet . add ( "tys" ) ; tempSet . add ( "swój" ) ; tempSet . add ( "mój" ) ; tempSet . add ( "twój" ) ; tempSet . add ( "nasz" ) ; tempSet . add ( "wasz" ) ; tempSet . add ( "i" ) ; tempSet . add ( "zbyt" ) ; tempSet . add ( "się" ) ; EXC_WORDS = Collections . unmodifiableSet ( tempSet ) ; } private static final Pattern EXC_POS = Pattern . compile ( "prep:.*|ppron.*" ) ; private static final Pattern EXC_NONWORDS = Pattern . compile ( "&quot|&gt|&lt|&amp|[0-9].*|" + "M*(D?C{0,3}|C[DM])(L?X{0,3}|X[LC])(V?I{0,3}|I[VX])$" ) ; public PolishWordRepeatRule ( final ResourceBundle messages ) { super ( messages ) ; addExamplePair ( Example . wrong ( "Mówiła długo, bo lubiła robić wszystko <marker>długo</marker>." ) , Example . fixed ( "Mówiła długo, bo lubiła robić wszystko <marker>powoli</marker>." ) ) ; } @ Override public final String getDescription ( ) { return "Powtórzenia wyrazów w zdaniu (monotonia stylistyczna)" ; } @ Override protected Pattern getExcludedNonWordsPattern ( ) { return EXC_NONWORDS ; } @ Override protected Pattern getExcludedPos ( ) { return EXC_POS ; } @ Override protected Set < String > getExcludedWordsPattern ( ) { return EXC_WORDS ; } @ Override public final String getId ( ) { return "PL_WORD_REPEAT" ; } @ Override public final String getMessage ( ) { return "Powtórzony wyraz w zdaniu" ; } @ Override public final String getShortMessage ( ) { return "Powtórzenie wyrazu" ; } }
package org . languagetool . rules . pl ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; import java . io . IOException ; import java . util . * ; import java . util . regex . Pattern ; public final class MorfologikPolishSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/pl/hunspell/pl_PL.dict" ; private static final Pattern POLISH_TOKENIZING_CHARS = Pattern . compile ( "(?:[Qq]uasi|[Nn]iby)-" ) ; private static final Set < String > prefixes ; static { final Set < String > tempSet = new HashSet < > ( ) ; tempSet . add ( "arcy" ) ; tempSet . add ( "neo" ) ; tempSet . add ( "pre" ) ; tempSet . add ( "anty" ) ; tempSet . add ( "eks" ) ; tempSet . add ( "bez" ) ; tempSet . add ( "beze" ) ; tempSet . add ( "ekstra" ) ; tempSet . add ( "hiper" ) ; tempSet . add ( "infra" ) ; tempSet . add ( "kontr" ) ; tempSet . add ( "maksi" ) ; tempSet . add ( "midi" ) ; tempSet . add ( "między" ) ; tempSet . add ( "mini" ) ; tempSet . add ( "nad" ) ; tempSet . add ( "nade" ) ; tempSet . add ( "około" ) ; tempSet . add ( "ponad" ) ; tempSet . add ( "post" ) ; tempSet . add ( "pro" ) ; tempSet . add ( "przeciw" ) ; tempSet . add ( "pseudo" ) ; tempSet . add ( "super" ) ; tempSet . add ( "śród" ) ; tempSet . add ( "ultra" ) ; tempSet . add ( "wice" ) ; tempSet . add ( "wokół" ) ; tempSet . add ( "wokoło" ) ; prefixes = Collections . unmodifiableSet ( tempSet ) ; } private static final Set < String > bannedSuffixes ; static { final Set < String > tempSet = new HashSet < > ( ) ; tempSet . add ( "ami" ) ; tempSet . add ( "ach" ) ; tempSet . add ( "e" ) ; tempSet . add ( "ego" ) ; tempSet . add ( "em" ) ; tempSet . add ( "emu" ) ; tempSet . add ( "ie" ) ; tempSet . add ( "im" ) ; tempSet . add ( "m" ) ; tempSet . add ( "om" ) ; tempSet . add ( "owie" ) ; tempSet . add ( "owi" ) ; tempSet . add ( "ze" ) ; bannedSuffixes = Collections . unmodifiableSet ( tempSet ) ; } public MorfologikPolishSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; setCategory ( new Category ( "Prawdopodobne literówki" ) ) ; addExamplePair ( Example . wrong ( "To jest zdanie z <marker>bledem</marker>" ) , Example . fixed ( "To jest zdanie z <marker>błędem</marker>." ) ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_PL_PL" ; } @ Override public Pattern tokenizingPattern ( ) { return POLISH_TOKENIZING_CHARS ; } @ Override protected List < RuleMatch > getRuleMatches ( final String word , final int startPos ) throws IOException { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; if ( isMisspelled ( speller1 , word ) && isNotCompound ( word ) ) { final RuleMatch ruleMatch = new RuleMatch ( this , startPos , startPos + word . length ( ) , messages . getString ( "spelling" ) , messages . getString ( "desc_spelling_short" ) ) ; if ( ! isMisspelled ( speller1 , word . toLowerCase ( conversionLocale ) ) ) { List < String > suggestion = Arrays . asList ( word . toLowerCase ( conversionLocale ) ) ; ruleMatch . setSuggestedReplacements ( suggestion ) ; ruleMatches . add ( ruleMatch ) ; return ruleMatches ; } List < String > suggestions = speller1 . getSuggestions ( word ) ; suggestions . addAll ( 0 , getAdditionalTopSuggestions ( suggestions , word ) ) ; suggestions . addAll ( getAdditionalSuggestions ( suggestions , word ) ) ; if ( ! suggestions . isEmpty ( ) ) { ruleMatch . setSuggestedReplacements ( pruneSuggestions ( orderSuggestions ( suggestions , word ) ) ) ; } ruleMatches . add ( ruleMatch ) ; } return ruleMatches ; } private boolean isNotCompound ( String word ) throws IOException { List < String > probablyCorrectWords = new ArrayList < > ( ) ; List < String > testedTokens = new ArrayList < > ( 2 ) ; for ( int i = 2 ; i < word . length ( ) ; i ++ ) { final String first = word . substring ( 0 , i ) ; final String second = word . substring ( i , word . length ( ) ) ; if ( prefixes . contains ( first . toLowerCase ( conversionLocale ) ) && ! isMisspelled ( speller1 , second ) && second . length ( ) > first . length ( ) ) { probablyCorrectWords . add ( word ) ; } else { testedTokens . clear ( ) ; testedTokens . add ( first ) ; testedTokens . add ( second ) ; List < AnalyzedTokenReadings > taggedToks = language . getTagger ( ) . tag ( testedTokens ) ; if ( taggedToks . size ( ) == 2 && ( taggedToks . get ( 0 ) . hasPosTag ( "adja" ) || ( taggedToks . get ( 0 ) . hasPosTag ( "num:comp" ) && ! taggedToks . get ( 0 ) . hasPosTag ( "adv" ) ) ) && taggedToks . get ( 1 ) . hasPartialPosTag ( "adj:" ) ) { probablyCorrectWords . add ( word ) ; } } } if ( ! probablyCorrectWords . isEmpty ( ) ) { addIgnoreTokens ( probablyCorrectWords ) ; return false ; } return true ; } private List < String > pruneSuggestions ( final List < String > suggestions ) { List < String > prunedSuggestions = new ArrayList < > ( suggestions . size ( ) ) ; for ( final String suggestion : suggestions ) { if ( suggestion . indexOf ( ' ' ) == - 1 ) { prunedSuggestions . add ( suggestion ) ; } else { String [ ] complexSug = suggestion . split ( " " ) ; if ( ! bannedSuffixes . contains ( complexSug [ 1 ] ) ) { prunedSuggestions . add ( suggestion ) ; } } } return prunedSuggestions ; } }
package org . languagetool . rules . pl ; import org . languagetool . rules . AbstractDateCheckFilter ; import java . util . Calendar ; import java . util . Locale ; public class DateCheckFilter extends AbstractDateCheckFilter { @ Override protected Calendar getCalendar ( ) { return Calendar . getInstance ( Locale . forLanguageTag ( "pl" ) ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfWeek ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . startsWith ( "pon" ) ) return Calendar . MONDAY ; if ( day . startsWith ( "wt" ) ) return Calendar . TUESDAY ; if ( day . startsWith ( "śr" ) ) return Calendar . WEDNESDAY ; if ( day . startsWith ( "czw" ) ) return Calendar . THURSDAY ; if ( day . equals ( "pt" ) || day . startsWith ( "piątk" ) || day . equals ( "piątek" ) ) return Calendar . FRIDAY ; if ( day . startsWith ( "sob" ) ) return Calendar . SATURDAY ; if ( day . startsWith ( "niedz" ) ) return Calendar . SUNDAY ; throw new RuntimeException ( "Could not find day of week for '" + dayStr + "'" ) ; } @ Override protected String getDayOfWeek ( Calendar date ) { return date . getDisplayName ( Calendar . DAY_OF_WEEK , Calendar . LONG , Locale . forLanguageTag ( "pl" ) ) ; } @ SuppressWarnings ( { "ControlFlowStatementWithoutBraces" , "MagicNumber" } ) @ Override protected int getMonth ( String monthStr ) { String mon = monthStr . toLowerCase ( ) ; if ( mon . equals ( "stycznia" ) || monthStr . equals ( "I" ) ) return 1 ; if ( mon . equals ( "lutego" ) || monthStr . equals ( "II" ) ) return 2 ; if ( mon . equals ( "marca" ) || monthStr . equals ( "III" ) ) return 3 ; if ( mon . equals ( "kwietnia" ) || monthStr . equals ( "IV" ) ) return 4 ; if ( mon . equals ( "maja" ) || monthStr . equals ( "V" ) ) return 5 ; if ( mon . equals ( "czerwca" ) || monthStr . equals ( "VI" ) ) return 6 ; if ( mon . equals ( "lipca" ) || monthStr . equals ( "VII" ) ) return 7 ; if ( mon . equals ( "sierpnia" ) || monthStr . equals ( "VIII" ) ) return 8 ; if ( mon . equals ( "września" ) || monthStr . equals ( "IX" ) ) return 9 ; if ( mon . equals ( "października" ) || monthStr . equals ( "X" ) ) return 10 ; if ( mon . equals ( "listopada" ) || monthStr . equals ( "XI" ) ) return 11 ; if ( mon . equals ( "grudnia" ) || monthStr . equals ( "XII" ) ) return 12 ; throw new RuntimeException ( "Could not find month '" + monthStr + "'" ) ; } }
package org . languagetool . tagging . disambiguation . pl ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . language . Polish ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . MultiWordChunker ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; public class PolishHybridDisambiguator implements Disambiguator { private final Disambiguator chunker = new MultiWordChunker ( "/pl/multiwords.txt" ) ; private final Disambiguator disambiguator = new XmlRuleDisambiguator ( new Polish ( ) ) ; @ Override public final AnalyzedSentence disambiguate ( AnalyzedSentence input ) throws IOException { return chunker . disambiguate ( disambiguator . disambiguate ( input ) ) ; } }
package org . languagetool . tagging . pl ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tagging . BaseTagger ; import org . languagetool . tools . StringTools ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; public class PolishTagger extends BaseTagger { private final Locale plLocale = new Locale ( "pl" ) ; public PolishTagger ( ) { super ( "/pl/polish.dict" ) ; } @ Override public String getManualAdditionsFileName ( ) { return "/pl/added.txt" ; } @ Override public final List < AnalyzedTokenReadings > tag ( final List < String > sentenceTokens ) { List < AnalyzedToken > taggerTokens ; List < AnalyzedToken > lowerTaggerTokens ; List < AnalyzedToken > upperTaggerTokens ; final List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; int pos = 0 ; for ( String word : sentenceTokens ) { final List < AnalyzedToken > l = new ArrayList < > ( ) ; final String lowerWord = word . toLowerCase ( plLocale ) ; taggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( word ) ) ; lowerTaggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( lowerWord ) ) ; final boolean isLowercase = word . equals ( lowerWord ) ; addTokens ( taggerTokens , l ) ; if ( ! isLowercase ) { addTokens ( lowerTaggerTokens , l ) ; } if ( lowerTaggerTokens . isEmpty ( ) && taggerTokens . isEmpty ( ) ) { if ( isLowercase ) { upperTaggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( StringTools . uppercaseFirstChar ( word ) ) ) ; if ( ! upperTaggerTokens . isEmpty ( ) ) { addTokens ( upperTaggerTokens , l ) ; } else { l . add ( new AnalyzedToken ( word , null , null ) ) ; } } else { l . add ( new AnalyzedToken ( word , null , null ) ) ; } } tokenReadings . add ( new AnalyzedTokenReadings ( l , pos ) ) ; pos += word . length ( ) ; } return tokenReadings ; } private void addTokens ( final List < AnalyzedToken > taggedTokens , final List < AnalyzedToken > l ) { if ( taggedTokens != null ) { for ( AnalyzedToken at : taggedTokens ) { final String [ ] tagsArr = StringTools . asString ( at . getPOSTag ( ) ) . split ( "\\+" ) ; for ( final String currTag : tagsArr ) { l . add ( new AnalyzedToken ( at . getToken ( ) , currTag , at . getLemma ( ) ) ) ; } } } } }
package org . languagetool . tokenizers . pl ; import java . io . IOException ; import java . util . * ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tagging . BaseTagger ; import org . languagetool . tagging . Tagger ; import org . languagetool . tokenizers . WordTokenizer ; public class PolishWordTokenizer extends WordTokenizer { private final String plTokenizing ; private Tagger tagger ; private static final Set < String > prefixes ; static { final Set < String > tempSet = new HashSet < > ( Arrays . asList ( "arcy" , "neo" , "pre" , "anty" , "eks" , "bez" , "beze" , "ekstra" , "hiper" , "infra" , "kontr" , "maksi" , "midi" , "między" , "mini" , "nad" , "nade" , "około" , "ponad" , "post" , "pro" , "przeciw" , "pseudo" , "super" , "śród" , "ultra" , "wice" , "wokół" , "wokoło" ) ) ; prefixes = Collections . unmodifiableSet ( tempSet ) ; } public PolishWordTokenizer ( ) { plTokenizing = super . getTokenizingCharacters ( ) + "–" ; } @ Override public List < String > tokenize ( final String text ) { final List < String > l = new ArrayList < > ( ) ; final StringTokenizer st = new StringTokenizer ( text , plTokenizing , true ) ; while ( st . hasMoreElements ( ) ) { final String token = st . nextToken ( ) ; if ( token . length ( ) > 1 ) { if ( token . endsWith ( "-" ) ) { l . add ( token . substring ( 0 , token . length ( ) - 1 ) ) ; l . add ( "-" ) ; } else if ( token . charAt ( 0 ) == '-' ) { l . add ( "-" ) ; l . add ( token . substring ( 1 , token . length ( ) ) ) ; } else if ( token . contains ( "-" ) ) { String [ ] tokenParts = token . split ( "-" ) ; if ( prefixes . contains ( tokenParts [ 0 ] ) || tagger == null ) { l . add ( token ) ; } else { List < String > testedTokens = new ArrayList < > ( tokenParts . length + 1 ) ; Collections . addAll ( testedTokens , tokenParts ) ; testedTokens . add ( token ) ; try { List < AnalyzedTokenReadings > taggedToks = tagger . tag ( testedTokens ) ; if ( taggedToks . size ( ) == tokenParts . length + 1 && ! taggedToks . get ( tokenParts . length ) . isTagged ( ) ) { boolean isCompound = false ; switch ( tokenParts . length ) { case 2 : if ( ( taggedToks . get ( 0 ) . hasPosTag ( "adja" ) && taggedToks . get ( 1 ) . hasPartialPosTag ( "adj:" ) ) || ( taggedToks . get ( 0 ) . hasPartialPosTag ( "subst:" ) && taggedToks . get ( 1 ) . hasPartialPosTag ( "subst:" ) ) || ( taggedToks . get ( 0 ) . hasPartialPosTag ( "num:" ) && taggedToks . get ( 1 ) . hasPartialPosTag ( "num:" ) ) ) { isCompound = true ; } break ; case 3 : if ( taggedToks . get ( 0 ) . hasPosTag ( "adja" ) && taggedToks . get ( 1 ) . hasPosTag ( "adja" ) && taggedToks . get ( 2 ) . hasPartialPosTag ( "adj:" ) ) { isCompound = true ; } break ; } if ( isCompound ) { for ( int i = 0 ; i < tokenParts . length ; i ++ ) { l . add ( tokenParts [ i ] ) ; if ( i != tokenParts . length - 1 ) { l . add ( "-" ) ; } } } else { l . add ( token ) ; } } else { l . add ( token ) ; } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } } else { l . add ( token ) ; } } else { l . add ( token ) ; } } return joinUrls ( l ) ; } public void setTagger ( Tagger tagger ) { this . tagger = tagger ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . SimpleGerman ; public class SimpleGermanConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new SimpleGerman ( ) ; } @ Override protected String createSampleText ( ) { return " \"Auch wenn Deine xleinen Füße die Erde nie berührten, sind deine Spuren trotzdem da überall.\"\n \n" ; } }
package org . languagetool . rules . de ; import org . languagetool . language . German ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class SimpleGermanPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( new German ( ) ) ; } }
package org . languagetool . language ; import org . languagetool . rules . Rule ; import java . util . Collections ; import java . util . List ; import java . util . ResourceBundle ; public class SimpleGerman extends GermanyGerman { @ Override public String getName ( ) { return "Simple German" ; } @ Override public String getShortName ( ) { return "de-DE-x-simple-language" ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Annika Nietzio" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Collections . emptyList ( ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Malayalam ; public class MalayalamConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Malayalam ( ) ; } @ Override protected String createSampleText ( ) { return "വിക്കിപീഡിയ, ഒരു സ്വതന്ത്ര വിജ്ഞാനകോശം." ; } }
package org . languagetool . rules . ca ; import java . io . IOException ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . HashMap ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; import java . util . Scanner ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . synthesis . ca . CatalanSynthesizer ; import org . languagetool . tools . StringTools ; public class ReplaceOperationNamesRule extends Rule { private static final String FILE_NAME = "/ca/replace_operationnames.txt" ; private static final Locale CA_LOCALE = new Locale ( "CA" ) ; private static final String FILE_ENCODING = "utf-8" ; protected final Map < String , List < String > > possibleWrongWords ; private final CatalanSynthesizer synth ; private static final Pattern PrevToken_POS = Pattern . compile ( "D[^R].*|PX.*|SPS00|SENT_START" ) ; private static final Pattern PrevToken_POS_Excep = Pattern . compile ( "RG_anteposat|N.*|CC|_PUNCT.*|_loc_unavegada|RN" ) ; private static final Pattern NextToken_POS_Excep = Pattern . compile ( "N.*" ) ; private static final Pattern PUNTUACIO = Pattern . compile ( "PUNCT.*|SENT_START" ) ; private static final Pattern DETERMINANT = Pattern . compile ( "D[^R].M.*" ) ; public final String getFileName ( ) { return FILE_NAME ; } public String getEncoding ( ) { return FILE_ENCODING ; } public ReplaceOperationNamesRule ( final ResourceBundle messages ) throws IOException { super . setLocQualityIssueType ( ITSIssueType . Style ) ; super . setCategory ( new Category ( "C8) Formes secundàries" ) ) ; possibleWrongWords = loadWords ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( getFileName ( ) ) ) ; synth = new CatalanSynthesizer ( ) ; } @ Override public final String getId ( ) { return "NOMS_OPERACIONS" ; } @ Override public String getDescription ( ) { return "Noms d'operació tècnica: buidat/buidatge" ; } public String getShort ( ) { return "Forma preferible" ; } public String getMessage ( String tokenStr , List < String > replacements ) { return "Si és el nom d'una operació tècnica, val més usar una altra forma." ; } public Locale getLocale ( ) { return CA_LOCALE ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) throws IOException { List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; loop : for ( int i = 1 ; i < tokens . length ; i ++ ) { List < String > replacementLemmas = null ; String token = tokens [ i ] . getToken ( ) . toLowerCase ( ) ; if ( token . length ( ) > 3 && token . endsWith ( "s" ) ) { token = token . substring ( 0 , token . length ( ) - 1 ) ; } if ( possibleWrongWords . containsKey ( token ) ) { replacementLemmas = possibleWrongWords . get ( token ) ; } else { continue loop ; } if ( token . equals ( "duplicat" ) && tokens [ i - 1 ] . getToken ( ) . equalsIgnoreCase ( "per" ) ) { continue loop ; } if ( i + 1 < tokens . length && matchPostagRegexp ( tokens [ i - 1 ] , PUNTUACIO ) && matchPostagRegexp ( tokens [ i + 1 ] , DETERMINANT ) ) { continue loop ; } if ( tokens [ i ] . hasPosTag ( "_GV_" ) ) { continue loop ; } if ( i + 1 < tokens . length && ( tokens [ i + 1 ] . hasLemma ( "per" ) || tokens [ i + 1 ] . hasLemma ( "com" ) || tokens [ i + 1 ] . hasLemma ( "des" ) || tokens [ i + 1 ] . hasLemma ( "amb" ) || matchPostagRegexp ( tokens [ i + 1 ] , NextToken_POS_Excep ) ) ) { continue loop ; } if ( ! matchPostagRegexp ( tokens [ i - 1 ] , PrevToken_POS ) || matchPostagRegexp ( tokens [ i - 1 ] , PrevToken_POS_Excep ) ) { continue loop ; } if ( replacementLemmas != null ) { List < String > possibleReplacements = new ArrayList < > ( ) ; String [ ] synthesized = null ; if ( ! tokens [ i ] . getToken ( ) . toLowerCase ( ) . endsWith ( "s" ) ) { possibleReplacements . addAll ( replacementLemmas ) ; } else { for ( String replacementLemma : replacementLemmas ) { synthesized = synth . synthesize ( new AnalyzedToken ( replacementLemma , "NCMS000" , replacementLemma ) , "NC.P.*" ) ; possibleReplacements . addAll ( Arrays . asList ( synthesized ) ) ; } } if ( possibleReplacements . size ( ) > 0 ) { RuleMatch potentialRuleMatch = createRuleMatch ( tokens [ i ] , possibleReplacements ) ; ruleMatches . add ( potentialRuleMatch ) ; } } } return toRuleMatchArray ( ruleMatches ) ; } private RuleMatch createRuleMatch ( AnalyzedTokenReadings tokenReadings , List < String > replacements ) { String tokenString = tokenReadings . getToken ( ) ; int pos = tokenReadings . getStartPos ( ) ; RuleMatch potentialRuleMatch = new RuleMatch ( this , pos , pos + tokenString . length ( ) , getMessage ( tokenString , replacements ) , getShort ( ) ) ; if ( StringTools . startsWithUppercase ( tokenString ) ) { for ( int i = 0 ; i < replacements . size ( ) ; i ++ ) { replacements . set ( i , StringTools . uppercaseFirstChar ( replacements . get ( i ) ) ) ; } } potentialRuleMatch . setSuggestedReplacements ( replacements ) ; return potentialRuleMatch ; } private Map < String , List < String > > loadWords ( final InputStream stream ) throws IOException { Map < String , List < String > > map = new HashMap < > ( ) ; try ( Scanner scanner = new Scanner ( stream , getEncoding ( ) ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } String [ ] parts = line . split ( "=" ) ; if ( parts . length != 2 ) { throw new IOException ( "Format error in file " + JLanguageTool . getDataBroker ( ) . getFromRulesDirAsUrl ( getFileName ( ) ) + ", line: " + line ) ; } String [ ] replacements = parts [ 1 ] . split ( "\\|" ) ; final String [ ] wrongForms = parts [ 0 ] . split ( "\\|" ) ; for ( String wrongForm : wrongForms ) { map . put ( wrongForm , Arrays . asList ( replacements ) ) ; } } } return map ; } @ Override public void reset ( ) { } private boolean matchPostagRegexp ( AnalyzedTokenReadings aToken , Pattern pattern ) { boolean matches = false ; for ( AnalyzedToken analyzedToken : aToken ) { String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag == null ) { posTag = "UNKNOWN" ; } final Matcher m = pattern . matcher ( posTag ) ; if ( m . matches ( ) ) { matches = true ; break ; } } return matches ; } }
package org . languagetool . rules . ml ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class MalayalamPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . ml ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Malayalam ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import static org . junit . Assert . assertEquals ; public class MorfologikMalayalamSpellerRuleTest { @ Test public void testMorfologikSpeller ( ) throws IOException { final Malayalam language = new Malayalam ( ) ; final MorfologikMalayalamSpellerRule rule = new MorfologikMalayalamSpellerRule ( TestTools . getMessages ( "ml" ) , language ) ; RuleMatch [ ] matches ; final JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "എന്തുകൊണ്ട്‌ അംഗത്വം" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "എങ്ങനെ അംഗമാകാം?" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "LanguageTool" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Zolw" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 4 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( matches [ 0 ] . getSuggestedReplacements ( ) . isEmpty ( ) , true ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "എaങ്ങനെ" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 7 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) , "എങ്ങനെ" ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "aõh" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "a" ) ) . length ) ; } }
package org . languagetool . tokenizers . ml ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Malayalam ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class MalayalamSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Malayalam ( ) ) ; public void testTokenize ( ) { testSplit ( "1983 ൽ റിച്ചാർഡ് സ്റ്റാൾമാൻ സ്ഥാപിച്ച ഗ്നു എന്ന സംഘടനയിൽ നിന്നും വളർന്നു വന്ന സോഫ്റ്റ്‌വെയറും ടൂളുകളുമാണ് ഇന്ന് ഗ്നൂ/ലിനക്സിൽ ലഭ്യമായിട്ടുള്ള സോഫ്റ്റ്‌വെയറിൽ സിംഹഭാഗവും. " , "ഗ്നു സംഘത്തിന്റെ മുഖ്യലക്ഷ്യം സ്വതന്ത്ര സോഫ്റ്റ്‌വെയറുകൾ മാത്രം ഉപയോഗിച്ചുകൊണ്ട് യുണിക്സ് പോലുള്ള ഒരു ഓപ്പറേറ്റിംഗ് സിസ്റ്റം നിർമ്മിക്കുന്നതായിരുന്നു." ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . ml . MorfologikMalayalamSpellerRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . ml . MalayalamTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . ml . MalayalamWordTokenizer ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; public class Malayalam extends Language { private SentenceTokenizer sentenceTokenizer ; private Tagger tagger ; private Tokenizer wordTokenizer ; @ Override public String getName ( ) { return "Malayalam" ; } @ Override public String getShortName ( ) { return "ml" ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new MalayalamWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "IN" } ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new MalayalamTagger ( ) ; } return tagger ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Jithesh.V.S" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages ) , new MorfologikMalayalamSpellerRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new WordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) ) ; } }
package org . languagetool . rules . ml ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikMalayalamSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/ml/hunspell/ml_IN.dict" ; public MorfologikMalayalamSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_ML_IN" ; } }
package org . languagetool . tagging . ml ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class MalayalamTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/ml/added.txt" ; } public MalayalamTagger ( ) { super ( "/ml/malayalam.dict" , new Locale ( "ml" ) ) ; } }
package org . languagetool . tokenizers . ml ; import java . util . ArrayList ; import java . util . List ; import java . util . StringTokenizer ; import org . languagetool . tokenizers . Tokenizer ; public class MalayalamWordTokenizer implements Tokenizer { public MalayalamWordTokenizer ( ) { } @ Override public List < String > tokenize ( final String text ) { final List < String > tokens = new ArrayList < > ( ) ; final StringTokenizer st = new StringTokenizer ( text , "\u0020\u00A0\u115f\u1160\u1680" + ",.;()[]{}!?:\"'’‘„“”…\\/\t\n" , true ) ; while ( st . hasMoreElements ( ) ) { tokens . add ( st . nextToken ( ) ) ; } return tokens ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . GermanyGerman ; public class GermanyGermanConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new GermanyGerman ( ) ; } @ Override protected String createSampleText ( ) { return " \"Auch wenn Deine xleinen Füße die Erde nie berührten, sind deine Spuren trotzdem da überall.\"\n \n" ; } }
package org . languagetool ; import junit . framework . TestCase ; import org . languagetool . language . German ; import org . languagetool . language . GermanyGerman ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . List ; public class JLanguageToolTest extends TestCase { public void testGerman ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new German ( ) ) ; assertEquals ( 0 , tool . check ( "Ein Test, der keine Fehler geben sollte." ) . size ( ) ) ; assertEquals ( 1 , tool . check ( "Ein Test Test, der Fehler geben sollte." ) . size ( ) ) ; tool . setListUnknownWords ( true ) ; assertEquals ( 0 , tool . check ( "I can give you more a detailed description" ) . size ( ) ) ; assertEquals ( "[I, can, description, detailed, give, more, you]" , tool . getUnknownWords ( ) . toString ( ) ) ; } public void testGermanyGerman ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new GermanyGerman ( ) ) ; assertEquals ( 0 , tool . check ( "Ein Test, der keine Fehler geben sollte." ) . size ( ) ) ; assertEquals ( 1 , tool . check ( "Ein Test Test, der Fehler geben sollte." ) . size ( ) ) ; tool . setListUnknownWords ( true ) ; assertEquals ( 6 , tool . check ( "I can give you more a detailed description" ) . size ( ) ) ; assertEquals ( "[I, can, description, detailed, give, more, you]" , tool . getUnknownWords ( ) . toString ( ) ) ; } public void testPositionsWithGerman ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new German ( ) ) ; final List < RuleMatch > matches = tool . check ( "Stundenkilometer" ) ; assertEquals ( 1 , matches . size ( ) ) ; final RuleMatch match = matches . get ( 0 ) ; assertEquals ( 0 , match . getLine ( ) ) ; assertEquals ( 1 , match . getColumn ( ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . AustrianGerman ; public class AustrianGermanConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new AustrianGerman ( ) ; } @ Override protected String createSampleText ( ) { return " \"Auch wenn Deine xleinen Füße die Erde nie berührten, sind deine Spuren trotzdem da überall.\"\n \n" ; } }
package org . languagetool . rules . ca ; import org . languagetool . rules . AbstractDateCheckFilter ; import java . util . Calendar ; import java . util . Locale ; public class DateCheckFilter extends AbstractDateCheckFilter { @ Override protected Calendar getCalendar ( ) { return Calendar . getInstance ( Locale . UK ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfWeek ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . equals ( "dg" ) || day . equals ( "diumenge" ) ) return Calendar . SUNDAY ; if ( day . equals ( "dl" ) || day . equals ( "dilluns" ) ) return Calendar . MONDAY ; if ( day . equals ( "dt" ) || day . equals ( "dimarts" ) ) return Calendar . TUESDAY ; if ( day . equals ( "dc" ) || day . equals ( "dimecres" ) ) return Calendar . WEDNESDAY ; if ( day . equals ( "dj" ) || day . equals ( "dijous" ) ) return Calendar . THURSDAY ; if ( day . equals ( "dv" ) || day . equals ( "divendres" ) ) return Calendar . FRIDAY ; if ( day . equals ( "ds" ) || day . equals ( "dissabte" ) ) return Calendar . SATURDAY ; throw new RuntimeException ( "Could not find day of week for '" + dayStr + "'" ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected String getDayOfWeek ( Calendar date ) { String englishDay = date . getDisplayName ( Calendar . DAY_OF_WEEK , Calendar . LONG , Locale . UK ) ; if ( englishDay . equals ( "Sunday" ) ) return "diumenge" ; if ( englishDay . equals ( "Monday" ) ) return "dilluns" ; if ( englishDay . equals ( "Tuesday" ) ) return "dimarts" ; if ( englishDay . equals ( "Wednesday" ) ) return "dimecres" ; if ( englishDay . equals ( "Thursday" ) ) return "dijous" ; if ( englishDay . equals ( "Friday" ) ) return "divendres" ; if ( englishDay . equals ( "Saturday" ) ) return "dissabte" ; return "" ; } @ SuppressWarnings ( { "ControlFlowStatementWithoutBraces" , "MagicNumber" } ) @ Override protected int getMonth ( String monthStr ) { String mon = monthStr . toLowerCase ( ) ; if ( mon . startsWith ( "gen" ) ) return 1 ; if ( mon . startsWith ( "febr" ) ) return 2 ; if ( mon . startsWith ( "març" ) ) return 3 ; if ( mon . startsWith ( "abr" ) ) return 4 ; if ( mon . startsWith ( "maig" ) ) return 5 ; if ( mon . startsWith ( "juny" ) ) return 6 ; if ( mon . startsWith ( "jul" ) ) return 7 ; if ( mon . startsWith ( "ag" ) ) return 8 ; if ( mon . startsWith ( "set" ) ) return 9 ; if ( mon . startsWith ( "oct" ) ) return 10 ; if ( mon . startsWith ( "nov" ) ) return 11 ; if ( mon . startsWith ( "des" ) ) return 12 ; throw new RuntimeException ( "Could not find month '" + monthStr + "'" ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . SwissGerman ; public class SwissGermanConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new SwissGerman ( ) ; } @ Override protected String createSampleText ( ) { return " \"Auch wenn Deine xleinen Füße die Erde nie berührten, sind deine Spuren trotzdem da überall.\"\n \n" ; } }
package org . languagetool . chunking ; import org . junit . Test ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . language . German ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import static junit . framework . TestCase . fail ; public class GermanChunkerTest { private final JLanguageTool lt = new JLanguageTool ( new German ( ) ) ; private final GermanChunker chunker = new GermanChunker ( ) ; @ Test public void testChunking ( ) throws Exception { assertFullChunks ( "Ein/B Haus/I" ) ; assertFullChunks ( "Ein/NPP Hund/NPP und/NPP eine/NPP Katze/NPP stehen dort" ) ; assertFullChunks ( "Es war die/NPS größte/NPS und/NPS erfolgreichste/NPS Erfindung/NPS" ) ; assertFullChunks ( "Geräte/B , deren/NPS Bestimmung/NPS und/NPS Funktion/NPS unklar sind." ) ; assertFullChunks ( "Julia/NPP und/NPP Karsten/NPP sind alt" ) ; assertFullChunks ( "Es ist die/NPS älteste/NPS und/NPS bekannteste/NPS Maßnahme/NPS" ) ; assertFullChunks ( "Das ist eine/NPS Masseeinheit/NPS und/NPS keine/NPS Gewichtseinheit/NPS" ) ; assertFullChunks ( "Sie fährt nur eins/NPS ihrer/NPS drei/NPS Autos/NPS" ) ; assertFullChunks ( "Da sind er/NPP und/NPP seine/NPP Schwester/NPP" ) ; assertFullChunks ( "Rekonstruktionen/NPP oder/NPP der/NPP Wiederaufbau/NPP sind das/NPS Ziel/NPS" ) ; assertFullChunks ( "Isolation/NPP und/NPP ihre/NPP Überwindung/NPP ist das/NPS Thema/NPS" ) ; assertFullChunks ( "Es gibt weder/NPP Gerechtigkeit/NPP noch/NPP Freiheit/NPP" ) ; assertFullChunks ( "Da sitzen drei/NPP Katzen/NPP" ) ; assertFullChunks ( "Der/NPS von/NPS der/NPS Regierung/NPS geprüfte/NPS Hund/NPS ist grün" ) ; assertFullChunks ( "Herr/NPP und/NPP Frau/NPP Schröder/NPP sind betrunken" ) ; assertFullChunks ( "Das sind 37/NPS Prozent/NPS" ) ; assertFullChunks ( "Das sind 37/NPP Prozent/NPP" ) ; assertFullChunks ( "Er will die/NPP Arbeitsplätze/NPP so umgestalten , dass/NPP sie/NPP wie/NPP ein/NPP Spiel/NPP sind." ) ; assertFullChunks ( "So dass Knochenbrüche/NPP und/NPP Platzwunden/NPP die/NPP Regel/NPP sind" ) ; assertFullChunks ( "Eine/NPS Veranstaltung/NPS ,/NPS die/NPS immer/NPS wieder/NPS ein/NPS kultureller/NPS Höhepunkt/NPS war" ) ; assertFullChunks ( "Und die/NPS ältere/NPS der/NPS beiden/NPS Töchter/NPS ist 20." ) ; assertFullChunks ( "Der/NPS Synthese/NPS organischer/NPS Verbindungen/NPS steht nichts im/PP Weg/NPS" ) ; assertFullChunks ( "Aber die/NPP Kenntnisse/NPP der/NPP Sprache/NPP sind nötig." ) ; assertFullChunks ( "Dort steht die/NPS Pyramide/NPS des/NPS Friedens/NPS und/NPS der/NPS Eintracht/NPS" ) ; assertFullChunks ( "Und Teil/B der/NPS dort/NPS ausgestellten/NPS Bestände/NPS wurde privat finanziert." ) ; assertFullChunks ( "Autor/NPS der/NPS ersten/NPS beiden/NPS Bücher/NPS ist Stephen King/NPS" ) ; assertFullChunks ( "Autor/NPS der/NPS beiden/NPS Bücher/NPS ist Stephen King/NPS" ) ; assertFullChunks ( "Teil/NPS der/NPS umfangreichen/NPS dort/NPS ausgestellten/NPS Bestände/NPS stammt von privat" ) ; assertFullChunks ( "Ein/NPS Teil/NPS der/NPS umfangreichen/NPS dort/NPS ausgestellten/NPS Bestände/NPS stammt von privat" ) ; assertFullChunks ( "Die/NPS Krankheit/NPS unserer/NPS heutigen/NPS Städte/NPS und/NPS Siedlungen/NPS ist der/NPS Verkehr/NPS" ) ; assertFullChunks ( "Der/B Nil/I ist der/NPS letzte/NPS der/NPS vier/NPS großen/NPS Flüsse/NPS" ) ; assertFullChunks ( "Der/NPS letzte/NPS der/NPS vier/NPS großen/NPS Flüsse/NPS ist der/B Nil/I" ) ; assertFullChunks ( "Sie kennt eine/NPP Menge/NPP englischer/NPP Wörter/NPP" ) ; assertFullChunks ( "Eine/NPP Menge/NPP englischer/NPP Wörter/NPP sind aus/PP dem/NPS Lateinischen/NPS abgeleitet." ) ; assertFullChunks ( "Laut/PP den/PP meisten/PP Quellen/PP ist er 35 Jahre/B alt." ) ; assertFullChunks ( "Bei/PP den/PP sehr/PP niedrigen/PP Oberflächentemperaturen/PP verbrennt nichts" ) ; assertFullChunks ( "In/PP den/PP alten/PP Religionen/PP ,/PP Mythen/PP und/PP Sagen/PP tauchen Geister/B auf." ) ; assertFullChunks ( "Die/B Straße/I ist wichtig für/PP die/PP Stadtteile/PP und/PP selbständigen/PP Ortsteile/PP" ) ; assertFullChunks ( "Es herrscht gute/NPS Laune/NPS in/PP chemischen/PP Komplexverbindungen/PP" ) ; assertFullChunks ( "Funktionen/NPP des/NPP Körpers/NPP einschließlich/PP der/PP biologischen/PP und/PP sozialen/PP Grundlagen/PP" ) ; assertFullChunks ( "Das/NPS Dokument/NPS umfasst das für/PP Ärzte/PP und/PP Ärztinnen/PP festgestellte/PP Risikoprofil/PP" ) ; assertFullChunks ( "In/PP den/PP darauf/PP folgenden/PP Wochen/PP ging es los." ) ; assertFullChunks ( "In/PP nur/PP zwei/PP Wochen/PP geht es los." ) ; assertFullChunks ( "Programme/B , in/PP deren/PP deutschen/PP Installationen/PP nichts funktioniert." ) ; assertFullChunks ( "Nach/PP sachlichen/PP und/PP militärischen/PP Kriterien/PP war das unnötig." ) ; assertFullChunks ( "Mit/PP über/PP 1000/PP Handschriften/PP ist es die/NPS größte/NPS Sammlung/NPS" ) ; assertFullChunks ( "Es gab Beschwerden/NPP über/PP laufende/PP Sanierungsmaßnahmen/PP" ) ; assertFullChunks ( "Gesteigerte/NPS Effizienz/NPS durch/PP Einsatz/PP größerer/PP Maschinen/PP und/PP bessere/PP Kapazitätsplanung/PP" ) ; assertFullChunks ( "Bei/PP sehr/PP guten/PP Beobachtungsbedingungen/PP bin ich dabei" ) ; assertFullChunks ( "Die/NPP Beziehungen/NPP zwischen/NPP Kanada/NPP und/NPP dem/NPP Iran/NPP sind unterkühlt" ) ; assertFullChunks ( "Die/PP darauffolgenden/PP Jahre/PP war es kalt" ) ; assertFullChunks ( "Die/NPP darauffolgenden/NPP Jahre/NPP waren kalt" ) ; assertFullChunks ( "Die/PP letzten/PP zwei/PP Monate/PP war es kalt" ) ; assertFullChunks ( "Letztes/PP Jahr/PP war kalt" ) ; assertFullChunks ( "Letztes/PP Jahr/PP war es kalt" ) ; assertFullChunks ( "Es sind Atome/NPP ,/NPP welche/NPP der/NPP Urstoff/NPP aller/NPP Körper/NPP sind" ) ; assertFullChunks ( "Kommentare/NPP ,/NPP Korrekturen/NPP ,/NPP Kritik/NPP bitte nach /dev/null" ) ; assertFullChunks ( "Einer/NPS der/NPS beiden/NPS Höfe/NPS war schön" ) ; } @ Test public void testOpenNLPLikeChunking ( ) throws Exception { assertBasicChunks ( "Ein/B Haus/I" ) ; assertBasicChunks ( "Da steht ein/B Haus/I" ) ; assertBasicChunks ( "Da steht ein/B schönes/I Haus/I" ) ; assertBasicChunks ( "Da steht ein/B schönes/I großes/I Haus/I" ) ; assertBasicChunks ( "Da steht ein/B sehr/I großes/I Haus/I" ) ; assertBasicChunks ( "Da steht ein/B sehr/I schönes/I großes/I Haus/I" ) ; assertBasicChunks ( "Da steht ein/B sehr/I großes/I Haus/I mit Dach/B" ) ; assertBasicChunks ( "Da steht ein/B sehr/I großes/I Haus/I mit einem/B blauen/I Dach/I" ) ; assertBasicChunks ( "Eine/B leckere/I Lasagne/I" ) ; assertBasicChunks ( "Herr/B Meier/I isst eine/B leckere/I Lasagne/I" ) ; assertBasicChunks ( "Herr/B Schrödinger/I isst einen/B Kuchen/I" ) ; assertBasicChunks ( "Herr/B Schrödinger/I isst einen/B leckeren/I Kuchen/I" ) ; assertBasicChunks ( "Herr/B Karl/I Meier/I isst eine/B leckere/I Lasagne/I" ) ; assertBasicChunks ( "Herr/B Finn/I Westerwalbesloh/I isst eine/B leckere/I Lasagne/I" ) ; assertBasicChunks ( "Unsere/B schöne/I Heimat/I geht den/B Bach/I runter" ) ; assertBasicChunks ( "Er meint das/B Haus/I am grünen/B Hang/I" ) ; assertBasicChunks ( "Ich muss dem/B Hund/I Futter/I geben" ) ; assertBasicChunks ( "Das/B Wasser/I , das die/B Wärme/I überträgt" ) ; assertBasicChunks ( "Er mag das/B Wasser/I , das/B Meer/I und die/B Luft/I" ) ; assertBasicChunks ( "Schon mehr als zwanzig/B Prozent/I der/B Arbeiter/I sind im Streik/B" ) ; assertBasicChunks ( "Das/B neue/I Gesetz/I betrifft 1000 Bürger/B" ) ; assertBasicChunks ( "In zwei/B Wochen/I ist Weihnachten/B" ) ; assertBasicChunks ( "Eines ihrer/B drei/I Autos/I ist blau" ) ; } @ Test public void testTemp ( ) throws Exception { } private void assertBasicChunks ( String input ) throws Exception { String plainInput = getPlainInput ( input ) ; AnalyzedSentence analyzedSentence = lt . getAnalyzedSentence ( plainInput ) ; AnalyzedTokenReadings [ ] result = analyzedSentence . getTokensWithoutWhitespace ( ) ; List < ChunkTaggedToken > basicChunks = chunker . getBasicChunks ( Arrays . asList ( result ) ) ; List < String > expectedChunks = getExpectedChunks ( input ) ; assertChunks ( input , plainInput , basicChunks , expectedChunks ) ; } private void assertFullChunks ( String input ) throws Exception { String plainInput = getPlainInput ( input ) ; AnalyzedSentence analyzedSentence = lt . getAnalyzedSentence ( plainInput ) ; AnalyzedTokenReadings [ ] result = analyzedSentence . getTokensWithoutWhitespace ( ) ; chunker . addChunkTags ( Arrays . asList ( result ) ) ; List < String > expectedChunks = getExpectedChunks ( input ) ; List < ChunkTaggedToken > result2 = new ArrayList < > ( ) ; int i = 0 ; for ( AnalyzedTokenReadings readings : result ) { if ( i > 0 ) { ChunkTaggedToken chunkTaggedToken = new ChunkTaggedToken ( readings . getToken ( ) , readings . getChunkTags ( ) , readings ) ; result2 . add ( chunkTaggedToken ) ; } i ++ ; } assertChunks ( input , plainInput , result2 , expectedChunks ) ; } private String getPlainInput ( String input ) { return input . replaceAll ( "/[A-Z-]*" , "" ) . replace ( " ," , "," ) ; } private List < String > getExpectedChunks ( String input ) { List < String > expectedChunks = new ArrayList < > ( ) ; String [ ] parts = input . split ( " " ) ; for ( String part : parts ) { String [ ] tokenParts = part . split ( "/" ) ; if ( tokenParts . length == 2 ) { String chunk = tokenParts [ 1 ] ; if ( chunk . equals ( "B" ) ) { expectedChunks . add ( "B-NP" ) ; } else if ( chunk . equals ( "I" ) ) { expectedChunks . add ( "I-NP" ) ; } else if ( chunk . equals ( "NPP" ) ) { expectedChunks . add ( "NPP" ) ; } else if ( chunk . equals ( "NPS" ) ) { expectedChunks . add ( "NPS" ) ; } else if ( chunk . equals ( "PP" ) ) { expectedChunks . add ( "PP" ) ; } else { throw new RuntimeException ( "Unknown chunk type: '" + chunk + "'" ) ; } } else { expectedChunks . add ( "O" ) ; } } return expectedChunks ; } private void assertChunks ( String input , String plainInput , List < ChunkTaggedToken > chunks , List < String > expectedChunks ) { int i = 0 ; for ( String expectedChunk : expectedChunks ) { ChunkTaggedToken outputChunksHere = chunks . get ( i ) ; if ( ! outputChunksHere . getChunkTags ( ) . contains ( new ChunkTag ( expectedChunk ) ) ) { fail ( "Expected '" + expectedChunk + "' but got '" + outputChunksHere + "' at position " + i + " for input:\n " + input + "\nPlain input:\n " + plainInput + "\nChunks:\n " + chunks + "\nExpected:\n " + expectedChunks ) ; } i ++ ; } } }
package org . languagetool . chunking ; import org . junit . Test ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import java . util . Arrays ; import java . util . List ; import static org . junit . Assert . * ; public class TokenPredicateTest { @ Test public void test ( ) { List < ChunkTag > chunkTags = Arrays . asList ( new ChunkTag ( "CHUNK1" ) , new ChunkTag ( "CHUNK2" ) ) ; AnalyzedTokenReadings readings = new AnalyzedTokenReadings ( new AnalyzedToken ( "mytoken" , "MYPOS" , "mylemma" ) , 0 ) ; ChunkTaggedToken chunkTaggedToken = new ChunkTaggedToken ( "mytoken" , chunkTags , readings ) ; assertMatch ( "mytoken" , chunkTaggedToken ) ; assertNoMatch ( "mytoken2" , chunkTaggedToken ) ; assertMatch ( "string=mytoken" , chunkTaggedToken ) ; assertNoMatch ( "string=mytoken2" , chunkTaggedToken ) ; assertMatch ( "regex=my[abct]oken" , chunkTaggedToken ) ; assertNoMatch ( "regex=my[abc]oken" , chunkTaggedToken ) ; assertMatch ( "chunk=CHUNK1" , chunkTaggedToken ) ; assertMatch ( "chunk=CHUNK2" , chunkTaggedToken ) ; assertNoMatch ( "chunk=OTHERCHUNK" , chunkTaggedToken ) ; assertMatch ( "pos=MYPOS" , chunkTaggedToken ) ; assertNoMatch ( "pos=OTHER" , chunkTaggedToken ) ; assertMatch ( "posre=M.POS" , chunkTaggedToken ) ; assertNoMatch ( "posre=O.HER" , chunkTaggedToken ) ; try { assertNoMatch ( "invalid=token" , chunkTaggedToken ) ; fail ( ) ; } catch ( RuntimeException expected ) { } } private void assertMatch ( String expr , ChunkTaggedToken chunkTaggedToken ) { TokenPredicate predicate = new TokenPredicate ( expr , false ) ; assertTrue ( predicate . apply ( chunkTaggedToken ) ) ; } private void assertNoMatch ( String expr , ChunkTaggedToken chunkTaggedToken ) { TokenPredicate predicate = new TokenPredicate ( expr , false ) ; assertFalse ( predicate . apply ( chunkTaggedToken ) ) ; } }
package org . languagetool . synthesis ; import org . junit . Test ; import org . languagetool . AnalyzedToken ; import java . io . IOException ; import java . util . Arrays ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . assertThat ; public class GermanSynthesizerTest { private final GermanSynthesizer synthesizer = new GermanSynthesizer ( ) ; @ Test public void testSynthesize ( ) throws IOException { assertThat ( synth ( "Äußerung" , "SUB:NOM:PLU:FEM" ) , is ( "[Äußerungen]" ) ) ; assertThat ( synth ( "Äußerung" , "SUB:NOM:PLU:MAS" ) , is ( "[]" ) ) ; assertThat ( synth ( "Haus" , "SUB:AKK:PLU:NEU" ) , is ( "[Häuser]" ) ) ; assertThat ( synth ( "Haus" , ".*" , true ) , is ( "[Häuser, Haus, Häusern, Haus, Hause, Häuser, Hauses, Häuser, Haus]" ) ) ; } private String synth ( String word , String posTag ) throws IOException { return Arrays . toString ( synthesizer . synthesize ( dummyToken ( word ) , posTag ) ) ; } private String synth ( String word , String posTag , boolean regEx ) throws IOException { return Arrays . toString ( synthesizer . synthesize ( dummyToken ( word ) , posTag , regEx ) ) ; } private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } }
package org . languagetool . rules . de ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . German ; public class GermanWordRepeatBeginningRuleTest extends TestCase { public void testRule ( ) throws IOException { JLanguageTool langTool = new JLanguageTool ( new German ( ) ) ; assertEquals ( 0 , langTool . check ( "Er ist nett. Er heißt Max." ) . size ( ) ) ; assertEquals ( 0 , langTool . check ( "Außerdem kommt er. Ferner kommt sie. Außerdem kommt es." ) . size ( ) ) ; assertEquals ( 0 , langTool . check ( "2011: Dieses passiert. 2011: Jenes passiert. 2011: Nicht passiert" ) . size ( ) ) ; assertEquals ( 1 , langTool . check ( "Er ist nett. Er heißt Max. Er ist 11." ) . size ( ) ) ; assertEquals ( 1 , langTool . check ( "Außerdem kommt er. Außerdem kommt sie." ) . size ( ) ) ; assertEquals ( 0 , langTool . check ( "Außerdem ist das ein neuer Text." ) . size ( ) ) ; } }
package org . languagetool . rules . de ; import java . io . IOException ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import org . languagetool . rules . AbstractCompoundRuleTest ; public class CompoundRuleTest extends AbstractCompoundRuleTest { @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; langTool = new JLanguageTool ( new German ( ) ) ; rule = new CompoundRule ( TestTools . getMessages ( "de" ) ) ; } public void testRule ( ) throws IOException { check ( 0 , "Eine tolle CD-ROM" ) ; check ( 0 , "Eine tolle CD-ROM." ) ; check ( 0 , "Ein toller CD-ROM-Test." ) ; check ( 0 , "Systemadministrator" ) ; check ( 0 , "System-Administrator" ) ; check ( 0 , "Eine Million Dollar" ) ; check ( 0 , "Das System des Administrators" ) ; check ( 0 , "Nur im Stand-by-Betrieb" ) ; check ( 0 , "Start, Ziel, Sieg" ) ; check ( 0 , "Roll-on-roll-off-Schiff" ) ; check ( 0 , "Halswirbelsäule" ) ; check ( 0 , "Castrop-Rauxel" ) ; check ( 0 , "Hals-Wirbel-Säule" ) ; check ( 1 , "System Administrator" , new String [ ] { "System-Administrator" , "Systemadministrator" } ) ; check ( 1 , "bla bla bla bla bla System Administrator bla bla bla bla bla" ) ; check ( 1 , "System Administrator blubb" ) ; check ( 1 , "Der System Administrator" ) ; check ( 1 , "Der dumme System Administrator" ) ; check ( 1 , "CD ROM" , new String [ ] { "CD-ROM" } ) ; check ( 1 , "Nur im Stand by Betrieb" , new String [ ] { "Stand-by-Betrieb" } ) ; check ( 1 , "Ein echter Start Ziel Sieg" , new String [ ] { "Start-Ziel-Sieg" } ) ; check ( 1 , "Ein echter Start Ziel Sieg." ) ; check ( 1 , "Ein Start Ziel Sieg" ) ; check ( 1 , "Start Ziel Sieg" ) ; check ( 1 , "Start Ziel Sieg!" ) ; check ( 2 , "Der dumme System Administrator legt die CD ROM" ) ; check ( 2 , "Der dumme System Administrator legt die CD ROM." ) ; check ( 2 , "Der dumme System Administrator legt die CD ROM ein blah" ) ; check ( 2 , "System Administrator CD ROM" ) ; check ( 2 , "Hals Wirbel Säule" ) ; check ( 1 , "Und herum zu knobeln können." , new String [ ] { "herumzuknobeln" } ) ; check ( 1 , "Castrop Rauxel" , new String [ ] { "Castrop-Rauxel" } ) ; check ( 1 , "Spin off" ) ; check ( 1 , "Das ist Haar sträubend" , new String [ ] { "Haarsträubend" } ) ; check ( 1 , "Reality TV" , new String [ ] { "Reality-TV" } ) ; check ( 1 , "Spin off" , new String [ ] { "Spin-off" } ) ; check ( 1 , "Spin Off" , new String [ ] { "Spin-Off" } ) ; check ( 1 , "CW Wert" , new String [ ] { "CW-Wert" } ) ; check ( 1 , "Roll-on-roll-off Schiff" , new String [ ] { "Roll-on-roll-off-Schiff" } ) ; check ( 1 , "E-Mail Adressen" , new String [ ] { "E-Mail-Adressen" } ) ; check ( 0 , "x-mal" ) ; check ( 1 , "x mal" , new String [ ] { "x-mal" } ) ; check ( 0 , "y-Achse" ) ; check ( 1 , "y Achse" , new String [ ] { "y-Achse" } ) ; } }
package org . languagetool . rules . de ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import java . io . IOException ; public class DashRuleTest extends TestCase { private final DashRule rule = new DashRule ( TestTools . getMessages ( "de" ) ) ; public void testRule ( ) throws IOException { JLanguageTool lt = new JLanguageTool ( new German ( ) ) ; assertGood ( "Die große Diäten-Erhöhung kam dann doch." , lt ) ; assertGood ( "Die große Diätenerhöhung kam dann doch." , lt ) ; assertGood ( "Die große Diäten-Erhöhungs-Manie kam dann doch." , lt ) ; assertGood ( "Die große Diäten- und Gehaltserhöhung kam dann doch." , lt ) ; assertGood ( "Die große Diäten- sowie Gehaltserhöhung kam dann doch." , lt ) ; assertGood ( "Die große Diäten- oder Gehaltserhöhung kam dann doch." , lt ) ; assertGood ( "Erst so - Karl-Heinz dann blah." , lt ) ; assertGood ( "Erst so -- Karl-Heinz aber..." , lt ) ; assertBad ( "Die große Diäten- Erhöhung kam dann doch." , lt ) ; assertBad ( "Die große Diäten- Erhöhung kam dann doch." , lt ) ; assertBad ( "Die große Diäten-Erhöhungs- Manie kam dann doch." , lt ) ; assertBad ( "Die große Diäten- Erhöhungs-Manie kam dann doch." , lt ) ; } private void assertGood ( String text , JLanguageTool langTool ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( text ) ) . length ) ; } private void assertBad ( String text , JLanguageTool langTool ) throws IOException { assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( text ) ) . length ) ; } }
package org . languagetool . rules . de ; import org . junit . Assert ; import org . junit . BeforeClass ; import org . junit . Test ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . chunking . GermanChunker ; import org . languagetool . language . German ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import static junit . framework . TestCase . assertFalse ; import static junit . framework . TestCase . assertTrue ; public class SubjectVerbAgreementRuleTest { private static SubjectVerbAgreementRule rule ; private static JLanguageTool langTool ; @ BeforeClass public static void setUp ( ) { German german = new German ( ) ; rule = new SubjectVerbAgreementRule ( TestTools . getMessages ( "de" ) , german ) ; langTool = new JLanguageTool ( german ) ; } @ Test public void testTemp ( ) throws IOException { } @ Test public void testPrevChunkIsNominative ( ) throws IOException { assertTrue ( rule . prevChunkIsNominative ( getTokens ( "Die Katze ist süß" ) , 2 ) ) ; assertTrue ( rule . prevChunkIsNominative ( getTokens ( "Das Fell der Katzen ist süß" ) , 4 ) ) ; assertFalse ( rule . prevChunkIsNominative ( getTokens ( "Dem Mann geht es gut." ) , 2 ) ) ; assertFalse ( rule . prevChunkIsNominative ( getTokens ( "Dem alten Mann geht es gut." ) , 2 ) ) ; assertFalse ( rule . prevChunkIsNominative ( getTokens ( "Beiden Filmen war kein Erfolg beschieden." ) , 2 ) ) ; assertFalse ( rule . prevChunkIsNominative ( getTokens ( "Aber beiden Filmen war kein Erfolg beschieden." ) , 3 ) ) ; } private AnalyzedTokenReadings [ ] getTokens ( String s ) throws IOException { return langTool . getAnalyzedSentence ( s ) . getTokensWithoutWhitespace ( ) ; } @ Test public void testRuleWithIncorrectSingularVerb ( ) throws IOException { List < String > sentences = Arrays . asList ( "Die Autos ist schnell." , "Der Hund und die Katze ist draußen." , "Ein Hund und eine Katze ist schön." , "Der Hund und die Katze ist schön." , "Der große Hund und die Katze ist schön." , "Der Hund und die graue Katze ist schön." , "Der große Hund und die graue Katze ist schön." , "Die Kenntnisse ist je nach Bildungsgrad verschieden." , "Die Kenntnisse der Sprachen ist je nach Bildungsgrad verschieden." , "Die Kenntnisse der Sprache ist je nach Bildungsgrad verschieden." , "Die Kenntnisse der europäischen Sprachen ist je nach Bildungsgrad verschieden." , "Die Kenntnisse der neuen europäischen Sprachen ist je nach Bildungsgrad verschieden." , "Die Kenntnisse der deutschen Sprache ist je nach Bildungsgrad verschieden." , "Die Kenntnisse der aktuellen deutschen Sprache ist je nach Bildungsgrad verschieden." , "Drei Katzen ist im Haus." , "Drei kleine Katzen ist im Haus." , "Viele Katzen ist schön." , "Drei Viertel der Erdoberfläche ist Wasser." , "Die ältesten und bekanntesten Maßnahmen ist die Einrichtung von Schutzgebieten." , "Ein Gramm Pfeffer waren früher wertvoll." , "Isolation und ihre Überwindung ist ein häufiges Thema in der Literatur." ) ; for ( String sentence : sentences ) { assertBad ( sentence ) ; } } @ Test public void testRuleWithCorrectSingularVerb ( ) throws IOException { List < String > sentences = Arrays . asList ( "Die Katze ist schön." , "Die eine Katze ist schön." , "Eine Katze ist schön." , "Beiden Filmen war kein Erfolg beschieden." , "In einigen Fällen ist der vermeintliche Beschützer schwach." , "Was Wasser für die Fische ist." , "In den letzten Jahrzehnten ist die Zusammenarbeit der Astronomie verbessert worden." , "Für Oberleitungen bei elektrischen Bahnen ist es dagegen anders." , "... deren Thema die Liebe zwischen männlichen Charakteren ist." , "Mehr als das in westlichen Produktionen der Fall ist." , "Da das ein fast aussichtsloses Unterfangen ist." , "Was sehr verbreitet bei der Synthese organischer Verbindungen ist." , "In chemischen Komplexverbindungen ist das Kation wichtig." , "In chemischen Komplexverbindungen ist das As5+-Kation wichtig." , "Die selbstständige Behandlung psychischer Störungen ist jedoch ineffektiv." , "Die selbstständige Behandlung eigener psychischer Störungen ist jedoch ineffektiv." , "Im Gegensatz zu anderen akademischen Berufen ist es in der Medizin durchaus üblich ..." , "Im Unterschied zu anderen Branchen ist Ärzten anpreisende Werbung verboten." , "Aus den verfügbaren Quellen ist es ersichtlich." , "Das Mädchen mit den langen Haaren ist Judy." , "Der Durchschnitt offener Mengen ist nicht notwendig offen." , "Der Durchschnitt vieler offener Mengen ist nicht notwendig offen." , "Der Durchschnitt unendlich vieler offener Mengen ist nicht notwendig offen." , "Der Ausgangspunkt für die heute gebräuchlichen Alphabete ist ..." , "Nach sieben männlichen Amtsvorgängern ist Merkel ..." , "Für einen japanischen Hamburger ist er günstig." , "Derzeitiger Bürgermeister ist seit 2008 der ehemalige Minister Müller." , "Derzeitiger Bürgermeister der Stadt ist seit 2008 der ehemalige Minister Müller." , "Die Eingabe mehrerer assoziativer Verknüpfungen ist beliebig." , "Die inhalative Anwendung anderer Adrenalinpräparate zur Akutbehandlung asthmatischer Beschwerden ist somit außerhalb der arzneimittelrechtlichen Zulassung." , "Die Kategorisierung anhand morphologischer Merkmale ist nicht objektivierbar." , "Die Kategorisierung mit morphologischen Merkmalen ist nicht objektivierbar." , "Ute, deren Hauptproblem ihr Mangel an Problemen ist, geht baden." , "Ute, deren Hauptproblem ihr Mangel an realen Problemen ist, geht baden." , "In zwei Wochen ist Weihnachten." , "In nur zwei Wochen ist Weihnachten." , "Mit chemischen Methoden ist es möglich, das zu erreichen." , "Für die Stadtteile ist auf kommunalpolitischer Ebene jeweils ein Beirat zuständig." , "Für die Stadtteile und selbständigen Ortsteile ist auf kommunalpolitischer Ebene jeweils ein Beirat zuständig." , "Die Qualität der Straßen ist unterschiedlich." , "In deutschen Installationen ist seit Version 3.3 ein neues Feature vorhanden." , "In deren Installationen ist seit Version 3.3 ein neues Feature vorhanden." , "In deren deutschen Installationen ist seit Version 3.3 ein neues Feature vorhanden." , "Die Führung des Wortes in Unternehmensnamen ist nur mit Genehmigung zulässig." , "Die Führung des Wortes in Unternehmensnamen und Institutionen ist nur mit Genehmigung zulässig." , "Die Hintereinanderreihung mehrerer Einheitenvorsatznamen oder Einheitenvorsatzzeichen ist nicht zulässig." , "Eines ihrer drei Autos ist blau und die anderen sind weiß." , "Eines von ihren drei Autos ist blau und die anderen sind weiß." , "Bei fünf Filmen war Robert F. Boyle für das Production Design verantwortlich." , "Insbesondere das Wasserstoffatom als das einfachste aller Atome war dabei wichtig." , "In den darauf folgenden Wochen war die Partei führungslos" , "Gegen die wegen ihrer Schönheit bewunderte Phryne ist ein Asebie-Prozess überliefert." , "Dieses für Ärzte und Ärztinnen festgestellte Risikoprofil ist berufsunabhängig." , "Das ist problematisch, da kDa eine Masseeinheit und keine Gewichtseinheit ist." , "Nach sachlichen oder militärischen Kriterien war das nicht nötig." , "Die Pyramide des Friedens und der Eintracht ist ein Bauwerk." , "Ohne Architektur der Griechen ist die westliche Kultur der Neuzeit nicht denkbar." , "Ohne Architektur der Griechen und Römer ist die westliche Kultur der Neuzeit nicht denkbar." , "Ohne Architektur und Kunst der Griechen und Römer ist die westliche Kultur der Neuzeit nicht denkbar." , "In denen jeweils für eine bestimmte Anzahl Elektronen Platz ist." , "Mit über 1000 Handschriften ist Aristoteles ein Vielschreiber." , "Mit über neun Handschriften ist Aristoteles ein Vielschreiber." , "Die Klammerung assoziativer Verknüpfungen ist beliebig." , "Die Klammerung mehrerer assoziativer Verknüpfungen ist beliebig." , "Einen Sonderfall bildete jedoch Ägypten, dessen neue Hauptstadt Alexandria eine Gründung Alexanders und der Ort seines Grabes war." , "Jeder Junge und jedes Mädchen war erfreut." , "Jedes Mädchen und jeder Junge war erfreut." , "Jede Frau und jeder Junge war erfreut." , "Als Wissenschaft vom Erleben des Menschen einschließlich der biologischen Grundlagen ist die Psychologie interdisziplinär." , "Als Wissenschaft vom Erleben des Menschen einschließlich der biologischen und sozialen Grundlagen ist die Psychologie interdisziplinär." , "Als Wissenschaft vom Erleben des Menschen einschließlich der biologischen und neurowissenschaftlichen Grundlagen ist die Psychologie interdisziplinär." , "Als Wissenschaft vom Erleben und Verhalten des Menschen einschließlich der biologischen bzw. sozialen Grundlagen ist die Psychologie interdisziplinär." , "Alle vier Jahre ist dem Volksfest das Landwirtschaftliche Hauptfest angeschlossen." , "Aller Anfang ist schwer." , "Alle Dichtung ist zudem Darstellung von Handlungen." , "Allen drei Varianten ist gemeinsam, dass meistens nicht unter bürgerlichem..." , "Er sagte, dass es neun Uhr war." , "Auch den Mädchen war es untersagt, eine Schule zu besuchen." , "Das dazugehörende Modell der Zeichen-Wahrscheinlichkeiten ist unter Entropiekodierung beschrieben." , "Ein über längere Zeit entladener Akku ist zerstört." , "Der Fluss mit seinen Oberläufen Río Paraná und Río Uruguay ist der wichtigste Wasserweg." , "In den alten Mythen und Sagen war die Eiche ein heiliger Baum." , "In den alten Religionen, Mythen und Sagen war die Eiche ein heiliger Baum." , "Zehn Jahre ist es her, seit ich mit achtzehn nach Tokio kam." , "Bei den niedrigen Oberflächentemperaturen ist Wassereis hart wie Gestein." , "Bei den sehr niedrigen Oberflächentemperaturen ist Wassereis hart wie Gestein." , "Die älteste und bekannteste Maßnahme ist die Einrichtung von Schutzgebieten." , "Die größte Dortmunder Grünanlage ist der Friedhof." , "Die größte Berliner Grünanlage ist der Friedhof." , "Die größte Bielefelder Grünanlage ist der Friedhof." , "Die Pariser Linie ist hier mit 2,2558 mm gerechnet." , "Die Frankfurter Innenstadt ist 7 km entfernt." , "Die Dortmunder Konzernzentrale ist ein markantes Gebäude an der Bundesstraße 1." , "Die Düsseldorfer Brückenfamilie war ursprünglich ein Sammelbegriff." , "Die Düssel ist ein rund 40 Kilometer langer Fluss." , "Die Berliner Mauer war während der Teilung Deutschlands die Grenze." , "Für amtliche Dokumente und Formulare ist das anders." , "Wie viele Kilometer ist ihre Stadt von unserer entfernt?" , "Über laufende Sanierungsmaßnahmen ist bislang nichts bekannt." , "In den letzten zwei Monate war ich fleißig wie eine Biene." , "Durch Einsatz größerer Maschinen und bessere Kapazitätsplanung ist die Zahl der Flüge gestiegen." , "Die hohe Zahl dieser relativ kleinen Verwaltungseinheiten ist immer wieder Gegenstand von Diskussionen." , "Teil der ausgestellten Bestände ist auch die Bierdeckel-Sammlung." , "Teil der umfangreichen dort ausgestellten Bestände ist auch die Bierdeckel-Sammlung." , "Teil der dort ausgestellten Bestände ist auch die Bierdeckel-Sammlung." , "Der zweite Teil dieses Buches ist in England angesiedelt." , "Eine der am meisten verbreiteten Krankheiten ist die Diagnose" , "Eine der verbreitetsten Krankheiten ist hier." , "Die Krankheit unserer heutigen Städte und Siedlungen ist folgendes." , "Die darauffolgenden Jahre war er ..." , "Die letzten zwei Monate war ich fleißig wie eine Biene." , "Bei sehr guten Beobachtungsbedingungen ist zu erkennen, dass ..." , "Die beste Rache für Undank und schlechte Manieren ist Höflichkeit." , "Ein Gramm Pfeffer war früher wertvoll." , "Die größte Stuttgarter Grünanlage ist der Friedhof." , "Mancher will Meister sein und ist kein Lehrjunge gewesen." , "Ellen war vom Schock ganz bleich." , "Nun gut, die Nacht ist sehr lang, oder?" , "Der Morgen ist angebrochen, die lange Nacht ist vorüber." , "Die stabilste und häufigste Oxidationsstufe ist dabei −1." , "Man kann nicht eindeutig zuordnen, wer Täter und wer Opfer war." , "Ich schätze, die Batterie ist leer." , "Der größte und schönste Tempel eines Menschen ist in ihm selbst." , "Begehe keine Dummheit zweimal, die Auswahl ist doch groß genug!" , "Seine größte und erfolgreichste Erfindung war die Säule." , "Egal was du sagst, die Antwort ist Nein." , "... in der Geschichte des Museums, die Sammlung ist seit 2011 zugänglich." , "Deren Bestimmung und Funktion ist allerdings nicht so klar." , "Sie hat eine Tochter, die Pianistin ist." , "Ja, die Milch ist sehr gut." , "Der als Befestigung gedachte östliche Teil der Burg ist weitgehend verfallen." , "Das Kopieren und Einfügen ist sehr nützlich." , "Der letzte der vier großen Flüsse ist die Kolyma." , "In christlichen, islamischen und jüdischen Traditionen ist das höchste Ziel der meditativen Praxis." , "Der Autor der beiden Spielbücher war Markus Heitz selbst." , "Der Autor der ersten beiden Spielbücher war Markus Heitz selbst." , "Das Ziel der elf neuen Vorstandmitglieder ist klar definiert." , "Laut den meisten Quellen ist das Seitenverhältnis der Nationalflagge..." , "Seine Novelle, die eigentlich eine Glosse ist, war toll." , "Für in Österreich lebende Afrikaner und Afrikanerinnen ist dies nicht üblich." , "Von ursprünglich drei Almhütten ist noch eine erhalten." , "Einer seiner bedeutendsten Kämpfe war gegen den späteren Weltmeister." ) ; for ( String sentence : sentences ) { assertGood ( sentence ) ; } } @ Test public void testRuleWithIncorrectPluralVerb ( ) throws IOException { List < String > sentences = Arrays . asList ( "Die Katze sind schön." , "Die Katze waren schön." , "Der Text sind gut." , "Das Auto sind schnell." , "Herr Schröder sind alt." , "Julia und Karsten ist alt." , "Julia, Heike und Karsten ist alt." , "Herr Karsten Schröder sind alt." ) ; for ( String sentence : sentences ) { assertBad ( sentence ) ; } } @ Test public void testRuleWithCorrectPluralVerb ( ) throws IOException { List < String > sentences = Arrays . asList ( "Die Katzen sind schön." , "Frau Meier und Herr Müller sind alt." , "Frau Julia Meier und Herr Karsten Müller sind alt." , "Julia und Karsten sind alt." , "Julia, Heike und Karsten sind alt." , "Frau und Herr Müller sind alt." , "Herr und Frau Schröder sind alt." , "Herr Meier und Frau Schröder sind alt." , "Die restlichen 86 Prozent sind in der Flasche." , "Die restlichen sechsundachtzig Prozent sind in der Flasche." , "Die restlichen 86 oder 87 Prozent sind in der Flasche." , "Die restlichen 86 % sind in der Flasche." , "Durch den schnellen Zerfall des Actiniums waren stets nur geringe Mengen verfügbar." , "Soda und Anilin waren die ersten Produkte des Unternehmens." , "Bob und Tom sind Brüder." , "Letztes Jahr sind wir nach London gegangen." , "Trotz des Regens sind die Kinder in die Schule gegangen." , "Die Zielgruppe sind Männer." , "Männer sind die Zielgruppe." , "Die Zielgruppe sind meist junge Erwachsene." , "Die USA sind ein repräsentativer demokratischer Staat." , "Wesentliche Eigenschaften der Hülle sind oben beschrieben." , "Wesentliche Eigenschaften der Hülle sind oben unter Quantenmechanische Atommodelle und Erklärung grundlegender Atomeigenschaften dargestellt." , "Er und seine Schwester sind eingeladen." , "Er und seine Schwester sind zur Party eingeladen." , "Sowohl er als auch seine Schwester sind zur Party eingeladen." , "Rekonstruktionen oder der Wiederaufbau sind wissenschaftlich sehr umstritten." , "Form und Materie eines Einzeldings sind aber nicht zwei verschiedene Objekte." , "Dieses Jahr sind die Birnen groß." , "Es so umzugestalten, dass sie wie ein Spiel sind." , "Die Zielgruppe sind meist junge Erwachsene." , "Die Ursache eines Hauses sind so Ziegel und Holz." , "Vertreter dieses Ansatzes sind unter anderem Roth und Meyer." , "Sowohl sein Vater als auch seine Mutter sind tot." , "Einige der Inhaltsstoffe sind schädlich." , "Diese Woche sind wir schon einen großen Schritt weiter." , "Diese Woche sind sie hier." , "Vorsitzende des Vereins waren:" , "Weder Gerechtigkeit noch Freiheit sind möglich, wenn nur das Geld regiert." , "Ein typisches Beispiel sind Birkenpollenallergene." , "Eine weitere Variante sind die Miniatur-Wohnlandschaften." , "Eine Menge englischer Wörter sind aus dem Lateinischen abgeleitet." , "Völkerrechtlich umstrittenes Territorium sind die Falklandinseln." , "Einige dieser älteren Synthesen sind wegen geringer Ausbeuten ..." , "Einzelne Atome sind klein." , "Die Haare dieses Jungens sind schwarz." , "Die wichtigsten Mechanismen des Aminosäurenabbaus sind:" , "Wasserlösliche Bariumverbindungen sind giftig." , "Die Schweizer Trinkweise ist dabei die am wenigsten etablierte." , "Die Anordnung der vier Achsen ist damit identisch." , "Die Nauheimer Musiktage, die immer wieder ein kultureller Höhepunkt sind." , "Räumliche und zeitliche Abstände sowie die Trägheit sind vom Bewegungszustand abhängig." , "Solche Gewerbe sowie der Karosseriebau sind traditionell stark vertreten." , "Hundert Dollar sind doch gar nichts!" , "Sowohl Tom als auch Maria waren überrascht." , "Robben, die die hauptsächliche Beute der Eisbären sind." , "Die Albatrosse sind eine Gruppe von Seevögeln" , "Die Albatrosse sind eine Gruppe von großen Seevögeln" , "Die Albatrosse sind eine Gruppe von großen bis sehr großen Seevögeln" , "Vier Elemente, welche der Urstoff aller Körper sind." , "Die Beziehungen zwischen Kanada und dem Iran sind seitdem abgebrochen." , "Die diplomatischen Beziehungen zwischen Kanada und dem Iran sind seitdem abgebrochen." , "Die letzten zehn Jahre seines Lebens war er erblindet." , "Die letzten zehn Jahre war er erblindet." , "... so dass Knochenbrüche und Platzwunden die Regel sind." , "Die Eigentumsverhältnisse an der Gesellschaft sind unverändert geblieben." , "Gegenstand der Definition sind für ihn die Urbilder." , "Mindestens zwanzig Häuser sind abgebrannt." , "Sie hielten geheim, dass sie Geliebte waren." , "Einige waren verspätet." , "Kommentare, Korrekturen und Kritik sind verboten." , "Kommentare, Korrekturen, Kritik sind verboten." , "Letztere sind wichtig, um die Datensicherheit zu garantieren." , "Jüngere sind oft davon überzeugt, im Recht zu sein." , "Verwandte sind selten mehr als Bekannte." , "Ursache waren die hohe Arbeitslosigkeit und die Wohnungsnot." , "Ursache waren unter anderem die hohe Arbeitslosigkeit und die Wohnungsnot." , "Er ahnt nicht, dass sie und sein Sohn ein Paar sind." , "Die Ursachen der vorliegenden Durchblutungsstörung sind noch unbekannt." , "Der See und das Marschland sind ein Naturschutzgebiet" ) ; for ( String sentence : sentences ) { assertGood ( sentence ) ; } } @ Test public void testRuleWithCorrectSingularAndPluralVerb ( ) throws IOException { List < String > sentences = Arrays . asList ( "So mancher Mitarbeiter und manche Führungskraft ist im Urlaub." , "So mancher Mitarbeiter und manche Führungskraft sind im Urlaub." , "Jeder Schüler und jede Schülerin ist mal schlecht gelaunt." , "Jeder Schüler und jede Schülerin sind mal schlecht gelaunt." , "Kaum mehr als vier Prozent der Fläche ist für landwirtschaftliche Nutzung geeignet." , "Kaum mehr als vier Prozent der Fläche sind für landwirtschaftliche Nutzung geeignet." , "Kaum mehr als vier Millionen Euro des Haushalts ist verplant." , "Kaum mehr als vier Millionen Euro des Haushalts sind verplant." , "80 Cent ist nicht genug." , "80 Cent sind nicht genug." , "1,5 Pfund ist nicht genug." , "1,5 Pfund sind nicht genug." , "Hier ist sowohl Anhalten wie Parken verboten." , "Hier sind sowohl Anhalten wie Parken verboten." ) ; for ( String sentence : sentences ) { assertGood ( sentence ) ; } } private void assertGood ( String input ) throws IOException { RuleMatch [ ] matches = getMatches ( input ) ; if ( matches . length != 0 ) { fail ( "Got unexpected match(es) for '" + input + "': " + Arrays . toString ( matches ) , input ) ; } } private void assertBad ( String input ) throws IOException { int matchCount = getMatches ( input ) . length ; if ( matchCount == 0 ) { fail ( "Did not get the expected match for '" + input + "'" , input ) ; } } private void fail ( String message , String input ) throws IOException { if ( ! GermanChunker . isDebug ( ) ) { GermanChunker . setDebug ( true ) ; getMatches ( input ) ; } Assert . fail ( message ) ; } private RuleMatch [ ] getMatches ( String input ) throws IOException { return rule . match ( langTool . getAnalyzedSentence ( input ) ) ; } }
package org . languagetool . rules . de ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import java . io . IOException ; import static org . junit . Assert . assertEquals ; public class MissingVerbRuleTest { private final MissingVerbRule rule = new MissingVerbRule ( TestTools . getEnglishMessages ( ) , new German ( ) ) ; @ Test public void test ( ) throws IOException { JLanguageTool lt = new JLanguageTool ( new German ( ) ) ; assertGood ( "Da ist ein Verb, mal so zum testen." , lt ) ; assertGood ( "Überschrift ohne Verb aber doch nicht zu kurz" , lt ) ; assertGood ( "Sprechen Sie vielleicht zufällig Türkisch?" , lt ) ; assertGood ( "Leg den Tresor in den Koffer im Kofferraum." , lt ) ; assertGood ( "Bring doch einfach deine Kinder mit." , lt ) ; assertGood ( "Gut so." , lt ) ; assertGood ( "Ja!" , lt ) ; assertGood ( "Vielen Dank für alles, was Du für mich getan hast." , lt ) ; assertGood ( "Herzlichen Glückwunsch zu Deinem zwanzigsten Geburtstag." , lt ) ; assertBad ( "Dieser Satz kein Verb." , lt ) ; assertBad ( "Aus einer Idee sich erste Wortgruppen, aus Wortgruppen einzelne Sätze, aus Sätzen ganze Texte." , lt ) ; } private void assertGood ( String text , JLanguageTool langTool ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( text ) ) . length ) ; } private void assertBad ( String text , JLanguageTool langTool ) throws IOException { assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( text ) ) . length ) ; } }
package org . languagetool . rules . de ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . German ; import org . languagetool . rules . GenericUnpairedBracketsRule ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Collections ; public class GenericUnpairedBracketsRuleTest extends TestCase { private GenericUnpairedBracketsRule rule ; private JLanguageTool langTool ; public void testGermanRule ( ) throws IOException { langTool = new JLanguageTool ( new German ( ) ) ; rule = org . languagetool . rules . GenericUnpairedBracketsRuleTest . getBracketsRule ( langTool ) ; assertMatches ( "(Das sind die Sätze, die sie testen sollen)." , 0 ) ; assertMatches ( "(Das sind die «Sätze», die sie testen sollen)." , 0 ) ; assertMatches ( "(Das sind die »Sätze«, die sie testen sollen)." , 0 ) ; assertMatches ( "(Das sind die Sätze (noch mehr Klammern [schon wieder!]), die sie testen sollen)." , 0 ) ; assertMatches ( "Das ist ein Satz mit Smiley :-)" , 0 ) ; assertMatches ( "Das ist auch ein Satz mit Smiley ;-)" , 0 ) ; assertMatches ( "Die „Sätze zum Testen." , 1 ) ; assertMatches ( "Die «Sätze zum Testen." , 1 ) ; assertMatches ( "Die »Sätze zum Testen." , 1 ) ; } private void assertMatches ( String input , int expectedMatches ) throws IOException { final RuleMatch [ ] matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( input ) ) ) ; assertEquals ( expectedMatches , matches . length ) ; } }
package org . languagetool . rules . ca ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . GenericUnpairedBracketsRule ; import org . languagetool . rules . ITSIssueType ; public class CatalanUnpairedExclamationMarksRule extends GenericUnpairedBracketsRule { private static final List < String > CA_START_SYMBOLS = Arrays . asList ( "¡" ) ; private static final List < String > CA_END_SYMBOLS = Arrays . asList ( "!" ) ; public CatalanUnpairedExclamationMarksRule ( final ResourceBundle messages , final Language language ) { super ( messages , CA_START_SYMBOLS , CA_END_SYMBOLS ) ; setLocQualityIssueType ( ITSIssueType . Style ) ; setDefaultOff ( ) ; } @ Override public String getDescription ( ) { return "Exigeix signe d'exclamació inicial" ; } @ Override public String getId ( ) { return "CA_UNPAIRED_EXCLAMATION" ; } }
package org . languagetool . rules . de ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import java . io . IOException ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . * ; public class SimilarNameRuleTest { @ Test public void testRule ( ) throws IOException { SimilarNameRule rule = new SimilarNameRule ( TestTools . getEnglishMessages ( ) ) ; JLanguageTool lt = new JLanguageTool ( new German ( ) ) ; assertErrors ( "Hier steht Angela Müller. Im nächsten Satz dann Miller." , 1 , rule , lt ) ; assertErrors ( "Hier steht Angela Müller. Im nächsten Satz dann Müllers Ehemann." , 0 , rule , lt ) ; assertErrors ( "Hier steht Angela Müller. Dann Mulla, nicht ähnlich genug." , 0 , rule , lt ) ; } private void assertErrors ( String input , int expectedMatches , SimilarNameRule rule , JLanguageTool lt ) throws IOException { assertThat ( rule . match ( lt . getAnalyzedSentence ( input ) ) . length , is ( expectedMatches ) ) ; rule . reset ( ) ; } }
package org . languagetool . rules . de ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; public class CaseRuleTest extends TestCase { private CaseRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new CaseRule ( TestTools . getMessages ( "de" ) , new German ( ) ) ; langTool = new JLanguageTool ( new German ( ) ) ; } public void testRuleActivation ( ) throws IOException { assertTrue ( rule . supportsLanguage ( new German ( ) ) ) ; } public void testRule ( ) throws IOException { assertGood ( "Dem Hund Futter geben" ) ; assertGood ( "Heute spricht Frau Stieg." ) ; assertGood ( "Ein einfacher Satz zum Testen." ) ; assertGood ( "Das Laufen fällt mir leicht." ) ; assertGood ( "Das Winseln stört." ) ; assertGood ( "Das schlägt nicht so zu Buche." ) ; assertGood ( "Dirk Hetzel ist ein Name." ) ; assertGood ( "Sein Verhalten war okay." ) ; assertGood ( "Hier ein Satz. \"Ein Zitat.\"" ) ; assertGood ( "Hier ein Satz. 'Ein Zitat.'" ) ; assertGood ( "Hier ein Satz. «Ein Zitat.»" ) ; assertGood ( "Hier ein Satz. »Ein Zitat.«" ) ; assertGood ( "Hier ein Satz. (Noch einer.)" ) ; assertGood ( "Hier geht es nach Tel Aviv." ) ; assertGood ( "Unser Jüngster ist da." ) ; assertGood ( "Alles Erfundene ist wahr." ) ; assertGood ( "Sie hat immer ihr Bestes getan." ) ; assertGood ( "Er wird etwas Verrücktes träumen." ) ; assertGood ( "Er wird etwas schön Verrücktes träumen." ) ; assertGood ( "Er wird etwas ganz schön Verrücktes träumen." ) ; assertGood ( "Mit aufgewühltem Innerem." ) ; assertGood ( "Mit völlig aufgewühltem Innerem." ) ; assertGood ( "Er wird etwas so Verrücktes träumen." ) ; assertGood ( "Tom ist etwas über dreißig." ) ; assertGood ( "Diese Angriffe bleiben im Verborgenen." ) ; assertGood ( "Ihr sollt mich das wissen lassen." ) ; assertGood ( "Wenn er mich das rechtzeitig wissen lässt, gerne." ) ; assertGood ( "Und sein völlig aufgewühltes Inneres erzählte von den Geschehnissen." ) ; assertGood ( "Aber sein aufgewühltes Inneres erzählte von den Geschehnissen." ) ; assertGood ( "Aber sein Inneres erzählte von den Geschehnissen." ) ; assertGood ( "Ein Kaninchen, das zaubern kann." ) ; assertBad ( "Tom ist etwas über Dreißig." ) ; assertBad ( "Unser warten wird sich lohnen." ) ; assertBad ( "Tom kann mit fast Allem umgehen." ) ; assertGood ( "Ein Menschenfreund." ) ; assertGood ( "Der Nachfahre." ) ; assertGood ( "Hier ein Satz, \"Ein Zitat.\"" ) ; assertGood ( "Hier ein Satz, \"ein Zitat.\"" ) ; assertGood ( "Schon Le Monde schrieb das." ) ; assertGood ( "In Blubberdorf macht man das so." ) ; assertGood ( "Sie werden im Allgemeinen gefasst." ) ; assertGood ( "Sie werden im allgemeinen Fall gefasst." ) ; assertBad ( "Sie werden im Allgemeinen Fall gefasst." ) ; assertGood ( "Das sind Euroscheine." ) ; assertGood ( "John Stallman isst." ) ; assertGood ( "Das ist die neue Gesellschafterin hier." ) ; assertGood ( "Das ist die neue Dienerin hier." ) ; assertGood ( "Das ist die neue Geigerin hier." ) ; assertGood ( "Die ersten Gespanne erreichen Köln." ) ; assertGood ( "Er beschrieb den Angeklagten wie einen Schuldigen" ) ; assertGood ( "Er beschrieb den Angeklagten wie einen Schuldigen." ) ; assertGood ( "Das ist das Dümmste, was ich je gesagt habe." ) ; assertBad ( "Das ist das Dümmste Kind." ) ; assertGood ( "Man sagt, Liebe mache blind." ) ; assertGood ( "Die Deutschen sind sehr listig." ) ; assertGood ( "Der Lesestoff bestimmt die Leseweise." ) ; assertGood ( "Ich habe nicht viel von einem Reisenden." ) ; assertGood ( "Die Vereinigten Staaten" ) ; assertGood ( "Die Ausgewählten werden gut betreut." ) ; assertGood ( "Die ausgewählten Leute werden gut betreut." ) ; assertBad ( "Die Ausgewählten Leute werden gut betreut." ) ; assertGood ( "Die Schlinge zieht sich zu." ) ; assertGood ( "Die Schlingen ziehen sich zu." ) ; assertGood ( "Sie fällt auf durch ihre hilfsbereite Art. Zudem zeigt sie soziale Kompetenz." ) ; assertGood ( "Das ist es: kein Satz." ) ; assertGood ( "Das ist es: Kein Satz." ) ; assertGood ( "Das wirklich Wichtige ist dies:" ) ; assertGood ( "Das wirklich wichtige Verfahren ist dies:" ) ; assertBad ( "Das wirklich Wichtige Verfahren ist dies:" ) ; assertBad ( "Die Schöne Tür" ) ; assertBad ( "Das Blaue Auto." ) ; assertBad ( "Ein Einfacher Satz zum Testen." ) ; assertBad ( "Das Winseln Stört." ) ; assertBad ( "Sein verhalten war okay." ) ; assertEquals ( 1 , langTool . check ( "Karten werden vom Auswahlstapel gezogen. Auch […] Der Auswahlstapel gehört zum Inhalt." ) . size ( ) ) ; assertEquals ( 0 , langTool . check ( "Karten werden vom Auswahlstapel gezogen. […] Der Auswahlstapel gehört zum Inhalt." ) . size ( ) ) ; assertGood ( "Im Norwegischen klingt das schöner." ) ; assertGood ( "Übersetzt aus dem Norwegischen von Ingenieur Frederik Dingsbums." ) ; assertGood ( "Dem norwegischen Ingenieur gelingt das gut." ) ; assertBad ( "Dem Norwegischen Ingenieur gelingt das gut." ) ; assertGood ( "Peter Peterson, dessen Namen auf Griechisch Stein bedeutet." ) ; assertGood ( "Peter Peterson, dessen Namen auf Griechisch gut klingt." ) ; } private void assertGood ( String input ) throws IOException { assertEquals ( "Did not expect error in: '" + input + "'" , 0 , rule . match ( langTool . getAnalyzedSentence ( input ) ) . length ) ; } private void assertBad ( String input ) throws IOException { assertEquals ( "Did not find expected error in: '" + input + "'" , 1 , rule . match ( langTool . getAnalyzedSentence ( input ) ) . length ) ; } public void testSubstantivierteVerben ( ) throws IOException { assertGood ( "Das fahrende Auto." ) ; assertGood ( "Das können wir so machen." ) ; assertGood ( "Denn das Fahren ist einfach." ) ; assertGood ( "Das Fahren ist einfach." ) ; assertGood ( "Das Gehen fällt mir leicht." ) ; assertGood ( "Das Ernten der Kartoffeln ist mühsam." ) ; assertGood ( "Entschuldige das späte Weiterleiten." ) ; assertGood ( "Ich liebe das Lesen." ) ; assertGood ( "Das Betreten des Rasens ist verboten." ) ; assertGood ( "Das haben wir aus eigenem Antrieb getan." ) ; assertGood ( "Das haben wir." ) ; assertGood ( "Das haben wir schon." ) ; assertGood ( "Das lesen sie doch sicher in einer Minute durch." ) ; assertGood ( "Das lesen Sie doch sicher in einer Minute durch!" ) ; assertGood ( "Formationswasser, das oxidiert war." ) ; assertGood ( "Das Lesen fällt mir schwer." ) ; assertGood ( "Sie hörten ein starkes Klopfen." ) ; assertGood ( "Wer erledigt das Fensterputzen?" ) ; assertGood ( "Viele waren am Zustandekommen des Vertrages beteiligt." ) ; assertGood ( "Die Sache kam ins Stocken." ) ; assertGood ( "Das ist zum Lachen." ) ; assertGood ( "Euer Fernbleiben fiel uns auf." ) ; assertGood ( "Uns half nur noch lautes Rufen." ) ; assertGood ( "Die Mitbewohner begnügten sich mit Wegsehen und Schweigen." ) ; assertGood ( "Sie wollte auf Biegen und Brechen gewinnen." ) ; assertGood ( "Er klopfte mit Zittern und Zagen an." ) ; assertGood ( "Ich nehme die Tabletten auf Anraten meiner Ärztin." ) ; assertGood ( "Sie hat ihr Soll erfüllt." ) ; assertGood ( "Dies ist ein absolutes Muss." ) ; assertGood ( "Das Lesen fällt mir schwer." ) ; assertBad ( "Das fahren ist einfach." ) ; assertBad ( "Denn das fahren ist einfach." ) ; assertBad ( "Denn das laufen ist einfach." ) ; assertBad ( "Denn das essen ist einfach." ) ; assertBad ( "Denn das gehen ist einfach." ) ; assertBad ( "Das Große Auto wurde gewaschen." ) ; assertBad ( "Ich habe ein Neues Fahrrad." ) ; } public void testPhraseExceptions ( ) throws IOException { assertGood ( "Das gilt ohne Wenn und Aber." ) ; assertGood ( "ohne Wenn und Aber" ) ; assertGood ( "Das gilt ohne Wenn und Aber bla blubb." ) ; assertGood ( "Das gilt ohne wenn" ) ; assertGood ( "Das gilt ohne wenn und" ) ; assertGood ( "wenn und aber" ) ; assertGood ( "und aber" ) ; assertGood ( "aber" ) ; } public void testCompareLists ( ) throws IOException { AnalyzedSentence sentence1 = langTool . getAnalyzedSentence ( "Hier ein Test" ) ; assertTrue ( rule . compareLists ( sentence1 . getTokensWithoutWhitespace ( ) , 0 , 2 , new String [ ] { "" , "Hier" , "ein" } ) ) ; assertTrue ( rule . compareLists ( sentence1 . getTokensWithoutWhitespace ( ) , 1 , 2 , new String [ ] { "Hier" , "ein" } ) ) ; assertTrue ( rule . compareLists ( sentence1 . getTokensWithoutWhitespace ( ) , 0 , 3 , new String [ ] { "" , "Hier" , "ein" , "Test" } ) ) ; assertFalse ( rule . compareLists ( sentence1 . getTokensWithoutWhitespace ( ) , 0 , 4 , new String [ ] { "" , "Hier" , "ein" , "Test" } ) ) ; AnalyzedSentence sentence2 = langTool . getAnalyzedSentence ( "das Heilige Römische Reich" ) ; assertTrue ( rule . compareLists ( sentence2 . getTokensWithoutWhitespace ( ) , 0 , 4 , new String [ ] { "" , "das" , "Heilige" , "Römische" , "Reich" } ) ) ; assertFalse ( rule . compareLists ( sentence2 . getTokensWithoutWhitespace ( ) , 8 , 11 , new String [ ] { "" , "das" , "Heilige" , "Römische" , "Reich" } ) ) ; } }
package org . languagetool . rules . de ; import morfologik . speller . Speller ; import morfologik . stemming . Dictionary ; import org . apache . commons . lang . StringUtils ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . net . URL ; import java . nio . charset . CharacterCodingException ; import java . util . Arrays ; import java . util . List ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertThat ; public class MorfologikGermanyGermanSpellerRuleTest { @ Test public void testMorfologikSpeller ( ) throws IOException { final MorfologikGermanyGermanSpellerRule rule = new MorfologikGermanyGermanSpellerRule ( TestTools . getMessages ( "en" ) , new German ( ) ) ; final JLanguageTool langTool = new JLanguageTool ( new German ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Hier stimmt jedes Wort!" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Hir nicht so ganz." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Überall äußerst böse Umlaute!" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Üperall äußerst böse Umlaute!" ) ) . length ) ; final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "daß" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "dass" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } @ Test @ Ignore ( "testing for https://github.com/languagetool-org/languagetool/issues/236" ) public void testFrequency ( ) throws IOException { URL fsaURL = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( "de/hunspell/de_DE.dict" ) ; Dictionary dictionary = Dictionary . read ( fsaURL ) ; Speller speller = new Speller ( dictionary , 2 ) ; assertThat ( speller . getFrequency ( "der" ) , is ( 25 ) ) ; assertThat ( speller . getFrequency ( "Haus" ) , is ( 11 ) ) ; assertThat ( speller . getFrequency ( "schön" ) , is ( 9 ) ) ; assertThat ( speller . getFrequency ( "gippsnicht" ) , is ( 0 ) ) ; } @ Test @ Ignore ( "help testing for https://github.com/morfologik/morfologik-stemming/issues/34" ) public void testCommonMisspellings ( ) throws IOException { URL fsaURL = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( "de/hunspell/de_DE.dict" ) ; Dictionary dictionary = Dictionary . read ( fsaURL ) ; Speller speller = new Speller ( dictionary , 2 ) ; List < String > input = Arrays . asList ( ( "Abenteur Abhängikeit abzuschliessen agerufen Aktivitiäten Aktzeptanz " + "Algorhitmus Algoritmus aliiert allgmein Amtsitz änlich Anstoss atakieren begrüsst Bezeichnug chinesiche " + "dannach Frima Fahrad Gebaüde gesammt Schrifsteller seperat Septmber Staddteil Rhytmen rhytmisch Maschiene " + "Lebensmittelgäschefte enstand großmutter Rytmus " + "Vorstelungsgespräch Heißhunge-Attakcen evntl. langwalig Selbstportät Erdgeshoss " + "kommmischeweise gegensatz Gesichte Suedkaukasus Englisch-sprachigige " + "gerägelt Aufjedenfall ivh hällt daß muß woeder oderso anwalt" ) . split ( " " ) ) ; for ( String word : input ) { check ( word , speller ) ; } } private void check ( String word , Speller speller ) throws CharacterCodingException { List < String > suggestions = speller . findReplacements ( word ) ; System . out . println ( word + ": " + StringUtils . join ( suggestions , ", " ) ) ; } }
package org . languagetool . rules . de ; import morfologik . fsa . CFSA2Serializer ; import morfologik . fsa . FSA ; import morfologik . fsa . FSABuilder ; import morfologik . speller . Speller ; import morfologik . stemming . Dictionary ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . AustrianGerman ; import org . languagetool . language . German ; import org . languagetool . language . GermanyGerman ; import org . languagetool . language . SwissGerman ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . spelling . hunspell . HunspellRule ; import java . io . ByteArrayInputStream ; import java . io . ByteArrayOutputStream ; import java . io . IOException ; import java . io . InputStream ; import java . util . * ; import static junit . framework . TestCase . assertFalse ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertThat ; import static org . junit . Assert . assertTrue ; public class GermanSpellerRuleTest { private static final GermanyGerman GERMAN_DE = new GermanyGerman ( ) ; private static final SwissGerman GERMAN_CH = new SwissGerman ( ) ; @ Test public void testSortSuggestion ( ) throws Exception { final GermanSpellerRule rule = new GermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_DE ) ; assertThat ( rule . sortSuggestionByQuality ( "fehler" , Arrays . asList ( "Fehler" , "fehl er" , "fehle r" ) ) . toString ( ) , is ( "[Fehler, fehl er]" ) ) ; assertThat ( rule . sortSuggestionByQuality ( "mülleimer" , Arrays . asList ( "Mülheimer" , "-mülheimer" , "Melkeimer" , "Mühlheimer" , "Mülleimer" ) ) . toString ( ) , is ( "[Mülleimer, Mülheimer, -mülheimer, Melkeimer, Mühlheimer]" ) ) ; } @ Test public void testGetAdditionalTopSuggestions ( ) throws Exception { final GermanSpellerRule rule = new GermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_DE ) ; final JLanguageTool langTool = new JLanguageTool ( GERMAN_DE ) ; RuleMatch [ ] matches1 = rule . match ( langTool . getAnalyzedSentence ( "konservierungsstoffe" ) ) ; assertThat ( matches1 [ 0 ] . getSuggestedReplacements ( ) . toString ( ) , is ( "[Konservierungsstoffe]" ) ) ; RuleMatch [ ] matches2 = rule . match ( langTool . getAnalyzedSentence ( "konservierungsstoffstatistik" ) ) ; assertThat ( matches2 [ 0 ] . getSuggestedReplacements ( ) . toString ( ) , is ( "[Konservierungsstoffstatistik]" ) ) ; RuleMatch [ ] matches3 = rule . match ( langTool . getAnalyzedSentence ( "konservierungsstoffsasdsasda" ) ) ; assertThat ( matches3 [ 0 ] . getSuggestedReplacements ( ) . size ( ) , is ( 0 ) ) ; assertFirstSuggestion ( "denkte" , "dachte" , rule , langTool ) ; assertFirstSuggestion ( "schwimmte" , "schwamm" , rule , langTool ) ; assertFirstSuggestion ( "gehte" , "ging" , rule , langTool ) ; assertFirstSuggestion ( "greifte" , "griff" , rule , langTool ) ; assertFirstSuggestion ( "geschwimmt" , "geschwommen" , rule , langTool ) ; assertFirstSuggestion ( "gegeht" , "gegangen" , rule , langTool ) ; assertFirstSuggestion ( "getrinkt" , "getrunken" , rule , langTool ) ; assertFirstSuggestion ( "gespringt" , "gesprungen" , rule , langTool ) ; assertFirstSuggestion ( "geruft" , "gerufen" , rule , langTool ) ; } @ Test public void testAddIgnoreWords ( ) throws Exception { MyGermanSpellerRule rule = new MyGermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_DE ) ; Set < String > set = new HashSet < > ( ) ; rule . addIgnoreWords ( "Fußelmappse" , set ) ; assertTrue ( set . contains ( "Fußelmappse" ) ) ; rule . addIgnoreWords ( "Fußelmappse/N" , set ) ; assertTrue ( set . contains ( "Fußelmappse" ) ) ; assertTrue ( set . contains ( "Fußelmappsen" ) ) ; rule . addIgnoreWords ( "Toggeltröt/NS" , set ) ; assertTrue ( set . contains ( "Toggeltröt" ) ) ; assertTrue ( set . contains ( "Toggeltröts" ) ) ; assertTrue ( set . contains ( "Toggeltrötn" ) ) ; rule . addIgnoreWords ( "Toggeltröt/NS" , set ) ; MyGermanSpellerRule ruleCH = new MyGermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_CH ) ; ruleCH . addIgnoreWords ( "Fußelmappse/N" , set ) ; assertTrue ( set . contains ( "Fusselmappse" ) ) ; assertTrue ( set . contains ( "Fusselmappsen" ) ) ; } private void assertFirstSuggestion ( String input , String expected , GermanSpellerRule rule , JLanguageTool langTool ) throws IOException { RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( input ) ) ; assertThat ( matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) , is ( expected ) ) ; } @ Test public void testDashAndHyphen ( ) throws Exception { final HunspellRule rule = new GermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_DE ) ; final JLanguageTool langTool = new JLanguageTool ( GERMAN_DE ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Ist doch - gut" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Ist doch -- gut" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Stil- und Grammatikprüfung gut" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Stil-, Text- und Grammatikprüfung gut" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Stil-, Text- und Grammatikprüfung" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Stil-, Text- oder Grammatikprüfung" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Miet- und Zinseinkünfte" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Haupt- und Nebensatz" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Miet und Zinseinkünfte" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Stil- und Grammatik gut" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Flasch- und Grammatikprüfung gut" ) ) . length ) ; } @ Test public void testGetSuggestionsFromSpellingTxt ( ) throws Exception { MyGermanSpellerRule ruleGermany = new MyGermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_DE ) ; assertThat ( ruleGermany . getSuggestions ( "Ligafußboll" ) . toString ( ) , is ( "[Ligafußball, Ligafußballs]" ) ) ; MyGermanSpellerRule ruleSwiss = new MyGermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_CH ) ; assertThat ( ruleSwiss . getSuggestions ( "Ligafußboll" ) . toString ( ) , is ( "[Ligafussball, Ligafussballs]" ) ) ; assertThat ( ruleSwiss . getSuggestions ( "konfliktbereid" ) . toString ( ) , is ( "[konfliktbereit, konfliktbereite]" ) ) ; assertThat ( ruleSwiss . getSuggestions ( "konfliktbereitel" ) . toString ( ) , is ( "[konfliktbereite, konfliktbereitem, konfliktbereiten, konfliktbereiter, konfliktbereites, konfliktbereit]" ) ) ; } @ Test public void testIgnoreWord ( ) throws Exception { MyGermanSpellerRule ruleGermany = new MyGermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_DE ) ; assertTrue ( ruleGermany . doIgnoreWord ( "einPseudoWortFürLanguageToolTests" ) ) ; assertTrue ( ruleGermany . doIgnoreWord ( "Ligafußball" ) ) ; assertTrue ( ruleGermany . doIgnoreWord ( "Wichtelmännchen" ) ) ; assertTrue ( ruleGermany . doIgnoreWord ( "Wichtelmännchens" ) ) ; assertTrue ( ruleGermany . doIgnoreWord ( "vorgehängt" ) ) ; assertTrue ( ruleGermany . doIgnoreWord ( "vorgehängten" ) ) ; MyGermanSpellerRule ruleSwiss = new MyGermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_CH ) ; assertTrue ( ruleSwiss . doIgnoreWord ( "einPseudoWortFürLanguageToolTests" ) ) ; assertFalse ( ruleSwiss . doIgnoreWord ( "Ligafußball" ) ) ; } private static class MyGermanSpellerRule extends GermanSpellerRule { MyGermanSpellerRule ( ResourceBundle messages , German language ) throws IOException { super ( messages , language ) ; init ( ) ; } boolean doIgnoreWord ( String word ) throws IOException { return super . ignoreWord ( Collections . singletonList ( word ) , 0 ) ; } } @ Test public void testRuleWithGermanyGerman ( ) throws Exception { final HunspellRule rule = new GermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_DE ) ; final JLanguageTool langTool = new JLanguageTool ( GERMAN_DE ) ; commonGermanAsserts ( rule , langTool ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der äußere Übeltäter." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der äussere Übeltäter." ) ) . length ) ; } @ Test public void testRuleWithAustrianGerman ( ) throws Exception { final AustrianGerman language = new AustrianGerman ( ) ; final HunspellRule rule = new GermanSpellerRule ( TestTools . getMessages ( "de" ) , language ) ; final JLanguageTool langTool = new JLanguageTool ( language ) ; commonGermanAsserts ( rule , langTool ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der äußere Übeltäter." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der äussere Übeltäter." ) ) . length ) ; } @ Test public void testRuleWithSwissGerman ( ) throws Exception { final SwissGerman language = new SwissGerman ( ) ; final HunspellRule rule = new GermanSpellerRule ( TestTools . getMessages ( "de" ) , language ) ; final JLanguageTool langTool = new JLanguageTool ( language ) ; commonGermanAsserts ( rule , langTool ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der äußere Übeltäter." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der äussere Übeltäter." ) ) . length ) ; } private void commonGermanAsserts ( HunspellRule rule , JLanguageTool langTool ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der Waschmaschinentestversuch" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der Waschmaschinentest-Versuch" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der Arbeitnehmer" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Die Verhaltensänderung" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der Waschmaschinentest-Dftgedgs" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der Dftgedgs-Waschmaschinentest" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der Waschmaschinentestdftgedgs" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der Waschmaschinentestversuch orkt" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der Arbeitsnehmer" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Die Verhaltenänderung" ) ) . length ) ; assertEquals ( 2 , rule . match ( langTool . getAnalyzedSentence ( "Der asdegfue orkt" ) ) . length ) ; } @ Test public void testGetSuggestions ( ) throws Exception { final HunspellRule rule = new GermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_DE ) ; assertCorrection ( rule , "Hauk" , "Haus" , "Haut" ) ; assertCorrection ( rule , "Eisnbahn" , "Einbahn" , "Eisbahn" , "Eisenbahn" ) ; assertCorrection ( rule , "Rechtschreipreform" , "Rechtschreibreform" ) ; assertCorrection ( rule , "Theatrekasse" , "Theaterkasse" ) ; assertCorrection ( rule , "Traprennen" , "Trabrennen" ) ; assertCorrection ( rule , "Autuverkehr" , "Autoverkehr" ) ; assertCorrection ( rule , "Rechtschreibprüfun" , "Rechtschreibprüfung" ) ; assertCorrection ( rule , "Rechtschreib-Prüfun" , "Rechtschreib-Prüfung" ) ; assertCorrection ( rule , "Autoverkehrr" , "Autoverkehr" ) ; assertCorrection ( rule , "hasslich" , "hässlich" , "fasslich" ) ; assertCorrection ( rule , "Struße" , "Strauße" , "Straße" , "Sträuße" ) ; assertCorrection ( rule , "gewohnlich" , "gewöhnlich" ) ; assertCorrection ( rule , "gawöhnlich" , "gewöhnlich" ) ; assertCorrection ( rule , "gwöhnlich" , "gewöhnlich" ) ; assertCorrection ( rule , "geewöhnlich" , "gewöhnlich" ) ; assertCorrection ( rule , "gewönlich" , "gewöhnlich" ) ; assertCorrection ( rule , "außergewöhnkich" , "außergewöhnlich" ) ; assertCorrection ( rule , "agressiv" , "aggressiv" ) ; assertCorrection ( rule , "agressivster" , "aggressivster" ) ; assertCorrection ( rule , "agressiver" , "aggressiver" ) ; assertCorrection ( rule , "agressive" , "aggressive" ) ; assertCorrection ( rule , "Algorythmus" , "Algorithmus" ) ; assertCorrection ( rule , "Algorhythmus" , "Algorithmus" ) ; assertCorrection ( rule , "Amalgan" , "Amalgam" ) ; assertCorrection ( rule , "Amaturenbrett" , "Armaturenbrett" ) ; assertCorrection ( rule , "Aquise" , "Akquise" ) ; assertCorrection ( rule , "Artzt" , "Arzt" ) ; assertCorrection ( rule , "aufgrunddessen" , "aufgrund dessen" ) ; assertCorrection ( rule , "barfuss" , "barfuß" ) ; assertCorrection ( rule , "Batallion" , "Bataillon" ) ; assertCorrection ( rule , "aul" , "auf" ) ; assertCorrection ( rule , "Icj" , "Ich" ) ; assertCorrection ( rule , "Handelsvertretertrffen" , "Handelsvertretertreffen" ) ; assertCorrection ( rule , "Handelsvartretertreffen" , "Handelsvertretertreffen" ) ; assertCorrection ( rule , "Handelsvertretertriffen" , "Handelsvertretertreffen" ) ; } @ Test public void testGetSuggestionOrder ( ) throws Exception { final HunspellRule rule = new GermanSpellerRule ( TestTools . getMessages ( "de" ) , GERMAN_DE ) ; assertCorrectionsByOrder ( rule , "heisst" , "heißt" ) ; assertCorrectionsByOrder ( rule , "heissen" , "heißen" ) ; assertCorrectionsByOrder ( rule , "müßte" , "müsste" ) ; assertCorrectionsByOrder ( rule , "schmohren" , "schmoren" ) ; assertCorrectionsByOrder ( rule , "Fänomen" , "Phänomen" ) ; assertCorrectionsByOrder ( rule , "homofob" , "homophob" ) ; assertCorrectionsByOrder ( rule , "ueber" , "über" ) ; assertCorrectionsByOrder ( rule , "uebel" , "übel" ) ; assertCorrectionsByOrder ( rule , "Aerger" , "Ärger" ) ; assertCorrectionsByOrder ( rule , "Walt" , "Wald" ) ; assertCorrectionsByOrder ( rule , "Rythmus" , "Rhythmus" ) ; assertCorrectionsByOrder ( rule , "Rytmus" , "Rhythmus" ) ; assertCorrectionsByOrder ( rule , "is" , "iss" , "in" , "im" , "ist" ) ; } @ Test @ Ignore ( "testing a potential bug in Morfologik" ) public void testMorfologikSpeller ( ) throws Exception { List < byte [ ] > lines = new ArrayList < > ( ) ; lines . add ( "die" . getBytes ( ) ) ; lines . add ( "ist" . getBytes ( ) ) ; byte [ ] info = "fsa.dict.separator=+\nfsa.dict.encoding=utf-8\nfsa.dict.frequency-included=true" . getBytes ( ) ; Dictionary dict = getDictionary ( lines , new ByteArrayInputStream ( info ) ) ; Speller speller = new Speller ( dict , 2 ) ; System . out . println ( speller . findReplacements ( "is" ) ) ; } private Dictionary getDictionary ( List < byte [ ] > lines , InputStream infoFile ) throws IOException { Collections . sort ( lines , FSABuilder . LEXICAL_ORDERING ) ; FSA fsa = FSABuilder . build ( lines ) ; ByteArrayOutputStream fsaOutStream = new CFSA2Serializer ( ) . serialize ( fsa , new ByteArrayOutputStream ( ) ) ; ByteArrayInputStream fsaInStream = new ByteArrayInputStream ( fsaOutStream . toByteArray ( ) ) ; return Dictionary . readAndClose ( fsaInStream , infoFile ) ; } private void assertCorrection ( HunspellRule rule , String input , String ... expectedTerms ) throws IOException { final List < String > suggestions = rule . getSuggestions ( input ) ; for ( String expectedTerm : expectedTerms ) { assertTrue ( "Not found: '" + expectedTerm + "' in: " + suggestions , suggestions . contains ( expectedTerm ) ) ; } } private void assertCorrectionsByOrder ( HunspellRule rule , String input , String ... expectedTerms ) throws IOException { final List < String > suggestions = rule . getSuggestions ( input ) ; int i = 0 ; for ( String expectedTerm : expectedTerms ) { assertTrue ( "Not found at position " + i + ": '" + expectedTerm + "' in: " + suggestions , suggestions . get ( i ) . equals ( expectedTerm ) ) ; i ++ ; } } }
package org . languagetool . rules . de ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class GermanPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . de ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import org . languagetool . rules . WordRepeatRule ; import java . io . IOException ; public class WordRepeatRuleTest extends TestCase { private final German german = new German ( ) ; private final WordRepeatRule rule = new GermanWordRepeatRule ( TestTools . getEnglishMessages ( ) , german ) ; public void testRuleGerman ( ) throws IOException { JLanguageTool lt = new JLanguageTool ( german ) ; assertGood ( "Das sind die Sätze, die die testen sollen." , lt ) ; assertGood ( "Sätze, die die testen." , lt ) ; assertGood ( "Das Haus, auf das das Mädchen zeigt." , lt ) ; assertGood ( "Warum fragen Sie sie nicht selbst?" , lt ) ; assertBad ( "Die die Sätze zum testen." , lt ) ; assertBad ( "Und die die Sätze zum testen." , lt ) ; assertBad ( "Auf der der Fensterbank steht eine Blume." , lt ) ; assertBad ( "Das Buch, in in dem es steht." , lt ) ; assertBad ( "Das Haus, auf auf das Mädchen zurennen." , lt ) ; assertBad ( "Sie sie gehen nach Hause." , lt ) ; } private void assertGood ( String text , JLanguageTool langTool ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( text ) ) . length ) ; } private void assertBad ( String text , JLanguageTool langTool ) throws IOException { assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( text ) ) . length ) ; } }
package org . languagetool . rules . de ; import org . junit . Test ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tagging . de . GermanToken ; import static junit . framework . TestCase . assertFalse ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class GermanHelperTest { @ Test public void testHasReadingOfType ( ) throws Exception { AnalyzedTokenReadings readings = new AnalyzedTokenReadings ( new AnalyzedToken ( "der" , "ART:DEF:DAT:SIN:FEM" , null ) , 0 ) ; assertTrue ( GermanHelper . hasReadingOfType ( readings , GermanToken . POSType . DETERMINER ) ) ; assertFalse ( GermanHelper . hasReadingOfType ( readings , GermanToken . POSType . NOMEN ) ) ; } @ Test public void testGetDeterminerNumber ( ) throws Exception { assertThat ( GermanHelper . getDeterminerNumber ( "ART:DEF:DAT:SIN:FEM" ) , is ( "SIN" ) ) ; } @ Test public void testGetDeterminerDefiniteness ( ) throws Exception { assertThat ( GermanHelper . getDeterminerDefiniteness ( "ART:DEF:DAT:SIN:FEM" ) , is ( "DEF" ) ) ; } @ Test public void testGetDeterminerCase ( ) throws Exception { assertThat ( GermanHelper . getDeterminerCase ( "ART:DEF:DAT:SIN:FEM" ) , is ( "DAT" ) ) ; } @ Test public void testGetDeterminerGender ( ) throws Exception { assertThat ( GermanHelper . getDeterminerGender ( null ) , is ( "" ) ) ; assertThat ( GermanHelper . getDeterminerGender ( "" ) , is ( "" ) ) ; assertThat ( GermanHelper . getDeterminerGender ( "ART:DEF:DAT:SIN:FEM" ) , is ( "FEM" ) ) ; } }
package org . languagetool . rules . de ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . assertThat ; public class VerbAgreementRuleTest extends TestCase { private VerbAgreementRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new VerbAgreementRule ( TestTools . getMessages ( "de" ) , new German ( ) ) ; langTool = new JLanguageTool ( new German ( ) ) ; } public void testWrongVerb ( ) throws IOException { assertGood ( "Wobei er äußerst selten darüber spricht." ) ; assertGood ( "Wobei er äußerst selten über seine erste Frau spricht." ) ; assertGood ( "Das Wort „schreibst“ ist schön." ) ; assertGood ( "Die Jagd nach bin Laden." ) ; assertGood ( "Die Unterlagen solltet ihr gründlich durcharbeiten." ) ; assertGood ( "Er reagierte äußerst negativ." ) ; assertGood ( "Max und ich sollten das machen." ) ; assertGood ( "Osama bin Laden stammt aus Saudi-Arabien." ) ; assertGood ( "Solltet ihr das machen?" ) ; assertGood ( "Ein Geschenk, das er einst von Aphrodite erhalten hatte." ) ; assertGood ( "Wenn ich sterben sollte, wer würde sich dann um die Katze kümmern?" ) ; assertGood ( "Wenn er sterben sollte, wer würde sich dann um die Katze kümmern?" ) ; assertGood ( "Wenn sie sterben sollte, wer würde sich dann um die Katze kümmern?" ) ; assertGood ( "Wenn es sterben sollte, wer würde sich dann um die Katze kümmern?" ) ; assertGood ( "Wenn ihr sterben solltet, wer würde sich dann um die Katze kümmern?" ) ; assertGood ( "Wenn wir sterben sollten, wer würde sich dann um die Katze kümmern?" ) ; assertGood ( "Dafür erhielten er sowie der Hofgoldschmied Theodor Heiden einen Preis." ) ; assertGood ( "/usr/bin/firefox" ) ; assertBad ( "Als Borcarbid weißt es eine hohe Härte auf." ) ; assertBad ( "Das greift auf Vorläuferinstitutionen bist auf die Zeit von 1234 zurück." ) ; assertBad ( "Die Eisenbahn dienst überwiegend dem Güterverkehr." ) ; assertBad ( "Die Unterlagen solltest ihr gründlich durcharbeiten." ) ; assertBad ( "Peter bin nett." ) ; assertBad ( "Solltest ihr das machen?" , "Subjekt und Prädikat (Solltest)" ) ; assertBad ( "Weiter befindest sich im Osten die Gemeinde Dorf." ) ; } public void testWrongVerbSubject ( ) throws IOException { assertGood ( "Auch morgen lebe ich." ) ; assertGood ( "Auch morgen leben wir noch." ) ; assertGood ( "Auch morgen lebst du." ) ; assertGood ( "Auch morgen lebt er." ) ; assertGood ( "Auch wenn du leben möchtest." ) ; assertGood ( "auf der er sieben Jahre blieb." ) ; assertGood ( "Das absolute Ich ist nicht mit dem individuellen Geist zu verwechseln." ) ; assertGood ( "Das Ich ist keine Einbildung" ) ; assertGood ( "Das lyrische Ich ist verzweifelt." ) ; assertGood ( "Den Park, von dem er äußerst genaue Karten zeichnete." ) ; assertGood ( "Der auffälligste Ring ist der erster Ring, obwohl er verglichen mit den anderen Ringen sehr schwach erscheint." ) ; assertGood ( "Der Fehler, falls er bestehen sollte, ist schwerwiegend." ) ; assertGood ( "Der Vorfall, bei dem er einen Teil seines Vermögens verloren hat, ist lange vorbei." ) ; assertGood ( "Diese Lösung wurde in der 64'er beschrieben, kam jedoch nie." ) ; assertGood ( "Die Theorie, mit der ich arbeiten konnte." ) ; assertGood ( "Du bist nett." ) ; assertGood ( "Du kannst heute leider nicht kommen." ) ; assertGood ( "Du lebst." ) ; assertGood ( "Du wünschst dir so viel." ) ; assertGood ( "Er geht zu ihr." ) ; assertGood ( "Er ist nett." ) ; assertGood ( "Er kann heute leider nicht kommen." ) ; assertGood ( "Er lebt." ) ; assertGood ( "Er wisse nicht, ob er lachen oder weinen solle." ) ; assertGood ( "Er und du leben." ) ; assertGood ( "Er und ich leben." ) ; assertGood ( "Falls er bestehen sollte, gehen sie weg." ) ; assertGood ( "Heere, des Gottes der Schlachtreihen Israels, den du verhöhnt hast." ) ; assertGood ( "Ich bin" ) ; assertGood ( "Ich bin Frankreich!" ) ; assertGood ( "Ich bin froh, dass ich arbeiten kann." ) ; assertGood ( "Ich bin nett." ) ; assertGood ( "‚ich bin tot‘" ) ; assertGood ( "Ich kann heute leider nicht kommen." ) ; assertGood ( "Ich lebe." ) ; assertGood ( "Lebst du?" ) ; assertGood ( "Morgen kommen du und ich." ) ; assertGood ( "Morgen kommen er, den ich sehr mag, und ich." ) ; assertGood ( "Morgen kommen er und ich." ) ; assertGood ( "Morgen kommen ich und sie." ) ; assertGood ( "Morgen kommen wir und sie." ) ; assertGood ( "nachdem er erfahren hatte" ) ; assertGood ( "Nett bin ich." ) ; assertGood ( "Nett bist du." ) ; assertGood ( "Nett ist er." ) ; assertGood ( "Nett sind wir." ) ; assertGood ( "Niemand ahnte, dass er gewinnen könne." ) ; assertGood ( "Sie lebt und wir leben." ) ; assertGood ( "Sie und er leben." ) ; assertGood ( "Sind ich und Peter nicht nette Kinder?" ) ; assertGood ( "Sodass ich sagen möchte, dass unsere schönen Erinnerungen gut sind." ) ; assertGood ( "Wann ich meinen letzten Film drehen werde, ist unbekannt." ) ; assertGood ( "Was ich tun muss." ) ; assertGood ( "Welche Aufgaben er dabei tatsächlich übernehmen könnte" ) ; assertGood ( "wie er beschaffen war" ) ; assertGood ( "Wir gelangen zu dir." ) ; assertGood ( "Wir können heute leider nicht kommen." ) ; assertGood ( "Wir leben noch." ) ; assertGood ( "Wir sind nett." ) ; assertGood ( "Wobei wir benutzt haben, dass der Satz gilt." ) ; assertGood ( "Wünschst du dir mehr Zeit?" ) ; assertGood ( "Wyrjtjbst du?" ) ; assertGood ( "Wenn ich du wäre, würde ich das nicht machen." ) ; assertBad ( "Auch morgen leben du." ) ; assertBad ( "Auch morgen leben du" ) ; assertBad ( "Auch morgen leben er." ) ; assertBad ( "Auch morgen leben ich." ) ; assertBad ( "Auch morgen lebte wir noch." ) ; assertBad ( "Du bin nett." , 2 ) ; assertBad ( "Du können heute leider nicht kommen." ) ; assertBad ( "Du können heute leider nicht kommen." , "Du kannst" , "Du konntest" , "Du könnest" , "Du könntest" , "Wir können" , "Sie können" ) ; assertBad ( "Du leben." ) ; assertBad ( "Du wünscht dir so viel." ) ; assertBad ( "Er bin nett." , 2 ) ; assertBad ( "Er gelangst zu ihr." , 2 ) ; assertBad ( "Er können heute leider nicht kommen." , "Subjekt (Er) und Prädikat (können)" ) ; assertBad ( "Er lebst." , 2 ) ; assertBad ( "Ich bist nett." , 2 ) ; assertBad ( "Ich kannst heute leider nicht kommen." , 2 ) ; assertBad ( "Ich leben." ) ; assertBad ( "Ich leben." , "Ich lebe" , "Ich lebte" , "Wir leben" , "Sie leben" ) ; assertBad ( "Lebe du?" ) ; assertBad ( "Lebe du?" , "Lebest du" , "Lebst du" , "Lebtest du" , "Lebe ich" , "Lebe er" , "Lebe sie" , "Lebe es" ) ; assertBad ( "Nett bist ich nicht." , 2 ) ; assertBad ( "Nett bist ich nicht." , 2 , "bin ich" , "sei ich" , "war ich" , "wäre ich" , "bist du" ) ; assertBad ( "Nett sind du." ) ; assertBad ( "Nett sind er." ) ; assertBad ( "Nett sind er." , "ist er" , "sei er" , "war er" , "wäre er" , "sind wir" , "sind sie" ) ; assertBad ( "Nett warst wir." , 2 ) ; assertBad ( "Wir bin nett." , 2 ) ; assertBad ( "Wir gelangst zu ihr." , 2 ) ; assertBad ( "Wir könnt heute leider nicht kommen." ) ; assertBad ( "Wünscht du dir mehr Zeit?" , "Subjekt (du) und Prädikat (Wünscht)" ) ; assertBad ( "Wir lebst noch." , 2 ) ; assertBad ( "Wir lebst noch." , 2 , "Wir leben" , "Wir lebten" , "Du lebst" ) ; } private void assertGood ( String s ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( s ) ) . length ) ; } private void assertBad ( String s , int n ) throws IOException { assertEquals ( n , rule . match ( langTool . getAnalyzedSentence ( s ) ) . length ) ; } private void assertBad ( String s ) throws IOException { assertBad ( s , 1 ) ; } private void assertBad ( String s , String expectedErrorSubstring ) throws IOException { assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( s ) ) . length ) ; final String errorMessage = rule . match ( langTool . getAnalyzedSentence ( s ) ) [ 0 ] . getMessage ( ) ; assertTrue ( "Got error '" + errorMessage + "', expected substring '" + expectedErrorSubstring + "'" , errorMessage . contains ( expectedErrorSubstring ) ) ; } private void assertBad ( String s , int n , String ... expectedSuggestions ) throws IOException { RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( s ) ) ; assertEquals ( "Did not find " + n + " match(es) in sentence '" + s + "'" , n , matches . length ) ; if ( expectedSuggestions . length > 0 ) { RuleMatch match = matches [ 0 ] ; if ( matches . length > 1 && match . getSuggestedReplacements ( ) . size ( ) == 0 ) { match = matches [ 1 ] ; } List < String > suggestions = match . getSuggestedReplacements ( ) ; assertThat ( suggestions , is ( Arrays . asList ( expectedSuggestions ) ) ) ; } } private void assertBad ( String s , String ... expectedSuggestions ) throws IOException { assertBad ( s , 1 , expectedSuggestions ) ; } }
package org . languagetool . rules . de ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import java . io . IOException ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; public class SentenceWhitespaceRuleTest { @ Test public void testMatch ( ) throws Exception { SentenceWhitespaceRule rule = new SentenceWhitespaceRule ( TestTools . getEnglishMessages ( ) ) ; JLanguageTool languageTool = new JLanguageTool ( new German ( ) ) ; languageTool . addRule ( rule ) ; assertGood ( "Das ist ein Satz. Und hier der nächste." , rule , languageTool ) ; assertGood ( "Das ist ein Satz! Und hier der nächste." , rule , languageTool ) ; assertGood ( "Ist das ein Satz? Hier der nächste." , rule , languageTool ) ; assertBad ( "Das ist ein Satz.Und hier der nächste." , rule , languageTool ) ; assertBad ( "Das ist ein Satz!Und hier der nächste." , rule , languageTool ) ; assertBad ( "Ist das ein Satz?Hier der nächste." , rule , languageTool ) ; assertGood ( "Am 28. September." , rule , languageTool ) ; assertBad ( "Am 28.September." , rule , languageTool ) ; assertTrue ( languageTool . check ( "Am 7.September 2014." ) . get ( 0 ) . getMessage ( ) . contains ( "nach Ordnungszahlen" ) ) ; assertTrue ( languageTool . check ( "Im September.Dann der nächste Satz." ) . get ( 0 ) . getMessage ( ) . contains ( "zwischen Sätzen" ) ) ; } private void assertGood ( String text , SentenceWhitespaceRule rule , JLanguageTool languageTool ) throws IOException { assertThat ( languageTool . check ( text ) . size ( ) , is ( 0 ) ) ; rule . reset ( ) ; } private void assertBad ( String text , SentenceWhitespaceRule rule , JLanguageTool languageTool ) throws IOException { assertThat ( languageTool . check ( text ) . size ( ) , is ( 1 ) ) ; rule . reset ( ) ; } }
package org . languagetool . rules . de ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import java . io . IOException ; public class WiederVsWiderRuleTest extends TestCase { private final WiederVsWiderRule rule = new WiederVsWiderRule ( TestTools . getMessages ( "de" ) ) ; public void testRule ( ) throws IOException { JLanguageTool lt = new JLanguageTool ( new German ( ) ) ; assertGood ( "Das spiegelt wider, wie es wieder läuft." , lt ) ; assertGood ( "Das spiegelt die Situation gut wider." , lt ) ; assertGood ( "Das spiegelt die Situation." , lt ) ; assertGood ( "Immer wieder spiegelt das die Situation." , lt ) ; assertGood ( "Immer wieder spiegelt das die Situation wider." , lt ) ; assertGood ( "Das spiegelt wieder wider, wie es läuft." , lt ) ; assertBad ( "Das spiegelt wieder, wie es wieder läuft." , lt ) ; assertBad ( "Sie spiegeln das Wachstum der Stadt wieder." , lt ) ; assertBad ( "Das spiegelt die Situation gut wieder." , lt ) ; assertBad ( "Immer wieder spiegelt das die Situation wieder." , lt ) ; assertBad ( "Immer wieder spiegelte das die Situation wieder." , lt ) ; } private void assertGood ( String text , JLanguageTool langTool ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( text ) ) . length ) ; } private void assertBad ( String text , JLanguageTool langTool ) throws IOException { assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( text ) ) . length ) ; } }
package org . languagetool . tagging . ca ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import morfologik . stemming . DictionaryLookup ; import morfologik . stemming . IStemmer ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . chunking . ChunkTag ; import org . languagetool . tagging . BaseTagger ; import org . languagetool . tools . StringTools ; public class CatalanTagger extends BaseTagger { private static final Pattern ADJ_PART_FS = Pattern . compile ( "VMP00SF.|A[QO].[FC][SN]." ) ; private static final Pattern VERB = Pattern . compile ( "V.+" ) ; private static final Pattern PREFIXES_FOR_VERBS = Pattern . compile ( "(auto)(.*[aeiouàéèíòóïü].+[aeiouàéèíòóïü].*)" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; @ Override public String getManualAdditionsFileName ( ) { return "/ca/manual-tagger.txt" ; } public CatalanTagger ( ) { super ( "/ca/catalan.dict" , new Locale ( "ca" ) , false ) ; } @ Override public boolean overwriteWithManualTagger ( ) { return true ; } @ Override public List < AnalyzedTokenReadings > tag ( final List < String > sentenceTokens ) throws IOException { final List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; int pos = 0 ; final IStemmer dictLookup = new DictionaryLookup ( getDictionary ( ) ) ; for ( String word : sentenceTokens ) { boolean containsTypewriterApostrophe = false ; if ( word . length ( ) > 1 ) { if ( word . contains ( "'" ) ) { containsTypewriterApostrophe = true ; } word = word . replace ( "’" , "'" ) ; } final List < AnalyzedToken > l = new ArrayList < > ( ) ; final String lowerWord = word . toLowerCase ( conversionLocale ) ; final boolean isLowercase = word . equals ( lowerWord ) ; final boolean isMixedCase = StringTools . isMixedCase ( word ) ; List < AnalyzedToken > taggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( word ) ) ; addTokens ( taggerTokens , l ) ; if ( ! isLowercase && ! isMixedCase ) { List < AnalyzedToken > lowerTaggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( lowerWord ) ) ; addTokens ( lowerTaggerTokens , l ) ; } if ( l . isEmpty ( ) && ! isMixedCase ) { addTokens ( additionalTags ( word , dictLookup ) , l ) ; } if ( l . isEmpty ( ) ) { l . add ( new AnalyzedToken ( word , null , null ) ) ; } AnalyzedTokenReadings atr = new AnalyzedTokenReadings ( l , pos ) ; if ( containsTypewriterApostrophe ) { List < ChunkTag > listChunkTags = new ArrayList < > ( ) ; listChunkTags . add ( new ChunkTag ( "containsTypewriterApostrophe" ) ) ; atr . setChunkTags ( listChunkTags ) ; } tokenReadings . add ( atr ) ; pos += word . length ( ) ; } return tokenReadings ; } @ Nullable protected List < AnalyzedToken > additionalTags ( String word , IStemmer stemmer ) { final IStemmer dictLookup = new DictionaryLookup ( getDictionary ( ) ) ; List < AnalyzedToken > additionalTaggedTokens = new ArrayList < > ( ) ; if ( word . endsWith ( "ment" ) ) { final String lowerWord = word . toLowerCase ( conversionLocale ) ; final String possibleAdj = lowerWord . replaceAll ( "^(.+)ment$" , "$1" ) ; List < AnalyzedToken > taggerTokens ; taggerTokens = asAnalyzedTokenList ( possibleAdj , dictLookup . lookup ( possibleAdj ) ) ; for ( AnalyzedToken taggerToken : taggerTokens ) { final String posTag = taggerToken . getPOSTag ( ) ; if ( posTag != null ) { final Matcher m = ADJ_PART_FS . matcher ( posTag ) ; if ( m . matches ( ) ) { additionalTaggedTokens . add ( new AnalyzedToken ( word , "RG" , lowerWord ) ) ; return additionalTaggedTokens ; } } } } Matcher matcher = PREFIXES_FOR_VERBS . matcher ( word ) ; if ( matcher . matches ( ) ) { final String possibleVerb = matcher . group ( 2 ) . toLowerCase ( ) ; List < AnalyzedToken > taggerTokens ; taggerTokens = asAnalyzedTokenList ( possibleVerb , dictLookup . lookup ( possibleVerb ) ) ; for ( AnalyzedToken taggerToken : taggerTokens ) { final String posTag = taggerToken . getPOSTag ( ) ; if ( posTag != null ) { final Matcher m = VERB . matcher ( posTag ) ; if ( m . matches ( ) ) { String lemma = matcher . group ( 1 ) . toLowerCase ( ) . concat ( taggerToken . getLemma ( ) ) ; additionalTaggedTokens . add ( new AnalyzedToken ( word , posTag , lemma ) ) ; } } } return additionalTaggedTokens ; } if ( word . contains ( "\u0140" ) || word . contains ( "\u013f" ) ) { final String lowerWord = word . toLowerCase ( conversionLocale ) ; final String possibleWord = lowerWord . replaceAll ( "\u0140" , "l·" ) ; List < AnalyzedToken > taggerTokens = asAnalyzedTokenList ( word , dictLookup . lookup ( possibleWord ) ) ; return taggerTokens ; } return null ; } private void addTokens ( final List < AnalyzedToken > taggedTokens , final List < AnalyzedToken > l ) { if ( taggedTokens != null ) { for ( AnalyzedToken at : taggedTokens ) { l . add ( at ) ; } } } }
package org . languagetool . rules . de ; import org . junit . Test ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . language . German ; import java . util . ArrayList ; import java . util . List ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . assertThat ; public class AgreementSuggestorTest { @ Test public void testSuggestions ( ) throws Exception { assertSuggestion ( "das/der/ART:DEF:NOM:SIN:NEU Haus/Haus/SUB:NOM:SIN:NEU" , "[das Haus]" ) ; assertSuggestion ( "der/der/ART:DEF:NOM:SIN:MAS Haus/Haus/SUB:NOM:SIN:NEU" , "[das Haus]" ) ; assertSuggestion ( "die/der/ART:DEF:NOM:PLU:FEM Haus/Haus/SUB:NOM:SIN:NEU" , "[das Haus]" ) ; assertSuggestion ( "das/der/ART:DEF:NOM:PLU:FEM Häuser/Haus/SUB:NOM:PLU:NEU" , "[die Häuser]" ) ; assertSuggestion ( "das/der/ART:DEF:NOM:PLU:FEM Häusern/Haus/SUB:DAT:PLU:NEU" , "[den Häusern]" ) ; } private void assertSuggestion ( String input , String expectedSuggestions ) { String [ ] tokens = input . split ( " " ) ; List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; int pos = 0 ; for ( String inputToken : tokens ) { String [ ] parts = inputToken . split ( "/" ) ; String token = parts [ 0 ] ; String lemma = parts [ 1 ] ; String posTag = parts [ 2 ] ; tokenReadings . add ( new AnalyzedTokenReadings ( new AnalyzedToken ( token , posTag , lemma ) , pos ++ ) ) ; } if ( tokenReadings . size ( ) != 2 ) { throw new RuntimeException ( "Size of input not yet supported: " + tokenReadings . size ( ) ) ; } AgreementSuggestor suggestor = new AgreementSuggestor ( new German ( ) . getSynthesizer ( ) , tokenReadings . get ( 0 ) , tokenReadings . get ( 1 ) ) ; List < String > suggestions = suggestor . getSuggestions ( ) ; assertThat ( suggestions . toString ( ) , is ( expectedSuggestions ) ) ; } }
package org . languagetool . rules . de ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import org . languagetool . rules . RuleMatch ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . assertThat ; public class AgreementRuleTest extends TestCase { private AgreementRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new AgreementRule ( TestTools . getMessages ( "de" ) , new German ( ) ) ; langTool = new JLanguageTool ( new German ( ) ) ; } public void testDetNounRule ( ) throws IOException { assertGood ( "So ist es in den USA." ) ; assertGood ( "Das ist der Tisch." ) ; assertGood ( "Das ist das Haus." ) ; assertGood ( "Das ist die Frau." ) ; assertGood ( "Das ist das Auto der Frau." ) ; assertGood ( "Das gehört dem Mann." ) ; assertGood ( "Das Auto des Mannes." ) ; assertGood ( "Das interessiert den Mann." ) ; assertGood ( "Das interessiert die Männer." ) ; assertGood ( "Das Auto von einem Mann." ) ; assertGood ( "Das Auto eines Mannes." ) ; assertGood ( "Des großen Mannes." ) ; assertGood ( "Und nach der Nummerierung kommt die Überschrift." ) ; assertGood ( "Sie wiesen dieselben Verzierungen auf." ) ; assertGood ( "Die erwähnte Konferenz ist am Samstag." ) ; assertGood ( "Sie erreichten 5 Prozent." ) ; assertGood ( "Sie erreichten mehrere Prozent Zustimmung." ) ; assertGood ( "Die Bestandteile, aus denen Schwefel besteht." ) ; assertGood ( "Das Dach von meinem Auto." ) ; assertGood ( "Das Dach von meinen Autos." ) ; assertGood ( "Das Dach meines Autos." ) ; assertGood ( "Das Dach meiner Autos." ) ; assertGood ( "Das Dach meines großen Autos." ) ; assertGood ( "Das Dach meiner großen Autos." ) ; assertGood ( "Dann schlug er so kräftig wie er konnte mit den Schwingen." ) ; assertGood ( "Also wenn wir Glück haben, ..." ) ; assertGood ( "Wenn wir Pech haben, ..." ) ; assertGood ( "Ledorn öffnete eines der an ihr vorhandenen Fächer." ) ; assertGood ( "Auf der einen Seite endlose Dünen" ) ; assertGood ( "In seinem Maul hielt er einen blutigen Fleischklumpen." ) ; assertGood ( "Gleichzeitig dachte er intensiv an Nebelschwaden, aus denen Wolken ja bestanden." ) ; assertGood ( "Warum stellte der bloß immer wieder dieselben Fragen?" ) ; assertGood ( "Bei der Hinreise." ) ; assertGood ( "Schließlich tauchten in einem Waldstück unter ihnen Schienen auf." ) ; assertGood ( "Das Wahlrecht, das Frauen damals zugesprochen bekamen." ) ; assertGood ( "Es war Karl, dessen Leiche Donnerstag gefunden wurde." ) ; assertGood ( "Erst recht ich Arbeiter." ) ; assertGood ( "Erst recht wir Arbeiter." ) ; assertGood ( "Erst recht wir fleißigen Arbeiter." ) ; assertGood ( "Dann lud er Freunde ein." ) ; assertGood ( "Dann lud sie Freunde ein." ) ; assertGood ( "Aller Kommunikation liegt dies zugrunde." ) ; assertGood ( "Pragmatisch wählt man solche Formeln als Axiome." ) ; assertGood ( "Der eine Polizist rief dem anderen zu..." ) ; assertGood ( "Das eine Kind rief dem anderen zu..." ) ; assertGood ( "Er wollte seine Interessen wahrnehmen." ) ; assertGood ( "... wo Krieg den Unschuldigen Leid und Tod bringt." ) ; assertGood ( "Der Abschuss eines Papageien." ) ; assertGood ( "Die Beibehaltung des Art. 1 ist geplant." ) ; assertGood ( "Die Verschiebung des bisherigen Art. 1 ist geplant." ) ; assertGood ( "Das Recht, das Frauen eingeräumt wird." ) ; assertGood ( "Der Mann, in dem quadratische Fische schwammen." ) ; assertGood ( "Der Mann, durch den quadratische Fische schwammen." ) ; assertGood ( "Gutenberg, der quadratische Mann." ) ; assertGood ( "Die größte Stuttgarter Grünanlage ist der Friedhof." ) ; assertGood ( "Die meisten Lebensmittel enthalten das." ) ; assertGood ( "Das Münchener Fest." ) ; assertGood ( "Das Münchner Fest." ) ; assertGood ( "Die Planung des Münchener Festes." ) ; assertGood ( "Das Berliner Wetter." ) ; assertGood ( "Den Berliner Arbeitern ist das egal." ) ; assertGood ( "Das Haus des Berliner Arbeiters." ) ; assertGood ( "Es gehört dem Berliner Arbeiter." ) ; assertGood ( "Das Stuttgarter Auto." ) ; assertGood ( "Das Bielefelder Radio." ) ; assertGood ( "Das Gütersloher Radio." ) ; assertGood ( "Das wirklich Wichtige kommt jetzt erst." ) ; assertGood ( "Besonders wenn wir Wermut oder Absinth trinken." ) ; assertGood ( "Ich wünsche dir alles Gute." ) ; assertGood ( "Es ist nicht bekannt, mit welchem Alter Kinder diese Fähigkeit erlernen." ) ; assertGood ( "Dieser ist nun in den Ortungsbereich des einen Roboters gefahren." ) ; assertGood ( "Wenn dies großen Erfolg hat, werden wir es weiter fördern." ) ; assertGood ( "Die Ereignisse dieses einen Jahres waren sehr schlimm." ) ; assertGood ( "Er musste einen Hochwasser führenden Fluss nach dem anderen überqueren." ) ; assertBad ( "Es sind die Tisch." , "dem Tisch" , "den Tisch" , "der Tisch" , "die Tische" ) ; assertBad ( "Es sind das Tisch." , "dem Tisch" , "den Tisch" , "der Tisch" ) ; assertBad ( "Es sind die Haus." , "das Haus" , "dem Haus" , "die Häuser" ) ; assertBad ( "Es sind der Haus." , "das Haus" , "dem Haus" , "der Häuser" ) ; assertBad ( "Es sind das Frau." , "der Frau" , "die Frau" ) ; assertBad ( "Das Auto des Mann." , "dem Mann" , "den Mann" , "der Mann" , "des Mannes" , "des Manns" ) ; assertBad ( "Das interessiert das Mann." , "dem Mann" , "den Mann" , "der Mann" ) ; assertBad ( "Das interessiert die Mann." , "dem Mann" , "den Mann" , "der Mann" , "die Männer" ) ; assertBad ( "Das Auto ein Mannes." , "ein Mann" , "eines Mannes" ) ; assertBad ( "Das Auto einem Mannes." , "einem Mann" , "einem Manne" , "eines Mannes" ) ; assertBad ( "Das Auto einer Mannes." , "eines Mannes" ) ; assertBad ( "Das Auto einen Mannes." , "einen Mann" , "eines Mannes" ) ; assertBad ( "Die erwähnt Konferenz ist am Samstag." ) ; assertBad ( "Die erwähntes Konferenz ist am Samstag." ) ; assertBad ( "Die erwähnten Konferenz ist am Samstag." ) ; assertBad ( "Die erwähnter Konferenz ist am Samstag." ) ; assertBad ( "Des großer Mannes." ) ; assertBad ( "Das Dach von meine Auto." , "mein Auto" , "meine Autos" , "meinem Auto" ) ; assertBad ( "Das Dach von meinen Auto." , "mein Auto" , "meinem Auto" , "meinen Autos" ) ; assertBad ( "Das Dach mein Autos." , "mein Auto" , "meine Autos" , "meinen Autos" , "meiner Autos" , "meines Autos" ) ; assertBad ( "Das Dach meinem Autos." , "meine Autos" , "meinem Auto" , "meinen Autos" , "meiner Autos" , "meines Autos" ) ; assertBad ( "Das Dach meinem großen Autos." ) ; assertBad ( "Das Dach mein großen Autos." ) ; assertBad ( "Das Klientel der Partei." , "Der Klientel" , "Die Klientel" ) ; assertGood ( "Die Klientel der Partei." ) ; assertBad ( "Der Haus ist groß" , "Das Haus" , "Dem Haus" , "Der Häuser" ) ; assertBad ( "Aber der Haus ist groß" , "das Haus" , "dem Haus" , "der Häuser" ) ; assertBad ( "Ich habe einen Feder gefunden." , "eine Feder" , "einer Feder" ) ; assertGood ( "Wenn die Gott zugeschriebenen Eigenschaften stimmen, dann..." ) ; assertGood ( "Dieses Grünkern genannte Getreide ist aber nicht backbar." ) ; assertGood ( "Außerdem unterstützt mich Herr Müller beim abheften" ) ; assertGood ( "Außerdem unterstützt mich Frau Müller beim abheften" ) ; } public void testVieleWenige ( ) throws IOException { assertGood ( "Zusammenschluss mehrerer dörflicher Siedlungen an einer Furt" ) ; assertGood ( "Für einige markante Szenen" ) ; assertGood ( "Für einige markante Szenen baute Hitchcock ein Schloss." ) ; assertGood ( "Haben Sie viele glückliche Erfahrungen in Ihrer Kindheit gemacht?" ) ; assertGood ( "Es gibt viele gute Sachen auf der Welt." ) ; assertGood ( "Viele englische Wörter haben lateinischen Ursprung" ) ; assertGood ( "Ein Bericht über Fruchtsaft, einige ähnliche Erzeugnisse und Fruchtnektar" ) ; assertGood ( "Der Typ, der seit einiger Zeit immer wieder hierher kommt." ) ; assertGood ( "Jede Schnittmenge abzählbar vieler offener Mengen" ) ; assertGood ( "Es kam zur Fusion der genannten und noch einiger weiterer Unternehmen." ) ; assertGood ( "Zu dieser Fragestellung gibt es viele unterschiedliche Meinungen." ) ; } public void testDetNounRuleErrorMessages ( ) throws IOException { assertBadWithMessage ( "Das Fahrrads." , "bezüglich Kasus" ) ; assertBadWithMessage ( "Der Fahrrad." , "bezüglich Genus" ) ; assertBadWithMessage ( "Das Fahrräder." , "bezüglich Numerus" ) ; assertBadWithMessage ( "Die Tischen sind ecking." , "bezüglich Kasus" ) ; assertBadWithMessage ( "Die Tischen sind ecking." , "und Genus" ) ; assertBadWithMessage ( "Bei dem Papierabzüge von Digitalbildern bestellt werden." , "bezüglich Kasus, Genus oder Numerus." ) ; } public void testRegression ( ) throws IOException { JLanguageTool lt = new JLanguageTool ( new German ( ) ) ; String str = "Und so.\r\nDie Bier." ; List < RuleMatch > matches = lt . check ( str ) ; assertEquals ( 1 , matches . size ( ) ) ; } public void testDetAdjNounRule ( ) throws IOException { assertGood ( "Das ist der riesige Tisch." ) ; assertGood ( "Der riesige Tisch ist groß." ) ; assertGood ( "Die Kanten der der riesigen Tische." ) ; assertGood ( "Den riesigen Tisch mag er." ) ; assertGood ( "Es mag den riesigen Tisch." ) ; assertGood ( "Die Kante des riesigen Tisches." ) ; assertGood ( "Dem riesigen Tisch fehlt was." ) ; assertGood ( "Die riesigen Tische sind groß." ) ; assertGood ( "Der riesigen Tische wegen." ) ; assertGood ( "An der roten Ampel." ) ; assertGood ( "Dann hat das natürlich Nachteile." ) ; assertBad ( "Es sind die riesigen Tisch." ) ; assertBad ( "Als die riesigen Tischs kamen." ) ; assertBad ( "Als die riesigen Tisches kamen." ) ; assertBad ( "Der riesigen Tisch und so." ) ; assertBad ( "An der roter Ampel." ) ; assertBad ( "An der rote Ampel." ) ; assertBad ( "An der rotes Ampel." ) ; assertBad ( "An der rotem Ampel." ) ; } private void assertGood ( String s ) throws IOException { RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( s ) ) ; assertEquals ( "Found unexpected match in sentence '" + s + "': " + Arrays . toString ( matches ) , 0 , matches . length ) ; } private void assertBad ( String s , String ... expectedSuggestions ) throws IOException { RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( s ) ) ; assertEquals ( "Did not find one match in sentence '" + s + "'" , 1 , matches . length ) ; if ( expectedSuggestions . length > 0 ) { RuleMatch match = matches [ 0 ] ; List < String > suggestions = match . getSuggestedReplacements ( ) ; assertThat ( suggestions , is ( Arrays . asList ( expectedSuggestions ) ) ) ; } } private void assertBadWithMessage ( String s , String expectedErrorSubstring ) throws IOException { assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( s ) ) . length ) ; final String errorMessage = rule . match ( langTool . getAnalyzedSentence ( s ) ) [ 0 ] . getMessage ( ) ; assertTrue ( "Got error '" + errorMessage + "', expected substring '" + expectedErrorSubstring + "'" , errorMessage . contains ( expectedErrorSubstring ) ) ; } }
package org . languagetool . rules . de ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . German ; import java . io . IOException ; public class GermanWrongWordInContextRuleTest extends TestCase { private JLanguageTool langTool ; private GermanWrongWordInContextRule rule ; @ Override public void setUp ( ) throws IOException { langTool = new JLanguageTool ( new German ( ) ) ; rule = new GermanWrongWordInContextRule ( null ) ; } public void testRule ( ) throws IOException { assertBad ( "Eine Laiche ist ein toter Körper." ) ; assertGood ( "Eine Leiche ist ein toter Körper." ) ; assertGood ( "Die Leichen der Verstorbenen wurden ins Wasser geworfen." ) ; assertGood ( "Ihre Lider sind entzündet." ) ; assertGood ( "Er hat entzündete Lider." ) ; assertGood ( "Wir singen gemeinsam Lieder." ) ; assertGood ( "Lieder singen wir." ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Lider singen wir." ) ) [ 0 ] . getFromPos ( ) ) ; assertEquals ( 11 , rule . match ( langTool . getAnalyzedSentence ( "Ihre Lieder sind entzündet." ) ) [ 0 ] . getToPos ( ) ) ; assertEquals ( "Lider" , rule . match ( langTool . getAnalyzedSentence ( "Er hat entzündete Lieder." ) ) [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "Lieder" , rule . match ( langTool . getAnalyzedSentence ( "Wir singen gemeinsam Lider." ) ) [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertGood ( "Ich soll Bilder einer Mühle malen." ) ; assertGood ( "Ich male ein Bild einer Mühle." ) ; assertGood ( "Das Bild zeigt eine mahlende Mühle." ) ; assertGood ( "Eine mahlende Mühle zeigt das Bild." ) ; assertGood ( "Wenn du mal etwas Mehl brauchst, kannst du zu mir kommen." ) ; assertBad ( "Weizen ausmalen." ) ; assertBad ( "Ich mahle das Bild aus." ) ; assertBad ( "Eine Mühle wird zum Malen verwendet." ) ; assertBad ( "Das gemalene Korn aus der Mühle ist gut." ) ; assertBad ( "Zum Malen verwendet man eine Mühle." ) ; assertBad ( "Du musst das Bild ausmahlen." ) ; assertBad ( "Wir haben das im Kunstunterricht gemahlt." ) ; assertBad ( "Er hat ein schönes Selbstporträt gemahlt." ) ; assertEquals ( "gemahlen" , rule . match ( langTool . getAnalyzedSentence ( "Das Korn wird in den Mühlen gemalen." ) ) [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "malten" , rule . match ( langTool . getAnalyzedSentence ( "Wir mahlten im Kunstunterricht." ) ) [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertGood ( "Er verzieht keine Miene." ) ; assertGood ( "Er verzieht keine Miene." ) ; assertGood ( "Die Explosion der Mine." ) ; assertGood ( "Die Mine ist explodiert." ) ; assertGood ( "Er versucht, keine Miene zu verziehen." ) ; assertGood ( "Sie sollen weiter Minen eingesetzt haben." ) ; assertGood ( "Er verzieht sich nach Bekanntgabe der Mineralölsteuerverordnung." ) ; assertBad ( "Er verzieht keine Mine." ) ; assertBad ( "Mit unbewegter Mine." ) ; assertBad ( "Er setzt eine kalte Mine auf." ) ; assertBad ( "Er sagt, die unterirdische Miene sei zusammengestürzt." ) ; assertBad ( "Die Miene ist eingestürzt." ) ; assertBad ( "Die Sprengung mit Mienen ist toll." ) ; assertBad ( "Der Bleistift hat eine Miene." ) ; assertBad ( "Die Mienen sind gestern Abend explodiert." ) ; assertBad ( "Die Miene des Kugelschreibers ist leer." ) ; assertEquals ( "Minen" , rule . match ( langTool . getAnalyzedSentence ( "Er hat das mit den Mienen weggesprengt." ) ) [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "Miene" , rule . match ( langTool . getAnalyzedSentence ( "Er versucht, keine Mine zu verziehen." ) ) [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertGood ( "Die Seiten des Buches sind beschrieben." ) ; assertGood ( "Dieses Buch über die Gitarre hat nur sechs Seiten." ) ; assertGood ( "Diese Gitarre hat sechs Saiten." ) ; assertGood ( "Die UNO muss andere Saiten aufziehen." ) ; assertGood ( "Eine Gitarre hat Saiten, aber keine Seiten." ) ; assertGood ( "Die Saiten des Violoncellos sind kurz." ) ; assertGood ( "Dieses Buch über die Gitarre hat nur sechs Seiten." ) ; assertGood ( "Eine Seite und eine scharfe Suppe." ) ; assertBad ( "Die Saiten des Buches sind beschrieben." ) ; assertBad ( "Die Seiten des Klaviers werden angeschlagen." ) ; assertBad ( "Die Seiten der Kurzhalsgeige sind gerissen." ) ; assertBad ( "Die Seiten des Kontrabasses sind gerissen." ) ; assertBad ( "Bei der UNO müssen andere Seiten aufgezogen werden." ) ; assertBad ( "Die Seiten des Violoncellos sind kurz." ) ; assertEquals ( "Saite" , rule . match ( langTool . getAnalyzedSentence ( "Die E-Gitarre hat eine sechste Seite." ) ) [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "Seiten" , rule . match ( langTool . getAnalyzedSentence ( "Dieses Buch hat sechs Saiten." ) ) [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } private void assertGood ( String sentence ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( sentence ) ) . length ) ; } private void assertBad ( String sentence ) throws IOException { assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( sentence ) ) . length ) ; } }
package org . languagetool . rules . de ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import java . io . IOException ; public class WordCoherencyRuleTest extends TestCase { public void testRule ( ) throws IOException { final WordCoherencyRule rule = new WordCoherencyRule ( TestTools . getEnglishMessages ( ) ) ; final JLanguageTool langTool = new JLanguageTool ( new German ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Das ist aufwendig, aber nicht zu aufwendig." ) ) . length ) ; rule . reset ( ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Das ist aufwändig, aber nicht zu aufwändig." ) ) . length ) ; assertError ( "Das ist aufwendig, aber nicht zu aufwändig." , langTool ) ; assertError ( "Das ist aufwendiger, aber nicht zu aufwändig." , langTool ) ; assertError ( "Das ist aufwändig, aber nicht zu aufwendig." , langTool ) ; assertError ( "Das ist aufwändiger, aber nicht zu aufwendig." , langTool ) ; assertError ( "Delfin und Delphin" , langTool ) ; assertError ( "Delfins und Delphine" , langTool ) ; assertError ( "essentiell und essenziell" , langTool ) ; assertError ( "essentieller und essenzielles" , langTool ) ; assertError ( "Differential und Differenzial" , langTool ) ; assertError ( "Differentials und Differenzials" , langTool ) ; assertError ( "Facette und Fassette" , langTool ) ; assertError ( "Facetten und Fassetten" , langTool ) ; assertError ( "Joghurt und Jogurt" , langTool ) ; assertError ( "Joghurts und Jogurt" , langTool ) ; assertError ( "Joghurt und Jogurts" , langTool ) ; assertError ( "Joghurts und Jogurts" , langTool ) ; assertError ( "Ketchup und Ketschup" , langTool ) ; assertError ( "Ketchups und Ketschups" , langTool ) ; assertError ( "Kommuniqué und Kommunikee" , langTool ) ; assertError ( "Kommuniqués und Kommunikees" , langTool ) ; assertError ( "Necessaire und Nessessär" , langTool ) ; assertError ( "Necessaires und Nessessärs" , langTool ) ; assertError ( "Orthographie und Orthografie" , langTool ) ; assertError ( "Orthographien und Orthografien" , langTool ) ; assertError ( "Potential und Potenzial" , langTool ) ; assertError ( "Potentials und Potenziale" , langTool ) ; assertError ( "Portemonnaie und Portmonee" , langTool ) ; assertError ( "Portemonnaies und Portmonees" , langTool ) ; assertError ( "potentiell und potenziell" , langTool ) ; assertError ( "potentielles und potenzieller" , langTool ) ; assertError ( "Schenke und Schänke" , langTool ) ; assertError ( "substantiell und substanziell" , langTool ) ; assertError ( "substantieller und substanzielles" , langTool ) ; assertError ( "Thunfisch und Tunfisch" , langTool ) ; assertError ( "Thunfische und Tunfische" , langTool ) ; assertError ( "Xylophon und Xylofon" , langTool ) ; assertError ( "Xylophone und Xylofone" , langTool ) ; assertError ( "selbständig und selbstständig" , langTool ) ; assertError ( "selbständiges und selbstständiger" , langTool ) ; assertError ( "Bahnhofsplatz und Bahnhofplatz" , langTool ) ; } public void testCallIndependence ( ) throws IOException { final JLanguageTool langTool = new JLanguageTool ( new German ( ) ) ; assertGood ( "Das ist aufwendig." , langTool ) ; assertGood ( "Aber nicht zu aufwändig." , langTool ) ; } private void assertError ( String s , JLanguageTool langTool ) throws IOException { final WordCoherencyRule rule = new WordCoherencyRule ( TestTools . getEnglishMessages ( ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( s ) ) . length ) ; } private void assertGood ( String s , JLanguageTool langTool ) throws IOException { final WordCoherencyRule rule = new WordCoherencyRule ( TestTools . getEnglishMessages ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( s ) ) . length ) ; } public void testRuleCompleteTexts ( ) throws IOException { JLanguageTool lt = new JLanguageTool ( new German ( ) ) ; assertEquals ( 0 , lt . check ( "Das ist aufwändig. Aber hallo. Es ist wirklich aufwändig." ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "Das ist aufwendig. Aber hallo. Es ist wirklich aufwändig." ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "Das ist aufwändig. Aber hallo. Es ist wirklich aufwendig." ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "Das ist aufwendig. Aber hallo. Es ist wirklich aufwendiger als so." ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "Das ist aufwendig. Aber hallo. Es ist wirklich aufwändiger als so." ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "Das ist aufwändig. Aber hallo. Es ist wirklich aufwendiger als so." ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "Das ist das aufwändigste. Aber hallo. Es ist wirklich aufwendiger als so." ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "Das ist das aufwändigste. Aber hallo. Es ist wirklich aufwendig." ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "Das ist das aufwändigste.\n\nAber hallo. Es ist wirklich aufwendig." ) . size ( ) ) ; } }
package org . languagetool . rules . de ; import org . junit . Test ; import org . languagetool . rules . RuleMatch ; import java . util . Calendar ; import java . util . HashMap ; import java . util . Map ; import static junit . framework . Assert . assertNull ; import static junit . framework . TestCase . assertNotNull ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class DateCheckFilterTest { private final RuleMatch match = new RuleMatch ( null , 0 , 10 , "message" ) ; private final DateCheckFilter filter = new DateCheckFilter ( ) ; @ Test public void testAccept ( ) throws Exception { assertNull ( filter . acceptRuleMatch ( match , makeMap ( "2014" , "8" , "23" , "Samstag" ) , null ) ) ; assertNotNull ( filter . acceptRuleMatch ( match , makeMap ( "2014" , "8" , "23" , "Sonntag" ) , null ) ) ; } @ Test ( expected = IllegalArgumentException . class ) public void testAcceptIncompleteArgs ( ) throws Exception { Map < String , String > map = makeMap ( "2014" , "8" , "23" , "Samstag" ) ; map . remove ( "weekDay" ) ; filter . acceptRuleMatch ( match , map , null ) ; } @ Test ( expected = RuntimeException . class ) public void testInvalidDay ( ) throws Exception { filter . acceptRuleMatch ( match , makeMap ( "2014" , "8" , "23" , "invalid" ) , null ) ; } @ Test public void testGetDayOfWeek1 ( ) throws Exception { assertThat ( filter . getDayOfWeek ( "So" ) , is ( 1 ) ) ; assertThat ( filter . getDayOfWeek ( "Mo" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "mo" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Mon." ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Montag" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "montag" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "Di" ) , is ( 3 ) ) ; assertThat ( filter . getDayOfWeek ( "Fr" ) , is ( 6 ) ) ; assertThat ( filter . getDayOfWeek ( "Samstag" ) , is ( 7 ) ) ; assertThat ( filter . getDayOfWeek ( "Sonnabend" ) , is ( 7 ) ) ; } @ Test public void testGetDayOfWeek2 ( ) throws Exception { Calendar calendar = Calendar . getInstance ( ) ; calendar . set ( 2014 , 8 - 1 , 29 ) ; assertThat ( filter . getDayOfWeek ( calendar ) , is ( "Freitag" ) ) ; calendar . set ( 2014 , 8 - 1 , 30 ) ; assertThat ( filter . getDayOfWeek ( calendar ) , is ( "Samstag" ) ) ; } @ Test public void testGetMonth ( ) throws Exception { assertThat ( filter . getMonth ( "Januar" ) , is ( 1 ) ) ; assertThat ( filter . getMonth ( "Jan" ) , is ( 1 ) ) ; assertThat ( filter . getMonth ( "Jan." ) , is ( 1 ) ) ; assertThat ( filter . getMonth ( "Dezember" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "Dez" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "dez" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "DEZEMBER" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "dezember" ) , is ( 12 ) ) ; } private Map < String , String > makeMap ( String year , String month , String dayOfMonth , String weekDay ) { Map < String , String > map = new HashMap < > ( ) ; map . put ( "year" , year ) ; map . put ( "month" , month ) ; map . put ( "day" , dayOfMonth ) ; map . put ( "weekDay" , weekDay ) ; return map ; } }
package org . languagetool . rules . de ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . German ; import org . languagetool . rules . Rule ; import java . io . IOException ; public class UppercaseSentenceStartRuleTest extends TestCase { public void testRule ( ) throws IOException { final JLanguageTool lt = new JLanguageTool ( new German ( ) ) ; for ( Rule rule : lt . getAllActiveRules ( ) ) { lt . disableRule ( rule . getId ( ) ) ; } lt . enableRule ( "UPPERCASE_SENTENCE_START" ) ; assertEquals ( 2 , lt . check ( "etwas beginnen. und der auch nicht" ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "Dies ist ein Satz. Und hier kommt noch einer" ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "Dies ist ein Satz. Ätsch, noch einer mit Umlaut." ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "Dieser Satz ist bspw. okay so." ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "Dieser Satz ist z.B. okay so." ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "Dies ist ein Satz. \"Aber der hier auch!\"." ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "\"Dies ist ein Satz!\"" ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "'Dies ist ein Satz!'" ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "Sehr geehrte Frau Merkel,\nwie wir Ihnen schon früher mitgeteilt haben..." ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "Dies ist ein Satz. ätsch, noch einer mit Umlaut." ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "Dies ist ein Satz. \"aber der hier auch!\"" ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "Dies ist ein Satz. „aber der hier auch!“" ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "\"dies ist ein Satz!\"" ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "'dies ist ein Satz!'" ) . size ( ) ) ; } }
package org . languagetool . rules . spelling . hunspell ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . TestTools ; import org . languagetool . language . AustrianGerman ; import org . languagetool . language . German ; import org . languagetool . language . GermanyGerman ; import org . languagetool . language . SwissGerman ; import org . languagetool . rules . de . GermanSpellerRule ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . ResourceBundle ; import static org . junit . Assert . assertEquals ; public class HunspellRuleTest { @ Test public void testRuleWithGerman ( ) throws Exception { final HunspellRule rule = new HunspellRule ( TestTools . getMessages ( "de" ) , new GermanyGerman ( ) ) ; final JLanguageTool langTool = new JLanguageTool ( new German ( ) ) ; commonGermanAsserts ( rule , langTool ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der äußere Übeltäter." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der äussere Übeltäter." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Unter http://foo.org/bar steht was." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "dasdassda http://foo.org/bar steht was." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Unter http://foo.org/bar steht dasdassda." ) ) . length ) ; } @ Test public void testRuleWithAustrianGerman ( ) throws Exception { final HunspellRule rule = new HunspellRule ( TestTools . getMessages ( "de" ) , new AustrianGerman ( ) ) ; final JLanguageTool langTool = new JLanguageTool ( new German ( ) ) ; commonGermanAsserts ( rule , langTool ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der äußere Übeltäter." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der äussere Übeltäter." ) ) . length ) ; } @ Test public void testRuleWithSwissGerman ( ) throws Exception { final HunspellRule rule = new HunspellRule ( TestTools . getMessages ( "de" ) , new SwissGerman ( ) ) ; final JLanguageTool langTool = new JLanguageTool ( new German ( ) ) ; commonGermanAsserts ( rule , langTool ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der äußere Übeltäter." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der äussere Übeltäter." ) ) . length ) ; } private void commonGermanAsserts ( HunspellRule rule , JLanguageTool langTool ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der Waschmaschinentestversuch" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der Waschmaschinentest-Versuch" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Der Arbeitnehmer" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Die Verhaltensänderung" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der Waschmaschinentest-Dftgedgs" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der Dftgedgs-Waschmaschinentest" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der Waschmaschinentestdftgedgs" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der Waschmaschinentestversuch orkt" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Der Arbeitsnehmer" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Die Verhaltenänderung" ) ) . length ) ; assertEquals ( 2 , rule . match ( langTool . getAnalyzedSentence ( "Der asdegfue orkt" ) ) . length ) ; } @ Ignore ( "just for internal performance testing, thus ignored by default" ) @ Test public void testPerformance ( ) throws Exception { final List < Language > allLanguages = Languages . get ( ) ; for ( Language language : allLanguages ) { final JLanguageTool langTool = new JLanguageTool ( language ) ; langTool . check ( "warmup" ) ; langTool . check ( "anotherwarmup" ) ; final long startTime = System . currentTimeMillis ( ) ; langTool . check ( "fdfds fdfdsa fdfdsb fdfdsc fdfdsd fdfdse fdfdsf fdfds fdfdsa fdfdsb fdfdsc fdfdsd fdfdse fdfdsf" ) ; final long endTime = System . currentTimeMillis ( ) ; System . out . println ( ( endTime - startTime ) + "ms for " + language ) ; } } @ Ignore ( "just for internal performance testing, thus ignored by default" ) @ Test public void testCompoundAwareRulePerformance ( ) throws IOException { final ResourceBundle messages = ResourceBundle . getBundle ( "org.languagetool.MessagesBundle" , new Locale ( "de" ) ) ; final CompoundAwareHunspellRule rule = new GermanSpellerRule ( messages , new GermanyGerman ( ) ) ; rule . init ( ) ; final String [ ] words = { "foo" , "warmup" , "Rechtschreipreform" , "Theatrekasse" , "Zoobesuck" , "Handselvertreter" , "Mückenstick" , "gewönlich" , "Traprennen" , "Autoverkehrr" } ; for ( String word : words ) { final long startTime = System . currentTimeMillis ( ) ; final List < String > suggest = rule . getSuggestions ( word ) ; System . out . println ( ( System . currentTimeMillis ( ) - startTime ) + "ms for " + word + ": " + suggest ) ; } } }
package org . languagetool . rules . spelling . hunspell ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . GermanyGerman ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . de . GermanSpellerRule ; import java . io . IOException ; import java . util . List ; public class SpellingCheckRuleTest extends TestCase { public void testIgnoreSuggestionsWithHunspell ( ) throws IOException { final JLanguageTool langTool = new JLanguageTool ( new GermanyGerman ( ) ) ; final List < RuleMatch > matches = langTool . check ( "Das ist ein einPseudoWortFürLanguageToolTests" ) ; assertEquals ( 0 , matches . size ( ) ) ; final List < RuleMatch > matches2 = langTool . check ( "Das ist ein Tibbfehla" ) ; assertEquals ( 1 , matches2 . size ( ) ) ; assertEquals ( GermanSpellerRule . RULE_ID , matches2 . get ( 0 ) . getRule ( ) . getId ( ) ) ; } }
package org . languagetool . tagging . disambiguation . rules . de ; import org . languagetool . tagging . disambiguation . rules . DisambiguationRuleTest ; public class GermanDisambiguationRuleTest extends DisambiguationRuleTest { }
package org . languagetool . tagging . de ; import junit . framework . TestCase ; import morfologik . stemming . Dictionary ; import morfologik . stemming . DictionaryLookup ; import morfologik . stemming . WordData ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . util . * ; @ SuppressWarnings ( "ConstantConditions" ) public class GermanTaggerTest extends TestCase { public void testTagger ( ) throws IOException { final GermanTagger tagger = new GermanTagger ( ) ; AnalyzedTokenReadings aToken = tagger . lookup ( "Haus" ) ; assertEquals ( "Haus[Haus/SUB:AKK:SIN:NEU, Haus/SUB:DAT:SIN:NEU, Haus/SUB:NOM:SIN:NEU]" , toSortedString ( aToken ) ) ; assertEquals ( "Haus" , aToken . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; assertEquals ( "Haus" , aToken . getReadings ( ) . get ( 1 ) . getLemma ( ) ) ; assertEquals ( "Haus" , aToken . getReadings ( ) . get ( 2 ) . getLemma ( ) ) ; AnalyzedTokenReadings aToken2 = tagger . lookup ( "Hauses" ) ; assertEquals ( "Hauses[Haus/SUB:GEN:SIN:NEU]" , toSortedString ( aToken2 ) ) ; assertEquals ( "Haus" , aToken2 . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; assertNull ( tagger . lookup ( "hauses" ) ) ; assertNull ( tagger . lookup ( "Groß" ) ) ; assertEquals ( "Lieblingsbuchstabe[Lieblingsbuchstabe/SUB:NOM:SIN:MAS]" , toSortedString ( tagger . lookup ( "Lieblingsbuchstabe" ) ) ) ; AnalyzedTokenReadings aToken3 = tagger . lookup ( "großer" ) ; assertEquals ( "großer[groß/ADJ:DAT:SIN:FEM:GRU:SOL, groß/ADJ:GEN:PLU:FEM:GRU:SOL, groß/ADJ:GEN:PLU:MAS:GRU:SOL, " + "groß/ADJ:GEN:PLU:NEU:GRU:SOL, groß/ADJ:GEN:SIN:FEM:GRU:SOL, groß/ADJ:NOM:SIN:MAS:GRU:IND, " + "groß/ADJ:NOM:SIN:MAS:GRU:SOL]" , toSortedString ( tagger . lookup ( "großer" ) ) ) ; assertEquals ( "groß" , aToken3 . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; AnalyzedTokenReadings aToken4 = tagger . lookup ( "Interessen" ) ; assertEquals ( "Interessen[Interesse/SUB:AKK:PLU:NEU, Interesse/SUB:DAT:PLU:NEU, " + "Interesse/SUB:GEN:PLU:NEU, Interesse/SUB:NOM:PLU:NEU]" , toSortedString ( aToken4 ) ) ; assertEquals ( "Interesse" , aToken4 . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; assertEquals ( "Interesse" , aToken4 . getReadings ( ) . get ( 1 ) . getLemma ( ) ) ; assertEquals ( "Interesse" , aToken4 . getReadings ( ) . get ( 2 ) . getLemma ( ) ) ; assertEquals ( "Interesse" , aToken4 . getReadings ( ) . get ( 3 ) . getLemma ( ) ) ; AnalyzedTokenReadings aToken5 = tagger . lookup ( "Donaudampfschiff" ) ; assertEquals ( "Donaudampfschiff[Donaudampfschiff/SUB:AKK:SIN:NEU, Donaudampfschiff/SUB:DAT:SIN:NEU, " + "Donaudampfschiff/SUB:NOM:SIN:NEU]" , toSortedString ( aToken5 ) ) ; assertEquals ( "Donaudampfschiff" , aToken5 . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; assertEquals ( "Donaudampfschiff" , aToken5 . getReadings ( ) . get ( 1 ) . getLemma ( ) ) ; AnalyzedTokenReadings aToken6 = tagger . lookup ( "Häuserkämpfe" ) ; assertEquals ( "Häuserkämpfe[Häuserkampf/SUB:AKK:PLU:MAS, Häuserkampf/SUB:GEN:PLU:MAS, Häuserkampf/SUB:NOM:PLU:MAS]" , toSortedString ( aToken6 ) ) ; assertEquals ( "Häuserkampf" , aToken6 . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; assertEquals ( "Häuserkampf" , aToken6 . getReadings ( ) . get ( 1 ) . getLemma ( ) ) ; assertEquals ( "Häuserkampf" , aToken6 . getReadings ( ) . get ( 2 ) . getLemma ( ) ) ; AnalyzedTokenReadings aToken7 = tagger . lookup ( "Häuserkampfes" ) ; assertEquals ( "Häuserkampfes[Häuserkampf/SUB:GEN:SIN:MAS]" , toSortedString ( aToken7 ) ) ; assertEquals ( "Häuserkampf" , aToken7 . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; AnalyzedTokenReadings aToken8 = tagger . lookup ( "Häuserkampfs" ) ; assertEquals ( "Häuserkampfs[Häuserkampf/SUB:GEN:SIN:MAS]" , toSortedString ( aToken8 ) ) ; assertEquals ( "Häuserkampf" , aToken8 . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; AnalyzedTokenReadings aToken9 = tagger . lookup ( "Lieblingsfarben" ) ; assertEquals ( "Lieblingsfarben[Lieblingsfarbe/SUB:AKK:PLU:FEM, Lieblingsfarbe/SUB:DAT:PLU:FEM, " + "Lieblingsfarbe/SUB:GEN:PLU:FEM, Lieblingsfarbe/SUB:NOM:PLU:FEM]" , toSortedString ( aToken9 ) ) ; assertEquals ( "Lieblingsfarbe" , aToken9 . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; AnalyzedTokenReadings aToken10 = tagger . lookup ( "Autolieblingsfarben" ) ; assertEquals ( "Autolieblingsfarben[Autolieblingsfarbe/SUB:AKK:PLU:FEM, Autolieblingsfarbe/SUB:DAT:PLU:FEM, " + "Autolieblingsfarbe/SUB:GEN:PLU:FEM, Autolieblingsfarbe/SUB:NOM:PLU:FEM]" , toSortedString ( aToken10 ) ) ; assertEquals ( "Autolieblingsfarbe" , aToken10 . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; AnalyzedTokenReadings aToken11 = tagger . lookup ( "übrigbleibst" ) ; assertEquals ( "übrigbleibst[übrigbleiben/VER:2:SIN:PRÄ:NON:NEB]" , toSortedString ( aToken11 ) ) ; assertEquals ( "übrigbleiben" , aToken11 . getReadings ( ) . get ( 0 ) . getLemma ( ) ) ; } public void testExtendedTagger ( ) throws IOException { final GermanTagger tagger = new GermanTagger ( ) ; assertEquals ( "Kuß[Kuß/SUB:AKK:SIN:MAS, Kuß/SUB:DAT:SIN:MAS, Kuß/SUB:NOM:SIN:MAS]" , toSortedString ( tagger . lookup ( "Kuß" ) ) ) ; assertEquals ( "Kuss[Kuss/SUB:AKK:SIN:MAS, Kuss/SUB:DAT:SIN:MAS, Kuss/SUB:NOM:SIN:MAS]" , toSortedString ( tagger . lookup ( "Kuss" ) ) ) ; assertEquals ( "Haß[Haß/SUB:AKK:SIN:MAS, Haß/SUB:DAT:SIN:MAS, Haß/SUB:NOM:SIN:MAS]" , toSortedString ( tagger . lookup ( "Haß" ) ) ) ; assertEquals ( "Hass[Hass/SUB:AKK:SIN:MAS, Hass/SUB:DAT:SIN:MAS, Hass/SUB:NOM:SIN:MAS]" , toSortedString ( tagger . lookup ( "Hass" ) ) ) ; assertEquals ( "muß[müssen/VER:MOD:1:SIN:PRÄ, müssen/VER:MOD:3:SIN:PRÄ]" , toSortedString ( tagger . lookup ( "muß" ) ) ) ; assertEquals ( "muss[müssen/VER:MOD:1:SIN:PRÄ, müssen/VER:MOD:3:SIN:PRÄ]" , toSortedString ( tagger . lookup ( "muss" ) ) ) ; } public void testTaggerBaseforms ( ) throws IOException { final GermanTagger tagger = new GermanTagger ( ) ; List < AnalyzedToken > readings1 = tagger . lookup ( "übrigbleibst" ) . getReadings ( ) ; assertEquals ( 1 , readings1 . size ( ) ) ; assertEquals ( "übrigbleiben" , readings1 . get ( 0 ) . getLemma ( ) ) ; List < AnalyzedToken > readings2 = tagger . lookup ( "Haus" ) . getReadings ( ) ; assertEquals ( 3 , readings2 . size ( ) ) ; assertEquals ( "Haus" , readings2 . get ( 0 ) . getLemma ( ) ) ; assertEquals ( "Haus" , readings2 . get ( 1 ) . getLemma ( ) ) ; assertEquals ( "Haus" , readings2 . get ( 2 ) . getLemma ( ) ) ; List < AnalyzedToken > readings3 = tagger . lookup ( "Häuser" ) . getReadings ( ) ; assertEquals ( 3 , readings3 . size ( ) ) ; assertEquals ( "Haus" , readings3 . get ( 0 ) . getLemma ( ) ) ; assertEquals ( "Haus" , readings3 . get ( 1 ) . getLemma ( ) ) ; assertEquals ( "Haus" , readings3 . get ( 2 ) . getLemma ( ) ) ; } public void testTag ( ) throws IOException { GermanTagger tagger = new GermanTagger ( ) ; List < String > upperCaseWord = Arrays . asList ( "Das" ) ; List < AnalyzedTokenReadings > readings = tagger . tag ( upperCaseWord , false ) ; assertEquals ( "[Das[Das/null*]]" , readings . toString ( ) ) ; List < AnalyzedTokenReadings > readings2 = tagger . tag ( upperCaseWord , true ) ; assertTrue ( readings2 . toString ( ) . startsWith ( "[Das[der/ART:" ) ) ; } public void testTagWithManualDictExtension ( ) throws IOException { final GermanTagger tagger = new GermanTagger ( ) ; final List < AnalyzedTokenReadings > readings = tagger . tag ( Collections . singletonList ( "Wichtigtuerinnen" ) ) ; assertEquals ( "[Wichtigtuerinnen[Wichtigtuerin/SUB:AKK:PLU:FEM*," + "Wichtigtuerin/SUB:DAT:PLU:FEM*,Wichtigtuerin/SUB:GEN:PLU:FEM*,Wichtigtuerin/SUB:NOM:PLU:FEM*]]" , readings . toString ( ) ) ; } public void testDictionary ( ) throws IOException { final Dictionary dictionary = Dictionary . read ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( "/de/german.dict" ) ) ; final DictionaryLookup dl = new DictionaryLookup ( dictionary ) ; for ( WordData wd : dl ) { if ( wd . getTag ( ) == null || wd . getTag ( ) . length ( ) == 0 ) { System . err . println ( "**** Warning: the word " + wd . getWord ( ) + "/" + wd . getStem ( ) + " lacks a POS tag in the dictionary." ) ; } } } private String toSortedString ( AnalyzedTokenReadings tokenReadings ) { final StringBuilder sb = new StringBuilder ( tokenReadings . getToken ( ) ) ; final Set < String > elements = new TreeSet < > ( ) ; sb . append ( '[' ) ; for ( AnalyzedToken reading : tokenReadings ) { if ( ! elements . contains ( reading . toString ( ) ) ) { elements . add ( reading . toString ( ) ) ; } } sb . append ( StringTools . listToString ( elements , ", " ) ) ; sb . append ( ']' ) ; return sb . toString ( ) ; } }
package org . languagetool . tagging . disambiguation . ca ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . language . Catalan ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . MultiWordChunker ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; public class CatalanHybridDisambiguator implements Disambiguator { private final Disambiguator chunker = new MultiWordChunker ( "/ca/multiwords.txt" , true ) ; private final Disambiguator disambiguator = new XmlRuleDisambiguator ( new Catalan ( ) ) ; @ Override public final AnalyzedSentence disambiguate ( AnalyzedSentence input ) throws IOException { return disambiguator . disambiguate ( chunker . disambiguate ( input ) ) ; } }
package org . languagetool . tokenizers . de ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . German ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class GermanSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new German ( ) ) ; public void testTokenize ( ) { testSplit ( "Dies ist ein Satz." ) ; testSplit ( "Dies ist ein Satz. " , "Noch einer." ) ; testSplit ( "Dies ist ein Satz.¹ " , "Noch einer." ) ; testSplit ( "Ein Satz! " , "Noch einer." ) ; testSplit ( "Ein Satz... " , "Noch einer." ) ; testSplit ( "Unter http://www.test.de gibt es eine Website." ) ; testSplit ( "Das Schreiben ist auf den 3.10. datiert." ) ; testSplit ( "Das Schreiben ist auf den 31.1. datiert." ) ; testSplit ( "Das Schreiben ist auf den 3.10.2000 datiert." ) ; testSplit ( "Natürliche Vererbungsprozesse prägten sich erst im 18. und frühen 19. Jahrhundert aus." ) ; testSplit ( "Das ist ja 1a. " , "Und das auch." ) ; testSplit ( "Friedrich I., auch bekannt als Friedrich der Große." ) ; testSplit ( "Friedrich II., auch bekannt als Friedrich der Große." ) ; testSplit ( "Friedrich IIXC., auch bekannt als Friedrich der Große." ) ; testSplit ( "Friedrich II. öfter auch bekannt als Friedrich der Große." ) ; testSplit ( "Friedrich VII. öfter auch bekannt als Friedrich der Große." ) ; testSplit ( "Friedrich X. öfter auch bekannt als Friedrich der Zehnte." ) ; testSplit ( "Heute ist der 13.12.2004." ) ; testSplit ( "Heute ist der 13. Dezember." ) ; testSplit ( "Heute ist der 1. Januar." ) ; testSplit ( "Es geht am 24.09. los." ) ; testSplit ( "Es geht um ca. 17:00 los." ) ; testSplit ( "Das in Punkt 3.9.1 genannte Verhalten." ) ; testSplit ( "Diese Periode begann im 13. Jahrhundert und damit bla." ) ; testSplit ( "Diese Periode begann im 13. oder 14. Jahrhundert und damit bla." ) ; testSplit ( "Diese Periode datiert auf das 13. bis zum 14. Jahrhundert und damit bla." ) ; testSplit ( "Das gilt lt. aktuellem Plan." ) ; testSplit ( "Orangen, Äpfel etc. werden gekauft." ) ; testSplit ( "Das ist,, also ob es bla." ) ; testSplit ( "Das ist es.. " , "So geht es weiter." ) ; testSplit ( "Das hier ist ein(!) Satz." ) ; testSplit ( "Das hier ist ein(!!) Satz." ) ; testSplit ( "Das hier ist ein(?) Satz." ) ; testSplit ( "Das hier ist ein(???) Satz." ) ; testSplit ( "Das hier ist ein(???) Satz." ) ; testSplit ( "»Der Papagei ist grün.« " , "Das kam so." ) ; testSplit ( "»Der Papagei ist grün«, sagte er" ) ; testSplit ( "Das war es: gar nichts." ) ; testSplit ( "Das war es: Dies ist ein neuer Satz." ) ; testSplit ( "schlug er die Richtung nach der K … brücke ein. " ) ; testSplit ( "sobald ich es von einem Freunde zurückbekomme …« Er wurde verlegen und schwieg." ) ; testSplit ( "Er kannte eine Unmenge Quellen, aus denen er schöpfen konnte, d. h. natürlich, wo er durch Arbeit sich etwas verdienen konnte." ) ; testSplit ( "Stimme am lautesten heraustönte …. " , "Sobald er auf der Straße war" ) ; testSplit ( "»Welche Wohnung?\" " , "»Die, wo wir arbeiten." ) ; testSplit ( "»Nun also, wie ist's?« fragte Lushin und blickte sie fest an." ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . jetbrains . annotations . NotNull ; import org . languagetool . Language ; import org . languagetool . chunking . Chunker ; import org . languagetool . chunking . GermanChunker ; import org . languagetool . rules . * ; import org . languagetool . rules . de . * ; import org . languagetool . rules . de . SentenceWhitespaceRule ; import org . languagetool . synthesis . GermanSynthesizer ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . de . GermanTagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . de . GermanRuleDisambiguator ; import org . languagetool . tokenizers . CompoundWordTokenizer ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . de . GermanCompoundTokenizer ; public class German extends Language { private Tagger tagger ; private Synthesizer synthesizer ; private SentenceTokenizer sentenceTokenizer ; private Disambiguator disambiguator ; private GermanChunker chunker ; private CompoundWordTokenizer compoundTokenizer ; private GermanCompoundTokenizer strictCompoundTokenizer ; @ Override public Language getDefaultLanguageVariant ( ) { return new GermanyGerman ( ) ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new GermanRuleDisambiguator ( ) ; } return disambiguator ; } @ Override public Chunker getPostDisambiguationChunker ( ) { if ( chunker == null ) { chunker = new GermanChunker ( ) ; } return chunker ; } @ Override public String getName ( ) { return "German" ; } @ Override public String getShortName ( ) { return "de" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "LU" , "LI" , "BE" } ; } @ Override public Tagger getTagger ( ) { Tagger t = tagger ; if ( t == null ) { synchronized ( this ) { t = tagger ; if ( t == null ) { tagger = t = new GermanTagger ( ) ; } } } return t ; } @ Override @ NotNull public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new GermanSynthesizer ( ) ; } return synthesizer ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Jan Schreiber" ) , new Contributor ( "Markus Brenneis" ) , Contributors . DANIEL_NABER , } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new GenericUnpairedBracketsRule ( messages , Arrays . asList ( "[" , "(" , "{" , "„" , "»" , "«" ) , Arrays . asList ( "]" , ")" , "}" , "“" , "«" , "»" ) ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new SentenceWhitespaceRule ( messages ) , new GermanDoublePunctuationRule ( messages ) , new MissingVerbRule ( messages , this ) , new GermanWordRepeatRule ( messages , this ) , new GermanWordRepeatBeginningRule ( messages , this ) , new GermanWrongWordInContextRule ( messages ) , new AgreementRule ( messages , this ) , new CaseRule ( messages , this ) , new CompoundRule ( messages ) , new DashRule ( messages ) , new VerbAgreementRule ( messages , this ) , new SubjectVerbAgreementRule ( messages , this ) , new WordCoherencyRule ( messages ) , new SimilarNameRule ( messages ) , new WiederVsWiderRule ( messages ) ) ; } public CompoundWordTokenizer getNonStrictCompoundSplitter ( ) { if ( compoundTokenizer == null ) { try { final GermanCompoundTokenizer tokenizer = new GermanCompoundTokenizer ( false ) ; compoundTokenizer = new CompoundWordTokenizer ( ) { @ Override public List < String > tokenize ( String word ) { return new ArrayList < > ( tokenizer . tokenize ( word ) ) ; } } ; } catch ( IOException e ) { throw new RuntimeException ( "Could not set up German compound splitter" , e ) ; } } return compoundTokenizer ; } public GermanCompoundTokenizer getStrictCompoundTokenizer ( ) { if ( strictCompoundTokenizer == null ) { try { strictCompoundTokenizer = new GermanCompoundTokenizer ( ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not set up strict German compound splitter" , e ) ; } } return strictCompoundTokenizer ; } }
package org . languagetool . language ; import org . languagetool . rules . Rule ; import org . languagetool . rules . de . GermanSpellerRule ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; public class SwissGerman extends German { @ Override public String [ ] getCountries ( ) { return new String [ ] { "CH" } ; } @ Override public String getName ( ) { return "German (Swiss)" ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { List < Rule > rules = new ArrayList < > ( super . getRelevantRules ( messages ) ) ; rules . add ( new GermanSpellerRule ( messages , this ) ) ; return rules ; } }
package org . languagetool . language ; import org . languagetool . rules . Rule ; import org . languagetool . rules . de . GermanSpellerRule ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; public class GermanyGerman extends German { @ Override public String [ ] getCountries ( ) { return new String [ ] { "DE" } ; } @ Override public String getName ( ) { return "German (Germany)" ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { List < Rule > rules = new ArrayList < > ( super . getRelevantRules ( messages ) ) ; rules . add ( new GermanSpellerRule ( messages , this ) ) ; return rules ; } }
package org . languagetool . language ; import org . languagetool . rules . Rule ; import org . languagetool . rules . de . GermanSpellerRule ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; public class AustrianGerman extends German { @ Override public String [ ] getCountries ( ) { return new String [ ] { "AT" } ; } @ Override public String getName ( ) { return "German (Austria)" ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { List < Rule > rules = new ArrayList < > ( super . getRelevantRules ( messages ) ) ; rules . add ( new GermanSpellerRule ( messages , this ) ) ; return rules ; } }
package org . languagetool . chunking ; import edu . washington . cs . knowitall . logic . Expression ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import java . util . regex . Pattern ; final class TokenPredicate extends Expression . Arg . Pred < ChunkTaggedToken > { private final boolean caseSensitive ; TokenPredicate ( String description , boolean caseSensitive ) { super ( description ) ; this . caseSensitive = caseSensitive ; } @ Override public boolean apply ( ChunkTaggedToken analyzedToken ) { final String [ ] parts = getDescription ( ) . split ( "=" ) ; final String exprType ; String exprValue ; if ( parts . length == 1 ) { exprType = "string" ; exprValue = parts [ 0 ] ; } else if ( parts . length == 2 ) { exprType = parts [ 0 ] ; exprValue = parts [ 1 ] ; } else { throw new RuntimeException ( "Could not parse expression: " + getDescription ( ) ) ; } if ( exprValue . startsWith ( "'" ) && exprValue . endsWith ( "'" ) ) { exprValue = exprValue . substring ( 1 , exprValue . length ( ) - 1 ) ; } switch ( exprType ) { case "string" : if ( caseSensitive ) { return analyzedToken . getToken ( ) . equals ( exprValue ) ; } else { return analyzedToken . getToken ( ) . equalsIgnoreCase ( exprValue ) ; } case "regex" : Pattern p1 = caseSensitive ? Pattern . compile ( exprValue ) : Pattern . compile ( exprValue , Pattern . CASE_INSENSITIVE ) ; return p1 . matcher ( analyzedToken . getToken ( ) ) . matches ( ) ; case "regexCS" : Pattern p2 = Pattern . compile ( exprValue ) ; return p2 . matcher ( analyzedToken . getToken ( ) ) . matches ( ) ; case "chunk" : Pattern chunkPattern = Pattern . compile ( exprValue ) ; for ( ChunkTag chunkTag : analyzedToken . getChunkTags ( ) ) { if ( chunkPattern . matcher ( chunkTag . getChunkTag ( ) ) . matches ( ) ) { return true ; } } return false ; case "pos" : AnalyzedTokenReadings readings = analyzedToken . getReadings ( ) ; if ( readings != null ) { for ( AnalyzedToken token : readings ) { if ( token . getPOSTag ( ) != null && token . getPOSTag ( ) . contains ( exprValue ) ) { return true ; } } } return false ; case "posre" : case "posregex" : Pattern posPattern = Pattern . compile ( exprValue ) ; AnalyzedTokenReadings readings2 = analyzedToken . getReadings ( ) ; if ( readings2 != null ) { for ( AnalyzedToken token : readings2 ) { if ( token . getPOSTag ( ) != null && posPattern . matcher ( token . getPOSTag ( ) ) . matches ( ) ) { return true ; } } } return false ; default : throw new RuntimeException ( "Expression type not supported: '" + exprType + "'" ) ; } } }
package org . languagetool . chunking ; import com . google . common . base . Function ; import edu . washington . cs . knowitall . logic . LogicExpression ; import edu . washington . cs . knowitall . regex . Expression ; import edu . washington . cs . knowitall . regex . ExpressionFactory ; final class TokenExpressionFactory extends ExpressionFactory < ChunkTaggedToken > { private final boolean caseSensitive ; TokenExpressionFactory ( boolean caseSensitive ) { this . caseSensitive = caseSensitive ; } @ Override public Expression . BaseExpression < ChunkTaggedToken > create ( final String expr ) { final LogicExpression < ChunkTaggedToken > logicExpression = LogicExpression . compile ( expr , new Function < String , edu . washington . cs . knowitall . logic . Expression . Arg < ChunkTaggedToken > > ( ) { @ Override public edu . washington . cs . knowitall . logic . Expression . Arg < ChunkTaggedToken > apply ( final String input ) { return new TokenPredicate ( input , caseSensitive ) ; } } ) ; return new Expression . BaseExpression < ChunkTaggedToken > ( expr ) { @ Override public boolean apply ( ChunkTaggedToken token ) { return logicExpression . apply ( token ) ; } } ; } }
package org . languagetool . chunking ; import edu . washington . cs . knowitall . regex . Match ; import edu . washington . cs . knowitall . regex . RegularExpression ; import org . languagetool . AnalyzedTokenReadings ; import java . util . * ; import java . util . regex . Pattern ; import static org . languagetool . chunking . GermanChunker . PhraseType . * ; public class GermanChunker implements Chunker { private static final Set < String > FILTER_TAGS = new HashSet < > ( Arrays . asList ( "PP" , "NPP" , "NPS" ) ) ; private static final TokenExpressionFactory FACTORY = new TokenExpressionFactory ( false ) ; private static final Map < String , String > SYNTAX_EXPANSION = new HashMap < > ( ) ; static { SYNTAX_EXPANSION . put ( "<NP>" , "<chunk=B-NP> <chunk=I-NP>*" ) ; SYNTAX_EXPANSION . put ( "&prozent;" , "Prozent|Kilo|Kilogramm|Gramm|Euro|Pfund" ) ; } enum PhraseType { NP , NPS , NPP , PP } public static void setDebug ( boolean debugMode ) { debug = debugMode ; } public static boolean isDebug ( ) { return debug ; } private static boolean debug = false ; private static final List < RegularExpressionWithPhraseType > REGEXES1 = Arrays . asList ( build ( "(<posre=^ART.*>|<pos=PRO>)? <pos=ADV>* <pos=PA2>* <pos=ADJ>* <pos=SUB>+" , NP ) , build ( "<pos=SUB> (<und|oder>|(<bzw> <.>)) <pos=SUB>" , NP ) , build ( "<pos=ADJ> (<und|oder>|(<bzw> <.>)) <pos=PA2> <pos=SUB>" , NP ) , build ( "<pos=ADJ> (<und|oder>|(<bzw> <.>)) <pos=ADJ> <pos=SUB>" , NP ) , build ( "<posre=^ART.*> <pos=ADV>* <pos=ADJ>* <regexCS=[A-ZÖÄÜ][a-zöäü]+>" , NP ) , build ( "<pos=PRO>? <pos=ZAL> <pos=SUB>" , NP ) , build ( "<Herr|Herrn|Frau> <pos=EIG>+" , NP ) , build ( "<Herr|Herrn|Frau> <regexCS=[A-ZÖÄÜ][a-zöäü-]+>+" , NP ) , build ( "<der>" , NP ) ) ; private static final List < RegularExpressionWithPhraseType > REGEXES2 = Arrays . asList ( build ( "<pos=ADJ> <,> <chunk=B-NP> <chunk=I-NP>* <und|sowie> <NP>" , NPP ) , build ( "<chunk=B-NP & !regex=jede[rs]?> <chunk=I-NP>* <und|sowie> <NP>" , NPP ) , build ( "<pos=ADJ> <und|sowie> <chunk=B-NP & !pos=PLU> <chunk=I-NP>*" , NPS , true ) , build ( "<deren> <chunk=B-NP & !pos=PLU> <und|sowie> <chunk=B-NP>*" , NPS , true ) , build ( "<pos=EIG> <und> <pos=EIG>" , NPP ) , build ( "<pos=ART> <pos=ADJ> <und|sowie> (<pos=ADJ>|<pos=PA2>) <chunk=I-NP & !pos=PLU>+" , NPS , true ) , build ( "<chunk=B-NP & !pos=PLU> <chunk=I-NP>* <und|sowie> <keine> <chunk=I-NP>+" , NPS , true ) , build ( "<NP> <und|sowie> <pos=ART> <pos=PA1> <pos=SUB>" , NPP , true ) , build ( "(<eins>|<eines>) <chunk=B-NP> <chunk=I-NP>+" , NPS ) , build ( "<ich|du|er|sie|es|wir|ihr|sie> <und|oder|sowie> <NP>" , NPP ) , build ( "<sowohl> <NP> <als> <auch> <NP>" , NPP ) , build ( "<sowohl> <pos=EIG> <als> <auch> <pos=EIG>" , NPP ) , build ( "<sowohl> <ich|du|er|sie|es|wir|ihr|sie> <als> <auch> <NP>" , NPP ) , build ( "<pos=SUB> <und|oder|sowie> <chunk=B-NP & !ihre> <chunk=I-NP>*" , NPP ) , build ( "<weder> <pos=SUB> <noch> <pos=SUB>" , NPP ) , build ( "(<zwei|drei|vier|fünf|sechs|sieben|acht|neun|zehn|elf|zwölf>) <chunk=I-NP>" , NPP ) , build ( "<chunk=B-NP> <pos=PRP> <NP> <chunk=B-NP & pos=SIN> <chunk=I-NP>*" , NPS ) , build ( "<chunk=B-NP> <pos=PRP> <NP> <chunk=B-NP & pos=PLU> <chunk=I-NP>*" , NPP ) , build ( "<chunk=B-NP> <pos=PRP> <NP> <pos=PA2> <chunk=B-NP & !pos=PLU> <chunk=I-NP>*" , NPS ) , build ( "<chunk=B-NP> <pos=PRP> <NP> <pos=PA2> <chunk=B-NP & !pos=SIN> <chunk=I-NP>*" , NPP ) , build ( "<Herr|Frau> <und> <Herr|Frau> <pos=EIG>*" , NPP ) , build ( "<chunk=B-NP & !pos=ZAL & !pos=PLU & !chunk=NPP & !einige & !(regex=&prozent;)> <chunk=I-NP & !pos=PLU & !und>*" , NPS ) , build ( "<chunk=B-NP & !pos=SIN & !chunk=NPS & !Ellen> <chunk=I-NP & !pos=SIN>*" , NPP ) , build ( "<chunk=NPS> <pos=PRO> <pos=ADJ> <pos=ADJ> <NP>" , NPS ) , build ( "<regex=eine[rs]?> <der> <am> <pos=ADJ> <pos=PA2> <NP>" , NPS ) , build ( "<regex=eine[rs]?> <der> <beiden> <pos=ADJ>* <pos=SUB>" , NPS ) , build ( "<regex=eine[rs]?> <seiner|ihrer> <pos=PA1> <pos=SUB>" , NPS ) , build ( "<regex=[\\d,.]+> <&prozent;>" , NPS ) , build ( "<regex=[\\d,.]+> <&prozent;>" , NPP ) , build ( "<dass> <sie> <wie> <NP>" , NPP ) , build ( "<pos=PLU> <die> <Regel>" , NPP ) , build ( "<chunk=B-NP & pos=SIN> <chunk=I-NP & pos=SIN>* <,> <die> <pos=ADV>+ <chunk=NPS>+" , NPS ) , build ( "<chunk=B-NP & pos=PLU> <chunk=I-NP & pos=PLU>* <,> <die> <pos=ADV>+ <chunk=NPS>+" , NPP ) , build ( "<der|die|das> <pos=ADJ> <der> <pos=PA1> <pos=SUB>" , NPS ) , build ( "<pos=SUB & pos=PLU> <der> <pos=PA1> <pos=SUB>" , NPP ) , build ( "<der|die|das> <pos=ADJ> <der> <pos=PRO>? <pos=SUB>" , NPS ) , build ( "<chunk=NPS & !einige> <chunk=NPP & (pos=GEN |pos=ZAL)>+" , NPS , true ) , build ( "<chunk=NPP> <chunk=NPS & pos=GEN>+" , NPP , true ) , build ( "<chunk=NPS>+ <und> <chunk=NP[SP] & pos=GEN>+" , NPS , true ) , build ( "<chunk=NPS>+ <der> <pos=ADV> <pos=PA2> <chunk=I-NP>" , NPS , true ) , build ( "<chunk=NPS>+ <der> (<pos=ADJ>|<pos=ZAL>) <NP>" , NPS , true ) , build ( "<chunk=NPS>+ <der> <NP>" , NPS , true ) , build ( "<chunk=NPS>+ <der> <pos=ADJ> <pos=ADV> <pos=PA2> <NP>" , NPS , true ) , build ( "<chunk=NPS>+ <pos=PRO:POS> <pos=ADJ> <NP>" , NPS , true ) , build ( "<der|das> <pos=ADJ> <der> <pos=ZAL> <NP>" , NPS , true ) , build ( "<eine> <menge> <NP>+" , NPP , true ) , build ( "<er|sie|es> <und> <NP> <NP>" , NPP ) , build ( "<laut> <regex=.*>{0,3} <Quellen>" , PP , true ) , build ( "<pos=PRP> <pos=ART:> <pos=ADV>* <pos=ADJ> <NP>" , PP , true ) , build ( "<pos=PRP> <chunk=NPP>+ <,> <NP>" , PP , true ) , build ( "<pos=PRP> <chunk=NPP>+" , PP , true ) , build ( "<pos=PRP> <NP>" , PP ) , build ( "<pos=PRP> <NP> <pos=ADJ> (<und>|<oder>|<bzw.>) <NP>" , PP ) , build ( "<pos=PRP> (<NP>)+" , PP ) , build ( "<pos=PRP> <chunk=B-NP> <pos=ADV> <NP>" , PP ) , build ( "<pos=PRP> <pos=ADV> <pos=ZAL> <chunk=B-NP>" , PP ) , build ( "<pos=PRP> <pos=PRO> <NP>" , PP ) , build ( "<pos=PRP> <pos=ADJ> (<und|oder|sowie>) <NP>" , PP ) , build ( "<pos=PRP> <pos=ADV> <regex=\\d+> <NP>" , PP ) , build ( "<pos=PRP> <pos=PA1> <NP>" , PP ) , build ( "<pos=PRP> <NP> <NP> (<und|oder>) <NP>" , PP ) , build ( "<pos=PRP> <pos=ADV> <pos=ADJ> <NP>" , PP ) , build ( "<pos=PRP> <pos=ADJ:PRD:GRU> <pos=ZAL> <NP>" , PP ) , build ( "<die> <pos=ADJ> <Sekunden|Minuten|Stunden|Tage|Wochen|Monate|Jahre|Jahrzehnte|Jahrhunderte> (<NP>)?" , PP ) , build ( "<die> <pos=ADJ> <pos=ZAL> <Sekunden|Minuten|Stunden|Tage|Wochen|Monate|Jahre|Jahrzehnte|Jahrhunderte> (<NP>)?" , PP ) , build ( "<regex=(vor)?letzte[sn]?> <Woche|Monat|Jahr|Jahrzehnt|Jahrhundert>" , PP ) , build ( "<für> <in> <pos=EIG> <pos=PA1> <pos=SUB> <und> <pos=SUB>" , PP , true ) , build ( "<chunk=NPP> <zwischen> <pos=EIG> <und|sowie> <NP>" , NPP ) , build ( "<,> <die|welche> <NP> <chunk=NPS & pos=GEN>+" , NPP ) , build ( "<NP> <,> <NP> <,> <NP>" , NPP ) ) ; private static RegularExpressionWithPhraseType build ( String expr , PhraseType phraseType ) { return build ( expr , phraseType , false ) ; } private static RegularExpressionWithPhraseType build ( String expr , PhraseType phraseType , boolean overwrite ) { String expandedExpr = expr ; for ( Map . Entry < String , String > entry : SYNTAX_EXPANSION . entrySet ( ) ) { expandedExpr = expandedExpr . replace ( entry . getKey ( ) , entry . getValue ( ) ) ; } RegularExpression < ChunkTaggedToken > expression = RegularExpression . compile ( expandedExpr , FACTORY ) ; return new RegularExpressionWithPhraseType ( expression , phraseType , overwrite ) ; } public GermanChunker ( ) { } @ Override public void addChunkTags ( List < AnalyzedTokenReadings > tokenReadings ) { List < ChunkTaggedToken > chunkTaggedTokens = getBasicChunks ( tokenReadings ) ; for ( RegularExpressionWithPhraseType regex : REGEXES2 ) { apply ( regex , chunkTaggedTokens ) ; } assignChunksToReadings ( chunkTaggedTokens ) ; } List < ChunkTaggedToken > getBasicChunks ( List < AnalyzedTokenReadings > tokenReadings ) { List < ChunkTaggedToken > chunkTaggedTokens = new ArrayList < > ( ) ; for ( AnalyzedTokenReadings tokenReading : tokenReadings ) { if ( ! tokenReading . isWhitespace ( ) ) { List < ChunkTag > chunkTags = Collections . singletonList ( new ChunkTag ( "O" ) ) ; ChunkTaggedToken chunkTaggedToken = new ChunkTaggedToken ( tokenReading . getToken ( ) , chunkTags , tokenReading ) ; chunkTaggedTokens . add ( chunkTaggedToken ) ; } } if ( debug ) { System . out . println ( "=============== CHUNKER INPUT ===============" ) ; System . out . println ( getDebugString ( chunkTaggedTokens ) ) ; } for ( RegularExpressionWithPhraseType regex : REGEXES1 ) { apply ( regex , chunkTaggedTokens ) ; } return chunkTaggedTokens ; } private void apply ( RegularExpressionWithPhraseType regex , List < ChunkTaggedToken > tokens ) { String prevDebug = getDebugString ( tokens ) ; try { AffectedSpans affectedSpans = doApplyRegex ( regex , tokens ) ; String debug = getDebugString ( tokens ) ; if ( ! debug . equals ( prevDebug ) ) { printDebugInfo ( regex , affectedSpans , debug ) ; } } catch ( Exception e ) { throw new RuntimeException ( "Could not apply chunk regexp '" + regex + "' to tokens: " + tokens , e ) ; } } private void assignChunksToReadings ( List < ChunkTaggedToken > chunkTaggedTokens ) { for ( ChunkTaggedToken taggedToken : chunkTaggedTokens ) { AnalyzedTokenReadings readings = taggedToken . getReadings ( ) ; if ( readings != null ) { readings . setChunkTags ( taggedToken . getChunkTags ( ) ) ; } } } private AffectedSpans doApplyRegex ( RegularExpressionWithPhraseType regex , List < ChunkTaggedToken > tokens ) { List < Match < ChunkTaggedToken > > matches = regex . expression . findAll ( tokens ) ; List < Span > affectedSpans = new ArrayList < > ( ) ; for ( Match < ChunkTaggedToken > match : matches ) { affectedSpans . add ( new Span ( match . startIndex ( ) , match . endIndex ( ) ) ) ; for ( int i = match . startIndex ( ) ; i < match . endIndex ( ) ; i ++ ) { ChunkTaggedToken token = tokens . get ( i ) ; List < ChunkTag > newChunkTags = new ArrayList < > ( ) ; newChunkTags . addAll ( token . getChunkTags ( ) ) ; if ( regex . overwrite ) { List < ChunkTag > filtered = new ArrayList < > ( ) ; for ( ChunkTag newChunkTag : newChunkTags ) { if ( ! FILTER_TAGS . contains ( newChunkTag . getChunkTag ( ) ) ) { filtered . add ( newChunkTag ) ; } } newChunkTags = filtered ; } ChunkTag newTag = getChunkTag ( regex , match , i ) ; if ( ! newChunkTags . contains ( newTag ) ) { newChunkTags . add ( newTag ) ; newChunkTags . remove ( new ChunkTag ( "O" ) ) ; } tokens . set ( i , new ChunkTaggedToken ( token . getToken ( ) , newChunkTags , token . getReadings ( ) ) ) ; } } return new AffectedSpans ( affectedSpans ) ; } private ChunkTag getChunkTag ( RegularExpressionWithPhraseType regex , Match < ChunkTaggedToken > match , int i ) { ChunkTag newTag ; if ( regex . phraseType == NP ) { if ( i == match . startIndex ( ) ) { newTag = new ChunkTag ( "B-NP" ) ; } else { newTag = new ChunkTag ( "I-NP" ) ; } } else { newTag = new ChunkTag ( regex . phraseType . name ( ) ) ; } return newTag ; } private void printDebugInfo ( RegularExpressionWithPhraseType regex , AffectedSpans affectedSpans , String debug ) { System . out . println ( "=== Applied " + regex + " ===" ) ; if ( regex . overwrite ) { System . out . println ( "Note: overwrite mode, replacing old " + FILTER_TAGS + " tags" ) ; } String [ ] debugLines = debug . split ( "\n" ) ; int i = 0 ; for ( String debugLine : debugLines ) { if ( affectedSpans . isAffected ( i ) ) { System . out . println ( debugLine . replaceFirst ( "^ " , " *" ) ) ; } else { System . out . println ( debugLine ) ; } i ++ ; } System . out . println ( ) ; } private String getDebugString ( List < ChunkTaggedToken > tokens ) { if ( ! debug ) { return "" ; } StringBuilder sb = new StringBuilder ( ) ; for ( ChunkTaggedToken token : tokens ) { String tokenReadingStr = token . getReadings ( ) . toString ( ) . replaceFirst ( Pattern . quote ( token . getToken ( ) ) + "\\[" , "[" ) ; sb . append ( " " ) . append ( token ) . append ( " -- " ) . append ( tokenReadingStr ) . append ( "\n" ) ; } return sb . toString ( ) ; } private static class Span { final int startIndex ; final int endIndex ; Span ( int startIndex , int endIndex ) { this . startIndex = startIndex ; this . endIndex = endIndex ; } } private static class AffectedSpans { final List < Span > spans ; AffectedSpans ( List < Span > spans ) { this . spans = spans ; } boolean isAffected ( int pos ) { for ( Span span : spans ) { if ( pos >= span . startIndex && pos < span . endIndex ) { return true ; } } return false ; } } private static class RegularExpressionWithPhraseType { final RegularExpression < ChunkTaggedToken > expression ; final PhraseType phraseType ; final boolean overwrite ; RegularExpressionWithPhraseType ( RegularExpression < ChunkTaggedToken > expression , PhraseType phraseType , boolean overwrite ) { this . expression = expression ; this . phraseType = phraseType ; this . overwrite = overwrite ; } @ Override public String toString ( ) { return phraseType + " <= " + expression + " (overwrite: " + overwrite + ")" ; } } }
package org . languagetool . chunking ; import org . apache . commons . lang . StringUtils ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedTokenReadings ; import java . util . List ; import java . util . Objects ; class ChunkTaggedToken { private final String token ; private final List < ChunkTag > chunkTags ; private final AnalyzedTokenReadings readings ; ChunkTaggedToken ( String token , List < ChunkTag > chunkTags , AnalyzedTokenReadings readings ) { this . token = Objects . requireNonNull ( token ) ; this . chunkTags = Objects . requireNonNull ( chunkTags ) ; this . readings = readings ; } String getToken ( ) { return token ; } List < ChunkTag > getChunkTags ( ) { return chunkTags ; } @ Nullable AnalyzedTokenReadings getReadings ( ) { return readings ; } @ Override public String toString ( ) { return token + '/' + StringUtils . join ( chunkTags , "," ) ; } }
package org . languagetool . synthesis ; public class GermanSynthesizer extends BaseSynthesizer { public GermanSynthesizer ( ) { super ( "/de/german_synth.dict" , "/de/german_tags.txt" ) ; } }
package org . languagetool . tokenizers . ca ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . StringTokenizer ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . JLanguageTool ; import org . languagetool . rules . spelling . morfologik . MorfologikSpeller ; import org . languagetool . tokenizers . WordTokenizer ; public class CatalanWordTokenizer extends WordTokenizer { private static final String PF = "(['’]en|['’]hi|['’]ho|['’]l|['’]ls|['’]m|['’]n|['’]ns|['’]s|['’]t|-el|-els|-em|-en|-ens|-hi|-ho|-l|-la|-les|-li|-lo|-los|-m|-me|-n|-ne|-nos|-s|-se|-t|-te|-us|-vos)" ; private final int maxPatterns = 11 ; private final Pattern [ ] patterns = new Pattern [ maxPatterns ] ; private static final String DICT_FILENAME = "/ca/catalan.dict" ; protected MorfologikSpeller speller ; private static final Pattern ELA_GEMINADA = Pattern . compile ( "([aeiouàéèíóòúïü])l[.\u2022]l([aeiouàéèíóòúïü])" , Pattern . UNICODE_CASE ) ; private static final Pattern ELA_GEMINADA_UPPERCASE = Pattern . compile ( "([AEIOUÀÈÉÍÒÓÚÏÜ])L[.\u2022]L([AEIOUÀÈÉÍÒÓÚÏÜ])" , Pattern . UNICODE_CASE ) ; private static final Pattern APOSTROF_RECTE = Pattern . compile ( "([\\p{L}])'([\\p{L}\"‘“«])" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern APOSTROF_RODO = Pattern . compile ( "([\\p{L}])’([\\p{L}\"‘“«])" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern APOSTROF_RECTE_1 = Pattern . compile ( "([dlDL])'(\\d[\\d\\s\\.,]?)" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern APOSTROF_RODO_1 = Pattern . compile ( "([dlDL])’(\\d[\\d\\s\\.,]?)" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern NEARBY_HYPHENS = Pattern . compile ( "([\\p{L}])-([\\p{L}])-([\\p{L}])" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern HYPHENS = Pattern . compile ( "([\\p{L}])-([\\p{L}\\d])" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern DECIMAL_POINT = Pattern . compile ( "([\\d])\\.([\\d])" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern DECIMAL_COMMA = Pattern . compile ( "([\\d]),([\\d])" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; private static final Pattern SPACE_DIGITS = Pattern . compile ( "([\\d]) ([\\d])" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; public CatalanWordTokenizer ( ) { if ( speller == null ) { if ( JLanguageTool . getDataBroker ( ) . resourceExists ( DICT_FILENAME ) ) { try { speller = new MorfologikSpeller ( DICT_FILENAME ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } } patterns [ 0 ] = Pattern . compile ( "^([lnmtsd]['’])([^'’\\-]*)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; patterns [ 1 ] = Pattern . compile ( "^(qui-sap-lo|qui-sap-la|qui-sap-los|qui-sap-les)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; patterns [ 2 ] = Pattern . compile ( "^([lnmtsd]['’])(.{2,})" + PF + PF + PF + "$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; patterns [ 3 ] = Pattern . compile ( "^(.{2,})" + PF + PF + PF + "$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; patterns [ 4 ] = Pattern . compile ( "^([lnmtsd]['’])(.{2,})" + PF + PF + "$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; patterns [ 5 ] = Pattern . compile ( "^(.{2,})" + PF + PF + "$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; patterns [ 6 ] = Pattern . compile ( "^([lnmtsd]['’])(.{2,})" + PF + "$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; patterns [ 7 ] = Pattern . compile ( "^(.{2,})" + PF + "$" , Pattern . UNICODE_CASE ) ; patterns [ 8 ] = Pattern . compile ( "^([lnmtsd]['’])(.*)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; patterns [ 9 ] = Pattern . compile ( "^(a|de|pe)(ls?)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; patterns [ 10 ] = Pattern . compile ( "^(ca)(n)$" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; } @ Override public List < String > tokenize ( final String text ) { final List < String > l = new ArrayList < > ( ) ; String auxText = text ; Matcher matcher = ELA_GEMINADA . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001ELA_GEMINADA\u0001\u0001$2" ) ; matcher = ELA_GEMINADA_UPPERCASE . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001ELA_GEMINADA_UPPERCASE\u0001\u0001$2" ) ; matcher = APOSTROF_RECTE . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001CA_APOS_RECTE\u0001\u0001$2" ) ; matcher = APOSTROF_RECTE_1 . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001CA_APOS_RECTE\u0001\u0001$2" ) ; matcher = APOSTROF_RODO . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001CA_APOS_RODO\u0001\u0001$2" ) ; matcher = APOSTROF_RODO_1 . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001CA_APOS_RODO\u0001\u0001$2" ) ; matcher = NEARBY_HYPHENS . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001CA_HYPHEN\u0001\u0001$2\u0001\u0001CA_HYPHEN\u0001\u0001$3" ) ; matcher = HYPHENS . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001CA_HYPHEN\u0001\u0001$2" ) ; matcher = DECIMAL_POINT . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001CA_DECIMALPOINT\u0001\u0001$2" ) ; matcher = DECIMAL_COMMA . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001CA_DECIMALCOMMA\u0001\u0001$2" ) ; matcher = SPACE_DIGITS . matcher ( auxText ) ; auxText = matcher . replaceAll ( "$1\u0001\u0001CA_SPACE\u0001\u0001$2" ) ; final StringTokenizer st = new StringTokenizer ( auxText , "\u0020\u00A0\u115f\u1160\u1680" + "\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007" + "\u2008\u2009\u200A\u200B\u200c\u200d\u200e\u200f" + "\u2012\u2013\u2014\u2015\u2022" + "\u2028\u2029\u202a\u202b\u202c\u202d\u202e\u202f" + "\u205F\u2060\u2061\u2062\u2063\u206A\u206b\u206c\u206d" + "\u206E\u206F\u3000\u3164\ufeff\uffa0\ufff9\ufffa\ufffb" + "|,.;()[]{}=*#∗+×÷<>!?:~/\\\"'«»„”“‘’`´…¿¡\t\n\r-" , true ) ; String s ; String groupStr ; while ( st . hasMoreElements ( ) ) { s = st . nextToken ( ) . replace ( "\u0001\u0001CA_APOS_RECTE\u0001\u0001" , "'" ) . replace ( "\u0001\u0001CA_APOS_RODO\u0001\u0001" , "’" ) . replace ( "\u0001\u0001CA_HYPHEN\u0001\u0001" , "-" ) . replace ( "\u0001\u0001CA_DECIMALPOINT\u0001\u0001" , "." ) . replace ( "\u0001\u0001CA_DECIMALCOMMA\u0001\u0001" , "," ) . replace ( "\u0001\u0001CA_SPACE\u0001\u0001" , " " ) . replace ( "\u0001\u0001ELA_GEMINADA\u0001\u0001" , "l.l" ) . replace ( "\u0001\u0001ELA_GEMINADA_UPPERCASE\u0001\u0001" , "L.L" ) ; boolean matchFound = false ; int j = 0 ; while ( j < maxPatterns && ! matchFound ) { matcher = patterns [ j ] . matcher ( s ) ; matchFound = matcher . find ( ) ; j ++ ; } if ( matchFound ) { for ( int i = 1 ; i <= matcher . groupCount ( ) ; i ++ ) { groupStr = matcher . group ( i ) ; l . addAll ( wordsToAdd ( groupStr ) ) ; } } else { l . addAll ( wordsToAdd ( s ) ) ; } } return joinUrls ( l ) ; } private List < String > wordsToAdd ( String s ) { final List < String > l = new ArrayList < > ( ) ; synchronized ( this ) { if ( ! s . isEmpty ( ) ) { if ( ! s . contains ( "-" ) ) { l . add ( s ) ; } else { if ( ! speller . isMisspelled ( s ) ) { l . add ( s ) ; } else if ( ! speller . isMisspelled ( s . replace ( "l-l" , "l·l" ) ) ) { l . add ( s ) ; } else { final StringTokenizer st2 = new StringTokenizer ( s , "-" , true ) ; while ( st2 . hasMoreElements ( ) ) { l . add ( st2 . nextToken ( ) ) ; } } } } return l ; } } }
package org . languagetool . rules . de ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; import org . languagetool . rules . Example ; public class CompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/de/compounds.txt" , "/de/compound-cities.txt" ) ; public CompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "Dieses Wort wird mit Bindestrich geschrieben." , "Dieses Wort wird zusammengeschrieben." , "Dieses Wort wird zusammen oder mit Bindestrich geschrieben." , "Zusammenschreibung von Wörtern" ) ; addExamplePair ( Example . wrong ( "Wenn es schlimmer wird, solltest Du zum <marker>HNO Arzt</marker> gehen." ) , Example . fixed ( "Wenn es schlimmer wird, solltest Du zum <marker>HNO-Arzt</marker> gehen." ) ) ; } @ Override public String getId ( ) { return "DE_COMPOUNDS" ; } @ Override public String getDescription ( ) { return "Zusammenschreibung von Wörtern, z.B. 'CD-ROM' statt 'CD ROM'" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . rules . de ; import org . languagetool . rules . Rule ; public abstract class GermanRule extends Rule { }
package org . languagetool . rules . de ; import org . languagetool . JLanguageTool ; import java . io . * ; import java . util . Collections ; import java . util . HashSet ; import java . util . Set ; final class CaseRuleExceptions { private static final Set < String > exceptions = loadExceptions ( "/de/case_rule_exceptions.txt" ) ; private CaseRuleExceptions ( ) { } public static Set < String > getExceptions ( ) { return exceptions ; } private static Set < String > loadExceptions ( String path ) { Set < String > result = new HashSet < > ( ) ; try ( InputStream stream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( path ) ; InputStreamReader reader = new InputStreamReader ( stream , "utf-8" ) ; BufferedReader br = new BufferedReader ( reader ) ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { if ( line . isEmpty ( ) || line . startsWith ( "#" ) ) { continue ; } if ( line . matches ( "^\\s.*" ) || line . matches ( ".*\\s$" ) ) { throw new RuntimeException ( "Invalid line in " + path + ", starts or ends with whitespace: '" + line + "'" ) ; } result . add ( line ) ; } } catch ( Exception e ) { throw new RuntimeException ( "Could not load case rule exceptions from " + path , e ) ; } return Collections . unmodifiableSet ( result ) ; } }
package org . languagetool . rules . de ; import java . util . Arrays ; import java . util . HashSet ; import java . util . ResourceBundle ; import java . util . Set ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . Example ; import org . languagetool . rules . WordRepeatBeginningRule ; public class GermanWordRepeatBeginningRule extends WordRepeatBeginningRule { public GermanWordRepeatBeginningRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; addExamplePair ( Example . wrong ( "Dann hatten wir Freizeit. Dann gab es Essen. <marker>Dann</marker> gingen wir schlafen." ) , Example . fixed ( "Dann hatten wir Freizeit. Danach gab es Essen. <marker>Schließlich</marker> gingen wir schlafen." ) ) ; } @ Override public String getId ( ) { return "GERMAN_WORD_REPEAT_BEGINNING_RULE" ; } private static final Set < String > ADVERBS = new HashSet < > ( Arrays . asList ( "Auch" , "Anschließend" , "Außerdem" , "Danach" , "Ferner" , "Nebenher" , "Nebenbei" , "Überdies" , "Weiterführend" , "Zudem" , "Zusätzlich" ) ) ; @ Override protected boolean isAdverb ( final AnalyzedTokenReadings token ) { return ADVERBS . contains ( token . getToken ( ) ) ; } }
package org . languagetool . rules . de ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . RuleMatch ; public class WiederVsWiderRule extends GermanRule { public WiederVsWiderRule ( ResourceBundle messages ) { super . setCategory ( new Category ( messages . getString ( "category_typo" ) ) ) ; addExamplePair ( Example . wrong ( "Das spiegelt die Situation in Deutschland <marker>wieder</marker>." ) , Example . fixed ( "Das spiegelt die Situation in Deutschland <marker>wider</marker>." ) ) ; } @ Override public String getId ( ) { return "DE_WIEDER_VS_WIDER" ; } @ Override public String getDescription ( ) { return "Möglicher Tippfehler 'spiegeln ... wieder(wider)'" ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; boolean foundSpiegelt = false ; boolean foundWieder = false ; boolean foundWider = false ; for ( int i = 0 ; i < tokens . length ; i ++ ) { final String token = tokens [ i ] . getToken ( ) ; if ( token . equalsIgnoreCase ( "spiegelt" ) || token . equalsIgnoreCase ( "spiegeln" ) || token . equalsIgnoreCase ( "spiegelte" ) || token . equalsIgnoreCase ( "spiegelten" ) || token . equalsIgnoreCase ( "spiegelst" ) ) { foundSpiegelt = true ; } else if ( token . equalsIgnoreCase ( "wieder" ) && foundSpiegelt ) { foundWieder = true ; } else if ( token . equalsIgnoreCase ( "wider" ) && foundSpiegelt ) { foundWider = true ; } if ( foundSpiegelt && foundWieder && ! foundWider && ! ( tokens . length > i + 2 && ( tokens [ i + 1 ] . getToken ( ) . equals ( "wider" ) || tokens [ i + 2 ] . getToken ( ) . equals ( "wider" ) ) ) ) { final String msg = "'wider' in 'widerspiegeln' wird mit 'i' statt mit 'ie' " + "geschrieben, z.B. 'Das spiegelt die Situation gut wider.'" ; final String shortMsg = "'wider' in 'widerspiegeln' wird mit 'i' geschrieben" ; final int pos = tokens [ i ] . getStartPos ( ) ; final RuleMatch ruleMatch = new RuleMatch ( this , pos , pos + token . length ( ) , msg , shortMsg ) ; ruleMatch . setSuggestedReplacement ( "wider" ) ; ruleMatches . add ( ruleMatch ) ; foundSpiegelt = false ; foundWieder = false ; foundWider = false ; } } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . de ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . language . German ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tagging . de . GermanTagger ; import org . languagetool . tagging . de . GermanToken ; import org . languagetool . tagging . de . GermanToken . POSType ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . net . MalformedURLException ; import java . net . URL ; import java . util . * ; import java . util . regex . Pattern ; public class CaseRule extends GermanRule { private static final Pattern NUMERALS_EN = Pattern . compile ( "[a-z]|[0-9]+|(m{0,4}(cm|cd|d?c{0,3})(xc|xl|l?x{0,3})(ix|iv|v?i{0,3}))$" ) ; private static final Set < String > nounIndicators = new HashSet < > ( ) ; static { nounIndicators . add ( "das" ) ; nounIndicators . add ( "sein" ) ; nounIndicators . add ( "mein" ) ; nounIndicators . add ( "dein" ) ; nounIndicators . add ( "euer" ) ; nounIndicators . add ( "unser" ) ; } private static final Set < String > sentenceStartExceptions = new HashSet < > ( ) ; static { sentenceStartExceptions . add ( "(" ) ; sentenceStartExceptions . add ( ":" ) ; sentenceStartExceptions . add ( "\"" ) ; sentenceStartExceptions . add ( "'" ) ; sentenceStartExceptions . add ( "„" ) ; sentenceStartExceptions . add ( "“" ) ; sentenceStartExceptions . add ( "«" ) ; sentenceStartExceptions . add ( "»" ) ; sentenceStartExceptions . add ( "." ) ; } private static final Set < String > exceptions = new HashSet < > ( Arrays . asList ( "Dienstreisender" , "Verletzte" , "Vermisste" , "Äußeres" , "Abseits" , "Beschäftigter" , "Beschäftigte" , "Beschäftigten" , "Üblichen" , "Bekannter" , "Bekannte" , "Tel" , "Unschuldiger" , "Vorgesetzter" , "Abs" , "Klappe" , "Vorfahre" , "Mittler" , "Hr" , "Schwarz" , "Genese" , "Rosa" , "Auftrieb" , "Zuschnitt" , "Geschossen" , "Vortrieb" , "Abtrieb" , "Gesandter" , "Durchfahrt" , "Durchgriff" , "Überfahrt" , "Zeche" , "Sparte" , "Sparten" , "Heiliger" , "Reisender" , "Hochdeutsch" , "Pest" , "Schwinge" , "Verlies" , "Nachfolge" , "Stift" , "Belange" , "Geistlicher" , "Jenseits" , "Abends" , "Abgeordneter" , "Angestellter" , "Liberaler" , "Abriss" , "Ahne" , "Ähnlichem" , "Ähnliches" , "Allerlei" , "Anklang" , "Anstrich" , "Armes" , "Aus" , "Ausdrücke" , "Auswüchsen" , "Bände" , "Bänden" , "Beauftragter" , "Belange" , "besonderes" , "Biss" , "De" , "Dr" , "Durcheinander" , "Eindrücke" , "Erwachsener" , "Flöße" , "Folgendes" , "Fort" , "Fraß" , "Für" , "Genüge" , "Gläubiger" , "Goldener" , "Guten" , "Hechte" , "Herzöge" , "Herzögen" , "Hinfahrt" , "Hundert" , "Ihnen" , "Ihr" , "Ihre" , "Ihrem" , "Ihren" , "Ihrer" , "Ihres" , "Infrarot" , "Jenseits" , "Jugendlicher" , "Jünger" , "Klaue" , "Konditional" , "Krähe" , "Kurzem" , "Landwirtschaft" , "Langem" , "Längerem" , "Le" , "Letzt" , "Letzt" , "Letztere" , "Letzterer" , "Letzteres" , "Link" , "Links" , "Löhne" , "Luden" , "Mitfahrt" , "Mr" , "Mrd" , "Mrs" , "Nachfrage" , "Nachts" , "Nähte" , "Nähten" , "Neuem" , "Nr" , "Nutze" , "Obdachloser" , "Oder" , "Patsche" , "Pfiffe" , "Pfiffen" , "Prof" , "Puste" , "Sachverständiger" , "Sankt" , "Scheine" , "Scheiße" , "Schuft" , "Schufte" , "Schuld" , "Schwärme" , "Schwarzes" , "Sie" , "Spitz" , "St" , "Stereotyp" , "Störe" , "Tausend" , "Toter" , "tun" , "Übrigen" , "Unvorhergesehenes" , "Verantwortlicher" , "Verwandter" , "Vielfaches" , "Vorsitzender" , "Fraktionsvorsitzender" , "Weitem" , "Weiteres" , "Wicht" , "Wichtiges" , "Wider" , "Wild" , "Zeche" , "Zusage" , "Zwinge" , "Tertiär" , "Erster" , "Zweiter" , "Dritter" , "Vierter" , "Fünfter" , "Sechster" , "Siebter" , "Achter" , "Neunter" , "Erste" , "Zweite" , "Dritte" , "Vierte" , "Fünfte" , "Sechste" , "Siebte" , "Achte" , "Neunte" , "Dein" , "Deine" , "Deinem" , "Deinen" , "Deiner" , "Deines" , "Dich" , "Dir" , "Du" , "Euch" , "Euer" , "Eure" , "Eurem" , "Euren" , "Eures" ) ) ; private static final Set < String > languages = new HashSet < > ( ) ; static { languages . add ( "Afrikanisch" ) ; languages . add ( "Altarabisch" ) ; languages . add ( "Altchinesisch" ) ; languages . add ( "Altgriechisch" ) ; languages . add ( "Althochdeutsch" ) ; languages . add ( "Altpersisch" ) ; languages . add ( "Amerikanisch" ) ; languages . add ( "Arabisch" ) ; languages . add ( "Chinesisch" ) ; languages . add ( "Dänisch" ) ; languages . add ( "Deutsch" ) ; languages . add ( "Englisch" ) ; languages . add ( "Finnisch" ) ; languages . add ( "Französisch" ) ; languages . add ( "Frühneuhochdeutsch" ) ; languages . add ( "Germanisch" ) ; languages . add ( "Griechisch" ) ; languages . add ( "Hocharabisch" ) ; languages . add ( "Hochchinesisch" ) ; languages . add ( "Hochdeutsch" ) ; languages . add ( "Holländisch" ) ; languages . add ( "Italienisch" ) ; languages . add ( "Japanisch" ) ; languages . add ( "Jiddisch" ) ; languages . add ( "Jugoslawisch" ) ; languages . add ( "Koreanisch" ) ; languages . add ( "Kroatisch" ) ; languages . add ( "Lateinisch" ) ; languages . add ( "Luxemburgisch" ) ; languages . add ( "Mittelhochdeutsch" ) ; languages . add ( "Neuhochdeutsch" ) ; languages . add ( "Niederländisch" ) ; languages . add ( "Norwegisch" ) ; languages . add ( "Persisch" ) ; languages . add ( "Polnisch" ) ; languages . add ( "Portugiesisch" ) ; languages . add ( "Russisch" ) ; languages . add ( "Schwedisch" ) ; languages . add ( "Schweizerisch" ) ; languages . add ( "Serbisch" ) ; languages . add ( "Serbokroatisch" ) ; languages . add ( "Slawisch" ) ; languages . add ( "Spanisch" ) ; languages . add ( "Tschechisch" ) ; languages . add ( "Türkisch" ) ; languages . add ( "Ukrainisch" ) ; languages . add ( "Ungarisch" ) ; languages . add ( "Weißrussisch" ) ; } private static final Set < String > myExceptionPhrases = CaseRuleExceptions . getExceptions ( ) ; private static final Set < String > substVerbenExceptions = new HashSet < > ( ) ; static { substVerbenExceptions . add ( "hinziehen" ) ; substVerbenExceptions . add ( "helfen" ) ; substVerbenExceptions . add ( "lassen" ) ; substVerbenExceptions . add ( "passieren" ) ; substVerbenExceptions . add ( "machen" ) ; substVerbenExceptions . add ( "haben" ) ; substVerbenExceptions . add ( "passiert" ) ; substVerbenExceptions . add ( "beschränkt" ) ; substVerbenExceptions . add ( "wiederholt" ) ; substVerbenExceptions . add ( "scheinen" ) ; substVerbenExceptions . add ( "klar" ) ; substVerbenExceptions . add ( "heißen" ) ; substVerbenExceptions . add ( "einen" ) ; substVerbenExceptions . add ( "gehören" ) ; substVerbenExceptions . add ( "bedeutet" ) ; substVerbenExceptions . add ( "ermöglicht" ) ; substVerbenExceptions . add ( "funktioniert" ) ; substVerbenExceptions . add ( "sollen" ) ; substVerbenExceptions . add ( "werden" ) ; substVerbenExceptions . add ( "dürfen" ) ; substVerbenExceptions . add ( "müssen" ) ; substVerbenExceptions . add ( "so" ) ; substVerbenExceptions . add ( "ist" ) ; substVerbenExceptions . add ( "können" ) ; substVerbenExceptions . add ( "mein" ) ; substVerbenExceptions . add ( "sein" ) ; substVerbenExceptions . add ( "muss" ) ; substVerbenExceptions . add ( "muß" ) ; substVerbenExceptions . add ( "wollen" ) ; substVerbenExceptions . add ( "habe" ) ; substVerbenExceptions . add ( "ein" ) ; substVerbenExceptions . add ( "tun" ) ; substVerbenExceptions . add ( "bestätigt" ) ; substVerbenExceptions . add ( "bestätigte" ) ; substVerbenExceptions . add ( "bestätigten" ) ; substVerbenExceptions . add ( "bekommen" ) ; substVerbenExceptions . add ( "sauer" ) ; } private final GermanTagger tagger ; public CaseRule ( final ResourceBundle messages , final German german ) { super . setCategory ( new Category ( messages . getString ( "category_case" ) ) ) ; this . tagger = ( GermanTagger ) german . getTagger ( ) ; addExamplePair ( Example . wrong ( "<marker>Das laufen</marker> fällt mir schwer." ) , Example . fixed ( "<marker>Das Laufen</marker> fällt mir schwer." ) ) ; } @ Override public String getId ( ) { return "DE_CASE" ; } @ Override public URL getUrl ( ) { try { return new URL ( "http://www.canoo.net/services/GermanSpelling/Regeln/Gross-klein/index.html" ) ; } catch ( MalformedURLException e ) { throw new RuntimeException ( e ) ; } } @ Override public String getDescription ( ) { return "Großschreibung von Nomen und substantivierten Verben" ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) throws IOException { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; boolean prevTokenIsDas = false ; for ( int i = 0 ; i < tokens . length ; i ++ ) { final String posToken = tokens [ i ] . getAnalyzedToken ( 0 ) . getPOSTag ( ) ; if ( posToken != null && posToken . equals ( JLanguageTool . SENTENCE_START_TAGNAME ) ) { continue ; } if ( i == 1 ) { if ( nounIndicators . contains ( tokens [ 1 ] . getToken ( ) . toLowerCase ( ) ) ) { prevTokenIsDas = true ; } continue ; } if ( i > 0 && isSalutation ( tokens [ i - 1 ] . getToken ( ) ) ) { continue ; } final AnalyzedTokenReadings analyzedToken = tokens [ i ] ; final String token = analyzedToken . getToken ( ) ; boolean isBaseform = analyzedToken . getReadingsLength ( ) >= 1 && analyzedToken . hasLemma ( token ) ; if ( ( analyzedToken . getAnalyzedToken ( 0 ) . getPOSTag ( ) == null || GermanHelper . hasReadingOfType ( analyzedToken , GermanToken . POSType . VERB ) ) && isBaseform ) { boolean nextTokenIsPersonalPronoun = false ; if ( i < tokens . length - 1 ) { nextTokenIsPersonalPronoun = tokens [ i + 1 ] . hasPartialPosTag ( "PRO:PER" ) || tokens [ i + 1 ] . getToken ( ) . equals ( "Sie" ) ; if ( tokens [ i + 1 ] . hasLemma ( "lassen" ) ) { continue ; } if ( tokens [ i + 1 ] . isSentenceEnd ( ) ) { continue ; } } if ( isPrevProbablyRelativePronoun ( tokens , i ) ) { continue ; } potentiallyAddLowercaseMatch ( ruleMatches , tokens [ i ] , prevTokenIsDas , token , nextTokenIsPersonalPronoun ) ; } prevTokenIsDas = nounIndicators . contains ( tokens [ i ] . getToken ( ) . toLowerCase ( ) ) ; if ( hasNounReading ( analyzedToken ) ) { continue ; } AnalyzedTokenReadings lowercaseReadings = tagger . lookup ( token . toLowerCase ( ) ) ; if ( analyzedToken . getAnalyzedToken ( 0 ) . getPOSTag ( ) == null && lowercaseReadings == null ) { continue ; } if ( analyzedToken . getAnalyzedToken ( 0 ) . getPOSTag ( ) == null && lowercaseReadings != null && lowercaseReadings . getAnalyzedToken ( 0 ) . getPOSTag ( ) == null ) { continue ; } potentiallyAddUppercaseMatch ( ruleMatches , tokens , i , analyzedToken , token ) ; } return toRuleMatchArray ( ruleMatches ) ; } private boolean isPrevProbablyRelativePronoun ( AnalyzedTokenReadings [ ] tokens , int i ) { if ( i >= 3 ) { AnalyzedTokenReadings prev1 = tokens [ i - 1 ] ; AnalyzedTokenReadings prev2 = tokens [ i - 2 ] ; AnalyzedTokenReadings prev3 = tokens [ i - 3 ] ; if ( prev1 . getToken ( ) . equals ( "das" ) && prev2 . getToken ( ) . equals ( "," ) && prev3 . matchesPosTagRegex ( "SUB:...:SIN:NEU" ) ) { return true ; } } return false ; } private boolean isSalutation ( String token ) { return token . equals ( "Herr" ) || token . equals ( "Herrn" ) || token . equals ( "Frau" ) ; } private boolean hasNounReading ( AnalyzedTokenReadings readings ) { try { AnalyzedTokenReadings allReadings = tagger . lookup ( readings . getToken ( ) ) ; if ( allReadings != null ) { for ( AnalyzedToken reading : allReadings ) { String posTag = reading . getPOSTag ( ) ; if ( posTag != null && posTag . contains ( "SUB:" ) && ! posTag . contains ( ":ADJ" ) ) { return true ; } } } } catch ( IOException e ) { throw new RuntimeException ( "Could not lookup " + readings . getToken ( ) , e ) ; } return false ; } private void potentiallyAddLowercaseMatch ( List < RuleMatch > ruleMatches , AnalyzedTokenReadings tokenReadings , boolean prevTokenIsDas , String token , boolean nextTokenIsPersonalPronoun ) { if ( prevTokenIsDas && ! nextTokenIsPersonalPronoun ) { if ( Character . isLowerCase ( token . charAt ( 0 ) ) && ! substVerbenExceptions . contains ( token ) && tokenReadings . hasPartialPosTag ( "VER:INF" ) && ! tokenReadings . isIgnoredBySpeller ( ) ) { final String msg = "Substantivierte Verben werden großgeschrieben." ; final RuleMatch ruleMatch = new RuleMatch ( this , tokenReadings . getStartPos ( ) , tokenReadings . getEndPos ( ) , msg ) ; final String word = tokenReadings . getToken ( ) ; final String fixedWord = StringTools . uppercaseFirstChar ( word ) ; ruleMatch . setSuggestedReplacement ( fixedWord ) ; ruleMatches . add ( ruleMatch ) ; } } } private void potentiallyAddUppercaseMatch ( List < RuleMatch > ruleMatches , AnalyzedTokenReadings [ ] tokens , int i , AnalyzedTokenReadings analyzedToken , String token ) { if ( Character . isUpperCase ( token . charAt ( 0 ) ) && token . length ( ) > 1 && ! tokens [ i ] . isIgnoredBySpeller ( ) && ! sentenceStartExceptions . contains ( tokens [ i - 1 ] . getToken ( ) ) && ! exceptions . contains ( token ) && ! StringTools . isAllUppercase ( token ) && ! isLanguage ( i , tokens ) && ! isProbablyCity ( i , tokens ) && ! GermanHelper . hasReadingOfType ( analyzedToken , POSType . PROPER_NOUN ) && ! analyzedToken . isSentenceEnd ( ) && ! isEllipsis ( i , tokens ) && ! isNumbering ( i , tokens ) && ! isNominalization ( i , tokens ) && ! isAdverbAndNominalization ( i , tokens ) && ! isSpecialCase ( i , tokens ) && ! isAdjectiveAsNoun ( i , tokens ) && ! isExceptionPhrase ( i , tokens ) ) { final String msg = "Außer am Satzanfang werden nur Nomen und Eigennamen großgeschrieben" ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ i ] . getStartPos ( ) , tokens [ i ] . getEndPos ( ) , msg ) ; final String word = tokens [ i ] . getToken ( ) ; final String fixedWord = Character . toLowerCase ( word . charAt ( 0 ) ) + word . substring ( 1 ) ; ruleMatch . setSuggestedReplacement ( fixedWord ) ; ruleMatches . add ( ruleMatch ) ; } } private boolean isNumbering ( int i , AnalyzedTokenReadings [ ] tokens ) { return i >= 2 && ( tokens [ i - 1 ] . getToken ( ) . equals ( ")" ) || tokens [ i - 1 ] . getToken ( ) . equals ( "]" ) ) && NUMERALS_EN . matcher ( tokens [ i - 2 ] . getToken ( ) ) . matches ( ) ; } private boolean isEllipsis ( int i , AnalyzedTokenReadings [ ] tokens ) { return ( tokens [ i - 1 ] . getToken ( ) . equals ( "]" ) || tokens [ i - 1 ] . getToken ( ) . equals ( ")" ) ) && ( ( i == 4 && tokens [ i - 2 ] . getToken ( ) . equals ( "…" ) ) || ( i == 6 && tokens [ i - 2 ] . getToken ( ) . equals ( "." ) ) ) ; } private boolean isNominalization ( int i , AnalyzedTokenReadings [ ] tokens ) { String token = tokens [ i ] . getToken ( ) ; AnalyzedTokenReadings nextReadings = i < tokens . length - 1 ? tokens [ i + 1 ] : null ; if ( StringTools . startsWithUppercase ( token ) && ! isNumber ( token ) && ! hasNounReading ( nextReadings ) && ! token . matches ( "Alle[nm]" ) ) { AnalyzedTokenReadings prevToken = i > 0 ? tokens [ i - 1 ] : null ; AnalyzedTokenReadings prevPrevToken = i >= 2 ? tokens [ i - 2 ] : null ; AnalyzedTokenReadings prevPrevPrevToken = i >= 3 ? tokens [ i - 3 ] : null ; return ( prevToken != null && ( "irgendwas" . equals ( prevToken . getToken ( ) ) || "aufs" . equals ( prevToken . getToken ( ) ) ) ) || hasPartialTag ( prevToken , "PRO" ) || ( hasPartialTag ( prevPrevToken , "PRO" , "PRP" ) && hasPartialTag ( prevToken , "ADJ" , "ADV" , "PA2" ) ) || ( hasPartialTag ( prevPrevPrevToken , "PRO" , "PRP" ) && hasPartialTag ( prevPrevToken , "ADJ" , "ADV" ) && hasPartialTag ( prevToken , "ADJ" , "ADV" , "PA2" ) ) ; } return false ; } private boolean isNumber ( String token ) { try { AnalyzedTokenReadings lookup = tagger . lookup ( StringTools . lowercaseFirstChar ( token ) ) ; return lookup != null && lookup . hasPosTag ( "ZAL" ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } private boolean isAdverbAndNominalization ( int i , AnalyzedTokenReadings [ ] tokens ) { String prevPrevToken = i > 1 ? tokens [ i - 2 ] . getToken ( ) : "" ; AnalyzedTokenReadings prevToken = i > 0 ? tokens [ i - 1 ] : null ; String token = tokens [ i ] . getToken ( ) ; AnalyzedTokenReadings nextReadings = i < tokens . length - 1 ? tokens [ i + 1 ] : null ; return "das" . equalsIgnoreCase ( prevPrevToken ) && hasPartialTag ( prevToken , "ADV" ) && StringTools . startsWithUppercase ( token ) && ! hasNounReading ( nextReadings ) ; } private boolean hasPartialTag ( AnalyzedTokenReadings token , String ... posTags ) { if ( token != null ) { for ( String posTag : posTags ) { if ( token . hasPartialPosTag ( posTag ) ) { return true ; } } } return false ; } private boolean isSpecialCase ( int i , AnalyzedTokenReadings [ ] tokens ) { String prevToken = i > 1 ? tokens [ i - 1 ] . getToken ( ) : "" ; String token = tokens [ i ] . getToken ( ) ; AnalyzedTokenReadings nextReadings = i < tokens . length - 1 ? tokens [ i + 1 ] : null ; return "im" . equalsIgnoreCase ( prevToken ) && "Allgemeinen" . equals ( token ) && ! hasNounReading ( nextReadings ) ; } private boolean isAdjectiveAsNoun ( int i , AnalyzedTokenReadings [ ] tokens ) { AnalyzedTokenReadings prevToken = i > 0 ? tokens [ i - 1 ] : null ; boolean isPrevDeterminer = prevToken != null && ( prevToken . hasPartialPosTag ( "ART" ) || prevToken . hasPartialPosTag ( "PRP" ) ) ; if ( ! isPrevDeterminer ) { return false ; } AnalyzedTokenReadings nextReadings = i < tokens . length - 1 ? tokens [ i + 1 ] : null ; for ( AnalyzedToken reading : tokens [ i ] . getReadings ( ) ) { String posTag = reading . getPOSTag ( ) ; if ( posTag != null && posTag . contains ( ":ADJ" ) && ! hasNounReading ( nextReadings ) ) { return true ; } } return false ; } private boolean isLanguage ( int i , AnalyzedTokenReadings [ ] tokens ) { String token = tokens [ i ] . getToken ( ) ; boolean maybeLanguage = languages . contains ( token ) || languages . contains ( token . replaceFirst ( "e$" , "" ) ) || languages . contains ( token . replaceFirst ( "en$" , "" ) ) ; AnalyzedTokenReadings prevToken = i > 0 ? tokens [ i - 1 ] : null ; AnalyzedTokenReadings nextReadings = i < tokens . length - 1 ? tokens [ i + 1 ] : null ; return maybeLanguage && ( ( nextReadings != null && ! hasNounReading ( nextReadings ) ) || ( prevToken != null && prevToken . getToken ( ) . equals ( "auf" ) ) ) ; } private boolean isProbablyCity ( int i , AnalyzedTokenReadings [ ] tokens ) { String token = tokens [ i ] . getToken ( ) ; boolean hasCityPrefix = "Klein" . equals ( token ) || "Groß" . equals ( token ) || "Neu" . equals ( token ) ; if ( hasCityPrefix ) { AnalyzedTokenReadings nextReadings = i < tokens . length - 1 ? tokens [ i + 1 ] : null ; return nextReadings != null && ( ! nextReadings . isTagged ( ) || nextReadings . hasPartialPosTag ( "EIG" ) ) ; } return false ; } private boolean isExceptionPhrase ( int i , AnalyzedTokenReadings [ ] tokens ) { for ( String exc : myExceptionPhrases ) { final String [ ] parts = exc . split ( " " ) ; for ( int j = 0 ; j < parts . length ; j ++ ) { if ( parts [ j ] . equals ( tokens [ i ] . getToken ( ) ) ) { final int startIndex = i - j ; if ( compareLists ( tokens , startIndex , startIndex + parts . length - 1 , parts ) ) { return true ; } } } } return false ; } boolean compareLists ( AnalyzedTokenReadings [ ] tokens , int startIndex , int endIndex , String [ ] parts ) { if ( startIndex < 0 ) { return false ; } int i = 0 ; for ( int j = startIndex ; j <= endIndex ; j ++ ) { if ( i >= parts . length || j >= tokens . length ) { return false ; } if ( ! tokens [ j ] . getToken ( ) . equals ( parts [ i ] ) ) { return false ; } i ++ ; } return true ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . de ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . language . German ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tagging . de . AnalyzedGermanToken ; import org . languagetool . tagging . de . GermanToken ; import org . languagetool . tagging . de . GermanToken . POSType ; import org . languagetool . tools . StringTools ; import java . util . * ; public class AgreementRule extends GermanRule { private final German language ; private enum GrammarCategory { KASUS ( "Kasus (Fall: Wer/Was, Wessen, Wem, Wen/Was - Beispiel: 'das Fahrrads' statt 'des Fahrrads')" ) , GENUS ( "Genus (männlich, weiblich, sächlich - Beispiel: 'der Fahrrad' statt 'das Fahrrad')" ) , NUMERUS ( "Numerus (Einzahl, Mehrzahl - Beispiel: 'das Fahrräder' statt 'die Fahrräder')" ) ; private final String displayName ; GrammarCategory ( String displayName ) { this . displayName = displayName ; } } private static final Set < String > VIELE_WENIGE_LOWERCASE = new HashSet < > ( Arrays . asList ( "viele" , "vieler" , "wenige" , "weniger" , "einige" , "einiger" , "mehrerer" , "mehrere" ) ) ; private static final Set < String > REL_PRONOUN = new HashSet < > ( ) ; static { REL_PRONOUN . add ( "der" ) ; REL_PRONOUN . add ( "die" ) ; REL_PRONOUN . add ( "das" ) ; REL_PRONOUN . add ( "dessen" ) ; REL_PRONOUN . add ( "deren" ) ; REL_PRONOUN . add ( "dem" ) ; REL_PRONOUN . add ( "den" ) ; REL_PRONOUN . add ( "denen" ) ; REL_PRONOUN . add ( "welche" ) ; REL_PRONOUN . add ( "welcher" ) ; REL_PRONOUN . add ( "welchen" ) ; REL_PRONOUN . add ( "welchem" ) ; REL_PRONOUN . add ( "welches" ) ; } private static final Set < String > PREPOSITIONS = new HashSet < > ( ) ; static { PREPOSITIONS . add ( "in" ) ; PREPOSITIONS . add ( "auf" ) ; PREPOSITIONS . add ( "an" ) ; PREPOSITIONS . add ( "ab" ) ; PREPOSITIONS . add ( "für" ) ; PREPOSITIONS . add ( "zu" ) ; PREPOSITIONS . add ( "bei" ) ; PREPOSITIONS . add ( "nach" ) ; PREPOSITIONS . add ( "über" ) ; PREPOSITIONS . add ( "von" ) ; PREPOSITIONS . add ( "mit" ) ; PREPOSITIONS . add ( "durch" ) ; } private static final Set < String > PRONOUNS_TO_BE_IGNORED = new HashSet < > ( Arrays . asList ( "ich" , "dir" , "du" , "er" , "sie" , "es" , "wir" , "mir" , "uns" , "ihnen" , "euch" , "ihm" , "ihr" , "ihn" , "dessen" , "deren" , "denen" , "sich" , "unser" , "aller" , "man" , "beide" , "beiden" , "beider" , "wessen" , "a" , "alle" , "etwas" , "was" , "wer" , "jenen" , "diejenigen" , "jemand" , "niemand" ) ) ; private static final Set < String > NOUNS_TO_BE_IGNORED = new HashSet < > ( Arrays . asList ( "Prozent" , "Gramm" , "Kilogramm" , "Uhr" ) ) ; public AgreementRule ( final ResourceBundle messages , German language ) { this . language = language ; super . setCategory ( new Category ( messages . getString ( "category_grammar" ) ) ) ; addExamplePair ( Example . wrong ( "<marker>Der Haus</marker> wurde letztes Jahr gebaut." ) , Example . fixed ( "<marker>Das Haus</marker> wurde letztes Jahr gebaut" ) ) ; } @ Override public String getId ( ) { return "DE_AGREEMENT" ; } @ Override public String getDescription ( ) { return "Kongruenz von Nominalphrasen (unvollständig!), z.B. 'mein kleiner(kleines) Haus'" ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; for ( int i = 0 ; i < tokens . length ; i ++ ) { final String posToken = tokens [ i ] . getAnalyzedToken ( 0 ) . getPOSTag ( ) ; if ( posToken != null && posToken . equals ( JLanguageTool . SENTENCE_START_TAGNAME ) ) { continue ; } if ( tokens [ i ] . isImmunized ( ) ) { continue ; } final AnalyzedTokenReadings tokenReadings = tokens [ i ] ; final boolean relevantPronoun = isRelevantPronoun ( tokens , i ) ; boolean ignore = couldBeRelativeClause ( tokens , i ) ; if ( i > 0 ) { final String prevToken = tokens [ i - 1 ] . getToken ( ) . toLowerCase ( ) ; if ( ( tokens [ i ] . getToken ( ) . equals ( "eine" ) || tokens [ i ] . getToken ( ) . equals ( "einen" ) ) && ( prevToken . equals ( "der" ) || prevToken . equals ( "die" ) || prevToken . equals ( "das" ) || prevToken . equals ( "des" ) || prevToken . equals ( "dieses" ) ) ) { ignore = true ; } } if ( tokenReadings . getToken ( ) . equals ( "nichts" ) || tokenReadings . getToken ( ) . equals ( "alles" ) || tokenReadings . getToken ( ) . equals ( "dies" ) ) { ignore = true ; } boolean detAbbrev = i < tokens . length - 2 && tokens [ i + 1 ] . getToken ( ) . equals ( "Art" ) && tokens [ i + 2 ] . getToken ( ) . equals ( "." ) ; boolean detAdjAbbrev = i < tokens . length - 3 && tokens [ i + 2 ] . getToken ( ) . equals ( "Art" ) && tokens [ i + 3 ] . getToken ( ) . equals ( "." ) ; boolean followingParticiple = i < tokens . length - 3 && ( tokens [ i + 2 ] . hasPartialPosTag ( "PA1" ) || tokens [ i + 2 ] . getToken ( ) . matches ( "zugeschriebenen?|genannten?" ) ) ; if ( detAbbrev || detAdjAbbrev || followingParticiple ) { ignore = true ; } if ( ( GermanHelper . hasReadingOfType ( tokenReadings , POSType . DETERMINER ) || relevantPronoun ) && ! ignore ) { int tokenPos = i + 1 ; if ( tokenPos >= tokens . length ) { break ; } AnalyzedTokenReadings nextToken = tokens [ tokenPos ] ; if ( isNonPredicativeAdjective ( nextToken ) || isParticiple ( nextToken ) ) { tokenPos = i + 2 ; if ( tokenPos >= tokens . length ) { break ; } if ( GermanHelper . hasReadingOfType ( tokens [ tokenPos ] , POSType . NOMEN ) ) { if ( i >= 2 && GermanHelper . hasReadingOfType ( tokens [ i - 2 ] , POSType . ADJEKTIV ) && "als" . equals ( tokens [ i - 1 ] . getToken ( ) ) && "das" . equals ( tokens [ i ] . getToken ( ) ) ) { continue ; } final RuleMatch ruleMatch = checkDetAdjNounAgreement ( tokens [ i ] , nextToken , tokens [ i + 2 ] ) ; if ( ruleMatch != null ) { ruleMatches . add ( ruleMatch ) ; } } } else if ( GermanHelper . hasReadingOfType ( nextToken , POSType . NOMEN ) && ! "Herr" . equals ( nextToken . getToken ( ) ) ) { final RuleMatch ruleMatch = checkDetNounAgreement ( tokens [ i ] , tokens [ i + 1 ] ) ; if ( ruleMatch != null ) { ruleMatches . add ( ruleMatch ) ; } } } } return toRuleMatchArray ( ruleMatches ) ; } private boolean isNonPredicativeAdjective ( AnalyzedTokenReadings tokensReadings ) { for ( AnalyzedToken reading : tokensReadings . getReadings ( ) ) { String posTag = reading . getPOSTag ( ) ; if ( posTag != null && posTag . startsWith ( "ADJ:" ) && ! posTag . contains ( "PRD" ) ) { return true ; } } return false ; } private boolean isParticiple ( AnalyzedTokenReadings tokensReadings ) { return tokensReadings . hasPartialPosTag ( "PA1" ) || tokensReadings . hasPartialPosTag ( "PA2" ) ; } private boolean isRelevantPronoun ( AnalyzedTokenReadings [ ] tokens , int pos ) { final AnalyzedTokenReadings analyzedToken = tokens [ pos ] ; boolean relevantPronoun = GermanHelper . hasReadingOfType ( analyzedToken , POSType . PRONOMEN ) ; final String token = tokens [ pos ] . getToken ( ) ; if ( pos > 0 && tokens [ pos - 1 ] . getToken ( ) . equalsIgnoreCase ( "vor" ) && tokens [ pos ] . getToken ( ) . equalsIgnoreCase ( "allem" ) ) { relevantPronoun = false ; } else if ( PRONOUNS_TO_BE_IGNORED . contains ( token . toLowerCase ( ) ) ) { relevantPronoun = false ; } return relevantPronoun ; } private boolean couldBeRelativeClause ( AnalyzedTokenReadings [ ] tokens , int pos ) { boolean comma ; boolean relPronoun ; if ( pos >= 1 ) { comma = tokens [ pos - 1 ] . getToken ( ) . equals ( "," ) ; final String term = tokens [ pos ] . getToken ( ) . toLowerCase ( ) ; relPronoun = REL_PRONOUN . contains ( term ) ; if ( comma && relPronoun ) { return true ; } } if ( pos >= 2 ) { comma = tokens [ pos - 2 ] . getToken ( ) . equals ( "," ) ; final String term1 = tokens [ pos - 1 ] . getToken ( ) . toLowerCase ( ) ; final String term2 = tokens [ pos ] . getToken ( ) . toLowerCase ( ) ; final boolean prep = PREPOSITIONS . contains ( term1 ) ; relPronoun = REL_PRONOUN . contains ( term2 ) ; return comma && prep && relPronoun ; } return false ; } @ Nullable private RuleMatch checkDetNounAgreement ( final AnalyzedTokenReadings token1 , final AnalyzedTokenReadings token2 ) { if ( NOUNS_TO_BE_IGNORED . contains ( token2 . getToken ( ) ) ) { return null ; } if ( token2 . isImmunized ( ) ) { return null ; } final Set < String > set1 = getAgreementCategories ( token1 ) ; if ( set1 == null ) { return null ; } final Set < String > set2 = getAgreementCategories ( token2 ) ; if ( set2 == null ) { return null ; } set1 . retainAll ( set2 ) ; RuleMatch ruleMatch = null ; if ( set1 . size ( ) == 0 && ! isException ( token1 , token2 ) ) { final List < String > errorCategories = getCategoriesCausingError ( token1 , token2 ) ; final String errorDetails = errorCategories . size ( ) > 0 ? StringTools . listToString ( errorCategories , " und " ) : "Kasus, Genus oder Numerus" ; final String msg = "Möglicherweise fehlende grammatische Übereinstimmung zwischen Artikel und Nomen " + "bezüglich " + errorDetails + "." ; final String shortMsg = "Möglicherweise keine Übereinstimmung bezüglich " + errorDetails ; ruleMatch = new RuleMatch ( this , token1 . getStartPos ( ) , token2 . getEndPos ( ) , msg , shortMsg ) ; final AgreementSuggestor suggestor = new AgreementSuggestor ( language . getSynthesizer ( ) , token1 , token2 ) ; final List < String > suggestions = suggestor . getSuggestions ( ) ; ruleMatch . setSuggestedReplacements ( suggestions ) ; } return ruleMatch ; } private boolean isException ( AnalyzedTokenReadings token1 , AnalyzedTokenReadings token2 ) { String phrase = token1 . getToken ( ) + " " + token2 . getToken ( ) ; return "allen Grund" . equals ( phrase ) ; } private List < String > getCategoriesCausingError ( AnalyzedTokenReadings token1 , AnalyzedTokenReadings token2 ) { final List < String > categories = new ArrayList < > ( ) ; final List < GrammarCategory > categoriesToCheck = Arrays . asList ( GrammarCategory . KASUS , GrammarCategory . GENUS , GrammarCategory . NUMERUS ) ; for ( GrammarCategory category : categoriesToCheck ) { if ( agreementWithCategoryRelaxation ( token1 , token2 , category ) ) { categories . add ( category . displayName ) ; } } return categories ; } private RuleMatch checkDetAdjNounAgreement ( final AnalyzedTokenReadings token1 , final AnalyzedTokenReadings token2 , final AnalyzedTokenReadings token3 ) { final Set < String > set = retainCommonCategories ( token1 , token2 , token3 ) ; RuleMatch ruleMatch = null ; if ( set == null || set . size ( ) == 0 ) { final String msg = "Möglicherweise fehlende grammatische Übereinstimmung zwischen Artikel, Adjektiv und " + "Nomen bezüglich Kasus, Numerus oder Genus. Beispiel: 'mein kleiner Haus' " + "statt 'mein kleines Haus'" ; final String shortMsg = "Möglicherweise keine Übereinstimmung bezüglich Kasus, Numerus oder Genus" ; ruleMatch = new RuleMatch ( this , token1 . getStartPos ( ) , token3 . getEndPos ( ) , msg , shortMsg ) ; } return ruleMatch ; } private boolean agreementWithCategoryRelaxation ( final AnalyzedTokenReadings token1 , final AnalyzedTokenReadings token2 , final GrammarCategory categoryToRelax ) { final Set < GrammarCategory > categoryToRelaxSet ; if ( categoryToRelax != null ) { categoryToRelaxSet = Collections . singleton ( categoryToRelax ) ; } else { categoryToRelaxSet = Collections . emptySet ( ) ; } final Set < String > set1 = getAgreementCategories ( token1 , categoryToRelaxSet , true ) ; if ( set1 == null ) { return true ; } final Set < String > set2 = getAgreementCategories ( token2 , categoryToRelaxSet , true ) ; if ( set2 == null ) { return true ; } set1 . retainAll ( set2 ) ; return set1 . size ( ) > 0 ; } @ Nullable private Set < String > retainCommonCategories ( final AnalyzedTokenReadings token1 , final AnalyzedTokenReadings token2 , final AnalyzedTokenReadings token3 ) { final Set < GrammarCategory > categoryToRelaxSet = Collections . emptySet ( ) ; final Set < String > set1 = getAgreementCategories ( token1 , categoryToRelaxSet , true ) ; if ( set1 == null ) { return null ; } final boolean skipSol = ! VIELE_WENIGE_LOWERCASE . contains ( token1 . getToken ( ) . toLowerCase ( ) ) ; final Set < String > set2 = getAgreementCategories ( token2 , categoryToRelaxSet , skipSol ) ; if ( set2 == null ) { return null ; } final Set < String > set3 = getAgreementCategories ( token3 , categoryToRelaxSet , true ) ; if ( set3 == null ) { return null ; } set1 . retainAll ( set2 ) ; set1 . retainAll ( set3 ) ; return set1 ; } private Set < String > getAgreementCategories ( final AnalyzedTokenReadings aToken ) { return getAgreementCategories ( aToken , new HashSet < GrammarCategory > ( ) , false ) ; } private Set < String > getAgreementCategories ( final AnalyzedTokenReadings aToken , Set < GrammarCategory > omit , boolean skipSol ) { final Set < String > set = new HashSet < > ( ) ; final List < AnalyzedToken > readings = aToken . getReadings ( ) ; for ( AnalyzedToken tmpReading : readings ) { if ( skipSol && tmpReading . getPOSTag ( ) != null && tmpReading . getPOSTag ( ) . endsWith ( ":SOL" ) ) { continue ; } final AnalyzedGermanToken reading = new AnalyzedGermanToken ( tmpReading ) ; if ( reading . getCasus ( ) == null && reading . getNumerus ( ) == null && reading . getGenus ( ) == null ) { continue ; } if ( reading . getGenus ( ) == GermanToken . Genus . ALLGEMEIN && tmpReading . getPOSTag ( ) != null && ! tmpReading . getPOSTag ( ) . endsWith ( ":STV" ) ) { set . add ( makeString ( reading . getCasus ( ) , reading . getNumerus ( ) , GermanToken . Genus . MASKULINUM , omit ) ) ; set . add ( makeString ( reading . getCasus ( ) , reading . getNumerus ( ) , GermanToken . Genus . FEMININUM , omit ) ) ; set . add ( makeString ( reading . getCasus ( ) , reading . getNumerus ( ) , GermanToken . Genus . NEUTRUM , omit ) ) ; } else { set . add ( makeString ( reading . getCasus ( ) , reading . getNumerus ( ) , reading . getGenus ( ) , omit ) ) ; } } return set ; } private String makeString ( GermanToken . Kasus casus , GermanToken . Numerus num , GermanToken . Genus gen , Set < GrammarCategory > omit ) { final List < String > l = new ArrayList < > ( ) ; if ( casus != null && ! omit . contains ( GrammarCategory . KASUS ) ) { l . add ( casus . toString ( ) ) ; } if ( num != null && ! omit . contains ( GrammarCategory . NUMERUS ) ) { l . add ( num . toString ( ) ) ; } if ( gen != null && ! omit . contains ( GrammarCategory . GENUS ) ) { l . add ( gen . toString ( ) ) ; } return StringTools . listToString ( l , "/" ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . de ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . RuleFilter ; import java . util . Calendar ; import java . util . Map ; public class RecentYearFilter implements RuleFilter { @ Override public RuleMatch acceptRuleMatch ( RuleMatch match , Map < String , String > arguments , AnalyzedTokenReadings [ ] patternTokens ) { int thisYear = Calendar . getInstance ( ) . get ( Calendar . YEAR ) ; int maxYear = thisYear - Integer . parseInt ( arguments . get ( "maxYearsBack" ) ) ; int year = Integer . parseInt ( arguments . get ( "year" ) ) ; if ( year < thisYear && year >= maxYear ) { return match ; } return null ; } }
package org . languagetool . rules . de ; import de . danielnaber . jwordsplitter . GermanWordSplitter ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . language . German ; import org . languagetool . rules . Example ; import org . languagetool . rules . spelling . hunspell . CompoundAwareHunspellRule ; import org . languagetool . rules . spelling . morfologik . MorfologikMultiSpeller ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tokenizers . de . GermanCompoundTokenizer ; import org . languagetool . tools . StringTools ; import java . io . * ; import java . util . * ; public class GermanSpellerRule extends CompoundAwareHunspellRule { public static final String RULE_ID = "GERMAN_SPELLER_RULE" ; private static final int MAX_EDIT_DISTANCE = 2 ; private static final int SUGGESTION_MIN_LENGTH = 2 ; private static final List < Replacement > REPL = Arrays . asList ( new Replacement ( "f" , "ph" ) , new Replacement ( "ph" , "f" ) , new Replacement ( "ß" , "ss" ) , new Replacement ( "ss" , "ß" ) , new Replacement ( "s" , "ss" ) , new Replacement ( "ss" , "s" ) , new Replacement ( "i" , "ie" ) , new Replacement ( "ie" , "i" ) , new Replacement ( "ee" , "e" ) , new Replacement ( "o" , "oh" ) , new Replacement ( "oh" , "o" ) , new Replacement ( "a" , "ah" ) , new Replacement ( "ah" , "a" ) , new Replacement ( "e" , "eh" ) , new Replacement ( "eh" , "e" ) , new Replacement ( "ae" , "ä" ) , new Replacement ( "oe" , "ö" ) , new Replacement ( "ue" , "ü" ) , new Replacement ( "Ae" , "Ä" ) , new Replacement ( "Oe" , "Ö" ) , new Replacement ( "Ue" , "Ü" ) , new Replacement ( "d" , "t" ) , new Replacement ( "t" , "d" ) , new Replacement ( "th" , "t" ) , new Replacement ( "t" , "th" ) , new Replacement ( "r" , "rh" ) , new Replacement ( "ch" , "k" ) , new Replacement ( "k" , "ch" ) , new Replacement ( "F" , "Ph" ) , new Replacement ( "Ph" , "F" ) ) ; private final LineExpander lineExpander = new LineExpander ( ) ; private final GermanCompoundTokenizer compoundTokenizer ; private final GermanWordSplitter splitter ; private final Synthesizer synthesizer ; private final Tagger tagger ; public GermanSpellerRule ( ResourceBundle messages , German language ) { super ( messages , language , language . getNonStrictCompoundSplitter ( ) , getSpeller ( language ) ) ; addExamplePair ( Example . wrong ( "LanguageTool kann mehr als eine <marker>nromale</marker> Rechtschreibprüfung." ) , Example . fixed ( "LanguageTool kann mehr als eine <marker>normale</marker> Rechtschreibprüfung." ) ) ; compoundTokenizer = language . getStrictCompoundTokenizer ( ) ; tagger = language . getTagger ( ) ; synthesizer = language . getSynthesizer ( ) ; try { splitter = new GermanWordSplitter ( false ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } @ Override public String getId ( ) { return RULE_ID ; } @ Override public List < String > getCandidates ( String word ) { List < String > suggestions = new ArrayList < > ( ) ; List < List < String > > partList = splitter . getAllSplits ( word ) ; final List < String > candidates = new ArrayList < > ( ) ; for ( List < String > parts : partList ) { candidates . addAll ( super . getCandidates ( parts ) ) ; } suggestions . addAll ( candidates ) ; return suggestions ; } @ Override protected void addIgnoreWords ( String origLine , Set < String > wordsToBeIgnored ) { String line ; if ( language . getShortNameWithCountryAndVariant ( ) . equals ( "de-CH" ) ) { line = origLine . replace ( "ß" , "ss" ) ; } else { line = origLine ; } wordsToBeIgnored . addAll ( expandLine ( line ) ) ; } @ Override protected List < String > expandLine ( String line ) { return lineExpander . expandLine ( line ) ; } @ Nullable private static MorfologikMultiSpeller getSpeller ( Language language ) { if ( ! language . getShortName ( ) . equals ( Locale . GERMAN . getLanguage ( ) ) ) { throw new RuntimeException ( "Language is not a variant of German: " + language ) ; } try { final String morfoFile = "/de/hunspell/de_" + language . getCountries ( ) [ 0 ] + ".dict" ; if ( JLanguageTool . getDataBroker ( ) . resourceExists ( morfoFile ) ) { try ( InputStream stream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( "/de/hunspell/spelling.txt" ) ; BufferedReader br = new BufferedReader ( new InputStreamReader ( stream , "utf-8" ) ) ) { return new MorfologikMultiSpeller ( morfoFile , new ExpandingReader ( br ) , MAX_EDIT_DISTANCE ) ; } } else { return null ; } } catch ( IOException e ) { throw new RuntimeException ( "Could not set up morfologik spell checker" , e ) ; } } @ Override protected void filterForLanguage ( List < String > suggestions ) { if ( language . getShortNameWithCountryAndVariant ( ) . equals ( "de-CH" ) ) { for ( int i = 0 ; i < suggestions . size ( ) ; i ++ ) { String s = suggestions . get ( i ) ; suggestions . set ( i , s . replace ( "ß" , "ss" ) ) ; } } } @ Override protected List < String > sortSuggestionByQuality ( String misspelling , List < String > suggestions ) { List < String > sorted1 = sortByReplacements ( misspelling , suggestions ) ; List < String > sorted2 = sortByCase ( misspelling , sorted1 ) ; return sorted2 ; } @ Override protected boolean ignoreWord ( List < String > words , int idx ) throws IOException { boolean ignore = super . ignoreWord ( words , idx ) ; boolean ignoreByHyphen = ! ignore && words . get ( idx ) . endsWith ( "-" ) && ignoreByHangingHyphen ( words , idx ) ; return ignore || ignoreByHyphen ; } @ Override protected List < String > getAdditionalTopSuggestions ( List < String > suggestions , String word ) { String w = word . replaceFirst ( "\\.$" , "" ) ; if ( "unzwar" . equals ( w ) ) { return Collections . singletonList ( "und zwar" ) ; } else if ( "desweiteren" . equals ( w ) ) { return Collections . singletonList ( "des Weiteren" ) ; } else if ( "wieviel" . equals ( w ) ) { return Collections . singletonList ( "wie viel" ) ; } else if ( "wieviele" . equals ( w ) ) { return Collections . singletonList ( "wie viele" ) ; } else if ( "wievielen" . equals ( w ) ) { return Collections . singletonList ( "wie vielen" ) ; } else if ( "vorteilen" . equals ( w ) ) { return Collections . singletonList ( "Vorteilen" ) ; } else if ( "Trons" . equals ( w ) ) { return Collections . singletonList ( "Trance" ) ; } else if ( "einzigste" . equals ( w ) ) { return Collections . singletonList ( "einzige" ) ; } else if ( word . endsWith ( "standart" ) ) { return Collections . singletonList ( word . replaceFirst ( "standart$" , "standard" ) ) ; } else if ( word . endsWith ( "standarts" ) ) { return Collections . singletonList ( word . replaceFirst ( "standarts$" , "standards" ) ) ; } else if ( word . equals ( "Rolladen" ) ) { return Collections . singletonList ( "Rollladen" ) ; } else if ( ! StringTools . startsWithUppercase ( word ) ) { String ucWord = StringTools . uppercaseFirstChar ( word ) ; if ( ! suggestions . contains ( ucWord ) && ! hunspellDict . misspelled ( ucWord ) ) { return Collections . singletonList ( ucWord ) ; } } String verbSuggestion = getPastTenseVerbSuggestion ( word ) ; if ( verbSuggestion != null ) { return Collections . singletonList ( verbSuggestion ) ; } String participleSuggestion = getParticipleSuggestion ( word ) ; if ( participleSuggestion != null ) { return Collections . singletonList ( participleSuggestion ) ; } return Collections . emptyList ( ) ; } @ Nullable private String getPastTenseVerbSuggestion ( String word ) { if ( word . endsWith ( "e" ) ) { String wordStem = word . replaceFirst ( "e$" , "" ) ; try { String lemma = baseForThirdPersonSingularVerb ( wordStem ) ; if ( lemma != null ) { AnalyzedToken token = new AnalyzedToken ( lemma , null , lemma ) ; String [ ] forms = synthesizer . synthesize ( token , "VER:3:SIN:PRT:.*" , true ) ; if ( forms . length > 0 ) { return forms [ 0 ] ; } } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } return null ; } @ Nullable private String baseForThirdPersonSingularVerb ( String word ) throws IOException { List < AnalyzedTokenReadings > readings = tagger . tag ( Collections . singletonList ( word ) ) ; for ( AnalyzedTokenReadings reading : readings ) { if ( reading . hasPartialPosTag ( "VER:3:SIN:" ) ) { return reading . getReadings ( ) . get ( 0 ) . getLemma ( ) ; } } return null ; } @ Nullable private String getParticipleSuggestion ( String word ) { if ( word . startsWith ( "ge" ) && word . endsWith ( "t" ) ) { String baseform = word . replaceFirst ( "^ge" , "" ) . replaceFirst ( "t$" , "en" ) ; try { String participle = getParticipleForBaseform ( baseform ) ; if ( participle != null ) { return participle ; } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } return null ; } @ Nullable private String getParticipleForBaseform ( String baseform ) throws IOException { AnalyzedToken token = new AnalyzedToken ( baseform , null , baseform ) ; String [ ] forms = synthesizer . synthesize ( token , "VER:PA2:.*" , true ) ; if ( forms . length > 0 && ! hunspellDict . misspelled ( forms [ 0 ] ) ) { return forms [ 0 ] ; } return null ; } private boolean ignoreByHangingHyphen ( List < String > words , int idx ) { String word = words . get ( idx ) ; String nextWord = getWordAfterEnumerationOrNull ( words , idx ) ; boolean isCompound = nextWord != null && compoundTokenizer . tokenize ( nextWord ) . size ( ) > 1 ; if ( isCompound ) { return ! hunspellDict . misspelled ( word . replaceFirst ( "-$" , "" ) ) ; } return false ; } @ Nullable private String getWordAfterEnumerationOrNull ( List < String > words , int idx ) { for ( int i = idx ; i < words . size ( ) ; i ++ ) { String word = words . get ( i ) ; boolean inEnumeration = "," . equals ( word ) || "und" . equals ( word ) || "oder" . equals ( word ) || word . trim ( ) . isEmpty ( ) || word . endsWith ( "-" ) ; if ( ! inEnumeration ) { return word ; } } return null ; } private List < String > sortByReplacements ( String misspelling , List < String > suggestions ) { final List < String > result = new ArrayList < > ( ) ; for ( String suggestion : suggestions ) { boolean moveSuggestionToTop = false ; for ( Replacement replacement : REPL ) { final String modifiedMisspelling = misspelling . replace ( replacement . key , replacement . value ) ; final boolean equalsAfterReplacement = modifiedMisspelling . equals ( suggestion ) ; if ( equalsAfterReplacement ) { moveSuggestionToTop = true ; break ; } } if ( ! ignoreSuggestion ( suggestion ) ) { if ( moveSuggestionToTop ) { result . add ( 0 , suggestion ) ; } else { result . add ( suggestion ) ; } } } return result ; } private List < String > sortByCase ( String misspelling , List < String > suggestions ) { final List < String > result = new ArrayList < > ( ) ; for ( String suggestion : suggestions ) { if ( misspelling . equalsIgnoreCase ( suggestion ) ) { result . add ( 0 , suggestion ) ; } else { result . add ( suggestion ) ; } } return result ; } private boolean ignoreSuggestion ( String suggestion ) { String [ ] parts = suggestion . split ( " " ) ; if ( parts . length > 1 ) { for ( String part : parts ) { if ( part . length ( ) < SUGGESTION_MIN_LENGTH ) { return true ; } } } return false ; } private static class Replacement { final String key ; final String value ; private Replacement ( String key , String value ) { this . key = key ; this . value = value ; } } static class ExpandingReader extends BufferedReader { private final List < String > buffer = new ArrayList < > ( ) ; private final LineExpander lineExpander = new LineExpander ( ) ; ExpandingReader ( Reader in ) { super ( in ) ; } @ Override public String readLine ( ) throws IOException { if ( buffer . size ( ) > 0 ) { return buffer . remove ( 0 ) ; } else { String line = super . readLine ( ) ; if ( line == null ) { return null ; } buffer . addAll ( lineExpander . expandLine ( line ) ) ; return buffer . remove ( 0 ) ; } } } }
package org . languagetool . rules . de ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . Example ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikGermanyGermanSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/de/hunspell/de_DE.dict" ; public MorfologikGermanyGermanSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; addExamplePair ( Example . wrong ( "LanguageTool kann mehr als eine <marker>nromale</marker> Rechtschreibprüfung." ) , Example . fixed ( "LanguageTool kann mehr als eine <marker>normale</marker> Rechtschreibprüfung." ) ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_DE_DE" ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Danish ; public class DanishConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Danish ( ) ; } @ Override protected String createSampleText ( ) { return "Se hjælpesiderne for dokumentation eller find svar på ofte stillede spørgsmål." ; } }
package org . languagetool . rules . ca ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class CatalanWordRepeatRuleTest extends TestCase { public void testRule ( ) throws IOException { final CatalanWordRepeatRule rule = new CatalanWordRepeatRule ( TestTools . getMessages ( "ca" ) , new Catalan ( ) ) ; RuleMatch [ ] matches ; JLanguageTool langTool = new JLanguageTool ( new Catalan ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Sempre pensa en en Joan." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Els els portaré aviat." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Maximilià I i Maria de Borgonya" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "De la A a la z" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Entre I i II." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "fills de Sigebert I i Brunegilda" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "del segle I i del segle II" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "entre el capítol I i el II" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "cada una una casa" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "cada un un llibre" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Tots els els homes són iguals." ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Maximilià i i Maria de Borgonya" ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . rules . de ; import java . util . ResourceBundle ; import org . languagetool . rules . Example ; import org . languagetool . rules . WrongWordInContextRule ; public class GermanWrongWordInContextRule extends WrongWordInContextRule { public GermanWrongWordInContextRule ( final ResourceBundle messages ) { super ( messages ) ; addExamplePair ( Example . wrong ( "Eine Gitarre hat sechs <marker>Seiten</marker>." ) , Example . fixed ( "Eine Gitarre hat sechs <marker>Saiten</marker>." ) ) ; } @ Override protected String getCategoryString ( ) { return "Leicht zu verwechselnde Wörter" ; } @ Override public String getId ( ) { return "GERMAN_WRONG_WORD_IN_CONTEXT" ; } @ Override public String getDescription ( ) { return "Wortverwechslungen (Mine/Miene, Saite/Seite etc.)" ; } @ Override protected String getFilename ( ) { return "/de/wrongWordInContext.txt" ; } @ Override protected String getMessageString ( ) { return "Mögliche Wortverwechslung: Meinten Sie <suggestion>$SUGGESTION</suggestion> anstatt '$WRONGWORD'?" ; } @ Override protected String getShortMessageString ( ) { return "Mögliche Wortverwechslung" ; } @ Override protected String getLongMessageString ( ) { return "Mögliche Wortverwechslung: Meinten Sie <suggestion>$SUGGESTION</suggestion> (= $EXPLANATION_SUGGESTION) anstatt '$WRONGWORD' (= $EXPLANATION_WRONGWORD)?" ; } }
package org . languagetool . rules . de ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . chunking . ChunkTag ; import org . languagetool . language . German ; import org . languagetool . rules . Category ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tagging . de . GermanTagger ; import java . io . IOException ; import java . net . MalformedURLException ; import java . net . URL ; import java . util . * ; import java . util . regex . Pattern ; public class SubjectVerbAgreementRule extends GermanRule { private static final ChunkTag NPS = new ChunkTag ( "NPS" ) ; private static final ChunkTag NPP = new ChunkTag ( "NPP" ) ; private static final ChunkTag PP = new ChunkTag ( "PP" ) ; private static final List < String > QUESTION_PRONOUNS = Arrays . asList ( "wie" ) ; private static final List < String > CURRENCIES = Arrays . asList ( "Dollar" , "Euro" , "Yen" ) ; private static final List < SingularPluralPair > PAIRS = Arrays . asList ( new SingularPluralPair ( "ist" , "sind" ) , new SingularPluralPair ( "war" , "waren" ) ) ; private final Set < String > singular = new HashSet < > ( ) ; private final Set < String > plural = new HashSet < > ( ) ; private final GermanTagger tagger ; public SubjectVerbAgreementRule ( ResourceBundle messages , German language ) { super . setCategory ( new Category ( messages . getString ( "category_grammar" ) ) ) ; tagger = ( GermanTagger ) language . getTagger ( ) ; for ( SingularPluralPair pair : PAIRS ) { singular . add ( pair . singular ) ; plural . add ( pair . plural ) ; } } @ Override public String getId ( ) { return "DE_SUBJECT_VERB_AGREEMENT" ; } @ Override public String getDescription ( ) { return "Kongruenz von Subjekt und Prädikat (unvollständig)" ; } @ Override public URL getUrl ( ) { try { return new URL ( "http://www.canoo.net/services/OnlineGrammar/Wort/Verb/Numerus-Person/ProblemNum.html" ) ; } catch ( MalformedURLException e ) { throw new RuntimeException ( e ) ; } } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; for ( int i = 1 ; i < tokens . length ; i ++ ) { AnalyzedTokenReadings token = tokens [ i ] ; String tokenStr = token . getToken ( ) ; RuleMatch singularMatch = getSingularMatchOrNull ( tokens , i , token , tokenStr ) ; if ( singularMatch != null ) { ruleMatches . add ( singularMatch ) ; } RuleMatch pluralMatch = getPluralMatchOrNull ( tokens , i , token , tokenStr ) ; if ( pluralMatch != null ) { ruleMatches . add ( pluralMatch ) ; } } return toRuleMatchArray ( ruleMatches ) ; } @ Nullable private RuleMatch getSingularMatchOrNull ( AnalyzedTokenReadings [ ] tokens , int i , AnalyzedTokenReadings token , String tokenStr ) throws IOException { if ( singular . contains ( tokenStr ) ) { AnalyzedTokenReadings prevToken = tokens [ i - 1 ] ; AnalyzedTokenReadings nextToken = i + 1 < tokens . length ? tokens [ i + 1 ] : null ; List < ChunkTag > prevChunkTags = prevToken . getChunkTags ( ) ; boolean match = prevChunkTags . contains ( NPP ) && ! prevChunkTags . contains ( PP ) && ! prevToken . getToken ( ) . equals ( "Uhr" ) && ! isCurrency ( prevToken ) && ! ( nextToken != null && nextToken . getToken ( ) . equals ( "es" ) ) && prevChunkIsNominative ( tokens , i - 1 ) && ! hasUnknownTokenToTheLeft ( tokens , i ) && ! hasQuestionPronounToTheLeft ( tokens , i - 1 ) && ! containsRegexToTheLeft ( "wer" , tokens , i - 1 ) && ! containsRegexToTheLeft ( "(?i)alle[nr]?" , tokens , i - 1 ) && ! containsRegexToTheLeft ( "(?i)jede[rs]?" , tokens , i - 1 ) && ! containsRegexToTheLeft ( "(?i)manche[nrs]?" , tokens , i - 1 ) && ! containsOnlyInfinitivesToTheLeft ( tokens , i - 1 ) ; if ( match ) { String message = "Bitte prüfen, ob hier <suggestion>" + getPluralFor ( tokenStr ) + "</suggestion> stehen sollte." ; return new RuleMatch ( this , token . getStartPos ( ) , token . getEndPos ( ) , message ) ; } } return null ; } @ Nullable private RuleMatch getPluralMatchOrNull ( AnalyzedTokenReadings [ ] tokens , int i , AnalyzedTokenReadings token , String tokenStr ) { if ( plural . contains ( tokenStr ) ) { AnalyzedTokenReadings prevToken = tokens [ i - 1 ] ; List < ChunkTag > prevChunkTags = prevToken . getChunkTags ( ) ; boolean match = prevChunkTags . contains ( NPS ) && ! prevChunkTags . contains ( NPP ) && ! prevChunkTags . contains ( PP ) && ! isCurrency ( prevToken ) && prevChunkIsNominative ( tokens , i - 1 ) && ! hasUnknownTokenToTheLeft ( tokens , i ) && ! hasUnknownTokenToTheRight ( tokens , i + 1 ) && ! isFollowedByNominativePlural ( tokens , i + 1 ) ; if ( match ) { String message = "Bitte prüfen, ob hier <suggestion>" + getSingularFor ( tokenStr ) + "</suggestion> stehen sollte." ; return new RuleMatch ( this , token . getStartPos ( ) , token . getEndPos ( ) , message ) ; } } return null ; } private boolean isCurrency ( AnalyzedTokenReadings token ) { return CURRENCIES . contains ( token . getToken ( ) ) ; } boolean prevChunkIsNominative ( AnalyzedTokenReadings [ ] tokens , int startPos ) { for ( int i = startPos ; i > 0 ; i -- ) { AnalyzedTokenReadings token = tokens [ i ] ; List < ChunkTag > chunkTags = token . getChunkTags ( ) ; if ( chunkTags . contains ( NPS ) || chunkTags . contains ( NPP ) ) { if ( token . hasPartialPosTag ( "NOM" ) ) { return true ; } } else { return false ; } } return false ; } private boolean hasUnknownTokenToTheLeft ( AnalyzedTokenReadings [ ] tokens , int startPos ) { return hasUnknownTokenAt ( tokens , 0 , startPos ) ; } private boolean hasUnknownTokenToTheRight ( AnalyzedTokenReadings [ ] tokens , int startPos ) { return hasUnknownTokenAt ( tokens , startPos , tokens . length - 1 ) ; } private boolean hasUnknownTokenAt ( AnalyzedTokenReadings [ ] tokens , int startPos , int endPos ) { if ( endPos < startPos ) { throw new RuntimeException ( "endPos < startPos: " + endPos + " < " + startPos ) ; } for ( int i = startPos ; i < endPos ; i ++ ) { AnalyzedTokenReadings token = tokens [ i ] ; for ( AnalyzedToken analyzedToken : token . getReadings ( ) ) { if ( analyzedToken . hasNoTag ( ) ) { return true ; } } } return false ; } private boolean hasQuestionPronounToTheLeft ( AnalyzedTokenReadings [ ] tokens , int startPos ) { for ( int i = startPos ; i > 0 ; i -- ) { AnalyzedTokenReadings token = tokens [ i ] ; if ( QUESTION_PRONOUNS . contains ( token . getToken ( ) . toLowerCase ( ) ) ) { return true ; } } return false ; } private boolean containsRegexToTheLeft ( String regex , AnalyzedTokenReadings [ ] tokens , int startPos ) { Pattern p = Pattern . compile ( regex ) ; for ( int i = startPos ; i > 0 ; i -- ) { String token = tokens [ i ] . getToken ( ) ; if ( p . matcher ( token ) . matches ( ) ) { return true ; } } return false ; } private boolean containsOnlyInfinitivesToTheLeft ( AnalyzedTokenReadings [ ] tokens , int startPos ) throws IOException { int infinitives = 0 ; for ( int i = startPos ; i > 0 ; i -- ) { String token = tokens [ i ] . getToken ( ) ; if ( tokens [ i ] . hasPartialPosTag ( "SUB:" ) ) { AnalyzedTokenReadings lookup = tagger . lookup ( token . toLowerCase ( ) ) ; if ( lookup != null && lookup . hasPartialPosTag ( "VER:INF:" ) ) { infinitives ++ ; } else { return false ; } } } return infinitives >= 2 ; } boolean isFollowedByNominativePlural ( AnalyzedTokenReadings [ ] tokens , int startPos ) { for ( int i = startPos ; i < tokens . length ; i ++ ) { AnalyzedTokenReadings token = tokens [ i ] ; if ( token . hasPartialPosTag ( "SUB" ) || token . hasPartialPosTag ( "PRO" ) ) { if ( token . hasPartialPosTag ( "NOM:PLU" ) || token . getChunkTags ( ) . contains ( new ChunkTag ( "NPP" ) ) ) { return true ; } } } return false ; } private String getSingularFor ( String token ) { for ( SingularPluralPair pair : PAIRS ) { if ( pair . plural . equals ( token ) ) { return pair . singular ; } } throw new RuntimeException ( "No singular found for '" + token + "'" ) ; } private String getPluralFor ( String token ) { for ( SingularPluralPair pair : PAIRS ) { if ( pair . singular . equals ( token ) ) { return pair . plural ; } } throw new RuntimeException ( "No plural found for '" + token + "'" ) ; } @ Override public void reset ( ) { } private static class SingularPluralPair { String singular ; String plural ; SingularPluralPair ( String singular , String plural ) { this . singular = singular ; this . plural = plural ; } } }
package org . languagetool . rules . de ; import java . util . * ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . RuleMatch ; public class DashRule extends GermanRule { public DashRule ( final ResourceBundle messages ) { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; addExamplePair ( Example . wrong ( "Bundestag beschließt <marker>Diäten- Erhöhung</marker>" ) , Example . fixed ( "Bundestag beschließt <marker>Diäten-Erhöhung</marker>" ) ) ; } @ Override public String getId ( ) { return "DE_DASH" ; } @ Override public String getDescription ( ) { return "Keine Leerzeichen in Bindestrich-Komposita (wie z.B. in 'Diäten- Erhöhung')" ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; String prevToken = null ; for ( int i = 0 ; i < tokens . length ; i ++ ) { final String token = tokens [ i ] . getToken ( ) ; if ( tokens [ i ] . isWhitespace ( ) ) { continue ; } if ( prevToken != null && ! prevToken . equals ( "-" ) && ! prevToken . contains ( "--" ) && ! prevToken . contains ( "–-" ) && prevToken . endsWith ( "-" ) ) { final char firstChar = token . charAt ( 0 ) ; if ( Character . isUpperCase ( firstChar ) ) { final String msg = "Möglicherweise fehlt ein 'und' oder ein Komma, oder es wurde nach dem Wort " + "ein überflüssiges Leerzeichen eingefügt. Eventuell haben Sie auch versehentlich einen Bindestrich statt eines Punktes eingefügt." ; final String shortMsg = "Fehlendes 'und' oder Komma oder überflüssiges Leerzeichen?" ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ i - 1 ] . getStartPos ( ) , tokens [ i - 1 ] . getStartPos ( ) + prevToken . length ( ) + 1 , msg , shortMsg ) ; String prevTokenStr = tokens [ i - 1 ] . getToken ( ) ; ruleMatch . setSuggestedReplacements ( Arrays . asList ( prevTokenStr , prevTokenStr + ", " ) ) ; ruleMatches . add ( ruleMatch ) ; } } prevToken = token ; } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . de ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . HashSet ; import java . util . List ; import java . util . ResourceBundle ; import java . util . Set ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . language . German ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tools . StringTools ; import java . io . IOException ; public class VerbAgreementRule extends GermanRule { private static final Set < String > BIN_IGNORE = new HashSet < > ( Arrays . asList ( "Suleiman" , "Mohamed" , "Muhammad" , "Muhammed" , "Mohammed" , "Mohammad" , "Mansour" , "Qaboos" , "Qabus" , "Tamim" , "Majid" , "Salman" , "Ghazi" , "Mahathir" , "Madschid" , "Maktum" , "al-Aziz" , "Asis" , "Numan" , "Hussein" , "Abdul" , "Abdulla" , "Abdullah" , "Isa" , "Osama" , "Said" , "Zayid" , "Zayed" , "Hamad" , "Chalifa" , "Raschid" , "Turki" , "/" ) ) ; private static final Set < String > QUOTATION_MARKS = new HashSet < > ( Arrays . asList ( "\"" , "„" ) ) ; private final German language ; private AnalyzedTokenReadings finiteVerb ; public VerbAgreementRule ( final ResourceBundle messages , German language ) { this . language = language ; super . setCategory ( new Category ( messages . getString ( "category_grammar" ) ) ) ; addExamplePair ( Example . wrong ( "Ich <marker>bist</marker> über die Entwicklung sehr froh." ) , Example . fixed ( "Ich <marker>bin</marker> über die Entwicklung sehr froh." ) ) ; } @ Override public String getId ( ) { return "DE_VERBAGREEMENT" ; } @ Override public String getDescription ( ) { return "Kongruenz von Subjekt und Prädikat (nur 1. u. 2. Pers. od. m. Personalpronomen), z.B. 'Er bist (ist)'" ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; if ( tokens . length < 4 ) { return toRuleMatchArray ( ruleMatches ) ; } int posIch = - 1 ; int posDu = - 1 ; int posEr = - 1 ; int posWir = - 1 ; int posVer1Sin = - 1 ; int posVer2Sin = - 1 ; int posVer1Plu = - 1 ; int posPossibleVer1Sin = - 1 ; int posPossibleVer2Sin = - 1 ; int posPossibleVer3Sin = - 1 ; int posPossibleVer1Plu = - 1 ; for ( int i = 1 ; i < tokens . length ; ++ i ) { String strToken = tokens [ i ] . getToken ( ) . toLowerCase ( ) ; strToken = strToken . replace ( "‚" , "" ) ; switch ( strToken ) { case "ich" : posIch = i ; break ; case "du" : posDu = i ; break ; case "er" : posEr = i ; break ; case "wir" : posWir = i ; break ; } if ( tokens [ i ] . hasPartialPosTag ( "VER" ) && ( Character . isLowerCase ( tokens [ i ] . getToken ( ) . charAt ( 0 ) ) || i == 1 ) ) { if ( hasUnambiguouslyPersonAndNumber ( tokens [ i ] , "1" , "SIN" ) && ! ( strToken . equals ( "bin" ) && ( BIN_IGNORE . contains ( tokens [ i - 1 ] . getToken ( ) ) || ( tokens . length != i + 1 && tokens [ i + 1 ] . getToken ( ) . startsWith ( "Laden" ) ) ) ) ) { posVer1Sin = i ; } else if ( hasUnambiguouslyPersonAndNumber ( tokens [ i ] , "2" , "SIN" ) ) { posVer2Sin = i ; } else if ( hasUnambiguouslyPersonAndNumber ( tokens [ i ] , "1" , "PLU" ) ) { posVer1Plu = i ; } if ( tokens [ i ] . hasPartialPosTag ( ":1:SIN" ) ) { posPossibleVer1Sin = i ; } if ( tokens [ i ] . hasPartialPosTag ( ":2:SIN" ) ) { posPossibleVer2Sin = i ; } if ( tokens [ i ] . hasPartialPosTag ( ":3:SIN" ) ) { posPossibleVer3Sin = i ; } if ( tokens [ i ] . hasPartialPosTag ( ":1:PLU" ) ) { posPossibleVer1Plu = i ; } } } if ( posVer1Sin != - 1 && posIch == - 1 && ! isQuotationMark ( tokens [ posVer1Sin - 1 ] ) ) { ruleMatches . add ( ruleMatchWrongVerb ( tokens [ posVer1Sin ] ) ) ; } else if ( posIch > 0 && ! isNear ( posPossibleVer1Sin , posIch ) && ( tokens [ posIch ] . getToken ( ) . equals ( "ich" ) || tokens [ posIch ] . getStartPos ( ) == 0 ) && ! isQuotationMark ( tokens [ posIch - 1 ] ) ) { final int plus1 = ( ( posIch + 1 ) == tokens . length ) ? 0 : + 1 ; if ( ! verbDoesMatchPersonAndNumber ( tokens [ posIch - 1 ] , tokens [ posIch + plus1 ] , "1" , "SIN" ) ) { if ( ! nextButOneIsModal ( tokens , posIch ) ) { ruleMatches . add ( ruleMatchWrongVerbSubject ( tokens [ posIch ] , finiteVerb , "1:SIN" ) ) ; } } } if ( posVer2Sin != - 1 && posDu == - 1 && ! isQuotationMark ( tokens [ posVer2Sin - 1 ] ) ) { ruleMatches . add ( ruleMatchWrongVerb ( tokens [ posVer2Sin ] ) ) ; } else if ( posDu > 0 && ! isNear ( posPossibleVer2Sin , posDu ) && ! isQuotationMark ( tokens [ posDu - 1 ] ) ) { final int plus1 = ( ( posDu + 1 ) == tokens . length ) ? 0 : + 1 ; if ( ! verbDoesMatchPersonAndNumber ( tokens [ posDu - 1 ] , tokens [ posDu + plus1 ] , "2" , "SIN" ) && ! tokens [ posDu + plus1 ] . hasPartialPosTag ( "VER:1:SIN:KJ2" ) && ! tokens [ posDu + plus1 ] . hasPartialPosTag ( "ADJ:" ) && ! tokens [ posDu - 1 ] . hasPartialPosTag ( "VER:1:SIN:KJ2" ) ) { if ( ! nextButOneIsModal ( tokens , posDu ) ) { ruleMatches . add ( ruleMatchWrongVerbSubject ( tokens [ posDu ] , finiteVerb , "2:SIN" ) ) ; } } } if ( posEr > 0 && ! isNear ( posPossibleVer3Sin , posEr ) && ! isQuotationMark ( tokens [ posEr - 1 ] ) ) { final int plus1 = ( ( posEr + 1 ) == tokens . length ) ? 0 : + 1 ; if ( ! verbDoesMatchPersonAndNumber ( tokens [ posEr - 1 ] , tokens [ posEr + plus1 ] , "3" , "SIN" ) && ! nextButOneIsModal ( tokens , posEr ) && ! "äußerst" . equals ( finiteVerb . getToken ( ) ) && ! "regen" . equals ( finiteVerb . getToken ( ) ) ) { ruleMatches . add ( ruleMatchWrongVerbSubject ( tokens [ posEr ] , finiteVerb , "3:SIN" ) ) ; } } if ( posVer1Plu != - 1 && posWir == - 1 && ! isQuotationMark ( tokens [ posVer1Plu - 1 ] ) ) { ruleMatches . add ( ruleMatchWrongVerb ( tokens [ posVer1Plu ] ) ) ; } else if ( posWir > 0 && ! isNear ( posPossibleVer1Plu , posWir ) && ! isQuotationMark ( tokens [ posWir - 1 ] ) ) { final int plus1 = ( ( posWir + 1 ) == tokens . length ) ? 0 : + 1 ; if ( ! verbDoesMatchPersonAndNumber ( tokens [ posWir - 1 ] , tokens [ posWir + plus1 ] , "1" , "PLU" ) && ! nextButOneIsModal ( tokens , posWir ) ) { ruleMatches . add ( ruleMatchWrongVerbSubject ( tokens [ posWir ] , finiteVerb , "1:PLU" ) ) ; } } return toRuleMatchArray ( ruleMatches ) ; } private boolean nextButOneIsModal ( AnalyzedTokenReadings [ ] tokens , int pos ) { return pos < tokens . length - 2 && tokens [ pos + 2 ] . hasPartialPosTag ( ":MOD:" ) ; } private boolean isNear ( final int a , final int b ) { return ( Math . abs ( a - b ) < 5 ) && a != - 1 ; } private boolean isQuotationMark ( final AnalyzedTokenReadings token ) { return QUOTATION_MARKS . contains ( token . getToken ( ) ) ; } private boolean hasUnambiguouslyPersonAndNumber ( final AnalyzedTokenReadings tokenReadings , final String person , final String number ) { if ( tokenReadings . getToken ( ) . length ( ) == 0 || ( Character . isUpperCase ( tokenReadings . getToken ( ) . charAt ( 0 ) ) && tokenReadings . getStartPos ( ) != 0 ) || ! tokenReadings . hasPartialPosTag ( "VER" ) ) { return false ; } for ( AnalyzedToken analyzedToken : tokenReadings ) { final String postag = analyzedToken . getPOSTag ( ) ; if ( postag . contains ( "_END" ) ) { continue ; } if ( ! postag . contains ( ":" + person + ":" + number ) ) { return false ; } } return true ; } private boolean isFiniteVerb ( final AnalyzedTokenReadings token ) { if ( token . getToken ( ) . length ( ) == 0 || ( Character . isUpperCase ( token . getToken ( ) . charAt ( 0 ) ) && token . getStartPos ( ) != 0 ) || ! token . hasPartialPosTag ( "VER" ) || token . hasPartialPosTag ( "PA2" ) || token . hasPartialPosTag ( "PRO:" ) || token . hasPartialPosTag ( "ZAL" ) || "einst" . equals ( token . getToken ( ) ) ) { return false ; } return token . hasPartialPosTag ( ":1:" ) || token . hasPartialPosTag ( ":2:" ) || token . hasPartialPosTag ( ":3:" ) ; } private boolean verbDoesMatchPersonAndNumber ( final AnalyzedTokenReadings token1 , final AnalyzedTokenReadings token2 , final String person , final String number ) { String token1Str = token1 . getToken ( ) ; String token2Str = token2 . getToken ( ) ; if ( token1Str . equals ( "," ) || token1Str . equals ( "und" ) || token1Str . equals ( "sowie" ) || token2Str . equals ( "," ) || token2Str . equals ( "und" ) || token2Str . equals ( "sowie" ) ) { return true ; } boolean foundFiniteVerb = false ; if ( isFiniteVerb ( token1 ) ) { foundFiniteVerb = true ; finiteVerb = token1 ; if ( token1 . hasPartialPosTag ( ":" + person + ":" + number ) ) { return true ; } } if ( isFiniteVerb ( token2 ) ) { foundFiniteVerb = true ; finiteVerb = token2 ; if ( token2 . hasPartialPosTag ( ":" + person + ":" + number ) ) { return true ; } } return ! foundFiniteVerb ; } private List < String > getVerbSuggestions ( final AnalyzedTokenReadings verb , final String expectedVerbPOS , final boolean toUppercase ) { AnalyzedToken verbToken = new AnalyzedToken ( "" , "" , "" ) ; for ( AnalyzedToken token : verb . getReadings ( ) ) { if ( token . getPOSTag ( ) . startsWith ( "VER:" ) ) { verbToken = token ; break ; } } try { String [ ] synthesized = language . getSynthesizer ( ) . synthesize ( verbToken , "VER.*:" + expectedVerbPOS + ".*" , true ) ; Set < String > suggestionSet = new HashSet < > ( ) ; suggestionSet . addAll ( Arrays . asList ( synthesized ) ) ; List < String > suggestions = new ArrayList < > ( ) ; suggestions . addAll ( suggestionSet ) ; if ( toUppercase ) { for ( int i = 0 ; i < suggestions . size ( ) ; ++ i ) { suggestions . set ( i , StringTools . uppercaseFirstChar ( suggestions . get ( i ) ) ) ; } } Collections . sort ( suggestions ) ; return suggestions ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } private List < String > getPronounSuggestions ( final AnalyzedTokenReadings verb , final boolean toUppercase ) { List < String > result = new ArrayList < > ( ) ; if ( verb . hasPartialPosTag ( ":1:SIN" ) ) { result . add ( "ich" ) ; } if ( verb . hasPartialPosTag ( ":2:SIN" ) ) { result . add ( "du" ) ; } if ( verb . hasPartialPosTag ( ":3:SIN" ) ) { result . add ( "er" ) ; result . add ( "sie" ) ; result . add ( "es" ) ; } if ( verb . hasPartialPosTag ( ":1:PLU" ) ) { result . add ( "wir" ) ; } if ( verb . hasPartialPosTag ( ":2:PLU" ) ) { result . add ( "ihr" ) ; } if ( verb . hasPartialPosTag ( ":3:PLU" ) && ! result . contains ( "sie" ) ) { result . add ( "sie" ) ; } if ( toUppercase ) { for ( int i = 0 ; i < result . size ( ) ; ++ i ) { result . set ( i , StringTools . uppercaseFirstChar ( result . get ( i ) ) ) ; } } return result ; } private RuleMatch ruleMatchWrongVerb ( final AnalyzedTokenReadings token ) { final String msg = "Möglicherweise fehlende grammatische Übereinstimmung zwischen Subjekt und Prädikat (" + token . getToken ( ) + ") bezüglich Person oder Numerus (Einzahl, Mehrzahl - Beispiel: " + "'Max bist' statt 'Max ist')." ; return new RuleMatch ( this , token . getStartPos ( ) , token . getEndPos ( ) , msg ) ; } private RuleMatch ruleMatchWrongVerbSubject ( final AnalyzedTokenReadings subject , final AnalyzedTokenReadings verb , final String expectedVerbPOS ) { final String msg = "Möglicherweise fehlende grammatische Übereinstimmung zwischen Subjekt (" + subject . getToken ( ) + ") und Prädikat (" + verb . getToken ( ) + ") bezüglich Person oder Numerus (Einzahl, Mehrzahl - Beispiel: " + "'ich sind' statt 'ich bin')." ; List < String > suggestions = new ArrayList < > ( ) ; List < String > verbSuggestions = new ArrayList < > ( ) ; List < String > pronounSuggestions = new ArrayList < > ( ) ; RuleMatch ruleMatch ; if ( subject . getStartPos ( ) < verb . getStartPos ( ) ) { ruleMatch = new RuleMatch ( this , subject . getStartPos ( ) , verb . getStartPos ( ) + verb . getToken ( ) . length ( ) , msg ) ; verbSuggestions . addAll ( getVerbSuggestions ( verb , expectedVerbPOS , false ) ) ; for ( String verbSuggestion : verbSuggestions ) { suggestions . add ( subject . getToken ( ) + " " + verbSuggestion ) ; } pronounSuggestions . addAll ( getPronounSuggestions ( verb , Character . isUpperCase ( subject . getToken ( ) . charAt ( 0 ) ) ) ) ; for ( String pronounSuggestion : pronounSuggestions ) { suggestions . add ( pronounSuggestion + " " + verb . getToken ( ) ) ; } ruleMatch . setSuggestedReplacements ( suggestions ) ; } else { ruleMatch = new RuleMatch ( this , verb . getStartPos ( ) , subject . getStartPos ( ) + subject . getToken ( ) . length ( ) , msg ) ; verbSuggestions . addAll ( getVerbSuggestions ( verb , expectedVerbPOS , Character . isUpperCase ( verb . getToken ( ) . charAt ( 0 ) ) ) ) ; for ( String verbSuggestion : verbSuggestions ) { suggestions . add ( verbSuggestion + " " + subject . getToken ( ) ) ; } pronounSuggestions . addAll ( getPronounSuggestions ( verb , false ) ) ; for ( String pronounSuggestion : pronounSuggestions ) { suggestions . add ( verb . getToken ( ) + " " + pronounSuggestion ) ; } ruleMatch . setSuggestedReplacements ( suggestions ) ; } return ruleMatch ; } @ Override public void reset ( ) { finiteVerb = null ; } }
package org . languagetool . rules . de ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . language . German ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import java . util . ResourceBundle ; public class MissingVerbRule extends GermanRule { private static final int MIN_TOKENS_FOR_ERROR = 5 ; private final PatternRule rule1 ; private final PatternRule rule2 ; private final Language language ; public MissingVerbRule ( ResourceBundle messages , German language ) { this . language = language ; rule1 = new PatternRule ( "internal" , language , Arrays . asList ( new PatternToken ( "Vielen" , true , false , false ) , new PatternToken ( "Dank" , true , false , false ) ) , "" , "" , "" ) ; rule2 = new PatternRule ( "internal" , language , Arrays . asList ( new PatternToken ( "Herzlichen" , true , false , false ) , new PatternToken ( "Glückwunsch" , true , false , false ) ) , "" , "" , "" ) ; super . setCategory ( new Category ( messages . getString ( "category_grammar" ) ) ) ; setDefaultOff ( ) ; addExamplePair ( Example . wrong ( "<marker>In diesem Satz kein Wort.</marker>" ) , Example . fixed ( "In diesem Satz <marker>fehlt</marker> kein Wort." ) ) ; } @ Override public String getId ( ) { return "MISSING_VERB" ; } @ Override public String getDescription ( ) { return "Satz ohne Verb" ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { if ( ! isRealSentence ( sentence ) ) { return new RuleMatch [ 0 ] ; } if ( isSpecialCase ( sentence ) ) { return new RuleMatch [ 0 ] ; } boolean verbFound = false ; AnalyzedTokenReadings lastToken = null ; int i = 0 ; for ( AnalyzedTokenReadings readings : sentence . getTokensWithoutWhitespace ( ) ) { if ( readings . hasPartialPosTag ( "VER" ) || ( ! readings . isTagged ( ) && ! StringTools . isCapitalizedWord ( readings . getToken ( ) ) ) ) { verbFound = true ; break ; } else if ( i == 1 && verbAtSentenceStart ( readings ) ) { verbFound = true ; break ; } lastToken = readings ; i ++ ; } if ( ! verbFound && lastToken != null && i - 1 >= MIN_TOKENS_FOR_ERROR ) { RuleMatch match = new RuleMatch ( this , 0 , lastToken . getStartPos ( ) + lastToken . getToken ( ) . length ( ) , "Dieser Satz scheint kein Verb zu enthalten" ) ; return new RuleMatch [ ] { match } ; } return new RuleMatch [ 0 ] ; } private boolean isRealSentence ( AnalyzedSentence sentence ) { AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; if ( tokens . length > 0 ) { AnalyzedTokenReadings lastToken = tokens [ tokens . length - 1 ] ; String lastTokenStr = lastToken . getToken ( ) ; if ( lastTokenStr . equals ( "." ) || lastTokenStr . equals ( "?" ) || lastTokenStr . equals ( "!" ) ) { return true ; } } return false ; } private boolean isSpecialCase ( AnalyzedSentence sentence ) throws IOException { return rule1 . match ( sentence ) . length > 0 || rule2 . match ( sentence ) . length > 0 ; } private boolean verbAtSentenceStart ( AnalyzedTokenReadings readings ) throws IOException { String lowercased = StringTools . lowercaseFirstChar ( readings . getToken ( ) ) ; List < AnalyzedTokenReadings > lcReadings = language . getTagger ( ) . tag ( Collections . singletonList ( lowercased ) ) ; if ( lcReadings . size ( ) > 0 && lcReadings . get ( 0 ) . hasPartialPosTag ( "VER" ) ) { return true ; } if ( ! lowercased . endsWith ( "e" ) ) { List < AnalyzedTokenReadings > lcImperativeReadings = language . getTagger ( ) . tag ( Collections . singletonList ( lowercased + "e" ) ) ; if ( lcImperativeReadings . size ( ) > 0 && lcImperativeReadings . get ( 0 ) . hasPartialPosTag ( "VER" ) ) { return true ; } } return false ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . de ; import java . net . MalformedURLException ; import java . net . URL ; import java . util . ResourceBundle ; import org . languagetool . rules . DoublePunctuationRule ; import org . languagetool . rules . Example ; public class GermanDoublePunctuationRule extends DoublePunctuationRule { public GermanDoublePunctuationRule ( final ResourceBundle messages ) { super ( messages ) ; try { setUrl ( new URL ( "http://www.canoo.net/services/GermanSpelling/Amtlich/Interpunktion/pgf101-105.html#pgf103" ) ) ; } catch ( MalformedURLException e ) { throw new RuntimeException ( e ) ; } addExamplePair ( Example . wrong ( "Sein Vater ist Regierungsrat <marker>a. D..</marker>" ) , Example . fixed ( "Sein Vater ist Regierungsrat <marker>a. D.</marker>" ) ) ; } @ Override public final String getId ( ) { return "DE_DOUBLE_PUNCTUATION" ; } @ Override protected String getDotMessage ( ) { return "Zwei aufeinander folgende Punkte. Auch wenn ein Satz mit einer Abkürzung endet, " + "endet er nur mit einem Punkt (§103 Regelwerk)." ; } }
package org . languagetool . rules . de ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . tagging . de . AnalyzedGermanToken ; import org . languagetool . tagging . de . GermanToken ; public final class GermanHelper { private GermanHelper ( ) { } public static boolean hasReadingOfType ( AnalyzedTokenReadings tokenReadings , GermanToken . POSType type ) { if ( tokenReadings == null ) { return false ; } for ( AnalyzedToken token : tokenReadings ) { if ( token . getPOSTag ( ) != null ) { if ( token . getPOSTag ( ) . equals ( JLanguageTool . SENTENCE_END_TAGNAME ) || token . getPOSTag ( ) . equals ( JLanguageTool . PARAGRAPH_END_TAGNAME ) ) { return false ; } } final AnalyzedGermanToken germanToken = new AnalyzedGermanToken ( token ) ; if ( germanToken . getType ( ) == type ) { return true ; } } return false ; } public static String getNounCase ( String posTag ) { return getIndexOrEmptyString ( posTag , 1 ) ; } public static String getNounNumber ( String posTag ) { return getIndexOrEmptyString ( posTag , 2 ) ; } public static String getNounGender ( String posTag ) { return getIndexOrEmptyString ( posTag , 3 ) ; } public static String getDeterminerDefiniteness ( String posTag ) { return getIndexOrEmptyString ( posTag , 1 ) ; } public static String getDeterminerCase ( String posTag ) { return getIndexOrEmptyString ( posTag , 2 ) ; } public static String getDeterminerNumber ( String posTag ) { return getIndexOrEmptyString ( posTag , 3 ) ; } public static String getDeterminerGender ( String posTag ) { return getIndexOrEmptyString ( posTag , 4 ) ; } private static String getIndexOrEmptyString ( String posTag , int idx ) { if ( posTag == null ) { return "" ; } String [ ] array = posTag . split ( ":" ) ; if ( array . length > idx ) { return array [ idx ] ; } else { return "" ; } } }
package org . languagetool . rules . de ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . RuleMatch ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; public class SentenceWhitespaceRule extends org . languagetool . rules . SentenceWhitespaceRule { private static final Pattern NUMBER_REGEX = Pattern . compile ( "\\d+" ) ; private boolean prevSentenceEndsWithNumber = false ; public SentenceWhitespaceRule ( ResourceBundle messages ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setLocQualityIssueType ( ITSIssueType . Whitespace ) ; } @ Override public String getId ( ) { return "DE_SENTENCE_WHITESPACE" ; } @ Override public String getDescription ( ) { return "Fehlendes Leerzeichen zwischen Sätzen oder nach Ordnungszahlen" ; } @ Override public String getMessage ( ) { if ( prevSentenceEndsWithNumber ) { return "Fügen Sie nach Ordnungszahlen (1., 2. usw.) ein Leerzeichen ein" ; } else { return "Fügen Sie zwischen Sätzen ein Leerzeichen ein" ; } } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) { AnalyzedTokenReadings [ ] tokens = sentence . getTokens ( ) ; List < RuleMatch > matches = Arrays . asList ( super . match ( sentence ) ) ; if ( tokens . length > 1 ) { String prevLastToken = tokens [ tokens . length - 2 ] . getToken ( ) ; prevSentenceEndsWithNumber = NUMBER_REGEX . matcher ( prevLastToken ) . matches ( ) ; } return toRuleMatchArray ( matches ) ; } @ Override public void reset ( ) { super . reset ( ) ; prevSentenceEndsWithNumber = false ; } }
package org . languagetool . rules . de ; import java . util . ArrayList ; import java . util . List ; class LineExpander { List < String > expandLine ( String line ) { List < String > result = new ArrayList < > ( ) ; if ( ! line . startsWith ( "#" ) && line . contains ( "/" ) ) { String [ ] parts = line . split ( "/" ) ; if ( parts . length != 2 ) { throw new RuntimeException ( "Unexpected line format, expected at most one slash: " + line ) ; } String word = parts [ 0 ] ; String suffix = parts [ 1 ] ; result . add ( word ) ; for ( int i = 0 ; i < suffix . length ( ) ; i ++ ) { char c = suffix . charAt ( i ) ; if ( c == 'S' ) { result . add ( word + "s" ) ; } else if ( c == 'N' ) { result . add ( word + "n" ) ; } else if ( c == 'A' ) { result . add ( word + "e" ) ; result . add ( word + "er" ) ; result . add ( word + "es" ) ; result . add ( word + "en" ) ; result . add ( word + "em" ) ; } else { throw new RuntimeException ( "Unknown suffix: " + suffix + " in line: " + line ) ; } } } else { result . add ( line ) ; } return result ; } }
package org . languagetool . rules . de ; import org . languagetool . rules . AbstractWordCoherencyRule ; import org . languagetool . rules . Example ; import org . languagetool . rules . WordCoherencyDataLoader ; import java . io . IOException ; import java . util . Map ; import java . util . ResourceBundle ; public class WordCoherencyRule extends AbstractWordCoherencyRule { private static final Map < String , String > wordMap = new WordCoherencyDataLoader ( ) . loadWords ( "/de/coherency.txt" ) ; public WordCoherencyRule ( ResourceBundle messages ) throws IOException { super ( messages ) ; addExamplePair ( Example . wrong ( "Die Delfine gehören zu den Zahnwalen. <marker>Delphine</marker> sind in allen Meeren verbreitet." ) , Example . fixed ( "Die Delfine gehören zu den Zahnwalen. <marker>Delfine</marker> sind in allen Meeren verbreitet." ) ) ; } @ Override protected Map < String , String > getWordMap ( ) { return wordMap ; } @ Override protected String getMessage ( String word1 , String word2 ) { return "'" + word1 + "' und '" + word2 + "' sollten nicht gleichzeitig benutzt werden" ; } @ Override public String getId ( ) { return "DE_WORD_COHERENCY" ; } @ Override public String getDescription ( ) { return "Einheitliche Schreibweise für Wörter mit mehr als einer korrekten Schreibweise" ; } }
package org . languagetool . rules . da ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class DanishPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . de ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . util . * ; class AgreementSuggestor { private final Synthesizer synthesizer ; private final AnalyzedTokenReadings determinerToken ; private final AnalyzedTokenReadings nounToken ; AgreementSuggestor ( Synthesizer synthesizer , AnalyzedTokenReadings determinerToken , AnalyzedTokenReadings nounToken ) { this . synthesizer = synthesizer ; this . determinerToken = determinerToken ; this . nounToken = nounToken ; } List < String > getSuggestions ( ) { Set < String > suggestionSet = new HashSet < > ( ) ; try { for ( AnalyzedToken token2Reading : nounToken . getReadings ( ) ) { String nounCase = GermanHelper . getNounCase ( token2Reading . getPOSTag ( ) ) ; String nounNumber = GermanHelper . getNounNumber ( token2Reading . getPOSTag ( ) ) ; String nounGender = GermanHelper . getNounGender ( token2Reading . getPOSTag ( ) ) ; for ( AnalyzedToken token1Reading : determinerToken . getReadings ( ) ) { List < String > articleSuggestions = getArticleSuggestions ( nounCase , nounNumber , nounGender , token1Reading ) ; suggestionSet . addAll ( articleSuggestions ) ; List < String > pronounSuggestions = getPronounSuggestions ( nounCase , nounNumber , nounGender , token1Reading ) ; suggestionSet . addAll ( pronounSuggestions ) ; List < String > nounSuggestions = getNounSuggestions ( token2Reading , token1Reading ) ; suggestionSet . addAll ( nounSuggestions ) ; } } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } List < String > suggestions = new ArrayList < > ( suggestionSet ) ; Collections . sort ( suggestions ) ; return suggestions ; } private List < String > getArticleSuggestions ( String nounCase , String nounNumber , String nounGender , AnalyzedToken article ) throws IOException { String determinerDefiniteness = GermanHelper . getDeterminerDefiniteness ( article . getPOSTag ( ) ) ; if ( StringTools . isEmpty ( determinerDefiniteness ) ) { return Collections . emptyList ( ) ; } String correctPosTag = "ART:" + determinerDefiniteness + ":" + nounCase + ":" + nounNumber + ":" + nounGender ; return getDeterminerSuggestionsForPosTag ( article , correctPosTag , null ) ; } private List < String > getPronounSuggestions ( String nounCase , String nounNumber , String nounGender , AnalyzedToken pronoun ) throws IOException { String correctPosTag = "PRO:POS:" + nounCase + ":" + nounNumber + ":" + nounGender + ":BEG" ; return getDeterminerSuggestionsForPosTag ( pronoun , correctPosTag , determinerToken . getToken ( ) . substring ( 0 , 1 ) ) ; } private List < String > getNounSuggestions ( AnalyzedToken token2Reading , AnalyzedToken determiner ) throws IOException { if ( determiner . getPOSTag ( ) != null && determiner . getPOSTag ( ) . endsWith ( ":STV" ) ) { return Collections . emptyList ( ) ; } String determinerCase = GermanHelper . getDeterminerCase ( determiner . getPOSTag ( ) ) ; String determinerNumber = GermanHelper . getDeterminerNumber ( determiner . getPOSTag ( ) ) ; String determinerGender = GermanHelper . getDeterminerGender ( determiner . getPOSTag ( ) ) ; String correctPosTag = "SUB:" + determinerCase + ":" + determinerNumber + ":" + determinerGender ; return getNounSuggestionsForPosTag ( determinerToken , token2Reading , correctPosTag ) ; } private List < String > getDeterminerSuggestionsForPosTag ( AnalyzedToken token1Reading , String correctPosTag , String startsWith ) throws IOException { List < String > suggestions = new ArrayList < > ( ) ; String [ ] correctedDeterminer = synthesizer . synthesize ( token1Reading , correctPosTag ) ; for ( String determiner : correctedDeterminer ) { if ( startsWith != null && ! determiner . startsWith ( startsWith ) ) { continue ; } String correctDeterminer = StringTools . isCapitalizedWord ( determinerToken . getToken ( ) ) ? StringTools . uppercaseFirstChar ( determiner ) : determiner ; suggestions . add ( correctDeterminer + " " + nounToken . getToken ( ) ) ; } return suggestions ; } private List < String > getNounSuggestionsForPosTag ( AnalyzedTokenReadings token1 , AnalyzedToken token2Reading , String correctPosTag ) throws IOException { List < String > suggestions = new ArrayList < > ( ) ; String [ ] correctedNouns = synthesizer . synthesize ( token2Reading , correctPosTag ) ; for ( String correctedNoun : correctedNouns ) { suggestions . add ( token1 . getToken ( ) + " " + correctedNoun ) ; } return suggestions ; } }
package org . languagetool . rules . de ; import org . apache . commons . lang . StringUtils ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . * ; import org . languagetool . tools . StringTools ; import java . util . * ; public class SimilarNameRule extends Rule { private static final int minLength = 4 ; private static final int maxDiff = 1 ; private final Set < String > namesSoFar = new HashSet < > ( ) ; public SimilarNameRule ( ResourceBundle messages ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_typo" ) ) ) ; addExamplePair ( Example . wrong ( "Angela Müller ist CEO. <marker>Miller</marker> wurde in Hamburg geboren." ) , Example . fixed ( "Angela Müller ist CEO. <marker>Müller</marker> wurde in Hamburg geboren." ) ) ; setDefaultOff ( ) ; } @ Override public String getId ( ) { return "DE_SIMILAR_NAMES" ; } @ Override public String getDescription ( ) { return "Mögliche Tippfehler in Namen finden" ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; for ( AnalyzedTokenReadings token : tokens ) { String word = token . getToken ( ) ; boolean isName = word . length ( ) >= minLength && token . hasPartialPosTag ( "EIG:" ) && ! token . hasPartialPosTag ( ":COU" ) ; if ( isName && StringTools . startsWithUppercase ( word ) ) { String similarName = similarName ( word ) ; if ( similarName != null ) { String msg = "'" + word + "' ähnelt dem vorher benutzten '" + similarName + "', handelt es sich evtl. um einen Tippfehler?" ; final RuleMatch ruleMatch = new RuleMatch ( this , token . getStartPos ( ) , token . getEndPos ( ) , msg ) ; ruleMatch . setSuggestedReplacement ( similarName ) ; ruleMatches . add ( ruleMatch ) ; } namesSoFar . add ( word ) ; } } return toRuleMatchArray ( ruleMatches ) ; } @ Nullable private String similarName ( String nameHere ) { for ( String name : namesSoFar ) { if ( name . equals ( nameHere ) ) { continue ; } int lenDiff = Math . abs ( name . length ( ) - nameHere . length ( ) ) ; boolean nameEndsWithS = name . endsWith ( "s" ) && ! nameHere . endsWith ( "s" ) ; boolean otherNameEndsWithS = ! name . endsWith ( "s" ) && nameHere . endsWith ( "s" ) ; if ( nameEndsWithS || otherNameEndsWithS ) { continue ; } if ( lenDiff <= maxDiff && StringUtils . getLevenshteinDistance ( name , nameHere ) <= maxDiff ) { return name ; } } return null ; } @ Override public void reset ( ) { namesSoFar . clear ( ) ; } }
package org . languagetool . rules . de ; import org . languagetool . rules . AbstractDateCheckFilter ; import java . util . Calendar ; import java . util . Locale ; public class DateCheckFilter extends AbstractDateCheckFilter { @ Override protected Calendar getCalendar ( ) { return Calendar . getInstance ( Locale . GERMANY ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfWeek ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . startsWith ( "sonnabend" ) ) return Calendar . SATURDAY ; if ( day . startsWith ( "so" ) ) return Calendar . SUNDAY ; if ( day . startsWith ( "mo" ) ) return Calendar . MONDAY ; if ( day . startsWith ( "di" ) ) return Calendar . TUESDAY ; if ( day . startsWith ( "mi" ) ) return Calendar . WEDNESDAY ; if ( day . startsWith ( "do" ) ) return Calendar . THURSDAY ; if ( day . startsWith ( "fr" ) ) return Calendar . FRIDAY ; if ( day . startsWith ( "sa" ) ) return Calendar . SATURDAY ; throw new RuntimeException ( "Could not find day of week for '" + dayStr + "'" ) ; } @ Override protected String getDayOfWeek ( Calendar date ) { return date . getDisplayName ( Calendar . DAY_OF_WEEK , Calendar . LONG , Locale . GERMAN ) ; } @ SuppressWarnings ( { "ControlFlowStatementWithoutBraces" , "MagicNumber" } ) @ Override protected int getMonth ( String monthStr ) { String mon = monthStr . toLowerCase ( ) ; if ( mon . startsWith ( "jän" ) ) return 1 ; if ( mon . startsWith ( "jan" ) ) return 1 ; if ( mon . startsWith ( "feb" ) ) return 2 ; if ( mon . startsWith ( "mär" ) ) return 3 ; if ( mon . startsWith ( "apr" ) ) return 4 ; if ( mon . startsWith ( "mai" ) ) return 5 ; if ( mon . startsWith ( "jun" ) ) return 6 ; if ( mon . startsWith ( "jul" ) ) return 7 ; if ( mon . startsWith ( "aug" ) ) return 8 ; if ( mon . startsWith ( "sep" ) ) return 9 ; if ( mon . startsWith ( "okt" ) ) return 10 ; if ( mon . startsWith ( "nov" ) ) return 11 ; if ( mon . startsWith ( "dez" ) ) return 12 ; throw new RuntimeException ( "Could not find month '" + monthStr + "'" ) ; } }
package org . languagetool . rules . de ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . Example ; import org . languagetool . rules . WordRepeatRule ; public class GermanWordRepeatRule extends WordRepeatRule { private static final Pattern PREPOSITIONS = Pattern . compile ( "ab|an|auf|bei|durch|für|in|mit|nach|ohne|über|von|zu" ) ; public GermanWordRepeatRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; addExamplePair ( Example . wrong ( "In diesem Satz <marker>ist ist</marker> ein Wort doppelt." ) , Example . fixed ( "In diesem Satz <marker>ist</marker> ein Wort doppelt." ) ) ; } @ Override public String getId ( ) { return "GERMAN_WORD_REPEAT_RULE" ; } @ Override public boolean ignore ( final AnalyzedTokenReadings [ ] tokens , final int position ) { if ( tokens [ position - 1 ] . getToken ( ) . length ( ) == 3 && tokens [ position - 1 ] . getToken ( ) . charAt ( 0 ) == 'd' ) { if ( position >= 2 && "," . equals ( tokens [ position - 2 ] . getToken ( ) ) ) { return true ; } if ( position >= 3 && "," . equals ( tokens [ position - 3 ] . getToken ( ) ) && isPreposition ( tokens [ position - 2 ] ) ) { return true ; } return false ; } if ( position != 2 && tokens [ position - 1 ] . getToken ( ) . equals ( "Sie" ) && tokens [ position ] . getToken ( ) . equals ( "sie" ) || tokens [ position - 1 ] . getToken ( ) . equals ( "sie" ) && tokens [ position ] . getToken ( ) . equals ( "Sie" ) ) { return true ; } return false ; } private boolean isPreposition ( AnalyzedTokenReadings token ) { return PREPOSITIONS . matcher ( token . getToken ( ) ) . matches ( ) ; } }
package org . languagetool . tagging . disambiguation . rules . de ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . language . German ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; public class GermanRuleDisambiguator implements Disambiguator { private final Disambiguator disambiguator = new XmlRuleDisambiguator ( new German ( ) ) ; @ Override public final AnalyzedSentence disambiguate ( AnalyzedSentence input ) throws IOException { return disambiguator . disambiguate ( input ) ; } }
package org . languagetool . tagging . de ; public final class GermanToken { private GermanToken ( ) { } public static final class POSType { public static final POSType NOMEN = new POSType ( "Nomen" ) ; public static final POSType VERB = new POSType ( "Verb" ) ; public static final POSType ADJEKTIV = new POSType ( "Adjektiv" ) ; public static final POSType DETERMINER = new POSType ( "Determiner" ) ; public static final POSType PRONOMEN = new POSType ( "Pronomen" ) ; public static final POSType PARTIZIP = new POSType ( "Partizip" ) ; public static final POSType PROPER_NOUN = new POSType ( "Eigenname" ) ; public static final POSType OTHER = new POSType ( "Other" ) ; private final String name ; private POSType ( final String name ) { this . name = name ; } @ Override public String toString ( ) { return name ; } } public static final class Kasus { public static final Kasus NOMINATIV = new Kasus ( "Nominativ" ) ; public static final Kasus AKKUSATIV = new Kasus ( "Akkusativ" ) ; public static final Kasus DATIV = new Kasus ( "Dativ" ) ; public static final Kasus GENITIV = new Kasus ( "Genitiv" ) ; public static final Kasus OTHER = new Kasus ( "Other" ) ; private final String name ; private Kasus ( final String name ) { this . name = name ; } @ Override public String toString ( ) { return name ; } } public static final class Numerus { public static final Numerus SINGULAR = new Numerus ( "Singular" ) ; public static final Numerus PLURAL = new Numerus ( "Plural" ) ; public static final Numerus OTHER = new Numerus ( "Other" ) ; private final String name ; private Numerus ( final String name ) { this . name = name ; } @ Override public String toString ( ) { return name ; } } public static final class Genus { public static final Genus NEUTRUM = new Genus ( "Neutrum" ) ; public static final Genus MASKULINUM = new Genus ( "Maskulinum" ) ; public static final Genus FEMININUM = new Genus ( "Femininum" ) ; public static final Genus OTHER = new Genus ( "Other" ) ; public static final Genus ALLGEMEIN = new Genus ( "Allgemein" ) ; private final String name ; private Genus ( final String name ) { this . name = name ; } @ Override public String toString ( ) { return name ; } } }
package org . languagetool . tagging . de ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tagging . BaseTagger ; import org . languagetool . tagging . TaggedWord ; import org . languagetool . tokenizers . de . GermanCompoundTokenizer ; import org . languagetool . tools . StringTools ; public class GermanTagger extends BaseTagger { private GermanCompoundTokenizer compoundTokenizer ; public GermanTagger ( ) { super ( "/de/german.dict" ) ; } @ Override public String getManualAdditionsFileName ( ) { return "/de/added.txt" ; } @ Nullable public AnalyzedTokenReadings lookup ( String word ) throws IOException { List < AnalyzedTokenReadings > result = tag ( Collections . singletonList ( word ) , false ) ; AnalyzedTokenReadings atr = result . get ( 0 ) ; if ( atr . getAnalyzedToken ( 0 ) . getPOSTag ( ) == null ) { return null ; } return atr ; } @ Override public List < AnalyzedTokenReadings > tag ( List < String > sentenceTokens ) throws IOException { return tag ( sentenceTokens , true ) ; } public List < AnalyzedTokenReadings > tag ( List < String > sentenceTokens , boolean ignoreCase ) throws IOException { initializeIfRequired ( ) ; boolean firstWord = true ; List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; int pos = 0 ; for ( String word : sentenceTokens ) { List < AnalyzedToken > l = new ArrayList < > ( ) ; List < TaggedWord > taggerTokens = getWordTagger ( ) . tag ( word ) ; if ( firstWord && taggerTokens . size ( ) == 0 && ignoreCase ) { taggerTokens = getWordTagger ( ) . tag ( word . toLowerCase ( ) ) ; firstWord = false ; } if ( taggerTokens . size ( ) > 0 ) { l . addAll ( getAnalyzedTokens ( taggerTokens , word ) ) ; } else { if ( ! StringTools . isEmpty ( word . trim ( ) ) ) { List < String > compoundParts = compoundTokenizer . tokenize ( word ) ; if ( compoundParts . size ( ) <= 1 ) { l . add ( getNoInfoToken ( word ) ) ; } else { String lastPart = compoundParts . get ( compoundParts . size ( ) - 1 ) ; if ( StringTools . startsWithUppercase ( word ) ) { lastPart = StringTools . uppercaseFirstChar ( lastPart ) ; } List < TaggedWord > partTaggerTokens = getWordTagger ( ) . tag ( lastPart ) ; if ( partTaggerTokens . size ( ) > 0 ) { l . addAll ( getAnalyzedTokens ( partTaggerTokens , word , compoundParts ) ) ; } else { l . add ( getNoInfoToken ( word ) ) ; } } } else { l . add ( getNoInfoToken ( word ) ) ; } } tokenReadings . add ( new AnalyzedTokenReadings ( l . toArray ( new AnalyzedToken [ l . size ( ) ] ) , pos ) ) ; pos += word . length ( ) ; } return tokenReadings ; } private synchronized void initializeIfRequired ( ) throws IOException { if ( compoundTokenizer == null ) { compoundTokenizer = new GermanCompoundTokenizer ( ) ; } } private AnalyzedToken getNoInfoToken ( String word ) { return new AnalyzedToken ( word , null , null ) ; } private List < AnalyzedToken > getAnalyzedTokens ( List < TaggedWord > taggedWords , String word ) { List < AnalyzedToken > result = new ArrayList < > ( ) ; for ( TaggedWord taggedWord : taggedWords ) { result . add ( new AnalyzedToken ( word , taggedWord . getPosTag ( ) , taggedWord . getLemma ( ) ) ) ; } return result ; } private List < AnalyzedToken > getAnalyzedTokens ( List < TaggedWord > taggedWords , String word , List < String > compoundParts ) { List < AnalyzedToken > result = new ArrayList < > ( ) ; for ( TaggedWord taggedWord : taggedWords ) { List < String > allButLastPart = compoundParts . subList ( 0 , compoundParts . size ( ) - 1 ) ; String lemma = StringTools . listToString ( allButLastPart , "" ) + StringTools . lowercaseFirstChar ( taggedWord . getLemma ( ) ) ; result . add ( new AnalyzedToken ( word , taggedWord . getPosTag ( ) , lemma ) ) ; } return result ; } }
package org . languagetool . tagging . de ; import org . languagetool . AnalyzedToken ; import org . languagetool . tagging . de . GermanToken . Genus ; import org . languagetool . tagging . de . GermanToken . Kasus ; import org . languagetool . tagging . de . GermanToken . Numerus ; import org . languagetool . tagging . de . GermanToken . POSType ; public class AnalyzedGermanToken { private final POSType type ; private final Kasus casus ; private final Numerus numerus ; private final Genus genus ; public AnalyzedGermanToken ( AnalyzedToken token ) { String posTag = token . getPOSTag ( ) ; if ( posTag == null || posTag . split ( ":" ) . length < 3 ) { type = null ; casus = null ; numerus = null ; genus = null ; return ; } final String [ ] parts = posTag . split ( ":" ) ; POSType tempType = null ; Kasus tempCasus = null ; Numerus tempNumerus = null ; Genus tempGenus = null ; for ( String part : parts ) { if ( part . equals ( "EIG" ) ) { tempType = POSType . PROPER_NOUN ; } else if ( part . equals ( "SUB" ) && tempType == null ) { tempType = POSType . NOMEN ; } else if ( part . equals ( "PA1" ) || part . equals ( "PA2" ) ) { tempType = POSType . PARTIZIP ; } else if ( part . equals ( "VER" ) && tempType == null ) { tempType = POSType . VERB ; } else if ( part . equals ( "ADJ" ) && tempType == null ) { tempType = POSType . ADJEKTIV ; } else if ( part . equals ( "PRO" ) && tempType == null ) { tempType = POSType . PRONOMEN ; } else if ( part . equals ( "ART" ) && tempType == null ) { tempType = POSType . DETERMINER ; } else if ( part . equals ( "AKK" ) ) { tempCasus = Kasus . AKKUSATIV ; } else if ( part . equals ( "GEN" ) ) { tempCasus = Kasus . GENITIV ; } else if ( part . equals ( "NOM" ) ) { tempCasus = Kasus . NOMINATIV ; } else if ( part . equals ( "DAT" ) ) { tempCasus = Kasus . DATIV ; } else if ( part . equals ( "PLU" ) ) { tempNumerus = Numerus . PLURAL ; } else if ( part . equals ( "SIN" ) ) { tempNumerus = Numerus . SINGULAR ; } else if ( part . equals ( "MAS" ) ) { tempGenus = Genus . MASKULINUM ; } else if ( part . equals ( "FEM" ) ) { tempGenus = Genus . FEMININUM ; } else if ( part . equals ( "NEU" ) ) { tempGenus = Genus . NEUTRUM ; } else if ( part . equals ( "NOG" ) ) { tempGenus = Genus . FEMININUM ; } else if ( part . equals ( "ALG" ) ) { tempGenus = Genus . ALLGEMEIN ; } } type = tempType != null ? tempType : null ; casus = tempCasus != null ? tempCasus : null ; numerus = tempNumerus != null ? tempNumerus : null ; genus = tempGenus != null ? tempGenus : null ; } public POSType getType ( ) { return type ; } public Kasus getCasus ( ) { return casus ; } public Numerus getNumerus ( ) { return numerus ; } public Genus getGenus ( ) { return genus ; } }
package org . languagetool . tokenizers . de ; import java . io . IOException ; import java . util . List ; import de . danielnaber . jwordsplitter . GermanWordSplitter ; import org . languagetool . tokenizers . Tokenizer ; public class GermanCompoundTokenizer implements Tokenizer { private final GermanWordSplitter wordSplitter ; public GermanCompoundTokenizer ( ) throws IOException { this ( true ) ; } public GermanCompoundTokenizer ( boolean strictMode ) throws IOException { wordSplitter = new GermanWordSplitter ( false ) ; wordSplitter . setStrictMode ( strictMode ) ; wordSplitter . setMinimumWordLength ( 3 ) ; } @ Override public List < String > tokenize ( String word ) { return wordSplitter . splitWord ( word ) ; } public static void main ( String [ ] args ) throws IOException { if ( args . length != 1 ) { System . out . println ( "Usage: " + GermanCompoundTokenizer . class . getSimpleName ( ) + " <wordToSplit>" ) ; System . exit ( 1 ) ; } final GermanCompoundTokenizer tokenizer = new GermanCompoundTokenizer ( ) ; System . out . println ( tokenizer . tokenize ( args [ 0 ] ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . French ; public class FrenchConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new French ( ) ; } @ Override protected String createSampleText ( ) { return "Cherchez d'autres pages de Wikipédia pointant vers ce titre." ; } }
package org . languagetool . tokenizers . da ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Danish ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class DanishSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Danish ( ) ) ; public void testTokenize ( ) { testSplit ( "Dette er en sætning." ) ; testSplit ( "Dette er en sætning. " , "Her er den næste." ) ; testSplit ( "En sætning! " , "Yderlige en." ) ; testSplit ( "En sætning... " , "Yderlige en." ) ; testSplit ( "På hjemmesiden http://www.stavekontrolden.dk bygger vi stavekontrollen." ) ; testSplit ( "Den 31.12. går ikke!" ) ; testSplit ( "Den 3.12.2011 går ikke!" ) ; testSplit ( "I det 18. og tidlige 19. århundrede hentede amerikansk kunst det meste af sin inspiration fra Europa." ) ; testSplit ( "Hendes Majestæt Dronning Margrethe II (Margrethe Alexandrine Þórhildur Ingrid, Danmarks dronning) (født 16. april 1940 på Amalienborg Slot) er siden 14. januar 1972 Danmarks regent." ) ; testSplit ( "Hun har residensbolig i Christian IX's Palæ på Amalienborg Slot." ) ; testSplit ( "Tronfølgeren ledte herefter statsrådsmøderne under Kong Frederik 9.'s fravær." ) ; testSplit ( "Marie Hvidt, Frederik IV - En letsindig alvorsmand, Gads Forlag, 2004." ) ; testSplit ( "Da vi første gang besøgte Restaurant Chr. IV, var vi de eneste gæster." ) ; testSplit ( "I dag er det den 25.12.2010." ) ; testSplit ( "I dag er det d. 25.12.2010." ) ; testSplit ( "I dag er den 13. december." ) ; testSplit ( "Arrangementet starter ca. 17:30 i dag." ) ; testSplit ( "Arrangementet starter ca. 17:30." ) ; testSplit ( "Det er nævnt i punkt 3.6.4 Rygbelastende helkropsvibrationer." ) ; testSplit ( "Rent praktisk er det også lettest lige at mødes, så der kan udveksles nøgler og brugsanvisninger etc." ) ; testSplit ( "Andre partier incl. borgerlige partier har deres særlige problemer: nogle samarbejder med apartheidstyret i Sydafrika, med NATO-landet Tyrkiet etc., men det skal så sandelig ikke begrunde en SF-offensiv for et samarbejde med et parti." ) ; testSplit ( "Hvad nu,, den bliver også." ) ; testSplit ( "Det her er det.. " , "Og her fortsætter det." ) ; testSplit ( "Dette er en(!) sætning." ) ; testSplit ( "Dette er en(!!) sætning." ) ; testSplit ( "Dette er en(?) sætning." ) ; testSplit ( "Dette er en(??) sætning." ) ; testSplit ( "Dette er en(???) sætning." ) ; testSplit ( "Militær værnepligt blev indført (traktaten krævede, at den tyske hær ikke oversteg 100.000 mand)." ) ; testSplit ( "Siden illustrerede hun \"Historierne om Regnar Lodbrog\" 1979 og \"Bjarkemål\" 1982 samt Poul Ørums \"Komedie i Florens\" 1990." ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . synthesis . fr ; import org . languagetool . synthesis . FrenchSynthesizer ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; public class FrenchSynthesizerTest extends TestCase { public final void testSynthesizeStringString ( ) throws IOException { FrenchSynthesizer synth = new FrenchSynthesizer ( ) ; assertEquals ( synth . synthesize ( dummyToken ( "blablabla" ) , "blablabla" ) . length , 0 ) ; assertEquals ( "[nagent]" , Arrays . toString ( synth . synthesize ( dummyToken ( "nager" ) , "V ind pres 3 p" ) ) ) ; } private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } }
package org . languagetool . rules . fr ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class FrenchPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . fr ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . French ; import org . languagetool . rules . GenericUnpairedBracketsRule ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Collections ; public class GenericUnpairedBracketsRuleTest extends TestCase { private GenericUnpairedBracketsRule rule ; private JLanguageTool langTool ; public void testFrenchRule ( ) throws IOException { langTool = new JLanguageTool ( new French ( ) ) ; rule = org . languagetool . rules . GenericUnpairedBracketsRuleTest . getBracketsRule ( langTool ) ; assertMatches ( "(Qu'est ce que c'est ?)" , 0 ) ; assertMatches ( "(Qu'est ce que c'est ?" , 1 ) ; } private void assertMatches ( String input , int expectedMatches ) throws IOException { final RuleMatch [ ] matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( input ) ) ) ; assertEquals ( expectedMatches , matches . length ) ; } }
package org . languagetool . rules . fr ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . French ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class QuestionWhitespaceRuleTest extends TestCase { public final void testRule ( ) throws IOException { QuestionWhitespaceRule rule = new QuestionWhitespaceRule ( TestTools . getEnglishMessages ( ) ) ; RuleMatch [ ] matches ; JLanguageTool langTool = new JLanguageTool ( new French ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "C'est vrai !" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Qu'est ce que c'est ?" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "L'enjeu de ce livre est donc triple : philosophique" ) ) . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "C'est vrai!" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "C'est vrai !" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Qu'est ce que c'est ?" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Qu'est ce que c'est?" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "L'enjeu de ce livre est donc triple: philosophique;" ) ) ; assertEquals ( 2 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "L'enjeu de ce livre est donc triple: philosophique ;" ) ) ; assertEquals ( 2 , matches . length ) ; assertEquals ( 2 , matches . length ) ; assertEquals ( 29 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 36 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( 50 , matches [ 1 ] . getFromPos ( ) ) ; assertEquals ( 52 , matches [ 1 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Le guillemet ouvrant est suivi d'un espace insécable : « mais le lieu [...] et le guillemet fermant est précédé d'un espace insécable : [...] littérature »." ) ) ; assertEquals ( 2 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Le guillemet ouvrant est suivi d'un espace insécable : «mais le lieu [...] et le guillemet fermant est précédé d'un espace insécable : [...] littérature»." ) ) ; assertEquals ( 2 , matches . length ) ; } }
package org . languagetool . rules . spelling . hunspell ; import org . languagetool . AnalyzedSentence ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . DisambiguationPatternRule ; import org . languagetool . tagging . disambiguation . rules . DisambiguationRuleLoader ; import java . io . IOException ; import java . io . InputStream ; import java . util . List ; class TestFrenchDisambiguator implements Disambiguator { @ Override public AnalyzedSentence disambiguate ( AnalyzedSentence input ) throws IOException { AnalyzedSentence sentence = input ; String filePath = "/disambiguator.xml" ; try ( InputStream inputStream = getClass ( ) . getResourceAsStream ( filePath ) ) { final DisambiguationRuleLoader ruleLoader = new DisambiguationRuleLoader ( ) ; List < DisambiguationPatternRule > disambiguationRules = ruleLoader . getRules ( inputStream ) ; for ( final DisambiguationPatternRule patternRule : disambiguationRules ) { sentence = patternRule . replace ( sentence ) ; } } catch ( Exception e ) { throw new RuntimeException ( "Problems with loading disambiguation file: " + filePath , e ) ; } return sentence ; } }
package org . languagetool . rules . spelling . hunspell ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . French ; import org . languagetool . tagging . disambiguation . Disambiguator ; import static org . junit . Assert . * ; public class HunspellRuleTest { @ Test public void testRuleWithFrench ( ) throws Exception { final French french = new French ( ) ; final HunspellRule rule = new HunspellRule ( TestTools . getMessages ( "fr" ) , french ) ; final JLanguageTool langTool = new JLanguageTool ( french ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Un test simple." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Un test simpple." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Le cœur, la sœur." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "LanguageTool" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Il arrive après-demain." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "L'Haÿ-les-Roses" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "L'Haÿ les Roses" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Aujourd'hui et jusqu'à demain." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Aujourd’hui et jusqu’à demain." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "L'Allemagne et l'Italie." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "L’Allemagne et l’Italie." ) ) . length ) ; assertEquals ( 2 , rule . match ( langTool . getAnalyzedSentence ( "L’allemagne et l’italie." ) ) . length ) ; } @ Test public void testImmunizedFrenchWord ( ) throws Exception { final French french = new French ( ) ; final HunspellRule rule = new HunspellRule ( TestTools . getMessages ( "fr" ) , french ) ; JLanguageTool langTool = new JLanguageTool ( french ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "languageTool est génial." ) ) . length ) ; final French frenchWithDisambiguator = new French ( ) { @ Override public Disambiguator getDisambiguator ( ) { return new TestFrenchDisambiguator ( ) ; } } ; langTool = new JLanguageTool ( frenchWithDisambiguator ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "languageTool est génial." ) ) . length ) ; } }
package org . languagetool . tagging . disambiguation . rules . fr ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . French ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . disambiguation . xx . DemoDisambiguator ; import org . languagetool . tagging . fr . FrenchTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; public class FrenchRuleDisambiguatorTest extends TestCase { private FrenchTagger tagger ; private WordTokenizer tokenizer ; private SentenceTokenizer sentenceTokenizer ; private XmlRuleDisambiguator disambiguator ; private DemoDisambiguator disamb2 ; @ Override public void setUp ( ) throws IOException { tagger = new FrenchTagger ( ) ; tokenizer = new WordTokenizer ( ) ; French language = new French ( ) ; sentenceTokenizer = new SRXSentenceTokenizer ( language ) ; disambiguator = new XmlRuleDisambiguator ( language ) ; disamb2 = new DemoDisambiguator ( ) ; } public void testChunker ( ) throws IOException { TestTools . myAssert ( "Il a enfin publié son livre." , "/[null]SENT_START Il/[il]R pers suj 3 m s /[null]null a/[avoir]V avoir ind pres 3 s /[null]null enfin/[enfin]A /[null]null publié/[publier]V ppa m s /[null]null son/[son]D e s /[null]null livre/[livre]N e s ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Je danse toutes les semaines au club." , "/[null]SENT_START Je/[je]R pers suj 1 s /[null]null danse/[danser]V ind pres 1 s|danse/[danser]V sub pres 1 s /[null]null toutes/[tous]R f p|toutes/[tout]D f p /[null]null les/[le]D e p /[null]null semaines/[semaine]N f p /[null]null au/[au]D m s /[null]null club/[club]N m s ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Je danse toutes les semaines au club." , "/[null]SENT_START Je/[je]R pers suj 1 s /[null]null danse/[danse]N f s|danse/[danser]V imp pres 2 s|danse/[danser]V ind pres 1 s|danse/[danser]V ind pres 3 s|danse/[danser]V sub pres 1 s|danse/[danser]V sub pres 3 s /[null]null toutes/[tous]R f p|toutes/[tout]D f p /[null]null les/[le]D e p|les/[les]R pers obj 3 p /[null]null semaines/[semaine]N f p /[null]null au/[au]D m s /[null]null club/[club]N m s ./[null]null" , tokenizer , sentenceTokenizer , tagger , disamb2 ) ; TestTools . myAssert ( "Quand j'étais petit, je jouais au football." , "/[null]SENT_START Quand/[quand]C sub /[null]null j/[je]R pers suj 1 s '/[null]null étais/[être]V etre ind impa 1 s /[null]null petit/[petit]J m s ,/[null]null /[null]null je/[je]R pers suj 1 s /[null]null jouais/[jouer]V ind impa 1 s /[null]null au/[au]D m s /[null]null football/[football]N m s ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Quand j'étais petit, je jouais au football." , "/[null]SENT_START Quand/[quand]C sub /[null]null j/[j]N m sp|j/[je]R pers suj 1 s '/[null]null étais/[étai]N m p|étais/[être]V etre ind impa 1 s|étais/[être]V etre ind impa 2 s /[null]null petit/[petit]J m s|petit/[petit]N m s ,/[null]null /[null]null je/[je]R pers suj 1 s /[null]null jouais/[jouer]V ind impa 1 s|jouais/[jouer]V ind impa 2 s /[null]null au/[au]D m s /[null]null football/[football]N m s ./[null]null" , tokenizer , sentenceTokenizer , tagger , disamb2 ) ; TestTools . myAssert ( "Je suis petite." , "/[null]SENT_START Je/[je]R pers suj 1 s /[null]null suis/[être]V etre ind pres 1 s /[null]null petite/[petit]J f s ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "Je suis petite." , "/[null]SENT_START Je/[je]R pers suj 1 s /[null]null suis/[suivre]V imp pres 2 s|suis/[suivre]V ind pres 1 s|suis/[suivre]V ind pres 2 s|suis/[être]V etre ind pres 1 s /[null]null petite/[petit]J f s|petite/[petit]N f s ./[null]null" , tokenizer , sentenceTokenizer , tagger , disamb2 ) ; } }
package org . languagetool . tagging . fr ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . French ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; public class FrenchTaggerTest extends TestCase { private FrenchTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new FrenchTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new French ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "C'est la vie." , "C/[C]N m sp|C/[c]N m sp|C/[c]R dem e s -- est/[est]N m s|est/[être]V etre ind pres 3 s -- la/[la]N m sp|la/[la]R pers obj 3 f s|la/[le]D f s -- vie/[vie]N f s" , tokenizer , tagger ) ; TestTools . myAssert ( "Je ne parle pas français." , "Je/[je]R pers suj 1 s -- ne/[null]null -- parle/[parler]V imp pres 2 s|parle/[parler]V ind pres 1 s|parle/[parler]V ind pres 3 s|parle/[parler]V sub pres 1 s|parle/[parler]V sub pres 3 s -- pas/[pas]N m sp -- français/[français]J m sp|français/[français]N m sp" , tokenizer , tagger ) ; TestTools . myAssert ( "blablabla" , "blablabla/[blablabla]N m s" , tokenizer , tagger ) ; TestTools . myAssert ( "passagère" , "passagère/[passager]J f s|passagère/[passager]N f s" , tokenizer , tagger ) ; TestTools . myAssert ( "non_existing_word" , "non_existing_word/[null]null" , tokenizer , tagger ) ; } }
package org . languagetool . language ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import java . io . IOException ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . fr . * ; import org . languagetool . rules . spelling . hunspell . HunspellNoSuggestionRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . FrenchSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . fr . FrenchHybridDisambiguator ; import org . languagetool . tagging . fr . FrenchTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class French extends Language { private SentenceTokenizer sentenceTokenizer ; private Synthesizer synthesizer ; private Tagger tagger ; private Disambiguator disambiguator ; @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public String getName ( ) { return "French" ; } @ Override public String getShortName ( ) { return "fr" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "FR" , "" , "BE" , "CH" , "CA" , "LU" , "MC" , "CM" , "CI" , "HT" , "ML" , "SN" , "CD" , "MA" , "RE" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new FrenchTagger ( ) ; } return tagger ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new FrenchSynthesizer ( ) ; } return synthesizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new FrenchHybridDisambiguator ( ) ; } return disambiguator ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { Contributors . DOMINIQUE_PELLE , new Contributor ( "Agnes Souque" ) , new Contributor ( "Hugo Voisard (2006-2007)" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages , Arrays . asList ( "[" , "(" , "{" ) , Arrays . asList ( "]" , ")" , "}" ) ) , new HunspellNoSuggestionRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new SentenceWhitespaceRule ( messages ) , new CompoundRule ( messages ) , new QuestionWhitespaceRule ( messages ) ) ; } }
package org . languagetool . synthesis ; public class FrenchSynthesizer extends BaseSynthesizer { public FrenchSynthesizer ( ) { super ( "/fr/french_synth.dict" , "/fr/french_tags.txt" ) ; } }
package org . languagetool . language ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . spelling . hunspell . HunspellNoSuggestionRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . da . DanishTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Danish extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; private Disambiguator disambiguator ; @ Override public String getName ( ) { return "Danish" ; } @ Override public String getShortName ( ) { return "da" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "DK" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new DanishTagger ( ) ; } return tagger ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new XmlRuleDisambiguator ( new Danish ( ) ) ; } return disambiguator ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Esben Aaberg" ) , new Contributor ( "Henrik Bendt" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages , Arrays . asList ( "[" , "(" , "{" , "\"" , "”" ) , Arrays . asList ( "]" , ")" , "}" , "\"" , "”" ) ) , new HunspellNoSuggestionRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) ) ; } }
package org . languagetool . rules . fr ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; import org . languagetool . rules . Example ; public class CompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/fr/compounds.txt" ) ; public CompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "Écrivez avec un trait d’union." , "Écrivez avec un mot seul sans espace ni trait d’union." , "Écrivez avec un mot seul ou avec trait d’union." , "Erreur de trait d’union" ) ; addExamplePair ( Example . wrong ( "Le <marker>Haut Rhin</marker>." ) , Example . fixed ( "Le <marker>Haut-Rhin</marker>." ) ) ; } @ Override public String getId ( ) { return "FR_COMPOUNDS" ; } @ Override public String getDescription ( ) { return "Mots avec trait d’union" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . rules . fr ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . Category ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tools . StringTools ; public class QuestionWhitespaceRule extends FrenchRule { private static final Pattern urlPattern = Pattern . compile ( "^(file|s?ftp|finger|git|gopher|hdl|https?|shttp|imap|mailto|mms|nntp|s?news(post|reply)?|prospero|rsync|rtspu|sips?|svn|svn\\+ssh|telnet|wais)$" ) ; public QuestionWhitespaceRule ( final ResourceBundle messages ) { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } @ Override public String getId ( ) { return "FRENCH_WHITESPACE" ; } @ Override public String getDescription ( ) { return "Insertion des espaces fines insécables" ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokens ( ) ; String prevToken = "" ; for ( int i = 1 ; i < tokens . length ; i ++ ) { final String token = tokens [ i ] . getToken ( ) ; final boolean isWhiteBefore = tokens [ i ] . isWhitespaceBefore ( ) ; String msg = null ; int fixLen = 0 ; String suggestionText = null ; if ( isWhiteBefore ) { switch ( token ) { case "?" : msg = "Point d'interrogation est précédé d'une espace fine insécable." ; suggestionText = " ?" ; fixLen = 1 ; break ; case "!" : msg = "Point d'exclamation est précédé d'une espace fine insécable." ; suggestionText = " !" ; fixLen = 1 ; break ; case "»" : msg = "Le guillemet fermant est précédé d'une espace fine insécable." ; suggestionText = " »" ; fixLen = 1 ; break ; case ";" : msg = "Point-virgule est précédé d'une espace fine insécable." ; suggestionText = " ;" ; fixLen = 1 ; break ; case ":" : msg = "Deux-points sont précédé d'une espace fine insécable." ; suggestionText = " :" ; fixLen = 1 ; break ; } } else { if ( token . equals ( "?" ) && ! prevToken . equals ( "!" ) && ! prevToken . equals ( "\u00a0" ) && ! prevToken . equals ( "\u202f" ) ) { msg = "Point d'interrogation est précédé d'une espace fine insécable." ; suggestionText = prevToken + " ?" ; fixLen = 1 ; } else if ( token . equals ( "!" ) && ! prevToken . equals ( "?" ) && ! prevToken . equals ( "\u00a0" ) && ! prevToken . equals ( "\u202f" ) ) { msg = "Point d'exclamation est précédé d'une espace fine insécable." ; suggestionText = prevToken + " !" ; fixLen = 1 ; } else if ( token . equals ( ";" ) && ! prevToken . equals ( "\u00a0" ) && ! prevToken . equals ( "\u202f" ) ) { msg = "Point-virgule est précédé d'une espace fine insécable." ; suggestionText = prevToken + " ;" ; fixLen = 1 ; } else if ( token . equals ( ":" ) && ! prevToken . equals ( "\u00a0" ) && ! prevToken . equals ( "\u202f" ) ) { final Matcher matcherUrl = urlPattern . matcher ( prevToken ) ; if ( ! matcherUrl . find ( ) ) { msg = "Deux-points précédés d'une espace fine insécable." ; suggestionText = prevToken + " :" ; fixLen = 1 ; } } else if ( token . equals ( "»" ) && ! prevToken . equals ( "\u00a0" ) && ! prevToken . equals ( "\u202f" ) ) { msg = "Le guillemet fermant est précédé d'une espace fine insécable." ; suggestionText = prevToken + " »" ; fixLen = 1 ; } } if ( StringTools . isEmpty ( token ) && prevToken . equals ( "«" ) ) { msg = "Le guillemet ouvrant est suivi d'une espace fine insécable." ; suggestionText = "« " ; fixLen = 1 ; } else if ( ! StringTools . isEmpty ( token ) && prevToken . equals ( "«" ) && ! token . equals ( "\u00a0" ) && ! token . equals ( "\u202f" ) ) { msg = "Le guillemet ouvrant est suivi d'une espace fine insécable." ; suggestionText = "« " ; fixLen = 0 ; } if ( msg != null ) { final int fromPos = tokens [ i - 1 ] . getStartPos ( ) ; final int toPos = tokens [ i - 1 ] . getStartPos ( ) + fixLen + tokens [ i - 1 ] . getToken ( ) . length ( ) ; final RuleMatch ruleMatch = new RuleMatch ( this , fromPos , toPos , msg , "Insérer un espace insécable" ) ; if ( suggestionText != null ) { ruleMatch . setSuggestedReplacement ( suggestionText ) ; } ruleMatches . add ( ruleMatch ) ; } prevToken = token ; } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . fr ; import org . languagetool . rules . Rule ; public abstract class FrenchRule extends Rule { }
package org . languagetool . rules . fr ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . RuleMatch ; import java . util . Map ; public class DMYDateCheckFilter extends DateCheckFilter { @ Override public RuleMatch acceptRuleMatch ( RuleMatch match , Map < String , String > args , AnalyzedTokenReadings [ ] patternTokens ) { if ( args . containsKey ( "year" ) || args . containsKey ( "month" ) || args . containsKey ( "day" ) ) { throw new RuntimeException ( "Set only 'weekDay' and 'date' for " + DMYDateCheckFilter . class . getSimpleName ( ) ) ; } String dateString = getRequired ( "date" , args ) ; String [ ] parts = dateString . split ( "-" ) ; if ( parts . length != 3 ) { throw new RuntimeException ( "Expected date in format 'dd-mm-yyyy': '" + dateString + "'" ) ; } args . put ( "day" , parts [ 0 ] ) ; args . put ( "month" , parts [ 1 ] ) ; args . put ( "year" , parts [ 2 ] ) ; return super . acceptRuleMatch ( match , args , patternTokens ) ; } }
package org . languagetool . rules . fr ; import org . languagetool . rules . AbstractDateCheckFilter ; import java . util . Calendar ; import java . util . Locale ; public class DateCheckFilter extends AbstractDateCheckFilter { @ Override protected Calendar getCalendar ( ) { return Calendar . getInstance ( Locale . FRENCH ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfWeek ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . startsWith ( "dim" ) ) return Calendar . SUNDAY ; if ( day . startsWith ( "lun" ) ) return Calendar . MONDAY ; if ( day . startsWith ( "mar" ) ) return Calendar . TUESDAY ; if ( day . startsWith ( "mer" ) ) return Calendar . WEDNESDAY ; if ( day . startsWith ( "jeu" ) ) return Calendar . THURSDAY ; if ( day . startsWith ( "ven" ) ) return Calendar . FRIDAY ; if ( day . startsWith ( "sam" ) ) return Calendar . SATURDAY ; throw new RuntimeException ( "Could not find day of week for '" + dayStr + "'" ) ; } @ Override protected String getDayOfWeek ( Calendar date ) { return date . getDisplayName ( Calendar . DAY_OF_WEEK , Calendar . LONG , Locale . FRENCH ) ; } @ SuppressWarnings ( { "ControlFlowStatementWithoutBraces" , "MagicNumber" } ) @ Override protected int getMonth ( String monthStr ) { String mon = monthStr . toLowerCase ( ) ; if ( mon . startsWith ( "jan" ) ) return 1 ; if ( mon . startsWith ( "fév" ) ) return 2 ; if ( mon . startsWith ( "mar" ) ) return 3 ; if ( mon . startsWith ( "avr" ) ) return 4 ; if ( mon . startsWith ( "mai" ) ) return 5 ; if ( mon . startsWith ( "jui" ) ) return 6 ; if ( mon . startsWith ( "jui" ) ) return 7 ; if ( mon . startsWith ( "aou" ) || mon . startsWith ( "aoû" ) ) return 8 ; if ( mon . startsWith ( "sep" ) ) return 9 ; if ( mon . startsWith ( "oct" ) ) return 10 ; if ( mon . startsWith ( "nov" ) ) return 11 ; if ( mon . startsWith ( "déc" ) ) return 12 ; throw new RuntimeException ( "Could not find month '" + monthStr + "'" ) ; } }
package org . languagetool . tagging . disambiguation . fr ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . language . French ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . MultiWordChunker ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; public class FrenchHybridDisambiguator implements Disambiguator { private final Disambiguator chunker = new MultiWordChunker ( "/fr/multiwords.txt" ) ; private final Disambiguator disambiguator = new XmlRuleDisambiguator ( new French ( ) ) ; @ Override public final AnalyzedSentence disambiguate ( AnalyzedSentence input ) throws IOException { return disambiguator . disambiguate ( chunker . disambiguate ( input ) ) ; } }
package org . languagetool . tagging . fr ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class FrenchTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/fr/added.txt" ; } public FrenchTagger ( ) { super ( "/fr/french.dict" , Locale . FRENCH , false ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Russian ; public class RussianConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Russian ( ) ; } @ Override protected String createSampleText ( ) { return "Материал из Википедии — свободной энциклопедии" ; } }
package org . languagetool . synthesis . ru ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; public class RussianSynthesizerTest extends TestCase { private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } public final void testSynthesizeString ( ) throws IOException { RussianSynthesizer synth = new RussianSynthesizer ( ) ; assertEquals ( synth . synthesize ( dummyToken ( "blablabla" ) , "blablabla" ) . length , 0 ) ; assertEquals ( "[семья]" , Arrays . toString ( synth . synthesize ( dummyToken ( "семья" ) , "NN:Fem:Sin:Nom" ) ) ) ; assertEquals ( "[семьи]" , Arrays . toString ( synth . synthesize ( dummyToken ( "семья" ) , "NN:Fem:Sin:R" ) ) ) ; } }
package org . languagetool . rules . ru ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Russian ; import org . languagetool . rules . AbstractCompoundRuleTest ; import java . io . IOException ; public class RussianCompoundRuleTest extends AbstractCompoundRuleTest { @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; langTool = new JLanguageTool ( new Russian ( ) ) ; rule = new RussianCompoundRule ( TestTools . getEnglishMessages ( ) ) ; } public void testRule ( ) throws IOException { check ( 0 , "Он вышел из-за дома." ) ; check ( 0 , "естественно-научный" ) ; check ( 1 , "из за" , new String [ ] { "из-за" } ) ; check ( 1 , "нет нет из за да да" ) ; check ( 1 , "Ростов на Дону" , new String [ ] { "Ростов-на-Дону" } ) ; check ( 1 , "кругло суточный" , new String [ ] { "круглосуточный" } ) ; check ( 1 , "Ростов на дону" , new String [ ] { "Ростов-на-дону" } ) ; check ( 1 , "Ростов-на Дону" , new String [ ] { "Ростов-на-Дону" } ) ; check ( 0 , "во-первых" ) ; check ( 1 , "во первых" , new String [ ] { "во-первых" } ) ; } }
package org . languagetool . tagging . da ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class DanishTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/da/added.txt" ; } public DanishTagger ( ) { super ( "/da/danish.dict" , new Locale ( "da" ) ) ; } }
package org . languagetool . rules . ru ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Russian ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Collections ; public class RussianUnpairedBracketsRuleTest extends TestCase { public void testRuleRussian ( ) throws IOException { RussianUnpairedBracketsRule rule = new RussianUnpairedBracketsRule ( TestTools . getEnglishMessages ( ) , new Russian ( ) ) ; RuleMatch [ ] matches ; JLanguageTool langTool = new JLanguageTool ( new Russian ( ) ) ; matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( "(О жене и детях не беспокойся, я беру их на свои руки)." ) ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( "Позже выходит другая «южная поэма» «Бахчисарайский фонтан» (1824)." ) ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( "А \"б\" Д." ) ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( "а), б), Д)..., ДД), аа) и 1а)" ) ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( "В таком ключе был начат в мае 1823 в Кишинёве роман в стихах 'Евгений Онегин." ) ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . rules . ru ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Russian ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class RussianSimpleReplaceRuleTest extends TestCase { public void testRule ( ) throws IOException { RussianSimpleReplaceRule rule = new RussianSimpleReplaceRule ( TestTools . getMessages ( "ru" ) ) ; RuleMatch [ ] matches ; JLanguageTool langTool = new JLanguageTool ( new Russian ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Рост кораллов тут самый быстрый," ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Книга была порвана." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Книга была порвата." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 1 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( "порвана" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . ru ; import org . junit . Test ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class DateCheckFilterTest { @ Test public void testGetDayOfWeek ( ) throws Exception { DateCheckFilter filter = new DateCheckFilter ( ) ; assertThat ( filter . getDayOfWeek ( "пн" ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "пн." ) , is ( 2 ) ) ; assertThat ( filter . getDayOfWeek ( "вт" ) , is ( 3 ) ) ; assertThat ( filter . getDayOfWeek ( "пт" ) , is ( 6 ) ) ; } @ Test public void testMonth ( ) throws Exception { DateCheckFilter filter = new DateCheckFilter ( ) ; assertThat ( filter . getMonth ( "I" ) , is ( 1 ) ) ; assertThat ( filter . getMonth ( "XII" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "декабрь" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "Декабрь" ) , is ( 12 ) ) ; assertThat ( filter . getMonth ( "ДЕКАБРЬ" ) , is ( 12 ) ) ; } }
package org . languagetool . rules . ru ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class RussianPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . tagging . ru ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Russian ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; public class RussianTaggerTest extends TestCase { private RussianTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new RussianTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Russian ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "Все счастливые семьи похожи друг на друга, каждая несчастливая семья несчастлива по-своему." , "Все/[весь]PADJ:PL:Nom|Все/[весь]PADJ:PL:V|Все/[все]PNN:PL:Nom|Все/[все]PNN:PL:V|Все/[все]PNN:Sin:Nom|Все/[все]PNN:Sin:V -- счастливые/[счастливый]ADJ:PL:Nom|счастливые/[счастливый]ADJ:PL:V -- семьи/[семья]NN:Fem:PL:Nom|семьи/[семья]NN:Fem:PL:V|семьи/[семья]NN:Fem:Sin:R -- похожи/[похожий]ADJ_Short:PL -- друг/[друг]NN:Masc:Sin:Nom -- на/[на]PREP -- друга/[друг]NN:Masc:Sin:R|друга/[друг]NN:Masc:Sin:V -- каждая/[каждый]PADJ:Fem:Nom -- несчастливая/[несчастливый]ADJ:Fem:Nom -- семья/[семья]NN:Fem:Sin:Nom -- несчастлива/[несчастливый]ADJ_Short:Fem -- по-своему/[по-своему]ADV" , tokenizer , tagger ) ; TestTools . myAssert ( "Все смешалось в доме Облонских." , "Все/[весь]PADJ:PL:Nom|Все/[весь]PADJ:PL:V|Все/[все]PNN:PL:Nom|Все/[все]PNN:PL:V|Все/[все]PNN:Sin:Nom|Все/[все]PNN:Sin:V -- смешалось/[смешаться]VB:Past:Neut -- в/[в]PREP -- доме/[дом]NN:Masc:Sin:P -- Облонских/[null]null" , tokenizer , tagger ) ; } }
package org . languagetool . tokenizers . ru ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Russian ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class RussianSRXSentenceTokenizerTest extends TestCase { private final SentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Russian ( ) ) ; public final void testTokenize ( ) { testSplit ( "Отток капитала из России составил 7 млрд. долларов, сообщил министр финансов Алексей Кудрин." ) ; testSplit ( "Журнал издаётся с 1967 г., пользуется большой популярностью в мире." ) ; testSplit ( "С 2007 г. периодичность выхода газеты – 120 раз в год." ) ; testSplit ( "Редакция журнала находится в здании по адресу: г. Москва, 110000, улица Мира, д. 1." ) ; testSplit ( "Все эти вопросы заставляют нас искать ответы в нашей истории 60-80-х гг. прошлого столетия." ) ; testSplit ( "Более 300 тыс. документов и справочников." ) ; testSplit ( "Скидки до 50000 руб. на автомобили." ) ; testSplit ( "Изготовление визиток любыми тиражами (от 20 шт. до 10 тысяч) в минимальные сроки (от 20 минут)." ) ; } private void testSplit ( final String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . ru . RussianCompoundRule ; import org . languagetool . rules . ru . RussianSimpleReplaceRule ; import org . languagetool . rules . ru . RussianUnpairedBracketsRule ; import org . languagetool . rules . ru . RussianWordRepeatRule ; import org . languagetool . rules . ru . MorfologikRussianSpellerRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . ru . RussianSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . ru . RussianHybridDisambiguator ; import org . languagetool . tagging . ru . RussianTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Russian extends Language { private Tagger tagger ; private Disambiguator disambiguator ; private Synthesizer synthesizer ; private SentenceTokenizer sentenceTokenizer ; @ Override public String getName ( ) { return "Russian" ; } @ Override public String getShortName ( ) { return "ru" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "RU" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new RussianTagger ( ) ; } return tagger ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new RussianHybridDisambiguator ( ) ; } return disambiguator ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new RussianSynthesizer ( ) ; } return synthesizer ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Yakov Reztsov" , "http://myooo.ru/content/view/83/43/" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new UppercaseSentenceStartRule ( messages , this ) , new MorfologikRussianSpellerRule ( messages , this ) , new WordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new RussianUnpairedBracketsRule ( messages , this ) , new RussianCompoundRule ( messages ) , new RussianSimpleReplaceRule ( messages ) , new RussianWordRepeatRule ( messages ) ) ; } }
package org . languagetool . synthesis . ru ; import org . languagetool . synthesis . BaseSynthesizer ; public class RussianSynthesizer extends BaseSynthesizer { private static final String RESOURCE_FILENAME = "/ru/russian_synth.dict" ; private static final String TAGS_FILE_NAME = "/ru/tags_russian.txt" ; public RussianSynthesizer ( ) { super ( RESOURCE_FILENAME , TAGS_FILE_NAME ) ; } }
package org . languagetool . rules . ru ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; public class RussianCompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/ru/compounds.txt" ) ; public RussianCompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "Эти слова должны быть написаны через дефис." , "Эти слова должны быть написаны слитно." , "Эти слова могут быть написаны через дефис или слитно." ) ; } @ Override public String getId ( ) { return "RU_COMPOUNDS" ; } @ Override public String getDescription ( ) { return "Правописание через дефис" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . rules . ru ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . AbstractSimpleReplaceRule ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; public class RussianSimpleReplaceRule extends AbstractSimpleReplaceRule { private static final Map < String , List < String > > wrongWords = load ( "/ru/replace.txt" ) ; private static final Locale RU_LOCALE = new Locale ( "ru" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public RussianSimpleReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; } @ Override public final String getId ( ) { return "RU_SIMPLE_REPLACE" ; } @ Override public String getDescription ( ) { return "Поиск ошибочных слов/фраз" ; } @ Override public String getShort ( ) { return "Ошибка?" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return tokenStr + " - ошибочное слово/фраза, исправление: " + StringUtils . join ( replacements , ", " ) + "." ; } @ Override public boolean isCaseSensitive ( ) { return false ; } @ Override public Locale getLocale ( ) { return RU_LOCALE ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Slovak ; public class SlovakConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Slovak ( ) ; } @ Override protected String createSampleText ( ) { return "Wikipédia neobsahuje článok s takýmto názvom." ; } }
package org . languagetool . rules . ru ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import org . languagetool . Language ; import org . languagetool . rules . GenericUnpairedBracketsRule ; public class RussianUnpairedBracketsRule extends GenericUnpairedBracketsRule { private static final List < String > RU_START_SYMBOLS = Arrays . asList ( "(" , "{" , "„" , "\"" , "'" ) ; private static final List < String > RU_END_SYMBOLS = Arrays . asList ( ")" , "}" , "“" , "\"" , "'" ) ; private static final Pattern NUMERALS_RU = Pattern . compile ( "(?i)\\d{1,2}?[а-я]*|[а-я]|[А-Я]|[а-я][а-я]|[А-Я][А-Я]|(?i)\\d{1,2}?[a-z']*|M*(D?C{0,3}|C[DM])(L?X{0,3}|X[LC])(V?I{0,3}|I[VX])$" ) ; public RussianUnpairedBracketsRule ( final ResourceBundle messages , final Language language ) { super ( messages , RU_START_SYMBOLS , RU_END_SYMBOLS ) ; numerals = NUMERALS_RU ; } @ Override public String getId ( ) { return "RU_UNPAIRED_BRACKETS" ; } }
package org . languagetool . rules . ru ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikRussianSpellerRule extends MorfologikSpellerRule { public static final String RULE_ID = "MORFOLOGIK_RULE_RU_RU" ; private static final String RESOURCE_FILENAME = "/ru/hunspell/ru_RU.dict" ; public MorfologikRussianSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return RULE_ID ; } }
package org . languagetool . rules . ru ; import java . util . Collections ; import java . util . HashSet ; import java . util . ResourceBundle ; import java . util . Set ; import java . util . regex . Pattern ; import org . languagetool . rules . AdvancedWordRepeatRule ; public class RussianWordRepeatRule extends AdvancedWordRepeatRule { private static final Set < String > EXC_WORDS ; static { final Set < String > tempSet = new HashSet < > ( ) ; tempSet . add ( "не" ) ; tempSet . add ( "ни" ) ; tempSet . add ( "а" ) ; tempSet . add ( "на" ) ; tempSet . add ( "в" ) ; EXC_WORDS = Collections . unmodifiableSet ( tempSet ) ; } private static final Pattern EXC_POS = Pattern . compile ( "INTERJECTION|PRDC|PNN:.*" ) ; private static final Pattern EXC_NONWORDS = Pattern . compile ( "&quot|&gt|&lt|&amp|[0-9].*|" + "M*(D?C{0,3}|C[DM])(L?X{0,3}|X[LC])(V?I{0,3}|I[VX])$" ) ; public RussianWordRepeatRule ( final ResourceBundle messages ) { super ( messages ) ; } @ Override public final String getId ( ) { return "RU_WORD_REPEAT" ; } @ Override public final String getDescription ( ) { return "Повтор слов в предложении" ; } @ Override protected Set < String > getExcludedWordsPattern ( ) { return EXC_WORDS ; } @ Override protected Pattern getExcludedNonWordsPattern ( ) { return EXC_NONWORDS ; } @ Override protected Pattern getExcludedPos ( ) { return EXC_POS ; } @ Override public final String getMessage ( ) { return "Повтор слов в предложении" ; } @ Override public final String getShortMessage ( ) { return "Повтор слов в предложении" ; } }
package org . languagetool . rules . ru ; import org . languagetool . rules . Rule ; public abstract class RussianRule extends Rule { }
package org . languagetool . rules . ru ; import org . languagetool . rules . AbstractDateCheckFilter ; import java . util . Calendar ; import java . util . Locale ; public class DateCheckFilter extends AbstractDateCheckFilter { @ Override protected Calendar getCalendar ( ) { return Calendar . getInstance ( Locale . forLanguageTag ( "ru" ) ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfWeek ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . startsWith ( "пн" ) || day . equals ( "понедельник" ) ) return Calendar . MONDAY ; if ( day . startsWith ( "вт" ) ) return Calendar . TUESDAY ; if ( day . startsWith ( "ср" ) ) return Calendar . WEDNESDAY ; if ( day . startsWith ( "чт" ) || day . equals ( "четверг" ) ) return Calendar . THURSDAY ; if ( day . equals ( "пт" ) || day . equals ( "пятница" ) ) return Calendar . FRIDAY ; if ( day . startsWith ( "сб" ) || day . equals ( "суббота" ) ) return Calendar . SATURDAY ; if ( day . startsWith ( "вс" ) || day . equals ( "воскресенье" ) ) return Calendar . SUNDAY ; throw new RuntimeException ( "Could not find day of week for '" + dayStr + "'" ) ; } @ Override protected String getDayOfWeek ( Calendar date ) { return date . getDisplayName ( Calendar . DAY_OF_WEEK , Calendar . LONG , Locale . forLanguageTag ( "ru" ) ) ; } @ SuppressWarnings ( { "ControlFlowStatementWithoutBraces" , "MagicNumber" } ) @ Override protected int getMonth ( String monthStr ) { String mon = monthStr . toLowerCase ( ) ; if ( mon . equals ( "январь" ) || monthStr . equals ( "I" ) || mon . equals ( "января" ) || mon . equals ( "янв" ) ) return 1 ; if ( mon . equals ( "февраль" ) || monthStr . equals ( "II" ) || mon . equals ( "февраля" ) || mon . equals ( "фев" ) ) return 2 ; if ( mon . equals ( "март" ) || monthStr . equals ( "III" ) || mon . equals ( "марта" ) || mon . equals ( "мар" ) ) return 3 ; if ( mon . equals ( "апрель" ) || monthStr . equals ( "IV" ) || mon . equals ( "апреля" ) || mon . equals ( "апр" ) ) return 4 ; if ( mon . equals ( "май" ) || monthStr . equals ( "V" ) || mon . equals ( "мая" ) ) return 5 ; if ( mon . equals ( "июнь" ) || monthStr . equals ( "VI" ) || mon . equals ( "июня" ) || mon . equals ( "ин" ) ) return 6 ; if ( mon . equals ( "июль" ) || monthStr . equals ( "VII" ) || mon . equals ( "июля" ) || mon . equals ( "ил" ) ) return 7 ; if ( mon . equals ( "август" ) || monthStr . equals ( "VIII" ) || mon . equals ( "августа" ) || mon . equals ( "авг" ) ) return 8 ; if ( mon . equals ( "сентябрь" ) || monthStr . equals ( "IX" ) || mon . equals ( "сентября" ) || mon . equals ( "сен" ) ) return 9 ; if ( mon . equals ( "октябрь" ) || monthStr . equals ( "X" ) || mon . equals ( "октября" ) || mon . equals ( "окт" ) ) return 10 ; if ( mon . equals ( "ноябрь" ) || monthStr . equals ( "XI" ) || mon . equals ( "ноября" ) || mon . equals ( "ноя" ) ) return 11 ; if ( mon . equals ( "декабрь" ) || monthStr . equals ( "XII" ) || mon . equals ( "декабря" ) || mon . equals ( "дек" ) ) return 12 ; throw new RuntimeException ( "Could not find month '" + monthStr + "'" ) ; } }
package org . languagetool . tagging . disambiguation . ru ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . language . Russian ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . MultiWordChunker ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; public class RussianHybridDisambiguator implements Disambiguator { private final Disambiguator chunker = new MultiWordChunker ( "/ru/multiwords.txt" ) ; private final Disambiguator disambiguator = new XmlRuleDisambiguator ( new Russian ( ) ) ; @ Override public final AnalyzedSentence disambiguate ( AnalyzedSentence input ) throws IOException { return disambiguator . disambiguate ( chunker . disambiguate ( input ) ) ; } }
package org . languagetool . tagging . ru ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class RussianTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/ru/added.txt" ; } public RussianTagger ( ) { super ( "/ru/russian.dict" , new Locale ( "ru" ) ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Khmer ; public class KhmerConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Khmer ( ) ; } @ Override protected String createSampleText ( ) { return "បច្ចុប្បន្នគ្មានអត្ថបទក្នុងទំព័រនេះទេ។" ; } }
package org . languagetool . rules . km ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Khmer ; import java . io . IOException ; public class KhmerWordRepeatRuleTest extends TestCase { public void testWordRepeatRule ( ) throws IOException { final Khmer language = new Khmer ( ) ; KhmerWordRepeatRule rule = new KhmerWordRepeatRule ( TestTools . getEnglishMessages ( ) , language ) ; JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "នេះ​ហើយៗ​នោះ។" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "គាត់​ហើយ ហើយ​ខ្ញុំ។" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "នេះ​ហើយ​ហើយ​នោះ។" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "ខ្ញុំ​និង​និង​គាត់។" ) ) . length ) ; } }
package org . languagetool . rules . km ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Khmer ; import java . io . IOException ; public class KhmerSpaceBeforeRuleTest extends TestCase { public void testSpaceBeforeRule ( ) throws IOException { final Khmer language = new Khmer ( ) ; KhmerSpaceBeforeRule rule = new KhmerSpaceBeforeRule ( TestTools . getEnglishMessages ( ) , language ) ; JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "គាត់​បាន​ទៅ ដើម្បី​ទិញ​ម្ហូប។" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "ខ្ញុំ និង​គាត់។" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "គាត់​ចង់​បាន ពីព្រោះ​គាត់​អត់​មាន។" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "គាត់​បាន​ទៅ​ដើម្បី​ទិញ​ម្ហូប។" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "ខ្ញុំ​និង​គាត់។" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "គាត់​ចង់​បាន​ពីព្រោះ​គាត់​អត់​មាន។" ) ) . length ) ; } }
package org . languagetool . synthesis . sk ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; public class SlovakSynthesizerTest extends TestCase { public final void testSynthesizeStringString ( ) throws IOException { SlovakSynthesizer synth = new SlovakSynthesizer ( ) ; assertEquals ( synth . synthesize ( dummyToken ( "blablabla" ) , "blablabla" ) . length , 0 ) ; assertEquals ( "[časopisu]" , Arrays . toString ( synth . synthesize ( dummyToken ( "časopis" ) , "SSis2" ) ) ) ; assertEquals ( "[časopisy, časopisov, časopisom, časopisy, časopisy, časopisoch, časopismi, časopis, časopisu, časopisu, časopis, časopis, časopise, časopisom]" , Arrays . toString ( synth . synthesize ( dummyToken ( "časopis" ) , "SS.*" , true ) ) ) ; } private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } }
package org . languagetool . rules . km ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class KhmerPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . Rule ; import org . languagetool . rules . km . KhmerSimpleReplaceRule ; import org . languagetool . rules . km . KhmerUnpairedBracketsRule ; import org . languagetool . rules . km . KhmerWordRepeatRule ; import org . languagetool . rules . km . KhmerSpaceBeforeRule ; import org . languagetool . rules . spelling . hunspell . HunspellRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . km . KhmerTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . km . KhmerWordTokenizer ; public class Khmer extends Language { private Tagger tagger ; private Tokenizer wordTokenizer ; private SentenceTokenizer sentenceTokenizer ; private Disambiguator disambiguator ; @ Override public String getName ( ) { return "Khmer" ; } @ Override public String getShortName ( ) { return "km" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "KH" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new KhmerTagger ( ) ; } return tagger ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new KhmerWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new XmlRuleDisambiguator ( new Khmer ( ) ) ; } return disambiguator ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Nathan Wells" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new HunspellRule ( messages , this ) , new KhmerSimpleReplaceRule ( messages ) , new KhmerWordRepeatRule ( messages , this ) , new KhmerUnpairedBracketsRule ( messages , this ) , new KhmerSpaceBeforeRule ( messages , this ) ) ; } }
package org . languagetool . rules . km ; import org . languagetool . language . Khmer ; import org . languagetool . rules . AbstractSimpleReplaceRule2 ; import org . languagetool . rules . Category ; import java . io . IOException ; import java . util . Locale ; import java . util . ResourceBundle ; public class KhmerSimpleReplaceRule extends AbstractSimpleReplaceRule2 { public static final String KHMER_SIMPLE_REPLACE_RULE = "KM_SIMPLE_REPLACE" ; private static final String FILE_NAME = "/km/coherency.txt" ; private static final Locale KM_LOCALE = new Locale ( "km" ) ; @ Override public final String getFileName ( ) { return FILE_NAME ; } public KhmerSimpleReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages , new Khmer ( ) ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } @ Override public final String getId ( ) { return KHMER_SIMPLE_REPLACE_RULE ; } @ Override public String getDescription ( ) { return "Words or groups of words that are incorrect or obsolete" ; } @ Override public String getShort ( ) { return "Consider following the spelling of Chuon Nath" ; } @ Override public String getSuggestion ( ) { return " Consider following the spelling of Chuon Nath " ; } @ Override public String getSuggestionsSeparator ( ) { return " or " ; } @ Override public Locale getLocale ( ) { return KM_LOCALE ; } }
package org . languagetool . rules . km ; import org . languagetool . Language ; import org . languagetool . rules . AbstractSpaceBeforeRule ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; public class KhmerSpaceBeforeRule extends AbstractSpaceBeforeRule { private static final Pattern CONJUNCTIONS = Pattern . compile ( "ដើម្បី|និង|ពីព្រោះ" , Pattern . CASE_INSENSITIVE | Pattern . UNICODE_CASE ) ; public KhmerSpaceBeforeRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; } @ Override public Pattern getConjunctions ( ) { return CONJUNCTIONS ; } @ Override public String getId ( ) { return "KM_SPACE_BEFORE_CONJUNCTION" ; } }
package org . languagetool . rules . km ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . Category ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public class KhmerWordRepeatRule extends Rule { public KhmerWordRepeatRule ( final ResourceBundle messages , final Language language ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } public boolean ignore ( final AnalyzedSentence sentence , final AnalyzedTokenReadings [ ] tokensWithWhiteSpace , final int position ) { final int origPos = sentence . getOriginalPosition ( position ) ; if ( position >= 1 && "\u0020" . equals ( tokensWithWhiteSpace [ origPos - 1 ] . getToken ( ) ) ) { return true ; } return false ; } @ Override public String getId ( ) { return "KM_WORD_REPEAT_RULE" ; } @ Override public String getDescription ( ) { return messages . getString ( "desc_repetition" ) ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; final AnalyzedTokenReadings [ ] tokensWithWS = sentence . getTokens ( ) ; String prevToken = "" ; for ( int i = 1 ; i < tokens . length ; i ++ ) { final String token = tokens [ i ] . getToken ( ) ; if ( isWord ( token ) && prevToken . equalsIgnoreCase ( token ) && ! ignore ( sentence , tokensWithWS , i ) ) { final int prevPos = tokens [ i - 1 ] . getStartPos ( ) ; final int pos = tokens [ i ] . getStartPos ( ) ; final RuleMatch ruleMatch = new RuleMatch ( this , prevPos , pos + prevToken . length ( ) , messages . getString ( "repetition" ) , messages . getString ( "desc_repetition_short" ) ) ; final List < String > replacements = new ArrayList < > ( ) ; replacements . add ( prevToken + " " + token ) ; replacements . add ( prevToken ) ; replacements . add ( prevToken + "ៗ" ) ; ruleMatch . setSuggestedReplacements ( replacements ) ; ruleMatches . add ( ruleMatch ) ; } prevToken = token ; } return toRuleMatchArray ( ruleMatches ) ; } private boolean isWord ( String token ) { if ( token . length ( ) == 1 ) { final char c = token . charAt ( 0 ) ; if ( ! Character . isLetter ( c ) ) { return false ; } } return true ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . km ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . GenericUnpairedBracketsRule ; public class KhmerUnpairedBracketsRule extends GenericUnpairedBracketsRule { private static final List < String > KM_START_SYMBOLS = Arrays . asList ( "[" , "(" , "{" , "“" , "\"" , "'" , "«" ) ; private static final List < String > KM_END_SYMBOLS = Arrays . asList ( "]" , ")" , "}" , "”" , "\"" , "'" , "»" ) ; public KhmerUnpairedBracketsRule ( final ResourceBundle messages , final Language language ) { super ( messages , KM_START_SYMBOLS , KM_END_SYMBOLS ) ; } @ Override public String getId ( ) { return "KM_UNPAIRED_BRACKETS" ; } }
package org . languagetool . rules . km ; import org . languagetool . rules . Rule ; public abstract class KhmerRule extends Rule { }
package org . languagetool . tagging . km ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class KhmerTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/km/added.txt" ; } public KhmerTagger ( ) { super ( "/km/khmer.dict" , new Locale ( "km" ) ) ; } }
package org . languagetool . tokenizers . km ; import java . util . ArrayList ; import java . util . List ; import java . util . StringTokenizer ; import org . languagetool . tokenizers . Tokenizer ; public class KhmerWordTokenizer implements Tokenizer { public KhmerWordTokenizer ( ) { } @ Override public List < String > tokenize ( final String text ) { final List < String > tokens = new ArrayList < > ( ) ; final StringTokenizer st = new StringTokenizer ( text , "\u17D4\u17D5\u0020\u00A0\u115f\u1160\u1680" + "\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007" + "\u2008\u2009\u200A\u200B\u200c\u200d\u200e\u200f" + "\u2028\u2029\u202a\u202b\u202c\u202d\u202e\u202f" + "\u205F\u2060\u2061\u2062\u2063\u206A\u206b\u206c\u206d" + "\u206E\u206F\u3000\u3164\ufeff\uffa0\ufff9\ufffa\ufffb" + ",.;()[]{}«»!?:\"'’‘„“”…\\/\t\n" , true ) ; while ( st . hasMoreElements ( ) ) { tokens . add ( st . nextToken ( ) ) ; } return tokens ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Asturian ; public class AsturianConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Asturian ( ) ; } @ Override protected String createSampleText ( ) { return "L'asturianu ye una llingua romancep ropia d'Asturies, perteneciente al subgrupu asturllionés." ; } }
package org . languagetool . rules . sk ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class SlovakPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . language . rules . ast ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Asturian ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import static org . junit . Assert . assertEquals ; public class MorfologikAsturianSpellerRuleTest { @ Test public void testMorfologikSpeller ( ) throws IOException { Asturian language = new Asturian ( ) ; MorfologikAsturianSpellerRule rule = new MorfologikAsturianSpellerRule ( TestTools . getMessages ( "en" ) , language ) ; JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "¿Festeyate colos correutores gramaticales?" ) ) . length ) ; RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "¿Afáyeste colos correutores gramaticales?" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 1 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 9 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( "Afayesti" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . ast ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class AsturianPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . tokenizers . ast ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Asturian ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class AsturianSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Asturian ( ) ) ; public void testTokenize ( ) { testSplit ( "De secute, los hackers de Minix aportaron idegues y códigu al núcleu Linux, y güey recibiera contribuciones de miles de programadores. " , "Torvalds sigue lliberando nueves versiones del núcleu, consolidando aportes d'otros programadores y faciendo cambios el mesmu." ) ; stokenizer . setSingleLineBreaksMarksParagraph ( false ) ; testSplit ( "De secute,\nlos hackers de Minix..." ) ; testSplit ( "De secute,\n\n" , "los hackers de Minix..." ) ; stokenizer . setSingleLineBreaksMarksParagraph ( true ) ; testSplit ( "De secute,\n" , "los hackers de Minix..." ) ; testSplit ( "De secute,\n" , "\n" , "los hackers de Minix..." ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . language . rules . ast . MorfologikAsturianSpellerRule ; import org . languagetool . rules . * ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . ast . AsturianTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Asturian extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; @ Override public String getName ( ) { return "Asturian" ; } @ Override public String getShortName ( ) { return "ast" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "ES" } ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Xesús González Rato" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages ) , new MorfologikAsturianSpellerRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) ) ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new AsturianTagger ( ) ; } return tagger ; } }
package org . languagetool . language . rules . ast ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; import java . io . IOException ; import java . util . ResourceBundle ; public class MorfologikAsturianSpellerRule extends MorfologikSpellerRule { public MorfologikAsturianSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return "/ast/hunspell/ast_ES.dict" ; } @ Override public final String getId ( ) { return "MORFOLOGIK_RULE_AST" ; } }
package org . languagetool . tagging . ast ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class AsturianTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/ast/added.txt" ; } public AsturianTagger ( ) { super ( "/ast/asturian.dict" , new Locale ( "ast" ) ) ; } }
package org . languagetool . rules . fa ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class PersianPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . fa ; import org . languagetool . TestTools ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; public class PersianSpaceBeforeRuleTest extends TestCase { private PersianSpaceBeforeRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new PersianSpaceBeforeRule ( TestTools . getEnglishMessages ( ) , TestTools . getDemoLanguage ( ) ) ; langTool = new JLanguageTool ( TestTools . getDemoLanguage ( ) ) ; } public void testRules ( ) throws IOException { assertMatches ( "به اینجا" , 1 ) ; assertMatches ( "من به اینجا" , 0 ) ; assertMatches ( "(به اینجا" , 0 ) ; } private void assertMatches ( String text , int expectedMatches ) throws IOException { assertEquals ( expectedMatches , rule . match ( langTool . getAnalyzedSentence ( text ) ) . length ) ; } }
package org . languagetool . rules . fa ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Persian ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class WordCoherencyRuleTest extends PatternRuleTest { private JLanguageTool langTool ; private Rule rule ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; langTool = new JLanguageTool ( new Persian ( ) ) ; rule = new WordCoherencyRule ( TestTools . getMessages ( "fa" ) ) ; } public void testRules ( ) throws IOException { RuleMatch [ ] matches ; matches = rule . match ( langTool . getAnalyzedSentence ( "این یک اتاق است." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "این یک اطاق است." ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . tokenizers ; import org . junit . Test ; import org . languagetool . TestTools ; import org . languagetool . language . Persian ; public class PersianSRXSentenceTokenizerTest { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Persian ( ) ) ; @ Test public void test ( ) { testSplit ( "این یک جمله است. " , "جملهٔ بعدی" ) ; testSplit ( "آیا این یک جمله است؟ " , "جملهٔ بعدی" ) ; testSplit ( "یک جمله!!! " , "جملهٔ بعدی" ) ; testSplit ( "جملهٔ اول... خوب نیست؟ " , "جملهٔ دوم." ) ; testSplit ( "جملهٔ اول (...) ادامهٔ متن. " ) ; testSplit ( "جملهٔ اول [...] ادامهٔ متن. " ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . rules . sk ; import java . io . IOException ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Slovak ; import org . languagetool . rules . AbstractCompoundRuleTest ; public class CompoundRuleTest extends AbstractCompoundRuleTest { @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; langTool = new JLanguageTool ( new Slovak ( ) ) ; rule = new CompoundRule ( TestTools . getEnglishMessages ( ) ) ; } public void testRule ( ) throws IOException { check ( 0 , "česko-slovenský" ) ; check ( 0 , "rakúsko-uhorský" ) ; check ( 1 , "bim bam" , new String [ ] { "bim-bam" } ) ; } }
package org . languagetool . language ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . fa . * ; import org . languagetool . tokenizers . PersianWordTokenizer ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; public class Persian extends Language { private SentenceTokenizer sentenceTokenizer ; private WordTokenizer wordTokenizer ; @ Override public String getName ( ) { return "Persian" ; } @ Override public String getShortName ( ) { return "fa" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "IR" , "AF" } ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public WordTokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new PersianWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Reza1615" ) , new Contributor ( "Alireza Eskandarpour Shoferi" ) , new Contributor ( "Ebrahim Byagowi" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new MultipleWhitespaceRule ( messages , this ) , new LongSentenceRule ( messages ) , new PersianCommaWhitespaceRule ( messages ) , new PersianDoublePunctuationRule ( messages ) , new PersianWordRepeatBeginningRule ( messages , this ) , new PersianWordRepeatRule ( messages , this ) , new SimpleReplaceRule ( messages ) , new PersianSpaceBeforeRule ( messages , this ) , new WordCoherencyRule ( messages ) ) ; } }
package org . languagetool . rules . fa ; import java . util . HashSet ; import java . util . ResourceBundle ; import java . util . Set ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . Example ; import org . languagetool . rules . WordRepeatBeginningRule ; public class PersianWordRepeatBeginningRule extends WordRepeatBeginningRule { public PersianWordRepeatBeginningRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; addExamplePair ( Example . wrong ( "همچنین، خیابان تقریباً کاملاً مسکونی است. <marker>همچنین</marker>، به افتخار یک شاعر نامگذاری شده‌است." ) , Example . fixed ( "همچنین، خیابان تقریباً مسکونی است. <marker>این خیابان</marker> به افتخار یک شاعر نامگذاری شده‌است." ) ) ; } @ Override public String getId ( ) { return "PERSIAN_WORD_REPEAT_BEGINNING_RULE" ; } private static final Set < String > ADVERBS = new HashSet < > ( ) ; static { ADVERBS . add ( "هم" ) ; ADVERBS . add ( "همچنین" ) ; ADVERBS . add ( "نیز" ) ; ADVERBS . add ( "از یک سو" ) ; ADVERBS . add ( "از یک طرف" ) ; ADVERBS . add ( "از طرف ديگر" ) ; ADVERBS . add ( "بنابراین" ) ; ADVERBS . add ( "حتی" ) ; ADVERBS . add ( "چنانچه" ) ; } @ Override protected boolean isAdverb ( final AnalyzedTokenReadings token ) { return ADVERBS . contains ( token . getToken ( ) ) ; } }
package org . languagetool . rules . fa ; import java . util . ResourceBundle ; import org . languagetool . rules . DoublePunctuationRule ; public class PersianDoublePunctuationRule extends DoublePunctuationRule { public PersianDoublePunctuationRule ( final ResourceBundle messages ) { super ( messages ) ; } @ Override public final String getId ( ) { return "PERSIAN_DOUBLE_PUNCTUATION" ; } @ Override public String getCommaCharacter ( ) { return "،" ; } }
package org . languagetool . rules . fa ; import org . languagetool . rules . Rule ; public abstract class PersianRule extends Rule { }
package org . languagetool . rules . fa ; import java . util . ResourceBundle ; import org . languagetool . rules . CommaWhitespaceRule ; public class PersianCommaWhitespaceRule extends CommaWhitespaceRule { public PersianCommaWhitespaceRule ( final ResourceBundle messages ) { super ( messages ) ; } @ Override public final String getId ( ) { return "PERSIAN_COMMA_PARENTHESIS_WHITESPACE" ; } @ Override public String getCommaCharacter ( ) { return "،" ; } }
package org . languagetool . rules . fa ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . AbstractSimpleReplaceRule ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . ITSIssueType ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; public class SimpleReplaceRule extends AbstractSimpleReplaceRule { private static final Map < String , List < String > > wrongWords = load ( "/fa/replace.txt" ) ; public SimpleReplaceRule ( ResourceBundle messages ) throws IOException { super ( messages ) ; super . setCategory ( new Category ( "‫اشتباه تایپی محتمل‬" ) ) ; setLocQualityIssueType ( ITSIssueType . Misspelling ) ; addExamplePair ( Example . wrong ( "وی <marker>حاظر</marker> به همکاری شد." ) , Example . fixed ( "وی <marker>حاضر</marker> به همکاری شد." ) ) ; } @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } @ Override public final String getId ( ) { return "FA_SIMPLE_REPLACE" ; } @ Override public String getDescription ( ) { return "اشتباه محتمل املائی" ; } @ Override public String getShort ( ) { return "اشتباه محتمل املائی" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return "اشتباه محتمل املائی پیداشده: " + StringUtils . join ( replacements , "، " ) + "." ; } @ Override public boolean isCaseSensitive ( ) { return false ; } @ Override public Locale getLocale ( ) { return Locale . getDefault ( ) ; } }
package org . languagetool . rules . fa ; import org . languagetool . rules . AbstractWordCoherencyRule ; import org . languagetool . rules . WordCoherencyDataLoader ; import java . io . IOException ; import java . util . Map ; import java . util . ResourceBundle ; public class WordCoherencyRule extends AbstractWordCoherencyRule { private static final Map < String , String > wordMap = new WordCoherencyDataLoader ( ) . loadWords ( "/fa/coherency.txt" ) ; public WordCoherencyRule ( ResourceBundle messages ) throws IOException { super ( messages ) ; } @ Override protected Map < String , String > getWordMap ( ) { return wordMap ; } @ Override protected String getMessage ( String word1 , String word2 ) { return "'" + word1 + "' و '" + word2 + "' نباید در یک جا استفاده شوند" ; } @ Override public String getId ( ) { return "FA_WORD_COHERENCY" ; } @ Override public String getDescription ( ) { return "چند املا برای یک کلمه که یکی از آنها اولویت بیشتری دارد" ; } }
package org . languagetool . rules . fa ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import org . languagetool . Language ; import org . languagetool . rules . AbstractSpaceBeforeRule ; public class PersianSpaceBeforeRule extends AbstractSpaceBeforeRule { private static final Pattern CONJUNCTIONS = Pattern . compile ( "و|به|با|تا|زیرا|چون|بنابراین|چونکه" ) ; public PersianSpaceBeforeRule ( ResourceBundle messages , Language language ) { super ( messages , language ) ; } @ Override protected Pattern getConjunctions ( ) { return CONJUNCTIONS ; } @ Override public String getId ( ) { return "FA_SPACE_BEFORE_CONJUNCTION" ; } @ Override public String getDescription ( ) { return "بررسی‌کردن فاصله قبل از حرف ربط" ; } @ Override protected String getShort ( ) { return "فاصلهٔ حذف‌شده" ; } @ Override protected String getSuggestion ( ) { return "فاصلهٔ قبل از حرف ربط حذف شده‌است" ; } }
package org . languagetool . rules . fa ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . Example ; import org . languagetool . rules . WordRepeatRule ; public class PersianWordRepeatRule extends WordRepeatRule { public PersianWordRepeatRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; addExamplePair ( Example . wrong ( "این کار <marker>برای برای</marker> تو بود." ) , Example . fixed ( "این کار <marker>برای</marker> تو بود." ) ) ; } @ Override public String getId ( ) { return "PERSIAN_WORD_REPEAT_RULE" ; } @ Override public boolean ignore ( AnalyzedTokenReadings [ ] tokens , int position ) { if ( wordRepetitionOf ( "لی" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "سی" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "لک" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "ریز" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "جز" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "کل" , tokens , position ) ) { return true ; } return false ; } private boolean wordRepetitionOf ( String word , AnalyzedTokenReadings [ ] tokens , int position ) { return position > 0 && tokens [ position - 1 ] . getToken ( ) . equals ( word ) && tokens [ position ] . getToken ( ) . equals ( word ) ; } }
package org . languagetool . tokenizers ; public class PersianWordTokenizer extends WordTokenizer { @ Override public String getTokenizingCharacters ( ) { return super . getTokenizingCharacters ( ) + "،؟؛" ; } }
package org . languagetool . tagging . sk ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Slovak ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; public class SlovakTaggerTest extends TestCase { private SlovakTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new SlovakTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Slovak ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "Tu nájdete vybrané čísla a obsahy časopisu Kultúra slova." , "Tu/[tu]J|Tu/[tu]PD|Tu/[tu]T -- nájdete/[nájsť]VKdpb+ -- vybrané/[vybraný]Gtfp1x|vybrané/[vybraný]Gtfp4x|vybrané/[vybraný]Gtfp5x|vybrané/[vybraný]Gtip1x|vybrané/[vybraný]Gtip4x|vybrané/[vybraný]Gtip5x|vybrané/[vybraný]Gtnp1x|vybrané/[vybraný]Gtnp4x|vybrané/[vybraný]Gtnp5x|vybrané/[vybraný]Gtns1x|vybrané/[vybraný]Gtns4x|vybrané/[vybraný]Gtns5x -- čísla/[číslo]SSnp1|čísla/[číslo]SSnp4|čísla/[číslo]SSnp5|čísla/[číslo]SSns2 -- a/[a]J|a/[a]O|a/[a]Q|a/[a]SUnp1|a/[a]SUnp2|a/[a]SUnp3|a/[a]SUnp4|a/[a]SUnp5|a/[a]SUnp6|a/[a]SUnp7|a/[a]SUns1|a/[a]SUns2|a/[a]SUns3|a/[a]SUns4|a/[a]SUns5|a/[a]SUns6|a/[a]SUns7|a/[a]T|a/[a]W|a/[as]W -- obsahy/[obsah]SSip1|obsahy/[obsah]SSip4|obsahy/[obsah]SSip5 -- časopisu/[časopis]SSis2|časopisu/[časopis]SSis3 -- Kultúra/[kultúra]SSfs1|Kultúra/[kultúra]SSfs5 -- slova/[slovo]SSns2" , tokenizer , tagger ) ; TestTools . myAssert ( "blabla" , "blabla/[null]null" , tokenizer , tagger ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Belarusian ; public class BelarusianConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Belarusian ( ) ; } @ Override protected String createSampleText ( ) { return "Гэтая старонка была сцёртая. Ніжэй паказаны журнал сціранняў і пераносаў для гэтайстаронкі." ; } }
package org . languagetool . rules . be ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class BelarusianPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . be . MorfologikBelarusianSpellerRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . xx . DemoTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Belarusian extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; @ Override public String getName ( ) { return "Belarusian" ; } @ Override public String getShortName ( ) { return "be" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "BY" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new DemoTagger ( ) ; } return tagger ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Alex Buloichik" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new MorfologikBelarusianSpellerRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) ) ; } }
package org . languagetool . rules . be ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikBelarusianSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/be/hunspell/be_BY.dict" ; public MorfologikBelarusianSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_BE_BY" ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Italian ; public class ItalianConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Italian ( ) ; } @ Override protected String createSampleText ( ) { return "Da Wikipedia, l'enciclopedia libera." ; } }
package org . languagetool . rules . it ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class ItalianPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . tagging . it ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Italian ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; public class ItalianTaggerTest extends TestCase { private ItalianTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new ItalianTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Italian ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "Non c'è linguaggio senza inganno." , "Non/[non]ADV -- c/[C]NPR -- è/[essere]AUX:ind+pres+3+s|è/[essere]VER:ind+pres+3+s -- linguaggio/[linguaggio]NOUN-M:s -- senza/[senza]CON|senza/[senza]PRE -- inganno/[ingannare]VER:ind+pres+1+s|inganno/[inganno]NOUN-M:s" , tokenizer , tagger ) ; TestTools . myAssert ( "Amo quelli che desiderano l'impossibile." , "Amo/[amare]VER:ind+pres+1+s -- quelli/[quelli]PRO-DEMO-M-P|quelli/[quello]DET-DEMO:m+p -- che/[che]CON|che/[che]DET-WH:f+p|che/[che]DET-WH:f+s|che/[che]DET-WH:m+p|che/[che]DET-WH:m+s|che/[che]WH-CHE -- desiderano/[desiderare]VER:ind+pres+3+p -- l/[null]null -- impossibile/[impossibile]ADJ:pos+f+s|impossibile/[impossibile]ADJ:pos+m+s" , tokenizer , tagger ) ; TestTools . myAssert ( "blablabla" , "blablabla/[null]null" , tokenizer , tagger ) ; } }
package org . languagetool . tokenizers . it ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Italian ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class ItalianSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Italian ( ) ) ; public void testTokenize ( ) { testSplit ( "Il Castello Reale di Racconigi è situato a Racconigi, in provincia di Cuneo ma poco distante da Torino. " , "Nel corso della sua quasi millenaria storia ha visto numerosi rimaneggiamenti e divenne di proprietà dei Savoia a partire dalla seconda metà del XIV secolo." ) ; testSplit ( "Dott. Bunsen Honeydew" ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . it . ItalianWordRepeatRule ; import org . languagetool . rules . it . MorfologikItalianSpellerRule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . it . ItalianTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Italian extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; @ Override public String getName ( ) { return "Italian" ; } @ Override public String getShortName ( ) { return "it" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "IT" , "CH" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new ItalianTagger ( ) ; } return tagger ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Contributor [ ] getMaintainers ( ) { Contributor contributor = new Contributor ( "Paolo Bianchini" ) ; return new Contributor [ ] { contributor } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new WhitespaceBeforePunctuationRule ( messages ) , new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages , Arrays . asList ( "[" , "(" , "{" , "»" , "«" ) , Arrays . asList ( "]" , ")" , "}" , "«" , "»" ) ) , new MorfologikItalianSpellerRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new ItalianWordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) ) ; } }
package org . languagetool . rules . it ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . WordRepeatRule ; public class ItalianWordRepeatRule extends WordRepeatRule { public ItalianWordRepeatRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; } @ Override public String getId ( ) { return "ITALIAN_WORD_REPEAT_RULE" ; } @ Override public boolean ignore ( AnalyzedTokenReadings [ ] tokens , int position ) { if ( wordRepetitionOf ( "via" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "così" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "Pago" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "Wagga" , tokens , position ) ) { return true ; } if ( wordRepetitionOf ( "Duran" , tokens , position ) ) { return true ; } return false ; } private boolean wordRepetitionOf ( String word , AnalyzedTokenReadings [ ] tokens , int position ) { if ( position > 2 ) { return ( tokens [ position - 1 ] . getToken ( ) . equals ( word ) && tokens [ position ] . getToken ( ) . equals ( word ) ) ; } if ( position == 2 ) { return ( tokens [ 1 ] . getToken ( ) . equalsIgnoreCase ( word ) && tokens [ 2 ] . getToken ( ) . equals ( word ) ) ; } return false ; } }
package org . languagetool . tokenizers . sk ; import junit . framework . TestCase ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . language . Slovak ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class SlovakSentenceTokenizerTest extends TestCase { private final Language lang = new Slovak ( ) ; private final SentenceTokenizer stokenizer = new SRXSentenceTokenizer ( lang ) ; private final SentenceTokenizer stokenizer2 = new SRXSentenceTokenizer ( lang ) ; @ Override public final void setUp ( ) { stokenizer . setSingleLineBreaksMarksParagraph ( true ) ; stokenizer2 . setSingleLineBreaksMarksParagraph ( false ) ; } public final void testTokenize ( ) { testSplit ( "This is a sentence. " ) ; testSplit ( "Dies ist ein Satz." ) ; testSplit ( "Dies ist ein Satz. " , "Noch einer." ) ; testSplit ( "Ein Satz! " , "Noch einer." ) ; testSplit ( "Ein Satz... " , "Noch einer." ) ; testSplit ( "Unter http://www.test.de gibt es eine Website." ) ; testSplit ( "Das ist,, also ob es bla." ) ; testSplit ( "Das ist es.. " , "So geht es weiter." ) ; testSplit ( "Das hier ist ein(!) Satz." ) ; testSplit ( "Das hier ist ein(!!) Satz." ) ; testSplit ( "Das hier ist ein(?) Satz." ) ; testSplit ( "Das hier ist ein(???) Satz." ) ; testSplit ( "Das hier ist ein(???) Satz." ) ; testSplit ( "Das war es: gar nichts." ) ; testSplit ( "Das war es: Dies ist ein neuer Satz." ) ; testSplit ( "Here's a" ) ; testSplit ( "Here's a sentence. " , "And here's one that's not comp" ) ; testSplit ( "„Prezydent jest niemądry”. " , "Tak wyszło." ) ; testSplit ( "„Prezydent jest niemądry”, powiedział premier" ) ; testSplit ( "Das Schreiben ist auf den 3.10. datiert." ) ; testSplit ( "Das Schreiben ist auf den 31.1. datiert." ) ; testSplit ( "Das Schreiben ist auf den 3.10.2000 datiert." ) ; testSplit ( "Toto 2. vydanie bolo rozobrané za 1,5 roka." ) ; testSplit ( "Festival Bažant Pohoda slávi svoje 10. výročie." ) ; testSplit ( "Dlho odkladané parlamentné voľby v Angole sa uskutočnia 5. septembra." ) ; testSplit ( "Das in Punkt 3.9.1 genannte Verhalten." ) ; testSplit ( "Aké sú skutočné príčiny tzv. transformačných príznakov?" ) ; testSplit ( "Aké príplatky zamestnancovi (napr. za nadčas) stanovuje Zákonník práce?" ) ; testSplit ( "Počas neprítomnosti zastupuje MUDr. Marianna Krupšová." ) ; testSplit ( "Staroveký Egypt vznikol okolo r. 3150 p.n.l. (tzn. 3150 pred Kr.). " , "A zanikol v r. 31 pr. Kr." ) ; testSplit ( "Temperatura wody w systemie wynosi 30°C." , "W skład obiegu otwartego wchodzi zbiornik i armatura." ) ; testSplit ( "Zabudowano kolumny o długości 45 m. " , "Woda z ujęcia jest dostarczana do zakładu." ) ; testSplit ( "Najlepszym polskim reżyserem był St. Różewicz. " , "Chodzi o brata wielkiego poety." ) ; testSplit ( "Nore M. hrozí za podvod 10 až 15 rokov." ) ; testSplit ( "To jest zmienna A." , "Zaś to jest zmienna B." ) ; testSplit ( "Mam w magazynie dwie skrzynie LMD20. " , "Jestem żołnierzem i wiem, jak można ich użyć" ) ; testSplit ( "Rytmem tej wiecznie przemijającej światowej egzystencji […] rytmem mesjańskiej natury jest szczęście." ) ; testSplit ( "This is a sentence. " ) ; testSplit ( "This is a sentence. " , "And this is another one." ) ; testSplit ( "This is a sentence." , "Isn't it?" , "Yes, it is." ) ; testSplit ( "Don't split strings like U. S. A. either." ) ; testSplit ( "Don't split strings like U.S.A. either." ) ; testSplit ( "Don't split... " , "Well you know. " , "Here comes more text." ) ; testSplit ( "Don't split... well you know. " , "Here comes more text." ) ; testSplit ( "The \".\" should not be a delimiter in quotes." ) ; testSplit ( "\"Here he comes!\" she said." ) ; testSplit ( "\"Here he comes!\", she said." ) ; testSplit ( "\"Here he comes.\" " , "But this is another sentence." ) ; testSplit ( "\"Here he comes!\". " , "That's what he said." ) ; testSplit ( "The sentence ends here. " , "(Another sentence.)" ) ; testSplit ( "He won't go. " , "Really." ) ; testSplit ( "He won't say no." , "Not really." ) ; testSplit ( "This is it: a test." ) ; TestTools . testSplit ( new String [ ] { "He won't\n\n" , "Really." } , stokenizer2 ) ; TestTools . testSplit ( new String [ ] { "He won't\n" , "Really." } , stokenizer ) ; TestTools . testSplit ( new String [ ] { "He won't\n\n" , "Really." } , stokenizer2 ) ; TestTools . testSplit ( new String [ ] { "He won't\nReally." } , stokenizer2 ) ; testSplit ( "James is from the Ireland!" , "He lives in Spain now." ) ; } private void testSplit ( final String ... sentences ) { TestTools . testSplit ( sentences , stokenizer2 ) ; } }
package org . languagetool . rules . ca ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class SimpleReplaceRuleTest extends TestCase { private SimpleReplaceRule rule ; private JLanguageTool langTool ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; rule = new SimpleReplaceRule ( TestTools . getMessages ( "ca" ) ) ; langTool = new JLanguageTool ( new Catalan ( ) ) ; } public void testRule ( ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Això està força bé." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Joan Navarro no és de Navarra ni de Jerez." ) ) . length ) ; RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "El recader fa huelga." ) ) ; assertEquals ( 2 , matches . length ) ; assertEquals ( "ordinari" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "transportista" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "vaga" , matches [ 1 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "EEUU" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "EUA" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Aconteixements" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "Esdeveniments" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules . it ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikItalianSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/it/hunspell/it_IT.dict" ; public MorfologikItalianSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_IT_IT" ; } }
package org . languagetool . tagging . it ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class ItalianTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/it/added.txt" ; } public ItalianTagger ( ) { super ( "/it/italian.dict" , Locale . ITALIAN ) ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Greek ; public class GreekConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Greek ( ) ; } @ Override protected String createSampleText ( ) { return "Δεν υπάρχει αυτή τη στιγμή λήμμα με αυτόν τον τίτλο." ; } }
package org . languagetool . rules . el ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class GreekPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . el . MorfologikGreekSpellerRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . el . GreekSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . el . GreekTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . el . GreekWordTokenizer ; public class Greek extends Language { private Disambiguator disambiguator ; private SentenceTokenizer sentenceTokenizer ; private Synthesizer synthesizer ; private Tagger tagger ; @ Override public String getShortName ( ) { return "el" ; } @ Override public String getName ( ) { return "Greek" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "GR" } ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Panagiotis Minos" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( "EL_UNPAIRED_BRACKETS" , messages , Arrays . asList ( "[" , "(" , "{" , "“" , "\"" , "«" ) , Arrays . asList ( "]" , ")" , "}" , "”" , "\"" , "»" ) ) , new LongSentenceRule ( messages ) , new MorfologikGreekSpellerRule ( messages , this ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new WordRepeatBeginningRule ( messages , this ) , new WordRepeatRule ( messages , this ) ) ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new GreekTagger ( ) ; } return tagger ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Tokenizer getWordTokenizer ( ) { return new GreekWordTokenizer ( ) ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new GreekSynthesizer ( ) ; } return synthesizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new XmlRuleDisambiguator ( new Greek ( ) ) ; } return disambiguator ; } }
package org . languagetool . synthesis . el ; import org . languagetool . synthesis . BaseSynthesizer ; public class GreekSynthesizer extends BaseSynthesizer { private static final String RESOURCE_FILENAME = "/el/greek_synth.dict" ; private static final String TAGS_FILE_NAME = "/el/greek_tags.txt" ; public GreekSynthesizer ( ) { super ( RESOURCE_FILENAME , TAGS_FILE_NAME ) ; } }
package org . languagetool . rules . el ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikGreekSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/el/hunspell/el_GR.dict" ; public MorfologikGreekSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_EL_GR" ; } }
package org . languagetool . tagging . el ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class GreekTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/el/added.txt" ; } public GreekTagger ( ) { super ( "/el/greek.dict" , new Locale ( "el" ) ) ; } }
package org . languagetool . tokenizers . el ; import java . io . IOException ; import java . io . StringReader ; import java . util . ArrayList ; import java . util . List ; import org . languagetool . tokenizers . Tokenizer ; public class GreekWordTokenizer implements Tokenizer { private GreekWordTokenizerImpl tokenizer = new GreekWordTokenizerImpl ( new StringReader ( "" ) ) ; public GreekWordTokenizer ( ) { } @ Override public List < String > tokenize ( final String text ) { final List < String > tokens = new ArrayList < > ( ) ; tokenizer . yyreset ( new StringReader ( text ) ) ; try { while ( tokenizer . getNextToken ( ) != GreekWordTokenizerImpl . YYEOF ) { tokens . add ( tokenizer . getText ( ) ) ; } } catch ( IOException ex ) { throw new RuntimeException ( ex ) ; } return tokens ; } }
package org . languagetool . tokenizers . el ; public final class GreekWordTokenizerImpl { public static final int YYEOF = - 1 ; private static final int ZZ_BUFFERSIZE = 16384 ; public static final int YYINITIAL = 0 ; private static final int ZZ_LEXSTATE [ ] = { 0 , 0 } ; private static final String ZZ_CMAP_PACKED = "\11\0\1\1\1\1\25\0\1\1\1\1\1\1\4\0\1\1\1\1" + "\1\1\2\0\1\2\1\0\1\1\1\1\12\0\1\1\1\1\37\0" + "\1\1\1\1\1\1\35\0\1\1\1\0\1\1\42\0\1\1\u0318\0" + "\1\5\12\0\1\4\7\0\1\3\u0d92\0\1\1\1\1\u051f\0\1\1" + "\u097f\0\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1" + "\1\1\1\1\1\1\1\1\1\1\1\1\1\1\10\0\1\1\1\1" + "\2\0\1\1\1\1\1\1\7\0\1\1\1\0\1\1\1\1\1\1" + "\1\1\1\1\1\1\1\1\1\1\57\0\1\1\1\1\1\1\1\1" + "\1\1\6\0\1\1\1\1\1\1\1\1\1\1\1\1\u0f90\0\1\1" + "\u0163\0\1\1\ucd9a\0\1\1\240\0\1\1\130\0\1\1\1\1\1\1" + "\4\0" ; private static final char [ ] ZZ_CMAP = zzUnpackCMap ( ZZ_CMAP_PACKED ) ; private static final int [ ] ZZ_ACTION = zzUnpackAction ( ) ; private static final String ZZ_ACTION_PACKED_0 = "\4\1\2\0" ; private static int [ ] zzUnpackAction ( ) { int [ ] result = new int [ 6 ] ; int offset = 0 ; offset = zzUnpackAction ( ZZ_ACTION_PACKED_0 , offset , result ) ; return result ; } private static int zzUnpackAction ( String packed , int offset , int [ ] result ) { int i = 0 ; int j = offset ; int l = packed . length ( ) ; while ( i < l ) { int count = packed . charAt ( i ++ ) ; int value = packed . charAt ( i ++ ) ; do result [ j ++ ] = value ; while ( -- count > 0 ) ; } return j ; } private static final int [ ] ZZ_ROWMAP = zzUnpackRowMap ( ) ; private static final String ZZ_ROWMAP_PACKED_0 = "\0\0\0\6\0\14\0\22\0\30\0\36" ; private static int [ ] zzUnpackRowMap ( ) { int [ ] result = new int [ 6 ] ; int offset = 0 ; offset = zzUnpackRowMap ( ZZ_ROWMAP_PACKED_0 , offset , result ) ; return result ; } private static int zzUnpackRowMap ( String packed , int offset , int [ ] result ) { int i = 0 ; int j = offset ; int l = packed . length ( ) ; while ( i < l ) { int high = packed . charAt ( i ++ ) < < 16 ; result [ j ++ ] = high | packed . charAt ( i ++ ) ; } return j ; } private static final int [ ] ZZ_TRANS = zzUnpackTrans ( ) ; private static final String ZZ_TRANS_PACKED_0 = "\1\2\2\3\1\4\3\2\2\0\3\2\6\0\1\2" + "\1\0\1\5\3\2\4\0\1\6\6\0\1\3" ; private static int [ ] zzUnpackTrans ( ) { int [ ] result = new int [ 36 ] ; int offset = 0 ; offset = zzUnpackTrans ( ZZ_TRANS_PACKED_0 , offset , result ) ; return result ; } private static int zzUnpackTrans ( String packed , int offset , int [ ] result ) { int i = 0 ; int j = offset ; int l = packed . length ( ) ; while ( i < l ) { int count = packed . charAt ( i ++ ) ; int value = packed . charAt ( i ++ ) ; value -- ; do result [ j ++ ] = value ; while ( -- count > 0 ) ; } return j ; } private static final int ZZ_UNKNOWN_ERROR = 0 ; private static final int ZZ_NO_MATCH = 1 ; private static final int ZZ_PUSHBACK_2BIG = 2 ; private static final String ZZ_ERROR_MSG [ ] = { "Unkown internal scanner error" , "Error: could not match input" , "Error: pushback value was too large" } ; private static final int [ ] ZZ_ATTRIBUTE = zzUnpackAttribute ( ) ; private static final String ZZ_ATTRIBUTE_PACKED_0 = "\2\1\1\11\1\1\2\0" ; private static int [ ] zzUnpackAttribute ( ) { int [ ] result = new int [ 6 ] ; int offset = 0 ; offset = zzUnpackAttribute ( ZZ_ATTRIBUTE_PACKED_0 , offset , result ) ; return result ; } private static int zzUnpackAttribute ( String packed , int offset , int [ ] result ) { int i = 0 ; int j = offset ; int l = packed . length ( ) ; while ( i < l ) { int count = packed . charAt ( i ++ ) ; int value = packed . charAt ( i ++ ) ; do result [ j ++ ] = value ; while ( -- count > 0 ) ; } return j ; } private java . io . Reader zzReader ; private int zzState ; private int zzLexicalState = YYINITIAL ; private char zzBuffer [ ] = new char [ ZZ_BUFFERSIZE ] ; private int zzMarkedPos ; private int zzCurrentPos ; private int zzStartRead ; private int zzEndRead ; private int yyline ; private int yychar ; private int yycolumn ; private boolean zzAtBOL = true ; private boolean zzAtEOF ; private boolean zzEOFDone ; public final int yychar ( ) { return yychar ; } public final String getText ( ) { return new String ( zzBuffer , zzStartRead , zzMarkedPos - zzStartRead ) ; } public GreekWordTokenizerImpl ( java . io . Reader in ) { this . zzReader = in ; } public GreekWordTokenizerImpl ( java . io . InputStream in ) { this ( new java . io . InputStreamReader ( in ) ) ; } private static char [ ] zzUnpackCMap ( String packed ) { char [ ] map = new char [ 0x10000 ] ; int i = 0 ; int j = 0 ; while ( i < 202 ) { int count = packed . charAt ( i ++ ) ; char value = packed . charAt ( i ++ ) ; do map [ j ++ ] = value ; while ( -- count > 0 ) ; } return map ; } private boolean zzRefill ( ) throws java . io . IOException { if ( zzStartRead > 0 ) { System . arraycopy ( zzBuffer , zzStartRead , zzBuffer , 0 , zzEndRead - zzStartRead ) ; zzEndRead -= zzStartRead ; zzCurrentPos -= zzStartRead ; zzMarkedPos -= zzStartRead ; zzStartRead = 0 ; } if ( zzCurrentPos >= zzBuffer . length ) { char newBuffer [ ] = new char [ zzCurrentPos * 2 ] ; System . arraycopy ( zzBuffer , 0 , newBuffer , 0 , zzBuffer . length ) ; zzBuffer = newBuffer ; } int numRead = zzReader . read ( zzBuffer , zzEndRead , zzBuffer . length - zzEndRead ) ; if ( numRead > 0 ) { zzEndRead += numRead ; return false ; } if ( numRead == 0 ) { int c = zzReader . read ( ) ; if ( c == - 1 ) { return true ; } else { zzBuffer [ zzEndRead ++ ] = ( char ) c ; return false ; } } return true ; } public final void yyclose ( ) throws java . io . IOException { zzAtEOF = true ; zzEndRead = zzStartRead ; if ( zzReader != null ) zzReader . close ( ) ; } public final void yyreset ( java . io . Reader reader ) { zzReader = reader ; zzAtBOL = true ; zzAtEOF = false ; zzEOFDone = false ; zzEndRead = zzStartRead = 0 ; zzCurrentPos = zzMarkedPos = 0 ; yyline = yychar = yycolumn = 0 ; zzLexicalState = YYINITIAL ; } public final int yystate ( ) { return zzLexicalState ; } public final void yybegin ( int newState ) { zzLexicalState = newState ; } public final String yytext ( ) { return new String ( zzBuffer , zzStartRead , zzMarkedPos - zzStartRead ) ; } public final char yycharat ( int pos ) { return zzBuffer [ zzStartRead + pos ] ; } public final int yylength ( ) { return zzMarkedPos - zzStartRead ; } private void zzScanError ( int errorCode ) { String message ; try { message = ZZ_ERROR_MSG [ errorCode ] ; } catch ( ArrayIndexOutOfBoundsException e ) { message = ZZ_ERROR_MSG [ ZZ_UNKNOWN_ERROR ] ; } throw new Error ( message ) ; } public void yypushback ( int number ) { if ( number > yylength ( ) ) zzScanError ( ZZ_PUSHBACK_2BIG ) ; zzMarkedPos -= number ; } public int getNextToken ( ) throws java . io . IOException { int zzInput ; int zzAction ; int zzCurrentPosL ; int zzMarkedPosL ; int zzEndReadL = zzEndRead ; char [ ] zzBufferL = zzBuffer ; char [ ] zzCMapL = ZZ_CMAP ; int [ ] zzTransL = ZZ_TRANS ; int [ ] zzRowMapL = ZZ_ROWMAP ; int [ ] zzAttrL = ZZ_ATTRIBUTE ; while ( true ) { zzMarkedPosL = zzMarkedPos ; yychar += zzMarkedPosL - zzStartRead ; zzAction = - 1 ; zzCurrentPosL = zzCurrentPos = zzStartRead = zzMarkedPosL ; zzState = ZZ_LEXSTATE [ zzLexicalState ] ; zzForAction : { while ( true ) { if ( zzCurrentPosL < zzEndReadL ) zzInput = zzBufferL [ zzCurrentPosL ++ ] ; else if ( zzAtEOF ) { zzInput = YYEOF ; break zzForAction ; } else { zzCurrentPos = zzCurrentPosL ; zzMarkedPos = zzMarkedPosL ; boolean eof = zzRefill ( ) ; zzCurrentPosL = zzCurrentPos ; zzMarkedPosL = zzMarkedPos ; zzBufferL = zzBuffer ; zzEndReadL = zzEndRead ; if ( eof ) { zzInput = YYEOF ; break zzForAction ; } else { zzInput = zzBufferL [ zzCurrentPosL ++ ] ; } } int zzNext = zzTransL [ zzRowMapL [ zzState ] + zzCMapL [ zzInput ] ] ; if ( zzNext == - 1 ) break zzForAction ; zzState = zzNext ; int zzAttributes = zzAttrL [ zzState ] ; if ( ( zzAttributes & 1 ) == 1 ) { zzAction = zzState ; zzMarkedPosL = zzCurrentPosL ; if ( ( zzAttributes & 8 ) == 8 ) break zzForAction ; } } } zzMarkedPos = zzMarkedPosL ; switch ( zzAction < 0 ? zzAction : ZZ_ACTION [ zzAction ] ) { case 1 : { return 0 ; } case 2 : break ; default : if ( zzInput == YYEOF && zzStartRead == zzCurrentPos ) { zzAtEOF = true ; { return - 1 ; } } else { zzScanError ( ZZ_NO_MATCH ) ; } } } } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . databroker . ResourceDataBroker ; import org . languagetool . rules . * ; import org . languagetool . rules . sk . CompoundRule ; import org . languagetool . rules . sk . MorfologikSlovakSpellerRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . sk . SlovakSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . sk . SlovakTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class Slovak extends Language { private static final List < String > RULE_FILES = Arrays . asList ( "grammar-typography.xml" ) ; private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; private Synthesizer synthesizer ; @ Override public String getName ( ) { return "Slovak" ; } @ Override public String getShortName ( ) { return "sk" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "SK" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new SlovakTagger ( ) ; } return tagger ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new SlovakSynthesizer ( ) ; } return synthesizer ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Zdenko Podobný" , "http://sk-spell.sk.cx" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages , Arrays . asList ( "[" , "(" , "{" , "„" , "»" , "«" , "\"" ) , Arrays . asList ( "]" , ")" , "}" , "“" , "«" , "»" , "\"" ) ) , new UppercaseSentenceStartRule ( messages , this ) , new WordRepeatRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new CompoundRule ( messages ) , new MorfologikSlovakSpellerRule ( messages , this ) ) ; } @ Override public List < String > getRuleFileNames ( ) { List < String > ruleFileNames = super . getRuleFileNames ( ) ; ResourceDataBroker dataBroker = JLanguageTool . getDataBroker ( ) ; String dirBase = dataBroker . getRulesDir ( ) + "/" + getShortName ( ) + "/" ; for ( String ruleFile : RULE_FILES ) { ruleFileNames . add ( dirBase + ruleFile ) ; } return ruleFileNames ; } }
package org . languagetool . gui ; import junit . framework . TestCase ; public class ToolsTest extends TestCase { public void testShortenComment ( ) { final String testString = "Lorem ipsum dolor sit amet, consectetur (adipisici elit), sed eiusmod tempor incidunt." ; final String testStringShortened = "Lorem ipsum dolor sit amet, consectetur (adipisici elit), sed eiusmod tempor incidunt." ; final String testLongString = "Lorem ipsum dolor sit amet, consectetur (adipisici elit), sed eiusmod tempor incidunt ut labore (et dolore magna aliqua)." ; final String testLongStringShortened = "Lorem ipsum dolor sit amet, consectetur (adipisici elit), sed eiusmod tempor incidunt ut labore." ; final String testVeryLongString = "Lorem ipsum dolor sit amet, consectetur (adipisici elit), sed eiusmod (tempor incidunt [ut labore et dolore magna aliqua])." ; final String testVeryLongStringShortened = "Lorem ipsum dolor sit amet, consectetur (adipisici elit), sed eiusmod (tempor incidunt)." ; final String shortenedString = Tools . shortenComment ( testString ) ; assertEquals ( testStringShortened , shortenedString ) ; final String shortenedLongString = Tools . shortenComment ( testLongString ) ; assertEquals ( testLongStringShortened , shortenedLongString ) ; final String shortenedVeryLongString = Tools . shortenComment ( testVeryLongString ) ; assertEquals ( testVeryLongStringShortened , shortenedVeryLongString ) ; } public void testGetLabel ( ) { assertEquals ( "This is a Label" , Tools . getLabel ( "This is a &Label" ) ) ; assertEquals ( "Bits & Pieces" , Tools . getLabel ( "Bits && Pieces" ) ) ; } public void testGetOOoLabel ( ) { assertEquals ( "Bits & Pieces" , Tools . getLabel ( "Bits && Pieces" ) ) ; } public void testGetMnemonic ( ) { assertEquals ( 'F' , Tools . getMnemonic ( "&File" ) ) ; assertEquals ( 'O' , Tools . getMnemonic ( "&OK" ) ) ; assertEquals ( '\u0000' , Tools . getMnemonic ( "File && String operations" ) ) ; assertEquals ( 'O' , Tools . getMnemonic ( "File && String &Operations" ) ) ; } }
package org . languagetool . gui ; import java . awt . * ; import java . io . File ; import java . io . UnsupportedEncodingException ; import java . net . URL ; import java . net . URLEncoder ; import java . text . MessageFormat ; import java . util . * ; import java . util . List ; import javax . swing . BorderFactory ; import javax . swing . JDialog ; import javax . swing . JFileChooser ; import javax . swing . JOptionPane ; import javax . swing . JScrollPane ; import javax . swing . JTextPane ; import javax . swing . event . HyperlinkEvent ; import javax . swing . event . HyperlinkListener ; import javax . swing . filechooser . FileFilter ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . Category ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . rules . Rule ; import org . languagetool . rules . patterns . FalseFriendPatternRule ; import org . languagetool . tools . StringTools ; public class Tools { private Tools ( ) { } public static String makeTexti18n ( final ResourceBundle messages , final String key , final Object ... messageArguments ) { final MessageFormat formatter = new MessageFormat ( "" ) ; formatter . applyPattern ( messages . getString ( key ) . replaceAll ( "'" , "''" ) ) ; return formatter . format ( messageArguments ) ; } static File openFileDialog ( final Frame frame , final FileFilter fileFilter ) { final JFileChooser jfc = new JFileChooser ( ) ; jfc . setFileFilter ( fileFilter ) ; jfc . showOpenDialog ( frame ) ; return jfc . getSelectedFile ( ) ; } static File openFileDialog ( final Frame frame , final FileFilter fileFilter , final File initialDir ) { final JFileChooser jfc = new JFileChooser ( ) ; jfc . setCurrentDirectory ( initialDir ) ; jfc . setFileFilter ( fileFilter ) ; jfc . showOpenDialog ( frame ) ; return jfc . getSelectedFile ( ) ; } static void showError ( final Exception e ) { String stackTrace = org . languagetool . tools . Tools . getFullStackTrace ( e ) ; final String msg = "<html><p style='width: 600px;'>" + StringTools . escapeHTML ( stackTrace ) ; JOptionPane . showMessageDialog ( null , msg , "Error" , JOptionPane . ERROR_MESSAGE ) ; e . printStackTrace ( ) ; } static void showErrorMessage ( final Exception e , final Component parent ) { final String msg = e . getMessage ( ) ; JOptionPane . showMessageDialog ( parent , msg , "Error" , JOptionPane . ERROR_MESSAGE ) ; e . printStackTrace ( ) ; } static void showErrorMessage ( final Exception e ) { showErrorMessage ( e , null ) ; } public static String shortenComment ( String comment ) { final int maxCommentLength = 100 ; if ( comment . length ( ) > maxCommentLength ) { while ( comment . lastIndexOf ( " [" ) > 0 && comment . lastIndexOf ( ']' ) > comment . lastIndexOf ( " [" ) && comment . length ( ) > maxCommentLength ) { comment = comment . substring ( 0 , comment . lastIndexOf ( " [" ) ) + comment . substring ( comment . lastIndexOf ( ']' ) + 1 ) ; } while ( comment . lastIndexOf ( " (" ) > 0 && comment . lastIndexOf ( ')' ) > comment . lastIndexOf ( " (" ) && comment . length ( ) > maxCommentLength ) { comment = comment . substring ( 0 , comment . lastIndexOf ( " (" ) ) + comment . substring ( comment . lastIndexOf ( ')' ) + 1 ) ; } if ( comment . length ( ) > maxCommentLength ) { comment = comment . substring ( 0 , maxCommentLength - 1 ) + "…" ; } } return comment ; } public static String getLabel ( final String label ) { return label . replaceAll ( "&([^&])" , "$1" ) . replaceAll ( "&&" , "&" ) ; } public static char getMnemonic ( final String label ) { int mnemonicPos = label . indexOf ( '&' ) ; while ( mnemonicPos != - 1 && mnemonicPos == label . indexOf ( "&&" ) && mnemonicPos < label . length ( ) ) { mnemonicPos = label . indexOf ( '&' , mnemonicPos + 2 ) ; } if ( mnemonicPos == - 1 || mnemonicPos == label . length ( ) ) { return '\u0000' ; } return label . charAt ( mnemonicPos + 1 ) ; } public static void centerDialog ( JDialog dialog ) { final Dimension screenSize = Toolkit . getDefaultToolkit ( ) . getScreenSize ( ) ; final Dimension frameSize = dialog . getSize ( ) ; dialog . setLocation ( screenSize . width / 2 - frameSize . width / 2 , screenSize . height / 2 - frameSize . height / 2 ) ; dialog . setLocationByPlatform ( true ) ; } static void showRuleInfoDialog ( Component parent , String title , String message , Rule rule , ResourceBundle messages , String lang ) { int dialogWidth = 320 ; JTextPane textPane = new JTextPane ( ) ; textPane . setEditable ( false ) ; textPane . setContentType ( "text/html" ) ; textPane . setBorder ( BorderFactory . createEmptyBorder ( ) ) ; textPane . setOpaque ( false ) ; textPane . setBackground ( new Color ( 0 , 0 , 0 , 0 ) ) ; textPane . addHyperlinkListener ( new HyperlinkListener ( ) { @ Override public void hyperlinkUpdate ( HyperlinkEvent e ) { if ( e . getEventType ( ) == HyperlinkEvent . EventType . ACTIVATED ) { if ( Desktop . isDesktopSupported ( ) ) { try { Desktop . getDesktop ( ) . browse ( e . getURL ( ) . toURI ( ) ) ; } catch ( Exception ex ) { Tools . showError ( ex ) ; } } } } } ) ; textPane . setSize ( dialogWidth , Short . MAX_VALUE ) ; String messageWithBold = message . replaceAll ( "<suggestion>" , "<b>" ) . replaceAll ( "</suggestion>" , "</b>" ) ; String exampleSentences = getExampleSentences ( rule , messages ) ; String url = "http://community.languagetool.org/rule/show/" + encodeUrl ( rule ) + "?lang=" + lang + "&amp;ref=standalone-gui" ; boolean isExternal = rule . getCategory ( ) . getLocation ( ) == Category . Location . EXTERNAL ; String ruleDetailLink = rule instanceof FalseFriendPatternRule || isExternal ? "" : "<a href='" + url + "'>" + messages . getString ( "ruleDetailsLink" ) + "</a>" ; textPane . setText ( "<html>" + messageWithBold + exampleSentences + formatURL ( rule . getUrl ( ) ) + "<br><br>" + ruleDetailLink + "</html>" ) ; JScrollPane scrollPane = new JScrollPane ( textPane ) ; scrollPane . setPreferredSize ( new Dimension ( dialogWidth , textPane . getPreferredSize ( ) . height ) ) ; scrollPane . setBorder ( BorderFactory . createEmptyBorder ( ) ) ; String cleanTitle = title . replace ( "<suggestion>" , "'" ) . replace ( "</suggestion>" , "'" ) ; JOptionPane . showMessageDialog ( parent , scrollPane , cleanTitle , JOptionPane . INFORMATION_MESSAGE ) ; } private static String encodeUrl ( Rule rule ) { try { return URLEncoder . encode ( rule . getId ( ) , "utf-8" ) ; } catch ( UnsupportedEncodingException e ) { throw new RuntimeException ( e ) ; } } private static String getExampleSentences ( Rule rule , ResourceBundle messages ) { StringBuilder examples = new StringBuilder ( 200 ) ; java . util . List < IncorrectExample > incorrectExamples = rule . getIncorrectExamples ( ) ; if ( incorrectExamples . size ( ) > 0 ) { String incorrectExample = incorrectExamples . iterator ( ) . next ( ) . getExample ( ) ; String sentence = incorrectExample . replace ( "<marker>" , "<span style='background-color:#ff8080'>" ) . replace ( "</marker>" , "</span>" ) ; examples . append ( "<br/>" ) . append ( sentence ) . append ( "&nbsp;<span style='color:red;font-style:italic;font-weight:bold'>x</span>" ) ; } java . util . List < String > correctExamples = rule . getCorrectExamples ( ) ; if ( correctExamples . size ( ) > 0 ) { String correctExample = correctExamples . iterator ( ) . next ( ) ; String sentence = correctExample . replace ( "<marker>" , "<span style='background-color:#80ff80'>" ) . replace ( "</marker>" , "</span>" ) ; examples . append ( "<br/>" ) . append ( sentence ) . append ( "&nbsp;<span style='color:green'>✓</span>" ) ; } else if ( incorrectExamples . size ( ) > 0 ) { IncorrectExample incorrectExample = incorrectExamples . iterator ( ) . next ( ) ; List < String > corrections = incorrectExample . getCorrections ( ) ; if ( corrections != null && corrections . size ( ) > 0 ) { String incorrectSentence = incorrectExamples . iterator ( ) . next ( ) . getExample ( ) ; String correctedSentence = incorrectSentence . replaceAll ( "<marker>.*?</marker>" , "<span style='background-color:#80ff80'>" + corrections . get ( 0 ) + "</span>" ) ; examples . append ( "<br/>" ) . append ( correctedSentence ) . append ( "&nbsp;<span style='color:green'>✓</span>" ) ; } } if ( examples . length ( ) > 0 ) { examples . insert ( 0 , "<br/><br/>" + messages . getString ( "guiExamples" ) ) ; } return examples . toString ( ) ; } private static String formatURL ( URL url ) { if ( url == null ) { return "" ; } return String . format ( "<br/><br/><a href=\"%s\">%s</a>" , url . toExternalForm ( ) , StringUtils . abbreviate ( url . toString ( ) , 50 ) ) ; } }
package org . languagetool . gui ; import java . awt . Dimension ; import java . awt . event . KeyEvent ; import java . awt . event . KeyListener ; import java . awt . event . MouseEvent ; import java . awt . event . MouseListener ; import javax . swing . JCheckBox ; import javax . swing . JTree ; import javax . swing . tree . DefaultTreeModel ; import javax . swing . tree . TreePath ; class TreeListener implements KeyListener , MouseListener { static void install ( JTree tree ) { TreeListener listener = new TreeListener ( tree ) ; tree . addMouseListener ( listener ) ; tree . addKeyListener ( listener ) ; } private static final Dimension checkBoxDimension = new JCheckBox ( ) . getPreferredSize ( ) ; private final JTree tree ; private TreeListener ( JTree tree ) { this . tree = tree ; } @ Override public void keyTyped ( KeyEvent e ) { } @ Override public void keyPressed ( KeyEvent e ) { if ( e . getKeyCode ( ) == KeyEvent . VK_SPACE ) { TreePath [ ] paths = tree . getSelectionPaths ( ) ; if ( paths != null ) { for ( TreePath path : paths ) { handle ( path ) ; } } } } @ Override public void keyReleased ( KeyEvent e ) { } @ Override public void mouseClicked ( MouseEvent e ) { } @ Override public void mousePressed ( MouseEvent e ) { TreePath path = tree . getPathForLocation ( e . getX ( ) , e . getY ( ) ) ; if ( ( path != null ) && ( path . getPathCount ( ) > 0 ) ) { if ( isValidNode ( path . getLastPathComponent ( ) ) ) { if ( isOverCheckBox ( e . getX ( ) , e . getY ( ) , path ) ) { handle ( path ) ; } } } } @ Override public void mouseReleased ( MouseEvent e ) { } @ Override public void mouseEntered ( MouseEvent e ) { } @ Override public void mouseExited ( MouseEvent e ) { } private void handle ( TreePath path ) { if ( ( path != null ) && ( path . getPathCount ( ) > 0 ) ) { if ( path . getLastPathComponent ( ) instanceof CategoryNode ) { DefaultTreeModel model = ( DefaultTreeModel ) tree . getModel ( ) ; CategoryNode node = ( CategoryNode ) path . getLastPathComponent ( ) ; node . setEnabled ( ! node . isEnabled ( ) ) ; model . nodeChanged ( node ) ; for ( int i = 0 ; i < node . getChildCount ( ) ; i ++ ) { RuleNode child = ( RuleNode ) node . getChildAt ( i ) ; if ( child . isEnabled ( ) != node . isEnabled ( ) ) { child . setEnabled ( node . isEnabled ( ) ) ; model . nodeChanged ( child ) ; } } } if ( path . getLastPathComponent ( ) instanceof RuleNode ) { DefaultTreeModel model = ( DefaultTreeModel ) tree . getModel ( ) ; RuleNode node = ( RuleNode ) path . getLastPathComponent ( ) ; node . setEnabled ( ! node . isEnabled ( ) ) ; model . nodeChanged ( node ) ; if ( node . isEnabled ( ) ) { CategoryNode parent = ( CategoryNode ) node . getParent ( ) ; parent . setEnabled ( true ) ; } model . nodeChanged ( node . getParent ( ) ) ; } } } private boolean isOverCheckBox ( int x , int y , TreePath path ) { int offset = tree . getPathBounds ( path ) . x + checkBoxDimension . width ; if ( x > offset ) { return false ; } return true ; } private boolean isValidNode ( Object c ) { return ( ( c instanceof CategoryNode ) || ( c instanceof RuleNode ) ) ; } }
package org . languagetool . gui ; import org . jetbrains . annotations . Nullable ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . Rule ; import javax . swing . * ; import javax . swing . event . DocumentEvent ; import javax . swing . event . DocumentListener ; import javax . swing . event . TreeModelEvent ; import javax . swing . event . TreeModelListener ; import javax . swing . tree . DefaultMutableTreeNode ; import javax . swing . tree . DefaultTreeModel ; import javax . swing . tree . TreeNode ; import javax . swing . tree . TreePath ; import java . awt . * ; import java . awt . event . * ; import java . util . * ; import java . util . List ; public class ConfigurationDialog implements ActionListener { private static final String NO_MOTHER_TONGUE = "---" ; private static final int MAX_PORT = 65536 ; private final ResourceBundle messages ; private final Configuration original ; private final Configuration config ; private final Frame owner ; private final boolean insideOffice ; private JButton okButton ; private JButton cancelButton ; private JDialog dialog ; private JComboBox < String > motherTongueBox ; private JCheckBox serverCheckbox ; private JTextField serverPortField ; private JTree configTree ; private JCheckBox serverSettingsCheckbox ; public ConfigurationDialog ( Frame owner , boolean insideOffice , Configuration config ) { this . owner = owner ; this . insideOffice = insideOffice ; this . original = config ; this . config = original . copy ( original ) ; messages = JLanguageTool . getMessageBundle ( ) ; } private DefaultMutableTreeNode createTree ( List < Rule > rules ) { DefaultMutableTreeNode root = new DefaultMutableTreeNode ( "Rules" ) ; String lastRuleId = null ; Map < String , DefaultMutableTreeNode > parents = new TreeMap < > ( ) ; for ( final Rule rule : rules ) { if ( ! parents . containsKey ( rule . getCategory ( ) . getName ( ) ) ) { boolean enabled = true ; if ( config . getDisabledCategoryNames ( ) != null && config . getDisabledCategoryNames ( ) . contains ( rule . getCategory ( ) . getName ( ) ) ) { enabled = false ; } DefaultMutableTreeNode categoryNode = new CategoryNode ( rule . getCategory ( ) , enabled ) ; root . add ( categoryNode ) ; parents . put ( rule . getCategory ( ) . getName ( ) , categoryNode ) ; } if ( ! rule . getId ( ) . equals ( lastRuleId ) ) { RuleNode ruleNode = new RuleNode ( rule , getState ( rule ) ) ; parents . get ( rule . getCategory ( ) . getName ( ) ) . add ( ruleNode ) ; } lastRuleId = rule . getId ( ) ; } return root ; } private boolean getState ( Rule rule ) { boolean ret = true ; if ( config . getDisabledRuleIds ( ) . contains ( rule . getId ( ) ) ) { ret = false ; } if ( config . getDisabledCategoryNames ( ) . contains ( rule . getCategory ( ) . getName ( ) ) ) { ret = false ; } if ( rule . isDefaultOff ( ) && ! config . getEnabledRuleIds ( ) . contains ( rule . getId ( ) ) ) { ret = false ; } if ( rule . isDefaultOff ( ) && rule . getCategory ( ) . isDefaultOff ( ) && config . getEnabledRuleIds ( ) . contains ( rule . getId ( ) ) ) { config . getDisabledCategoryNames ( ) . remove ( rule . getCategory ( ) . getName ( ) ) ; } return ret ; } public void show ( List < Rule > rules ) { if ( original != null ) { config . restoreState ( original ) ; } dialog = new JDialog ( owner , true ) ; dialog . setTitle ( messages . getString ( "guiConfigWindowTitle" ) ) ; Collections . sort ( rules , new CategoryComparator ( ) ) ; final KeyStroke stroke = KeyStroke . getKeyStroke ( KeyEvent . VK_ESCAPE , 0 ) ; final ActionListener actionListener = new ActionListener ( ) { @ Override public void actionPerformed ( @ SuppressWarnings ( "unused" ) ActionEvent actionEvent ) { dialog . setVisible ( false ) ; } } ; final JRootPane rootPane = dialog . getRootPane ( ) ; rootPane . registerKeyboardAction ( actionListener , stroke , JComponent . WHEN_IN_FOCUSED_WINDOW ) ; final JPanel checkBoxPanel = new JPanel ( ) ; checkBoxPanel . setLayout ( new GridBagLayout ( ) ) ; GridBagConstraints cons = new GridBagConstraints ( ) ; cons . anchor = GridBagConstraints . NORTHWEST ; cons . gridx = 0 ; cons . weightx = 1.0 ; cons . weighty = 1.0 ; cons . fill = GridBagConstraints . BOTH ; DefaultMutableTreeNode rootNode = createTree ( rules ) ; DefaultTreeModel treeModel = new DefaultTreeModel ( rootNode ) ; treeModel . addTreeModelListener ( new TreeModelListener ( ) { @ Override public void treeNodesChanged ( TreeModelEvent e ) { DefaultMutableTreeNode node = ( DefaultMutableTreeNode ) e . getTreePath ( ) . getLastPathComponent ( ) ; int index = e . getChildIndices ( ) [ 0 ] ; node = ( DefaultMutableTreeNode ) node . getChildAt ( index ) ; if ( node instanceof RuleNode ) { RuleNode o = ( RuleNode ) node ; if ( o . getRule ( ) . isDefaultOff ( ) ) { if ( o . isEnabled ( ) ) { config . getEnabledRuleIds ( ) . add ( o . getRule ( ) . getId ( ) ) ; } else { config . getEnabledRuleIds ( ) . remove ( o . getRule ( ) . getId ( ) ) ; } } else { if ( o . isEnabled ( ) ) { config . getDisabledRuleIds ( ) . remove ( o . getRule ( ) . getId ( ) ) ; } else { config . getDisabledRuleIds ( ) . add ( o . getRule ( ) . getId ( ) ) ; } } } if ( node instanceof CategoryNode ) { CategoryNode o = ( CategoryNode ) node ; if ( o . isEnabled ( ) ) { config . getDisabledCategoryNames ( ) . remove ( o . getCategory ( ) . getName ( ) ) ; } else { config . getDisabledCategoryNames ( ) . add ( o . getCategory ( ) . getName ( ) ) ; } } } @ Override public void treeNodesInserted ( TreeModelEvent e ) { } @ Override public void treeNodesRemoved ( TreeModelEvent e ) { } @ Override public void treeStructureChanged ( TreeModelEvent e ) { } } ) ; configTree = new JTree ( treeModel ) ; Language lang = config . getLanguage ( ) ; if ( lang == null ) { lang = Languages . getLanguageForLocale ( Locale . getDefault ( ) ) ; } configTree . applyComponentOrientation ( ComponentOrientation . getOrientation ( lang . getLocale ( ) ) ) ; configTree . setRootVisible ( false ) ; configTree . setEditable ( false ) ; configTree . setCellRenderer ( new CheckBoxTreeCellRenderer ( ) ) ; TreeListener . install ( configTree ) ; checkBoxPanel . add ( configTree , cons ) ; MouseAdapter ma = new MouseAdapter ( ) { private void handlePopupEvent ( MouseEvent e ) { final JTree tree = ( JTree ) e . getSource ( ) ; TreePath path = tree . getPathForLocation ( e . getX ( ) , e . getY ( ) ) ; if ( path == null ) { return ; } DefaultMutableTreeNode node = ( DefaultMutableTreeNode ) path . getLastPathComponent ( ) ; TreePath [ ] paths = tree . getSelectionPaths ( ) ; boolean isSelected = false ; if ( paths != null ) { for ( TreePath selectionPath : paths ) { if ( selectionPath . equals ( path ) ) { isSelected = true ; } } } if ( ! isSelected ) { tree . setSelectionPath ( path ) ; } if ( node . isLeaf ( ) ) { JPopupMenu popup = new JPopupMenu ( ) ; final JMenuItem aboutRuleMenuItem = new JMenuItem ( messages . getString ( "guiAboutRuleMenu" ) ) ; aboutRuleMenuItem . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent actionEvent ) { RuleNode node = ( RuleNode ) tree . getSelectionPath ( ) . getLastPathComponent ( ) ; Rule rule = node . getRule ( ) ; Language lang = config . getLanguage ( ) ; if ( lang == null ) { lang = Languages . getLanguageForLocale ( Locale . getDefault ( ) ) ; } Tools . showRuleInfoDialog ( tree , messages . getString ( "guiAboutRuleTitle" ) , rule . getDescription ( ) , rule , messages , lang . getShortNameWithCountryAndVariant ( ) ) ; } } ) ; popup . add ( aboutRuleMenuItem ) ; popup . show ( tree , e . getX ( ) , e . getY ( ) ) ; } } @ Override public void mousePressed ( MouseEvent e ) { if ( e . isPopupTrigger ( ) ) { handlePopupEvent ( e ) ; } } @ Override public void mouseReleased ( MouseEvent e ) { if ( e . isPopupTrigger ( ) ) { handlePopupEvent ( e ) ; } } } ; configTree . addMouseListener ( ma ) ; final JPanel treeButtonPanel = new JPanel ( ) ; cons = new GridBagConstraints ( ) ; cons . gridx = 0 ; cons . gridy = 0 ; final JButton expandAllButton = new JButton ( messages . getString ( "guiExpandAll" ) ) ; treeButtonPanel . add ( expandAllButton , cons ) ; expandAllButton . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { TreeNode root = ( TreeNode ) configTree . getModel ( ) . getRoot ( ) ; TreePath parent = new TreePath ( root ) ; for ( Enumeration cat = root . children ( ) ; cat . hasMoreElements ( ) ; ) { TreeNode n = ( TreeNode ) cat . nextElement ( ) ; TreePath child = parent . pathByAddingChild ( n ) ; configTree . expandPath ( child ) ; } } } ) ; cons . gridx = 1 ; cons . gridy = 0 ; final JButton collapseAllButton = new JButton ( messages . getString ( "guiCollapseAll" ) ) ; treeButtonPanel . add ( collapseAllButton , cons ) ; collapseAllButton . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { TreeNode root = ( TreeNode ) configTree . getModel ( ) . getRoot ( ) ; TreePath parent = new TreePath ( root ) ; for ( Enumeration categ = root . children ( ) ; categ . hasMoreElements ( ) ; ) { TreeNode n = ( TreeNode ) categ . nextElement ( ) ; TreePath child = parent . pathByAddingChild ( n ) ; configTree . collapsePath ( child ) ; } } } ) ; final JPanel motherTonguePanel = new JPanel ( ) ; motherTonguePanel . add ( new JLabel ( messages . getString ( "guiMotherTongue" ) ) , cons ) ; motherTongueBox = new JComboBox < > ( getPossibleMotherTongues ( ) ) ; if ( config . getMotherTongue ( ) != null ) { motherTongueBox . setSelectedItem ( config . getMotherTongue ( ) . getTranslatedName ( messages ) ) ; } motherTongueBox . addItemListener ( new ItemListener ( ) { @ Override public void itemStateChanged ( ItemEvent e ) { if ( e . getStateChange ( ) == ItemEvent . SELECTED ) { Language motherTongue ; if ( motherTongueBox . getSelectedItem ( ) instanceof String ) { motherTongue = getLanguageForLocalizedName ( motherTongueBox . getSelectedItem ( ) . toString ( ) ) ; } else { motherTongue = ( Language ) motherTongueBox . getSelectedItem ( ) ; } config . setMotherTongue ( motherTongue ) ; } } } ) ; motherTonguePanel . add ( motherTongueBox , cons ) ; final JPanel portPanel = new JPanel ( ) ; portPanel . setLayout ( new GridBagLayout ( ) ) ; cons = new GridBagConstraints ( ) ; cons . insets = new Insets ( 0 , 4 , 0 , 0 ) ; cons . gridx = 0 ; cons . gridy = 0 ; cons . anchor = GridBagConstraints . WEST ; cons . fill = GridBagConstraints . NONE ; cons . weightx = 0.0f ; if ( ! insideOffice ) { serverCheckbox = new JCheckBox ( Tools . getLabel ( messages . getString ( "guiRunOnPort" ) ) ) ; serverCheckbox . setMnemonic ( Tools . getMnemonic ( messages . getString ( "guiRunOnPort" ) ) ) ; serverCheckbox . setSelected ( config . getRunServer ( ) ) ; portPanel . add ( serverCheckbox , cons ) ; serverCheckbox . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( @ SuppressWarnings ( "unused" ) ActionEvent e ) { serverPortField . setEnabled ( serverCheckbox . isSelected ( ) ) ; serverSettingsCheckbox . setEnabled ( serverCheckbox . isSelected ( ) ) ; } } ) ; serverCheckbox . addItemListener ( new ItemListener ( ) { @ Override public void itemStateChanged ( ItemEvent e ) { config . setRunServer ( serverCheckbox . isSelected ( ) ) ; } } ) ; serverPortField = new JTextField ( Integer . toString ( config . getServerPort ( ) ) ) ; serverPortField . setEnabled ( serverCheckbox . isSelected ( ) ) ; serverSettingsCheckbox = new JCheckBox ( Tools . getLabel ( messages . getString ( "useGUIConfig" ) ) ) ; serverPortField . setMinimumSize ( new Dimension ( 100 , 25 ) ) ; cons . gridx = 1 ; portPanel . add ( serverPortField , cons ) ; serverPortField . getDocument ( ) . addDocumentListener ( new DocumentListener ( ) { @ Override public void insertUpdate ( DocumentEvent e ) { changedUpdate ( e ) ; } @ Override public void removeUpdate ( DocumentEvent e ) { changedUpdate ( e ) ; } @ Override public void changedUpdate ( DocumentEvent e ) { try { int serverPort = Integer . parseInt ( serverPortField . getText ( ) ) ; if ( serverPort > - 1 && serverPort < MAX_PORT ) { serverPortField . setForeground ( null ) ; config . setServerPort ( serverPort ) ; } else { serverPortField . setForeground ( Color . RED ) ; } } catch ( NumberFormatException ex ) { serverPortField . setForeground ( Color . RED ) ; } } } ) ; cons . gridx = 0 ; cons . gridy = 10 ; serverSettingsCheckbox . setMnemonic ( Tools . getMnemonic ( messages . getString ( "useGUIConfig" ) ) ) ; serverSettingsCheckbox . setSelected ( config . getUseGUIConfig ( ) ) ; serverSettingsCheckbox . setEnabled ( config . getRunServer ( ) ) ; serverSettingsCheckbox . addItemListener ( new ItemListener ( ) { @ Override public void itemStateChanged ( ItemEvent e ) { config . setUseGUIConfig ( serverSettingsCheckbox . isSelected ( ) ) ; } } ) ; portPanel . add ( serverSettingsCheckbox , cons ) ; } final JPanel buttonPanel = new JPanel ( ) ; buttonPanel . setLayout ( new GridBagLayout ( ) ) ; okButton = new JButton ( Tools . getLabel ( messages . getString ( "guiOKButton" ) ) ) ; okButton . setMnemonic ( Tools . getMnemonic ( messages . getString ( "guiOKButton" ) ) ) ; okButton . addActionListener ( this ) ; cancelButton = new JButton ( Tools . getLabel ( messages . getString ( "guiCancelButton" ) ) ) ; cancelButton . setMnemonic ( Tools . getMnemonic ( messages . getString ( "guiCancelButton" ) ) ) ; cancelButton . addActionListener ( this ) ; cons = new GridBagConstraints ( ) ; cons . insets = new Insets ( 0 , 4 , 0 , 0 ) ; buttonPanel . add ( okButton , cons ) ; buttonPanel . add ( cancelButton , cons ) ; final Container contentPane = dialog . getContentPane ( ) ; contentPane . setLayout ( new GridBagLayout ( ) ) ; cons = new GridBagConstraints ( ) ; cons . insets = new Insets ( 4 , 4 , 4 , 4 ) ; cons . gridx = 0 ; cons . gridy = 0 ; cons . weightx = 10.0f ; cons . weighty = 10.0f ; cons . fill = GridBagConstraints . BOTH ; contentPane . add ( new JScrollPane ( checkBoxPanel ) , cons ) ; cons . gridx = 0 ; cons . gridy ++ ; cons . fill = GridBagConstraints . NONE ; cons . anchor = GridBagConstraints . LINE_END ; contentPane . add ( treeButtonPanel , cons ) ; cons . gridy ++ ; cons . anchor = GridBagConstraints . WEST ; contentPane . add ( motherTonguePanel , cons ) ; cons . gridy ++ ; cons . anchor = GridBagConstraints . WEST ; contentPane . add ( portPanel , cons ) ; cons . gridy ++ ; cons . anchor = GridBagConstraints . EAST ; contentPane . add ( buttonPanel , cons ) ; dialog . pack ( ) ; dialog . setSize ( 500 , 500 ) ; final Dimension screenSize = Toolkit . getDefaultToolkit ( ) . getScreenSize ( ) ; final Dimension frameSize = dialog . getSize ( ) ; dialog . setLocation ( screenSize . width / 2 - frameSize . width / 2 , screenSize . height / 2 - frameSize . height / 2 ) ; dialog . setLocationByPlatform ( true ) ; dialog . setVisible ( true ) ; } private String [ ] getPossibleMotherTongues ( ) { final List < String > motherTongues = new ArrayList < > ( ) ; motherTongues . add ( NO_MOTHER_TONGUE ) ; for ( final Language lang : Languages . get ( ) ) { motherTongues . add ( lang . getTranslatedName ( messages ) ) ; } return motherTongues . toArray ( new String [ motherTongues . size ( ) ] ) ; } @ Override public void actionPerformed ( ActionEvent e ) { if ( e . getSource ( ) == okButton ) { if ( original != null ) { original . restoreState ( config ) ; } dialog . setVisible ( false ) ; } else if ( e . getSource ( ) == cancelButton ) { dialog . setVisible ( false ) ; } } @ Nullable private Language getLanguageForLocalizedName ( final String languageName ) { for ( final Language element : Languages . get ( ) ) { if ( languageName . equals ( element . getTranslatedName ( messages ) ) ) { return element ; } } return null ; } static class CategoryComparator implements Comparator < Rule > { @ Override public int compare ( final Rule r1 , final Rule r2 ) { final boolean hasCat = r1 . getCategory ( ) != null && r2 . getCategory ( ) != null ; if ( hasCat ) { final int res = r1 . getCategory ( ) . getName ( ) . compareTo ( r2 . getCategory ( ) . getName ( ) ) ; if ( res == 0 ) { return r1 . getDescription ( ) . compareToIgnoreCase ( r2 . getDescription ( ) ) ; } return res ; } return r1 . getDescription ( ) . compareToIgnoreCase ( r2 . getDescription ( ) ) ; } } }
package org . languagetool . gui ; import java . awt . Color ; import java . awt . Component ; import java . awt . Desktop ; import java . awt . Dimension ; import java . awt . Toolkit ; import java . util . ResourceBundle ; import java . util . TreeMap ; import javax . swing . BorderFactory ; import javax . swing . BoxLayout ; import javax . swing . JOptionPane ; import javax . swing . JPanel ; import javax . swing . JScrollPane ; import javax . swing . JTextPane ; import javax . swing . event . HyperlinkEvent ; import javax . swing . event . HyperlinkListener ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . language . Contributor ; public class AboutDialog { private final ResourceBundle messages ; private final Component parent ; public AboutDialog ( final ResourceBundle messages , Component parent ) { this . messages = messages ; this . parent = parent ; } public void show ( ) { final String aboutText = Tools . getLabel ( messages . getString ( "guiMenuAbout" ) ) ; JTextPane aboutPane = new JTextPane ( ) ; aboutPane . setBackground ( new Color ( 0 , 0 , 0 , 0 ) ) ; aboutPane . setBorder ( BorderFactory . createEmptyBorder ( ) ) ; aboutPane . setContentType ( "text/html" ) ; aboutPane . setEditable ( false ) ; aboutPane . setOpaque ( false ) ; aboutPane . setText ( String . format ( "<html>" + "<p>LanguageTool %s (%s)<br>" + "Copyright (C) 2005-2015 the LanguageTool community and Daniel Naber<br>" + "This software is licensed under the GNU Lesser General Public License.<br>" + "<a href=\"http://www.languagetool.org\">http://www.languagetool.org</a><br>" + "Java max/total/free memory: %sMB, %sMB, %sMB</p>" + "<p>Maintainers of the language modules:</p><br>" + "</html>" , JLanguageTool . VERSION , JLanguageTool . BUILD_DATE , Runtime . getRuntime ( ) . maxMemory ( ) / 1024 / 1024 , Runtime . getRuntime ( ) . totalMemory ( ) / 1024 / 1024 , Runtime . getRuntime ( ) . freeMemory ( ) / 1024 / 1024 ) ) ; aboutPane . addHyperlinkListener ( new HyperlinkListener ( ) { @ Override public void hyperlinkUpdate ( HyperlinkEvent e ) { if ( e . getEventType ( ) == HyperlinkEvent . EventType . ACTIVATED ) { if ( Desktop . isDesktopSupported ( ) ) { try { Desktop . getDesktop ( ) . browse ( e . getURL ( ) . toURI ( ) ) ; } catch ( Exception ex ) { Tools . showError ( ex ) ; } } } } } ) ; JTextPane maintainersPane = new JTextPane ( ) ; maintainersPane . setBackground ( new Color ( 0 , 0 , 0 , 0 ) ) ; maintainersPane . setBorder ( BorderFactory . createEmptyBorder ( ) ) ; maintainersPane . setContentType ( "text/html" ) ; maintainersPane . setEditable ( false ) ; maintainersPane . setOpaque ( false ) ; maintainersPane . setText ( getMaintainers ( ) ) ; int maxHeight = Toolkit . getDefaultToolkit ( ) . getScreenSize ( ) . height / 2 ; if ( maintainersPane . getPreferredSize ( ) . height > maxHeight ) { maintainersPane . setPreferredSize ( new Dimension ( maintainersPane . getPreferredSize ( ) . width , maxHeight ) ) ; } JScrollPane scrollPane = new JScrollPane ( maintainersPane ) ; scrollPane . setBorder ( BorderFactory . createEmptyBorder ( ) ) ; JPanel panel = new JPanel ( ) ; panel . setLayout ( new BoxLayout ( panel , BoxLayout . PAGE_AXIS ) ) ; panel . add ( aboutPane ) ; panel . add ( scrollPane ) ; JOptionPane . showMessageDialog ( parent , panel , aboutText , JOptionPane . INFORMATION_MESSAGE ) ; } private String getMaintainers ( ) { final TreeMap < String , Language > list = new TreeMap < > ( ) ; for ( final Language lang : Languages . get ( ) ) { if ( ! lang . isVariant ( ) ) { if ( lang . getMaintainers ( ) != null ) { list . put ( messages . getString ( lang . getShortName ( ) ) , lang ) ; } } } final StringBuilder maintainersInfo = new StringBuilder ( ) ; maintainersInfo . append ( "<table border=0 cellspacing=0 cellpadding=0>" ) ; for ( String lang : list . keySet ( ) ) { maintainersInfo . append ( "<tr valign=\"top\"><td>" ) ; maintainersInfo . append ( lang ) ; maintainersInfo . append ( ":</td>" ) ; maintainersInfo . append ( "<td>&nbsp;</td>" ) ; maintainersInfo . append ( "<td>" ) ; int i = 0 ; for ( Contributor contributor : list . get ( lang ) . getMaintainers ( ) ) { if ( i > 0 ) { maintainersInfo . append ( ", " ) ; if ( i % 3 == 0 ) { maintainersInfo . append ( "<br>" ) ; } } maintainersInfo . append ( contributor . getName ( ) ) ; i ++ ; } maintainersInfo . append ( "</td></tr>" ) ; } maintainersInfo . append ( "</table>" ) ; return maintainersInfo . toString ( ) ; } }
package org . languagetool . gui ; import java . awt . BorderLayout ; import java . awt . Component ; import javax . swing . JCheckBox ; import javax . swing . JPanel ; import javax . swing . JTree ; import javax . swing . tree . DefaultTreeCellRenderer ; import javax . swing . tree . TreeCellRenderer ; class CheckBoxTreeCellRenderer extends JPanel implements TreeCellRenderer { private final DefaultTreeCellRenderer renderer = new DefaultTreeCellRenderer ( ) ; private final JCheckBox checkBox = new JCheckBox ( ) ; private Component defaultComponent ; CheckBoxTreeCellRenderer ( ) { setLayout ( new BorderLayout ( ) ) ; setOpaque ( false ) ; checkBox . setOpaque ( false ) ; renderer . setLeafIcon ( null ) ; add ( checkBox , BorderLayout . WEST ) ; } @ Override public Component getTreeCellRendererComponent ( JTree tree , Object value , boolean selected , boolean expanded , boolean leaf , int row , boolean hasFocus ) { Component component = renderer . getTreeCellRendererComponent ( tree , value , selected , expanded , leaf , row , hasFocus ) ; if ( value instanceof CategoryNode ) { if ( defaultComponent != null ) { remove ( defaultComponent ) ; } defaultComponent = component ; add ( component , BorderLayout . CENTER ) ; CategoryNode node = ( CategoryNode ) value ; checkBox . setSelected ( node . isEnabled ( ) ) ; return this ; } if ( value instanceof RuleNode ) { if ( defaultComponent != null ) { remove ( defaultComponent ) ; } defaultComponent = component ; add ( component , BorderLayout . CENTER ) ; RuleNode node = ( RuleNode ) value ; checkBox . setSelected ( node . isEnabled ( ) ) ; return this ; } return component ; } }
package org . languagetool . gui ; import javax . swing . tree . DefaultMutableTreeNode ; import org . languagetool . rules . Rule ; class RuleNode extends DefaultMutableTreeNode { private final Rule rule ; private boolean enabled ; RuleNode ( Rule rule , boolean enabled ) { super ( rule ) ; this . rule = rule ; this . enabled = enabled ; } Rule getRule ( ) { return rule ; } boolean isEnabled ( ) { return enabled ; } void setEnabled ( boolean enabled ) { this . enabled = enabled ; } @ Override public String toString ( ) { return rule . getDescription ( ) ; } }
package org . languagetool . gui ; import org . apache . commons . lang . StringUtils ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . tools . StringTools ; import java . awt . * ; import java . io . * ; import java . util . * ; import java . util . List ; public class Configuration { static final int DEFAULT_SERVER_PORT = 8081 ; static final int FONT_STYLE_INVALID = - 1 ; static final int FONT_SIZE_INVALID = - 1 ; private static final String CONFIG_FILE = ".languagetool.cfg" ; private static final String DISABLED_RULES_CONFIG_KEY = "disabledRules" ; private static final String ENABLED_RULES_CONFIG_KEY = "enabledRules" ; private static final String DISABLED_CATEGORIES_CONFIG_KEY = "disabledCategories" ; private static final String LANGUAGE_CONFIG_KEY = "language" ; private static final String MOTHER_TONGUE_CONFIG_KEY = "motherTongue" ; private static final String AUTO_DETECT_CONFIG_KEY = "autoDetect" ; private static final String SERVER_RUN_CONFIG_KEY = "serverMode" ; private static final String SERVER_PORT_CONFIG_KEY = "serverPort" ; private static final String USE_GUI_CONFIG_KEY = "useGUIConfig" ; private static final String FONT_NAME_CONFIG_KEY = "font.name" ; private static final String FONT_STYLE_CONFIG_KEY = "font.style" ; private static final String FONT_SIZE_CONFIG_KEY = "font.size" ; private static final String LF_NAME_CONFIG_KEY = "lookAndFeelName" ; private static final String ERROR_COLORS_CONFIG_KEY = "errorColors" ; private static final String DELIMITER = "," ; private static final String EXTERNAL_RULE_DIRECTORY = "extRulesDirectory" ; private final Map < String , String > configForOtherLangs = new HashMap < > ( ) ; private final Map < ITSIssueType , Color > errorColors = new HashMap < > ( ) ; private File configFile ; private Set < String > disabledRuleIds = new HashSet < > ( ) ; private Set < String > enabledRuleIds = new HashSet < > ( ) ; private Set < String > disabledCategoryNames = new HashSet < > ( ) ; private Language language ; private Language motherTongue ; private boolean runServer ; private boolean autoDetect ; private boolean guiConfig ; private String fontName ; private int fontStyle ; private int fontSize ; private int serverPort = DEFAULT_SERVER_PORT ; private String externalRuleDirectory ; private String lookAndFeelName ; public Configuration ( final Language lang ) throws IOException { this ( new File ( System . getProperty ( "user.home" ) ) , CONFIG_FILE , lang ) ; } public Configuration ( final File baseDir , final String filename , final Language lang ) throws IOException { this ( ) ; if ( ! baseDir . isDirectory ( ) ) { throw new IllegalArgumentException ( "Not a directory: " + baseDir ) ; } configFile = new File ( baseDir , filename ) ; loadConfiguration ( lang ) ; } public Configuration ( final File baseDir , final Language lang ) throws IOException { this ( baseDir , CONFIG_FILE , lang ) ; } Configuration ( ) { fontStyle = FONT_STYLE_INVALID ; fontSize = FONT_SIZE_INVALID ; } Configuration copy ( Configuration configuration ) { Configuration copy = new Configuration ( ) ; copy . restoreState ( configuration ) ; return copy ; } void restoreState ( Configuration configuration ) { this . configFile = configuration . configFile ; this . language = configuration . language ; this . motherTongue = configuration . motherTongue ; this . runServer = configuration . runServer ; this . autoDetect = configuration . autoDetect ; this . guiConfig = configuration . guiConfig ; this . fontName = configuration . fontName ; this . fontStyle = configuration . fontStyle ; this . fontSize = configuration . fontSize ; this . serverPort = configuration . serverPort ; this . lookAndFeelName = configuration . lookAndFeelName ; this . externalRuleDirectory = configuration . externalRuleDirectory ; this . disabledRuleIds . clear ( ) ; this . disabledRuleIds . addAll ( configuration . disabledRuleIds ) ; this . enabledRuleIds . clear ( ) ; this . enabledRuleIds . addAll ( configuration . enabledRuleIds ) ; this . disabledCategoryNames . clear ( ) ; this . disabledCategoryNames . addAll ( configuration . disabledCategoryNames ) ; this . configForOtherLangs . clear ( ) ; for ( String key : configuration . configForOtherLangs . keySet ( ) ) { this . configForOtherLangs . put ( key , configuration . configForOtherLangs . get ( key ) ) ; } } public Set < String > getDisabledRuleIds ( ) { return disabledRuleIds ; } public Set < String > getEnabledRuleIds ( ) { return enabledRuleIds ; } public Set < String > getDisabledCategoryNames ( ) { return disabledCategoryNames ; } public void setDisabledRuleIds ( final Set < String > ruleIDs ) { disabledRuleIds = ruleIDs ; } public void setEnabledRuleIds ( final Set < String > ruleIDs ) { enabledRuleIds = ruleIDs ; } public void setDisabledCategoryNames ( final Set < String > categoryNames ) { disabledCategoryNames = categoryNames ; } public Language getLanguage ( ) { return language ; } public void setLanguage ( final Language language ) { this . language = language ; } public Language getMotherTongue ( ) { return motherTongue ; } public void setMotherTongue ( final Language motherTongue ) { this . motherTongue = motherTongue ; } public boolean getAutoDetect ( ) { return autoDetect ; } public void setAutoDetect ( final boolean autoDetect ) { this . autoDetect = autoDetect ; } public boolean getRunServer ( ) { return runServer ; } public void setRunServer ( final boolean runServer ) { this . runServer = runServer ; } public int getServerPort ( ) { return serverPort ; } public void setUseGUIConfig ( final boolean useGUIConfig ) { this . guiConfig = useGUIConfig ; } public boolean getUseGUIConfig ( ) { return guiConfig ; } public void setServerPort ( final int serverPort ) { this . serverPort = serverPort ; } public String getExternalRuleDirectory ( ) { return externalRuleDirectory ; } public void setExternalRuleDirectory ( final String path ) { externalRuleDirectory = path ; } public String getFontName ( ) { return fontName ; } public void setFontName ( String fontName ) { this . fontName = fontName ; } public int getFontStyle ( ) { return fontStyle ; } public void setFontStyle ( int fontStyle ) { this . fontStyle = fontStyle ; } public int getFontSize ( ) { return fontSize ; } public void setFontSize ( int fontSize ) { this . fontSize = fontSize ; } public String getLookAndFeelName ( ) { return this . lookAndFeelName ; } public void setLookAndFeelName ( String lookAndFeelName ) { this . lookAndFeelName = lookAndFeelName ; } public Map < ITSIssueType , Color > getErrorColors ( ) { return errorColors ; } private void loadConfiguration ( final Language lang ) throws IOException { final String qualifier = getQualifier ( lang ) ; try ( FileInputStream fis = new FileInputStream ( configFile ) ) { final Properties props = new Properties ( ) ; props . load ( fis ) ; disabledRuleIds . addAll ( getListFromProperties ( props , DISABLED_RULES_CONFIG_KEY + qualifier ) ) ; enabledRuleIds . addAll ( getListFromProperties ( props , ENABLED_RULES_CONFIG_KEY + qualifier ) ) ; disabledCategoryNames . addAll ( getListFromProperties ( props , DISABLED_CATEGORIES_CONFIG_KEY + qualifier ) ) ; final String languageStr = ( String ) props . get ( LANGUAGE_CONFIG_KEY ) ; if ( languageStr != null ) { language = Languages . getLanguageForShortName ( languageStr ) ; } final String motherTongueStr = ( String ) props . get ( MOTHER_TONGUE_CONFIG_KEY ) ; if ( motherTongueStr != null && ! motherTongueStr . equals ( "xx" ) ) { motherTongue = Languages . getLanguageForShortName ( motherTongueStr ) ; } autoDetect = "true" . equals ( props . get ( AUTO_DETECT_CONFIG_KEY ) ) ; guiConfig = "true" . equals ( props . get ( USE_GUI_CONFIG_KEY ) ) ; runServer = "true" . equals ( props . get ( SERVER_RUN_CONFIG_KEY ) ) ; fontName = ( String ) props . get ( FONT_NAME_CONFIG_KEY ) ; if ( props . get ( FONT_STYLE_CONFIG_KEY ) != null ) { try { fontStyle = Integer . parseInt ( ( String ) props . get ( FONT_STYLE_CONFIG_KEY ) ) ; } catch ( NumberFormatException e ) { } } if ( props . get ( FONT_SIZE_CONFIG_KEY ) != null ) { try { fontSize = Integer . parseInt ( ( String ) props . get ( FONT_SIZE_CONFIG_KEY ) ) ; } catch ( NumberFormatException e ) { } } lookAndFeelName = ( String ) props . get ( LF_NAME_CONFIG_KEY ) ; final String serverPortString = ( String ) props . get ( SERVER_PORT_CONFIG_KEY ) ; if ( serverPortString != null ) { serverPort = Integer . parseInt ( serverPortString ) ; } final String extRules = ( String ) props . get ( EXTERNAL_RULE_DIRECTORY ) ; if ( extRules != null ) { externalRuleDirectory = extRules ; } String colorsString = ( String ) props . get ( ERROR_COLORS_CONFIG_KEY ) ; parseErrorColors ( colorsString ) ; loadConfigForOtherLanguages ( lang , props ) ; } catch ( final FileNotFoundException e ) { } } private void parseErrorColors ( String colorsString ) { if ( StringUtils . isNotEmpty ( colorsString ) ) { String [ ] typeToColorList = colorsString . split ( ",\\s*" ) ; for ( String typeToColor : typeToColorList ) { String [ ] typeAndColor = typeToColor . split ( ":" ) ; if ( typeAndColor . length != 2 ) { throw new RuntimeException ( "Could not parse type and color, colon expected: '" + typeToColor + "'" ) ; } ITSIssueType type = ITSIssueType . getIssueType ( typeAndColor [ 0 ] ) ; String hexColor = typeAndColor [ 1 ] ; errorColors . put ( type , Color . decode ( hexColor ) ) ; } } } private String getQualifier ( final Language lang ) { String qualifier = "" ; if ( lang != null ) { qualifier = "." + lang . getShortNameWithCountryAndVariant ( ) ; } return qualifier ; } private void loadConfigForOtherLanguages ( final Language lang , final Properties prop ) { for ( Language otherLang : Languages . get ( ) ) { if ( ! otherLang . equals ( lang ) ) { final String languageSuffix = "." + otherLang . getShortNameWithCountryAndVariant ( ) ; storeConfigKeyFromProp ( prop , DISABLED_RULES_CONFIG_KEY + languageSuffix ) ; storeConfigKeyFromProp ( prop , ENABLED_RULES_CONFIG_KEY + languageSuffix ) ; storeConfigKeyFromProp ( prop , DISABLED_CATEGORIES_CONFIG_KEY + languageSuffix ) ; } } } private void storeConfigKeyFromProp ( final Properties prop , final String key ) { if ( prop . containsKey ( key ) ) { configForOtherLangs . put ( key , prop . getProperty ( key ) ) ; } } private Collection < ? extends String > getListFromProperties ( final Properties props , final String key ) { final String value = ( String ) props . get ( key ) ; final List < String > list = new ArrayList < > ( ) ; if ( value != null && ! value . isEmpty ( ) ) { final String [ ] names = value . split ( DELIMITER ) ; list . addAll ( Arrays . asList ( names ) ) ; } return list ; } public void saveConfiguration ( final Language lang ) throws IOException { final Properties props = new Properties ( ) ; final String qualifier = getQualifier ( lang ) ; addListToProperties ( props , DISABLED_RULES_CONFIG_KEY + qualifier , disabledRuleIds ) ; addListToProperties ( props , ENABLED_RULES_CONFIG_KEY + qualifier , enabledRuleIds ) ; addListToProperties ( props , DISABLED_CATEGORIES_CONFIG_KEY + qualifier , disabledCategoryNames ) ; if ( language != null && ! language . isExternal ( ) ) { props . setProperty ( LANGUAGE_CONFIG_KEY , language . getShortNameWithCountryAndVariant ( ) ) ; } if ( motherTongue != null ) { props . setProperty ( MOTHER_TONGUE_CONFIG_KEY , motherTongue . getShortName ( ) ) ; } props . setProperty ( AUTO_DETECT_CONFIG_KEY , Boolean . toString ( autoDetect ) ) ; props . setProperty ( USE_GUI_CONFIG_KEY , Boolean . toString ( guiConfig ) ) ; props . setProperty ( SERVER_RUN_CONFIG_KEY , Boolean . toString ( runServer ) ) ; props . setProperty ( SERVER_PORT_CONFIG_KEY , Integer . toString ( serverPort ) ) ; if ( fontName != null ) { props . setProperty ( FONT_NAME_CONFIG_KEY , fontName ) ; } if ( fontStyle != FONT_STYLE_INVALID ) { props . setProperty ( FONT_STYLE_CONFIG_KEY , Integer . toString ( fontStyle ) ) ; } if ( fontSize != FONT_SIZE_INVALID ) { props . setProperty ( FONT_SIZE_CONFIG_KEY , Integer . toString ( fontSize ) ) ; } if ( this . lookAndFeelName != null ) { props . setProperty ( LF_NAME_CONFIG_KEY , lookAndFeelName ) ; } if ( externalRuleDirectory != null ) { props . setProperty ( EXTERNAL_RULE_DIRECTORY , externalRuleDirectory ) ; } StringBuilder sb = new StringBuilder ( ) ; for ( Map . Entry < ITSIssueType , Color > entry : errorColors . entrySet ( ) ) { String rgb = Integer . toHexString ( entry . getValue ( ) . getRGB ( ) ) ; rgb = rgb . substring ( 2 , rgb . length ( ) ) ; sb . append ( entry . getKey ( ) ) . append ( ":" ) . append ( "#" ) . append ( rgb ) . append ( ", " ) ; } props . setProperty ( ERROR_COLORS_CONFIG_KEY , sb . toString ( ) ) ; for ( final String key : configForOtherLangs . keySet ( ) ) { props . setProperty ( key , configForOtherLangs . get ( key ) ) ; } try ( FileOutputStream fos = new FileOutputStream ( configFile ) ) { props . store ( fos , "LanguageTool configuration (" + JLanguageTool . VERSION + "/" + JLanguageTool . BUILD_DATE + ")" ) ; } } private void addListToProperties ( final Properties props , final String key , final Set < String > list ) { if ( list == null ) { props . setProperty ( key , "" ) ; } else { props . setProperty ( key , StringTools . listToString ( list , DELIMITER ) ) ; } } }
package org . languagetool . gui ; import javax . swing . tree . DefaultMutableTreeNode ; import org . languagetool . rules . Category ; class CategoryNode extends DefaultMutableTreeNode { private final Category category ; private boolean enabled ; CategoryNode ( Category category , boolean enabled ) { super ( category ) ; this . category = category ; this . enabled = enabled ; } Category getCategory ( ) { return category ; } boolean isEnabled ( ) { return enabled ; } void setEnabled ( boolean enabled ) { this . enabled = enabled ; } @ Override public String toString ( ) { int children = this . getChildCount ( ) ; int selected = 0 ; for ( int i = 0 ; i < children ; i ++ ) { RuleNode child = ( RuleNode ) this . getChildAt ( i ) ; if ( child . isEnabled ( ) ) { selected ++ ; } } return String . format ( "%s (%d/%d)" , category . getName ( ) , selected , children ) ; } }
package org . languagetool . dev . dumpcheck ; import org . junit . Test ; import org . languagetool . language . English ; import javax . xml . stream . XMLStreamException ; import java . io . IOException ; import java . io . InputStream ; import static junit . framework . TestCase . assertFalse ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; public class WikipediaSentenceSourceTest { @ Test public void testWikipediaSource ( ) throws XMLStreamException , IOException { InputStream stream = WikipediaSentenceSourceTest . class . getResourceAsStream ( "/org/languagetool/dev/wikipedia/wikipedia-en.xml" ) ; WikipediaSentenceSource source = new WikipediaSentenceSource ( stream , new English ( ) ) ; assertTrue ( source . hasNext ( ) ) ; assertThat ( source . next ( ) . getText ( ) , is ( "This is the first document." ) ) ; assertThat ( source . next ( ) . getText ( ) , is ( "It has three sentences." ) ) ; assertThat ( source . next ( ) . getText ( ) , is ( "Here's the last sentence." ) ) ; assertThat ( source . next ( ) . getText ( ) , is ( "This is the second document." ) ) ; assertThat ( source . next ( ) . getText ( ) , is ( "It has two sentences." ) ) ; assertFalse ( source . hasNext ( ) ) ; } }
package org . languagetool . synthesis . sk ; import org . languagetool . synthesis . BaseSynthesizer ; public class SlovakSynthesizer extends BaseSynthesizer { private static final String RESOURCE_FILENAME = "/sk/slovak_synth.dict" ; private static final String TAGS_FILE_NAME = "/sk/slovak_tags.txt" ; public SlovakSynthesizer ( ) { super ( RESOURCE_FILENAME , TAGS_FILE_NAME ) ; } }
package org . languagetool . dev . dumpcheck ; import org . junit . Test ; import org . languagetool . language . English ; import java . io . ByteArrayInputStream ; import java . io . InputStream ; import java . io . UnsupportedEncodingException ; import static junit . framework . TestCase . assertFalse ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; public class TatoebaSentenceSourceTest { @ Test public void testTatoebaSource ( ) { InputStream stream = WikipediaSentenceSourceTest . class . getResourceAsStream ( "/org/languagetool/dev/wikipedia/tatoeba-en.txt" ) ; TatoebaSentenceSource source = new TatoebaSentenceSource ( stream , new English ( ) ) ; assertTrue ( source . hasNext ( ) ) ; assertThat ( source . next ( ) . getText ( ) , is ( "\"What is your wish?\" asked the little white rabbit." ) ) ; assertThat ( source . next ( ) . getText ( ) , is ( "The mother wakes up her daughter." ) ) ; assertThat ( source . next ( ) . getText ( ) , is ( "Ken beat me at chess." ) ) ; assertFalse ( source . hasNext ( ) ) ; } @ Test ( expected = RuntimeException . class ) public void testTatoebaSourceInvalidInput ( ) throws UnsupportedEncodingException { ByteArrayInputStream stream = new ByteArrayInputStream ( "just a text" . getBytes ( "utf-8" ) ) ; TatoebaSentenceSource source = new TatoebaSentenceSource ( stream , new English ( ) ) ; source . hasNext ( ) ; } }
package org . languagetool . dev . index ; import static org . languagetool . dev . index . PatternRuleQueryBuilder . FIELD_NAME ; import static org . languagetool . dev . index . PatternRuleQueryBuilder . FIELD_NAME_LOWERCASE ; import java . io . File ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Field ; import org . apache . lucene . document . FieldType ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . FSDirectory ; import org . apache . lucene . store . RAMDirectory ; import org . apache . lucene . util . LuceneTestCase ; import org . junit . Ignore ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . language . English ; import org . languagetool . language . German ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . PatternRule ; public class IndexerSearcherTest extends LuceneTestCase { private Searcher errorSearcher ; private Directory directory ; @ Override public void setUp ( ) throws Exception { super . setUp ( ) ; directory = new RAMDirectory ( ) ; } @ Override public void tearDown ( ) throws Exception { super . tearDown ( ) ; if ( directory != null ) { directory . close ( ) ; } } @ Ignore ( "ignored as long as it doesn't work 100%" ) public void testAllRules ( ) throws Exception { final long startTime = System . currentTimeMillis ( ) ; final Language language = new English ( ) ; final JLanguageTool lt = new JLanguageTool ( language ) ; System . out . println ( "Creating index for " + language + "..." ) ; final int ruleCount = createIndex ( lt ) ; System . out . println ( "Index created with " + ruleCount + " rules" ) ; int ruleCounter = 0 ; int ruleProblems = 0 ; int exceptionCount = 0 ; final List < Rule > rules = lt . getAllActiveRules ( ) ; for ( Rule rule : rules ) { if ( rule instanceof PatternRule && ! rule . isDefaultOff ( ) ) { final PatternRule patternRule = ( PatternRule ) rule ; try { ruleCounter ++ ; final SearcherResult searcherResult = errorSearcher . findRuleMatchesOnIndex ( patternRule , language ) ; final List < MatchingSentence > matchingSentences = searcherResult . getMatchingSentences ( ) ; boolean foundExpectedMatch = false ; for ( MatchingSentence matchingSentence : matchingSentences ) { final List < RuleMatch > ruleMatches = matchingSentence . getRuleMatches ( ) ; final List < String > ruleMatchIds = getRuleMatchIds ( ruleMatches ) ; if ( ruleMatchIds . contains ( getFullId ( patternRule ) ) ) { foundExpectedMatch = true ; break ; } } if ( ! foundExpectedMatch ) { System . out . println ( "Error: No match found for " + patternRule ) ; System . out . println ( "Query : " + searcherResult . getRelaxedQuery ( ) . toString ( FIELD_NAME_LOWERCASE ) ) ; System . out . println ( "Default field: " + FIELD_NAME_LOWERCASE ) ; System . out . println ( "Lucene Hits: " + searcherResult . getLuceneMatchCount ( ) ) ; System . out . println ( "Matches : " + matchingSentences ) ; System . out . println ( "Examples : " + rule . getIncorrectExamples ( ) ) ; System . out . println ( ) ; ruleProblems ++ ; } else { } } catch ( UnsupportedPatternRuleException e ) { System . out . println ( "UnsupportedPatternRuleException searching for rule " + getFullId ( patternRule ) + ": " + e . getMessage ( ) ) ; ruleProblems ++ ; } catch ( Exception e ) { System . out . println ( "Exception searching for rule " + getFullId ( patternRule ) + ": " + e . getMessage ( ) ) ; e . printStackTrace ( System . out ) ; exceptionCount ++ ; } } } System . out . println ( language + ": problems: " + ruleProblems + ", total rules: " + ruleCounter ) ; System . out . println ( language + ": exceptions: " + exceptionCount + " (including timeouts)" ) ; System . out . println ( "Total time: " + ( System . currentTimeMillis ( ) - startTime ) + "ms" ) ; } private String getFullId ( PatternRule patternRule ) { return patternRule . getId ( ) + "[" + patternRule . getSubId ( ) + "]" ; } private List < String > getRuleMatchIds ( List < RuleMatch > ruleMatches ) { final List < String > ids = new ArrayList < > ( ) ; for ( RuleMatch ruleMatch : ruleMatches ) { if ( ruleMatch . getRule ( ) instanceof PatternRule ) { final PatternRule patternRule = ( PatternRule ) ruleMatch . getRule ( ) ; ids . add ( getFullId ( patternRule ) ) ; } } return ids ; } private int createIndex ( JLanguageTool lt ) throws IOException { int ruleCount = 0 ; try ( Indexer indexer = new Indexer ( directory , lt . getLanguage ( ) ) ) { final List < Rule > rules = lt . getAllActiveRules ( ) ; for ( Rule rule : rules ) { if ( rule instanceof PatternRule && ! rule . isDefaultOff ( ) ) { final PatternRule patternRule = ( PatternRule ) rule ; final List < IncorrectExample > incorrectExamples = rule . getIncorrectExamples ( ) ; final Document doc = new Document ( ) ; final FieldType idType = new FieldType ( ) ; idType . setStored ( true ) ; idType . setTokenized ( false ) ; doc . add ( new Field ( "ruleId" , getFullId ( patternRule ) , idType ) ) ; for ( IncorrectExample incorrectExample : incorrectExamples ) { final String example = incorrectExample . getExample ( ) . replaceAll ( "</?marker>" , "" ) ; final FieldType fieldType = new FieldType ( ) ; fieldType . setStored ( true ) ; fieldType . setTokenized ( true ) ; fieldType . setIndexed ( true ) ; doc . add ( new Field ( FIELD_NAME , example , fieldType ) ) ; doc . add ( new Field ( FIELD_NAME_LOWERCASE , example , fieldType ) ) ; } indexer . add ( doc ) ; ruleCount ++ ; } } } errorSearcher = new Searcher ( directory ) ; return ruleCount ; } @ Ignore ( "manual debugging only" ) public void testForDebugging ( ) throws Exception { useRealIndex ( ) ; German language = new German ( ) ; PatternRule rule = getFirstRule ( "I_THIN" , language ) ; SearcherResult searcherResult = errorSearcher . findRuleMatchesOnIndex ( rule , language ) ; System . out . println ( "Matches: " + searcherResult . getMatchingSentences ( ) ) ; } public void testIndexerSearcherWithEnglish ( ) throws Exception { createIndex ( "How to move back and fourth from linux to xmb? Calcium deposits on eye lid." ) ; English language = new English ( ) ; SearcherResult searcherResult = errorSearcher . findRuleMatchesOnIndex ( getFirstRule ( "BACK_AND_FOURTH" , language ) , language ) ; assertEquals ( 2 , searcherResult . getCheckedSentences ( ) ) ; assertEquals ( false , searcherResult . isResultIsTimeLimited ( ) ) ; assertEquals ( 1 , searcherResult . getMatchingSentences ( ) . size ( ) ) ; searcherResult = errorSearcher . findRuleMatchesOnIndex ( getFirstRule ( "EYE_BROW" , language ) , language ) ; assertEquals ( 2 , searcherResult . getCheckedSentences ( ) ) ; assertEquals ( false , searcherResult . isResultIsTimeLimited ( ) ) ; assertEquals ( 1 , searcherResult . getMatchingSentences ( ) . size ( ) ) ; searcherResult = errorSearcher . findRuleMatchesOnIndex ( getFirstRule ( "ALL_OVER_THE_WORD" , language ) , language ) ; assertEquals ( 2 , searcherResult . getCheckedSentences ( ) ) ; assertEquals ( false , searcherResult . isResultIsTimeLimited ( ) ) ; assertEquals ( 0 , searcherResult . getMatchingSentences ( ) . size ( ) ) ; try { errorSearcher . findRuleMatchesOnIndex ( getFirstRule ( "Invalid Rule Id" , language ) , language ) ; fail ( "Exception should be thrown for invalid rule id." ) ; } catch ( PatternRuleNotFoundException ignored ) { } } private PatternRule getFirstRule ( String ruleId , Language language ) throws IOException { return errorSearcher . getRuleById ( ruleId , language ) . get ( 0 ) ; } public void testWithNewRule ( ) throws Exception { createIndex ( "How to move back and fourth from linux to xmb?" ) ; final List < PatternToken > patternTokens = Arrays . asList ( new PatternToken ( "move" , false , false , false ) , new PatternToken ( "back" , false , false , false ) ) ; final PatternRule rule1 = new PatternRule ( "RULE1" , new English ( ) , patternTokens , "desc" , "msg" , "shortMsg" ) ; final Searcher errorSearcher = new Searcher ( directory ) ; final SearcherResult searcherResult = errorSearcher . findRuleMatchesOnIndex ( rule1 , new English ( ) ) ; assertEquals ( 1 , searcherResult . getCheckedSentences ( ) ) ; assertEquals ( 1 , searcherResult . getMatchingSentences ( ) . size ( ) ) ; final List < RuleMatch > ruleMatches = searcherResult . getMatchingSentences ( ) . get ( 0 ) . getRuleMatches ( ) ; assertEquals ( 1 , ruleMatches . size ( ) ) ; final Rule rule = ruleMatches . get ( 0 ) . getRule ( ) ; assertEquals ( "RULE1" , rule . getId ( ) ) ; } public void testWithRegexRule ( ) throws Exception { createIndex ( "How to move back and fourth from linux to xmb?" ) ; final List < PatternToken > patternTokens = Arrays . asList ( new PatternToken ( "move" , false , false , false ) , new PatternToken ( "forth|back" , false , true , false ) ) ; final PatternRule rule1 = new PatternRule ( "RULE1" , new English ( ) , patternTokens , "desc" , "msg" , "shortMsg" ) ; final Searcher errorSearcher = new Searcher ( directory ) ; final SearcherResult searcherResult = errorSearcher . findRuleMatchesOnIndex ( rule1 , new English ( ) ) ; assertEquals ( 1 , searcherResult . getCheckedSentences ( ) ) ; assertEquals ( 1 , searcherResult . getMatchingSentences ( ) . size ( ) ) ; final List < RuleMatch > ruleMatches = searcherResult . getMatchingSentences ( ) . get ( 0 ) . getRuleMatches ( ) ; assertEquals ( 1 , ruleMatches . size ( ) ) ; final Rule rule = ruleMatches . get ( 0 ) . getRule ( ) ; assertEquals ( "RULE1" , rule . getId ( ) ) ; } public void testApostropheElement ( ) throws Exception { createIndex ( "Daily Bleed's Anarchist Encyclopedia" ) ; final List < PatternToken > elements1 = Arrays . asList ( new PatternToken ( "Bleed" , false , false , false ) , new PatternToken ( "'" , false , false , false ) , new PatternToken ( "s" , false , false , false ) ) ; final PatternRule rule1 = new PatternRule ( "RULE1" , new English ( ) , elements1 , "desc" , "msg" , "shortMsg" ) ; final List < PatternToken > elements2 = Arrays . asList ( new PatternToken ( "Bleed" , false , false , false ) , new PatternToken ( "'" , false , false , false ) , new PatternToken ( "x" , false , false , false ) ) ; final PatternRule rule2 = new PatternRule ( "RULE" , new English ( ) , elements2 , "desc" , "msg" , "shortMsg" ) ; final SearcherResult searcherResult1 = errorSearcher . findRuleMatchesOnIndex ( rule1 , new English ( ) ) ; assertEquals ( 1 , searcherResult1 . getMatchingSentences ( ) . size ( ) ) ; final List < RuleMatch > ruleMatches = searcherResult1 . getMatchingSentences ( ) . get ( 0 ) . getRuleMatches ( ) ; assertEquals ( 1 , ruleMatches . size ( ) ) ; final Rule rule = ruleMatches . get ( 0 ) . getRule ( ) ; assertEquals ( "RULE1" , rule . getId ( ) ) ; final SearcherResult searcherResult2 = errorSearcher . findRuleMatchesOnIndex ( rule2 , new English ( ) ) ; assertEquals ( 0 , searcherResult2 . getMatchingSentences ( ) . size ( ) ) ; } public void testWithException ( ) throws Exception { createIndex ( "How to move back and fourth from linux to xmb?" ) ; final PatternToken exceptionElem = new PatternToken ( "forth|back" , false , true , false ) ; exceptionElem . setStringPosException ( "exception" , false , false , false , false , false , "POS" , false , false , null ) ; final List < PatternToken > patternTokens = Arrays . asList ( new PatternToken ( "move" , false , false , false ) , exceptionElem ) ; final PatternRule rule1 = new PatternRule ( "RULE1" , new English ( ) , patternTokens , "desc" , "msg" , "shortMsg" ) ; final Searcher errorSearcher = new Searcher ( directory ) ; final SearcherResult searcherResult = errorSearcher . findRuleMatchesOnIndex ( rule1 , new English ( ) ) ; assertEquals ( 1 , searcherResult . getCheckedSentences ( ) ) ; assertEquals ( 1 , searcherResult . getMatchingSentences ( ) . size ( ) ) ; final List < RuleMatch > ruleMatches = searcherResult . getMatchingSentences ( ) . get ( 0 ) . getRuleMatches ( ) ; assertEquals ( 1 , ruleMatches . size ( ) ) ; final Rule rule = ruleMatches . get ( 0 ) . getRule ( ) ; assertEquals ( "RULE1" , rule . getId ( ) ) ; } public void testNegatedMatchAtSentenceStart ( ) throws Exception { createIndex ( "How to move?" ) ; final PatternToken negatedPatternToken = new PatternToken ( "Negated" , false , false , false ) ; negatedPatternToken . setNegation ( true ) ; final List < PatternToken > patternTokens = Arrays . asList ( negatedPatternToken , new PatternToken ( "How" , false , false , false ) ) ; final Searcher errorSearcher = new Searcher ( directory ) ; final PatternRule rule1 = new PatternRule ( "RULE1" , new English ( ) , patternTokens , "desc" , "msg" , "shortMsg" ) ; final SearcherResult searcherResult = errorSearcher . findRuleMatchesOnIndex ( rule1 , new English ( ) ) ; assertEquals ( 1 , searcherResult . getCheckedSentences ( ) ) ; assertEquals ( 1 , searcherResult . getMatchingSentences ( ) . size ( ) ) ; final List < RuleMatch > ruleMatches = searcherResult . getMatchingSentences ( ) . get ( 0 ) . getRuleMatches ( ) ; assertEquals ( 1 , ruleMatches . size ( ) ) ; final Rule rule = ruleMatches . get ( 0 ) . getRule ( ) ; assertEquals ( "RULE1" , rule . getId ( ) ) ; } public void testWithOneElementWithException ( ) throws Exception { createIndex ( "How to move back and fourth from linux to xmb?" ) ; final PatternToken exceptionElem = new PatternToken ( "" , false , true , false ) ; exceptionElem . setStringPosException ( "exception" , false , false , false , false , false , "POS" , false , false , null ) ; final List < PatternToken > patternTokens = Arrays . asList ( exceptionElem ) ; final PatternRule rule1 = new PatternRule ( "RULE1" , new English ( ) , patternTokens , "desc" , "msg" , "shortMsg" ) ; final Searcher errorSearcher = new Searcher ( directory ) ; try { errorSearcher . findRuleMatchesOnIndex ( rule1 , new English ( ) ) ; fail ( ) ; } catch ( UnsupportedPatternRuleException ignored ) { } } private void createIndex ( String content ) throws IOException { directory = new RAMDirectory ( ) ; Indexer . run ( content , directory , new English ( ) ) ; errorSearcher = new Searcher ( directory ) ; } private void useRealIndex ( ) throws IOException { directory = FSDirectory . open ( new File ( "/home/languagetool/corpus/en/" ) ) ; errorSearcher = new Searcher ( directory ) ; } }
package org . languagetool . dev . index ; import java . io . IOException ; import java . io . StringReader ; import org . apache . lucene . analysis . BaseTokenStreamTestCase ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . tokenattributes . CharTermAttribute ; import org . apache . lucene . analysis . tokenattributes . OffsetAttribute ; import org . apache . lucene . analysis . tokenattributes . PositionIncrementAttribute ; import org . apache . lucene . analysis . tokenattributes . TypeAttribute ; import org . languagetool . JLanguageTool ; import org . languagetool . language . English ; public class LanguageToolFilterTest extends BaseTokenStreamTestCase { public void testFilter ( ) throws Exception { final String input = "How to?" ; final TokenStream stream = new AnyCharTokenizer ( TEST_VERSION_CURRENT , new StringReader ( input ) ) ; final LanguageToolFilter filter = new LanguageToolFilter ( stream , new JLanguageTool ( new English ( ) ) , false ) ; String start = "_POS_SENT_START" ; assertTokenStreamContents ( filter , new String [ ] { start , "How" , "_LEMMA_how" , "_POS_WRB" , "to" , "_LEMMA_to" , "_POS_TO" , "_LEMMA_to" , "_POS_IN" , "?" , "_POS_SENT_END" } , new int [ ] { 0 , 0 , 0 , 0 , 4 , 4 , 4 , 4 , 4 , 6 , 6 } , new int [ ] { 0 , 3 , 3 , 3 , 6 , 6 , 6 , 6 , 6 , 7 , 7 } , new String [ ] { "pos" , "word" , "pos" , "pos" , "word" , "pos" , "pos" , "pos" , "pos" , "word" , "pos" } , new int [ ] { 1 , 1 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 1 , 0 } , 7 ) ; } private static void displayTokensWithFullDetails ( TokenStream stream ) throws IOException { final CharTermAttribute term = stream . addAttribute ( CharTermAttribute . class ) ; final PositionIncrementAttribute posIncr = stream . addAttribute ( PositionIncrementAttribute . class ) ; final OffsetAttribute offset = stream . addAttribute ( OffsetAttribute . class ) ; final TypeAttribute type = stream . addAttribute ( TypeAttribute . class ) ; int position = 0 ; while ( stream . incrementToken ( ) ) { final int increment = posIncr . getPositionIncrement ( ) ; if ( increment > 0 ) { position = position + increment ; System . out . println ( ) ; System . out . print ( position + ": " ) ; } System . out . print ( "[" + term + ":" + offset . startOffset ( ) + "->" + offset . endOffset ( ) + ":" + type . type ( ) + "] " ) ; } System . out . println ( ) ; } }
package org . languagetool . dev . index ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Field ; import org . apache . lucene . document . FieldType ; import org . apache . lucene . index . DirectoryReader ; import org . apache . lucene . index . IndexWriter ; import org . apache . lucene . index . IndexWriterConfig ; import org . apache . lucene . sandbox . queries . regex . RegexQuery ; import org . apache . lucene . search . BooleanQuery ; import org . apache . lucene . search . IndexSearcher ; import org . apache . lucene . search . Query ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . RAMDirectory ; import org . apache . lucene . util . LuceneTestCase ; import org . languagetool . Language ; import org . languagetool . language . English ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . rules . patterns . PatternRuleLoader ; import java . io . ByteArrayInputStream ; import java . io . IOException ; import java . io . InputStream ; import java . util . List ; import static org . languagetool . dev . index . PatternRuleQueryBuilder . FIELD_NAME ; import static org . languagetool . dev . index . PatternRuleQueryBuilder . FIELD_NAME_LOWERCASE ; public class PatternRuleQueryBuilderTest extends LuceneTestCase { private IndexSearcher searcher ; private DirectoryReader reader ; private Directory directory ; private Language language ; @ Override public void setUp ( ) throws Exception { super . setUp ( ) ; language = new English ( ) ; directory = new RAMDirectory ( ) ; final Analyzer analyzer = Indexer . getAnalyzer ( language ) ; final IndexWriterConfig config = Indexer . getIndexWriterConfig ( analyzer ) ; try ( IndexWriter writer = new IndexWriter ( directory , config ) ) { addDocument ( writer , "How do you thin about this wonderful idea?" ) ; addDocument ( writer , "The are several grammar checkers for English, E.G. LanguageTool 123." ) ; } reader = DirectoryReader . open ( directory ) ; searcher = newSearcher ( reader ) ; } @ Override public void tearDown ( ) throws Exception { super . tearDown ( ) ; if ( reader != null ) { reader . close ( ) ; } if ( directory != null ) { directory . close ( ) ; } } private void addDocument ( IndexWriter writer , String content ) throws IOException { final Document doc = new Document ( ) ; final FieldType type = new FieldType ( ) ; type . setStored ( true ) ; type . setIndexed ( true ) ; type . setTokenized ( true ) ; doc . add ( new Field ( FIELD_NAME , content , type ) ) ; doc . add ( new Field ( FIELD_NAME_LOWERCASE , content , type ) ) ; writer . addDocument ( doc ) ; } public void testQueryBuilder ( ) throws Exception { final String ruleXml = "<token skip='-1'>How</token>" + "<token postag='PRP'></token>" + "<token skip='1'>thin</token>" + "<token postag_regexp='yes' postag='JJ|DT'>this</token>" + "<token regexp='yes' negate='yes'>bad|good</token>" + "<token regexp='yes'>idea|proposal</token>" ; final PatternRule patternRule = makeRule ( ruleXml ) ; final PatternRuleQueryBuilder patternRuleQueryBuilder = new PatternRuleQueryBuilder ( language ) ; final Query query = patternRuleQueryBuilder . buildRelaxedQuery ( patternRule ) ; assertEquals ( "+fieldLowercase:how +fieldLowercase:_pos_prp +fieldLowercase:thin " + "+spanNear([fieldLowercase:this, SpanMultiTermQueryWrapper(fieldLowercase:/_pos_(jj|dt)/)], 0, false) " + "+fieldLowercase:/idea|proposal/" , query . toString ( ) ) ; } public void testCaseSensitive ( ) throws Exception { final InputStream input = new ByteArrayInputStream ( ( "<?xml version='1.0' encoding='UTF-8'?> <rules lang='en'> <category name='Test'>" + "<rule id='TEST_RULE_1' name='test_1'> <pattern case_sensitive='yes'>" + " <token>How</token>" + "</pattern> </rule>" + "<rule id='TEST_RULE_2' name='test_2'> <pattern case_sensitive='yes'>" + " <token>how</token>" + "</pattern> </rule>" + "<rule id='TEST_RULE_3' name='test_3'> <pattern>" + " <token>How</token>" + "</pattern> </rule>" + "<rule id='TEST_RULE_4' name='test_4'> <pattern>" + " <token>how</token>" + "</pattern> </rule>" + "</category> </rules>" ) . getBytes ( ) ) ; final PatternRuleLoader ruleLoader = new PatternRuleLoader ( ) ; final List < PatternRule > rules = ruleLoader . getRules ( input , "test.xml" ) ; final PatternRuleQueryBuilder patternRuleQueryBuilder = new PatternRuleQueryBuilder ( language ) ; Query query = patternRuleQueryBuilder . buildRelaxedQuery ( rules . get ( 0 ) ) ; assertEquals ( 1 , searcher . search ( query , null , 1000 ) . totalHits ) ; query = patternRuleQueryBuilder . buildRelaxedQuery ( rules . get ( 1 ) ) ; assertEquals ( 0 , searcher . search ( query , null , 1000 ) . totalHits ) ; query = patternRuleQueryBuilder . buildRelaxedQuery ( rules . get ( 2 ) ) ; assertEquals ( 1 , searcher . search ( query , null , 1000 ) . totalHits ) ; query = patternRuleQueryBuilder . buildRelaxedQuery ( rules . get ( 3 ) ) ; assertEquals ( 1 , searcher . search ( query , null , 1000 ) . totalHits ) ; } public void testUnsupportedPatternRule ( ) throws Exception { final PatternRuleQueryBuilder patternRuleQueryBuilder = new PatternRuleQueryBuilder ( language ) ; try { patternRuleQueryBuilder . buildRelaxedQuery ( makeRule ( "<token skip='-1'><exception>and</exception></token>" , false ) ) ; fail ( "Exception should be thrown for unsupported PatternRule" ) ; } catch ( UnsupportedPatternRuleException ignored ) { } } public void testUnsupportedBackReferencePatternRule ( ) throws Exception { final PatternRuleQueryBuilder patternRuleQueryBuilder = new PatternRuleQueryBuilder ( language ) ; try { patternRuleQueryBuilder . buildRelaxedQuery ( makeRule ( "<token>\\1</token>" , false ) ) ; fail ( "Exception should be thrown for unsupported PatternRule" ) ; } catch ( UnsupportedPatternRuleException ignored ) { } } public void testSpecialRegexSyntax ( ) throws Exception { final PatternRule patternRule = makeRule ( "<token regexp='yes'>\\p{Punct}</token>" , false ) ; final PatternRuleQueryBuilder queryBuilder = new PatternRuleQueryBuilder ( language ) ; final Query query = queryBuilder . buildRelaxedQuery ( patternRule ) ; assertEquals ( "+fieldLowercase:\\p{Punct}" , query . toString ( ) ) ; assertEquals ( RegexQuery . class , ( ( BooleanQuery ) query ) . clauses ( ) . get ( 0 ) . getQuery ( ) . getClass ( ) ) ; assertMatches ( patternRule , 2 ) ; } public void testSpecialRegexSyntax2 ( ) throws Exception { final PatternRule patternRule = makeRule ( "<token regexp='yes' inflected='yes'>\\p{Lu}\\p{Ll}+</token>" , false ) ; final PatternRuleQueryBuilder queryBuilder = new PatternRuleQueryBuilder ( language ) ; final Query query = queryBuilder . buildRelaxedQuery ( patternRule ) ; assertEquals ( "+fieldLowercase:\\p{Lu}\\p{Ll}+" , query . toString ( ) ) ; assertEquals ( RegexQuery . class , ( ( BooleanQuery ) query ) . clauses ( ) . get ( 0 ) . getQuery ( ) . getClass ( ) ) ; assertMatches ( patternRule , 0 ) ; } public void testNumberRegex ( ) throws Exception { assertMatches ( makeRule ( "<token regexp='yes'>13\\d</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token regexp='yes'>12\\d</token>" ) , 1 ) ; } public void testIgnoreOptionalTokens ( ) throws Exception { assertMatches ( makeRule ( "<token min='0'>optional</token><token>idea</token>" ) , 1 ) ; } public void testOnlyInflected ( ) throws Exception { assertMatches ( makeRule ( "<token inflected='yes'>think</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token inflected='yes'>LanguageTool</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token inflected='yes'>checker</token>" ) , 1 ) ; } public void testInflectedAndRegex ( ) throws Exception { assertMatches ( makeRule ( "<token inflected='yes' regexp='yes'>foo|bar</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token inflected='yes' regexp='yes'>walk|be</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token inflected='yes' regexp='yes'>somefoo|wonderful</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token inflected='yes' regexp='yes'>somefoo|wonderf.l</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token inflected='yes' regexp='yes'>somefoo|wonderX.l</token>" ) , 0 ) ; } public void testSeveralElements ( ) throws Exception { assertMatches ( makeRule ( "<token>How</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>how</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>LanguageTool</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>UnknownWord</token>" ) , 0 ) ; assertMatches ( makeCaseSensitiveRule ( "<token>How</token>" ) , 1 ) ; assertMatches ( makeCaseSensitiveRule ( "<token>how</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token regexp='yes'>Foo|How</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token regexp='yes'>Foo|how</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token regexp='yes'>Foo|Bar</token>" ) , 0 ) ; assertMatches ( makeCaseSensitiveRule ( "<token regexp='yes'>Foo|How</token>" ) , 1 ) ; assertMatches ( makeCaseSensitiveRule ( "<token regexp='yes'>foo|HOW</token>" ) , 0 ) ; assertMatches ( makeCaseSensitiveRule ( "<token regexp='yes'>foo|how</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token postag='WRB'></token>" ) , 1 ) ; assertMatches ( makeRule ( "<token postag='FOO'></token>" ) , 0 ) ; assertMatches ( makeRule ( "<token postag='[XW]RB' postag_regexp='yes'></token>" ) , 1 ) ; assertMatches ( makeRule ( "<token postag='FOO|WRB' postag_regexp='yes'></token>" ) , 1 ) ; assertMatches ( makeRule ( "<token postag='WRB|FOO' postag_regexp='yes'></token>" ) , 1 ) ; assertMatches ( makeRule ( "<token postag='[XY]OO' postag_regexp='yes'></token>" ) , 0 ) ; assertMatches ( makeRule ( "<token>grammar</token><token>checker</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token>grammar</token><token>checkers</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>grammar</token><token inflected='yes'>checker</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token postag='WRB'>How</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token postag='[XW]RB' postag_regexp='yes'>How</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token postag='WRB'>Foo</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token postag='FOO'>How</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token>How</token> <token>do</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>How</token> <token>foo</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token>How</token> <token>do</token> <token>you</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>How</token> <token>do</token> <token>foo</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token regexp='yes'>Foo|How</token> <token>do</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token skip='-1'>How</token> <token>wonderful</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token skip='6'>How</token> <token>wonderful</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token skip='5'>How</token> <token>wonderful</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>How</token> <token skip='-1'>do</token> <token>wonderful</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>How</token> <token skip='4'>do</token> <token>wonderful</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token skip='-1'>How</token> <token skip='-1'>thin</token> <token>wonderful</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token skip='3'>How</token> <token skip='3'>thin</token> <token>wonderful</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token skip='3'>How</token> <token skip='3'>thin</token> <token>foo</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token>E</token> <token>.</token> <token>G</token> <token>.</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>X</token> <token>.</token> <token>G</token> <token>.</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token>E</token> <token>.</token> <token>G</token> <token>.</token> <token>LanguageTool</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>E</token> <token>.</token> <token>G</token> <token>.</token> <token>foo</token>" ) , 0 ) ; assertMatches ( makeRule ( "<token>How</token> <token negate='yes'>foo</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>How</token> <token negate='yes'>do</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>How</token> <token>do</token> <token negate='yes'>foo</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>How</token> <token negate='yes'>foo</token> <token>you</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>How</token> <token>do</token> <token negate='yes'>you</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>How</token> <token negate='yes'>do</token> <token>you</token>" ) , 1 ) ; assertMatches ( makeRule ( "<token>How</token> <token negate='yes'>do</token> <token negate='yes'>you</token>" ) , 1 ) ; } private void assertMatches ( PatternRule patternRule , int expectedMatches ) throws Exception { final PatternRuleQueryBuilder queryBuilder = new PatternRuleQueryBuilder ( language ) ; final Query query = queryBuilder . buildRelaxedQuery ( patternRule ) ; final int matches = searcher . search ( query , null , 1000 ) . totalHits ; assertEquals ( "Query failed: " + query , expectedMatches , matches ) ; } private PatternRule makeCaseSensitiveRule ( String ruleXml ) throws IOException { return makeRule ( ruleXml , true ) ; } private PatternRule makeRule ( String ruleXml ) throws IOException { return makeRule ( ruleXml , false ) ; } private PatternRule makeRule ( String ruleXml , boolean caseSensitive ) throws IOException { final StringBuilder sb = new StringBuilder ( ) ; sb . append ( "<?xml version='1.0' encoding='UTF-8'?>" ) ; sb . append ( "<rules lang='en'> <category name='Test'> <rule id='TEST_RULE' name='test'>" ) ; if ( caseSensitive ) { sb . append ( "<pattern case_sensitive='yes'>" ) ; } else { sb . append ( "<pattern>" ) ; } sb . append ( ruleXml ) ; sb . append ( "</pattern> </rule> </category> </rules>" ) ; final InputStream input = new ByteArrayInputStream ( sb . toString ( ) . getBytes ( ) ) ; final PatternRuleLoader ruleLoader = new PatternRuleLoader ( ) ; final List < PatternRule > rules = ruleLoader . getRules ( input , "test.xml" ) ; assertEquals ( 1 , rules . size ( ) ) ; return rules . get ( 0 ) ; } }
package org . languagetool . dev . wikipedia ; import junit . framework . TestCase ; import xtc . tree . Location ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class LocationHelperTest extends TestCase { public void testAbsolutePositionFor ( ) { assertThat ( checkLocation ( 1 , 1 , "hallo" ) , is ( 0 ) ) ; assertThat ( checkLocation ( 1 , 2 , "hallo" ) , is ( 1 ) ) ; assertThat ( checkLocation ( 2 , 1 , "hallo\nx" ) , is ( 6 ) ) ; assertThat ( checkLocation ( 3 , 3 , "\n\nxyz" ) , is ( 4 ) ) ; } public void testInvalidPosition ( ) { assertThat ( checkLocation ( 1 , 1 , "hallo" ) , is ( 0 ) ) ; try { checkLocation ( 2 , 2 , "hallo" ) ; fail ( ) ; } catch ( RuntimeException ignored ) { } } private int checkLocation ( int line , int col , String text ) { return LocationHelper . absolutePositionFor ( new Location ( "" , line , col ) , text ) ; } }
package org . languagetool . dev . wikipedia ; import junit . framework . TestCase ; import org . languagetool . language . German ; import java . io . IOException ; import java . net . URL ; import java . util . List ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class WikipediaQuickCheckTest extends TestCase { public void noTestCheckPage ( ) throws IOException , PageNotFoundException { final WikipediaQuickCheck check = new WikipediaQuickCheck ( ) ; final String url = "https://de.wikipedia.org/wiki/Augsburg" ; final MarkupAwareWikipediaResult result = check . checkPage ( new URL ( url ) ) ; final List < AppliedRuleMatch > appliedMatches = result . getAppliedRuleMatches ( ) ; System . out . println ( "ruleApplications: " + appliedMatches . size ( ) ) ; for ( AppliedRuleMatch appliedMatch : appliedMatches ) { System . out . println ( "=====" ) ; System . out . println ( "Rule : " + appliedMatch . getRuleMatch ( ) . getRule ( ) . getDescription ( ) + "\n" ) ; for ( RuleMatchApplication ruleMatchApplication : appliedMatch . getRuleMatchApplications ( ) ) { System . out . println ( "Original : " + ruleMatchApplication . getOriginalErrorContext ( 10 ) . replace ( "\n" , " " ) ) ; if ( ruleMatchApplication . hasRealReplacement ( ) ) { System . out . println ( "Corrected: " + ruleMatchApplication . getCorrectedErrorContext ( 10 ) . replace ( "\n" , " " ) ) ; } System . out . println ( ) ; } } } public void testCheckWikipediaMarkup ( ) throws IOException { final WikipediaQuickCheck check = new WikipediaQuickCheck ( ) ; final String markup = "== Beispiele ==\n\n" + "Eine kleine Auswahl von Fehlern.\n\n" + "Das Komma ist richtig, wegen dem Leerzeichen." ; final MediaWikiContent wikiContent = new MediaWikiContent ( markup , "2012-11-11T20:00:00" ) ; final ErrorMarker errorMarker = new ErrorMarker ( "<err>" , "</err>" ) ; final MarkupAwareWikipediaResult result = check . checkWikipediaMarkup ( new URL ( "http://fake-url.org" ) , wikiContent , new German ( ) , errorMarker ) ; assertThat ( result . getLastEditTimestamp ( ) , is ( "2012-11-11T20:00:00" ) ) ; final List < AppliedRuleMatch > appliedMatches = result . getAppliedRuleMatches ( ) ; assertThat ( appliedMatches . size ( ) , is ( 1 ) ) ; final AppliedRuleMatch firstAppliedMatch = appliedMatches . get ( 0 ) ; assertThat ( firstAppliedMatch . getRuleMatchApplications ( ) . size ( ) , is ( 1 ) ) ; RuleMatchApplication ruleMatchApplication = firstAppliedMatch . getRuleMatchApplications ( ) . get ( 0 ) ; assertTrue ( "Got: " + ruleMatchApplication . getTextWithCorrection ( ) , ruleMatchApplication . getTextWithCorrection ( ) . contains ( "<err>wegen dem</err> Leerzeichen." ) ) ; assertThat ( ruleMatchApplication . getOriginalErrorContext ( 12 ) , is ( "st richtig, <err>wegen dem</err> Leerz" ) ) ; assertThat ( ruleMatchApplication . getCorrectedErrorContext ( 12 ) , is ( "st richtig, <err>wegen dem</err> Leerz" ) ) ; } public void testGetPlainText ( ) { final WikipediaQuickCheck check = new WikipediaQuickCheck ( ) ; final String filteredContent = check . getPlainText ( "<?xml version=\"1.0\"?><api><query><normalized><n from=\"Benutzer_Diskussion:Dnaber\" to=\"Benutzer Diskussion:Dnaber\" />" + "</normalized><pages><page pageid=\"143424\" ns=\"3\" title=\"Benutzer Diskussion:Dnaber\"><revisions><rev xml:space=\"preserve\">\n" + "Test [[Link]] Foo&amp;nbsp;bar.\n" + "</rev></revisions></page></pages></query></api>" ) ; assertEquals ( "Test Link Foo\u00A0bar." , filteredContent ) ; } public void testGetPlainTextMapping ( ) { final WikipediaQuickCheck check = new WikipediaQuickCheck ( ) ; final String text = "Test [[Link]] und [[AnotherLink|noch einer]] und [http://test.org external link] Foo&amp;nbsp;bar.\n" ; final PlainTextMapping filteredContent = check . getPlainTextMapping ( "<?xml version=\"1.0\"?><api><query><normalized><n from=\"Benutzer_Diskussion:Dnaber\" to=\"Benutzer Diskussion:Dnaber\" />" + "</normalized><pages><page pageid=\"143424\" ns=\"3\" title=\"Benutzer Diskussion:Dnaber\"><revisions><rev xml:space=\"preserve\">" + text + "</rev></revisions></page></pages></query></api>" ) ; assertEquals ( "Test Link und noch einer und external link Foo\u00A0bar." , filteredContent . getPlainText ( ) ) ; assertEquals ( 1 , filteredContent . getOriginalTextPositionFor ( 1 ) . line ) ; assertEquals ( 1 , filteredContent . getOriginalTextPositionFor ( 1 ) . column ) ; assertEquals ( filteredContent . getPlainText ( ) . charAt ( 0 ) , text . charAt ( 0 ) ) ; assertEquals ( 'u' , text . charAt ( 14 ) ) ; assertEquals ( 'u' , filteredContent . getPlainText ( ) . charAt ( 10 ) ) ; assertEquals ( 1 , filteredContent . getOriginalTextPositionFor ( 11 ) . line ) ; assertEquals ( 15 , filteredContent . getOriginalTextPositionFor ( 11 ) . column ) ; } public void testGetPlainTextMappingMultiLine1 ( ) { final WikipediaQuickCheck check = new WikipediaQuickCheck ( ) ; final String text = "Test [[Link]] und [[AnotherLink|noch einer]].\nUnd [[NextLink]] Foobar.\n" ; final PlainTextMapping filteredContent = check . getPlainTextMapping ( "<?xml version=\"1.0\"?><api><query><normalized><n from=\"Benutzer_Diskussion:Dnaber\" to=\"Benutzer Diskussion:Dnaber\" />" + "</normalized><pages><page pageid=\"143424\" ns=\"3\" title=\"Benutzer Diskussion:Dnaber\"><revisions><rev xml:space=\"preserve\">" + text + "</rev></revisions></page></pages></query></api>" ) ; assertEquals ( "Test Link und noch einer. Und NextLink Foobar." , filteredContent . getPlainText ( ) ) ; assertEquals ( 1 , filteredContent . getOriginalTextPositionFor ( 1 ) . line ) ; assertEquals ( 1 , filteredContent . getOriginalTextPositionFor ( 1 ) . column ) ; assertEquals ( filteredContent . getPlainText ( ) . charAt ( 0 ) , text . charAt ( 0 ) ) ; assertEquals ( 'U' , text . charAt ( 46 ) ) ; assertEquals ( ' ' , filteredContent . getPlainText ( ) . charAt ( 25 ) ) ; assertEquals ( 'U' , filteredContent . getPlainText ( ) . charAt ( 26 ) ) ; assertEquals ( 2 , filteredContent . getOriginalTextPositionFor ( 27 ) . line ) ; assertEquals ( 45 , filteredContent . getOriginalTextPositionFor ( 25 ) . column ) ; assertEquals ( 1 , filteredContent . getOriginalTextPositionFor ( 26 ) . column ) ; assertEquals ( 2 , filteredContent . getOriginalTextPositionFor ( 27 ) . column ) ; } public void testGetPlainTextMappingMultiLine2 ( ) { final WikipediaQuickCheck check = new WikipediaQuickCheck ( ) ; final String text = "Test [[Link]] und [[AnotherLink|noch einer]].\n\nUnd [[NextLink]] Foobar.\n" ; final PlainTextMapping filteredContent = check . getPlainTextMapping ( "<?xml version=\"1.0\"?><api><query><normalized><n from=\"Benutzer_Diskussion:Dnaber\" to=\"Benutzer Diskussion:Dnaber\" />" + "</normalized><pages><page pageid=\"143424\" ns=\"3\" title=\"Benutzer Diskussion:Dnaber\"><revisions><rev xml:space=\"preserve\">" + text + "</rev></revisions></page></pages></query></api>" ) ; assertEquals ( "Test Link und noch einer.\n\nUnd NextLink Foobar." , filteredContent . getPlainText ( ) ) ; assertEquals ( 1 , filteredContent . getOriginalTextPositionFor ( 1 ) . line ) ; assertEquals ( 1 , filteredContent . getOriginalTextPositionFor ( 1 ) . column ) ; assertEquals ( filteredContent . getPlainText ( ) . charAt ( 0 ) , text . charAt ( 0 ) ) ; assertEquals ( 'U' , text . charAt ( 47 ) ) ; assertEquals ( 'U' , filteredContent . getPlainText ( ) . charAt ( 27 ) ) ; assertEquals ( 3 , filteredContent . getOriginalTextPositionFor ( 28 ) . line ) ; assertEquals ( 45 , filteredContent . getOriginalTextPositionFor ( 25 ) . column ) ; assertEquals ( 46 , filteredContent . getOriginalTextPositionFor ( 26 ) . column ) ; assertEquals ( 47 , filteredContent . getOriginalTextPositionFor ( 27 ) . column ) ; assertEquals ( 1 , filteredContent . getOriginalTextPositionFor ( 28 ) . column ) ; } public void testRemoveInterLanguageLinks ( ) { final WikipediaQuickCheck check = new WikipediaQuickCheck ( ) ; assertEquals ( "foo bar" , check . removeWikipediaLinks ( "foo [[pt:Some Article]] bar" ) ) ; assertEquals ( "foo [[some link]] bar" , check . removeWikipediaLinks ( "foo [[some link]] bar" ) ) ; assertEquals ( "foo [[Some Link]] bar " , check . removeWikipediaLinks ( "foo [[Some Link]] bar [[pt:Some Article]]" ) ) ; assertEquals ( "foo [[zh-min-nan:Linux]] bar" , check . removeWikipediaLinks ( "foo [[zh-min-nan:Linux]] bar" ) ) ; assertEquals ( "[[Scultura bronzea di Gaudí mentre osserva il suo ''[[Il Capriccio|Capriccio]]'']]" , check . removeWikipediaLinks ( "[[File:Gaudì-capriccio.JPG|thumb|left|Scultura bronzea di Gaudí mentre osserva il suo ''[[Il Capriccio|Capriccio]]'']]" ) ) ; assertEquals ( "[[[[Palau de la Música Catalana]], entrada]]" , check . removeWikipediaLinks ( "[[Fitxer:Palau_de_musica_2.JPG|thumb|[[Palau de la Música Catalana]], entrada]]" ) ) ; assertEquals ( "foo bar" , check . removeWikipediaLinks ( "foo [[Kategorie:Kurgebäude]] bar" ) ) ; assertEquals ( "foo [[''Kursaal Palace'' in San Sebastián]] bar" , check . removeWikipediaLinks ( "foo [[Datei:FestivalSS.jpg|miniatur|''Kursaal Palace'' in San Sebastián]] bar" ) ) ; assertEquals ( "[[Yupana, emprat pels [[Inques]].]]" , check . removeWikipediaLinks ( "[[Fitxer:Yupana 1.GIF|thumb|Yupana, emprat pels [[Inques]].]]" ) ) ; } }
package org . languagetool . dev . wikipedia ; import junit . framework . TestCase ; import org . apache . commons . io . IOUtils ; import org . apache . commons . lang . StringUtils ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . language . English ; import org . languagetool . language . GermanyGerman ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . de . GermanSpellerRule ; import org . languagetool . rules . patterns . PatternRule ; import java . io . IOException ; import java . io . InputStream ; import java . util . Collections ; import java . util . List ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; public class SuggestionReplacerTest extends TestCase { private final SwebleWikipediaTextFilter filter = new SwebleWikipediaTextFilter ( ) ; private final GermanyGerman germanyGerman = new GermanyGerman ( ) ; private final JLanguageTool langTool = getLanguageTool ( ) ; private final JLanguageTool englishLangTool = getLanguageTool ( new English ( ) ) ; public void testApplySuggestionToOriginalText ( ) throws Exception { SwebleWikipediaTextFilter filter = new SwebleWikipediaTextFilter ( ) ; applySuggestion ( langTool , filter , "Die CD ROM." , "Die <s>CD-ROM.</s>" ) ; applySuggestion ( langTool , filter , "Die [[verlinkte]] CD ROM." , "Die [[verlinkte]] <s>CD-ROM.</s>" ) ; applySuggestion ( langTool , filter , "Die [[Link|verlinkte]] CD ROM." , "Die [[Link|verlinkte]] <s>CD-ROM.</s>" ) ; applySuggestion ( langTool , filter , "Die [[CD ROM]]." , "Die <s>[[CD-ROM]].</s>" ) ; applySuggestion ( langTool , filter , "Der [[Abschied]].\n\n==Überschrift==\n\nEin Ab schied." , "Der [[Abschied]].\n\n==Überschrift==\n\nEin <s>Abschied.</s>" ) ; applySuggestion ( langTool , filter , "Ein ökonomischer Gottesdienst." , "Ein <s>ökumenischer</s> Gottesdienst." ) ; applySuggestion ( langTool , filter , "Ein ökonomischer Gottesdienst mit ökonomischer Planung." , "Ein <s>ökumenischer</s> Gottesdienst mit ökonomischer Planung." ) ; applySuggestion ( langTool , filter , "\nEin ökonomischer Gottesdienst.\n" , "\nEin <s>ökumenischer</s> Gottesdienst.\n" ) ; applySuggestion ( langTool , filter , "\n\nEin ökonomischer Gottesdienst.\n" , "\n\nEin <s>ökumenischer</s> Gottesdienst.\n" ) ; } public void testNestedTemplates ( ) throws Exception { String markup = "{{FNBox|\n" + " {{FNZ|1|1979 und 1984}}\n" + " {{FNZ|2|[[Rundungsfehler]]}}\n" + "}}\n\nEin ökonomischer Gottesdienst.\n" ; applySuggestion ( langTool , filter , markup , markup . replace ( "ökonomischer" , "<s>ökumenischer</s>" ) ) ; } public void testReference1 ( ) throws Exception { String markup = "Hier <ref name=isfdb>\n" + "Retrieved 2012-07-31.</ref> steht,, das Haus." ; applySuggestion ( langTool , filter , markup , markup . replace ( "steht,, das Haus." , "<s>steht,</s> das Haus." ) ) ; } public void testReference2 ( ) throws Exception { String markup = "Hier <ref name=\"NPOVxxx\" /> steht,, das Haus." ; applySuggestion ( langTool , filter , markup , markup . replace ( "steht,, das Haus." , "<s>steht, das</s> Haus." ) ) ; } public void testErrorAtTextBeginning ( ) throws Exception { String markup = "A hour ago\n" ; applySuggestion ( englishLangTool , filter , markup , markup . replace ( "A" , "<s>An</s>" ) ) ; } public void testErrorAtParagraphBeginning ( ) throws Exception { String markup = "X\n\nA hour ago\n" ; applySuggestion ( englishLangTool , filter , markup , markup . replace ( "A" , "<s>An</s>" ) ) ; } public void testKnownBug ( ) throws Exception { String markup = "{{HdBG GKZ|9761000}}." ; try { applySuggestion ( langTool , filter , markup , markup ) ; } catch ( RuntimeException e ) { } } public void testComplexText ( ) throws Exception { String markup = "{{Dieser Artikel|behandelt die freie Onlineenzyklopädie Wikipedia; zu dem gleichnamigen Asteroiden siehe [[(274301) Wikipedia]].}}\n" + "\n" + "{{Infobox Website\n" + "| Name = '''Wikipedia'''\n" + "| Logo = [[Datei:Wikipedia-logo-v2-de.svg|180px|Das Wikipedia-Logo]]\n" + "| url = [//de.wikipedia.org/ de.wikipedia.org] (deutschsprachige Version)<br />\n" + "[//www.wikipedia.org/ www.wikipedia.org] (Übersicht aller Sprachen)\n" + "| Kommerziell = nein\n" + "| Beschreibung = [[Wiki]] einer freien kollektiv erstellten Online-Enzyklopädie\n" + "}}\n" + "\n" + "'''Wikipedia''' [{{IPA|ˌvɪkiˈpeːdia}}] (auch: ''die Wikipedia'') ist ein am [[15. Januar|15.&nbsp;Januar]] [[2001]] gegründetes Projekt. Und und so.\n" ; applySuggestion ( langTool , filter , markup , markup . replace ( "Und und so." , "<s>Und so.</s>" ) ) ; } public void testCompleteText ( ) throws Exception { InputStream stream = SuggestionReplacerTest . class . getResourceAsStream ( "/org/languagetool/dev/wikipedia/wikipedia.txt" ) ; String origMarkup = IOUtils . toString ( stream , "utf-8" ) ; JLanguageTool langTool = new JLanguageTool ( new GermanyGerman ( ) { @ Override protected synchronized List < PatternRule > getPatternRules ( ) { return Collections . emptyList ( ) ; } } ) ; langTool . disableRule ( GermanSpellerRule . RULE_ID ) ; langTool . disableRule ( "DE_AGREEMENT" ) ; langTool . disableRule ( "GERMAN_WORD_REPEAT_BEGINNING_RULE" ) ; langTool . disableRule ( "COMMA_PARENTHESIS_WHITESPACE" ) ; langTool . disableRule ( "DE_CASE" ) ; langTool . disableRule ( "ABKUERZUNG_LEERZEICHEN" ) ; langTool . disableRule ( "TYPOGRAFISCHE_ANFUEHRUNGSZEICHEN" ) ; PlainTextMapping mapping = filter . filter ( origMarkup ) ; List < RuleMatch > matches = langTool . check ( mapping . getPlainText ( ) ) ; assertThat ( "Expected 3 matches, got: " + matches , matches . size ( ) , is ( 3 ) ) ; int oldPos = 0 ; for ( RuleMatch match : matches ) { SuggestionReplacer replacer = new SuggestionReplacer ( mapping , origMarkup , new ErrorMarker ( "<s>" , "</s>" ) ) ; List < RuleMatchApplication > ruleMatchApplications = replacer . applySuggestionsToOriginalText ( match ) ; assertThat ( ruleMatchApplications . size ( ) , is ( 1 ) ) ; RuleMatchApplication ruleMatchApplication = ruleMatchApplications . get ( 0 ) ; assertThat ( StringUtils . countMatches ( ruleMatchApplication . getTextWithCorrection ( ) , "absichtlicher absichtlicher" ) , is ( 2 ) ) ; int pos = ruleMatchApplication . getTextWithCorrection ( ) . indexOf ( "<s>absichtlicher</s> Fehler" ) ; if ( pos == - 1 ) { pos = ruleMatchApplication . getTextWithCorrection ( ) . indexOf ( "<s>absichtlicher Fehler</s>" ) ; } assertTrue ( "Found correction at: " + pos , pos > oldPos ) ; oldPos = pos ; } } public void testCompleteText2 ( ) throws Exception { InputStream stream = SuggestionReplacerTest . class . getResourceAsStream ( "/org/languagetool/dev/wikipedia/wikipedia2.txt" ) ; String origMarkup = IOUtils . toString ( stream , "utf-8" ) ; JLanguageTool langTool = new JLanguageTool ( germanyGerman ) ; PlainTextMapping mapping = filter . filter ( origMarkup ) ; List < RuleMatch > matches = langTool . check ( mapping . getPlainText ( ) ) ; assertTrue ( "Expected >= 30 matches, got: " + matches , matches . size ( ) >= 30 ) ; for ( RuleMatch match : matches ) { SuggestionReplacer replacer = new SuggestionReplacer ( mapping , origMarkup , new ErrorMarker ( "<s>" , "</s>" ) ) ; List < RuleMatchApplication > ruleMatchApplications = replacer . applySuggestionsToOriginalText ( match ) ; if ( ruleMatchApplications . size ( ) == 0 ) { continue ; } RuleMatchApplication ruleMatchApplication = ruleMatchApplications . get ( 0 ) ; assertThat ( StringUtils . countMatches ( ruleMatchApplication . getTextWithCorrection ( ) , "<s>" ) , is ( 1 ) ) ; } } private JLanguageTool getLanguageTool ( ) { JLanguageTool langTool = getLanguageTool ( germanyGerman ) ; langTool . disableRule ( "DE_CASE" ) ; return langTool ; } private JLanguageTool getLanguageTool ( Language language ) { return new JLanguageTool ( language ) ; } private void applySuggestion ( JLanguageTool langTool , SwebleWikipediaTextFilter filter , String text , String expected ) throws IOException { PlainTextMapping mapping = filter . filter ( text ) ; List < RuleMatch > matches = langTool . check ( mapping . getPlainText ( ) ) ; assertThat ( "Expected 1 match, got: " + matches , matches . size ( ) , is ( 1 ) ) ; SuggestionReplacer replacer = new SuggestionReplacer ( mapping , text , new ErrorMarker ( "<s>" , "</s>" ) ) ; List < RuleMatchApplication > ruleMatchApplications = replacer . applySuggestionsToOriginalText ( matches . get ( 0 ) ) ; assertThat ( ruleMatchApplications . size ( ) , is ( 1 ) ) ; assertThat ( ruleMatchApplications . get ( 0 ) . getTextWithCorrection ( ) , is ( expected ) ) ; } }
package org . languagetool . dev . wikipedia ; import junit . framework . TestCase ; public class WikipediaTextFilterTest extends TestCase { final SwebleWikipediaTextFilter swebleFilter = new SwebleWikipediaTextFilter ( ) ; public void testImageRemoval ( ) throws Exception { assertExtract ( "foo [[Datei:Bundesarchiv Bild 183-1990-0803-017.jpg|miniatur|Mit Lothar de Maizière im August 1990]] bar" , "foo bar" ) ; } public void testRemovalOfImageWithLink ( ) throws Exception { assertExtract ( "foo [[Datei:Bundesarchiv Bild 183-1990-0803-017.jpg|miniatur|Mit [[Lothar de Maizière]] im August 1990]] bar [[Link]]" , "foo bar Link" ) ; } public void testLink1 ( ) throws Exception { assertExtract ( "foo [[Test]] bar" , "foo Test bar" ) ; } public void testLink2 ( ) throws Exception { assertExtract ( "foo [[Target|visible link]] bar" , "foo visible link bar" ) ; } public void testEntity ( ) throws Exception { assertExtract ( "rund 20&nbsp;Kilometer südlich" , "rund 20\u00A0Kilometer südlich" ) ; assertExtract ( "one&lt;br/&gt;two" , "one<br/>two" ) ; assertExtract ( "one &ndash; two" , "one – two" ) ; assertExtract ( "one &mdash; two" , "one — two" ) ; assertExtract ( "one &amp; two" , "one & two" ) ; } public void testLists ( ) throws Exception { assertExtract ( "# one\n# two\n" , "one\n\ntwo" ) ; assertExtract ( "* one\n* two\n" , "one\n\ntwo" ) ; } public void testOtherStuff ( ) throws Exception { assertExtract ( "Daniel Guerin, ''[http://theanarchistlibrary.org Anarchism: From Theory to Practice]''" , "Daniel Guerin, Anarchism: From Theory to Practice" ) ; assertExtract ( "foo <ref>\"At the end of the century in France [http://theanarchistlibrary.org] [[Daniel Guérin]]. ''Anarchism'']</ref>" , "foo" ) ; assertExtract ( "* [http://theanarchistlibrary.org ''Anarchism: From Theory to Practice''] by [[Daniel Guerin]]. Monthly Review Press.\n" , "Anarchism: From Theory to Practice by Daniel Guerin. Monthly Review Press." ) ; assertExtract ( "The <code>$pattern</code>" , "The $pattern" ) ; assertExtract ( "foo <source lang=\"bash\">some source</source> bar" , "foo bar" ) ; } private void assertExtract ( String input , String expected ) { assertEquals ( expected , swebleFilter . filter ( input ) . getPlainText ( ) ) ; } }
package org . languagetool . dev . wikipedia . atom ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . language . English ; import org . languagetool . language . German ; import org . languagetool . tools . Tools ; import java . io . FileInputStream ; import java . io . IOException ; import java . io . InputStream ; import java . sql . SQLException ; import java . text . SimpleDateFormat ; import java . util . Date ; import java . util . List ; import java . util . TimeZone ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class AtomFeedCheckerTest { private static final String DB_URL = "jdbc:derby:atomFeedChecksDB;create=true" ; @ Ignore ( "Interactive use only - for testing the 'recent changes' XML we get from the API" ) @ Test public void testCheckManually ( ) throws IOException { AtomFeedChecker atomFeedChecker = new AtomFeedChecker ( new English ( ) ) ; CheckResult checkResult = atomFeedChecker . checkChanges ( new FileInputStream ( "/home/dnaber/wiki.xml" ) ) ; List < ChangeAnalysis > changeAnalysisList = checkResult . getCheckResults ( ) ; for ( ChangeAnalysis changeAnalysis : changeAnalysisList ) { System . out . println ( changeAnalysis . getTitle ( ) ) ; for ( WikipediaRuleMatch match : changeAnalysis . getRemovedMatches ( ) ) { System . out . println ( " [-] " + match ) ; } for ( WikipediaRuleMatch match : changeAnalysis . getAddedMatches ( ) ) { System . out . println ( " [+] " + match ) ; } System . out . println ( "----------------------" ) ; } } @ Test public void testCheck ( ) throws IOException { AtomFeedChecker atomFeedChecker = new AtomFeedChecker ( new German ( ) ) ; CheckResult checkResult = atomFeedChecker . checkChanges ( getStream ( ) ) ; List < ChangeAnalysis > changeAnalysis = checkResult . getCheckResults ( ) ; assertThat ( changeAnalysis . size ( ) , is ( 3 ) ) ; assertThat ( changeAnalysis . get ( 0 ) . getAddedMatches ( ) . size ( ) , is ( 1 ) ) ; assertThat ( changeAnalysis . get ( 0 ) . getAddedMatches ( ) . get ( 0 ) . getRule ( ) . getId ( ) , is ( "DE_AGREEMENT" ) ) ; assertTrue ( changeAnalysis . get ( 0 ) . getAddedMatches ( ) . get ( 0 ) . getErrorContext ( ) . contains ( "Fehler: <err>der Haus</err>" ) ) ; assertThat ( changeAnalysis . get ( 0 ) . getRemovedMatches ( ) . size ( ) , is ( 0 ) ) ; assertThat ( changeAnalysis . get ( 1 ) . getAddedMatches ( ) . size ( ) , is ( 0 ) ) ; assertThat ( changeAnalysis . get ( 1 ) . getRemovedMatches ( ) . size ( ) , is ( 0 ) ) ; assertThat ( changeAnalysis . get ( 2 ) . getAddedMatches ( ) . size ( ) , is ( 0 ) ) ; assertThat ( changeAnalysis . get ( 2 ) . getRemovedMatches ( ) . size ( ) , is ( 0 ) ) ; CheckResult checkResult2 = atomFeedChecker . checkChanges ( getStream ( ) ) ; List < ChangeAnalysis > changeAnalysis2 = checkResult2 . getCheckResults ( ) ; assertThat ( changeAnalysis2 . size ( ) , is ( 3 ) ) ; } @ Test public void testCheckToDatabase ( ) throws IOException , SQLException { SimpleDateFormat dateFormat = new SimpleDateFormat ( "yyyy-MM-dd HH:mm" ) ; dateFormat . setTimeZone ( TimeZone . getTimeZone ( "Europe/Berlin" ) ) ; initDatabase ( ) ; DatabaseConfig databaseConfig = new DatabaseConfig ( DB_URL , "user" , "pass" ) ; AtomFeedChecker atomFeedChecker1 = new AtomFeedChecker ( new German ( ) , databaseConfig ) ; CheckResult checkResult = atomFeedChecker1 . runCheck ( getStream ( ) ) ; List < ChangeAnalysis > changeAnalysis = checkResult . getCheckResults ( ) ; assertThat ( changeAnalysis . size ( ) , is ( 3 ) ) ; assertThat ( changeAnalysis . get ( 0 ) . getAddedMatches ( ) . size ( ) , is ( 1 ) ) ; assertThat ( changeAnalysis . get ( 0 ) . getAddedMatches ( ) . get ( 0 ) . getRule ( ) . getId ( ) , is ( "DE_AGREEMENT" ) ) ; assertTrue ( changeAnalysis . get ( 0 ) . getAddedMatches ( ) . get ( 0 ) . getErrorContext ( ) . contains ( "Fehler: <err>der Haus</err>" ) ) ; assertThat ( changeAnalysis . get ( 0 ) . getRemovedMatches ( ) . size ( ) , is ( 0 ) ) ; assertThat ( changeAnalysis . get ( 1 ) . getAddedMatches ( ) . size ( ) , is ( 0 ) ) ; assertThat ( changeAnalysis . get ( 1 ) . getRemovedMatches ( ) . size ( ) , is ( 0 ) ) ; assertThat ( changeAnalysis . get ( 2 ) . getAddedMatches ( ) . size ( ) , is ( 0 ) ) ; assertThat ( changeAnalysis . get ( 2 ) . getRemovedMatches ( ) . size ( ) , is ( 0 ) ) ; Date latestCheckDate1 = atomFeedChecker1 . getDatabase ( ) . getCheckDates ( ) . get ( "de" ) ; assertThat ( dateFormat . format ( latestCheckDate1 ) , is ( "2013-12-03 10:48" ) ) ; AtomFeedChecker atomFeedChecker2 = new AtomFeedChecker ( new German ( ) , databaseConfig ) ; CheckResult checkResult2 = atomFeedChecker2 . runCheck ( getStream ( ) ) ; List < ChangeAnalysis > changeAnalysis2 = checkResult2 . getCheckResults ( ) ; assertThat ( changeAnalysis2 . size ( ) , is ( 0 ) ) ; assertThat ( atomFeedChecker2 . getDatabase ( ) . getCheckDates ( ) . size ( ) , is ( 1 ) ) ; Date latestCheckDate2 = atomFeedChecker2 . getDatabase ( ) . getCheckDates ( ) . get ( "de" ) ; assertThat ( dateFormat . format ( latestCheckDate2 ) , is ( "2013-12-03 10:48" ) ) ; } private void initDatabase ( ) throws SQLException { MatchDatabase database = new MatchDatabase ( DB_URL , "user" , "pass" ) ; database . dropTables ( ) ; database . createTables ( ) ; } private InputStream getStream ( ) throws IOException { return Tools . getStream ( "/org/languagetool/dev/wikipedia/atom/feed1.xml" ) ; } }
package org . languagetool . dev . wikipedia . atom ; import org . languagetool . AnalyzedSentence ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; class FakeRule extends Rule { private final int id ; FakeRule ( int id ) { this . id = id ; } @ Override public String getId ( ) { return "ID_" + id ; } @ Override public String getDescription ( ) { return "A fake rule" ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { throw new RuntimeException ( "not implemented" ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . sk ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; public final class CompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/sk/compounds.txt" ) ; public CompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "Toto slovo sa zvyčajne píše so spojovníkom." , "Toto slovo sa obvykle píše bez spojovníka." , "Tento výraz sa bežne píše s alebo bez spojovníka." , "Problém spájania slov" ) ; } @ Override public String getId ( ) { return "SK_COMPOUNDS" ; } @ Override public String getDescription ( ) { return "Slová so spojovníkom napr. použite „česko-slovenský” namiesto „česko slovenský”" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . dev . wikipedia . atom ; import org . junit . Test ; import org . languagetool . tools . StringTools ; import org . languagetool . tools . Tools ; import java . io . IOException ; import java . io . InputStream ; import java . util . Date ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class AtomFeedItemTest { @ Test public void testModifiedContent ( ) throws IOException { AtomFeedItem item = getSummary ( "summary1.txt" ) ; assertThat ( item . getOldContent ( ) . size ( ) , is ( 1 ) ) ; assertThat ( item . getOldContent ( ) . get ( 0 ) , is ( "}}added" ) ) ; assertThat ( item . getNewContent ( ) . size ( ) , is ( 1 ) ) ; assertThat ( item . getNewContent ( ) . get ( 0 ) , is ( "}}" ) ) ; } @ Test public void testAddedParagraphs ( ) throws IOException { AtomFeedItem item = getSummary ( "summary2.txt" ) ; assertThat ( item . getOldContent ( ) . size ( ) , is ( 0 ) ) ; assertThat ( item . getNewContent ( ) . size ( ) , is ( 3 ) ) ; assertThat ( item . getNewContent ( ) . get ( 0 ) , is ( "* [http://www.rp-online.de/nrw/staedte/]" ) ) ; assertThat ( item . getNewContent ( ) . get ( 1 ) , is ( "* [http://www.vmtubes.com]" ) ) ; assertThat ( item . getNewContent ( ) . get ( 2 ) , is ( "" ) ) ; } @ Test public void testDeletedParagraphs ( ) throws IOException { AtomFeedItem item = getSummary ( "summary3.txt" ) ; assertThat ( item . getOldContent ( ) . size ( ) , is ( 3 ) ) ; assertThat ( item . getOldContent ( ) . get ( 0 ) , is ( "* [http://www.rp-online.de/nrw/staedte/]" ) ) ; assertThat ( item . getOldContent ( ) . get ( 1 ) , is ( "* [http://www.vmtubes.com]" ) ) ; assertThat ( item . getOldContent ( ) . get ( 2 ) , is ( "" ) ) ; assertThat ( item . getNewContent ( ) . size ( ) , is ( 0 ) ) ; } @ Test public void testAddedTableLine ( ) throws IOException { AtomFeedItem item = getSummary ( "summary-table.txt" ) ; assertThat ( item . getOldContent ( ) . size ( ) , is ( 0 ) ) ; assertThat ( item . getNewContent ( ) . size ( ) , is ( 1 ) ) ; assertThat ( item . getNewContent ( ) . get ( 0 ) , is ( "Besetzung" ) ) ; } private AtomFeedItem getSummary ( String filename ) throws IOException { InputStream stream = Tools . getStream ( "/org/languagetool/dev/wikipedia/atom/" + filename ) ; return new AtomFeedItem ( "fakeId" , "fakeTitle" , StringTools . streamToString ( stream , "UTF-8" ) , new Date ( 100000 ) ) ; } }
package org . languagetool . dev . wikipedia . atom ; import org . junit . Test ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . RuleMatch ; import java . util . ArrayList ; import java . util . Date ; import java . util . List ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class ChangeAnalysisTest { private static final Language LANGUAGE = Languages . getLanguageForShortName ( "de" ) ; @ Test public void testAdd ( ) { List < WikipediaRuleMatch > oldMatches = makeMatches ( 1 , 2 ) ; List < WikipediaRuleMatch > newMatches = makeMatches ( 1 , 2 , 3 ) ; ChangeAnalysis analysis = new ChangeAnalysis ( "fakeTitle" , 123L , oldMatches , newMatches ) ; assertThat ( analysis . getAddedMatches ( ) . size ( ) , is ( 1 ) ) ; assertThat ( analysis . getAddedMatches ( ) . get ( 0 ) . getRule ( ) . getId ( ) , is ( "ID_3" ) ) ; assertThat ( analysis . getRemovedMatches ( ) . size ( ) , is ( 0 ) ) ; } @ Test public void testRemove ( ) { List < WikipediaRuleMatch > oldMatches = makeMatches ( 1 , 2 , 3 ) ; List < WikipediaRuleMatch > newMatches = makeMatches ( 1 , 2 ) ; ChangeAnalysis analysis = new ChangeAnalysis ( "fakeTitle" , 123L , oldMatches , newMatches ) ; assertThat ( analysis . getAddedMatches ( ) . size ( ) , is ( 0 ) ) ; assertThat ( analysis . getRemovedMatches ( ) . size ( ) , is ( 1 ) ) ; assertThat ( analysis . getRemovedMatches ( ) . get ( 0 ) . getRule ( ) . getId ( ) , is ( "ID_3" ) ) ; } @ Test public void testMove ( ) { List < WikipediaRuleMatch > oldMatches = makeMatches ( 1 , 2 , 3 ) ; List < WikipediaRuleMatch > newMatches = makeMatches ( 1 , 3 , 2 ) ; ChangeAnalysis analysis = new ChangeAnalysis ( "fakeTitle" , 123L , oldMatches , newMatches ) ; assertThat ( analysis . getAddedMatches ( ) . size ( ) , is ( 1 ) ) ; assertThat ( analysis . getAddedMatches ( ) . get ( 0 ) . getRule ( ) . getId ( ) , is ( "ID_2" ) ) ; assertThat ( analysis . getRemovedMatches ( ) . size ( ) , is ( 1 ) ) ; assertThat ( analysis . getRemovedMatches ( ) . get ( 0 ) . getRule ( ) . getId ( ) , is ( "ID_2" ) ) ; } private List < WikipediaRuleMatch > makeMatches ( int ... ids ) { List < WikipediaRuleMatch > matches = new ArrayList < > ( ) ; for ( int id : ids ) { RuleMatch ruleMatch = new RuleMatch ( new FakeRule ( id ) , 10 , 20 , "error1" ) ; AtomFeedItem feedItem = new AtomFeedItem ( "id1" , "title1" , "summary1" , new Date ( 10000 ) ) ; matches . add ( new WikipediaRuleMatch ( LANGUAGE , ruleMatch , "error context" , feedItem ) ) ; } return matches ; } }
package org . languagetool . dev . wikipedia . atom ; import org . junit . Test ; import org . languagetool . tools . Tools ; import javax . xml . stream . XMLStreamException ; import java . io . IOException ; import java . util . List ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class AtomFeedParserTest { @ Test public void testParsing ( ) throws IOException , XMLStreamException { AtomFeedParser atomFeedParser = new AtomFeedParser ( ) ; List < AtomFeedItem > items = atomFeedParser . getAtomFeedItems ( Tools . getStream ( "/org/languagetool/dev/wikipedia/atom/feed1.xml" ) ) ; assertThat ( items . size ( ) , is ( 3 ) ) ; AtomFeedItem item1 = items . get ( 0 ) ; assertThat ( item1 . getId ( ) , is ( "//de.wikipedia.org/w/index.php?title=Peter_Bichsel&diff=125079808&oldid=125079797" ) ) ; assertThat ( item1 . getTitle ( ) , is ( "Peter Bichsel" ) ) ; assertThat ( item1 . getDiffId ( ) , is ( 125079808L ) ) ; assertThat ( item1 . getOldContent ( ) . toString ( ) , is ( "[}}llllllllll]" ) ) ; assertThat ( item1 . getNewContent ( ) . toString ( ) , is ( "[}}]" ) ) ; AtomFeedItem item2 = items . get ( 1 ) ; assertThat ( item2 . getId ( ) , is ( "//de.wikipedia.org/wiki/Timo_b%C3%A4cker" ) ) ; assertThat ( item2 . getTitle ( ) , is ( "Timo bäcker" ) ) ; assertThat ( item2 . getDiffId ( ) , is ( 0L ) ) ; assertThat ( item2 . getOldContent ( ) . toString ( ) , is ( "[]" ) ) ; assertThat ( item2 . getNewContent ( ) . toString ( ) , is ( "[]" ) ) ; AtomFeedItem item3 = items . get ( 2 ) ; assertThat ( item3 . getId ( ) , is ( "//de.wikipedia.org/w/index.php?title=Vallourec_Deutschland_GmbH&diff=125079807&oldid=124992032" ) ) ; assertThat ( item3 . getTitle ( ) , is ( "Vallourec Deutschland GmbH" ) ) ; assertThat ( item3 . getDiffId ( ) , is ( 125079807L ) ) ; assertThat ( item3 . getOldContent ( ) . toString ( ) , is ( "[]" ) ) ; assertThat ( item3 . getNewContent ( ) . toString ( ) , is ( "[* [http://www.rp-online.de/nrw/staedte/] Fehler: der Haus, * [http://www.vmtubes.com], ]" ) ) ; } }
package org . languagetool . dev . wikipedia . atom ; import org . junit . Test ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . Category ; import org . languagetool . rules . RuleMatch ; import java . sql . SQLException ; import java . util . Date ; import static junit . framework . Assert . assertNull ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class MatchDatabaseTest { @ Test public void test ( ) throws SQLException , ClassNotFoundException { Language language = Languages . getLanguageForShortName ( "de" ) ; MatchDatabase database = new MatchDatabase ( "jdbc:derby:atomFeedChecksDB;create=true" , "user" , "pass" ) ; database . dropTables ( ) ; database . createTables ( ) ; assertThat ( database . getLatestDate ( language ) , is ( new Date ( 0 ) ) ) ; assertThat ( database . list ( ) . size ( ) , is ( 0 ) ) ; assertThat ( database . getCheckDates ( ) . size ( ) , is ( 0 ) ) ; FakeRule rule1 = new FakeRule ( 1 ) ; rule1 . setCategory ( new Category ( "My Category" ) ) ; RuleMatch ruleMatch = new RuleMatch ( rule1 , 5 , 10 , "my message" ) ; AtomFeedItem feedItem1 = new AtomFeedItem ( "//id1?diff=123" , "title" , "summary1" , new Date ( 10000 ) ) ; WikipediaRuleMatch wikiRuleMatch1 = new WikipediaRuleMatch ( language , ruleMatch , "my context" , feedItem1 ) ; database . add ( wikiRuleMatch1 ) ; assertThat ( database . list ( ) . size ( ) , is ( 1 ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getRuleId ( ) , is ( "ID_1" ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getRuleDescription ( ) , is ( "A fake rule" ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getRuleMessage ( ) , is ( "my message" ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getTitle ( ) , is ( "title" ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getErrorContext ( ) , is ( "my context" ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getDiffId ( ) , is ( 123L ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getFixDiffId ( ) , is ( 0L ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getEditDate ( ) , is ( new Date ( 10000 ) ) ) ; assertThat ( database . getLatestDate ( language ) , is ( new Date ( 0 ) ) ) ; assertNull ( database . list ( ) . get ( 0 ) . getRuleSubId ( ) ) ; assertNull ( database . list ( ) . get ( 0 ) . getFixDate ( ) ) ; assertThat ( database . getCheckDates ( ) . size ( ) , is ( 0 ) ) ; RuleMatch ruleMatch2 = new RuleMatch ( new FakeRule ( 1 ) , 9 , 11 , "my message" ) ; AtomFeedItem feedItem2 = new AtomFeedItem ( "//id2?diff=124" , "title" , "summary2" , new Date ( 9000000000L ) ) ; WikipediaRuleMatch wikiRuleMatch2 = new WikipediaRuleMatch ( language , ruleMatch2 , "my context" , feedItem2 ) ; int affected = database . markedFixed ( wikiRuleMatch2 ) ; assertThat ( affected , is ( 1 ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getFixDate ( ) , is ( new Date ( 9000000000L ) ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getDiffId ( ) , is ( 123L ) ) ; assertThat ( database . list ( ) . get ( 0 ) . getFixDiffId ( ) , is ( 124L ) ) ; assertThat ( database . getLatestDate ( language ) , is ( new Date ( 0 ) ) ) ; assertThat ( database . getCheckDates ( ) . size ( ) , is ( 0 ) ) ; } }
package org . languagetool . dev . dumpcheck ; import org . languagetool . Language ; import org . languagetool . Languages ; import java . io . FileInputStream ; import java . io . IOException ; class WikipediaSentenceExtractor { private void extract ( Language language , String xmlDumpPath ) throws IOException { try ( FileInputStream fis = new FileInputStream ( xmlDumpPath ) ) { int sentenceCount = 0 ; WikipediaSentenceSource source = new WikipediaSentenceSource ( fis , language ) ; while ( source . hasNext ( ) ) { String sentence = source . next ( ) . getText ( ) ; if ( skipSentence ( sentence ) ) { continue ; } System . out . println ( sentence ) ; sentenceCount ++ ; if ( sentenceCount % 1000 == 0 ) { System . err . println ( "Exporting sentence #" + sentenceCount + "..." ) ; } } } } private boolean skipSentence ( String sentence ) { return sentence . trim ( ) . length ( ) == 0 || Character . isLowerCase ( sentence . trim ( ) . charAt ( 0 ) ) ; } private static void checkUsageOrExit ( String [ ] args ) { if ( args . length != 2 ) { System . out . println ( "Usage: " + WikipediaSentenceExtractor . class . getSimpleName ( ) + " <langCode> <wikipediaXmlDump>" ) ; System . exit ( 1 ) ; } } public static void main ( String [ ] args ) throws IOException { checkUsageOrExit ( args ) ; WikipediaSentenceExtractor extractor = new WikipediaSentenceExtractor ( ) ; extractor . extract ( Languages . getLanguageForShortName ( args [ 0 ] ) , args [ 1 ] ) ; } }
package org . languagetool . dev . dumpcheck ; import org . languagetool . Language ; import java . io . InputStream ; import java . util . * ; import java . util . regex . Pattern ; class TatoebaSentenceSource extends SentenceSource { private final List < String > sentences ; private final Scanner scanner ; private int articleCount = 0 ; TatoebaSentenceSource ( InputStream textInput , Language language ) { this ( textInput , language , null ) ; } TatoebaSentenceSource ( InputStream textInput , Language language , Pattern filter ) { super ( language , filter ) ; scanner = new Scanner ( textInput ) ; sentences = new ArrayList < > ( ) ; } @ Override public boolean hasNext ( ) { fillSentences ( ) ; return sentences . size ( ) > 0 ; } @ Override public Sentence next ( ) { fillSentences ( ) ; if ( sentences . size ( ) == 0 ) { throw new NoSuchElementException ( ) ; } return new Sentence ( sentences . remove ( 0 ) , getSource ( ) , "<Tatoeba>" , "http://tatoeba.org" , ++ articleCount ) ; } @ Override public String getSource ( ) { return "tatoeba" ; } private void fillSentences ( ) { while ( sentences . size ( ) == 0 && scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; if ( line . isEmpty ( ) ) { continue ; } String [ ] parts = line . split ( "\t" ) ; if ( parts . length != 3 ) { throw new RuntimeException ( "Unexpected line format: expected three tab-separated columns: '" + line + "'" ) ; } String sentence = parts [ 2 ] ; if ( acceptSentence ( sentence ) ) { sentences . add ( sentence ) ; } } } }
package org . languagetool . dev . dumpcheck ; import org . apache . commons . lang . StringUtils ; import org . languagetool . Language ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . tools . ContextTools ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . sql . * ; import java . util . Date ; import java . util . List ; import java . util . Properties ; class DatabaseHandler extends ResultHandler { private static final int MAX_CONTEXT_LENGTH = 500 ; private static final int SMALL_CONTEXT_LENGTH = 40 ; private final Connection conn ; private final ContextTools contextTools ; private final ContextTools smallContextTools ; private final PreparedStatement insertSt ; private final int batchSize ; private int batchCount = 0 ; DatabaseHandler ( File propertiesFile , int maxSentences , int maxErrors ) { super ( maxSentences , maxErrors ) ; final String insertSql = "INSERT INTO corpus_match " + "(version, language_code, ruleid, rule_category, rule_subid, rule_description, message, error_context, small_error_context, corpus_date, " + "check_date, sourceuri, source_type, is_visible) " + "VALUES (0, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 1)" ; final Properties dbProperties = new Properties ( ) ; try ( FileInputStream inStream = new FileInputStream ( propertiesFile ) ) { dbProperties . load ( inStream ) ; final String dbUrl = getProperty ( dbProperties , "dbUrl" ) ; final String dbUser = getProperty ( dbProperties , "dbUser" ) ; final String dbPassword = getProperty ( dbProperties , "dbPassword" ) ; batchSize = Integer . decode ( dbProperties . getProperty ( "batchSize" , "1" ) ) ; conn = DriverManager . getConnection ( dbUrl , dbUser , dbPassword ) ; insertSt = conn . prepareStatement ( insertSql ) ; } catch ( SQLException | IOException e ) { throw new RuntimeException ( e ) ; } contextTools = new ContextTools ( ) ; contextTools . setContextSize ( MAX_CONTEXT_LENGTH ) ; contextTools . setErrorMarkerStart ( MARKER_START ) ; contextTools . setErrorMarkerEnd ( MARKER_END ) ; contextTools . setEscapeHtml ( false ) ; smallContextTools = new ContextTools ( ) ; smallContextTools . setContextSize ( SMALL_CONTEXT_LENGTH ) ; smallContextTools . setErrorMarkerStart ( MARKER_START ) ; smallContextTools . setErrorMarkerEnd ( MARKER_END ) ; smallContextTools . setEscapeHtml ( false ) ; } private String getProperty ( Properties prop , String key ) { final String value = prop . getProperty ( key ) ; if ( value == null ) { throw new RuntimeException ( "Required key '" + key + "' not found in properties" ) ; } return value ; } @ Override protected void handleResult ( Sentence sentence , List < RuleMatch > ruleMatches , Language language ) { try { final java . sql . Date nowDate = new java . sql . Date ( new Date ( ) . getTime ( ) ) ; for ( RuleMatch match : ruleMatches ) { final String smallContext = smallContextTools . getContext ( match . getFromPos ( ) , match . getToPos ( ) , sentence . getText ( ) ) ; insertSt . setString ( 1 , language . getShortName ( ) ) ; final Rule rule = match . getRule ( ) ; insertSt . setString ( 2 , rule . getId ( ) ) ; insertSt . setString ( 3 , rule . getCategory ( ) . getName ( ) ) ; if ( rule instanceof PatternRule ) { final PatternRule patternRule = ( PatternRule ) rule ; insertSt . setString ( 4 , patternRule . getSubId ( ) ) ; } else { insertSt . setNull ( 4 , Types . VARCHAR ) ; } insertSt . setString ( 5 , rule . getDescription ( ) ) ; insertSt . setString ( 6 , StringUtils . abbreviate ( match . getMessage ( ) , 255 ) ) ; final String context = contextTools . getContext ( match . getFromPos ( ) , match . getToPos ( ) , sentence . getText ( ) ) ; if ( context . length ( ) > MAX_CONTEXT_LENGTH ) { continue ; } insertSt . setString ( 7 , context ) ; insertSt . setString ( 8 , StringUtils . abbreviate ( smallContext , 255 ) ) ; insertSt . setDate ( 9 , nowDate ) ; insertSt . setDate ( 10 , nowDate ) ; insertSt . setString ( 11 , sentence . getUrl ( ) ) ; insertSt . setString ( 12 , sentence . getSource ( ) ) ; insertSt . addBatch ( ) ; if ( ++ batchCount >= batchSize ) { executeBatch ( ) ; batchCount = 0 ; } checkMaxErrors ( ++ errorCount ) ; if ( errorCount % 100 == 0 ) { System . out . println ( "Storing error #" + errorCount + " for text:" ) ; System . out . println ( " " + sentence . getText ( ) ) ; } } checkMaxSentences ( ++ sentenceCount ) ; } catch ( DocumentLimitReachedException | ErrorLimitReachedException e ) { throw e ; } catch ( Exception e ) { throw new RuntimeException ( "Error storing matches for '" + sentence . getTitle ( ) + "'" , e ) ; } } private void executeBatch ( ) throws SQLException { boolean autoCommit = conn . getAutoCommit ( ) ; conn . setAutoCommit ( false ) ; try { insertSt . executeBatch ( ) ; if ( autoCommit ) { conn . commit ( ) ; } } finally { conn . setAutoCommit ( autoCommit ) ; } } @ Override public void close ( ) throws Exception { if ( insertSt != null ) { if ( batchCount > 0 ) { executeBatch ( ) ; } insertSt . close ( ) ; } if ( conn != null ) { conn . close ( ) ; } } }
package org . languagetool . dev . dumpcheck ; import org . apache . commons . cli . * ; import org . apache . commons . lang . StringUtils ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . MultiThreadedJLanguageTool ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . text . NumberFormat ; import java . util . * ; import java . util . regex . Pattern ; public class SentenceSourceChecker { private SentenceSourceChecker ( ) { } public static void main ( String [ ] args ) throws IOException { final SentenceSourceChecker prg = new SentenceSourceChecker ( ) ; final CommandLine commandLine = ensureCorrectUsageOrExit ( args ) ; File propFile = null ; if ( commandLine . hasOption ( 'd' ) ) { propFile = new File ( commandLine . getOptionValue ( 'd' ) ) ; if ( ! propFile . exists ( ) || propFile . isDirectory ( ) ) { throw new IOException ( "File not found or isn't a file: " + propFile . getAbsolutePath ( ) ) ; } } final String languageCode = commandLine . getOptionValue ( 'l' ) ; final Set < String > disabledRuleIds = new HashSet < > ( ) ; if ( commandLine . hasOption ( "rule-properties" ) ) { final File disabledRulesPropFile = new File ( commandLine . getOptionValue ( "rule-properties" ) ) ; if ( ! disabledRulesPropFile . exists ( ) || disabledRulesPropFile . isDirectory ( ) ) { throw new IOException ( "File not found or isn't a file: " + disabledRulesPropFile . getAbsolutePath ( ) ) ; } final Properties disabledRules = new Properties ( ) ; try ( FileInputStream stream = new FileInputStream ( disabledRulesPropFile ) ) { disabledRules . load ( stream ) ; addDisabledRules ( "all" , disabledRuleIds , disabledRules ) ; addDisabledRules ( languageCode , disabledRuleIds , disabledRules ) ; } } final int maxArticles = Integer . parseInt ( commandLine . getOptionValue ( "max-sentences" , "0" ) ) ; final int maxErrors = Integer . parseInt ( commandLine . getOptionValue ( "max-errors" , "0" ) ) ; String [ ] ruleIds = commandLine . hasOption ( 'r' ) ? commandLine . getOptionValue ( 'r' ) . split ( "," ) : null ; String [ ] categoryIds = commandLine . hasOption ( "also-enable-categories" ) ? commandLine . getOptionValue ( "also-enable-categories" ) . split ( "," ) : null ; String [ ] fileNames = commandLine . getOptionValues ( 'f' ) ; File languageModelDir = commandLine . hasOption ( "languagemodel" ) ? new File ( commandLine . getOptionValue ( "languagemodel" ) ) : null ; Pattern filter = commandLine . hasOption ( "filter" ) ? Pattern . compile ( commandLine . getOptionValue ( "filter" ) ) : null ; prg . run ( propFile , disabledRuleIds , languageCode , Arrays . asList ( fileNames ) , ruleIds , categoryIds , maxArticles , maxErrors , languageModelDir , filter ) ; } private static void addDisabledRules ( String languageCode , Set < String > disabledRuleIds , Properties disabledRules ) { final String disabledRulesString = disabledRules . getProperty ( languageCode ) ; if ( disabledRulesString != null ) { final String [ ] ids = disabledRulesString . split ( "," ) ; disabledRuleIds . addAll ( Arrays . asList ( ids ) ) ; } } @ SuppressWarnings ( "AccessStaticViaInstance" ) private static CommandLine ensureCorrectUsageOrExit ( String [ ] args ) { Options options = new Options ( ) ; options . addOption ( OptionBuilder . withLongOpt ( "language" ) . withArgName ( "code" ) . hasArg ( ) . withDescription ( "language code like 'en' or 'de'" ) . isRequired ( ) . create ( "l" ) ) ; options . addOption ( OptionBuilder . withLongOpt ( "db-properties" ) . withArgName ( "file" ) . hasArg ( ) . withDescription ( "A file to set database access properties. If not set, the output will be written to STDOUT. " + "The file needs to set the properties dbUrl ('jdbc:...'), dbUser, and dbPassword. " + "It can optionally define the batchSize for insert statements, which defaults to 1." ) . create ( "d" ) ) ; options . addOption ( OptionBuilder . withLongOpt ( "rule-properties" ) . withArgName ( "file" ) . hasArg ( ) . withDescription ( "A file to set rules which should be disabled per language (e.g. en=RULE1,RULE2 or all=RULE3,RULE4)" ) . create ( ) ) ; options . addOption ( OptionBuilder . withLongOpt ( "rule-ids" ) . withArgName ( "id" ) . hasArg ( ) . withDescription ( "comma-separated list of rule-ids to activate" ) . create ( "r" ) ) ; options . addOption ( OptionBuilder . withLongOpt ( "also-enable-categories" ) . withArgName ( "categories" ) . hasArg ( ) . withDescription ( "comma-separated list of categories to activate, additionally to rules activated anyway" ) . create ( ) ) ; options . addOption ( OptionBuilder . withLongOpt ( "file" ) . withArgName ( "file" ) . hasArg ( ) . withDescription ( "an unpacked Wikipedia XML dump; (must be named *.xml, dumps are available from http://dumps.wikimedia.org/backup-index.html) " + "or a Tatoeba CSV file filtered to contain only one language (must be named tatoeba-*). You can specify this option more than once." ) . isRequired ( ) . create ( "f" ) ) ; options . addOption ( OptionBuilder . withLongOpt ( "max-sentences" ) . withArgName ( "number" ) . hasArg ( ) . withDescription ( "maximum number of sentences to check" ) . create ( ) ) ; options . addOption ( OptionBuilder . withLongOpt ( "max-errors" ) . withArgName ( "number" ) . hasArg ( ) . withDescription ( "maximum number of errors, stop when finding more" ) . create ( ) ) ; options . addOption ( OptionBuilder . withLongOpt ( "languagemodel" ) . withArgName ( "indexDir" ) . hasArg ( ) . withDescription ( "directory with a '3grams' sub directory that contains an ngram index" ) . create ( ) ) ; options . addOption ( OptionBuilder . withLongOpt ( "filter" ) . withArgName ( "regex" ) . hasArg ( ) . withDescription ( "Consider only sentences that contain this regular expression (for speed up)" ) . create ( ) ) ; try { CommandLineParser parser = new GnuParser ( ) ; return parser . parse ( options , args ) ; } catch ( ParseException e ) { System . err . println ( "Error: " + e . getMessage ( ) ) ; HelpFormatter formatter = new HelpFormatter ( ) ; formatter . setWidth ( 80 ) ; formatter . setSyntaxPrefix ( "Usage: " ) ; formatter . printHelp ( SentenceSourceChecker . class . getSimpleName ( ) + " [OPTION]... --file <file> --language <code>" , options ) ; System . exit ( 1 ) ; } throw new IllegalStateException ( ) ; } private void run ( File propFile , Set < String > disabledRules , String langCode , List < String > fileNames , String [ ] ruleIds , String [ ] additionalCategoryIds , int maxSentences , int maxErrors , File languageModelDir , Pattern filter ) throws IOException { final Language lang = Languages . getLanguageForShortName ( langCode ) ; final MultiThreadedJLanguageTool languageTool = new MultiThreadedJLanguageTool ( lang ) ; if ( languageModelDir != null ) { languageTool . activateLanguageModelRules ( languageModelDir ) ; } if ( ruleIds != null ) { enableOnlySpecifiedRules ( ruleIds , languageTool ) ; } else { applyRuleDeactivation ( languageTool , disabledRules ) ; } if ( filter != null ) { System . out . println ( "*** NOTE: only sentences that match regular expression '" + filter + "' will be checked" ) ; } activateAdditionalCategories ( additionalCategoryIds , languageTool ) ; disableSpellingRules ( languageTool ) ; System . out . println ( "Working on: " + StringUtils . join ( fileNames , ", " ) ) ; System . out . println ( "Sentence limit: " + ( maxSentences > 0 ? maxSentences : "no limit" ) ) ; System . out . println ( "Error limit: " + ( maxErrors > 0 ? maxErrors : "no limit" ) ) ; ResultHandler resultHandler = null ; int ruleMatchCount = 0 ; int sentenceCount = 0 ; try { if ( propFile != null ) { resultHandler = new DatabaseHandler ( propFile , maxSentences , maxErrors ) ; } else { resultHandler = new StdoutHandler ( maxSentences , maxErrors ) ; } MixingSentenceSource mixingSource = MixingSentenceSource . create ( fileNames , lang , filter ) ; while ( mixingSource . hasNext ( ) ) { Sentence sentence = mixingSource . next ( ) ; try { List < RuleMatch > matches = languageTool . check ( sentence . getText ( ) ) ; resultHandler . handleResult ( sentence , matches , lang ) ; sentenceCount ++ ; if ( sentenceCount % 5000 == 0 ) { System . err . printf ( "%s sentences checked...\n" , NumberFormat . getNumberInstance ( Locale . US ) . format ( sentenceCount ) ) ; } ruleMatchCount += matches . size ( ) ; } catch ( DocumentLimitReachedException | ErrorLimitReachedException e ) { throw e ; } catch ( Exception e ) { throw new RuntimeException ( "Check failed on sentence: " + StringUtils . abbreviate ( sentence . getText ( ) , 250 ) , e ) ; } } } catch ( DocumentLimitReachedException | ErrorLimitReachedException e ) { System . out . println ( getClass ( ) . getSimpleName ( ) + ": " + e ) ; } finally { languageTool . shutdown ( ) ; if ( resultHandler != null ) { final float matchesPerSentence = ( float ) ruleMatchCount / sentenceCount ; System . out . printf ( lang + ": %d total matches\n" , ruleMatchCount ) ; System . out . printf ( lang + ": ø%.2f rule matches per sentence\n" , matchesPerSentence ) ; try { resultHandler . close ( ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; } } } } private void enableOnlySpecifiedRules ( String [ ] ruleIds , JLanguageTool languageTool ) { for ( Rule rule : languageTool . getAllRules ( ) ) { languageTool . disableRule ( rule . getId ( ) ) ; } for ( String ruleId : ruleIds ) { languageTool . enableRule ( ruleId ) ; } for ( Rule rule : languageTool . getAllRules ( ) ) { if ( rule . isDefaultOff ( ) ) { languageTool . enableDefaultOffRule ( rule . getId ( ) ) ; } } warnOnNonExistingRuleIds ( ruleIds , languageTool ) ; System . out . println ( "Only these rules are enabled: " + Arrays . toString ( ruleIds ) ) ; } private void warnOnNonExistingRuleIds ( String [ ] ruleIds , JLanguageTool languageTool ) { for ( String ruleId : ruleIds ) { boolean found = false ; for ( Rule rule : languageTool . getAllRules ( ) ) { if ( rule . getId ( ) . equals ( ruleId ) ) { found = true ; break ; } } if ( ! found ) { System . out . println ( "WARNING: Could not find rule '" + ruleId + "'" ) ; } } } private void applyRuleDeactivation ( JLanguageTool languageTool , Set < String > disabledRules ) { for ( String disabledRuleId : disabledRules ) { languageTool . disableRule ( disabledRuleId ) ; } System . out . println ( "These rules are disabled: " + languageTool . getDisabledRules ( ) ) ; } private void activateAdditionalCategories ( String [ ] additionalCategoryIds , JLanguageTool languageTool ) { if ( additionalCategoryIds != null ) { for ( String categoryId : additionalCategoryIds ) { for ( Rule rule : languageTool . getAllRules ( ) ) { if ( rule . getCategory ( ) . getName ( ) . equals ( categoryId ) ) { System . out . println ( "Activating " + rule . getId ( ) + " in category " + categoryId ) ; languageTool . enableDefaultOffRule ( rule . getId ( ) ) ; } } } } } private void disableSpellingRules ( JLanguageTool languageTool ) { final List < Rule > allActiveRules = languageTool . getAllActiveRules ( ) ; for ( Rule rule : allActiveRules ) { if ( rule . isDictionaryBasedSpellingRule ( ) ) { languageTool . disableRule ( rule . getId ( ) ) ; } } System . out . println ( "All spelling rules are disabled" ) ; } }
package org . languagetool . dev . dumpcheck ; public class ErrorLimitReachedException extends RuntimeException { private final int limit ; public ErrorLimitReachedException ( int limit ) { this . limit = limit ; } @ Override public String getMessage ( ) { return "Maximum number of errors (" + limit + ") reached" ; } }
package org . languagetool . dev . dumpcheck ; import org . languagetool . Language ; import org . languagetool . tokenizers . Tokenizer ; import java . util . Iterator ; import java . util . List ; import java . util . regex . Pattern ; public abstract class SentenceSource implements Iterator < Sentence > { private static final int MIN_SENTENCE_SIZE = 10 ; private static final int MIN_SENTENCE_TOKEN_COUNT = 4 ; private static final int MAX_SENTENCE_LENGTH = 300 ; private final Tokenizer wordTokenizer ; private final Pattern acceptPattern ; SentenceSource ( Language language ) { this ( language , null ) ; } SentenceSource ( Language language , Pattern acceptPattern ) { wordTokenizer = language . getWordTokenizer ( ) ; this . acceptPattern = acceptPattern ; } @ Override public abstract boolean hasNext ( ) ; @ Override public abstract Sentence next ( ) ; public abstract String getSource ( ) ; @ Override public void remove ( ) { throw new UnsupportedOperationException ( "remove not supported" ) ; } @ Override public String toString ( ) { return getSource ( ) + "-" + super . toString ( ) ; } protected boolean acceptSentence ( String sentence ) { if ( acceptPattern != null ) { if ( ! acceptPattern . matcher ( sentence ) . find ( ) ) { return false ; } } String trimSentence = sentence . trim ( ) ; return trimSentence . length ( ) >= MIN_SENTENCE_SIZE && trimSentence . length ( ) <= MAX_SENTENCE_LENGTH && countTokens ( trimSentence ) >= MIN_SENTENCE_TOKEN_COUNT ; } private int countTokens ( String sentence ) { int realTokens = 0 ; List < String > allTokens = wordTokenizer . tokenize ( sentence ) ; for ( String token : allTokens ) { if ( ! token . trim ( ) . isEmpty ( ) ) { realTokens ++ ; } } return realTokens ; } }
package org . languagetool . rules . sk ; import org . languagetool . rules . Rule ; public abstract class SlovakRule extends Rule { }
package org . languagetool . dev . dumpcheck ; import org . languagetool . Language ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . tools . ContextTools ; import org . languagetool . tools . StringTools ; import java . util . List ; class StdoutHandler extends ResultHandler { private final ContextTools contextTools = new ContextTools ( ) ; StdoutHandler ( int maxSentences , int maxErrors ) { super ( maxSentences , maxErrors ) ; contextTools . setContextSize ( CONTEXT_SIZE ) ; } @ Override protected void handleResult ( Sentence sentence , List < RuleMatch > ruleMatches , Language language ) { if ( ruleMatches . size ( ) > 0 ) { int i = 1 ; System . out . println ( "\nTitle: " + sentence . getTitle ( ) ) ; for ( RuleMatch match : ruleMatches ) { String output = i + ".) Line " + ( match . getLine ( ) + 1 ) + ", column " + match . getColumn ( ) + ", Rule ID: " + match . getRule ( ) . getId ( ) ; if ( match . getRule ( ) instanceof PatternRule ) { final PatternRule pRule = ( PatternRule ) match . getRule ( ) ; output += "[" + pRule . getSubId ( ) + "]" ; } System . out . println ( output ) ; String msg = match . getMessage ( ) ; msg = msg . replaceAll ( "<suggestion>" , "'" ) ; msg = msg . replaceAll ( "</suggestion>" , "'" ) ; System . out . println ( "Message: " + msg ) ; final List < String > replacements = match . getSuggestedReplacements ( ) ; if ( ! replacements . isEmpty ( ) ) { System . out . println ( "Suggestion: " + StringTools . listToString ( replacements , "; " ) ) ; } System . out . println ( contextTools . getPlainTextContext ( match . getFromPos ( ) , match . getToPos ( ) , sentence . getText ( ) ) ) ; i ++ ; checkMaxErrors ( ++ errorCount ) ; } } checkMaxSentences ( ++ sentenceCount ) ; } @ Override public void close ( ) throws Exception { } }
package org . languagetool . dev . dumpcheck ; public class Sentence { private final String sentence ; private final String source ; private final String title ; private final String url ; private final int articleCount ; Sentence ( String sentence , String source , String title , String url , int articleCount ) { this . sentence = sentence . trim ( ) ; this . source = source ; this . title = title ; this . url = url ; this . articleCount = articleCount ; } public String getText ( ) { return sentence ; } public String getSource ( ) { return source ; } public String getTitle ( ) { return title ; } String getUrl ( ) { return url ; } int getArticleCount ( ) { return articleCount ; } @ Override public String toString ( ) { return sentence ; } }
package org . languagetool . dev . dumpcheck ; public class ArticleLimitReachedException extends RuntimeException { private final int limit ; public ArticleLimitReachedException ( int limit ) { this . limit = limit ; } @ Override public String getMessage ( ) { return "Maximum number of articles (" + limit + ") reached" ; } }
package org . languagetool . dev . dumpcheck ; public class DocumentLimitReachedException extends RuntimeException { private final int limit ; public DocumentLimitReachedException ( int limit ) { this . limit = limit ; } public int getLimit ( ) { return limit ; } @ Override public String getMessage ( ) { return "Maximum number of documents (" + limit + ") reached" ; } }
package org . languagetool . dev . dumpcheck ; import org . languagetool . Language ; import org . languagetool . rules . RuleMatch ; import java . util . List ; abstract class ResultHandler implements AutoCloseable { protected static final int CONTEXT_SIZE = 50 ; protected static final String MARKER_START = "<err>" ; protected static final String MARKER_END = "</err>" ; protected int sentenceCount = 0 ; protected int errorCount = 0 ; protected abstract void handleResult ( Sentence sentence , List < RuleMatch > ruleMatches , Language language ) ; private final int maxSentences ; private final int maxErrors ; protected ResultHandler ( int maxSentences , int maxErrors ) { this . maxSentences = maxSentences ; this . maxErrors = maxErrors ; } protected void checkMaxSentences ( int i ) { if ( maxSentences > 0 && sentenceCount >= maxSentences ) { throw new DocumentLimitReachedException ( maxSentences ) ; } } protected void checkMaxErrors ( int i ) { if ( maxErrors > 0 && errorCount >= maxErrors ) { throw new ErrorLimitReachedException ( maxErrors ) ; } } }
package org . languagetool . dev . dumpcheck ; import org . languagetool . Language ; import org . languagetool . dev . wikipedia . SwebleWikipediaTextFilter ; import org . languagetool . tokenizers . Tokenizer ; import javax . xml . stream . XMLEventReader ; import javax . xml . stream . XMLInputFactory ; import javax . xml . stream . XMLStreamConstants ; import javax . xml . stream . XMLStreamException ; import javax . xml . stream . events . XMLEvent ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . List ; import java . util . NoSuchElementException ; import java . util . regex . Pattern ; public class WikipediaSentenceSource extends SentenceSource { private static final boolean ONLY_ARTICLES = false ; private static final String ARTICLE_NAMESPACE = "0" ; private final SwebleWikipediaTextFilter textFilter = new SwebleWikipediaTextFilter ( ) ; private final XMLEventReader reader ; private final Tokenizer sentenceTokenizer ; private final List < WikipediaSentence > sentences ; private final Language language ; private int articleCount = 0 ; private int namespaceSkipCount = 0 ; private int redirectSkipCount = 0 ; public WikipediaSentenceSource ( InputStream xmlInput , Language language ) { this ( xmlInput , language , null ) ; } public WikipediaSentenceSource ( InputStream xmlInput , Language language , Pattern filter ) { super ( language , filter ) ; textFilter . enableMapping ( false ) ; try { XMLInputFactory factory = XMLInputFactory . newInstance ( ) ; reader = factory . createXMLEventReader ( xmlInput ) ; sentenceTokenizer = language . getSentenceTokenizer ( ) ; sentences = new ArrayList < > ( ) ; this . language = language ; } catch ( XMLStreamException e ) { throw new RuntimeException ( e ) ; } } @ Override public boolean hasNext ( ) { try { fillSentences ( ) ; } catch ( XMLStreamException e ) { throw new RuntimeException ( e ) ; } return sentences . size ( ) > 0 ; } @ Override public Sentence next ( ) { try { fillSentences ( ) ; if ( sentences . size ( ) == 0 ) { throw new NoSuchElementException ( ) ; } WikipediaSentence wikiSentence = sentences . remove ( 0 ) ; String url = "http://" + language . getShortName ( ) + ".wikipedia.org/wiki/" + wikiSentence . title ; return new Sentence ( wikiSentence . sentence , getSource ( ) , wikiSentence . title , url , wikiSentence . articleCount ) ; } catch ( XMLStreamException e ) { throw new RuntimeException ( e ) ; } } @ Override public String getSource ( ) { return "wikipedia" ; } private void fillSentences ( ) throws XMLStreamException { String title = null ; String namespace = null ; while ( sentences . size ( ) == 0 && reader . hasNext ( ) ) { XMLEvent event = reader . nextEvent ( ) ; if ( event . getEventType ( ) == XMLStreamConstants . START_ELEMENT ) { String elementName = event . asStartElement ( ) . getName ( ) . getLocalPart ( ) ; switch ( elementName ) { case "title" : event = reader . nextEvent ( ) ; title = event . asCharacters ( ) . getData ( ) ; articleCount ++ ; break ; case "ns" : event = reader . nextEvent ( ) ; namespace = event . asCharacters ( ) . getData ( ) ; break ; case "text" : handleTextElement ( namespace , title , articleCount ) ; break ; } } } } private void handleTextElement ( String namespace , String title , int articleCount ) throws XMLStreamException { if ( ONLY_ARTICLES && ! ARTICLE_NAMESPACE . equals ( namespace ) ) { namespaceSkipCount ++ ; return ; } XMLEvent event = reader . nextEvent ( ) ; StringBuilder sb = new StringBuilder ( ) ; while ( event . isCharacters ( ) ) { sb . append ( event . asCharacters ( ) . getData ( ) ) ; event = reader . nextEvent ( ) ; } try { if ( sb . toString ( ) . trim ( ) . toLowerCase ( ) . startsWith ( "#redirect" ) ) { redirectSkipCount ++ ; return ; } String textToCheck = textFilter . filter ( sb . toString ( ) ) . getPlainText ( ) ; for ( String sentence : sentenceTokenizer . tokenize ( textToCheck ) ) { if ( acceptSentence ( sentence ) ) { sentences . add ( new WikipediaSentence ( sentence , title , articleCount ) ) ; } } } catch ( Exception e ) { System . err . println ( "Could not extract text, skipping document: " + e + ", full stacktrace follows:" ) ; e . printStackTrace ( ) ; } } private static class WikipediaSentence { final String sentence ; final String title ; final int articleCount ; WikipediaSentence ( String sentence , String title , int articleCount ) { this . sentence = sentence ; this . title = title ; this . articleCount = articleCount ; } } }
package org . languagetool . dev . dumpcheck ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Field ; import org . apache . lucene . document . StringField ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . FSDirectory ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . dev . index . Indexer ; import org . xml . sax . helpers . DefaultHandler ; import java . io . File ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; public class SentenceSourceIndexer extends DefaultHandler implements AutoCloseable { public static final String MAX_DOC_COUNT_VALUE = "maxDocCountValue" ; public static final String MAX_DOC_COUNT_FIELD = "maxDocCount" ; public static final String MAX_DOC_COUNT_FIELD_VAL = "1" ; private final Indexer indexer ; private final int maxSentences ; private int sentenceCount = 0 ; SentenceSourceIndexer ( Directory dir , Language language , int maxSentences ) { this . indexer = new Indexer ( dir , language ) ; this . maxSentences = maxSentences ; } @ Override public void close ( ) throws Exception { indexer . close ( ) ; } private void run ( List < String > dumpFileNames , Language language ) throws IOException { MixingSentenceSource mixingSource = MixingSentenceSource . create ( dumpFileNames , language ) ; while ( mixingSource . hasNext ( ) ) { Sentence sentence = mixingSource . next ( ) ; if ( sentenceCount % 1000 == 0 ) { System . out . println ( "Indexing sentence #" + sentenceCount + " (" + mixingSource . getSourceDistribution ( ) + "):" ) ; System . out . println ( " [" + sentence . getSource ( ) + "] " + sentence ) ; } indexer . indexSentence ( sentence , sentenceCount ) ; sentenceCount ++ ; if ( maxSentences > 0 && sentenceCount >= maxSentences ) { throw new DocumentLimitReachedException ( maxSentences ) ; } } } private void writeMetaDocuments ( ) throws IOException { final Document doc = new Document ( ) ; doc . add ( new StringField ( MAX_DOC_COUNT_FIELD , MAX_DOC_COUNT_FIELD_VAL , Field . Store . YES ) ) ; doc . add ( new StringField ( MAX_DOC_COUNT_VALUE , sentenceCount + "" , Field . Store . YES ) ) ; indexer . add ( doc ) ; } public static void main ( String ... args ) throws Exception { if ( args . length != 4 ) { System . out . println ( "Usage: " + SentenceSourceIndexer . class . getSimpleName ( ) + " <dataFile...> <indexDir> <languageCode> <maxSentences>" ) ; System . out . println ( "\t<dataFiles> comma-separated list of a Wikipedia XML dump (*.xml) and/or Tatoeba files (tatoeba-*)" ) ; System . out . println ( "\t<indexDir> directory where Lucene index will be written to, existing index content will be removed" ) ; System . out . println ( "\t<languageCode> short code like en for English, de for German etc" ) ; System . out . println ( "\t<maxSentences> maximum number of sentences to be indexed, use 0 for no limit" ) ; System . exit ( 1 ) ; } final List < String > dumpFilesNames = Arrays . asList ( args [ 0 ] . split ( "," ) ) ; final File indexDir = new File ( args [ 1 ] ) ; final String languageCode = args [ 2 ] ; final int maxSentences = Integer . parseInt ( args [ 3 ] ) ; final Language language = Languages . getLanguageForShortName ( languageCode ) ; if ( maxSentences == 0 ) { System . out . println ( "Going to index contents from " + dumpFilesNames ) ; } else { System . out . println ( "Going to index up to " + maxSentences + " sentences from " + dumpFilesNames ) ; } System . out . println ( "Output index dir: " + indexDir ) ; final long start = System . currentTimeMillis ( ) ; try ( FSDirectory fsDirectory = FSDirectory . open ( indexDir ) ) { final SentenceSourceIndexer indexer = new SentenceSourceIndexer ( fsDirectory , language , maxSentences ) ; try { indexer . run ( dumpFilesNames , language ) ; } catch ( DocumentLimitReachedException e ) { System . out . println ( "Sentence limit (" + e . getLimit ( ) + ") reached, stopping indexing" ) ; } finally { indexer . writeMetaDocuments ( ) ; indexer . close ( ) ; } } final long end = System . currentTimeMillis ( ) ; final float minutes = ( end - start ) / ( float ) ( 1000 * 60 ) ; System . out . printf ( "Indexing took %.2f minutes\n" , minutes ) ; } }
package org . languagetool . dev . dumpcheck ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . tools . StringTools ; import org . w3c . dom . Document ; import org . w3c . dom . Node ; import org . w3c . dom . NodeList ; import org . xml . sax . InputSource ; import javax . xml . parsers . DocumentBuilder ; import javax . xml . parsers . DocumentBuilderFactory ; import javax . xml . xpath . XPath ; import javax . xml . xpath . XPathConstants ; import javax . xml . xpath . XPathExpressionException ; import javax . xml . xpath . XPathFactory ; import java . io . IOException ; import java . io . InputStream ; import java . io . StringReader ; import java . net . URL ; import java . net . URLEncoder ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; class AfterTheDeadlineChecker { private final String urlPrefix ; private final int maxSentenceCount ; AfterTheDeadlineChecker ( String urlPrefix , int maxSentenceCount ) { this . urlPrefix = urlPrefix ; this . maxSentenceCount = maxSentenceCount ; } private void run ( Language lang , List < String > fileNames ) throws IOException , XPathExpressionException { MixingSentenceSource mixingSource = MixingSentenceSource . create ( fileNames , lang ) ; int sentenceCount = 0 ; while ( mixingSource . hasNext ( ) ) { Sentence sentence = mixingSource . next ( ) ; String resultXml = queryAtDServer ( sentence . getText ( ) ) ; System . out . println ( "==========================" ) ; System . out . println ( sentence . getSource ( ) + ": " + sentence . getText ( ) ) ; List < String > matches = getMatches ( resultXml ) ; for ( String match : matches ) { System . out . println ( " " + match ) ; } sentenceCount ++ ; if ( maxSentenceCount > 0 && sentenceCount > maxSentenceCount ) { System . err . println ( "Limit reached, stopping at sentence #" + sentenceCount ) ; break ; } } } private String queryAtDServer ( String text ) { try { URL url = new URL ( urlPrefix + URLEncoder . encode ( text , "UTF-8" ) ) ; InputStream contentStream = ( InputStream ) url . getContent ( ) ; return StringTools . streamToString ( contentStream , "UTF-8" ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } private List < String > getMatches ( String resultXml ) throws XPathExpressionException { List < String > matches = new ArrayList < > ( ) ; Document document = getDocument ( resultXml ) ; XPath xPath = XPathFactory . newInstance ( ) . newXPath ( ) ; NodeList errors = ( NodeList ) xPath . evaluate ( "//error" , document , XPathConstants . NODESET ) ; for ( int i = 0 ; i < errors . getLength ( ) ; i ++ ) { Node error = errors . item ( i ) ; String string = xPath . evaluate ( "string" , error ) ; String description = xPath . evaluate ( "description" , error ) ; matches . add ( description + ": " + string ) ; } return matches ; } private Document getDocument ( String xml ) { try { DocumentBuilderFactory factory = DocumentBuilderFactory . newInstance ( ) ; DocumentBuilder builder = factory . newDocumentBuilder ( ) ; InputSource inputSource = new InputSource ( new StringReader ( xml ) ) ; return builder . parse ( inputSource ) ; } catch ( Exception e ) { throw new RuntimeException ( "Could not parse XML: " + xml ) ; } } public static void main ( String [ ] args ) throws Exception { if ( args . length < 4 ) { System . out . println ( "Usage: " + AfterTheDeadlineChecker . class . getSimpleName ( ) + " <langCode> <atdUrlPrefix> <file...>" ) ; System . out . println ( " <langCode> a language code like 'en' for English" ) ; System . out . println ( " <atdUrlPrefix> URL prefix of After the Deadline server, like 'http://localhost:1059/checkDocument?data='" ) ; System . out . println ( " <sentenceLimit> Maximum number of sentences to check, or 0 for no limit" ) ; System . out . println ( " <file...> Wikipedia and/or Tatoeba file(s)" ) ; System . exit ( 1 ) ; } Language language = Languages . getLanguageForShortName ( args [ 0 ] ) ; String urlPrefix = args [ 1 ] ; int maxSentenceCount = Integer . parseInt ( args [ 2 ] ) ; List < String > files = Arrays . asList ( args ) . subList ( 3 , args . length ) ; AfterTheDeadlineChecker atdChecker = new AfterTheDeadlineChecker ( urlPrefix , maxSentenceCount ) ; atdChecker . run ( language , files ) ; } }
package org . languagetool . dev . dumpcheck ; import org . apache . commons . lang . StringUtils ; import org . languagetool . Language ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . util . * ; import java . util . regex . Pattern ; public class MixingSentenceSource extends SentenceSource { private final List < SentenceSource > sources ; private final Map < String , Integer > sourceDistribution = new HashMap < > ( ) ; private int count ; public static MixingSentenceSource create ( List < String > dumpFileNames , Language language ) throws IOException { return create ( dumpFileNames , language , null ) ; } public static MixingSentenceSource create ( List < String > dumpFileNames , Language language , Pattern filter ) throws IOException { List < SentenceSource > sources = new ArrayList < > ( ) ; for ( String dumpFileName : dumpFileNames ) { File file = new File ( dumpFileName ) ; if ( file . getName ( ) . endsWith ( ".xml" ) ) { sources . add ( new WikipediaSentenceSource ( new FileInputStream ( dumpFileName ) , language , filter ) ) ; } else if ( file . getName ( ) . startsWith ( "tatoeba-" ) ) { sources . add ( new TatoebaSentenceSource ( new FileInputStream ( dumpFileName ) , language , filter ) ) ; } else if ( file . getName ( ) . endsWith ( ".txt" ) ) { sources . add ( new PlainTextSentenceSource ( new FileInputStream ( dumpFileName ) , language , filter ) ) ; } else { throw new RuntimeException ( "Could not find a source handler for " + dumpFileName + " - Wikipedia files must be named '*.xml', Tatoeba files must be named 'tatoeba-*'" ) ; } } return new MixingSentenceSource ( sources , language ) ; } private MixingSentenceSource ( List < SentenceSource > sources , Language language ) { super ( language ) ; this . sources = sources ; } Map < String , Integer > getSourceDistribution ( ) { return sourceDistribution ; } @ Override public boolean hasNext ( ) { for ( SentenceSource source : sources ) { if ( source . hasNext ( ) ) { return true ; } } return false ; } @ Override public Sentence next ( ) { SentenceSource sentenceSource = sources . get ( count % sources . size ( ) ) ; while ( ! sentenceSource . hasNext ( ) ) { sources . remove ( sentenceSource ) ; if ( sources . size ( ) == 0 ) { throw new NoSuchElementException ( ) ; } count ++ ; sentenceSource = sources . get ( count % sources . size ( ) ) ; } count ++ ; Sentence next = sentenceSource . next ( ) ; updateDistributionMap ( next ) ; return next ; } private void updateDistributionMap ( Sentence next ) { Integer prevCount = sourceDistribution . get ( next . getSource ( ) ) ; if ( prevCount != null ) { sourceDistribution . put ( next . getSource ( ) , prevCount + 1 ) ; } else { sourceDistribution . put ( next . getSource ( ) , 1 ) ; } } @ Override public String getSource ( ) { return StringUtils . join ( sources , ", " ) ; } }
package org . languagetool . dev . dumpcheck ; import org . languagetool . Language ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . List ; import java . util . NoSuchElementException ; import java . util . Scanner ; import java . util . regex . Pattern ; public class PlainTextSentenceSource extends SentenceSource { private final List < String > sentences ; private final Scanner scanner ; private int articleCount = 0 ; public PlainTextSentenceSource ( InputStream textInput , Language language ) { this ( textInput , language , null ) ; } public PlainTextSentenceSource ( InputStream textInput , Language language , Pattern filter ) { super ( language , filter ) ; scanner = new Scanner ( textInput ) ; sentences = new ArrayList < > ( ) ; } @ Override public boolean hasNext ( ) { fillSentences ( ) ; return sentences . size ( ) > 0 ; } @ Override public Sentence next ( ) { fillSentences ( ) ; if ( sentences . size ( ) == 0 ) { throw new NoSuchElementException ( ) ; } return new Sentence ( sentences . remove ( 0 ) , getSource ( ) , "<plaintext>" , null , ++ articleCount ) ; } @ Override public String getSource ( ) { return "plaintext" ; } private void fillSentences ( ) { while ( sentences . size ( ) == 0 && scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; if ( line . isEmpty ( ) ) { continue ; } if ( acceptSentence ( line ) ) { sentences . add ( line ) ; } } } }
package org . languagetool . rules . sk ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikSlovakSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/sk/hunspell/sk_SK.dict" ; public MorfologikSlovakSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_SK_SK" ; } }
package org . languagetool . dev . index ; public class UnsupportedPatternRuleException extends Exception { private static final long serialVersionUID = - 2346750825068970240L ; public UnsupportedPatternRuleException ( String message ) { super ( message ) ; } }
package org . languagetool . dev . index ; import java . io . IOException ; import java . util . Arrays ; import java . util . Iterator ; import java . util . List ; import java . util . Stack ; import org . apache . lucene . analysis . TokenFilter ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . tokenattributes . CharTermAttribute ; import org . apache . lucene . analysis . tokenattributes . OffsetAttribute ; import org . apache . lucene . analysis . tokenattributes . PositionIncrementAttribute ; import org . apache . lucene . analysis . tokenattributes . TypeAttribute ; import org . apache . lucene . util . AttributeSource ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; public final class LanguageToolFilter extends TokenFilter { static final String POS_PREFIX = "_POS_" ; static final String LEMMA_PREFIX = "_LEMMA_" ; private final JLanguageTool languageTool ; private final boolean toLowerCase ; private final Stack < String > posStack ; private final CharTermAttribute termAtt ; private final OffsetAttribute offsetAtt ; private final PositionIncrementAttribute posIncrAtt ; private final TypeAttribute typeAtt ; private AttributeSource . State current ; private Iterator < AnalyzedTokenReadings > tokenIter ; LanguageToolFilter ( TokenStream input , JLanguageTool languageTool , boolean toLowerCase ) { super ( input ) ; this . languageTool = languageTool ; this . toLowerCase = toLowerCase ; posStack = new Stack < > ( ) ; termAtt = addAttribute ( CharTermAttribute . class ) ; offsetAtt = addAttribute ( OffsetAttribute . class ) ; posIncrAtt = addAttribute ( PositionIncrementAttribute . class ) ; typeAtt = addAttribute ( TypeAttribute . class ) ; } @ Override public boolean incrementToken ( ) throws IOException { if ( posStack . size ( ) > 0 ) { final String pop = posStack . pop ( ) ; restoreState ( current ) ; termAtt . append ( pop ) ; posIncrAtt . setPositionIncrement ( 0 ) ; typeAtt . setType ( "pos" ) ; return true ; } if ( tokenIter == null || ! tokenIter . hasNext ( ) ) { if ( input . incrementToken ( ) ) { final AnalyzedSentence sentence = languageTool . getAnalyzedSentence ( termAtt . toString ( ) ) ; final List < AnalyzedTokenReadings > tokenBuffer = Arrays . asList ( sentence . getTokens ( ) ) ; tokenIter = tokenBuffer . iterator ( ) ; if ( ! tokenIter . hasNext ( ) ) { return false ; } } else { return false ; } } clearAttributes ( ) ; final AnalyzedTokenReadings tr = tokenIter . next ( ) ; if ( tr . isSentenceStart ( ) ) { typeAtt . setType ( "pos" ) ; String posTag = tr . getAnalyzedToken ( 0 ) . getPOSTag ( ) ; String lemma = tr . getAnalyzedToken ( 0 ) . getLemma ( ) ; if ( toLowerCase ) { termAtt . append ( POS_PREFIX . toLowerCase ( ) ) . append ( posTag . toLowerCase ( ) ) ; if ( lemma != null ) { termAtt . append ( LEMMA_PREFIX . toLowerCase ( ) ) . append ( lemma . toLowerCase ( ) ) ; } } else { termAtt . append ( POS_PREFIX ) . append ( posTag ) ; if ( lemma != null ) { termAtt . append ( LEMMA_PREFIX ) . append ( lemma ) ; } } return true ; } if ( tr . isWhitespace ( ) ) { return this . incrementToken ( ) ; } offsetAtt . setOffset ( tr . getStartPos ( ) , tr . getEndPos ( ) ) ; for ( AnalyzedToken token : tr ) { if ( token . getPOSTag ( ) != null ) { if ( toLowerCase ) { posStack . push ( POS_PREFIX . toLowerCase ( ) + token . getPOSTag ( ) . toLowerCase ( ) ) ; } else { posStack . push ( POS_PREFIX + token . getPOSTag ( ) ) ; } } if ( token . getLemma ( ) != null ) { if ( toLowerCase ) { posStack . push ( LEMMA_PREFIX . toLowerCase ( ) + token . getLemma ( ) . toLowerCase ( ) ) ; } else { posStack . push ( LEMMA_PREFIX + token . getLemma ( ) ) ; } } } current = captureState ( ) ; if ( toLowerCase ) { termAtt . append ( tr . getAnalyzedToken ( 0 ) . getToken ( ) . toLowerCase ( ) ) ; } else { termAtt . append ( tr . getAnalyzedToken ( 0 ) . getToken ( ) ) ; } return true ; } }
package org . languagetool . dev . index ; import org . apache . lucene . search . Query ; import java . util . List ; public class SearcherResult { private final List < MatchingSentence > matchingSentences ; private final int checkedSentences ; private final Query relaxedQuery ; private boolean resultIsTimeLimited ; private int docCount ; private boolean hasTooManyLuceneMatches ; private int luceneMatchCount ; public SearcherResult ( List < MatchingSentence > matchingSentences , int checkedSentences , Query relaxedQuery ) { this . matchingSentences = matchingSentences ; this . checkedSentences = checkedSentences ; this . relaxedQuery = relaxedQuery ; } public List < MatchingSentence > getMatchingSentences ( ) { return matchingSentences ; } public int getCheckedSentences ( ) { return checkedSentences ; } public Query getRelaxedQuery ( ) { return relaxedQuery ; } public boolean isResultIsTimeLimited ( ) { return resultIsTimeLimited ; } public void setResultIsTimeLimited ( boolean resultIsTimeLimited ) { this . resultIsTimeLimited = resultIsTimeLimited ; } public void setDocCount ( int docCount ) { this . docCount = docCount ; } public int getDocCount ( ) { return docCount ; } public void setHasTooManyLuceneMatches ( boolean hasTooManyLuceneMatches ) { this . hasTooManyLuceneMatches = hasTooManyLuceneMatches ; } public boolean hasTooManyLuceneMatches ( ) { return hasTooManyLuceneMatches ; } public void setLuceneMatchCount ( int luceneMatchCount ) { this . luceneMatchCount = luceneMatchCount ; } public int getLuceneMatchCount ( ) { return luceneMatchCount ; } }
package org . languagetool . dev . index ; import java . util . List ; import org . languagetool . AnalyzedSentence ; import org . languagetool . rules . RuleMatch ; public class MatchingSentence { private final String sentence ; private final String source ; private final String title ; private final AnalyzedSentence analyzedSentence ; private final List < RuleMatch > ruleMatches ; MatchingSentence ( String sentence , String source , String title , AnalyzedSentence analyzedSentence , List < RuleMatch > ruleMatches ) { this . sentence = sentence ; this . source = source ; this . title = title ; this . analyzedSentence = analyzedSentence ; this . ruleMatches = ruleMatches ; } public String getSentence ( ) { return sentence ; } public String getSource ( ) { return source ; } public String getTitle ( ) { return title ; } public AnalyzedSentence getAnalyzedSentence ( ) { return analyzedSentence ; } public List < RuleMatch > getRuleMatches ( ) { return ruleMatches ; } @ Override public String toString ( ) { return sentence ; } }
package org . languagetool . dev . index ; import org . apache . lucene . analysis . Analyzer ; import java . io . Reader ; class DoNotUseAnalyzer extends Analyzer { @ Override protected TokenStreamComponents createComponents ( String s , Reader reader ) { throw new RuntimeException ( "This analyzer is not supposed to be called" ) ; } }
package org . languagetool . dev . index ; import java . io . * ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . miscellaneous . PerFieldAnalyzerWrapper ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Field ; import org . apache . lucene . document . FieldType ; import org . apache . lucene . index . IndexWriter ; import org . apache . lucene . index . IndexWriterConfig ; import org . apache . lucene . index . IndexWriterConfig . OpenMode ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . FSDirectory ; import org . apache . lucene . util . Version ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . dev . dumpcheck . Sentence ; import org . languagetool . tokenizers . SentenceTokenizer ; import static org . languagetool . dev . index . PatternRuleQueryBuilder . FIELD_NAME ; import static org . languagetool . dev . index . PatternRuleQueryBuilder . FIELD_NAME_LOWERCASE ; import static org . languagetool . dev . index . PatternRuleQueryBuilder . SOURCE_FIELD_NAME ; public class Indexer implements AutoCloseable { static final String TITLE_FIELD_NAME = "title" ; private static final Version LUCENE_VERSION = Version . LUCENE_4_10_3 ; private final IndexWriter writer ; private final SentenceTokenizer sentenceTokenizer ; public Indexer ( Directory dir , Language language ) { try { final Analyzer analyzer = getAnalyzer ( language ) ; final IndexWriterConfig writerConfig = getIndexWriterConfig ( analyzer ) ; writerConfig . setOpenMode ( OpenMode . CREATE ) ; writer = new IndexWriter ( dir , writerConfig ) ; sentenceTokenizer = language . getSentenceTokenizer ( ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } public static void main ( String [ ] args ) throws IOException { ensureCorrectUsageOrExit ( args ) ; run ( args [ 0 ] , args [ 1 ] , args [ 2 ] ) ; } static Analyzer getAnalyzer ( Language language ) { final Map < String , Analyzer > analyzerMap = new HashMap < > ( ) ; analyzerMap . put ( FIELD_NAME , new LanguageToolAnalyzer ( LUCENE_VERSION , new JLanguageTool ( language ) , false ) ) ; analyzerMap . put ( FIELD_NAME_LOWERCASE , new LanguageToolAnalyzer ( LUCENE_VERSION , new JLanguageTool ( language ) , true ) ) ; return new PerFieldAnalyzerWrapper ( new DoNotUseAnalyzer ( ) , analyzerMap ) ; } static IndexWriterConfig getIndexWriterConfig ( Analyzer analyzer ) { return new IndexWriterConfig ( LUCENE_VERSION , analyzer ) ; } private static void ensureCorrectUsageOrExit ( String [ ] args ) { if ( args . length != 3 ) { System . err . println ( "Usage: Indexer <textFile> <indexDir> <languageCode>" ) ; System . err . println ( "\ttextFile path to a text file to be indexed (line end implies sentence end)" ) ; System . err . println ( "\tindexDir path to a directory storing the index" ) ; System . err . println ( "\tlanguageCode short language code, e.g. en for English" ) ; System . exit ( 1 ) ; } } private static void run ( String textFile , String indexDir , String languageCode ) throws IOException { final File file = new File ( textFile ) ; if ( ! file . exists ( ) || ! file . canRead ( ) ) { System . out . println ( "Text file '" + file . getAbsolutePath ( ) + "' does not exist or is not readable, please check the path" ) ; System . exit ( 1 ) ; } try ( BufferedReader reader = new BufferedReader ( new FileReader ( file ) ) ) { System . out . println ( "Indexing to directory '" + indexDir + "'..." ) ; try ( FSDirectory directory = FSDirectory . open ( new File ( indexDir ) ) ) { final Language language = Languages . getLanguageForShortName ( languageCode ) ; try ( Indexer indexer = new Indexer ( directory , language ) ) { indexer . indexText ( reader ) ; } } } System . out . println ( "Index complete!" ) ; } public static void run ( String content , Directory dir , Language language ) throws IOException { final BufferedReader br = new BufferedReader ( new StringReader ( content ) ) ; try ( Indexer indexer = new Indexer ( dir , language ) ) { indexer . indexText ( br ) ; } } public void indexSentence ( Sentence sentence , int docCount ) throws IOException { final BufferedReader reader = new BufferedReader ( new StringReader ( sentence . getText ( ) ) ) ; String line ; while ( ( line = reader . readLine ( ) ) != null ) { add ( line , sentence . getSource ( ) , sentence . getTitle ( ) , docCount ) ; } } public void indexText ( BufferedReader reader ) throws IOException { String line ; while ( ( line = reader . readLine ( ) ) != null ) { final List < String > sentences = sentenceTokenizer . tokenize ( line ) ; for ( String sentence : sentences ) { add ( sentence , null , null , - 1 ) ; } } } public void add ( Document doc ) throws IOException { writer . addDocument ( doc ) ; } private void add ( String sentence , String source , String title , int docCount ) throws IOException { final Document doc = new Document ( ) ; final FieldType type = new FieldType ( ) ; type . setStored ( true ) ; type . setIndexed ( true ) ; type . setTokenized ( true ) ; doc . add ( new Field ( FIELD_NAME , sentence , type ) ) ; doc . add ( new Field ( FIELD_NAME_LOWERCASE , sentence , type ) ) ; if ( docCount != - 1 ) { final FieldType countType = new FieldType ( ) ; countType . setStored ( true ) ; countType . setIndexed ( false ) ; doc . add ( new Field ( "docCount" , docCount + "" , countType ) ) ; } if ( title != null ) { final FieldType titleType = new FieldType ( ) ; titleType . setStored ( true ) ; titleType . setIndexed ( false ) ; titleType . setTokenized ( false ) ; doc . add ( new Field ( TITLE_FIELD_NAME , title , titleType ) ) ; } if ( source != null ) { final FieldType sourceType = new FieldType ( ) ; sourceType . setStored ( true ) ; sourceType . setIndexed ( true ) ; sourceType . setTokenized ( false ) ; doc . add ( new Field ( SOURCE_FIELD_NAME , source , sourceType ) ) ; } writer . addDocument ( doc ) ; } @ Override public void close ( ) throws IOException { writer . close ( ) ; } }
package org . languagetool . dev . index ; import java . io . Reader ; import org . apache . lucene . analysis . util . CharTokenizer ; import org . apache . lucene . util . AttributeFactory ; import org . apache . lucene . util . Version ; public final class AnyCharTokenizer extends CharTokenizer { public AnyCharTokenizer ( Version matchVersion , Reader in ) { super ( matchVersion , in ) ; } public AnyCharTokenizer ( Version matchVersion , AttributeFactory factory , Reader in ) { super ( matchVersion , factory , in ) ; } @ Override protected boolean isTokenChar ( int c ) { return true ; } }
package org . languagetool . dev . index ; import static org . languagetool . dev . dumpcheck . SentenceSourceIndexer . MAX_DOC_COUNT_FIELD ; import static org . languagetool . dev . dumpcheck . SentenceSourceIndexer . MAX_DOC_COUNT_FIELD_VAL ; import static org . languagetool . dev . dumpcheck . SentenceSourceIndexer . MAX_DOC_COUNT_VALUE ; import static org . languagetool . dev . index . PatternRuleQueryBuilder . FIELD_NAME ; import static org . languagetool . dev . index . PatternRuleQueryBuilder . FIELD_NAME_LOWERCASE ; import static org . languagetool . dev . index . PatternRuleQueryBuilder . SOURCE_FIELD_NAME ; import java . io . File ; import java . io . IOException ; import java . net . URLEncoder ; import java . util . ArrayList ; import java . util . List ; import org . apache . lucene . document . Document ; import org . apache . lucene . index . DirectoryReader ; import org . apache . lucene . index . Term ; import org . apache . lucene . search . IndexSearcher ; import org . apache . lucene . search . Query ; import org . apache . lucene . search . ScoreDoc ; import org . apache . lucene . search . Sort ; import org . apache . lucene . search . SortField ; import org . apache . lucene . search . TermQuery ; import org . apache . lucene . search . TimeLimitingCollector ; import org . apache . lucene . search . TopDocs ; import org . apache . lucene . search . TopFieldCollector ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . SimpleFSDirectory ; import org . apache . lucene . util . Counter ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . tools . ContextTools ; public class Searcher { private static boolean WIKITEXT_OUTPUT = false ; private final Directory directory ; private int maxHits = 1000 ; private int maxSearchTimeMillis = 5000 ; private IndexSearcher indexSearcher ; private DirectoryReader reader ; private boolean limitSearch = true ; public Searcher ( Directory directory ) { this . directory = directory ; } private void open ( ) throws IOException { reader = DirectoryReader . open ( directory ) ; indexSearcher = new IndexSearcher ( reader ) ; } private void close ( ) throws IOException { if ( reader != null ) { reader . close ( ) ; } } public int getDocCount ( ) throws IOException { try ( DirectoryReader reader = DirectoryReader . open ( directory ) ) { final IndexSearcher indexSearcher = new IndexSearcher ( reader ) ; return getDocCount ( indexSearcher ) ; } } private int getDocCount ( IndexSearcher indexSearcher ) throws IOException { final Term searchTerm = new Term ( MAX_DOC_COUNT_FIELD , MAX_DOC_COUNT_FIELD_VAL ) ; final TopDocs search = indexSearcher . search ( new TermQuery ( searchTerm ) , 1 ) ; if ( search . totalHits != 1 ) { return - 1 ; } final ScoreDoc scoreDoc = search . scoreDocs [ 0 ] ; final Document doc = indexSearcher . doc ( scoreDoc . doc ) ; return Integer . parseInt ( doc . get ( MAX_DOC_COUNT_VALUE ) ) ; } public int getMaxHits ( ) { return maxHits ; } public void setMaxHits ( int maxHits ) { this . maxHits = maxHits ; } public int getMaxSearchTimeMillis ( ) { return maxSearchTimeMillis ; } public void setMaxSearchTimeMillis ( int maxSearchTimeMillis ) { this . maxSearchTimeMillis = maxSearchTimeMillis ; } public SearcherResult findRuleMatchesOnIndex ( PatternRule rule , Language language ) throws IOException , UnsupportedPatternRuleException { open ( ) ; try { final PatternRuleQueryBuilder patternRuleQueryBuilder = new PatternRuleQueryBuilder ( language ) ; final Query query = patternRuleQueryBuilder . buildRelaxedQuery ( rule ) ; if ( query == null ) { throw new NullPointerException ( "Cannot search on null query for rule: " + rule . getId ( ) ) ; } System . out . println ( "Running query: " + query . toString ( FIELD_NAME_LOWERCASE ) ) ; final SearchRunnable runnable = new SearchRunnable ( indexSearcher , query , language , rule ) ; final Thread searchThread = new Thread ( runnable ) ; searchThread . start ( ) ; try { if ( limitSearch ) { searchThread . join ( maxSearchTimeMillis ) ; } else { searchThread . join ( Integer . MAX_VALUE ) ; } searchThread . interrupt ( ) ; } catch ( InterruptedException e ) { throw new RuntimeException ( "Search thread got interrupted for query " + query , e ) ; } if ( searchThread . isInterrupted ( ) ) { throw new SearchTimeoutException ( "Search timeout of " + maxSearchTimeMillis + "ms reached for query " + query ) ; } final Exception exception = runnable . getException ( ) ; if ( exception != null ) { if ( exception instanceof SearchTimeoutException ) { throw ( SearchTimeoutException ) exception ; } throw new RuntimeException ( "Exception during search for query " + query + " on rule " + rule . getId ( ) , exception ) ; } final List < MatchingSentence > matchingSentences = runnable . getMatchingSentences ( ) ; final int sentencesChecked = getSentenceCheckCount ( query , indexSearcher ) ; final SearcherResult searcherResult = new SearcherResult ( matchingSentences , sentencesChecked , query ) ; searcherResult . setHasTooManyLuceneMatches ( runnable . hasTooManyLuceneMatches ( ) ) ; searcherResult . setLuceneMatchCount ( runnable . getLuceneMatchCount ( ) ) ; if ( runnable . hasTooManyLuceneMatches ( ) ) { searcherResult . setDocCount ( maxHits ) ; } else { searcherResult . setDocCount ( getDocCount ( indexSearcher ) ) ; } return searcherResult ; } finally { close ( ) ; } } private PossiblyLimitedTopDocs getTopDocs ( Query query , Sort sort ) throws IOException { final TopFieldCollector topCollector = TopFieldCollector . create ( sort , maxHits , true , false , false , false ) ; final Counter clock = Counter . newCounter ( true ) ; final int waitMillis = 1000 ; final TimeLimitingCollector collector = new TimeLimitingCollector ( topCollector , clock , maxSearchTimeMillis / waitMillis ) ; collector . setBaseline ( 0 ) ; final Thread counterThread = new Thread ( ) { @ Override public void run ( ) { final long startTime = System . currentTimeMillis ( ) ; while ( true ) { final long runTimeMillis = System . currentTimeMillis ( ) - startTime ; if ( runTimeMillis > maxSearchTimeMillis ) { return ; } clock . addAndGet ( 1 ) ; try { Thread . sleep ( waitMillis ) ; } catch ( InterruptedException e ) { throw new RuntimeException ( e ) ; } } } } ; counterThread . setName ( "LuceneSearchTimeoutThread" ) ; counterThread . start ( ) ; boolean timeLimitActivated = false ; try { indexSearcher . search ( query , collector ) ; } catch ( TimeLimitingCollector . TimeExceededException e ) { timeLimitActivated = true ; } return new PossiblyLimitedTopDocs ( topCollector . topDocs ( ) , timeLimitActivated ) ; } List < PatternRule > getRuleById ( String ruleId , Language language ) throws IOException { List < PatternRule > rules = new ArrayList < > ( ) ; JLanguageTool langTool = new JLanguageTool ( language ) ; for ( Rule rule : langTool . getAllRules ( ) ) { if ( rule . getId ( ) . equals ( ruleId ) && rule instanceof PatternRule ) { rules . add ( ( PatternRule ) rule ) ; } } if ( rules . size ( ) > 0 ) { return rules ; } else { throw new PatternRuleNotFoundException ( ruleId , language ) ; } } private int getSentenceCheckCount ( Query query , IndexSearcher indexSearcher ) { final int indexSize = indexSearcher . getIndexReader ( ) . numDocs ( ) ; final int sentencesChecked = Math . min ( maxHits , indexSize ) ; return sentencesChecked ; } private List < MatchingSentence > findMatchingSentences ( IndexSearcher indexSearcher , TopDocs topDocs , JLanguageTool languageTool ) throws IOException { final List < MatchingSentence > matchingSentences = new ArrayList < > ( ) ; for ( ScoreDoc match : topDocs . scoreDocs ) { final Document doc = indexSearcher . doc ( match . doc ) ; final String sentence = doc . get ( FIELD_NAME ) ; final List < RuleMatch > ruleMatches = languageTool . check ( sentence ) ; if ( ruleMatches . size ( ) > 0 ) { final String source = doc . get ( SOURCE_FIELD_NAME ) ; final String title = doc . get ( Indexer . TITLE_FIELD_NAME ) ; final AnalyzedSentence analyzedSentence = languageTool . getAnalyzedSentence ( sentence ) ; final MatchingSentence matchingSentence = new MatchingSentence ( sentence , source , title , analyzedSentence , ruleMatches ) ; matchingSentences . add ( matchingSentence ) ; } } return matchingSentences ; } private JLanguageTool getLanguageToolWithOneRule ( Language lang , PatternRule patternRule ) { final JLanguageTool langTool = new JLanguageTool ( lang ) ; for ( Rule rule : langTool . getAllActiveRules ( ) ) { if ( ! rule . getId ( ) . equals ( patternRule . getId ( ) ) ) { langTool . disableRule ( rule . getId ( ) ) ; } } langTool . addRule ( patternRule ) ; langTool . enableDefaultOffRule ( patternRule . getId ( ) ) ; return langTool ; } class PossiblyLimitedTopDocs { TopDocs topDocs ; boolean resultIsTimeLimited ; PossiblyLimitedTopDocs ( TopDocs topDocs , boolean resultIsTimeLimited ) { this . topDocs = topDocs ; this . resultIsTimeLimited = resultIsTimeLimited ; } } private static void ensureCorrectUsageOrExit ( String [ ] args ) { if ( args . length < 3 || ( args . length == 4 && ! "--no_limit" . equals ( args [ 3 ] ) ) ) { System . err . println ( "Usage: Searcher <ruleId> <languageCode> <indexDir> [--no_limit]" ) ; System . err . println ( "\truleId Id of the rule to search for (or comma-separated list of ids)" ) ; System . err . println ( "\tlanguageCode short language code, e.g. 'en' for English" ) ; System . err . println ( "\tindexDir path to a directory containing the index" ) ; System . err . println ( "\t--no_limit do not limit search time" ) ; System . exit ( 1 ) ; } } class SearchRunnable implements Runnable { private final IndexSearcher indexSearcher ; private final Query query ; private final Language language ; private final PatternRule rule ; private List < MatchingSentence > matchingSentences ; private Exception exception ; private boolean tooManyLuceneMatches ; private int luceneMatchCount ; SearchRunnable ( IndexSearcher indexSearcher , Query query , Language language , PatternRule rule ) { this . indexSearcher = indexSearcher ; this . query = query ; this . language = language ; this . rule = rule ; } @ Override public void run ( ) { try { final Sort sort = new Sort ( new SortField ( "docCount" , SortField . Type . INT ) ) ; final long t1 = System . currentTimeMillis ( ) ; final JLanguageTool languageTool = getLanguageToolWithOneRule ( language , rule ) ; final long langToolCreationTime = System . currentTimeMillis ( ) - t1 ; final long t2 = System . currentTimeMillis ( ) ; final PossiblyLimitedTopDocs limitedTopDocs = getTopDocs ( query , sort ) ; final long luceneTime = System . currentTimeMillis ( ) - t2 ; final long t3 = System . currentTimeMillis ( ) ; luceneMatchCount = limitedTopDocs . topDocs . totalHits ; tooManyLuceneMatches = limitedTopDocs . topDocs . scoreDocs . length >= maxHits ; matchingSentences = findMatchingSentences ( indexSearcher , limitedTopDocs . topDocs , languageTool ) ; System . out . println ( "Check done in " + langToolCreationTime + "/" + luceneTime + "/" + ( System . currentTimeMillis ( ) - t3 ) + "ms (LT creation/Lucene/matching) for " + limitedTopDocs . topDocs . scoreDocs . length + " docs" ) ; } catch ( Exception e ) { exception = e ; } } Exception getException ( ) { return exception ; } boolean hasTooManyLuceneMatches ( ) { return tooManyLuceneMatches ; } int getLuceneMatchCount ( ) { return luceneMatchCount ; } List < MatchingSentence > getMatchingSentences ( ) { return matchingSentences ; } } private static ContextTools getContextTools ( int contextSize ) { final ContextTools contextTools = new ContextTools ( ) ; contextTools . setEscapeHtml ( false ) ; contextTools . setContextSize ( contextSize ) ; contextTools . setErrorMarkerStart ( "**" ) ; contextTools . setErrorMarkerEnd ( "**" ) ; return contextTools ; } public static void main ( String [ ] args ) throws Exception { ensureCorrectUsageOrExit ( args ) ; final long startTime = System . currentTimeMillis ( ) ; final String [ ] ruleIds = args [ 0 ] . split ( "," ) ; final String languageCode = args [ 1 ] ; final Language language = Languages . getLanguageForShortName ( languageCode ) ; final File indexDir = new File ( args [ 2 ] ) ; final boolean limitSearch = args . length > 3 && "--no_limit" . equals ( args [ 3 ] ) ; final Searcher searcher = new Searcher ( new SimpleFSDirectory ( indexDir ) ) ; if ( ! limitSearch ) { searcher . setMaxHits ( 100_000 ) ; } searcher . limitSearch = limitSearch ; final ContextTools contextTools = getContextTools ( 140 ) ; int totalMatches = 0 ; for ( String ruleId : ruleIds ) { final long ruleStartTime = System . currentTimeMillis ( ) ; for ( PatternRule rule : searcher . getRuleById ( ruleId , language ) ) { System . out . println ( "===== " + ruleId + "[" + rule . getSubId ( ) + "] =========================================================" ) ; final SearcherResult searcherResult = searcher . findRuleMatchesOnIndex ( rule , language ) ; int i = 1 ; if ( searcherResult . getMatchingSentences ( ) . size ( ) == 0 ) { System . out . println ( "[no matches]" ) ; } for ( MatchingSentence ruleMatch : searcherResult . getMatchingSentences ( ) ) { for ( RuleMatch match : ruleMatch . getRuleMatches ( ) ) { String context = contextTools . getContext ( match . getFromPos ( ) , match . getToPos ( ) , ruleMatch . getSentence ( ) ) ; if ( WIKITEXT_OUTPUT ) { ContextTools contextTools2 = getContextTools ( 0 ) ; String coveredText = contextTools2 . getContext ( match . getFromPos ( ) , match . getToPos ( ) , ruleMatch . getSentence ( ) ) ; coveredText = coveredText . replaceFirst ( "^\\.\\.\\." , "" ) . replaceFirst ( "\\.\\.\\.$" , "" ) ; coveredText = coveredText . replaceFirst ( "^\\*\\*" , "" ) . replaceFirst ( "\\*\\*$" , "" ) ; String encodedTextWithQuotes = URLEncoder . encode ( "\"" + coveredText + "\"" , "UTF-8" ) ; String searchLink = "https://de.wikipedia.org/w/index.php?search=" + encodedTextWithQuotes + "&title=Spezial%3ASuche&go=Artikel" ; context = context . replaceAll ( "\\*\\*.*?\\*\\*" , "[" + searchLink + " " + coveredText + "]" ) ; String encTitle = URLEncoder . encode ( ruleMatch . getTitle ( ) , "UTF-8" ) ; String encodedText = URLEncoder . encode ( coveredText , "UTF-8" ) ; System . out . println ( "# [[" + ruleMatch . getTitle ( ) + "]]: " + context + " ([http://wikipedia.ramselehof.de/wikiblame.php?user_lang=de&lang=de&project=wikipedia&article=" + encTitle + "&needle=" + encodedText + "&skipversions=0&ignorefirst=0&limit=500&searchmethod=int&order=desc&start=Start WikiBlame])" ) ; } else { System . out . println ( i + ": " + context + " [" + ruleMatch . getSource ( ) + "]" ) ; } } totalMatches += ruleMatch . getRuleMatches ( ) . size ( ) ; i ++ ; } System . out . println ( "Time: " + ( System . currentTimeMillis ( ) - ruleStartTime ) + "ms" ) ; } } System . out . println ( "Total time: " + ( System . currentTimeMillis ( ) - startTime ) + "ms, " + totalMatches + " matches" ) ; } }
package org . languagetool . dev . index ; import org . languagetool . Language ; import java . io . IOException ; public class PatternRuleNotFoundException extends IOException { private static final long serialVersionUID = - 220557881967037175L ; public PatternRuleNotFoundException ( String ruleId , Language language ) { super ( "Could not find pattern rule '" + ruleId + "' for language " + language ) ; } }
package org . languagetool . dev . index ; public class SearchTimeoutException extends RuntimeException { public SearchTimeoutException ( String message ) { super ( message ) ; } }
package org . languagetool . tagging . sk ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class SlovakTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/sk/added.txt" ; } public SlovakTagger ( ) { super ( "/sk/slovak.dict" , new Locale ( "sk" ) ) ; } }
package org . languagetool . dev . index ; import org . apache . commons . lang . StringUtils ; import org . apache . lucene . index . Term ; import org . apache . lucene . sandbox . queries . regex . JavaUtilRegexCapabilities ; import org . apache . lucene . sandbox . queries . regex . RegexQuery ; import org . apache . lucene . search . * ; import org . apache . lucene . search . spans . SpanMultiTermQueryWrapper ; import org . apache . lucene . search . spans . SpanNearQuery ; import org . apache . lucene . search . spans . SpanQuery ; import org . apache . lucene . search . spans . SpanTermQuery ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . Language ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . synthesis . Synthesizer ; import java . io . IOException ; import java . util . HashSet ; import java . util . Set ; import static org . languagetool . dev . index . LanguageToolFilter . LEMMA_PREFIX ; import static org . languagetool . dev . index . LanguageToolFilter . POS_PREFIX ; public class PatternRuleQueryBuilder { public static final String FIELD_NAME = "field" ; public static final String SOURCE_FIELD_NAME = "source" ; public static final String FIELD_NAME_LOWERCASE = "fieldLowercase" ; private final Language language ; public PatternRuleQueryBuilder ( Language language ) { this . language = language ; } public Query buildRelaxedQuery ( PatternRule rule ) throws UnsupportedPatternRuleException { final BooleanQuery booleanQuery = new BooleanQuery ( ) ; for ( PatternToken patternToken : rule . getPatternTokens ( ) ) { try { final BooleanClause clause = makeQuery ( patternToken ) ; booleanQuery . add ( clause ) ; } catch ( UnsupportedPatternRuleException e ) { } catch ( Exception e ) { throw new RuntimeException ( "Could not create query for rule " + rule . getId ( ) , e ) ; } } if ( booleanQuery . clauses ( ) . size ( ) == 0 ) { throw new UnsupportedPatternRuleException ( "No items found in rule that can be used to build a search query: " + rule ) ; } return booleanQuery ; } private BooleanClause makeQuery ( PatternToken patternToken ) throws UnsupportedPatternRuleException { checkUnsupportedElement ( patternToken ) ; final String termStr = patternToken . getString ( ) ; final String pos = patternToken . getPOStag ( ) ; final BooleanClause termQuery = getTermQueryOrNull ( patternToken , termStr ) ; final BooleanClause posQuery = getPosQueryOrNull ( patternToken , pos ) ; if ( termQuery != null && posQuery != null ) { if ( mustOccur ( termQuery ) && mustOccur ( posQuery ) ) { final SpanQuery spanQueryForTerm = asSpanQuery ( termQuery ) ; final SpanQuery spanQueryForPos = asSpanQuery ( posQuery ) ; final SpanQuery [ ] spanClauses = { spanQueryForTerm , spanQueryForPos } ; return new BooleanClause ( new SpanNearQuery ( spanClauses , 0 , false ) , BooleanClause . Occur . MUST ) ; } else { throw new UnsupportedPatternRuleException ( "Term/POS combination not supported yet: " + patternToken ) ; } } else if ( termQuery != null ) { return termQuery ; } else if ( posQuery != null ) { return posQuery ; } throw new UnsupportedPatternRuleException ( "Neither POS tag nor term set for element: " + patternToken ) ; } private SpanQuery asSpanQuery ( BooleanClause query ) { if ( query . getQuery ( ) instanceof MultiTermQuery ) { return new SpanMultiTermQueryWrapper < > ( ( MultiTermQuery ) query . getQuery ( ) ) ; } else { final Set < Term > terms = new HashSet < > ( ) ; query . getQuery ( ) . extractTerms ( terms ) ; if ( terms . size ( ) != 1 ) { throw new RuntimeException ( "Expected term set of size 1: " + terms ) ; } return new SpanTermQuery ( terms . iterator ( ) . next ( ) ) ; } } private boolean mustOccur ( BooleanClause query ) { return query != null && query . getOccur ( ) == BooleanClause . Occur . MUST ; } @ Nullable private BooleanClause getTermQueryOrNull ( PatternToken patternToken , String termStr ) { if ( termStr == null || termStr . isEmpty ( ) ) { return null ; } final Query termQuery ; final Term termQueryTerm = getTermQueryTerm ( patternToken , termStr ) ; if ( patternToken . getNegation ( ) || patternToken . getMinOccurrence ( ) == 0 ) { return null ; } else if ( patternToken . isInflected ( ) && patternToken . isRegularExpression ( ) ) { Term lemmaQueryTerm = getQueryTerm ( patternToken , LEMMA_PREFIX + "(" , simplifyRegex ( termStr ) , ")" ) ; final Query regexpQuery = getRegexQuery ( lemmaQueryTerm , termStr , patternToken ) ; return new BooleanClause ( regexpQuery , BooleanClause . Occur . MUST ) ; } else if ( patternToken . isInflected ( ) && ! patternToken . isRegularExpression ( ) ) { final Synthesizer synthesizer = language . getSynthesizer ( ) ; if ( synthesizer != null ) { try { final String [ ] synthesized = synthesizer . synthesize ( new AnalyzedToken ( termStr , null , termStr ) , ".*" , true ) ; final Query query ; if ( synthesized . length == 0 ) { query = new TermQuery ( termQueryTerm ) ; } else { query = new RegexpQuery ( getTermQueryTerm ( patternToken , StringUtils . join ( synthesized , "|" ) ) ) ; } return new BooleanClause ( query , BooleanClause . Occur . MUST ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not build Lucene query for '" + patternToken + "' and '" + termStr + "'" , e ) ; } } return null ; } else if ( patternToken . isRegularExpression ( ) ) { termQuery = getRegexQuery ( termQueryTerm , termStr , patternToken ) ; } else { termQuery = new TermQuery ( termQueryTerm ) ; } return new BooleanClause ( termQuery , BooleanClause . Occur . MUST ) ; } private String simplifyRegex ( String regex ) { return regex . replace ( "(?:" , "(" ) . replace ( "\\d" , "[0-9]" ) . replace ( "\\w" , "[a-zA-Z_0-9]" ) ; } private boolean needsSimplification ( String regex ) { return regex . contains ( "(?:" ) || regex . contains ( "\\d" ) || regex . contains ( "\\w" ) ; } @ Nullable private BooleanClause getPosQueryOrNull ( PatternToken patternToken , String pos ) { if ( pos == null || pos . isEmpty ( ) ) { return null ; } final Query posQuery ; final Term posQueryTerm ; if ( patternToken . getPOSNegation ( ) || patternToken . getMinOccurrence ( ) == 0 ) { return null ; } else if ( patternToken . isPOStagRegularExpression ( ) ) { posQueryTerm = getQueryTerm ( patternToken , POS_PREFIX + "(" , pos , ")" ) ; posQuery = getRegexQuery ( posQueryTerm , pos , patternToken ) ; } else { posQueryTerm = getQueryTerm ( patternToken , POS_PREFIX , pos , "" ) ; posQuery = new TermQuery ( posQueryTerm ) ; } return new BooleanClause ( posQuery , BooleanClause . Occur . MUST ) ; } private Term getTermQueryTerm ( PatternToken patternToken , String str ) { if ( patternToken . isCaseSensitive ( ) ) { return new Term ( FIELD_NAME , str ) ; } else { return new Term ( FIELD_NAME_LOWERCASE , str . toLowerCase ( ) ) ; } } private Term getQueryTerm ( PatternToken patternToken , String prefix , String str , String suffix ) { if ( patternToken . isCaseSensitive ( ) ) { return new Term ( FIELD_NAME , prefix + str + suffix ) ; } else { return new Term ( FIELD_NAME_LOWERCASE , prefix . toLowerCase ( ) + str . toLowerCase ( ) + suffix . toLowerCase ( ) ) ; } } private Query getRegexQuery ( Term term , String str , PatternToken patternToken ) { try { if ( needsSimplification ( str ) ) { Term newTerm = new Term ( term . field ( ) , simplifyRegex ( term . text ( ) ) ) ; return new RegexpQuery ( newTerm ) ; } if ( str . contains ( "?iu" ) || str . contains ( "?-i" ) ) { return getFallbackRegexQuery ( str , patternToken ) ; } return new RegexpQuery ( term ) ; } catch ( IllegalArgumentException e ) { return getFallbackRegexQuery ( str , patternToken ) ; } } private RegexQuery getFallbackRegexQuery ( String str , PatternToken patternToken ) { final RegexQuery query = new RegexQuery ( new Term ( patternToken . isCaseSensitive ( ) ? FIELD_NAME : FIELD_NAME_LOWERCASE , str ) ) ; query . setRegexImplementation ( new JavaUtilRegexCapabilities ( JavaUtilRegexCapabilities . FLAG_CASE_INSENSITIVE ) ) ; return query ; } private void checkUnsupportedElement ( PatternToken patternPatternToken ) throws UnsupportedPatternRuleException { if ( patternPatternToken . hasOrGroup ( ) ) { throw new UnsupportedPatternRuleException ( "<or> not yet supported." ) ; } if ( patternPatternToken . isUnified ( ) ) { throw new UnsupportedPatternRuleException ( "Elements with unified tokens are not supported." ) ; } if ( patternPatternToken . getString ( ) . matches ( "\\\\\\d+" ) ) { throw new UnsupportedPatternRuleException ( "Elements with only match references (e.g. \\1) are not supported." ) ; } } }
package org . languagetool . dev . index ; import java . io . Reader ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . util . Version ; import org . languagetool . JLanguageTool ; public final class LanguageToolAnalyzer extends Analyzer { private final JLanguageTool languageTool ; private final boolean toLowerCase ; private final Version luceneVersion ; public LanguageToolAnalyzer ( Version luceneVersion , JLanguageTool languageTool , boolean toLowerCase ) { super ( ) ; this . luceneVersion = luceneVersion ; this . languageTool = languageTool ; this . toLowerCase = toLowerCase ; } @ Override protected TokenStreamComponents createComponents ( String s , Reader reader ) { final Tokenizer tokenizer = new AnyCharTokenizer ( luceneVersion , reader ) ; final TokenStream result = new LanguageToolFilter ( tokenizer , languageTool , toLowerCase ) ; return new TokenStreamComponents ( tokenizer , result ) ; } }
package org . languagetool . dev . wikipedia ; import javax . xml . stream . XMLEventReader ; import javax . xml . stream . XMLInputFactory ; import javax . xml . stream . XMLStreamConstants ; import javax . xml . stream . XMLStreamException ; import javax . xml . stream . events . XMLEvent ; import java . io . FileInputStream ; import java . io . FileNotFoundException ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; class IpaExtractor { private static final Pattern FULL_IPA_PATTERN = Pattern . compile ( "'''?(.*?)'''?\\s+\\[?\\{\\{IPA\\|([^}]*)\\}\\}" ) ; private static final Pattern IPA_PATTERN = Pattern . compile ( "\\{\\{IPA\\|([^}]*)\\}\\}" ) ; private int articleCount = 0 ; private int ipaCount = 0 ; public static void main ( String [ ] args ) throws XMLStreamException , FileNotFoundException { if ( args . length == 0 ) { System . out . println ( "Usage: " + IpaExtractor . class . getSimpleName ( ) + " <xml-dump...>" ) ; System . exit ( 1 ) ; } IpaExtractor extractor = new IpaExtractor ( ) ; for ( String filename : args ) { FileInputStream fis = new FileInputStream ( filename ) ; extractor . run ( fis ) ; } System . err . println ( "articleCount: " + extractor . articleCount ) ; System . err . println ( "IPA count: " + extractor . ipaCount ) ; } private void run ( FileInputStream fis ) throws XMLStreamException { XMLInputFactory factory = XMLInputFactory . newInstance ( ) ; XMLEventReader reader = factory . createXMLEventReader ( fis ) ; String title = null ; while ( reader . hasNext ( ) ) { XMLEvent event = reader . nextEvent ( ) ; if ( event . getEventType ( ) == XMLStreamConstants . START_ELEMENT ) { String elementName = event . asStartElement ( ) . getName ( ) . getLocalPart ( ) ; switch ( elementName ) { case "title" : XMLEvent nextEvent = reader . nextEvent ( ) ; title = nextEvent . asCharacters ( ) . getData ( ) ; articleCount ++ ; break ; case "text" : ipaCount += handleTextElement ( title , reader ) ; break ; } } } } private int handleTextElement ( String title , XMLEventReader reader ) throws XMLStreamException { XMLEvent event = reader . nextEvent ( ) ; StringBuilder sb = new StringBuilder ( ) ; while ( event . isCharacters ( ) ) { sb . append ( event . asCharacters ( ) . getData ( ) ) ; event = reader . nextEvent ( ) ; } String wikiText = sb . toString ( ) ; int index = wikiText . indexOf ( "{{IPA" ) ; if ( index != - 1 ) { Matcher matcher = FULL_IPA_PATTERN . matcher ( wikiText ) ; if ( matcher . find ( ) ) { System . out . println ( title + ": " + matcher . group ( 1 ) + " -> " + matcher . group ( 2 ) ) ; return 1 ; } else { Matcher matcher2 = IPA_PATTERN . matcher ( wikiText ) ; if ( matcher2 . find ( ) ) { System . out . println ( title + ": " + matcher2 . group ( 1 ) ) ; return 1 ; } else { System . out . println ( title + ": (no pattern found)" ) ; } } } return 0 ; } }
package org . languagetool . dev . wikipedia ; import xtc . tree . Location ; public class LocationHelper { private LocationHelper ( ) { } public static int absolutePositionFor ( Location location , String text ) { int line = 1 ; int col = 1 ; int pos = 0 ; int ignoreLevel = 0 ; boolean inReference = false ; final StringBuilder relevantLine = new StringBuilder ( ) ; for ( int i = 0 ; i < text . length ( ) ; i ++ ) { char ch = text . charAt ( i ) ; if ( line == location . line ) { relevantLine . append ( ch ) ; } if ( line == location . line && col == location . column ) { return pos ; } char prevCh = i > 0 ? text . charAt ( i - 1 ) : '-' ; if ( isReferenceStart ( text , i ) ) { ignoreLevel ++ ; inReference = true ; } else if ( inReference && ( isFullReferenceEndTag ( text , i ) || isShortReferenceEndTag ( text , i ) ) ) { ignoreLevel -- ; inReference = false ; if ( isShortReferenceEndTag ( text , i ) ) { col ++ ; } } else if ( isHtmlCommentStart ( text , i ) ) { ignoreLevel ++ ; } else if ( isHtmlCommentEnd ( text , i ) ) { ignoreLevel -- ; } else if ( ch == '}' && prevCh == '}' ) { if ( ignoreLevel > 0 ) { ignoreLevel -- ; } } else if ( ch == '{' && prevCh == '{' ) { ignoreLevel ++ ; } else if ( ch == '\n' && ignoreLevel == 0 ) { line ++ ; col = 1 ; } else if ( ignoreLevel == 0 ) { col ++ ; } pos ++ ; } if ( line == location . line && col == location . column ) { return pos ; } throw new RuntimeException ( "Could not find location " + location + " in text. " + "Max line/col was: " + line + "/" + col + ", Content of relevant line (" + location . line + "): '" + relevantLine + "' (" + relevantLine . length ( ) + " chars)" ) ; } private static boolean isReferenceStart ( String text , int i ) { return i < text . length ( ) - 4 && text . substring ( i , i + 4 ) . equals ( "<ref" ) ; } private static boolean isFullReferenceEndTag ( String text , int i ) { return i < text . length ( ) - 6 && text . substring ( i , i + 6 ) . equals ( "</ref>" ) ; } private static boolean isShortReferenceEndTag ( String text , int i ) { return i < text . length ( ) - 2 && text . substring ( i , i + 2 ) . equals ( "/>" ) ; } private static boolean isHtmlCommentStart ( String text , int i ) { return i < text . length ( ) - 4 && text . substring ( i , i + 4 ) . equals ( "<!--" ) ; } private static boolean isHtmlCommentEnd ( String text , int i ) { return i < text . length ( ) - 3 && text . substring ( i , i + 3 ) . equals ( "-->" ) ; } }
package org . languagetool . dev . wikipedia ; import java . io . IOException ; import java . util . HashMap ; import java . util . LinkedList ; import java . util . Map ; import java . util . regex . Pattern ; import de . fau . cs . osr . ptk . common . ast . * ; import org . apache . commons . lang . StringEscapeUtils ; import org . sweble . wikitext . engine . Page ; import org . sweble . wikitext . engine . PageTitle ; import org . sweble . wikitext . engine . utils . SimpleWikiConfiguration ; import org . sweble . wikitext . lazy . LinkTargetException ; import org . sweble . wikitext . lazy . encval . IllegalCodePoint ; import org . sweble . wikitext . lazy . parser . * ; import org . sweble . wikitext . lazy . preprocessor . TagExtension ; import org . sweble . wikitext . lazy . preprocessor . Template ; import org . sweble . wikitext . lazy . preprocessor . TemplateArgument ; import org . sweble . wikitext . lazy . preprocessor . TemplateParameter ; import org . sweble . wikitext . lazy . preprocessor . XmlComment ; import org . sweble . wikitext . lazy . utils . XmlCharRef ; import org . sweble . wikitext . lazy . utils . XmlEntityRef ; import de . fau . cs . osr . ptk . common . Visitor ; import xtc . tree . Locatable ; import xtc . tree . Location ; public class TextConverter extends Visitor { private static final Pattern ws = Pattern . compile ( "\\s+" ) ; private final SimpleWikiConfiguration config ; private final int wrapCol ; private Map < Integer , Location > mapping = new HashMap < > ( ) ; private StringBuilder sb ; private StringBuilder line ; private boolean pastBod ; private int needNewlines ; private boolean needSpace ; private boolean noWrap ; private LinkedList < Integer > sections ; private boolean enableMapping = true ; public TextConverter ( SimpleWikiConfiguration config , int wrapCol ) { this . config = config ; this . wrapCol = wrapCol ; } public void enableMapping ( boolean enableMapping ) { this . enableMapping = enableMapping ; } public Map < Integer , Location > getMapping ( ) { if ( ! enableMapping ) { throw new IllegalStateException ( "enableMapping not activated" ) ; } return mapping ; } @ Override protected boolean before ( AstNode node ) { sb = new StringBuilder ( ) ; line = new StringBuilder ( ) ; mapping = new HashMap < > ( ) ; pastBod = false ; needNewlines = 0 ; needSpace = false ; noWrap = false ; sections = new LinkedList < > ( ) ; return super . before ( node ) ; } @ Override protected Object after ( AstNode node , Object result ) { finishLine ( ) ; return sb . toString ( ) ; } private boolean inGallery = false ; private boolean inSource = false ; public void visit ( AstNode n ) { Object data = n . getAttribute ( "RTD" ) ; if ( data != null && data instanceof RtData ) { RtData rtd = ( RtData ) data ; Object [ ] [ ] rts = rtd . getRts ( ) ; if ( rts . length > 0 && rts [ 0 ] . length > 0 ) { Object rtsElem = rts [ 0 ] [ 0 ] ; if ( "<gallery" . equals ( rtsElem ) ) { inGallery = true ; } else if ( "<source" . equals ( rtsElem ) ) { inSource = true ; } else if ( "</gallery>" . equals ( rtsElem ) ) { inGallery = false ; } else if ( "</source>" . equals ( rtsElem ) ) { inSource = false ; } } } } public void visit ( NodeList n ) { iterate ( n ) ; } public void visit ( Itemization e ) { iterate ( e . getContent ( ) ) ; } public void visit ( ItemizationItem i ) { newline ( 2 ) ; iterate ( i . getContent ( ) ) ; } public void visit ( Enumeration e ) { iterate ( e . getContent ( ) ) ; } public void visit ( EnumerationItem item ) { newline ( 2 ) ; iterate ( item . getContent ( ) ) ; } public void visit ( Page p ) { iterate ( p . getContent ( ) ) ; } public void visit ( Text text ) { if ( inGallery || inSource ) { return ; } addMapping ( text ) ; write ( text . getContent ( ) ) ; } public void visit ( Whitespace w ) { addMapping ( w ) ; write ( " " ) ; } public void visit ( Bold b ) { iterate ( b . getContent ( ) ) ; } public void visit ( Italics i ) { iterate ( i . getContent ( ) ) ; } public void visit ( XmlCharRef cr ) { addMapping ( cr ) ; write ( Character . toChars ( cr . getCodePoint ( ) ) ) ; } public void visit ( XmlEntityRef er ) { addMapping ( er ) ; if ( "nbsp" . equals ( er . getName ( ) ) ) { write ( '\u00A0' ) ; } else { String ch = StringEscapeUtils . unescapeHtml ( "&" + er . getName ( ) + ";" ) ; write ( ch ) ; } } public void visit ( Url url ) { addMapping ( url ) ; write ( url . getProtocol ( ) ) ; write ( ':' ) ; write ( url . getPath ( ) ) ; } public void visit ( ExternalLink link ) { StringBuilder out = new StringBuilder ( ) ; for ( AstNode node : link . getTitle ( ) ) { try { out . append ( toText ( node ) ) ; } catch ( IOException e ) { throw new RuntimeException ( "Error getting content of external link " + link , e ) ; } } addMapping ( link ) ; write ( out . toString ( ) ) ; } public void visit ( InternalLink link ) { try { PageTitle page = PageTitle . make ( config , link . getTarget ( ) ) ; if ( page . getNamespace ( ) . equals ( config . getNamespace ( "Category" ) ) ) return ; } catch ( LinkTargetException e ) { } addMapping ( link ) ; write ( link . getPrefix ( ) ) ; if ( link . getTitle ( ) . getContent ( ) == null || link . getTitle ( ) . getContent ( ) . isEmpty ( ) ) { addMapping ( link ) ; write ( link . getTarget ( ) ) ; } else { addMapping ( link ) ; iterate ( link . getTitle ( ) ) ; } write ( link . getPostfix ( ) ) ; } public void visit ( Section s ) { finishLine ( ) ; StringBuilder saveSb = sb ; boolean saveNoWrap = noWrap ; sb = new StringBuilder ( ) ; noWrap = true ; iterate ( s . getTitle ( ) ) ; finishLine ( ) ; String title = sb . toString ( ) . trim ( ) ; sb = saveSb ; if ( s . getLevel ( ) >= 1 ) { while ( sections . size ( ) > s . getLevel ( ) ) sections . removeLast ( ) ; while ( sections . size ( ) < s . getLevel ( ) ) sections . add ( 1 ) ; StringBuilder sb2 = new StringBuilder ( ) ; for ( int i = 0 ; i < sections . size ( ) ; ++ i ) { if ( i < 1 ) continue ; sb2 . append ( sections . get ( i ) ) ; sb2 . append ( '.' ) ; } if ( sb2 . length ( ) > 0 ) sb2 . append ( ' ' ) ; sb2 . append ( title ) ; title = sb2 . toString ( ) ; } newline ( 2 ) ; addMapping ( s ) ; write ( title ) ; newline ( 2 ) ; noWrap = saveNoWrap ; iterate ( s . getBody ( ) ) ; while ( sections . size ( ) > s . getLevel ( ) ) sections . removeLast ( ) ; sections . add ( sections . removeLast ( ) + 1 ) ; } public void visit ( Paragraph p ) { iterate ( p . getContent ( ) ) ; newline ( 2 ) ; } public void visit ( HorizontalRule hr ) { newline ( 2 ) ; } public void visit ( XmlElement e ) { if ( e . getName ( ) . equalsIgnoreCase ( "br" ) ) { newline ( 1 ) ; } else { iterate ( e . getBody ( ) ) ; } } public void visit ( ImageLink n ) { } public void visit ( IllegalCodePoint n ) { } public void visit ( XmlComment n ) { } public void visit ( Template n ) { } public void visit ( TemplateArgument n ) { } public void visit ( TemplateParameter n ) { } public void visit ( TagExtension n ) { } public void visit ( MagicWord n ) { } private String toText ( AstNode node ) throws IOException { StringBuilder out = new StringBuilder ( ) ; if ( node instanceof StringContentNode ) { out . append ( ( ( StringContentNode ) node ) . getContent ( ) ) ; } else if ( node instanceof ContentNode ) { NodeList nodes = ( ( ContentNode ) node ) . getContent ( ) ; for ( AstNode subNode : nodes ) { out . append ( toText ( subNode ) ) ; } } return out . toString ( ) ; } private void addMapping ( Locatable loc ) { addMapping ( loc , 0 ) ; } private void addMapping ( Locatable loc , int columnCorrection ) { if ( ! enableMapping ) { return ; } String contentSoFar = sb . toString ( ) + line ; int textPos = contentSoFar . length ( ) + needNewlines + 1 ; if ( loc . hasLocation ( ) ) { Location location = loc . getLocation ( ) ; mapping . put ( textPos , new Location ( location . file , location . line , location . column + columnCorrection ) ) ; } } private void newline ( int num ) { if ( pastBod ) { if ( num > needNewlines ) needNewlines = num ; } } private void wantSpace ( ) { if ( pastBod ) needSpace = true ; } private void finishLine ( ) { sb . append ( line ) ; line . setLength ( 0 ) ; } private void writeNewlines ( int num ) { finishLine ( ) ; for ( int i = 0 ; i < num ; i ++ ) { sb . append ( '\n' ) ; } needNewlines = 0 ; needSpace = false ; } private void writeWord ( String s ) { int length = s . length ( ) ; if ( length == 0 ) return ; if ( ! noWrap && needNewlines <= 0 ) { if ( needSpace ) length += 1 ; if ( line . length ( ) + length >= wrapCol && line . length ( ) > 0 ) writeNewlines ( 1 ) ; } if ( needSpace && needNewlines <= 0 ) line . append ( ' ' ) ; if ( needNewlines > 0 ) writeNewlines ( needNewlines ) ; needSpace = false ; pastBod = true ; line . append ( s ) ; } private void write ( String s ) { if ( s . isEmpty ( ) ) return ; if ( Character . isSpaceChar ( s . charAt ( 0 ) ) ) wantSpace ( ) ; String [ ] words = ws . split ( s ) ; for ( int i = 0 ; i < words . length ; ) { writeWord ( words [ i ] ) ; if ( ++ i < words . length ) wantSpace ( ) ; } if ( Character . isSpaceChar ( s . charAt ( s . length ( ) - 1 ) ) ) wantSpace ( ) ; } private void write ( char [ ] cs ) { write ( String . valueOf ( cs ) ) ; } private void write ( char ch ) { writeWord ( String . valueOf ( ch ) ) ; } private void write ( int num ) { writeWord ( String . valueOf ( num ) ) ; } }
package org . languagetool . dev . wikipedia ; import org . languagetool . rules . RuleMatch ; public class RuleMatchApplication { private final RuleMatch ruleMatch ; private final String text ; private final String textWithCorrection ; private final ErrorMarker errorMarker ; private final boolean hasRealReplacement ; static RuleMatchApplication forMatchWithReplacement ( RuleMatch ruleMatch , String text , String textWithCorrection , ErrorMarker errorMarker ) { return new RuleMatchApplication ( ruleMatch , text , textWithCorrection , errorMarker , true ) ; } static RuleMatchApplication forMatchWithoutReplacement ( RuleMatch ruleMatch , String text , String textWithCorrection , ErrorMarker errorMarker ) { return new RuleMatchApplication ( ruleMatch , text , textWithCorrection , errorMarker , false ) ; } private RuleMatchApplication ( RuleMatch ruleMatch , String text , String textWithCorrection , ErrorMarker errorMarker , boolean hasRealReplacement ) { if ( ! textWithCorrection . contains ( errorMarker . getStartMarker ( ) ) ) { throw new IllegalArgumentException ( "No start error marker (" + errorMarker . getStartMarker ( ) + ") found in text with correction" ) ; } if ( ! textWithCorrection . contains ( errorMarker . getEndMarker ( ) ) ) { throw new IllegalArgumentException ( "No end error marker (" + errorMarker . getEndMarker ( ) + ") found in text with correction" ) ; } this . ruleMatch = ruleMatch ; this . text = text ; this . textWithCorrection = textWithCorrection ; this . errorMarker = errorMarker ; this . hasRealReplacement = hasRealReplacement ; } public String getOriginalErrorContext ( int contextSize ) { return getContext ( text , contextSize ) ; } public String getCorrectedErrorContext ( int contextSize ) { return getContext ( textWithCorrection , contextSize ) ; } private String getContext ( String text , int contextSize ) { int errorStart = textWithCorrection . indexOf ( errorMarker . getStartMarker ( ) ) ; int errorEnd = textWithCorrection . indexOf ( errorMarker . getEndMarker ( ) ) ; int errorContextStart = Math . max ( errorStart - contextSize , 0 ) ; int errorContentEnd = Math . min ( errorEnd + contextSize , text . length ( ) ) ; return text . substring ( errorContextStart , errorContentEnd ) ; } public RuleMatch getRuleMatch ( ) { return ruleMatch ; } public String getOriginalText ( ) { return text ; } public String getTextWithCorrection ( ) { return textWithCorrection ; } public ErrorMarker getErrorMarker ( ) { return errorMarker ; } public boolean hasRealReplacement ( ) { return hasRealReplacement ; } @ Override public String toString ( ) { return ruleMatch . toString ( ) ; } }
package org . languagetool . dev . wikipedia ; public interface TextMapFilter { PlainTextMapping filter ( String text ) ; }
package org . languagetool . dev . wikipedia ; public class PageNotFoundException extends Exception { public PageNotFoundException ( String message ) { super ( message ) ; } }
package org . languagetool . dev . wikipedia ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . RuleMatch ; import xtc . tree . Location ; import java . util . ArrayList ; import java . util . List ; public class SuggestionReplacer { private final PlainTextMapping textMapping ; private final String originalText ; private final ErrorMarker errorMarker ; public SuggestionReplacer ( PlainTextMapping textMapping , String originalText ) { this ( textMapping , originalText , new ErrorMarker ( "<<span class=\"error\">>" , "<</span>>" ) ) ; } public SuggestionReplacer ( PlainTextMapping textMapping , String originalText , ErrorMarker errorMarker ) { this . textMapping = textMapping ; this . originalText = originalText ; this . errorMarker = errorMarker ; } public List < RuleMatchApplication > applySuggestionsToOriginalText ( RuleMatch match ) { final List < String > replacements = new ArrayList < > ( match . getSuggestedReplacements ( ) ) ; boolean hasRealReplacements = replacements . size ( ) > 0 ; if ( ! hasRealReplacements ) { String plainText = textMapping . getPlainText ( ) ; replacements . add ( plainText . substring ( match . getFromPos ( ) , match . getToPos ( ) ) ) ; } final List < RuleMatchApplication > ruleMatchApplications = new ArrayList < > ( ) ; final Location fromPosLocation = textMapping . getOriginalTextPositionFor ( match . getFromPos ( ) + 1 ) ; final Location toPosLocation = textMapping . getOriginalTextPositionFor ( match . getToPos ( ) + 1 ) ; final int fromPos = LocationHelper . absolutePositionFor ( fromPosLocation , originalText ) ; final int toPos = LocationHelper . absolutePositionFor ( toPosLocation , originalText ) ; for ( String replacement : replacements ) { final String errorText = textMapping . getPlainText ( ) . substring ( match . getFromPos ( ) , match . getToPos ( ) ) ; final int contextFrom = findNextWhitespaceToTheLeft ( originalText , fromPos ) ; final int contextTo = findNextWhitespaceToTheRight ( originalText , toPos ) ; final String context = originalText . substring ( contextFrom , contextTo ) ; final String text = originalText . substring ( 0 , contextFrom ) + errorMarker . getStartMarker ( ) + context + errorMarker . getEndMarker ( ) + originalText . substring ( contextTo ) ; String newContext ; if ( StringUtils . countMatches ( context , errorText ) == 1 ) { newContext = context . replace ( errorText , replacement ) ; } else { newContext = context ; hasRealReplacements = false ; } final String newText = originalText . substring ( 0 , contextFrom ) + errorMarker . getStartMarker ( ) + newContext + errorMarker . getEndMarker ( ) + originalText . substring ( contextTo ) ; final RuleMatchApplication application ; if ( hasRealReplacements ) { application = RuleMatchApplication . forMatchWithReplacement ( match , text , newText , errorMarker ) ; } else { application = RuleMatchApplication . forMatchWithoutReplacement ( match , text , newText , errorMarker ) ; } ruleMatchApplications . add ( application ) ; } return ruleMatchApplications ; } int findNextWhitespaceToTheRight ( String text , int position ) { for ( int i = position ; i < text . length ( ) ; i ++ ) { if ( Character . isWhitespace ( text . charAt ( i ) ) ) { return i ; } } return text . length ( ) ; } int findNextWhitespaceToTheLeft ( String text , int position ) { for ( int i = position ; i >= 0 ; i -- ) { if ( Character . isWhitespace ( text . charAt ( i ) ) ) { return i + 1 ; } } return 0 ; } }
package org . languagetool . dev . wikipedia ; import java . io . IOException ; import java . io . InputStream ; import java . io . StringReader ; import java . net . URL ; import java . net . URLEncoder ; import java . util . ArrayList ; import java . util . List ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import javax . xml . parsers . SAXParser ; import javax . xml . parsers . SAXParserFactory ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . MultiThreadedJLanguageTool ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . tools . StringTools ; import org . xml . sax . Attributes ; import org . xml . sax . InputSource ; import org . xml . sax . SAXException ; import org . xml . sax . helpers . DefaultHandler ; public class WikipediaQuickCheck { private static final Pattern WIKIPEDIA_URL_REGEX = Pattern . compile ( "https?://(..)\\.wikipedia\\.org/wiki/(.*)" ) ; private static final Pattern SECURE_WIKIPEDIA_URL_REGEX = Pattern . compile ( "https://secure\\.wikimedia\\.org/wikipedia/(..)/wiki/(.*)" ) ; private List < String > disabledRuleIds = new ArrayList < > ( ) ; public String getMediaWikiContent ( URL wikipediaUrl ) throws IOException { final Language lang = getLanguage ( wikipediaUrl ) ; final String pageTitle = getPageTitle ( wikipediaUrl ) ; final String apiUrl = "https://" + lang . getShortName ( ) + ".wikipedia.org/w/api.php?titles=" + URLEncoder . encode ( pageTitle , "utf-8" ) + "&action=query&prop=revisions&rvprop=content|timestamp&format=xml" ; return getContent ( new URL ( apiUrl ) ) ; } public Language getLanguage ( URL url ) { final Matcher matcher = getUrlMatcher ( url . toString ( ) ) ; return Languages . getLanguageForShortName ( matcher . group ( 1 ) ) ; } public String getPageTitle ( URL url ) { final Matcher matcher = getUrlMatcher ( url . toString ( ) ) ; return matcher . group ( 2 ) ; } private Matcher getUrlMatcher ( String url ) { final Matcher matcher1 = WIKIPEDIA_URL_REGEX . matcher ( url ) ; final Matcher matcher2 = SECURE_WIKIPEDIA_URL_REGEX . matcher ( url ) ; if ( matcher1 . matches ( ) ) { return matcher1 ; } else if ( matcher2 . matches ( ) ) { return matcher2 ; } throw new RuntimeException ( "URL does not seem to be a valid Wikipedia URL: " + url ) ; } public void setDisabledRuleIds ( List < String > ruleIds ) { disabledRuleIds = ruleIds ; } public List < String > getDisabledRuleIds ( ) { return disabledRuleIds ; } public MarkupAwareWikipediaResult checkPage ( URL url ) throws IOException , PageNotFoundException { return checkPage ( url , null ) ; } public MarkupAwareWikipediaResult checkPage ( URL url , ErrorMarker errorMarker ) throws IOException , PageNotFoundException { validateWikipediaUrl ( url ) ; final WikipediaQuickCheck check = new WikipediaQuickCheck ( ) ; final String xml = check . getMediaWikiContent ( url ) ; final MediaWikiContent wikiContent = getRevisionContent ( xml ) ; final String content = wikiContent . getContent ( ) ; if ( content . trim ( ) . isEmpty ( ) ) { throw new PageNotFoundException ( "No content found at '" + url + "'" ) ; } if ( content . toLowerCase ( ) . contains ( "#redirect" ) ) { throw new PageNotFoundException ( "No content but redirect found at '" + url + "'" ) ; } return checkWikipediaMarkup ( url , wikiContent , getLanguage ( url ) , errorMarker ) ; } MarkupAwareWikipediaResult checkWikipediaMarkup ( URL url , MediaWikiContent wikiContent , Language language , ErrorMarker errorMarker ) throws IOException { final SwebleWikipediaTextFilter filter = new SwebleWikipediaTextFilter ( ) ; final PlainTextMapping mapping = filter . filter ( wikiContent . getContent ( ) ) ; final MultiThreadedJLanguageTool langTool = getLanguageTool ( language ) ; final List < AppliedRuleMatch > appliedMatches = new ArrayList < > ( ) ; final List < RuleMatch > matches = langTool . check ( mapping . getPlainText ( ) ) ; langTool . shutdown ( ) ; int internalErrors = 0 ; for ( RuleMatch match : matches ) { final SuggestionReplacer replacer = errorMarker != null ? new SuggestionReplacer ( mapping , wikiContent . getContent ( ) , errorMarker ) : new SuggestionReplacer ( mapping , wikiContent . getContent ( ) ) ; try { final List < RuleMatchApplication > ruleMatchApplications = replacer . applySuggestionsToOriginalText ( match ) ; appliedMatches . add ( new AppliedRuleMatch ( match , ruleMatchApplications ) ) ; } catch ( Exception e ) { System . err . println ( "Failed to apply suggestion for rule match '" + match + "' for URL " + url + ": " + e ) ; internalErrors ++ ; } } return new MarkupAwareWikipediaResult ( wikiContent , appliedMatches , internalErrors ) ; } public WikipediaQuickCheckResult checkPage ( String plainText , Language lang ) throws IOException { final MultiThreadedJLanguageTool langTool = getLanguageTool ( lang ) ; final List < RuleMatch > ruleMatches = langTool . check ( plainText ) ; langTool . shutdown ( ) ; return new WikipediaQuickCheckResult ( plainText , ruleMatches , lang . getShortName ( ) ) ; } public void validateWikipediaUrl ( URL wikipediaUrl ) { getUrlMatcher ( wikipediaUrl . toString ( ) ) ; } public String getPlainText ( String completeWikiContent ) { final MediaWikiContent wikiContent = getRevisionContent ( completeWikiContent ) ; final String cleanedWikiContent = removeWikipediaLinks ( wikiContent . getContent ( ) ) ; final TextMapFilter filter = new SwebleWikipediaTextFilter ( ) ; return filter . filter ( cleanedWikiContent ) . getPlainText ( ) ; } public PlainTextMapping getPlainTextMapping ( String completeWikiContent ) { final MediaWikiContent wikiContent = getRevisionContent ( completeWikiContent ) ; final SwebleWikipediaTextFilter filter = new SwebleWikipediaTextFilter ( ) ; return filter . filter ( wikiContent . getContent ( ) ) ; } String removeWikipediaLinks ( String wikiContent ) { return wikiContent . replaceAll ( "\\[\\[[a-z]{2,6}:.*?\\]\\]" , "" ) . replaceAll ( "\\[\\[:?(Category|Categoria|Categoría|Catégorie|Kategorie):.*?\\]\\]" , "" ) . replaceAll ( "(File|Fitxer|Fichero|Ficheiro|Fichier|Datei):.*?\\.(png|jpg|svg|jpeg|tiff|gif|PNG|JPG|SVG|JPEG|TIFF|GIF)\\|((thumb|miniatur)\\|)?((right|left)\\|)?" , "" ) ; } private MediaWikiContent getRevisionContent ( String completeWikiContent ) { final SAXParserFactory factory = SAXParserFactory . newInstance ( ) ; final SAXParser saxParser ; final RevisionContentHandler handler = new RevisionContentHandler ( ) ; try { saxParser = factory . newSAXParser ( ) ; saxParser . parse ( new InputSource ( new StringReader ( completeWikiContent ) ) , handler ) ; } catch ( Exception e ) { throw new RuntimeException ( "Could not parse XML: " + completeWikiContent , e ) ; } return new MediaWikiContent ( handler . getRevisionContent ( ) , handler . getTimestamp ( ) ) ; } private MultiThreadedJLanguageTool getLanguageTool ( Language lang ) throws IOException { final MultiThreadedJLanguageTool langTool = new MultiThreadedJLanguageTool ( lang ) ; enableWikipediaRules ( langTool ) ; for ( String disabledRuleId : disabledRuleIds ) { langTool . disableRule ( disabledRuleId ) ; } disableSpellingRules ( langTool ) ; return langTool ; } private void enableWikipediaRules ( JLanguageTool langTool ) { List < Rule > allRules = langTool . getAllRules ( ) ; for ( Rule rule : allRules ) { if ( rule . getCategory ( ) . getName ( ) . equals ( "Wikipedia" ) ) { langTool . enableDefaultOffRule ( rule . getId ( ) ) ; } } } private void disableSpellingRules ( JLanguageTool languageTool ) { final List < Rule > allActiveRules = languageTool . getAllActiveRules ( ) ; for ( Rule rule : allActiveRules ) { if ( rule . isDictionaryBasedSpellingRule ( ) ) { languageTool . disableRule ( rule . getId ( ) ) ; } } } private String getContent ( URL wikipediaUrl ) throws IOException { final InputStream contentStream = ( InputStream ) wikipediaUrl . getContent ( ) ; return StringTools . streamToString ( contentStream , "UTF-8" ) ; } public static void main ( String [ ] args ) throws IOException , PageNotFoundException { if ( args . length != 1 ) { System . out . println ( "Usage: " + WikipediaQuickCheck . class . getName ( ) + " <url>" ) ; System . exit ( 1 ) ; } WikipediaQuickCheck check = new WikipediaQuickCheck ( ) ; String urlString = args [ 0 ] ; MarkupAwareWikipediaResult result = check . checkPage ( new URL ( urlString ) , new ErrorMarker ( "***" , "***" ) ) ; int errorCount = 0 ; for ( AppliedRuleMatch match : result . getAppliedRuleMatches ( ) ) { RuleMatchApplication matchApplication = match . getRuleMatchApplications ( ) . get ( 0 ) ; RuleMatch ruleMatch = match . getRuleMatch ( ) ; Rule rule = ruleMatch . getRule ( ) ; System . out . println ( "" ) ; String message = ruleMatch . getMessage ( ) . replace ( "<suggestion>" , "'" ) . replace ( "</suggestion>" , "'" ) ; errorCount ++ ; System . out . print ( errorCount + ". " + message ) ; if ( rule instanceof PatternRule ) { System . out . println ( " (" + rule . getId ( ) + "[" + ( ( PatternRule ) rule ) . getSubId ( ) + "])" ) ; } else { System . out . println ( " (" + rule . getId ( ) + ")" ) ; } System . out . println ( " ..." + matchApplication . getOriginalErrorContext ( 50 ) . replace ( "\n" , "\\n" ) + "..." ) ; } } class RevisionContentHandler extends DefaultHandler { private final StringBuilder revisionText = new StringBuilder ( ) ; private String timestamp ; private boolean inRevision = false ; @ Override public void startElement ( final String namespaceURI , final String lName , final String qName , final Attributes attrs ) throws SAXException { if ( "rev" . equals ( qName ) ) { timestamp = attrs . getValue ( "timestamp" ) ; inRevision = true ; } } @ Override public void endElement ( final String namespaceURI , final String sName , final String qName ) throws SAXException { if ( "rev" . equals ( qName ) ) { inRevision = false ; } } @ Override public void characters ( final char [ ] buf , final int offset , final int len ) { final String s = new String ( buf , offset , len ) ; if ( inRevision ) { revisionText . append ( s ) ; } } public String getRevisionContent ( ) { return revisionText . toString ( ) ; } public String getTimestamp ( ) { return timestamp ; } } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Dutch ; public class DutchConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Dutch ( ) ; } @ Override protected String createSampleText ( ) { return "lekkere frikandel" ; } }
package org . languagetool . dev . wikipedia ; import org . languagetool . JLanguageTool ; import org . languagetool . dev . dumpcheck . SentenceSourceChecker ; import org . languagetool . dev . dumpcheck . SentenceSourceIndexer ; import org . languagetool . dev . index . Indexer ; import org . languagetool . dev . index . Searcher ; import org . languagetool . tools . JnaTools ; import java . util . Arrays ; public class Main { public static void main ( String [ ] args ) throws Exception { JnaTools . setBugWorkaroundProperty ( ) ; if ( args . length == 0 ) { printUsageAndExit ( ) ; } else { final String [ ] remainingArgs = Arrays . copyOfRange ( args , 1 , args . length ) ; final String command = args [ 0 ] ; switch ( command ) { case "check-data" : SentenceSourceChecker . main ( remainingArgs ) ; break ; case "index-data" : SentenceSourceIndexer . main ( remainingArgs ) ; break ; case "wiki-check" : WikipediaQuickCheck . main ( remainingArgs ) ; break ; case "index" : Indexer . main ( remainingArgs ) ; break ; case "search" : Searcher . main ( remainingArgs ) ; break ; case "version" : System . out . println ( JLanguageTool . VERSION + " (" + JLanguageTool . BUILD_DATE + ")" ) ; break ; default : System . out . println ( "Error: unknown command '" + command + "'" ) ; printUsageAndExit ( ) ; break ; } } } private static void printUsageAndExit ( ) { System . out . println ( "Usage: " + Main . class . getName ( ) + " <command> <command-specific-arguments>" ) ; System . out . println ( "Where <command> is one of:" ) ; System . out . println ( " check-data - check a Wikipedia XML dump like those available from" ) ; System . out . println ( " http://dumps.wikimedia.org/backup-index.html" ) ; System . out . println ( " and/or a Tatoeba file (http://tatoeba.org)" ) ; System . out . println ( " index-data - fulltext-index a Wikipedia XML dump and/or a Tatoeba file" ) ; System . out . println ( " wiki-check - check a single Wikipedia page, fetched via the Mediawiki API" ) ; System . out . println ( " index - index a plain text file, putting the analysis in a Lucene index for faster rule match search" ) ; System . out . println ( " search - search for rule matches in an index created with 'index' or 'wiki-index'" ) ; System . out . println ( " version - print LanguageTool version number and build date" ) ; System . out . println ( "" ) ; System . out . println ( "All commands have different usages. Call them without arguments to get help." ) ; System . out . println ( "" ) ; System . out . println ( "Example for a call with valid arguments:" ) ; System . out . println ( " java -jar languagetool-wikipedia.jar wiki-check http://de.wikipedia.org/wiki/Bielefeld" ) ; System . exit ( 1 ) ; } }
package org . languagetool . dev . wikipedia ; import java . util . List ; public class MarkupAwareWikipediaResult { private final MediaWikiContent originalWikiMarkup ; private final List < AppliedRuleMatch > appliedRuleMatch ; private final int internalErrors ; public MarkupAwareWikipediaResult ( MediaWikiContent wikiContent , List < AppliedRuleMatch > appliedRuleMatch , int internalErrors ) { this . originalWikiMarkup = wikiContent ; this . appliedRuleMatch = appliedRuleMatch ; this . internalErrors = internalErrors ; } public List < AppliedRuleMatch > getAppliedRuleMatches ( ) { return appliedRuleMatch ; } public int getInternalErrorCount ( ) { return internalErrors ; } public String getOriginalWikiMarkup ( ) { return originalWikiMarkup . getContent ( ) ; } public String getLastEditTimestamp ( ) { return originalWikiMarkup . getTimestamp ( ) ; } }
package org . languagetool . dev . wikipedia ; import org . apache . commons . lang . StringUtils ; import org . sweble . wikitext . engine . CompiledPage ; import org . sweble . wikitext . engine . Compiler ; import org . sweble . wikitext . engine . PageId ; import org . sweble . wikitext . engine . PageTitle ; import org . sweble . wikitext . engine . utils . SimpleWikiConfiguration ; public class SwebleWikipediaTextFilter implements TextMapFilter { private static final int WRAP_COL = Integer . MAX_VALUE ; private final SimpleWikiConfiguration config ; private final Compiler compiler ; private final PageId pageId ; private boolean enableMapping = true ; public SwebleWikipediaTextFilter ( ) { try { config = new SimpleWikiConfiguration ( "classpath:/org/languagetool/resource/dev/SimpleWikiConfiguration.xml" ) ; compiler = new Compiler ( config ) ; final PageTitle pageTitle = PageTitle . make ( config , "fileTitle" ) ; pageId = new PageId ( pageTitle , - 1 ) ; } catch ( Exception e ) { throw new RuntimeException ( "Could not set up text filter" , e ) ; } } @ Override public PlainTextMapping filter ( String wikiText ) { try { final CompiledPage compiledPage = compiler . postprocess ( pageId , wikiText , null ) ; final TextConverter textConverter = new TextConverter ( config , WRAP_COL ) ; textConverter . enableMapping ( enableMapping ) ; final String plainText = ( String ) textConverter . go ( compiledPage . getPage ( ) ) ; if ( enableMapping ) { return new PlainTextMapping ( plainText , textConverter . getMapping ( ) ) ; } else { return new PlainTextMapping ( plainText , null ) ; } } catch ( Exception e ) { throw new RuntimeException ( "Could not extract plain text from MediaWiki syntax: '" + StringUtils . abbreviate ( wikiText , 500 ) + "'" , e ) ; } } public void enableMapping ( boolean enable ) { enableMapping = enable ; } }
package org . languagetool . dev . wikipedia ; import org . languagetool . rules . RuleMatch ; import java . util . List ; public class AppliedRuleMatch { private final RuleMatch ruleMatch ; private final List < RuleMatchApplication > ruleMatchApplications ; public AppliedRuleMatch ( RuleMatch ruleMatch , List < RuleMatchApplication > ruleMatchApplications ) { this . ruleMatch = ruleMatch ; this . ruleMatchApplications = ruleMatchApplications ; } public RuleMatch getRuleMatch ( ) { return ruleMatch ; } public List < RuleMatchApplication > getRuleMatchApplications ( ) { return ruleMatchApplications ; } @ Override public String toString ( ) { return ruleMatch + ":" + ruleMatchApplications ; } }
package org . languagetool . dev . wikipedia ; import java . util . List ; import org . languagetool . rules . RuleMatch ; public class WikipediaQuickCheckResult { private final String text ; private final String languageCode ; private final List < RuleMatch > ruleMatches ; public WikipediaQuickCheckResult ( String text , List < RuleMatch > ruleMatches , String languageCode ) { this . text = text ; this . ruleMatches = ruleMatches ; this . languageCode = languageCode ; } public String getText ( ) { return text ; } public List < RuleMatch > getRuleMatches ( ) { return ruleMatches ; } public String getLanguageCode ( ) { return languageCode ; } }
package org . languagetool . dev . wikipedia ; import java . util . Objects ; public class ErrorMarker { private final String startMarker ; private final String endMarker ; public ErrorMarker ( String startMarker , String endMarker ) { this . startMarker = Objects . requireNonNull ( startMarker ) ; this . endMarker = Objects . requireNonNull ( endMarker ) ; } public String getStartMarker ( ) { return startMarker ; } public String getEndMarker ( ) { return endMarker ; } }
package org . languagetool . dev . wikipedia ; public class MediaWikiContent { private final String content ; private final String timestamp ; public MediaWikiContent ( String content , String timestamp ) { this . content = content ; this . timestamp = timestamp ; } public String getContent ( ) { return content ; } public String getTimestamp ( ) { return timestamp ; } }
package org . languagetool . dev . wikipedia ; import xtc . tree . Location ; import java . util . Map ; public class PlainTextMapping { private final String plainText ; private final Map < Integer , Location > mapping ; public PlainTextMapping ( String plainText , Map < Integer , Location > mapping ) { this . plainText = plainText ; this . mapping = mapping ; } public String getPlainText ( ) { return plainText ; } public Map < Integer , Location > getMapping ( ) { return mapping ; } public Location getOriginalTextPositionFor ( int plainTextPosition ) { if ( plainTextPosition < 1 ) { throw new RuntimeException ( "plainTextPosition must be > 0 - its value starts at 1" ) ; } final Location origPosition = mapping . get ( plainTextPosition ) ; if ( origPosition != null ) { return origPosition ; } int minDiff = Integer . MAX_VALUE ; Location bestMatch = null ; for ( Map . Entry < Integer , Location > entry : mapping . entrySet ( ) ) { int maybeClosePosition = entry . getKey ( ) ; if ( plainTextPosition > maybeClosePosition ) { int diff = plainTextPosition - maybeClosePosition ; if ( diff >= 0 && diff < minDiff ) { bestMatch = entry . getValue ( ) ; minDiff = diff ; } } } if ( bestMatch == null ) { throw new RuntimeException ( "Could not map " + plainTextPosition + " to original position. Mapping: " + mapping ) ; } return new Location ( bestMatch . file , bestMatch . line , bestMatch . column + minDiff ) ; } }
package org . languagetool . dev . wikipedia . atom ; import java . io . FileInputStream ; import java . io . IOException ; import java . util . Properties ; class DatabaseConfig { private final String url ; private final String user ; private final String password ; DatabaseConfig ( String propFile ) throws IOException { Properties properties = new Properties ( ) ; try ( FileInputStream fis = new FileInputStream ( propFile ) ) { properties . load ( fis ) ; } this . url = getRequiredProperty ( properties , "dbUrl" ) ; this . user = getRequiredProperty ( properties , "dbUser" ) ; this . password = getRequiredProperty ( properties , "dbPassword" ) ; } DatabaseConfig ( String dbUrl , String dbUser , String dbPassword ) { this . url = dbUrl ; this . user = dbUser ; this . password = dbPassword ; } private String getRequiredProperty ( Properties properties , String propName ) { String value = properties . getProperty ( propName ) ; if ( value == null ) { throw new RuntimeException ( "Property key '" + propName + "' not found" ) ; } return value ; } String getUrl ( ) { return url ; } String getUser ( ) { return user ; } String getPassword ( ) { return password ; } }
package org . languagetool . dev . wikipedia . atom ; import java . util . ArrayList ; import java . util . Date ; import java . util . List ; import java . util . Objects ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; class AtomFeedItem { private static final Pattern TABLE_DATA_CONTENT = Pattern . compile ( "<td.*?>(.*)</td>" ) ; private static final Pattern DIFF_ID_PATTERN = Pattern . compile ( "diff=(\\d+)" ) ; private final String id ; private final String title ; private final String summary ; private final Date date ; AtomFeedItem ( String id , String title , String summary , Date date ) { this . id = Objects . requireNonNull ( id ) ; this . title = Objects . requireNonNull ( title ) ; this . summary = Objects . requireNonNull ( summary ) ; this . date = Objects . requireNonNull ( date ) ; } String getId ( ) { return id ; } String getTitle ( ) { return title ; } String getSummary ( ) { return summary ; } Date getDate ( ) { return date ; } List < String > getOldContent ( ) { return getMarkedContent ( "−" ) ; } List < String > getNewContent ( ) { return getMarkedContent ( "+" ) ; } private List < String > getMarkedContent ( String plusMinusMarker ) { List < String > result = new ArrayList < > ( ) ; String [ ] lines = summary . split ( "\n" ) ; boolean expectingChange = false ; for ( String line : lines ) { if ( line . trim ( ) . startsWith ( "<td class=\"diff-marker\">" + plusMinusMarker + "</td>" ) ) { expectingChange = true ; } else if ( expectingChange ) { Matcher matcher = TABLE_DATA_CONTENT . matcher ( line ) ; if ( matcher . find ( ) ) { String cleanContent = matcher . group ( 1 ) ; if ( cleanContent . matches ( ".*<div.*?>[!\\|].*" ) && cleanContent . matches ( ".*\\w!!\\w.*" ) ) { cleanContent = cleanContent . replaceAll ( "<div.*?>[!\\|].*?</div>" , "" ) ; } cleanContent = cleanContent . replaceAll ( "<span.*?>" , "" ) . replace ( "</span>" , "" ) . replaceAll ( "<div.*?>[!\\|]" , "" ) . replace ( "<div>" , "" ) . replaceAll ( "<div.*?>" , "" ) . replace ( "</div>" , "" ) . replaceAll ( "<ins.*?>" , "" ) . replace ( "</ins>" , "" ) . replaceAll ( "<del.*?>" , "" ) . replace ( "</del>" , "" ) . replaceAll ( "<!--.*?-->" , "" ) ; result . add ( cleanContent ) ; } else { throw new RuntimeException ( "Expected change ('" + plusMinusMarker + "') not found in line: " + line ) ; } expectingChange = false ; } } return result ; } public long getDiffId ( ) { Matcher matcher = DIFF_ID_PATTERN . matcher ( id ) ; if ( matcher . find ( ) ) { return Long . parseLong ( matcher . group ( 1 ) ) ; } else { return 0 ; } } @ Override public String toString ( ) { return "AtomFeedItem{" + "id='" + id + '\'' + ", title='" + title + "\'}" ; } }
package org . languagetool ; import junit . framework . TestCase ; import org . languagetool . language . Dutch ; import java . io . IOException ; public class JLanguageToolTest extends TestCase { public void testDutch ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new Dutch ( ) ) ; assertEquals ( 0 , tool . check ( "Een test, die geen fouten mag geven." ) . size ( ) ) ; assertEquals ( 1 , tool . check ( "Dit is fout.!" ) . size ( ) ) ; assertEquals ( 5 , tool . check ( "I can give you more a detailed description." ) . size ( ) ) ; } }
package org . languagetool . dev . wikipedia . atom ; import org . apache . commons . lang . StringUtils ; import org . languagetool . Language ; import org . languagetool . rules . patterns . PatternRule ; import java . sql . Connection ; import java . sql . ResultSet ; import java . sql . DriverManager ; import java . sql . PreparedStatement ; import java . sql . SQLException ; import java . sql . Timestamp ; import java . util . * ; class MatchDatabase { private final Connection conn ; MatchDatabase ( String dbUrl , String dbUser , String dbPassword ) { try { conn = DriverManager . getConnection ( dbUrl , dbUser , dbPassword ) ; } catch ( SQLException e ) { throw new RuntimeException ( "Could not get database connection to " + dbUrl , e ) ; } } void updateRuleMatchPingDate ( Language language , Date date ) { updateRuleMatchDate ( "pings" , language , date ) ; } void updateRuleMatchCheckDate ( Language language , Date date ) { updateRuleMatchDate ( "feed_checks" , language , date ) ; } private void updateRuleMatchDate ( String tableName , Language language , Date date ) { String updateSql = "UPDATE " + tableName + " SET check_date = ? WHERE language_code = ?" ; try ( PreparedStatement updateSt = conn . prepareStatement ( updateSql ) ) { updateSt . setTimestamp ( 1 , new Timestamp ( date . getTime ( ) ) ) ; updateSt . setString ( 2 , language . getShortName ( ) ) ; int affected = updateSt . executeUpdate ( ) ; if ( affected == 0 ) { String insertSql = "INSERT INTO " + tableName + " (language_code, check_date) VALUES (?, ?)" ; try ( PreparedStatement insertSt = conn . prepareStatement ( insertSql ) ) { insertSt . setString ( 1 , language . getShortName ( ) ) ; insertSt . setTimestamp ( 2 , new Timestamp ( date . getTime ( ) ) ) ; insertSt . execute ( ) ; } } } catch ( SQLException e ) { throw new RuntimeException ( "Could not store date for " + language + " to database, table " + tableName , e ) ; } } void add ( WikipediaRuleMatch ruleMatch ) { String sql = "INSERT INTO feed_matches " + "(title, language_code, rule_id, rule_sub_id, rule_description, rule_message, rule_category, error_context, edit_date, diff_id) " + "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)" ; try ( PreparedStatement prepSt = conn . prepareStatement ( sql ) ) { prepSt . setString ( 1 , StringUtils . abbreviate ( ruleMatch . getTitle ( ) , 255 ) ) ; prepSt . setString ( 2 , ruleMatch . getLanguage ( ) . getShortName ( ) ) ; prepSt . setString ( 3 , ruleMatch . getRule ( ) . getId ( ) ) ; if ( ruleMatch . getRule ( ) instanceof PatternRule ) { prepSt . setString ( 4 , ( ( PatternRule ) ruleMatch . getRule ( ) ) . getSubId ( ) ) ; } else { prepSt . setString ( 4 , null ) ; } prepSt . setString ( 5 , StringUtils . abbreviate ( ruleMatch . getRule ( ) . getDescription ( ) , 255 ) ) ; prepSt . setString ( 6 , StringUtils . abbreviate ( ruleMatch . getMessage ( ) , 255 ) ) ; if ( ruleMatch . getRule ( ) . getCategory ( ) != null ) { prepSt . setString ( 7 , StringUtils . abbreviate ( ruleMatch . getRule ( ) . getCategory ( ) . getName ( ) , 255 ) ) ; } else { prepSt . setString ( 7 , "<no category>" ) ; } prepSt . setString ( 8 , StringUtils . abbreviate ( ruleMatch . getErrorContext ( ) , 500 ) ) ; prepSt . setTimestamp ( 9 , new Timestamp ( ruleMatch . getEditDate ( ) . getTime ( ) ) ) ; prepSt . setLong ( 10 , ruleMatch . getDiffId ( ) ) ; prepSt . execute ( ) ; } catch ( SQLException e ) { if ( e . toString ( ) . contains ( "Incorrect string value" ) ) { System . err . println ( "Could not add rule match " + ruleMatch + " to database - stacktrace follows:" ) ; e . printStackTrace ( ) ; } else { throw new RuntimeException ( "Could not add rule match " + ruleMatch + " to database" , e ) ; } } } int markedFixed ( WikipediaRuleMatch ruleMatch ) { String sql = "UPDATE feed_matches SET fix_date = ?, fix_diff_id = ? WHERE language_code = ? AND title = ? AND rule_id = ? AND error_context = ?" ; try ( PreparedStatement prepSt = conn . prepareStatement ( sql ) ) { prepSt . setTimestamp ( 1 , new Timestamp ( ruleMatch . getEditDate ( ) . getTime ( ) ) ) ; prepSt . setLong ( 2 , ruleMatch . getDiffId ( ) ) ; prepSt . setString ( 3 , ruleMatch . getLanguage ( ) . getShortName ( ) ) ; prepSt . setString ( 4 , ruleMatch . getTitle ( ) ) ; prepSt . setString ( 5 , ruleMatch . getRule ( ) . getId ( ) ) ; prepSt . setString ( 6 , ruleMatch . getErrorContext ( ) ) ; return prepSt . executeUpdate ( ) ; } catch ( SQLException e ) { throw new RuntimeException ( "Could not mark rule match " + ruleMatch + " as fixed in database" , e ) ; } } void createTables ( ) throws SQLException { try ( PreparedStatement prepSt = conn . prepareStatement ( "CREATE TABLE pings (" + " language_code VARCHAR(5) NOT NULL," + " check_date TIMESTAMP NOT NULL" + ")" ) ) { prepSt . executeUpdate ( ) ; } try ( PreparedStatement prepSt = conn . prepareStatement ( "CREATE TABLE feed_checks (" + " language_code VARCHAR(5) NOT NULL," + " check_date TIMESTAMP NOT NULL" + ")" ) ) { prepSt . executeUpdate ( ) ; } try ( PreparedStatement prepSt = conn . prepareStatement ( "CREATE TABLE feed_matches (" + " id INT NOT NULL GENERATED ALWAYS AS IDENTITY (START WITH 1, INCREMENT BY 1)," + " language_code VARCHAR(5) NOT NULL," + " title VARCHAR(255) NOT NULL," + " rule_id VARCHAR(255) NOT NULL," + " rule_sub_id VARCHAR(255)," + " rule_description VARCHAR(255) NOT NULL," + " rule_message VARCHAR(255) NOT NULL," + " rule_category VARCHAR(255) NOT NULL," + " error_context VARCHAR(500) NOT NULL," + " edit_date TIMESTAMP NOT NULL," + " diff_id INT NOT NULL," + " fix_date TIMESTAMP," + " fix_diff_id INT" + ")" ) ) { prepSt . executeUpdate ( ) ; } } Date getLatestDate ( Language language ) { try { String sql = "SELECT check_date FROM feed_checks WHERE language_code = ?" ; try ( PreparedStatement prepSt = conn . prepareStatement ( sql ) ) { prepSt . setString ( 1 , language . getShortName ( ) ) ; ResultSet resultSet = prepSt . executeQuery ( ) ; if ( resultSet . next ( ) && resultSet . getTimestamp ( "check_date" ) != null ) { return new Date ( resultSet . getTimestamp ( "check_date" ) . getTime ( ) ) ; } } } catch ( Exception e ) { throw new RuntimeException ( "Could not get check_date from database for " + language , e ) ; } return new Date ( 0 ) ; } void dropTables ( ) throws SQLException { dropTable ( "feed_matches" ) ; dropTable ( "feed_checks" ) ; dropTable ( "pings" ) ; } private void dropTable ( String tableName ) { try ( PreparedStatement prepSt = conn . prepareStatement ( "DROP TABLE " + tableName ) ) { prepSt . execute ( ) ; } catch ( SQLException e ) { System . err . println ( "Note: could not drop table 'feed_matches' - this is okay on the first run: " + e ) ; } } List < StoredWikipediaRuleMatch > list ( ) throws SQLException { try ( PreparedStatement prepSt = conn . prepareStatement ( "SELECT * FROM feed_matches" ) ; ResultSet resultSet = prepSt . executeQuery ( ) ) { List < StoredWikipediaRuleMatch > result = new ArrayList < > ( ) ; while ( resultSet . next ( ) ) { String ruleId = resultSet . getString ( "rule_id" ) ; String ruleSubId = resultSet . getString ( "rule_sub_id" ) ; String ruleDescription = resultSet . getString ( "rule_description" ) ; String ruleMessage = resultSet . getString ( "rule_message" ) ; String errorContext = resultSet . getString ( "error_context" ) ; String title = resultSet . getString ( "title" ) ; Date editDate = new Date ( resultSet . getTimestamp ( "edit_date" ) . getTime ( ) ) ; Timestamp fixTimeStamp = resultSet . getTimestamp ( "fix_date" ) ; Date fixDate = fixTimeStamp != null ? new Date ( resultSet . getTimestamp ( "fix_date" ) . getTime ( ) ) : null ; long diffId = resultSet . getLong ( "diff_id" ) ; long fixDiffId = resultSet . getLong ( "fix_diff_id" ) ; result . add ( new StoredWikipediaRuleMatch ( ruleId , ruleSubId , ruleDescription , ruleMessage , errorContext , title , editDate , fixDate , diffId , fixDiffId ) ) ; } return result ; } } Map < String , Date > getCheckDates ( ) throws SQLException { Map < String , Date > result = new HashMap < > ( ) ; try ( PreparedStatement prepSt = conn . prepareStatement ( "SELECT * FROM feed_checks" ) ; ResultSet resultSet = prepSt . executeQuery ( ) ) { while ( resultSet . next ( ) ) { String langCode = resultSet . getString ( "language_code" ) ; Date checkDate = new Date ( resultSet . getTimestamp ( "check_date" ) . getTime ( ) ) ; result . put ( langCode , checkDate ) ; } } return result ; } }
package org . languagetool . dev . wikipedia . atom ; import difflib . Delta ; import difflib . DiffUtils ; import difflib . Patch ; import java . util . ArrayList ; import java . util . Collection ; import java . util . List ; import java . util . Objects ; class ChangeAnalysis { private final String title ; private final long diffId ; private final List < WikipediaRuleMatch > oldMatches ; private final List < WikipediaRuleMatch > newMatches ; ChangeAnalysis ( String title , long diffId , List < WikipediaRuleMatch > oldMatches , List < WikipediaRuleMatch > newMatches ) { this . title = Objects . requireNonNull ( title ) ; this . diffId = Objects . requireNonNull ( diffId ) ; this . oldMatches = Objects . requireNonNull ( oldMatches ) ; this . newMatches = Objects . requireNonNull ( newMatches ) ; } String getTitle ( ) { return title ; } long getDiffId ( ) { return diffId ; } List < WikipediaRuleMatch > getAddedMatches ( ) { List < Delta > deltas = getDeltas ( ) ; return getWikipediaRuleMatches ( deltas , Delta . TYPE . INSERT ) ; } List < WikipediaRuleMatch > getRemovedMatches ( ) { List < Delta > deltas = getDeltas ( ) ; return getWikipediaRuleMatches ( deltas , Delta . TYPE . DELETE ) ; } private List < WikipediaRuleMatch > getWikipediaRuleMatches ( List < Delta > deltas , Delta . TYPE changeType ) { List < WikipediaRuleMatch > matches = new ArrayList < > ( ) ; for ( Delta delta : deltas ) { if ( delta . getType ( ) . equals ( changeType ) ) { List < ? > lines = changeType == Delta . TYPE . INSERT ? delta . getRevised ( ) . getLines ( ) : delta . getOriginal ( ) . getLines ( ) ; matches . addAll ( ( Collection < WikipediaRuleMatch > ) lines ) ; } } return matches ; } private List < Delta > getDeltas ( ) { Patch diff = DiffUtils . diff ( oldMatches , newMatches ) ; return diff . getDeltas ( ) ; } @ Override public String toString ( ) { return "ChangeAnalysis{title=" + title + ",diffId=" + diffId + "}" ; } }
package org . languagetool . dev . wikipedia . atom ; import java . util . List ; import java . util . Objects ; class CheckResult { private final List < ChangeAnalysis > checkResults ; private final long latestDiffId ; CheckResult ( List < ChangeAnalysis > checkResults , long latestDiffId ) { this . checkResults = Objects . requireNonNull ( checkResults ) ; if ( latestDiffId < 0 ) { throw new IllegalArgumentException ( "latestDiffId must be >= 0: " + latestDiffId ) ; } this . latestDiffId = latestDiffId ; } List < ChangeAnalysis > getCheckResults ( ) { return checkResults ; } long getLatestDiffId ( ) { return latestDiffId ; } }
package org . languagetool . dev . wikipedia . atom ; import org . apache . commons . lang . builder . EqualsBuilder ; import org . languagetool . Language ; import org . languagetool . rules . RuleMatch ; import java . util . Date ; import java . util . Objects ; final class WikipediaRuleMatch extends RuleMatch { private final Language language ; private final String errorContext ; private final String title ; private final Date editDate ; private final long diffId ; WikipediaRuleMatch ( Language language , RuleMatch ruleMatch , String errorContext , AtomFeedItem feedItem ) { super ( ruleMatch . getRule ( ) , ruleMatch . getFromPos ( ) , ruleMatch . getToPos ( ) , ruleMatch . getMessage ( ) ) ; this . language = Objects . requireNonNull ( language ) ; this . errorContext = Objects . requireNonNull ( errorContext ) ; this . title = Objects . requireNonNull ( feedItem . getTitle ( ) ) ; this . editDate = Objects . requireNonNull ( feedItem . getDate ( ) ) ; this . diffId = feedItem . getDiffId ( ) ; } Language getLanguage ( ) { return language ; } String getErrorContext ( ) { return errorContext ; } String getTitle ( ) { return title ; } Date getEditDate ( ) { return new Date ( editDate . getTime ( ) ) ; } long getDiffId ( ) { return diffId ; } @ Override public String toString ( ) { return getRule ( ) . getId ( ) + ":" + getFromPos ( ) + "-" + getToPos ( ) ; } @ Override public int hashCode ( ) { return getRule ( ) . getId ( ) . hashCode ( ) ; } @ Override public boolean equals ( Object other ) { if ( other instanceof WikipediaRuleMatch ) { return new EqualsBuilder ( ) . append ( getRule ( ) . getId ( ) , ( ( RuleMatch ) other ) . getRule ( ) . getId ( ) ) . isEquals ( ) ; } return false ; } }
package org . languagetool . dev . wikipedia . atom ; import javax . xml . datatype . DatatypeFactory ; import javax . xml . stream . XMLEventReader ; import javax . xml . stream . XMLInputFactory ; import javax . xml . stream . XMLStreamException ; import javax . xml . stream . events . XMLEvent ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . Date ; import java . util . List ; class AtomFeedParser { List < AtomFeedItem > getAtomFeedItems ( InputStream xml ) throws XMLStreamException { List < AtomFeedItem > items = new ArrayList < > ( ) ; String id = null ; String title = null ; Date date = null ; XMLInputFactory inputFactory = XMLInputFactory . newInstance ( ) ; XMLEventReader eventReader = inputFactory . createXMLEventReader ( xml ) ; while ( eventReader . hasNext ( ) ) { XMLEvent event = eventReader . nextEvent ( ) ; if ( event . isStartElement ( ) ) { String localPart = event . asStartElement ( ) . getName ( ) . getLocalPart ( ) ; switch ( localPart ) { case "id" : id = getCharacterData ( eventReader ) ; break ; case "title" : title = getCharacterData ( eventReader ) ; break ; case "updated" : String dateString = getCharacterData ( eventReader ) ; try { date = DatatypeFactory . newInstance ( ) . newXMLGregorianCalendar ( dateString ) . toGregorianCalendar ( ) . getTime ( ) ; } catch ( Exception e ) { throw new RuntimeException ( "Could not parse date string '" + dateString + "'" , e ) ; } break ; case "summary" : if ( id == null || title == null || date == null ) { throw new RuntimeException ( "id, title and/or date is null: id=" + id + ", title=" + title + ", date=" + date ) ; } items . add ( new AtomFeedItem ( id , title , getCharacterData ( eventReader ) , date ) ) ; id = null ; title = null ; date = null ; break ; } } } return items ; } private String getCharacterData ( XMLEventReader eventReader ) throws XMLStreamException { XMLEvent event = eventReader . nextEvent ( ) ; StringBuilder sb = new StringBuilder ( ) ; while ( event . isCharacters ( ) ) { sb . append ( event . asCharacters ( ) . getData ( ) ) ; event = eventReader . nextEvent ( ) ; } return sb . toString ( ) ; } }
package org . languagetool . dev . wikipedia . atom ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . dev . wikipedia . LocationHelper ; import org . languagetool . dev . wikipedia . PlainTextMapping ; import org . languagetool . dev . wikipedia . SwebleWikipediaTextFilter ; import org . languagetool . dev . wikipedia . TextMapFilter ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . tools . ContextTools ; import xtc . tree . Location ; import javax . xml . stream . XMLStreamException ; import java . io . File ; import java . io . IOException ; import java . io . InputStream ; import java . net . URL ; import java . net . URLConnection ; import java . net . URLEncoder ; import java . util . * ; class AtomFeedChecker { private static final int CONTEXT_SIZE = 60 ; private static final String USER_AGENT = "http://tools.wmflabs.org/languagetool/ bot, contact: naber[@]danielnaber.de" ; private final JLanguageTool langTool ; private final Language language ; private final MatchDatabase matchDatabase ; private final TextMapFilter textFilter = new SwebleWikipediaTextFilter ( ) ; private final ContextTools contextTools = new ContextTools ( ) ; AtomFeedChecker ( Language language ) throws IOException { this ( language , null ) ; } AtomFeedChecker ( Language language , DatabaseConfig dbConfig ) throws IOException { this ( language , dbConfig , null ) ; } AtomFeedChecker ( Language language , DatabaseConfig dbConfig , File languageModelDir ) throws IOException { this . language = Objects . requireNonNull ( language ) ; langTool = new JLanguageTool ( language ) ; if ( languageModelDir != null ) { langTool . activateLanguageModelRules ( languageModelDir ) ; } langTool . disableRule ( "UNPAIRED_BRACKETS" ) ; langTool . disableRule ( "EN_UNPAIRED_BRACKETS" ) ; langTool . disableRule ( "EN_QUOTES" ) ; langTool . disableRule ( "COMMA_PARENTHESIS_WHITESPACE" ) ; langTool . disableRule ( "UPPERCASE_SENTENCE_START" ) ; langTool . disableRule ( "FRENCH_WHITESPACE" ) ; activateCategory ( "Wikipedia" , langTool ) ; disableSpellingRules ( langTool ) ; if ( dbConfig != null ) { matchDatabase = new MatchDatabase ( dbConfig . getUrl ( ) , dbConfig . getUser ( ) , dbConfig . getPassword ( ) ) ; } else { matchDatabase = null ; } contextTools . setContextSize ( CONTEXT_SIZE ) ; contextTools . setErrorMarkerStart ( "<err>" ) ; contextTools . setErrorMarkerEnd ( "</err>" ) ; contextTools . setEscapeHtml ( false ) ; } private void activateCategory ( String categoryName , JLanguageTool langTool ) { for ( Rule rule : langTool . getAllRules ( ) ) { if ( rule . getCategory ( ) . getName ( ) . equals ( categoryName ) ) { System . out . println ( "Activating " + rule . getId ( ) + " in category " + categoryName ) ; langTool . enableDefaultOffRule ( rule . getId ( ) ) ; } } } private void disableSpellingRules ( JLanguageTool langTool ) { for ( Rule rule : langTool . getAllActiveRules ( ) ) { if ( rule . isDictionaryBasedSpellingRule ( ) ) { langTool . disableRule ( rule . getId ( ) ) ; System . out . println ( "Disabled spelling rule: " + rule . getId ( ) ) ; } } } CheckResult runCheck ( InputStream feedStream ) throws IOException { CheckResult checkResult = checkChanges ( feedStream ) ; storeResults ( checkResult ) ; return checkResult ; } CheckResult runCheck ( String url ) throws IOException { CheckResult checkResult = checkChanges ( new URL ( url ) ) ; storeResults ( checkResult ) ; return checkResult ; } private void storeResults ( CheckResult checkResult ) throws IOException { List < ChangeAnalysis > checkResults = checkResult . getCheckResults ( ) ; System . out . println ( "Check results:" ) ; for ( ChangeAnalysis result : checkResults ) { List < WikipediaRuleMatch > addedMatches = result . getAddedMatches ( ) ; List < WikipediaRuleMatch > removedMatches = result . getRemovedMatches ( ) ; if ( addedMatches . size ( ) > 0 || removedMatches . size ( ) > 0 ) { System . out . println ( "'" + result . getTitle ( ) + "' new and removed matches:" ) ; for ( WikipediaRuleMatch match : addedMatches ) { System . out . println ( " [+] " + getId ( match . getRule ( ) ) + ": " + match . getErrorContext ( ) ) ; if ( matchDatabase != null ) { matchDatabase . add ( match ) ; } } for ( WikipediaRuleMatch match : removedMatches ) { System . out . println ( " [-] " + getId ( match . getRule ( ) ) + ": " + match . getErrorContext ( ) ) ; if ( matchDatabase != null ) { matchDatabase . markedFixed ( match ) ; } } String diffLink = "https://" + language . getShortName ( ) + ".wikipedia.org/w/index.php?title=" + URLEncoder . encode ( result . getTitle ( ) . replace ( " " , "_" ) , "UTF-8" ) + "&diff=" + result . getDiffId ( ) ; System . out . println ( " " + diffLink ) ; } } } private String getId ( Rule rule ) { if ( rule instanceof PatternRule ) { return rule . getId ( ) + "[" + ( ( PatternRule ) rule ) . getSubId ( ) + "]" ; } else { return rule . getId ( ) ; } } CheckResult checkChanges ( URL atomFeedUrl ) throws IOException { System . out . println ( "Getting atom feed from " + atomFeedUrl ) ; InputStream xml = getXmlStream ( atomFeedUrl ) ; return checkChanges ( xml ) ; } CheckResult checkChanges ( InputStream xml ) throws IOException { Date lastDateOfPreviousRun = matchDatabase != null ? matchDatabase . getLatestDate ( language ) : null ; List < ChangeAnalysis > result = new ArrayList < > ( ) ; long latestDiffId = 0 ; int skipCount = 0 ; try { List < AtomFeedItem > items = new AtomFeedParser ( ) . getAtomFeedItems ( xml ) ; Collections . reverse ( items ) ; printDates ( items , lastDateOfPreviousRun ) ; if ( matchDatabase != null ) { matchDatabase . updateRuleMatchPingDate ( language , new Date ( ) ) ; } for ( AtomFeedItem item : items ) { if ( lastDateOfPreviousRun != null && ( item . getDate ( ) . before ( lastDateOfPreviousRun ) || item . getDate ( ) . equals ( lastDateOfPreviousRun ) ) ) { System . out . println ( "Skipping " + item . getTitle ( ) + ", date " + item . getDate ( ) ) ; skipCount ++ ; } else { if ( matchDatabase != null ) { matchDatabase . updateRuleMatchCheckDate ( language , item . getDate ( ) ) ; } try { System . out . println ( "Checking " + item . getTitle ( ) + ", diff #" + item . getDiffId ( ) ) ; List < WikipediaRuleMatch > oldMatches = getMatches ( item , item . getOldContent ( ) ) ; List < WikipediaRuleMatch > newMatches = getMatches ( item , item . getNewContent ( ) ) ; ChangeAnalysis changeAnalysis = new ChangeAnalysis ( item . getTitle ( ) , item . getDiffId ( ) , oldMatches , newMatches ) ; result . add ( changeAnalysis ) ; if ( item . getDiffId ( ) > latestDiffId ) { latestDiffId = item . getDiffId ( ) ; } } catch ( Exception e ) { e . printStackTrace ( ) ; } } } } catch ( XMLStreamException e ) { throw new RuntimeException ( e ) ; } if ( lastDateOfPreviousRun != null && skipCount == 0 ) { System . err . println ( "Warning: no items from the Atom feed were skipped - this means that changes might be missing" ) ; } return new CheckResult ( result , latestDiffId ) ; } MatchDatabase getDatabase ( ) { return matchDatabase ; } private void printDates ( List < AtomFeedItem > items , Date lastDateOfPreviousRun ) { if ( items . size ( ) > 0 ) { Date firstDate = items . get ( 0 ) . getDate ( ) ; Date lastDate = items . get ( items . size ( ) - 1 ) . getDate ( ) ; System . out . println ( "Latest date in database: " + lastDateOfPreviousRun ) ; System . out . println ( "Dates in Atom Feed: " + firstDate + " - " + lastDate ) ; } } private List < WikipediaRuleMatch > getMatches ( AtomFeedItem item , List < String > texts ) throws IOException { List < WikipediaRuleMatch > oldMatches = new ArrayList < > ( ) ; for ( String text : texts ) { PlainTextMapping filteredContent = textFilter . filter ( text ) ; List < RuleMatch > ruleMatches = langTool . check ( filteredContent . getPlainText ( ) ) ; oldMatches . addAll ( toWikipediaRuleMatches ( text , filteredContent , ruleMatches , item ) ) ; } return oldMatches ; } private List < WikipediaRuleMatch > toWikipediaRuleMatches ( String content , PlainTextMapping filteredContent , List < RuleMatch > ruleMatches , AtomFeedItem item ) { List < WikipediaRuleMatch > result = new ArrayList < > ( ) ; for ( RuleMatch ruleMatch : ruleMatches ) { Location fromPos = filteredContent . getOriginalTextPositionFor ( ruleMatch . getFromPos ( ) + 1 ) ; Location toPos = filteredContent . getOriginalTextPositionFor ( ruleMatch . getToPos ( ) + 1 ) ; int origFrom = LocationHelper . absolutePositionFor ( fromPos , content ) ; int origTo = LocationHelper . absolutePositionFor ( toPos , content ) ; String errorContext = contextTools . getContext ( origFrom , origTo , content ) ; result . add ( new WikipediaRuleMatch ( language , ruleMatch , errorContext , item ) ) ; } return result ; } private InputStream getXmlStream ( URL url ) throws IOException { URLConnection conn = url . openConnection ( ) ; conn . setRequestProperty ( "User-Agent" , USER_AGENT ) ; return conn . getInputStream ( ) ; } }
package org . languagetool . dev . wikipedia . atom ; import java . util . Date ; import java . util . Objects ; class StoredWikipediaRuleMatch { private final String ruleId ; private final String ruleSubId ; private final String ruleDescription ; private final String ruleMessage ; private final String errorContext ; private final String title ; private final Date editDate ; private final Date fixDate ; private final long diffId ; private final long fixDiffId ; StoredWikipediaRuleMatch ( String ruleId , String ruleSubId , String ruleDescription , String ruleMessage , String errorContext , String title , Date editDate , Date fixDate , long diffId , long fixDiffId ) { this . ruleId = Objects . requireNonNull ( ruleId ) ; this . ruleSubId = ruleSubId ; this . ruleDescription = Objects . requireNonNull ( ruleDescription ) ; this . ruleMessage = Objects . requireNonNull ( ruleMessage ) ; this . errorContext = Objects . requireNonNull ( errorContext ) ; this . title = Objects . requireNonNull ( title ) ; this . editDate = Objects . requireNonNull ( editDate ) ; this . fixDate = fixDate ; this . diffId = diffId ; this . fixDiffId = fixDiffId ; } String getRuleId ( ) { return ruleId ; } String getRuleSubId ( ) { return ruleSubId ; } String getRuleDescription ( ) { return ruleDescription ; } String getRuleMessage ( ) { return ruleMessage ; } String getErrorContext ( ) { return errorContext ; } String getTitle ( ) { return title ; } Date getEditDate ( ) { return editDate ; } Date getFixDate ( ) { return fixDate ; } long getDiffId ( ) { return diffId ; } long getFixDiffId ( ) { return fixDiffId ; } @ Override public String toString ( ) { return ruleId ; } }
package org . languagetool . dev . wikipedia . atom ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import java . io . File ; import java . io . IOException ; final class AtomFeedCheckerCmd { private AtomFeedCheckerCmd ( ) { } public static void main ( String [ ] args ) throws IOException , InterruptedException { if ( args . length < 2 || args . length > 4 ) { System . out . println ( "Usage: " + AtomFeedCheckerCmd . class . getSimpleName ( ) + " <atomFeedUrl> <sleepTime> [database.properties] [languageModelDir]" ) ; System . out . println ( " <atomFeedUrl> is a Wikipedia URL to the latest changes, for example:" ) ; System . out . println ( " https://de.wikipedia.org/w/index.php?title=Spezial:Letzte_%C3%84nderungen&feed=atom&namespace=0" ) ; System . out . println ( " <sleepTime> -1: don't loop at all (run once), 0: run in loop, other number: run in loop and" ) ; System . out . println ( " wait this many milliseconds between runs" ) ; System . out . println ( " [database.properties] (optional) is a file that defines dbUrl, dbUser, and dbPassword," ) ; System . out . println ( " used to write the results to a database via JDBC" ) ; System . out . println ( " [languageModelDir] (optional, use only together with database.properties) a directory with ngram" ) ; System . out . println ( " sub directories, activates the confusion rule if supported" ) ; System . out . println ( "" ) ; System . out . println ( " When the database.properties file is specified, this command will store all feed changes that" ) ; System . out . println ( " cause LanguageTool rule matches to the database. If an error is then fixed later, this will" ) ; System . out . println ( " usually also be detected and the rule match in the database will be marked as fixed. One case" ) ; System . out . println ( " where this does not work is if the context of the error gets modified before the error is fixed." ) ; System . out . println ( "" ) ; System . out . println ( " Run this command regularly so that you don't miss any changes from the feed." ) ; System . out . println ( " As the feed may contain only the latest 50 changes, running it more often than" ) ; System . out . println ( " once per minute may be needed for active Wikipedias." ) ; System . exit ( 1 ) ; } String url = args [ 0 ] ; String langCode = url . substring ( url . indexOf ( "//" ) + 2 , url . indexOf ( "." ) ) ; System . out . println ( "Using URL: " + url ) ; System . out . println ( "Language code: " + langCode ) ; int sleepTimeMillis = Integer . parseInt ( args [ 1 ] ) ; System . out . println ( "Sleep time: " + sleepTimeMillis + "ms (-1 = don't loop)" ) ; System . out . println ( "LanguageTool version: " + JLanguageTool . VERSION + " (" + JLanguageTool . BUILD_DATE + ")" ) ; DatabaseConfig databaseConfig = null ; if ( args . length >= 3 ) { String propFile = args [ 2 ] ; databaseConfig = new DatabaseConfig ( propFile ) ; System . out . println ( "Writing results to database at: " + databaseConfig . getUrl ( ) ) ; } AtomFeedChecker atomFeedChecker ; Language language = Languages . getLanguageForShortName ( langCode ) ; if ( args . length == 4 ) { String languageModelDir = args [ 3 ] ; atomFeedChecker = new AtomFeedChecker ( language , databaseConfig , new File ( languageModelDir ) ) ; } else { atomFeedChecker = new AtomFeedChecker ( language , databaseConfig ) ; } while ( true ) { long startTime = System . currentTimeMillis ( ) ; try { atomFeedChecker . runCheck ( url ) ; System . out . println ( "Run time: " + ( System . currentTimeMillis ( ) - startTime ) + "ms" ) ; if ( sleepTimeMillis == - 1 ) { break ; } else { System . out . println ( "Sleeping " + sleepTimeMillis + "ms..." ) ; Thread . sleep ( sleepTimeMillis ) ; } } catch ( Exception e ) { e . printStackTrace ( ) ; System . out . println ( "Sleeping " + sleepTimeMillis + "ms..." ) ; Thread . sleep ( sleepTimeMillis ) ; } } } }
package org . languagetool ; import static junit . framework . TestCase . assertEquals ; import static junit . framework . TestCase . fail ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; import java . io . IOException ; import java . util . * ; import java . util . concurrent . RejectedExecutionException ; import org . junit . Assert ; import org . junit . Test ; import org . languagetool . language . Demo ; import org . languagetool . rules . MultipleWhitespaceRule ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . UppercaseSentenceStartRule ; import org . languagetool . rules . patterns . PatternRule ; @ SuppressWarnings ( "ResultOfObjectAllocationIgnored" ) public class MultiThreadedJLanguageToolTest { @ Test public void testCheck ( ) throws IOException { MultiThreadedJLanguageTool lt1 = new MultiThreadedJLanguageTool ( new Demo ( ) ) ; final List < String > ruleMatchIds1 = getRuleMatchIds ( lt1 ) ; assertEquals ( 9 , ruleMatchIds1 . size ( ) ) ; Assert . assertEquals ( 4 , lt1 . getSentenceCount ( ) ) ; lt1 . shutdown ( ) ; JLanguageTool lt2 = new JLanguageTool ( new Demo ( ) ) ; final List < String > ruleMatchIds2 = getRuleMatchIds ( lt2 ) ; assertEquals ( ruleMatchIds1 , ruleMatchIds2 ) ; Assert . assertEquals ( 4 , lt1 . getSentenceCount ( ) ) ; } @ Test public void testShutdownException ( ) throws IOException { MultiThreadedJLanguageTool tool = new MultiThreadedJLanguageTool ( new Demo ( ) ) ; getRuleMatchIds ( tool ) ; tool . shutdown ( ) ; try { getRuleMatchIds ( tool ) ; fail ( "should have been rejected as the thread pool has been shut down" ) ; } catch ( RejectedExecutionException ignore ) { } } @ Test public void testTextAnalysis ( ) throws IOException { MultiThreadedJLanguageTool lt = new MultiThreadedJLanguageTool ( new Demo ( ) ) ; List < AnalyzedSentence > analyzedSentences = lt . analyzeText ( "This is a sentence. And another one." ) ; assertThat ( analyzedSentences . size ( ) , is ( 2 ) ) ; assertThat ( analyzedSentences . get ( 0 ) . getTokens ( ) . length , is ( 10 ) ) ; assertThat ( analyzedSentences . get ( 0 ) . getTokensWithoutWhitespace ( ) . length , is ( 6 ) ) ; assertThat ( analyzedSentences . get ( 1 ) . getTokens ( ) . length , is ( 7 ) ) ; assertThat ( analyzedSentences . get ( 1 ) . getTokensWithoutWhitespace ( ) . length , is ( 5 ) ) ; lt . shutdown ( ) ; } @ Test public void testConfigurableThreadPoolSize ( ) throws IOException { MultiThreadedJLanguageTool lt = new MultiThreadedJLanguageTool ( new Demo ( ) ) ; Assert . assertEquals ( Runtime . getRuntime ( ) . availableProcessors ( ) , lt . getThreadPoolSize ( ) ) ; lt . shutdown ( ) ; } private List < String > getRuleMatchIds ( JLanguageTool langTool ) throws IOException { final String input = "A small toast. No error here. Foo go bar. First goes last there, please!" ; final List < RuleMatch > matches = langTool . check ( input ) ; final List < String > ruleMatchIds = new ArrayList < > ( ) ; for ( RuleMatch match : matches ) { ruleMatchIds . add ( match . getRule ( ) . getId ( ) ) ; } return ruleMatchIds ; } @ Test public void testTwoRulesOnly ( ) throws IOException { MultiThreadedJLanguageTool lt = new MultiThreadedJLanguageTool ( new FakeLanguage ( ) { @ Override protected synchronized List < PatternRule > getPatternRules ( ) { return Collections . emptyList ( ) ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Arrays . asList ( new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) ) ; } } ) ; assertThat ( lt . check ( "my test text" ) . size ( ) , is ( 2 ) ) ; lt . shutdown ( ) ; } @ Test ( expected = IllegalArgumentException . class ) public void testIllegalThreadPoolSize1 ( ) throws IOException { new MultiThreadedJLanguageTool ( new Demo ( ) , 0 ) ; } @ Test ( expected = IllegalArgumentException . class ) public void testIllegalThreadPoolSize2 ( ) throws IOException { new MultiThreadedJLanguageTool ( new Demo ( ) , null , 0 ) ; } }
package org . languagetool ; import java . io . IOException ; import junit . framework . TestCase ; public class ValidateFalseFriendsXmlTest extends TestCase { public void testFalseFriendsXML ( ) throws IOException { System . out . println ( "Validating false-friends.xml..." ) ; final XMLValidator validator = new XMLValidator ( ) ; validator . validateWithDtd ( JLanguageTool . getDataBroker ( ) . getRulesDir ( ) + "/false-friends.xml" , JLanguageTool . getDataBroker ( ) . getRulesDir ( ) + "/false-friends.dtd" , "rules" ) ; System . out . println ( "Validation successfully finished." ) ; } public static void main ( final String [ ] args ) throws IOException { final ValidateFalseFriendsXmlTest test = new ValidateFalseFriendsXmlTest ( ) ; test . testFalseFriendsXML ( ) ; } }
package org . languagetool . synthesis . nl ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; public class DutchSynthesizerTest extends TestCase { public final void testSynthesizeStringString ( ) throws IOException { DutchSynthesizer synth = new DutchSynthesizer ( ) ; assertEquals ( synth . synthesize ( dummyToken ( "blablabla" ) , "blablabla" ) . length , 0 ) ; assertEquals ( "[zwommen]" , Arrays . toString ( synth . synthesize ( dummyToken ( "zwemmen" ) , "VBh" ) ) ) ; assertEquals ( "[Afro-Surinamers]" , Arrays . toString ( synth . synthesize ( dummyToken ( "Afro-Surinamer" ) , "NN2" ) ) ) ; assertEquals ( "[hebt, heeft]" , Arrays . toString ( synth . synthesize ( dummyToken ( "hebben" ) , "VB3" , true ) ) ) ; assertEquals ( "[doorgeseind]" , Arrays . toString ( synth . synthesize ( dummyToken ( "doorseinen" ) , "VBp" , true ) ) ) ; assertEquals ( "[doorsein, doorseint, doorseinden, doorseinde, doorseinen, doorgeseind, doorgeseinde]" , Arrays . toString ( synth . synthesize ( dummyToken ( "doorseinen" ) , "VB.*" , true ) ) ) ; } private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } }
package org . languagetool ; import org . junit . Test ; import static org . junit . Assert . assertNotNull ; public class ResourceBundleToolsTest { @ Test public void testGetMessageBundle ( ) throws Exception { assertNotNull ( JLanguageTool . getMessageBundle ( ) ) ; } }
package org . languagetool ; import junit . framework . TestCase ; import java . util . Arrays ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class AnalyzedTokenReadingsTest extends TestCase { public void testNewTags ( ) { AnalyzedTokenReadings tokenReadings = new AnalyzedTokenReadings ( new AnalyzedToken ( "word" , "POS" , "lemma" ) ) ; assertEquals ( false , tokenReadings . isLinebreak ( ) ) ; assertEquals ( false , tokenReadings . isSentenceEnd ( ) ) ; assertEquals ( false , tokenReadings . isParagraphEnd ( ) ) ; assertEquals ( false , tokenReadings . isSentenceStart ( ) ) ; tokenReadings . setSentEnd ( ) ; assertEquals ( false , tokenReadings . isSentenceStart ( ) ) ; assertEquals ( true , tokenReadings . isSentenceEnd ( ) ) ; tokenReadings = new AnalyzedTokenReadings ( new AnalyzedToken ( "word" , null , "lemma" ) ) ; tokenReadings . addReading ( new AnalyzedToken ( "word" , "SENT_END" , null ) ) ; assertEquals ( true , tokenReadings . isSentenceEnd ( ) ) ; assertEquals ( false , tokenReadings . isParagraphEnd ( ) ) ; tokenReadings . addReading ( new AnalyzedToken ( "word" , "PARA_END" , null ) ) ; assertEquals ( true , tokenReadings . isParagraphEnd ( ) ) ; assertEquals ( false , tokenReadings . isSentenceStart ( ) ) ; tokenReadings . addReading ( new AnalyzedToken ( "word" , "SENT_START" , null ) ) ; assertEquals ( false , tokenReadings . isSentenceStart ( ) ) ; final AnalyzedToken aTok = new AnalyzedToken ( "word" , "POS" , "lemma" ) ; aTok . setWhitespaceBefore ( true ) ; tokenReadings = new AnalyzedTokenReadings ( aTok ) ; assertEquals ( aTok , tokenReadings . getAnalyzedToken ( 0 ) ) ; final AnalyzedToken aTok2 = new AnalyzedToken ( "word" , "POS" , "lemma" ) ; assertTrue ( ! aTok2 . equals ( tokenReadings . getAnalyzedToken ( 0 ) ) ) ; final AnalyzedToken aTok3 = new AnalyzedToken ( "word" , "POS" , "lemma" ) ; aTok3 . setWhitespaceBefore ( true ) ; assertEquals ( aTok3 , tokenReadings . getAnalyzedToken ( 0 ) ) ; final AnalyzedTokenReadings testReadings = new AnalyzedTokenReadings ( aTok3 ) ; testReadings . removeReading ( aTok3 ) ; assertTrue ( testReadings . getReadingsLength ( ) == 1 ) ; assertEquals ( "word" , testReadings . getToken ( ) ) ; assertTrue ( ! testReadings . hasPosTag ( "POS" ) ) ; testReadings . leaveReading ( aTok2 ) ; assertEquals ( "word" , testReadings . getToken ( ) ) ; assertTrue ( ! testReadings . hasPosTag ( "POS" ) ) ; testReadings . removeReading ( aTok2 ) ; assertEquals ( "word" , testReadings . getToken ( ) ) ; assertTrue ( ! testReadings . hasPosTag ( "POS" ) ) ; } public void testToString ( ) { final AnalyzedTokenReadings tokenReadings = new AnalyzedTokenReadings ( new AnalyzedToken ( "word" , "POS" , "lemma" ) ) ; assertEquals ( "word[lemma/POS*]" , tokenReadings . toString ( ) ) ; final AnalyzedToken aTok2 = new AnalyzedToken ( "word" , "POS2" , "lemma2" ) ; tokenReadings . addReading ( aTok2 ) ; assertEquals ( "word[lemma/POS*,lemma2/POS2*]" , tokenReadings . toString ( ) ) ; } public void testHasPosTag ( ) { final AnalyzedTokenReadings tokenReadings = new AnalyzedTokenReadings ( new AnalyzedToken ( "word" , "POS:FOO:BAR" , "lemma" ) ) ; assertTrue ( tokenReadings . hasPosTag ( "POS:FOO:BAR" ) ) ; assertFalse ( tokenReadings . hasPosTag ( "POS:FOO:bar" ) ) ; assertFalse ( tokenReadings . hasPosTag ( "POS:FOO" ) ) ; assertFalse ( tokenReadings . hasPosTag ( "xaz" ) ) ; } public void testHasPartialPosTag ( ) { final AnalyzedTokenReadings tokenReadings = new AnalyzedTokenReadings ( new AnalyzedToken ( "word" , "POS:FOO:BAR" , "lemma" ) ) ; assertTrue ( tokenReadings . hasPartialPosTag ( "POS:FOO:BAR" ) ) ; assertTrue ( tokenReadings . hasPartialPosTag ( "POS:FOO:" ) ) ; assertTrue ( tokenReadings . hasPartialPosTag ( "POS:FOO" ) ) ; assertTrue ( tokenReadings . hasPartialPosTag ( ":FOO:" ) ) ; assertTrue ( tokenReadings . hasPartialPosTag ( "FOO:BAR" ) ) ; assertFalse ( tokenReadings . hasPartialPosTag ( "POS:FOO:BARX" ) ) ; assertFalse ( tokenReadings . hasPartialPosTag ( "POS:foo:BAR" ) ) ; assertFalse ( tokenReadings . hasPartialPosTag ( "xaz" ) ) ; } public void testMatchesPosTagRegex ( ) { final AnalyzedTokenReadings tokenReadings = new AnalyzedTokenReadings ( new AnalyzedToken ( "word" , "POS:FOO:BAR" , "lemma" ) ) ; assertTrue ( tokenReadings . matchesPosTagRegex ( "POS:FOO:BAR" ) ) ; assertTrue ( tokenReadings . matchesPosTagRegex ( "POS:...:BAR" ) ) ; assertTrue ( tokenReadings . matchesPosTagRegex ( "POS:[A-Z]+:BAR" ) ) ; assertFalse ( tokenReadings . matchesPosTagRegex ( "POS:[AB]OO:BAR" ) ) ; assertFalse ( tokenReadings . matchesPosTagRegex ( "POS:FOO:BARX" ) ) ; } public void testIteration ( ) { final AnalyzedTokenReadings tokenReadings = new AnalyzedTokenReadings ( Arrays . asList ( new AnalyzedToken ( "word1" , null , null ) , new AnalyzedToken ( "word2" , null , null ) ) , 0 ) ; int i = 0 ; for ( AnalyzedToken tokenReading : tokenReadings ) { if ( i == 0 ) { assertThat ( tokenReading . getToken ( ) , is ( "word1" ) ) ; } else if ( i == 1 ) { assertThat ( tokenReading . getToken ( ) , is ( "word2" ) ) ; } else { fail ( ) ; } i ++ ; } } }
package org . languagetool ; import static org . junit . Assert . assertNotEquals ; import junit . framework . TestCase ; public class AnalyzedSentenceTest extends TestCase { public void testToString ( ) { final AnalyzedTokenReadings [ ] words = new AnalyzedTokenReadings [ 3 ] ; words [ 0 ] = new AnalyzedTokenReadings ( new AnalyzedToken ( "" , "SENT_START" , null ) ) ; words [ 1 ] = new AnalyzedTokenReadings ( new AnalyzedToken ( "word" , "POS" , "lemma" ) ) ; words [ 2 ] = new AnalyzedTokenReadings ( new AnalyzedToken ( "." , "INTERP" , null ) ) ; words [ 2 ] . addReading ( new AnalyzedToken ( "." , "SENT_END" , null ) ) ; final AnalyzedSentence sentence = new AnalyzedSentence ( words ) ; assertEquals ( "<S> word[lemma/POS].[./INTERP,</S>]" , sentence . toString ( ) ) ; } public void testCopy ( ) { final AnalyzedTokenReadings [ ] words = new AnalyzedTokenReadings [ 3 ] ; words [ 0 ] = new AnalyzedTokenReadings ( new AnalyzedToken ( "" , "SENT_START" , null ) ) ; words [ 1 ] = new AnalyzedTokenReadings ( new AnalyzedToken ( "word" , "POS" , "lemma" ) ) ; words [ 2 ] = new AnalyzedTokenReadings ( new AnalyzedToken ( "." , "INTERP" , null ) ) ; words [ 2 ] . addReading ( new AnalyzedToken ( "." , "SENT_END" , null ) ) ; final AnalyzedSentence sentence = new AnalyzedSentence ( words ) ; final AnalyzedSentence copySentence = sentence . copy ( sentence ) ; assertEquals ( sentence , copySentence ) ; words [ 1 ] . immunize ( ) ; assertEquals ( "<S> word[lemma/POS{!}].[./INTERP,</S>]" , sentence . toString ( ) ) ; assertNotEquals ( sentence , copySentence ) ; } }
package org . languagetool ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collections ; import java . util . HashSet ; import java . util . Iterator ; import java . util . List ; import java . util . Locale ; import java . util . ResourceBundle ; import java . util . Set ; import morfologik . stemming . Dictionary ; import morfologik . stemming . DictionaryLookup ; import morfologik . stemming . WordData ; import org . languagetool . language . Demo ; import org . languagetool . tagging . BaseTagger ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tools . StringTools ; import static org . junit . Assert . assertEquals ; public final class TestTools { private static final Language DEMO_LANGUAGE = new Demo ( ) ; private TestTools ( ) { } public static Language getDemoLanguage ( ) { return DEMO_LANGUAGE ; } public static Set < Language > getLanguagesExcept ( String [ ] langCodes ) { final Set < Language > languages = new HashSet < > ( ) ; languages . addAll ( Languages . getWithDemoLanguage ( ) ) ; if ( langCodes != null ) { for ( String langCode : langCodes ) { final Language lang = Languages . getLanguageForShortName ( langCode ) ; languages . remove ( lang ) ; } } return languages ; } public static ResourceBundle getEnglishMessages ( ) { return getMessages ( "en" ) ; } public static ResourceBundle getMessages ( String languageCode ) { if ( languageCode . length ( ) > 3 ) { throw new RuntimeException ( "Use a character code (ISO-639 code), not a full language name: " + languageCode ) ; } final ResourceBundle messages = ResourceBundle . getBundle ( JLanguageTool . MESSAGE_BUNDLE , new Locale ( languageCode ) ) ; return messages ; } public static void testSplit ( final String [ ] sentences , final SentenceTokenizer sTokenizer ) { final StringBuilder inputString = new StringBuilder ( ) ; final List < String > input = new ArrayList < > ( ) ; Collections . addAll ( input , sentences ) ; for ( final String s : input ) { inputString . append ( s ) ; } assertEquals ( input , sTokenizer . tokenize ( inputString . toString ( ) ) ) ; } public static void myAssert ( final String input , final String expected , final Tokenizer tokenizer , final Tagger tagger ) throws IOException { final List < String > tokens = tokenizer . tokenize ( input ) ; final List < String > noWhitespaceTokens = getNoWhitespaceTokens ( tokens ) ; final List < AnalyzedTokenReadings > output = tagger . tag ( noWhitespaceTokens ) ; final StringBuilder outputStr = new StringBuilder ( ) ; for ( final Iterator < AnalyzedTokenReadings > iter = output . iterator ( ) ; iter . hasNext ( ) ; ) { final AnalyzedTokenReadings tokenReadings = iter . next ( ) ; final List < String > readings = getAsStrings ( tokenReadings ) ; outputStr . append ( StringTools . listToString ( readings , "|" ) ) ; if ( iter . hasNext ( ) ) { outputStr . append ( " -- " ) ; } } assertEquals ( expected , outputStr . toString ( ) ) ; } public static void myAssert ( final String input , final String expected , final Tokenizer tokenizer , final SentenceTokenizer sentenceTokenizer , final Tagger tagger , final Disambiguator disambiguator ) throws IOException { final StringBuilder outputStr = new StringBuilder ( ) ; final List < String > sentences = sentenceTokenizer . tokenize ( input ) ; for ( final String sentence : sentences ) { final List < String > tokens = tokenizer . tokenize ( sentence ) ; final List < String > noWhitespaceTokens = getNoWhitespaceTokens ( tokens ) ; final List < AnalyzedTokenReadings > aTokens = tagger . tag ( noWhitespaceTokens ) ; final AnalyzedTokenReadings [ ] tokenArray = new AnalyzedTokenReadings [ tokens . size ( ) + 1 ] ; final AnalyzedToken [ ] startTokenArray = new AnalyzedToken [ 1 ] ; int toArrayCount = 0 ; final AnalyzedToken sentenceStartToken = new AnalyzedToken ( "" , JLanguageTool . SENTENCE_START_TAGNAME , null ) ; startTokenArray [ 0 ] = sentenceStartToken ; tokenArray [ toArrayCount ++ ] = new AnalyzedTokenReadings ( startTokenArray , 0 ) ; int startPos = 0 ; int noWhitespaceCount = 0 ; for ( final String tokenStr : tokens ) { AnalyzedTokenReadings posTag ; if ( isWord ( tokenStr ) ) { posTag = aTokens . get ( noWhitespaceCount ) ; posTag . setStartPos ( startPos ) ; noWhitespaceCount ++ ; } else { posTag = tagger . createNullToken ( tokenStr , startPos ) ; } tokenArray [ toArrayCount ++ ] = posTag ; startPos += tokenStr . length ( ) ; } AnalyzedSentence finalSentence = new AnalyzedSentence ( tokenArray ) ; finalSentence = disambiguator . disambiguate ( finalSentence ) ; final AnalyzedTokenReadings [ ] output = finalSentence . getTokens ( ) ; for ( int i = 0 ; i < output . length ; i ++ ) { final AnalyzedTokenReadings tokenReadings = output [ i ] ; final List < String > readings = getAsStrings ( tokenReadings ) ; outputStr . append ( StringTools . listToString ( readings , "|" ) ) ; if ( i < output . length - 1 ) { outputStr . append ( ' ' ) ; } } } assertEquals ( expected , outputStr . toString ( ) ) ; } public static boolean isWord ( final String token ) { for ( int i = 0 ; i < token . length ( ) ; i ++ ) { final char c = token . charAt ( i ) ; if ( Character . isLetter ( c ) || Character . isDigit ( c ) ) { return true ; } } return false ; } public static void testDictionary ( BaseTagger tagger , Language language ) throws IOException { final Dictionary dictionary = Dictionary . read ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( tagger . getDictionaryPath ( ) ) ) ; final DictionaryLookup lookup = new DictionaryLookup ( dictionary ) ; for ( WordData wordData : lookup ) { if ( wordData . getTag ( ) == null || wordData . getTag ( ) . length ( ) == 0 ) { System . err . println ( "**** Warning: " + language + ": the word " + wordData . getWord ( ) + "/" + wordData . getStem ( ) + " lacks a POS tag in the dictionary." ) ; } } } private static List < String > getAsStrings ( AnalyzedTokenReadings tokenReadings ) { final List < String > readings = new ArrayList < > ( ) ; for ( AnalyzedToken analyzedToken : tokenReadings ) { readings . add ( getAsString ( analyzedToken ) ) ; } Collections . sort ( readings ) ; return readings ; } private static String getAsString ( AnalyzedToken analyzedToken ) { return analyzedToken . getToken ( ) + "/[" + analyzedToken . getLemma ( ) + ']' + analyzedToken . getPOSTag ( ) ; } private static List < String > getNoWhitespaceTokens ( List < String > tokens ) { final List < String > noWhitespaceTokens = new ArrayList < > ( ) ; for ( final String token : tokens ) { if ( isWord ( token ) ) { noWhitespaceTokens . add ( token ) ; } } return noWhitespaceTokens ; } }
package org . languagetool ; import org . languagetool . language . Contributor ; import org . languagetool . rules . Rule ; import org . languagetool . rules . patterns . PatternRule ; import java . io . IOException ; import java . util . Collections ; import java . util . List ; import java . util . ResourceBundle ; public class FakeLanguage extends Language { private final String langCode ; private final String country ; public FakeLanguage ( ) { this . langCode = "yy" ; this . country = "YY" ; } public FakeLanguage ( String langCode ) { this . langCode = langCode ; this . country = "YY" ; } public FakeLanguage ( String langCode , String country ) { this . langCode = langCode ; this . country = country ; } @ Override protected synchronized List < PatternRule > getPatternRules ( ) throws IOException { return Collections . emptyList ( ) ; } @ Override public String getShortName ( ) { return langCode ; } @ Override public String getName ( ) { return "FakeLanguage" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { country } ; } @ Override public Contributor [ ] getMaintainers ( ) { return null ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Collections . emptyList ( ) ; } }
package org . languagetool ; import junit . framework . TestCase ; public class AnalyzedTokenTest extends TestCase { public void testToString ( ) { final AnalyzedToken testToken = new AnalyzedToken ( "word" , "POS" , "lemma" ) ; assertEquals ( "lemma/POS" , testToken . toString ( ) ) ; assertEquals ( "lemma" , testToken . getLemma ( ) ) ; final AnalyzedToken testToken2 = new AnalyzedToken ( "word" , "POS" , null ) ; assertEquals ( "word/POS" , testToken2 . toString ( ) ) ; assertEquals ( null , testToken2 . getLemma ( ) ) ; assertEquals ( "word" , testToken2 . getToken ( ) ) ; } public void testMatches ( ) { final AnalyzedToken testToken1 = new AnalyzedToken ( "word" , "POS" , "lemma" ) ; assertFalse ( testToken1 . matches ( new AnalyzedToken ( "" , null , null ) ) ) ; assertTrue ( testToken1 . matches ( new AnalyzedToken ( "word" , null , null ) ) ) ; assertTrue ( testToken1 . matches ( new AnalyzedToken ( "word" , "POS" , null ) ) ) ; assertTrue ( testToken1 . matches ( new AnalyzedToken ( "word" , "POS" , "lemma" ) ) ) ; assertFalse ( testToken1 . matches ( new AnalyzedToken ( "word" , "POS1" , "lemma" ) ) ) ; assertFalse ( testToken1 . matches ( new AnalyzedToken ( "word1" , "POS" , "lemma" ) ) ) ; assertFalse ( testToken1 . matches ( new AnalyzedToken ( "word" , "POS" , "lemma1" ) ) ) ; assertTrue ( testToken1 . matches ( new AnalyzedToken ( "" , "POS" , "lemma" ) ) ) ; assertTrue ( testToken1 . matches ( new AnalyzedToken ( "" , null , "lemma" ) ) ) ; } }
package org . languagetool ; import java . io . ByteArrayInputStream ; import java . io . IOException ; import java . io . InputStream ; import java . io . StringReader ; import java . net . URL ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import javax . xml . XMLConstants ; import javax . xml . parsers . DocumentBuilder ; import javax . xml . parsers . DocumentBuilderFactory ; import javax . xml . parsers . ParserConfigurationException ; import javax . xml . parsers . SAXParser ; import javax . xml . parsers . SAXParserFactory ; import javax . xml . transform . Source ; import javax . xml . transform . dom . DOMSource ; import javax . xml . transform . stream . StreamSource ; import javax . xml . validation . Schema ; import javax . xml . validation . SchemaFactory ; import javax . xml . validation . Validator ; import org . languagetool . tools . Tools ; import org . languagetool . tools . StringTools ; import org . w3c . dom . Document ; import org . w3c . dom . Node ; import org . w3c . dom . NodeList ; import org . xml . sax . InputSource ; import org . xml . sax . SAXException ; import org . xml . sax . SAXParseException ; import org . xml . sax . helpers . DefaultHandler ; public final class XMLValidator { public XMLValidator ( ) { Tools . setPasswordAuthenticator ( ) ; } public void checkSimpleXMLString ( String xml ) throws IOException { final Pattern pattern = Pattern . compile ( "(<error.*?/>)" , Pattern . DOTALL | Pattern . MULTILINE ) ; final Matcher matcher = pattern . matcher ( xml ) ; int pos = 0 ; while ( matcher . find ( pos ) ) { final String errorElement = matcher . group ( ) ; pos = matcher . end ( ) ; if ( errorElement . contains ( "\n" ) || errorElement . contains ( "\r" ) ) { throw new IOException ( "<error ...> may not contain line breaks" ) ; } final char beforeError = xml . charAt ( matcher . start ( ) - 1 ) ; if ( beforeError != '\n' && beforeError != '\r' ) { throw new IOException ( "Each <error ...> must start on a new line" ) ; } } } public void validateXMLString ( String xml , String dtdFile , String docType ) throws SAXException , IOException , ParserConfigurationException { validateInternal ( xml , dtdFile , docType ) ; } public void validateWithDtd ( String filename , String dtdPath , String docType ) throws IOException { try ( InputStream xmlStream = this . getClass ( ) . getResourceAsStream ( filename ) ) { if ( xmlStream == null ) { throw new IOException ( "Not found in classpath: " + filename ) ; } try { final String xml = StringTools . readStream ( xmlStream , "utf-8" ) ; validateInternal ( xml , dtdPath , docType ) ; } catch ( Exception e ) { throw new IOException ( "Cannot load or parse '" + filename + "'" , e ) ; } } } public void validateWithXmlSchema ( String filename , String xmlSchemaPath ) throws IOException { try ( InputStream xmlStream = this . getClass ( ) . getResourceAsStream ( filename ) ) { if ( xmlStream == null ) { throw new IOException ( "File not found in classpath: " + filename ) ; } final URL schemaUrl = this . getClass ( ) . getResource ( xmlSchemaPath ) ; if ( schemaUrl == null ) { throw new IOException ( "XML schema not found in classpath: " + xmlSchemaPath ) ; } validateInternal ( xmlStream , schemaUrl ) ; } catch ( Exception e ) { throw new IOException ( "Cannot load or parse '" + filename + "'" , e ) ; } } public void validateWithXmlSchema ( String baseFilename , String filename , String xmlSchemaPath ) throws IOException { try ( InputStream xmlStream = this . getClass ( ) . getResourceAsStream ( filename ) ; InputStream baseXmlStream = this . getClass ( ) . getResourceAsStream ( baseFilename ) ) { if ( xmlStream == null || baseXmlStream == null ) { throw new IOException ( "Files not found in classpath: " + filename + ", " + baseFilename ) ; } final URL schemaUrl = this . getClass ( ) . getResource ( xmlSchemaPath ) ; if ( schemaUrl == null ) { throw new IOException ( "XML schema not found in classpath: " + xmlSchemaPath ) ; } validateInternal ( mergeIntoSource ( baseXmlStream , xmlStream , this . getClass ( ) . getResource ( xmlSchemaPath ) ) , schemaUrl ) ; } catch ( Exception e ) { throw new IOException ( "Cannot load or parse '" + filename + "'" , e ) ; } } private static Source mergeIntoSource ( InputStream baseXmlStream , InputStream xmlStream , URL xmlSchema ) throws Exception { DocumentBuilderFactory domFactory = DocumentBuilderFactory . newInstance ( ) ; domFactory . setIgnoringComments ( true ) ; domFactory . setValidating ( false ) ; domFactory . setNamespaceAware ( true ) ; DocumentBuilder builder = domFactory . newDocumentBuilder ( ) ; Document baseDoc = builder . parse ( baseXmlStream ) ; Document ruleDoc = builder . parse ( xmlStream ) ; NodeList unificationNodes = baseDoc . getElementsByTagName ( "unification" ) ; Node ruleNode = ruleDoc . getElementsByTagName ( "rules" ) . item ( 0 ) ; Node firstChildRuleNode = ruleNode . getChildNodes ( ) . item ( 1 ) ; for ( int i = 0 ; i < unificationNodes . getLength ( ) ; i ++ ) { Node unificationNode = ruleDoc . importNode ( unificationNodes . item ( i ) , true ) ; ruleNode . insertBefore ( unificationNode , firstChildRuleNode ) ; } return new DOMSource ( ruleDoc ) ; } public void validateStringWithXmlSchema ( String xml , String xmlSchemaPath ) throws IOException { try { final URL schemaUrl = this . getClass ( ) . getResource ( xmlSchemaPath ) ; if ( schemaUrl == null ) { throw new IOException ( "XML schema not found in classpath: " + xmlSchemaPath ) ; } final ByteArrayInputStream stream = new ByteArrayInputStream ( xml . getBytes ( "utf-8" ) ) ; validateInternal ( stream , schemaUrl ) ; } catch ( SAXException e ) { throw new RuntimeException ( e ) ; } } private void validateInternal ( String xml , String dtdPath , String docType ) throws SAXException , IOException , ParserConfigurationException { final SAXParserFactory factory = SAXParserFactory . newInstance ( ) ; factory . setValidating ( true ) ; final SAXParser saxParser = factory . newSAXParser ( ) ; final String cleanXml = xml . replaceAll ( "<!DOCTYPE.+>" , "" ) ; final String decl = "<?xml version=\"1.0\"" ; final String endDecl = "?>" ; final URL dtdUrl = this . getClass ( ) . getResource ( dtdPath ) ; if ( dtdUrl == null ) { throw new RuntimeException ( "DTD not found in classpath: " + dtdPath ) ; } final String dtd = "<!DOCTYPE " + docType + " PUBLIC \"-//W3C//DTD Rules 0.1//EN\" \"" + dtdUrl + "\">" ; final int pos = cleanXml . indexOf ( decl ) ; final int endPos = cleanXml . indexOf ( endDecl ) ; if ( pos == - 1 ) { throw new IOException ( "No XML declaration found in '" + cleanXml . substring ( 0 , Math . min ( 100 , cleanXml . length ( ) ) ) + "...'" ) ; } final String newXML = cleanXml . substring ( 0 , endPos + endDecl . length ( ) ) + "\r\n" + dtd + cleanXml . substring ( endPos + endDecl . length ( ) ) ; final InputSource is = new InputSource ( new StringReader ( newXML ) ) ; saxParser . parse ( is , new ErrorHandler ( ) ) ; } private void validateInternal ( InputStream xml , URL xmlSchema ) throws SAXException , IOException { final Validator validator = getValidator ( xmlSchema ) ; validator . validate ( new StreamSource ( xml ) ) ; } private void validateInternal ( Source xmlSrc , URL xmlSchema ) throws SAXException , IOException { final Validator validator = getValidator ( xmlSchema ) ; validator . validate ( xmlSrc ) ; } private Validator getValidator ( URL xmlSchema ) throws SAXException { final SchemaFactory sf = SchemaFactory . newInstance ( XMLConstants . W3C_XML_SCHEMA_NS_URI ) ; final Schema schema = sf . newSchema ( xmlSchema ) ; final Validator validator = schema . newValidator ( ) ; validator . setErrorHandler ( new ErrorHandler ( ) ) ; return validator ; } static class ErrorHandler extends DefaultHandler { @ Override public void warning ( SAXParseException e ) throws SAXException { System . err . println ( e . getMessage ( ) + " Problem found at line " + e . getLineNumber ( ) + ", column " + e . getColumnNumber ( ) + "." ) ; throw e ; } @ Override public void error ( SAXParseException e ) throws SAXException { System . err . println ( e . getMessage ( ) + " Problem found at line " + e . getLineNumber ( ) + ", column " + e . getColumnNumber ( ) + "." ) ; throw e ; } } }
package org . languagetool . language ; import java . util . Collections ; import java . util . List ; import java . util . Locale ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . chunking . Chunker ; import org . languagetool . chunking . xx . DemoChunker ; import org . languagetool . rules . Rule ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . xx . DemoTagger ; public class Demo extends Language { public static final String SHORT_NAME = "xx" ; String name = "Testlanguage" ; private Tagger tagger ; private Chunker chunker ; @ Override public Locale getLocale ( ) { return new Locale ( "en" ) ; } @ Override public String getName ( ) { return name ; } @ Override public String getShortName ( ) { return SHORT_NAME ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "XX" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new DemoTagger ( ) ; } return tagger ; } @ Override public Chunker getChunker ( ) { if ( chunker == null ) { chunker = new DemoChunker ( ) ; } return chunker ; } @ Override public Contributor [ ] getMaintainers ( ) { return null ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Collections . emptyList ( ) ; } }
package org . languagetool . language ; import java . util . ArrayList ; import java . util . List ; import java . util . concurrent . locks . Lock ; import java . util . concurrent . locks . ReadWriteLock ; import java . util . concurrent . locks . ReentrantReadWriteLock ; import org . junit . Assert ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; public abstract class AbstractLanguageConcurrencyTest { protected abstract Language createLanguage ( ) ; protected abstract String createSampleText ( ) ; volatile int failedTests ; @ Test public void testSpellCheckerFailure ( ) throws Exception { final String sampleText = createSampleText ( ) ; final Language language = createLanguage ( ) ; final int threadCount = Runtime . getRuntime ( ) . availableProcessors ( ) * 10 ; final int testRuns = 100 ; final ReadWriteLock testWaitLock = new ReentrantReadWriteLock ( ) ; final Lock testWriteLock = testWaitLock . writeLock ( ) ; testWriteLock . lock ( ) ; failedTests = 0 ; List < Thread > threads = new ArrayList < > ( ) ; for ( int i = 0 ; i < threadCount ; i ++ ) { Thread t = new Thread ( new TestRunner ( testWaitLock , language , testRuns , sampleText ) ) ; t . start ( ) ; threads . add ( t ) ; } testWriteLock . unlock ( ) ; for ( Thread t : threads ) { t . join ( ) ; } Assert . assertEquals ( 0 , failedTests ) ; } final class TestRunner implements Runnable { private final ReadWriteLock waitLock ; private final Language language ; private final int testRuns ; private final String sampleText ; TestRunner ( ReadWriteLock waitLock , Language language , int testRuns , String sampleText ) { this . waitLock = waitLock ; this . language = language ; this . testRuns = testRuns ; this . sampleText = sampleText ; } @ Override public void run ( ) { Lock lock = waitLock . readLock ( ) ; lock . lock ( ) ; lock . unlock ( ) ; for ( int i = 0 ; i < this . testRuns ; i ++ ) { try { JLanguageTool tool = new JLanguageTool ( this . language ) ; Assert . assertNotNull ( tool . check ( this . sampleText ) ) ; } catch ( Exception e ) { failedTests += 1 ; throw new RuntimeException ( e ) ; } } } } }
package org . languagetool . language ; import java . io . File ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; public class LanguageBuilderTest extends TestCase { public void testMakeAdditionalLanguage ( ) throws Exception { final Language language = LanguageBuilder . makeAdditionalLanguage ( new File ( "rules-xy-Fakelanguage.xml" ) ) ; assertEquals ( "Fakelanguage" , language . getName ( ) ) ; assertEquals ( "xy" , language . getShortName ( ) ) ; assertEquals ( 0 , language . getRelevantRules ( JLanguageTool . getMessageBundle ( ) ) . size ( ) ) ; assertTrue ( language . isExternal ( ) ) ; } public void testIllegalFileName ( ) throws Exception { try { LanguageBuilder . makeAdditionalLanguage ( new File ( "foo" ) ) ; fail ( ) ; } catch ( RuleFilenameException ignored ) { } } }
package org . languagetool . rules . nl ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Dutch ; import java . io . IOException ; public class DutchWrongWordInContextRuleTest extends TestCase { public void testRule ( ) throws IOException { DutchWrongWordInContextRule rule = new DutchWrongWordInContextRule ( null ) ; JLanguageTool langTool = new JLanguageTool ( new Dutch ( ) ) ; } }
package org . languagetool . rules . ca ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class ReplaceOperationNamesRuleTest extends TestCase { private ReplaceOperationNamesRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new ReplaceOperationNamesRule ( TestTools . getEnglishMessages ( ) ) ; langTool = new JLanguageTool ( new Catalan ( ) ) ; } public void testRule ( ) throws IOException { assertCorrect ( "tot tenyit amb llum de nostàlgia" ) ; assertCorrect ( "Ho van fer per duplicat." ) ; assertCorrect ( "Assecat el braç del riu" ) ; assertCorrect ( "el llibre empaquetat" ) ; assertCorrect ( "un resultat equilibrat" ) ; assertCorrect ( "el nostre equip era bastant equilibrat" ) ; assertCorrect ( "un llibre ben empaquetat" ) ; assertCorrect ( "l'informe filtrat pel ministre" ) ; assertCorrect ( "L'informe filtrat és terrible" ) ; assertCorrect ( "ha liderat la batalla" ) ; assertCorrect ( "Els tinc empaquetats" ) ; assertCorrect ( "amb tractament unitari i equilibrat" ) ; assertCorrect ( "Processat després de la mort de Carles II" ) ; assertCorrect ( "Processat diverses vegades" ) ; assertCorrect ( "moltes vegades empaquetat amb pressa" ) ; assertCorrect ( "és llavors embotellat i llançat al mercat" ) ; assertCorrect ( "la comercialització de vi embotellat amb les firmes comercials" ) ; assertCorrect ( "eixia al mercat el vi blanc embotellat amb la marca" ) ; assertCorrect ( "que arribi a un equilibrat matrimoni" ) ; assertCorrect ( "És un cafè amb molt de cos i molt equilibrat." ) ; assertCorrect ( "i per tant etiquetat com a observat" ) ; assertCorrect ( "Molt equilibrat en les seves característiques" ) ; assertCorrect ( "filtrat per Wikileaks" ) ; assertCorrect ( "una vegada filtrat" ) ; assertCorrect ( "no equilibrat" ) ; assertIncorrect ( "Assecat del braç del riu" ) ; assertIncorrect ( "Cal vigilar el filtrat del vi" ) ; assertIncorrect ( "El procés d'empaquetat" ) ; assertIncorrect ( "Els equilibrats de les rodes" ) ; assertIncorrect ( "El procés d'etiquetat de les ampolles" ) ; assertIncorrect ( "El rentat de cotes" ) ; RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "El repicat i el rejuntat." ) ) ; assertEquals ( 2 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "El procés de relligat dels llibres." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "relligadura" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "relligament" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "relligada" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Els rentats de cervell." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "rentades" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "rentatges" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "rentaments" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; } private void assertCorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( 0 , matches . length ) ; } private void assertIncorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( 1 , matches . length ) ; } public void testPositions ( ) throws IOException { final AccentuationCheckRule rule = new AccentuationCheckRule ( TestTools . getEnglishMessages ( ) ) ; final RuleMatch [ ] matches ; final JLanguageTool langTool = new JLanguageTool ( new Catalan ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Són circumstancies extraordinàries." ) ) ; assertEquals ( 4 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 18 , matches [ 0 ] . getToPos ( ) ) ; } }
package org . languagetool . chunking . xx ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . chunking . ChunkTag ; import org . languagetool . chunking . Chunker ; import java . util . Collections ; import java . util . List ; public class DemoChunker implements Chunker { @ Override public void addChunkTags ( List < AnalyzedTokenReadings > tokenReadings ) { for ( AnalyzedTokenReadings tokenReading : tokenReadings ) { if ( "chunkbar" . equals ( tokenReading . getToken ( ) ) ) { tokenReading . setChunkTags ( Collections . singletonList ( new ChunkTag ( "B-NP-singular" ) ) ) ; } } } }
package org . languagetool . languagemodel ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import java . io . File ; import java . net . URL ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; public class LuceneLanguageModelTest extends LanguageModelTest { @ Test public void testLanguageModel ( ) throws Exception { URL ngramUrl = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( "/yy/ngram-index" ) ; try ( LanguageModel model = new LuceneLanguageModel ( new File ( ngramUrl . getFile ( ) ) ) ) { assertThat ( model . getCount ( "the" ) , is ( 55L ) ) ; assertThat ( model . getCount ( "the" , "nice" ) , is ( 3L ) ) ; assertThat ( model . getCount ( "the" , "nice" , "building" ) , is ( 1L ) ) ; assertThat ( model . getCount ( "not-in-here" ) , is ( 0L ) ) ; assertThat ( model . getTotalTokenCount ( ) , is ( 3L ) ) ; } } @ Test @ Ignore ( "for interactive use only" ) public void testPerformance ( ) throws Exception { LanguageModel model = new LuceneLanguageModel ( new File ( "/data/google-gram-index/" ) ) ; super . testPerformance ( model , 3 ) ; } }
package org . languagetool . languagemodel ; import org . languagetool . tokenizers . WordTokenizer ; import org . languagetool . tools . StringTools ; import java . io . FileInputStream ; import java . util . List ; public class LanguageModelTest { private static final int SKIP_FIRST_ITEMS = 5 ; private static final String FILE = "/lt/performance-test/en.txt" ; protected void testPerformance ( LanguageModel model , int ngramLength ) throws Exception { try ( FileInputStream fis = new FileInputStream ( FILE ) ) { String content = StringTools . readStream ( fis , "UTF-8" ) ; WordTokenizer wordTokenizer = new WordTokenizer ( ) ; List < String > words = wordTokenizer . tokenize ( content ) ; String prevPrevWord = null ; String prevWord = null ; int i = 0 ; long totalMicros = 0 ; for ( String word : words ) { if ( word . trim ( ) . isEmpty ( ) ) { continue ; } if ( prevWord != null ) { long t1 = System . nanoTime ( ) / 1000 ; long count = 0 ; if ( ngramLength == 2 ) { count = model . getCount ( prevWord , word ) ; } else if ( ngramLength == 3 ) { if ( prevPrevWord != null ) { count = model . getCount ( prevPrevWord , prevWord , word ) ; } } else { throw new IllegalArgumentException ( "ngram length not supported: " + ngramLength ) ; } long timeMicros = ( System . nanoTime ( ) / 1000 ) - t1 ; long timeMillis = timeMicros / 1000 ; if ( ngramLength == 2 ) { System . out . println ( count + "\t\t" + prevWord + " " + word + ": " + timeMicros + "µs = " + timeMillis + "ms" ) ; } else if ( ngramLength == 3 ) { System . out . println ( count + "\t\t" + prevPrevWord + " " + prevWord + " " + word + ": " + timeMicros + "µs = " + timeMillis + "ms" ) ; } if ( i > SKIP_FIRST_ITEMS ) { totalMicros += timeMicros ; } if ( ++ i % 25 == 0 ) { printStats ( i , totalMicros ) ; } } prevPrevWord = prevWord ; prevWord = word ; } printStats ( i , totalMicros ) ; } } private void printStats ( int i , long totalMicros ) { long averageMicros = totalMicros / i ; System . out . println ( "*** Average: " + averageMicros + "µs = " + ( averageMicros / 1000 ) + "ms" ) ; } }
package org . languagetool . synthesis ; import java . io . ByteArrayInputStream ; import java . io . IOException ; import junit . framework . TestCase ; public class ManualSynthesizerTest extends TestCase { private ManualSynthesizer synthesizer ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; final String data = "# some test data\n" + "InflectedForm11\tLemma1\tPOS1\n" + "InflectedForm121\tLemma1\tPOS2\n" + "InflectedForm122\tLemma1\tPOS2\n" + "InflectedForm2\tLemma2\tPOS1\n" ; synthesizer = new ManualSynthesizer ( new ByteArrayInputStream ( data . getBytes ( "UTF-8" ) ) ) ; } public void testLookupNonExisting ( ) throws IOException { assertNull ( synthesizer . lookup ( "" , "" ) ) ; assertNull ( synthesizer . lookup ( "" , null ) ) ; assertNull ( synthesizer . lookup ( null , "" ) ) ; assertNull ( synthesizer . lookup ( null , null ) ) ; assertNull ( synthesizer . lookup ( "NONE" , "UNKNOWN" ) ) ; } public void testInvalidLookup ( ) throws IOException { assertNull ( synthesizer . lookup ( "NONE" , "POS1" ) ) ; assertNull ( synthesizer . lookup ( "Lemma1" , "UNKNOWN" ) ) ; assertNull ( synthesizer . lookup ( "Lemma1" , "POS." ) ) ; assertNull ( synthesizer . lookup ( "Lemma2" , "POS2" ) ) ; } public void testValidLookup ( ) throws IOException { assertEquals ( "[InflectedForm11]" , String . valueOf ( synthesizer . lookup ( "Lemma1" , "POS1" ) ) ) ; assertEquals ( "[InflectedForm121, InflectedForm122]" , String . valueOf ( synthesizer . lookup ( "Lemma1" , "POS2" ) ) ) ; assertEquals ( "[InflectedForm2]" , String . valueOf ( synthesizer . lookup ( "Lemma2" , "POS1" ) ) ) ; } public void testCaseSensitive ( ) throws IOException { assertNull ( synthesizer . lookup ( "LEmma1" , "POS1" ) ) ; } }
package org . languagetool . synthesis ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; import morfologik . stemming . IStemmer ; import morfologik . stemming . WordData ; public class ManualSynthesizerAdapter extends BaseSynthesizer { private final ManualSynthesizer manualSynthesizer ; public ManualSynthesizerAdapter ( ManualSynthesizer manualSynthesizer ) { super ( null , null ) ; this . manualSynthesizer = manualSynthesizer ; } @ Override protected IStemmer createStemmer ( ) { return new IStemmer ( ) { @ Override public List < WordData > lookup ( CharSequence word ) { return Collections . emptyList ( ) ; } } ; } @ Override protected void initPossibleTags ( ) throws IOException { if ( possibleTags == null ) { possibleTags = new ArrayList < > ( manualSynthesizer . getPossibleTags ( ) ) ; } } @ Override protected void lookup ( String lemma , String posTag , List < String > results ) { super . lookup ( lemma , posTag , results ) ; final List < String > manualForms = manualSynthesizer . lookup ( lemma . toLowerCase ( ) , posTag ) ; if ( manualForms != null ) { results . addAll ( manualForms ) ; } } }
package org . languagetool . tools ; import junit . framework . TestCase ; public class ContextToolsTest extends TestCase { public void testGetContext ( ) throws Exception { final ContextTools contextTools = new ContextTools ( ) ; final String context = contextTools . getContext ( 4 , 8 , "Hi, this is some nice text waiting for its error markers." ) ; assertEquals ( "Hi, <b><font bgcolor=\"#ff8b8b\">this</font></b> is some nice text waiting for its error..." , context ) ; final String context2 = contextTools . getContext ( 3 , 5 , "xxx\n \nyyy" ) ; assertEquals ( "xxx<b><font bgcolor=\"#ff8b8b\">&nbsp;&nbsp;</font></b> yyy" , context2 ) ; } public void testPlainTextContext ( ) throws Exception { final ContextTools contextTools = new ContextTools ( ) ; contextTools . setContextSize ( 5 ) ; final String input = "This is a test sentence. Here's another sentence with more text." ; final String result = contextTools . getPlainTextContext ( 8 , 14 , input ) ; assertEquals ( "...s is a test sent...\n ^^^^^^ " , result ) ; } public void testLargerContext ( ) throws Exception { final ContextTools contextTools = new ContextTools ( ) ; contextTools . setContextSize ( 100 ) ; final String context = contextTools . getContext ( 4 , 8 , "Hi, this is some nice text waiting for its error markers." ) ; assertEquals ( "Hi, <b><font bgcolor=\"#ff8b8b\">this</font></b> is some nice text waiting for its error markers." , context ) ; } public void testHtmlEscape ( ) throws Exception { final ContextTools contextTools = new ContextTools ( ) ; final String context1 = contextTools . getContext ( 0 , 2 , "Hi, this is <html>." ) ; assertEquals ( "<b><font bgcolor=\"#ff8b8b\">Hi</font></b>, this is &lt;html&gt;." , context1 ) ; contextTools . setEscapeHtml ( false ) ; final String context2 = contextTools . getContext ( 0 , 2 , "Hi, this is <html>." ) ; assertEquals ( "<b><font bgcolor=\"#ff8b8b\">Hi</font></b>, this is <html>." , context2 ) ; } public void testMarkers ( ) throws Exception { final ContextTools contextTools = new ContextTools ( ) ; contextTools . setErrorMarkerStart ( "<X>" ) ; contextTools . setErrorMarkerEnd ( "</X>" ) ; final String context = contextTools . getContext ( 0 , 2 , "Hi, this is it." ) ; assertEquals ( "<X>Hi</X>, this is it." , context ) ; } }
package org . languagetool . tools ; import org . apache . commons . lang . StringUtils ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . FakeLanguage ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . PatternRule ; import java . io . IOException ; import java . net . MalformedURLException ; import java . net . URL ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . assertThat ; import static org . languagetool . tools . StringTools . XmlPrintMode . * ; @ SuppressWarnings ( "MagicNumber" ) public class RuleAsXmlSerializerTest { private static final RuleAsXmlSerializer SERIALIZER = new RuleAsXmlSerializer ( ) ; private static final Language LANG = TestTools . getDemoLanguage ( ) ; @ Test public void testLanguageAttributes ( ) throws IOException { final String xml1 = SERIALIZER . ruleMatchesToXml ( Collections . < RuleMatch > emptyList ( ) , "Fake" , 5 , NORMAL_XML , LANG , Collections . < String > emptyList ( ) ) ; assertTrue ( xml1 . contains ( "shortname=\"xx-XX\"" ) ) ; assertTrue ( xml1 . contains ( "name=\"Testlanguage\"" ) ) ; final String xml2 = SERIALIZER . ruleMatchesToXml ( Collections . < RuleMatch > emptyList ( ) , "Fake" , 5 , LANG , new FakeLanguage ( ) ) ; assertTrue ( xml2 . contains ( "shortname=\"xx-XX\"" ) ) ; assertTrue ( xml2 . contains ( "name=\"Testlanguage\"" ) ) ; assertTrue ( xml2 . contains ( "shortname=\"yy\"" ) ) ; assertTrue ( xml2 . contains ( "name=\"FakeLanguage\"" ) ) ; assertThat ( StringUtils . countMatches ( xml2 , "<matches" ) , is ( 1 ) ) ; assertThat ( StringUtils . countMatches ( xml2 , "</matches>" ) , is ( 1 ) ) ; } @ Test public void testApiModes ( ) throws IOException { String xmlStart = SERIALIZER . ruleMatchesToXml ( Collections . < RuleMatch > emptyList ( ) , "Fake" , 5 , START_XML , LANG , Collections . < String > emptyList ( ) ) ; assertThat ( StringUtils . countMatches ( xmlStart , "<matches" ) , is ( 1 ) ) ; assertThat ( StringUtils . countMatches ( xmlStart , "</matches>" ) , is ( 0 ) ) ; String xmlMiddle = SERIALIZER . ruleMatchesToXml ( Collections . < RuleMatch > emptyList ( ) , "Fake" , 5 , CONTINUE_XML , LANG , Collections . < String > emptyList ( ) ) ; assertThat ( StringUtils . countMatches ( xmlMiddle , "<matches" ) , is ( 0 ) ) ; assertThat ( StringUtils . countMatches ( xmlMiddle , "</matches>" ) , is ( 0 ) ) ; String xmlEnd = SERIALIZER . ruleMatchesToXml ( Collections . < RuleMatch > emptyList ( ) , "Fake" , 5 , END_XML , LANG , Collections . < String > emptyList ( ) ) ; assertThat ( StringUtils . countMatches ( xmlEnd , "<matches" ) , is ( 0 ) ) ; assertThat ( StringUtils . countMatches ( xmlEnd , "</matches>" ) , is ( 1 ) ) ; String xml = SERIALIZER . ruleMatchesToXml ( Collections . < RuleMatch > emptyList ( ) , "Fake" , 5 , NORMAL_XML , LANG , Collections . < String > emptyList ( ) ) ; assertThat ( StringUtils . countMatches ( xml , "<matches" ) , is ( 1 ) ) ; assertThat ( StringUtils . countMatches ( xml , "</matches>" ) , is ( 1 ) ) ; } @ Test public void testRuleMatchesToXML ( ) throws IOException { final List < RuleMatch > matches = new ArrayList < > ( ) ; final String text = "This is an test sentence. Here's another sentence with more text." ; final FakeRule rule = new FakeRule ( ) ; final RuleMatch match = new RuleMatch ( rule , 8 , 10 , "myMessage" ) ; match . setColumn ( 99 ) ; match . setEndColumn ( 100 ) ; match . setLine ( 44 ) ; match . setEndLine ( 45 ) ; matches . add ( match ) ; final String xml = SERIALIZER . ruleMatchesToXml ( matches , text , 5 , NORMAL_XML , LANG , Collections . < String > emptyList ( ) ) ; assertTrue ( xml . startsWith ( "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n" ) ) ; final Pattern matchesPattern = Pattern . compile ( ".*<matches software=\"LanguageTool\" version=\"" + JLanguageTool . VERSION + "\" buildDate=\".*?\">.*" , Pattern . DOTALL ) ; final Matcher matcher = matchesPattern . matcher ( xml ) ; assertTrue ( "Did not find expected '<matches>' element, got: " + xml , matcher . matches ( ) ) ; assertTrue ( xml . contains ( ">\n" + "<error fromy=\"44\" fromx=\"98\" toy=\"45\" tox=\"99\" ruleId=\"FAKE_ID\" msg=\"myMessage\" " + "replacements=\"\" context=\"...s is an test...\" contextoffset=\"8\" offset=\"8\" errorlength=\"2\" " + "locqualityissuetype=\"misspelling\"/>\n" + "</matches>\n" ) ) ; } @ Test public void testRuleMatchesToXMLWithCategory ( ) throws IOException { final List < RuleMatch > matches = new ArrayList < > ( ) ; final String text = "This is a test sentence." ; final List < PatternToken > patternTokens = Collections . emptyList ( ) ; final Rule patternRule = new PatternRule ( "MY_ID" , LANG , patternTokens , "my description" , "my message" , "short message" ) ; patternRule . setCategory ( new Category ( "MyCategory" ) ) ; final RuleMatch match = new RuleMatch ( patternRule , 8 , 10 , "myMessage" ) ; match . setColumn ( 99 ) ; match . setEndColumn ( 100 ) ; match . setLine ( 44 ) ; match . setEndLine ( 45 ) ; matches . add ( match ) ; final String xml = SERIALIZER . ruleMatchesToXml ( matches , text , 5 , LANG , LANG ) ; assertTrue ( xml . contains ( ">\n" + "<error fromy=\"44\" fromx=\"98\" toy=\"45\" tox=\"99\" ruleId=\"MY_ID\" msg=\"myMessage\" " + "replacements=\"\" context=\"...s is a test ...\" contextoffset=\"8\" offset=\"8\" errorlength=\"2\" category=\"MyCategory\" " + "locqualityissuetype=\"uncategorized\"/>\n" + "</matches>\n" ) ) ; } @ Test public void testRuleMatchesWithUrlToXML ( ) throws IOException { final List < RuleMatch > matches = new ArrayList < > ( ) ; final String text = "This is an test sentence. Here's another sentence with more text." ; final RuleMatch match = new RuleMatch ( new FakeRule ( ) { @ Override public URL getUrl ( ) { try { return new URL ( "http://server.org?id=1&foo=bar" ) ; } catch ( MalformedURLException e ) { throw new RuntimeException ( e ) ; } } } , 8 , 10 , "myMessage" ) ; match . setColumn ( 99 ) ; match . setEndColumn ( 100 ) ; match . setLine ( 44 ) ; match . setEndLine ( 45 ) ; matches . add ( match ) ; final String xml = SERIALIZER . ruleMatchesToXml ( matches , text , 5 , NORMAL_XML , LANG , Collections . < String > emptyList ( ) ) ; assertTrue ( xml . contains ( ">\n" + "<error fromy=\"44\" fromx=\"98\" toy=\"45\" tox=\"99\" ruleId=\"FAKE_ID\" msg=\"myMessage\" " + "replacements=\"\" context=\"...s is an test...\" contextoffset=\"8\" offset=\"8\" errorlength=\"2\" url=\"http://server.org?id=1&amp;foo=bar\" " + "locqualityissuetype=\"misspelling\"/>\n" + "</matches>\n" ) ) ; } @ Test public void testRuleMatchesToXMLEscapeBug ( ) throws IOException { final List < RuleMatch > matches = new ArrayList < > ( ) ; final String text = "This is \"an test sentence. Here's another sentence with more text." ; final RuleMatch match = new RuleMatch ( new FakeRule ( ) , 9 , 11 , "myMessage" ) ; match . setColumn ( 99 ) ; match . setEndColumn ( 100 ) ; match . setLine ( 44 ) ; match . setEndLine ( 45 ) ; matches . add ( match ) ; final String xml = SERIALIZER . ruleMatchesToXml ( matches , text , 5 , NORMAL_XML , LANG , Collections . < String > emptyList ( ) ) ; assertTrue ( xml . contains ( ">\n" + "<error fromy=\"44\" fromx=\"98\" toy=\"45\" tox=\"99\" ruleId=\"FAKE_ID\" msg=\"myMessage\" " + "replacements=\"\" context=\"... is &quot;an test...\" contextoffset=\"8\" offset=\"9\" errorlength=\"2\" " + "locqualityissuetype=\"misspelling\"/>\n" + "</matches>\n" ) ) ; } private static class FakeRule extends PatternRule { FakeRule ( ) { super ( "FAKE_ID" , TestTools . getDemoLanguage ( ) , Collections . singletonList ( new PatternToken ( "foo" , true , false , false ) ) , "My fake description" , "Fake message" , "Fake short message" ) ; } @ Override public ITSIssueType getLocQualityIssueType ( ) { return ITSIssueType . Misspelling ; } } }
package org . languagetool . tools ; import junit . framework . TestCase ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . FakeLanguage ; import java . io . FileInputStream ; import java . io . IOException ; import java . io . StringReader ; import java . util . ArrayList ; import java . util . List ; public class StringToolsTest extends TestCase { public void testAssureSet ( ) { try { StringTools . assureSet ( "" , "varName" ) ; fail ( ) ; } catch ( IllegalArgumentException ignored ) { } try { StringTools . assureSet ( " \t" , "varName" ) ; fail ( ) ; } catch ( IllegalArgumentException ignored ) { } try { StringTools . assureSet ( null , "varName" ) ; fail ( ) ; } catch ( NullPointerException ignored ) { } StringTools . assureSet ( "foo" , "varName" ) ; } public void testReadStream ( ) throws IOException { final String content = StringTools . readStream ( new FileInputStream ( "src/test/resources/testinput.txt" ) , "utf-8" ) ; assertEquals ( "one\ntwo\nöäüß\nșțîâăȘȚÎÂĂ\n" , content ) ; } public void testIsAllUppercase ( ) { assertTrue ( StringTools . isAllUppercase ( "A" ) ) ; assertTrue ( StringTools . isAllUppercase ( "ABC" ) ) ; assertTrue ( StringTools . isAllUppercase ( "ASV-EDR" ) ) ; assertTrue ( StringTools . isAllUppercase ( "ASV-ÖÄÜ" ) ) ; assertTrue ( StringTools . isAllUppercase ( "" ) ) ; assertFalse ( StringTools . isAllUppercase ( "ß" ) ) ; assertFalse ( StringTools . isAllUppercase ( "AAAAAAAAAAAAq" ) ) ; assertFalse ( StringTools . isAllUppercase ( "a" ) ) ; assertFalse ( StringTools . isAllUppercase ( "abc" ) ) ; } public void testIsMixedCase ( ) { assertTrue ( StringTools . isMixedCase ( "AbC" ) ) ; assertTrue ( StringTools . isMixedCase ( "MixedCase" ) ) ; assertTrue ( StringTools . isMixedCase ( "iPod" ) ) ; assertTrue ( StringTools . isMixedCase ( "AbCdE" ) ) ; assertFalse ( StringTools . isMixedCase ( "" ) ) ; assertFalse ( StringTools . isMixedCase ( "ABC" ) ) ; assertFalse ( StringTools . isMixedCase ( "abc" ) ) ; assertFalse ( StringTools . isMixedCase ( "!" ) ) ; assertFalse ( StringTools . isMixedCase ( "Word" ) ) ; } public void testIsCapitalizedWord ( ) { assertTrue ( StringTools . isCapitalizedWord ( "Abc" ) ) ; assertTrue ( StringTools . isCapitalizedWord ( "Uppercase" ) ) ; assertTrue ( StringTools . isCapitalizedWord ( "Ipod" ) ) ; assertFalse ( StringTools . isCapitalizedWord ( "" ) ) ; assertFalse ( StringTools . isCapitalizedWord ( "ABC" ) ) ; assertFalse ( StringTools . isCapitalizedWord ( "abc" ) ) ; assertFalse ( StringTools . isCapitalizedWord ( "!" ) ) ; assertFalse ( StringTools . isCapitalizedWord ( "wOrD" ) ) ; } public void testStartsWithUppercase ( ) { assertTrue ( StringTools . startsWithUppercase ( "A" ) ) ; assertTrue ( StringTools . startsWithUppercase ( "ÄÖ" ) ) ; assertFalse ( StringTools . startsWithUppercase ( "" ) ) ; assertFalse ( StringTools . startsWithUppercase ( "ß" ) ) ; assertFalse ( StringTools . startsWithUppercase ( "-" ) ) ; } public void testUppercaseFirstChar ( ) { assertEquals ( null , StringTools . uppercaseFirstChar ( null ) ) ; assertEquals ( "" , StringTools . uppercaseFirstChar ( "" ) ) ; assertEquals ( "A" , StringTools . uppercaseFirstChar ( "A" ) ) ; assertEquals ( "Öäü" , StringTools . uppercaseFirstChar ( "öäü" ) ) ; assertEquals ( "ßa" , StringTools . uppercaseFirstChar ( "ßa" ) ) ; assertEquals ( "'Test'" , StringTools . uppercaseFirstChar ( "'test'" ) ) ; assertEquals ( "''Test" , StringTools . uppercaseFirstChar ( "''test" ) ) ; assertEquals ( "''T" , StringTools . uppercaseFirstChar ( "''t" ) ) ; assertEquals ( "'''" , StringTools . uppercaseFirstChar ( "'''" ) ) ; } public void testLowercaseFirstChar ( ) { assertEquals ( null , StringTools . lowercaseFirstChar ( null ) ) ; assertEquals ( "" , StringTools . lowercaseFirstChar ( "" ) ) ; assertEquals ( "a" , StringTools . lowercaseFirstChar ( "A" ) ) ; assertEquals ( "öäü" , StringTools . lowercaseFirstChar ( "Öäü" ) ) ; assertEquals ( "ßa" , StringTools . lowercaseFirstChar ( "ßa" ) ) ; assertEquals ( "'test'" , StringTools . lowercaseFirstChar ( "'Test'" ) ) ; assertEquals ( "''test" , StringTools . lowercaseFirstChar ( "''Test" ) ) ; assertEquals ( "''t" , StringTools . lowercaseFirstChar ( "''T" ) ) ; assertEquals ( "'''" , StringTools . lowercaseFirstChar ( "'''" ) ) ; } public void testReaderToString ( ) throws IOException { final String str = StringTools . readerToString ( new StringReader ( "bla\nöäü" ) ) ; assertEquals ( "bla\nöäü" , str ) ; final StringBuilder longStr = new StringBuilder ( ) ; for ( int i = 0 ; i < 4000 ; i ++ ) { longStr . append ( "x" ) ; } longStr . append ( "1234567" ) ; assertEquals ( 4007 , longStr . length ( ) ) ; final String str2 = StringTools . readerToString ( new StringReader ( longStr . toString ( ) ) ) ; assertEquals ( longStr . toString ( ) , str2 ) ; } public void testEscapeXMLandHTML ( ) { assertEquals ( "!ä&quot;&lt;&gt;&amp;&amp;" , StringTools . escapeXML ( "!ä\"<>&&" ) ) ; assertEquals ( "!ä&quot;&lt;&gt;&amp;&amp;" , StringTools . escapeHTML ( "!ä\"<>&&" ) ) ; } public void testListToString ( ) { final List < String > list = new ArrayList < > ( ) ; list . add ( "foo" ) ; list . add ( "bar" ) ; list . add ( "," ) ; assertEquals ( "foo,bar,," , StringTools . listToString ( list , "," ) ) ; assertEquals ( "foo\tbar\t," , StringTools . listToString ( list , "\t" ) ) ; } public void testTrimWhitespace ( ) { try { assertEquals ( null , StringTools . trimWhitespace ( null ) ) ; fail ( ) ; } catch ( NullPointerException ignored ) { } assertEquals ( "" , StringTools . trimWhitespace ( "" ) ) ; assertEquals ( "" , StringTools . trimWhitespace ( " " ) ) ; assertEquals ( "XXY" , StringTools . trimWhitespace ( " \nXX\t Y" ) ) ; assertEquals ( "XXY" , StringTools . trimWhitespace ( " \r\nXX\t Y" ) ) ; assertEquals ( "word" , StringTools . trimWhitespace ( "word" ) ) ; assertEquals ( "1 234,56" , StringTools . trimWhitespace ( "1 234,56" ) ) ; assertEquals ( "1234,56" , StringTools . trimWhitespace ( "1 234,56" ) ) ; } public void testAddSpace ( ) { Language demoLanguage = TestTools . getDemoLanguage ( ) ; assertEquals ( " " , StringTools . addSpace ( "word" , demoLanguage ) ) ; assertEquals ( "" , StringTools . addSpace ( "," , demoLanguage ) ) ; assertEquals ( "" , StringTools . addSpace ( "," , demoLanguage ) ) ; assertEquals ( "" , StringTools . addSpace ( "," , demoLanguage ) ) ; assertEquals ( "" , StringTools . addSpace ( "." , new FakeLanguage ( "fr" ) ) ) ; assertEquals ( "" , StringTools . addSpace ( "." , new FakeLanguage ( "de" ) ) ) ; assertEquals ( " " , StringTools . addSpace ( "!" , new FakeLanguage ( "fr" ) ) ) ; assertEquals ( "" , StringTools . addSpace ( "!" , new FakeLanguage ( "de" ) ) ) ; } public void testIsWhitespace ( ) { assertEquals ( true , StringTools . isWhitespace ( " " ) ) ; assertEquals ( true , StringTools . isWhitespace ( "\t" ) ) ; assertEquals ( true , StringTools . isWhitespace ( "\u2002" ) ) ; assertEquals ( false , StringTools . isWhitespace ( "\u00a0" ) ) ; assertEquals ( false , StringTools . isWhitespace ( "abc" ) ) ; assertEquals ( false , StringTools . isWhitespace ( "\\u02" ) ) ; assertEquals ( false , StringTools . isWhitespace ( "\u0001" ) ) ; } public void testIsPositiveNumber ( ) { assertEquals ( true , StringTools . isPositiveNumber ( '3' ) ) ; assertEquals ( false , StringTools . isPositiveNumber ( 'a' ) ) ; } public void testIsEmpty ( ) { assertEquals ( true , StringTools . isEmpty ( "" ) ) ; assertEquals ( true , StringTools . isEmpty ( null ) ) ; assertEquals ( false , StringTools . isEmpty ( "a" ) ) ; } public void testFilterXML ( ) { assertEquals ( "test" , StringTools . filterXML ( "test" ) ) ; assertEquals ( "<<test>>" , StringTools . filterXML ( "<<test>>" ) ) ; assertEquals ( "test" , StringTools . filterXML ( "<b>test</b>" ) ) ; assertEquals ( "A sentence with a test" , StringTools . filterXML ( "A sentence with a <em>test</em>" ) ) ; } public void testAsString ( ) { assertNull ( StringTools . asString ( null ) ) ; assertEquals ( "foo!" , "foo!" ) ; } }
package org . languagetool . bitext ; import java . io . File ; import java . io . FileOutputStream ; import java . io . OutputStreamWriter ; import java . io . PrintWriter ; import junit . framework . TestCase ; public class TabBitextReaderTest extends TestCase { public void testReader ( ) throws Exception { final File input = File . createTempFile ( "input" , "txt" ) ; input . deleteOnExit ( ) ; final PrintWriter writer = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( input ) , "UTF-8" ) ) ; writer . println ( "This is not actual.\tTo nie jest aktualne." ) ; writer . println ( "Test\tTest" ) ; writer . println ( "ab\tVery strange data indeed, much longer than input" ) ; writer . close ( ) ; final TabBitextReader reader = new TabBitextReader ( input . getAbsolutePath ( ) , "UTF-8" ) ; int i = 1 ; for ( StringPair srcAndTrg : reader ) { assertTrue ( srcAndTrg . getSource ( ) != null ) ; assertTrue ( srcAndTrg . getTarget ( ) != null ) ; if ( i == 1 ) { assertEquals ( "This is not actual." , srcAndTrg . getSource ( ) ) ; } else if ( i == 2 ) { assertEquals ( "Test" , srcAndTrg . getSource ( ) ) ; } else if ( i == 3 ) { assertEquals ( "Very strange data indeed, much longer than input" , srcAndTrg . getTarget ( ) ) ; } i ++ ; } } }
package org . languagetool . bitext ; import java . io . File ; import java . io . FileOutputStream ; import java . io . OutputStreamWriter ; import java . io . PrintWriter ; import junit . framework . TestCase ; public class WordFastTMReaderTest extends TestCase { public void testReader ( ) throws Exception { final File input = File . createTempFile ( "input" , ".txt" ) ; input . deleteOnExit ( ) ; final PrintWriter writer = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( input ) , "UTF-8" ) ) ; writer . println ( "%20100801~111517\t%UserID,AHLJat,AHLJat\t%TU=00008580\t%EN-US\t%Wordfast TM v.546/00\t%PL-PL\t%\t." ) ; writer . println ( "20100727~145333\tAHLJat\t2\tEN-US\tObjection:\tPL-PL\tZarzut: " ) ; writer . println ( "20100727~051350\tAHLJat\t2\tEN-US\tWhy not?&tA;\tPL-PL\tDlaczego nie?&tA; " ) ; writer . close ( ) ; final WordFastTMReader reader = new WordFastTMReader ( input . getAbsolutePath ( ) , "UTF-8" ) ; int i = 1 ; for ( StringPair srcAndTrg : reader ) { assertTrue ( srcAndTrg . getSource ( ) != null ) ; assertTrue ( srcAndTrg . getTarget ( ) != null ) ; if ( i == 1 ) { assertEquals ( "Objection:" , srcAndTrg . getSource ( ) ) ; } else if ( i == 2 ) { assertEquals ( "Why not?&tA;" , srcAndTrg . getSource ( ) ) ; } i ++ ; } } }
package org . languagetool . rules . nl ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Dutch ; import org . languagetool . rules . GenericUnpairedBracketsRule ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Collections ; public class GenericUnpairedBracketsRuleTest extends TestCase { private GenericUnpairedBracketsRule rule ; private JLanguageTool langTool ; public void testDutchRule ( ) throws IOException { langTool = new JLanguageTool ( new Dutch ( ) ) ; rule = org . languagetool . rules . GenericUnpairedBracketsRuleTest . getBracketsRule ( langTool ) ; assertMatches ( "Het centrale probleem van het werk is de ‘dichterlijke kuischheid’." , 0 ) ; assertMatches ( " Eurlings: “De gegevens van de dienst zijn van cruciaal belang voor de veiligheid van de luchtvaart en de scheepvaart”." , 0 ) ; assertMatches ( " Eurlings: \u201eDe gegevens van de dienst zijn van cruciaal belang voor de veiligheid van de luchtvaart en de scheepvaart\u201d." , 0 ) ; assertMatches ( "Het centrale probleem van het werk is de „dichterlijke kuischheid." , 1 ) ; assertMatches ( " Eurlings: “De gegevens van de dienst zijn van cruciaal belang voor de veiligheid van de luchtvaart en de scheepvaart." , 1 ) ; } private void assertMatches ( String input , int expectedMatches ) throws IOException { final RuleMatch [ ] matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( input ) ) ) ; assertEquals ( expectedMatches , matches . length ) ; } }
package org . languagetool . rules ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; public abstract class AbstractCompoundRuleTest extends TestCase { protected JLanguageTool langTool ; protected AbstractCompoundRule rule ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; } public void check ( int expectedErrors , String text ) throws IOException { check ( expectedErrors , text , null ) ; } public void check ( int expectedErrors , String text , String [ ] expSuggestions ) throws IOException { assertNotNull ( "Please initialize langTool!" , langTool ) ; assertNotNull ( "Please initialize 'rule'!" , rule ) ; final RuleMatch [ ] ruleMatches = rule . match ( langTool . getAnalyzedSentence ( text ) ) ; assertEquals ( "Expected " + expectedErrors + "errors, but got: " + Arrays . toString ( ruleMatches ) , expectedErrors , ruleMatches . length ) ; if ( expSuggestions != null && expectedErrors != 1 ) { throw new RuntimeException ( "Sorry, test case can only check suggestion if there's one rule match" ) ; } if ( expSuggestions != null ) { final RuleMatch ruleMatch = ruleMatches [ 0 ] ; final String errorMessage = String . format ( "Got these suggestions: %s, expected %s " , ruleMatch . getSuggestedReplacements ( ) , Arrays . toString ( expSuggestions ) ) ; assertEquals ( errorMessage , expSuggestions . length , ruleMatch . getSuggestedReplacements ( ) . size ( ) ) ; int i = 0 ; for ( final Object element : ruleMatch . getSuggestedReplacements ( ) ) { final String suggestion = ( String ) element ; assertEquals ( expSuggestions [ i ] , suggestion ) ; i ++ ; } } } }
package org . languagetool . rules ; import org . junit . Test ; import org . languagetool . * ; import org . languagetool . languagemodel . LanguageModel ; import org . languagetool . tokenizers . WordTokenizer ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . util . * ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertThat ; public class ConfusionProbabilityRuleTest { private final ConfusionProbabilityRule rule = new FakeRule ( new FakeLanguageModel ( ) , new FakeLanguage ( ) ) ; private final JLanguageTool lt = new JLanguageTool ( new FakeLanguage ( ) ) ; @ Test public void testRule ( ) throws IOException { assertMatch ( "Their are new ideas to explore." ) ; assertGood ( "There are new ideas to explore." ) ; assertMatch ( "Why is there car broken again?" ) ; assertGood ( "Why is their car broken again?" ) ; assertGood ( "Is this their useful test?" ) ; assertGood ( "Is this there useful test?" ) ; } @ Test public void testPseudoProbability ( ) throws IOException { ConfusionProbabilityRule . Probability prob1 = rule . getPseudoProbability ( Arrays . asList ( "no" , "data" , "here" ) ) ; double delta = 0.001 ; assertEquals ( 0.010 , prob1 . prob , delta ) ; assertThat ( prob1 . coverage , is ( 0.0f ) ) ; ConfusionProbabilityRule . Probability prob2 = rule . getPseudoProbability ( Arrays . asList ( "1" , "2" , "3" , "4" ) ) ; assertEquals ( 0.010 , prob2 . prob , delta ) ; assertThat ( prob2 . coverage , is ( 0.0f ) ) ; ConfusionProbabilityRule . Probability prob3 = rule . getPseudoProbability ( Arrays . asList ( "There" , "are" ) ) ; assertEquals ( 0.119 , prob3 . prob , delta ) ; assertThat ( prob3 . coverage , is ( 0.5f ) ) ; } @ Test ( expected = IndexOutOfBoundsException . class ) public void testPseudoProbabilityFail1 ( ) throws IOException { rule . getPseudoProbability ( Collections . < String > emptyList ( ) ) ; } @ Test public void testGetContext ( ) throws IOException { List < ConfusionProbabilityRule . GoogleToken > tokens = Arrays . asList ( new ConfusionProbabilityRule . GoogleToken ( "This" , 0 , 0 ) , new ConfusionProbabilityRule . GoogleToken ( "is" , 0 , 0 ) , new ConfusionProbabilityRule . GoogleToken ( "a" , 0 , 0 ) , new ConfusionProbabilityRule . GoogleToken ( "test" , 0 , 0 ) ) ; ConfusionProbabilityRule . GoogleToken token = tokens . get ( 2 ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 1 , 1 ) . toString ( ) , is ( "[is, XX, test]" ) ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 0 , 2 ) . toString ( ) , is ( "[XX, test, .]" ) ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 2 , 0 ) . toString ( ) , is ( "[This, is, XX]" ) ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 3 , 0 ) . toString ( ) , is ( "[This, is, XX]" ) ) ; } @ Test public void testGetContext2 ( ) throws IOException { List < ConfusionProbabilityRule . GoogleToken > tokens = Arrays . asList ( new ConfusionProbabilityRule . GoogleToken ( "This" , 0 , 0 ) , new ConfusionProbabilityRule . GoogleToken ( "is" , 0 , 0 ) ) ; ConfusionProbabilityRule . GoogleToken token = tokens . get ( 1 ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 1 , 1 ) . toString ( ) , is ( "[This, XX, .]" ) ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 0 , 2 ) . toString ( ) , is ( "[XX, ., .]" ) ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 2 , 0 ) . toString ( ) , is ( "[This, XX]" ) ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 3 , 0 ) . toString ( ) , is ( "[This, XX]" ) ) ; } @ Test public void testGetContext3 ( ) throws IOException { List < ConfusionProbabilityRule . GoogleToken > tokens = Arrays . asList ( new ConfusionProbabilityRule . GoogleToken ( "This" , 0 , 0 ) ) ; ConfusionProbabilityRule . GoogleToken token = tokens . get ( 0 ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 1 , 1 ) . toString ( ) , is ( "[XX]" ) ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 0 , 2 ) . toString ( ) , is ( "[XX, ., .]" ) ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 2 , 0 ) . toString ( ) , is ( "[XX]" ) ) ; assertThat ( rule . getContext ( token , tokens , "XX" , 3 , 0 ) . toString ( ) , is ( "[XX]" ) ) ; } private void assertMatch ( String input ) throws IOException { RuleMatch [ ] matches = rule . match ( lt . getAnalyzedSentence ( input ) ) ; assertThat ( matches . length , is ( 1 ) ) ; } private void assertGood ( String input ) throws IOException { RuleMatch [ ] matches = rule . match ( lt . getAnalyzedSentence ( input ) ) ; assertThat ( matches . length , is ( 0 ) ) ; } static class FakeLanguageModel implements LanguageModel { Map < String , Integer > map = new HashMap < > ( ) ; FakeLanguageModel ( ) { map . put ( "There are" , 10 ) ; map . put ( "There are new" , 5 ) ; map . put ( "Their are" , 2 ) ; map . put ( "Their are new" , 1 ) ; map . put ( "Why is" , 50 ) ; map . put ( "Why is there" , 5 ) ; map . put ( "Why is their" , 5 ) ; map . put ( "their car" , 11 ) ; map . put ( "their car broken" , 2 ) ; } @ Override public long getCount ( List < String > tokens ) { Integer count = map . get ( StringTools . listToString ( tokens , " " ) ) ; return count == null ? 0 : count ; } @ Override public long getCount ( String token1 ) { return getCount ( Arrays . asList ( token1 ) ) ; } @ Override public long getCount ( String token1 , String token2 ) { return getCount ( Arrays . asList ( token1 , token2 ) ) ; } @ Override public long getCount ( String token1 , String token2 , String token3 ) { return getCount ( Arrays . asList ( token1 , token2 , token3 ) ) ; } @ Override public long getTotalTokenCount ( ) { int sum = 0 ; for ( int val : map . values ( ) ) { sum += val ; } return sum ; } @ Override public void close ( ) { } } private static class FakeRule extends ConfusionProbabilityRule { private final Language language ; private FakeRule ( LanguageModel languageModel , Language language ) { super ( JLanguageTool . getMessageBundle ( ) , languageModel , language ) ; this . language = language ; } @ Override protected WordTokenizer getTokenizer ( ) { return ( WordTokenizer ) language . getWordTokenizer ( ) ; } @ Override public String getDescription ( ) { return null ; } @ Override public String getMessage ( String suggestion , String description ) { return null ; } } }
package org . languagetool . rules ; import junit . framework . TestCase ; import java . util . EmptyStackException ; public class UnsyncStackTest extends TestCase { public void testStack ( ) { final UnsyncStack < String > stack = new UnsyncStack < > ( ) ; assertTrue ( stack . empty ( ) ) ; stack . push ( "test" ) ; assertEquals ( "test" , stack . peek ( ) ) ; assertFalse ( stack . empty ( ) ) ; assertEquals ( "test" , stack . pop ( ) ) ; assertTrue ( stack . empty ( ) ) ; try { stack . pop ( ) ; } catch ( EmptyStackException ignored ) { } try { stack . peek ( ) ; } catch ( EmptyStackException ignored ) { } } }
package org . languagetool . rules ; import org . junit . Test ; import org . languagetool . FakeLanguage ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . TestTools ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertThat ; public class GenericUnpairedBracketsRuleTest { private JLanguageTool langTool ; @ Test public void testRule ( ) throws IOException { setUpRule ( new FakeLanguage ( ) ) ; assertMatches ( 0 , "This is »correct«." ) ; assertMatches ( 0 , "»Correct«\n»And »here« it ends.«" ) ; assertMatches ( 0 , "»Correct. This is more than one sentence.«" ) ; assertMatches ( 0 , "»Correct. This is more than one sentence.«\n»And »here« it ends.«" ) ; assertMatches ( 0 , "»Correct«\n\n»And here it ends.«\n\nMore text." ) ; assertMatches ( 0 , "»Correct, he said. This is the next sentence.« Here's another sentence." ) ; assertMatches ( 0 , "»Correct, he said.\n\nThis is the next sentence.« Here's another sentence." ) ; assertMatches ( 0 , "»Correct, he said.\n\n\n\nThis is the next sentence.« Here's another sentence." ) ; assertMatches ( 0 , "This »is also »correct««." ) ; assertMatches ( 0 , "Good.\n\nThis »is also »correct««." ) ; assertMatches ( 0 , "Good.\n\n\nThis »is also »correct««." ) ; assertMatches ( 0 , "Good.\n\n\n\nThis »is also »correct««." ) ; assertMatches ( 1 , "This is not correct«" ) ; assertMatches ( 1 , "This is »not correct" ) ; assertMatches ( 1 , "This is correct.\n\n»But this is not." ) ; assertMatches ( 1 , "This is correct.\n\nBut this is not«" ) ; assertMatches ( 1 , "»This is correct«\n\nBut this is not«" ) ; assertMatches ( 1 , "»This is correct«\n\nBut this »is« not«" ) ; assertMatches ( 1 , "This is not correct. No matter if it's more than one sentence«" ) ; assertMatches ( 1 , "»This is not correct. No matter if it's more than one sentence" ) ; assertMatches ( 1 , "Correct, he said. This is the next sentence.« Here's another sentence." ) ; assertMatches ( 1 , "»Correct, he said. This is the next sentence. Here's another sentence." ) ; assertMatches ( 1 , "»Correct, he said. This is the next sentence.\n\nHere's another sentence." ) ; assertMatches ( 1 , "»Correct, he said. This is the next sentence.\n\n\n\nHere's another sentence." ) ; } @ Test public void testRuleMatchPositions ( ) throws IOException { setUpRule ( new FakeLanguage ( ) ) ; RuleMatch match1 = langTool . check ( "This »is a test." ) . get ( 0 ) ; assertThat ( match1 . getFromPos ( ) , is ( 5 ) ) ; assertThat ( match1 . getToPos ( ) , is ( 6 ) ) ; assertThat ( match1 . getLine ( ) , is ( 0 ) ) ; assertThat ( match1 . getEndLine ( ) , is ( 0 ) ) ; assertThat ( match1 . getColumn ( ) , is ( 5 ) ) ; assertThat ( match1 . getEndColumn ( ) , is ( 6 ) ) ; RuleMatch match2 = langTool . check ( "This.\nSome stuff.\nIt »is a test." ) . get ( 0 ) ; assertThat ( match2 . getFromPos ( ) , is ( 21 ) ) ; assertThat ( match2 . getToPos ( ) , is ( 22 ) ) ; assertThat ( match2 . getLine ( ) , is ( 2 ) ) ; assertThat ( match2 . getEndLine ( ) , is ( 2 ) ) ; assertThat ( match2 . getColumn ( ) , is ( 4 ) ) ; assertThat ( match2 . getEndColumn ( ) , is ( 5 ) ) ; } private void setUpRule ( Language language ) { langTool = new JLanguageTool ( language ) ; for ( Rule rule : langTool . getAllRules ( ) ) { langTool . disableRule ( rule . getId ( ) ) ; } GenericUnpairedBracketsRule rule = new GenericUnpairedBracketsRule ( TestTools . getEnglishMessages ( ) , Arrays . asList ( "»" ) , Arrays . asList ( "«" ) ) ; langTool . addRule ( rule ) ; } private void assertMatches ( int expectedMatches , String input ) throws IOException { List < RuleMatch > ruleMatches = langTool . check ( input ) ; assertEquals ( "Expected " + expectedMatches + " matches, got: " + ruleMatches , expectedMatches , ruleMatches . size ( ) ) ; } public static GenericUnpairedBracketsRule getBracketsRule ( JLanguageTool langTool ) { for ( Rule rule : langTool . getAllActiveRules ( ) ) { if ( rule instanceof GenericUnpairedBracketsRule ) { return ( GenericUnpairedBracketsRule ) rule ; } } throw new RuntimeException ( "Rule not found: " + GenericUnpairedBracketsRule . class ) ; } }
package org . languagetool . rules ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; public class CommaWhitespaceRuleTest extends TestCase { private CommaWhitespaceRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new CommaWhitespaceRule ( TestTools . getEnglishMessages ( ) ) ; langTool = new JLanguageTool ( TestTools . getDemoLanguage ( ) ) ; } public void testRule ( ) throws IOException { assertMatches ( "This is a test sentence." , 0 ) ; assertMatches ( "This, is, a test sentence." , 0 ) ; assertMatches ( "This (foo bar) is a test!." , 0 ) ; assertMatches ( "Das kostet €2,45." , 0 ) ; assertMatches ( "Das kostet 50,- Euro" , 0 ) ; assertMatches ( "This is a sentence with ellipsis ..." , 0 ) ; assertMatches ( "This is a figure: .5 and it's correct." , 0 ) ; assertMatches ( "This is $1,000,000." , 0 ) ; assertMatches ( "This is 1,5." , 0 ) ; assertMatches ( "This is a ,,test''." , 0 ) ; assertMatches ( "This is,\u00A0really,\u00A0non-breaking whitespace." , 0 ) ; assertMatches ( "In his book,\u0002 Einstein proved this to be true." , 0 ) ; assertMatches ( "This,is a test sentence." , 1 ) ; assertMatches ( "This , is a test sentence." , 1 ) ; assertMatches ( "This ,is a test sentence." , 2 ) ; assertMatches ( ",is a test sentence." , 2 ) ; assertMatches ( "This ( foo bar) is a test!." , 1 ) ; assertMatches ( "This (foo bar ) is a test!." , 1 ) ; assertMatches ( "This [ foo bar) is a test!." , 1 ) ; assertMatches ( "This (foo bar ] is a test!." , 1 ) ; assertMatches ( "This { foo bar) is a test!." , 1 ) ; assertMatches ( "This (foo bar } is a test!." , 1 ) ; assertMatches ( "This is a sentence with an orphaned full stop ." , 1 ) ; assertMatches ( "This is a test with a OOo footnote\u0002, which is denoted by 0x2 in the text." , 0 ) ; final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "ABB ( z.B. )" ) ) ; assertEquals ( 2 , matches . length ) ; assertEquals ( 4 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 6 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( 11 , matches [ 1 ] . getFromPos ( ) ) ; assertEquals ( 13 , matches [ 1 ] . getToPos ( ) ) ; assertMatches ( "Ellipsis . . . as suggested by The Chicago Manual of Style" , 3 ) ; assertMatches ( "Ellipsis . . . . as suggested by The Chicago Manual of Style" , 4 ) ; } private void assertMatches ( String text , int expectedMatches ) throws IOException { assertEquals ( expectedMatches , rule . match ( langTool . getAnalyzedSentence ( text ) ) . length ) ; } }
package org . languagetool . rules ; import junit . framework . TestCase ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . PatternRule ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; @ SuppressWarnings ( "MagicNumber" ) public class RuleWithMaxFilterTest extends TestCase { private static final Language language = TestTools . getDemoLanguage ( ) ; public void testFilter ( ) { final List < PatternToken > fakePatternTokens = new ArrayList < > ( ) ; final PatternRule rule1 = new PatternRule ( "id1" , language , fakePatternTokens , "desc1" , "msg1" , "shortMsg1" ) ; final PatternRule rule2 = new PatternRule ( "id1" , language , fakePatternTokens , "desc2" , "msg2" , "shortMsg2" ) ; final RuleMatch match1 = new RuleMatch ( rule1 , 10 , 20 , "Match1" ) ; final RuleMatch match2 = new RuleMatch ( rule2 , 15 , 25 , "Match2" ) ; final RuleWithMaxFilter filter = new RuleWithMaxFilter ( ) ; List < RuleMatch > filteredMatches1 = filter . filter ( Arrays . asList ( match1 , match2 ) ) ; assertEquals ( 2 , filteredMatches1 . size ( ) ) ; final RuleMatch match3 = new RuleMatch ( rule2 , 11 , 19 , "Match3" ) ; List < RuleMatch > filteredMatches2 = filter . filter ( Arrays . asList ( match1 , match3 ) ) ; assertEquals ( 1 , filteredMatches2 . size ( ) ) ; } public void testNoFilteringIfNotOverlapping ( ) { final List < PatternToken > fakePatternTokens = new ArrayList < > ( ) ; final PatternRule rule1 = new PatternRule ( "id1" , language , fakePatternTokens , "desc1" , "msg1" , "shortMsg1" ) ; final PatternRule rule2 = new PatternRule ( "id1" , language , fakePatternTokens , "desc2" , "msg2" , "shortMsg2" ) ; final RuleMatch match1 = new RuleMatch ( rule1 , 10 , 20 , "Match1" ) ; final RuleMatch match2 = new RuleMatch ( rule2 , 21 , 25 , "Match2" ) ; final RuleWithMaxFilter filter = new RuleWithMaxFilter ( ) ; final List < RuleMatch > filteredMatches = filter . filter ( Arrays . asList ( match1 , match2 ) ) ; assertEquals ( 2 , filteredMatches . size ( ) ) ; } public void testNoFilteringIfDifferentRulegroups ( ) { final List < PatternToken > fakePatternTokens = new ArrayList < > ( ) ; final Rule rule1 = new PatternRule ( "id1" , language , fakePatternTokens , "desc1" , "msg1" , "shortMsg1" ) ; final Rule rule2 = new PatternRule ( "id2" , language , fakePatternTokens , "desc2" , "msg2" , "shortMsg2" ) ; final RuleMatch match1 = new RuleMatch ( rule1 , 10 , 20 , "Match1" ) ; final RuleMatch match2 = new RuleMatch ( rule2 , 15 , 25 , "Match2" ) ; final RuleWithMaxFilter filter = new RuleWithMaxFilter ( ) ; List < RuleMatch > filteredMatches1 = filter . filter ( Arrays . asList ( match1 , match2 ) ) ; assertEquals ( 2 , filteredMatches1 . size ( ) ) ; final RuleMatch match3 = new RuleMatch ( rule2 , 11 , 19 , "Match3" ) ; List < RuleMatch > filteredMatches2 = filter . filter ( Arrays . asList ( match1 , match3 ) ) ; assertEquals ( 2 , filteredMatches2 . size ( ) ) ; } public void testOverlaps ( ) { final RuleWithMaxFilter filter = new RuleWithMaxFilter ( ) ; assertTrue ( filter . includes ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 10 , 20 ) ) ) ; assertFalse ( filter . includes ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 5 , 11 ) ) ) ; assertFalse ( filter . includes ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 11 , 21 ) ) ) ; assertTrue ( filter . includes ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 11 , 19 ) ) ) ; assertFalse ( filter . includes ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 1 , 10 ) ) ) ; assertTrue ( filter . includes ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 19 , 20 ) ) ) ; assertFalse ( filter . includes ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 21 , 30 ) ) ) ; assertFalse ( filter . includes ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 1 , 9 ) ) ) ; } private RuleMatch makeRuleMatch ( int fromPos , int toPos ) { return new RuleMatch ( null , fromPos , toPos , "FakeMatch1" ) ; } }
package org . languagetool . rules ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import java . io . IOException ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; public class LongSentenceRuleTest { @ Test public void testMatch ( ) throws Exception { JLanguageTool languageTool = new JLanguageTool ( TestTools . getDemoLanguage ( ) ) ; LongSentenceRule rule = new LongSentenceRule ( TestTools . getEnglishMessages ( ) ) ; assertNoMatch ( " is a rather short text." , rule , languageTool ) ; assertMatch ( "Now this is not " + "a a a a a a a a a a a " + "a a a a a a a a a a a " + "a a a a a a a a a a a " + "rather that short text." , rule , languageTool ) ; LongSentenceRule shortRule = new LongSentenceRule ( TestTools . getEnglishMessages ( ) , 6 ) ; assertNoMatch ( "This is a rather short text." , shortRule , languageTool ) ; assertMatch ( "This is also a rather short text." , shortRule , languageTool ) ; assertNoMatch ( "These ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ don't count." , shortRule , languageTool ) ; assertNoMatch ( "one two three four five six." , shortRule , languageTool ) ; assertNoMatch ( "one two three (four) five six." , shortRule , languageTool ) ; assertMatch ( "one two three four five six seven." , shortRule , languageTool ) ; } private void assertNoMatch ( String input , LongSentenceRule rule , JLanguageTool languageTool ) throws IOException { assertThat ( rule . match ( languageTool . getAnalyzedSentence ( input ) ) . length , is ( 0 ) ) ; } private void assertMatch ( String input , LongSentenceRule rule , JLanguageTool languageTool ) throws IOException { assertThat ( rule . match ( languageTool . getAnalyzedSentence ( input ) ) . length , is ( 1 ) ) ; } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import junit . framework . TestCase ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . PatternRule ; @ SuppressWarnings ( "MagicNumber" ) public class SameRuleGroupFilterTest extends TestCase { private static final Language language = TestTools . getDemoLanguage ( ) ; public void testFilter ( ) { final List < PatternToken > fakePatternTokens = new ArrayList < > ( ) ; final PatternRule rule1 = new PatternRule ( "id1" , language , fakePatternTokens , "desc1" , "msg1" , "shortMsg1" ) ; final PatternRule rule2 = new PatternRule ( "id1" , language , fakePatternTokens , "desc2" , "msg2" , "shortMsg2" ) ; final RuleMatch match1 = new RuleMatch ( rule1 , 10 , 20 , "Match1" ) ; final RuleMatch match2 = new RuleMatch ( rule2 , 15 , 25 , "Match2" ) ; final SameRuleGroupFilter filter = new SameRuleGroupFilter ( ) ; final List < RuleMatch > filteredMatches = filter . filter ( Arrays . asList ( match1 , match2 ) ) ; assertEquals ( 1 , filteredMatches . size ( ) ) ; assertEquals ( "Match1" , filteredMatches . get ( 0 ) . getMessage ( ) ) ; } public void testNoFilteringIfNotOverlapping ( ) { final List < PatternToken > fakePatternTokens = new ArrayList < > ( ) ; final PatternRule rule1 = new PatternRule ( "id1" , language , fakePatternTokens , "desc1" , "msg1" , "shortMsg1" ) ; final PatternRule rule2 = new PatternRule ( "id1" , language , fakePatternTokens , "desc2" , "msg2" , "shortMsg2" ) ; final RuleMatch match1 = new RuleMatch ( rule1 , 10 , 20 , "Match1" ) ; final RuleMatch match2 = new RuleMatch ( rule2 , 21 , 25 , "Match2" ) ; final SameRuleGroupFilter filter = new SameRuleGroupFilter ( ) ; final List < RuleMatch > filteredMatches = filter . filter ( Arrays . asList ( match1 , match2 ) ) ; assertEquals ( 2 , filteredMatches . size ( ) ) ; } public void testNoFilteringIfDifferentRulegroups ( ) { final List < PatternToken > fakePatternTokens = new ArrayList < > ( ) ; final Rule rule1 = new PatternRule ( "id1" , language , fakePatternTokens , "desc1" , "msg1" , "shortMsg1" ) ; final Rule rule2 = new PatternRule ( "id2" , language , fakePatternTokens , "desc2" , "msg2" , "shortMsg2" ) ; final RuleMatch match1 = new RuleMatch ( rule1 , 10 , 20 , "Match1" ) ; final RuleMatch match2 = new RuleMatch ( rule2 , 15 , 25 , "Match2" ) ; final SameRuleGroupFilter filter = new SameRuleGroupFilter ( ) ; final List < RuleMatch > filteredMatches = filter . filter ( Arrays . asList ( match1 , match2 ) ) ; assertEquals ( 2 , filteredMatches . size ( ) ) ; } public void testOverlaps ( ) { final SameRuleGroupFilter filter = new SameRuleGroupFilter ( ) ; assertTrue ( filter . overlaps ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 10 , 20 ) ) ) ; assertTrue ( filter . overlaps ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 5 , 11 ) ) ) ; assertTrue ( filter . overlaps ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 19 , 21 ) ) ) ; assertTrue ( filter . overlaps ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 11 , 19 ) ) ) ; assertTrue ( filter . overlaps ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 1 , 10 ) ) ) ; assertTrue ( filter . overlaps ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 19 , 20 ) ) ) ; assertFalse ( filter . overlaps ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 21 , 30 ) ) ) ; assertFalse ( filter . overlaps ( makeRuleMatch ( 10 , 20 ) , makeRuleMatch ( 1 , 9 ) ) ) ; } private RuleMatch makeRuleMatch ( int fromPos , int toPos ) { return new RuleMatch ( null , fromPos , toPos , "FakeMatch1" ) ; } }
package org . languagetool . rules ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; public class DemoPartialPosTagFilter extends PartialPosTagFilter { @ Override protected List < AnalyzedTokenReadings > tag ( String token ) { if ( "accurate" . equals ( token ) ) { AnalyzedToken resultToken = new AnalyzedToken ( token , "JJ" , "fake" ) ; List < AnalyzedToken > resultTokens = Collections . singletonList ( resultToken ) ; List < AnalyzedTokenReadings > result = new ArrayList < > ( ) ; result . add ( new AnalyzedTokenReadings ( resultTokens , 0 ) ) ; return result ; } return null ; } }
package org . languagetool . rules ; import org . junit . Test ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . * ; public class ConfusionSetTest { @ Test public void testGet ( ) { ConfusionSet confusionSet = new ConfusionSet ( 1 , "one" , "two" ) ; assertThat ( confusionSet . getSet ( ) . size ( ) , is ( 2 ) ) ; assertTrue ( confusionSet . getSet ( ) . toString ( ) . contains ( "one" ) ) ; assertTrue ( confusionSet . getSet ( ) . toString ( ) . contains ( "two" ) ) ; assertThat ( confusionSet . getUppercaseFirstCharSet ( ) . size ( ) , is ( 2 ) ) ; assertTrue ( confusionSet . getUppercaseFirstCharSet ( ) . toString ( ) . contains ( "One" ) ) ; assertTrue ( confusionSet . getUppercaseFirstCharSet ( ) . toString ( ) . contains ( "Two" ) ) ; } @ Test public void testEquals ( ) { ConfusionSet confusionSet1a = new ConfusionSet ( 1 , "one" , "two" ) ; ConfusionSet confusionSet1b = new ConfusionSet ( 1 , "two" , "one" ) ; ConfusionSet confusionSet3 = new ConfusionSet ( 1 , "Two" , "one" ) ; ConfusionSet confusionSet4 = new ConfusionSet ( 2 , "Two" , "one" ) ; assertTrue ( confusionSet1a . equals ( confusionSet1b ) ) ; assertFalse ( confusionSet1a . equals ( confusionSet3 ) ) ; assertFalse ( confusionSet1b . equals ( confusionSet3 ) ) ; assertFalse ( confusionSet3 . equals ( confusionSet4 ) ) ; } }
package org . languagetool . rules . nl ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Dutch ; import org . languagetool . rules . RuleMatch ; public class SimpleReplaceRuleTest extends TestCase { private SimpleReplaceRule rule ; private JLanguageTool langTool ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; rule = new SimpleReplaceRule ( TestTools . getMessages ( "nl" ) ) ; langTool = new JLanguageTool ( new Dutch ( ) ) ; } public void testRule ( ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "all right" ) ) . length ) ; checkSimpleReplaceRule ( "ofzo" , "of zo" ) ; } private void checkSimpleReplaceRule ( String sentence , String word ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( "Invalid matches.length while checking sentence: " + sentence , 1 , matches . length ) ; assertEquals ( "Invalid replacement count wile checking sentence: " + sentence , 1 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; assertEquals ( "Invalid suggested replacement while checking sentence: " + sentence , word , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; public class DoublePunctuationRuleTest extends TestCase { public void testRule ( ) throws IOException { final DoublePunctuationRule rule = new DoublePunctuationRule ( TestTools . getEnglishMessages ( ) ) ; RuleMatch [ ] matches ; final JLanguageTool langTool = new JLanguageTool ( TestTools . getDemoLanguage ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a test sentence..." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Это тестовое предложение?.." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Это тестовое предложение!.." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a test sentence... More stuff...." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a test sentence..... More stuff...." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This, is, a test sentence." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This,, is a test sentence." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 4 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 6 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a test sentence.. Another sentence" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 23 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 25 , matches [ 0 ] . getToPos ( ) ) ; } }
package org . languagetool . rules ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; public class MultipleWhitespaceRuleTest extends TestCase { public void testRule ( ) throws IOException { final MultipleWhitespaceRule rule = new MultipleWhitespaceRule ( TestTools . getEnglishMessages ( ) , TestTools . getDemoLanguage ( ) ) ; RuleMatch [ ] matches ; final JLanguageTool langTool = new JLanguageTool ( TestTools . getDemoLanguage ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a test sentence." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a test sentence..." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "\n\tThis is a test sentence..." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Multiple tabs\t\tare okay" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a test sentence." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 4 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 6 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a test sentence." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 14 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 17 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a test sentence." ) ) ; assertEquals ( 3 , matches . length ) ; assertEquals ( 7 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 10 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( 11 , matches [ 1 ] . getFromPos ( ) ) ; assertEquals ( 13 , matches [ 1 ] . getToPos ( ) ) ; assertEquals ( 17 , matches [ 2 ] . getFromPos ( ) ) ; assertEquals ( 20 , matches [ 2 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "\t\t\t \t\t\t\t " ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This \u00A0is a test sentence." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 4 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 6 , matches [ 0 ] . getToPos ( ) ) ; } }
package org . languagetool . rules ; import org . junit . Test ; import org . languagetool . FakeLanguage ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import java . io . IOException ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; public class SentenceWhitespaceRuleTest { @ Test public void testMatch ( ) throws Exception { SentenceWhitespaceRule rule = new SentenceWhitespaceRule ( TestTools . getEnglishMessages ( ) ) ; JLanguageTool languageTool = new JLanguageTool ( new FakeLanguage ( ) ) ; languageTool . addRule ( rule ) ; assertGood ( "This is a text. And there's the next sentence." , rule , languageTool ) ; assertGood ( "This is a text! And there's the next sentence." , rule , languageTool ) ; assertGood ( "This is a text\nAnd there's the next sentence." , rule , languageTool ) ; assertGood ( "This is a text\n\nAnd there's the next sentence." , rule , languageTool ) ; assertBad ( "This is a text.And there's the next sentence." , rule , languageTool ) ; assertBad ( "This is a text!And there's the next sentence." , rule , languageTool ) ; assertBad ( "This is a text?And there's the next sentence." , rule , languageTool ) ; } private void assertGood ( String text , SentenceWhitespaceRule rule , JLanguageTool languageTool ) throws IOException { assertThat ( languageTool . check ( text ) . size ( ) , is ( 0 ) ) ; rule . reset ( ) ; } private void assertBad ( String text , SentenceWhitespaceRule rule , JLanguageTool languageTool ) throws IOException { assertThat ( languageTool . check ( text ) . size ( ) , is ( 1 ) ) ; rule . reset ( ) ; } }
package org . languagetool . rules ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; public class UppercaseSentenceStartRuleTest extends TestCase { public void testRule ( ) throws IOException { final UppercaseSentenceStartRule rule = new UppercaseSentenceStartRule ( TestTools . getEnglishMessages ( ) , TestTools . getDemoLanguage ( ) ) ; RuleMatch [ ] matches ; final JLanguageTool langTool = new JLanguageTool ( TestTools . getDemoLanguage ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "a) This is a test sentence." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "iv. This is a test sentence..." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "\"iv. This is a test sentence...\"" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "»iv. This is a test sentence..." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "This is a test sentence" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "this is a sentence" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "http://www.languagetool.org" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "this is a test sentence." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 4 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "this" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 4 , matches [ 0 ] . getToPos ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "'this is a sentence'." ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "\"this is a sentence.\"" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "„this is a sentence." ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "«this is a sentence." ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "‘this is a sentence." ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . rules ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import java . io . IOException ; import java . io . InputStream ; import java . util . List ; import java . util . Map ; import java . util . Set ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . MatcherAssert . assertThat ; import static org . junit . Assert . assertFalse ; @ SuppressWarnings ( "QuestionableName" ) public class ConfusionSetLoaderTest { @ Test public void testLoadWithStrictLimits ( ) throws IOException { try ( InputStream inputStream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( "/yy/confusion_sets.txt" ) ) { ConfusionSetLoader loader = new ConfusionSetLoader ( ) ; Map < String , List < ConfusionSet > > map = loader . loadConfusionSet ( inputStream ) ; assertThat ( map . size ( ) , is ( 8 ) ) ; assertThat ( map . get ( "there" ) . size ( ) , is ( 1 ) ) ; assertThat ( map . get ( "there" ) . get ( 0 ) . getFactor ( ) , is ( 10L ) ) ; assertThat ( map . get ( "their" ) . size ( ) , is ( 1 ) ) ; assertThat ( map . get ( "their" ) . get ( 0 ) . getFactor ( ) , is ( 10L ) ) ; assertThat ( map . get ( "foo" ) . size ( ) , is ( 2 ) ) ; assertThat ( map . get ( "foo" ) . get ( 0 ) . getFactor ( ) , is ( 5L ) ) ; assertThat ( map . get ( "foo" ) . get ( 1 ) . getFactor ( ) , is ( 8L ) ) ; assertThat ( map . get ( "goo" ) . size ( ) , is ( 2 ) ) ; assertThat ( map . get ( "goo" ) . get ( 0 ) . getFactor ( ) , is ( 11L ) ) ; assertThat ( map . get ( "goo" ) . get ( 1 ) . getFactor ( ) , is ( 12L ) ) ; assertThat ( map . get ( "lol" ) . size ( ) , is ( 1 ) ) ; assertThat ( map . get ( "something" ) . size ( ) , is ( 1 ) ) ; assertThat ( map . get ( "bar" ) . size ( ) , is ( 1 ) ) ; assertThat ( map . get ( "bar" ) . get ( 0 ) . getFactor ( ) , is ( 5L ) ) ; Set < ConfusionString > there = map . get ( "there" ) . get ( 0 ) . getSet ( ) ; assertTrue ( getAsString ( there ) . contains ( "there - example 1" ) ) ; assertTrue ( getAsString ( there ) . contains ( "their - example 2" ) ) ; Set < ConfusionString > their = map . get ( "their" ) . get ( 0 ) . getSet ( ) ; assertTrue ( getAsString ( their ) . contains ( "there - example 1" ) ) ; assertTrue ( getAsString ( their ) . contains ( "their - example 2" ) ) ; assertFalse ( getAsString ( their ) . contains ( "comment" ) ) ; Set < ConfusionString > foo = map . get ( "foo" ) . get ( 0 ) . getSet ( ) ; assertTrue ( getAsString ( foo ) . contains ( "foo" ) ) ; Set < ConfusionString > bar = map . get ( "foo" ) . get ( 0 ) . getSet ( ) ; assertTrue ( getAsString ( bar ) . contains ( "bar" ) ) ; Set < ConfusionString > baz = map . get ( "foo" ) . get ( 1 ) . getSet ( ) ; assertTrue ( getAsString ( baz ) . contains ( "baz" ) ) ; } } private String getAsString ( Set < ConfusionString > their ) { StringBuilder sb = new StringBuilder ( ) ; for ( ConfusionString confusionString : their ) { sb . append ( confusionString . getString ( ) ) . append ( " - " ) ; sb . append ( confusionString . getDescription ( ) ) ; sb . append ( " " ) ; } return sb . toString ( ) ; } }
package org . languagetool . rules . patterns ; import org . junit . Test ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import java . util . Arrays ; import java . util . Collections ; import java . util . HashMap ; import java . util . Map ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class RuleFilterEvaluatorTest { private final RuleFilterEvaluator eval = new RuleFilterEvaluator ( null ) ; @ Test public void testGetResolvedArguments ( ) throws Exception { AnalyzedTokenReadings [ ] readingsList = { new AnalyzedTokenReadings ( new AnalyzedToken ( "fake1" , "pos" , null ) , 0 ) , new AnalyzedTokenReadings ( new AnalyzedToken ( "fake2" , "pos" , null ) , 0 ) } ; Map < String , String > map = eval . getResolvedArguments ( "year:\\1 month:\\2" , readingsList , Arrays . asList ( 1 , 1 ) ) ; assertThat ( map . get ( "year" ) , is ( "fake1" ) ) ; assertThat ( map . get ( "month" ) , is ( "fake2" ) ) ; assertThat ( map . size ( ) , is ( 2 ) ) ; } @ Test public void testGetResolvedArgumentsWithColon ( ) throws Exception { AnalyzedTokenReadings [ ] readingsList = { new AnalyzedTokenReadings ( new AnalyzedToken ( "fake1" , "pos" , null ) , 0 ) , } ; Map < String , String > map = eval . getResolvedArguments ( "regex:(?:foo[xyz])bar" , readingsList , Arrays . asList ( 1 , 1 ) ) ; assertThat ( map . get ( "regex" ) , is ( "(?:foo[xyz])bar" ) ) ; assertThat ( map . size ( ) , is ( 1 ) ) ; } @ Test ( expected = RuntimeException . class ) public void testDuplicateKey ( ) throws Exception { AnalyzedTokenReadings [ ] readingsList = { new AnalyzedTokenReadings ( new AnalyzedToken ( "fake1" , "SENT_START" , null ) , 0 ) , new AnalyzedTokenReadings ( new AnalyzedToken ( "fake1" , "pos" , null ) , 0 ) , new AnalyzedTokenReadings ( new AnalyzedToken ( "fake2" , "pos" , null ) , 0 ) } ; eval . getResolvedArguments ( "year:\\1 year:\\2" , readingsList , Arrays . asList ( 1 , 2 ) ) ; } @ Test public void testNoBackReference ( ) throws Exception { Map < String , String > args = eval . getResolvedArguments ( "year:2 foo:bar" , null , Collections . < Integer > emptyList ( ) ) ; Map < String , String > expected = new HashMap < > ( ) ; expected . put ( "year" , "2" ) ; expected . put ( "foo" , "bar" ) ; assertThat ( args , is ( expected ) ) ; } @ Test ( expected = RuntimeException . class ) public void testTooLargeBackRef ( ) throws Exception { eval . getResolvedArguments ( "year:\\1 month:\\2 day:\\3 weekDay:\\4" , null , Collections . < Integer > emptyList ( ) ) ; } }
package org . languagetool . rules . patterns ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertThat ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import org . junit . BeforeClass ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Languages ; import org . languagetool . language . Demo ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . Match . CaseConversion ; import org . languagetool . rules . patterns . Match . IncludeRange ; @ SuppressWarnings ( "MagicNumber" ) public class PatternRuleMatcherTest { private static JLanguageTool langTool ; @ BeforeClass public static void setup ( ) { langTool = new JLanguageTool ( new Demo ( ) ) ; } @ Test public void testMatch ( ) throws Exception { final PatternRuleMatcher matcher = new PatternRuleMatcher ( getPatternRule ( "my test" ) , false ) ; assertPartialMatch ( "This is my test." , matcher ) ; assertNoMatch ( "This is no test." , matcher ) ; } @ Test public void testZeroMinOccurrences ( ) throws Exception { final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMinOccurrence ( 0 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , patternTokenB , makeElement ( "c" ) ) ; assertNoMatch ( "b a" , matcher ) ; assertNoMatch ( "c a b" , matcher ) ; assertPartialMatch ( "b a c" , matcher ) ; assertPartialMatch ( "a c b" , matcher ) ; assertNoMatch ( "a b b c" , matcher ) ; assertCompleteMatch ( "a c" , matcher ) ; assertCompleteMatch ( "a b c" , matcher ) ; assertNoMatch ( "a X c" , matcher ) ; final RuleMatch [ ] matches = getMatches ( "a b c FOO a b c FOO a c a b c" , matcher ) ; assertThat ( matches . length , is ( 4 ) ) ; assertPosition ( matches [ 0 ] , 0 , 5 ) ; assertPosition ( matches [ 1 ] , 10 , 15 ) ; assertPosition ( matches [ 2 ] , 20 , 23 ) ; assertPosition ( matches [ 3 ] , 24 , 29 ) ; } @ Test public void testTwoZeroMinOccurrences ( ) throws Exception { PatternToken patternTokenB1 = makeElement ( "ba" ) ; patternTokenB1 . setMinOccurrence ( 0 ) ; PatternToken patternTokenB2 = makeElement ( "bb" ) ; patternTokenB2 . setMinOccurrence ( 0 ) ; PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , patternTokenB1 , patternTokenB2 , makeElement ( "c" ) ) ; assertNoMatch ( "ba a" , matcher ) ; assertNoMatch ( "c a bb" , matcher ) ; assertPartialMatch ( "z a c" , matcher ) ; assertPartialMatch ( "a c z" , matcher ) ; assertNoMatch ( "a ba ba c" , matcher ) ; assertCompleteMatch ( "a ba bb c" , matcher ) ; assertCompleteMatch ( "a ba c" , matcher ) ; assertCompleteMatch ( "a bb c" , matcher ) ; assertCompleteMatch ( "a c" , matcher ) ; assertNoMatch ( "a X c" , matcher ) ; RuleMatch [ ] matches = getMatches ( "a ba c FOO a bb c FOO a c a ba bb c" , matcher ) ; assertThat ( matches . length , is ( 4 ) ) ; assertPosition ( matches [ 0 ] , 0 , 6 ) ; assertPosition ( matches [ 1 ] , 11 , 17 ) ; assertPosition ( matches [ 2 ] , 22 , 25 ) ; assertPosition ( matches [ 3 ] , 26 , 35 ) ; } @ Test public void testZeroMinOccurrences2 ( ) throws Exception { final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMinOccurrence ( 0 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , patternTokenB , makeElement ( "c" ) , makeElement ( "d" ) , makeElement ( "e" ) ) ; assertCompleteMatch ( "a b c d e" , matcher ) ; assertCompleteMatch ( "a c d e" , matcher ) ; assertNoMatch ( "a d" , matcher ) ; assertNoMatch ( "a c b d" , matcher ) ; assertNoMatch ( "a c b d e" , matcher ) ; } @ Test public void testZeroMinOccurrences3 ( ) throws Exception { final PatternToken patternTokenC = makeElement ( "c" ) ; patternTokenC . setMinOccurrence ( 0 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , makeElement ( "b" ) , patternTokenC , makeElement ( "d" ) , makeElement ( "e" ) ) ; assertCompleteMatch ( "a b c d e" , matcher ) ; assertCompleteMatch ( "a b d e" , matcher ) ; assertPartialMatch ( "a b c d e x" , matcher ) ; assertPartialMatch ( "x a b c d e" , matcher ) ; assertNoMatch ( "a b c e d" , matcher ) ; assertNoMatch ( "a c b d e" , matcher ) ; } @ Test public void testZeroMinOccurrences4 ( ) throws Exception { final PatternToken patternTokenA = makeElement ( "a" ) ; patternTokenA . setMinOccurrence ( 0 ) ; final PatternToken patternTokenC = makeElement ( "c" ) ; patternTokenC . setMinOccurrence ( 0 ) ; final PatternRuleMatcher matcher = getMatcher ( patternTokenA , makeElement ( "b" ) , patternTokenC , makeElement ( "d" ) , makeElement ( "e" ) ) ; final RuleMatch [ ] matches = getMatches ( "a b c d e" , matcher ) ; assertThat ( matches . length , is ( 1 ) ) ; assertPosition ( matches [ 0 ] , 0 , 9 ) ; } @ Test public void testZeroMinOccurrencesWithEmptyElement ( ) throws Exception { final PatternToken patternTokenB = makeElement ( null ) ; patternTokenB . setMinOccurrence ( 0 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , patternTokenB , makeElement ( "c" ) ) ; assertNoMatch ( "b a" , matcher ) ; assertNoMatch ( "c a b" , matcher ) ; assertPartialMatch ( "b a c" , matcher ) ; assertPartialMatch ( "a c b" , matcher ) ; assertNoMatch ( "a b b c" , matcher ) ; assertCompleteMatch ( "a c" , matcher ) ; assertCompleteMatch ( "a b c" , matcher ) ; assertCompleteMatch ( "a X c" , matcher ) ; final RuleMatch [ ] matches = getMatches ( "a b c FOO a X c" , matcher ) ; assertThat ( matches . length , is ( 2 ) ) ; assertPosition ( matches [ 0 ] , 0 , 5 ) ; assertPosition ( matches [ 1 ] , 10 , 15 ) ; } @ Test public void testZeroMinOccurrencesWithSuggestion ( ) throws Exception { final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMinOccurrence ( 0 ) ; List < PatternToken > patternTokens = Arrays . asList ( makeElement ( "a" ) , patternTokenB , makeElement ( "c" ) ) ; PatternRule rule = new PatternRule ( "" , new Demo ( ) , patternTokens , "my description" , "<suggestion>\\1 \\2 \\3</suggestion>" , "short message" ) ; PatternRuleMatcher matcher = new PatternRuleMatcher ( rule , false ) ; rule . addSuggestionMatch ( new Match ( null , null , false , null , null , CaseConversion . NONE , false , false , IncludeRange . NONE ) ) ; RuleMatch [ ] matches = getMatches ( "a b c" , matcher ) ; assertEquals ( Arrays . asList ( "a b c" ) , matches [ 0 ] . getSuggestedReplacements ( ) ) ; RuleMatch [ ] matches2 = getMatches ( "a c" , matcher ) ; assertEquals ( Arrays . asList ( "a c" ) , matches2 [ 0 ] . getSuggestedReplacements ( ) ) ; } @ Test @ Ignore ( "min can only be 0 or 1 so far" ) public void testTwoMinOccurrences ( ) throws Exception { final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMinOccurrence ( 2 ) ; patternTokenB . setMaxOccurrence ( 3 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , patternTokenB , makeElement ( "c" ) ) ; assertCompleteMatch ( "a b b c" , matcher ) ; assertCompleteMatch ( "a b b b c" , matcher ) ; assertNoMatch ( "a c" , matcher ) ; assertNoMatch ( "a b c" , matcher ) ; } @ Test public void testZeroMinTwoMaxOccurrences ( ) throws Exception { final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMinOccurrence ( 0 ) ; patternTokenB . setMaxOccurrence ( 2 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , patternTokenB , makeElement ( "c" ) ) ; assertCompleteMatch ( "a c" , matcher ) ; assertCompleteMatch ( "a b c" , matcher ) ; assertCompleteMatch ( "a b b c" , matcher ) ; assertNoMatch ( "a b b b c" , matcher ) ; } @ Test public void testTwoMaxOccurrencesWithAnyToken ( ) throws Exception { final PatternToken anyPatternToken = makeElement ( null ) ; anyPatternToken . setMaxOccurrence ( 2 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , anyPatternToken , makeElement ( "c" ) ) ; assertCompleteMatch ( "a b c" , matcher ) ; assertCompleteMatch ( "a b b c" , matcher ) ; assertNoMatch ( "a b b b c" , matcher ) ; } @ Test public void testThreeMaxOccurrencesWithAnyToken ( ) throws Exception { final PatternToken anyPatternToken = makeElement ( null ) ; anyPatternToken . setMaxOccurrence ( 3 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , anyPatternToken , makeElement ( "c" ) ) ; assertCompleteMatch ( "a b c" , matcher ) ; assertCompleteMatch ( "a b b c" , matcher ) ; assertCompleteMatch ( "a b b b c" , matcher ) ; assertNoMatch ( "a b b b b c" , matcher ) ; } @ Test public void testZeroMinTwoMaxOccurrencesWithAnyToken ( ) throws Exception { final PatternToken anyPatternToken = makeElement ( null ) ; anyPatternToken . setMinOccurrence ( 0 ) ; anyPatternToken . setMaxOccurrence ( 2 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , anyPatternToken , makeElement ( "c" ) ) ; assertNoMatch ( "a b" , matcher ) ; assertNoMatch ( "b c" , matcher ) ; assertNoMatch ( "c" , matcher ) ; assertNoMatch ( "a" , matcher ) ; assertCompleteMatch ( "a c" , matcher ) ; assertCompleteMatch ( "a x c" , matcher ) ; assertCompleteMatch ( "a x x c" , matcher ) ; assertNoMatch ( "a x x x c" , matcher ) ; } @ Test public void testTwoMaxOccurrences ( ) throws Exception { final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMaxOccurrence ( 2 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , patternTokenB ) ; assertNoMatch ( "a a" , matcher ) ; assertCompleteMatch ( "a b" , matcher ) ; assertCompleteMatch ( "a b b" , matcher ) ; assertPartialMatch ( "a b c" , matcher ) ; assertPartialMatch ( "a b b c" , matcher ) ; assertPartialMatch ( "x a b b" , matcher ) ; final RuleMatch [ ] matches1 = getMatches ( "a b b b" , matcher ) ; assertThat ( matches1 . length , is ( 1 ) ) ; assertPosition ( matches1 [ 0 ] , 0 , 5 ) ; final RuleMatch [ ] matches2 = getMatches ( "a b b b foo a b b" , matcher ) ; assertThat ( matches2 . length , is ( 2 ) ) ; assertPosition ( matches2 [ 0 ] , 0 , 5 ) ; assertPosition ( matches2 [ 1 ] , 12 , 17 ) ; } @ Test public void testThreeMaxOccurrences ( ) throws Exception { final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMaxOccurrence ( 3 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , patternTokenB ) ; assertNoMatch ( "a a" , matcher ) ; assertCompleteMatch ( "a b" , matcher ) ; assertCompleteMatch ( "a b b" , matcher ) ; assertCompleteMatch ( "a b b b" , matcher ) ; assertPartialMatch ( "a b b b b" , matcher ) ; final RuleMatch [ ] matches1 = getMatches ( "a b b b b" , matcher ) ; assertThat ( matches1 . length , is ( 1 ) ) ; assertPosition ( matches1 [ 0 ] , 0 , 7 ) ; } @ Test public void testOptionalWithoutExplicitMarker ( ) throws Exception { final PatternToken patternTokenA = makeElement ( "a" ) ; final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMinOccurrence ( 0 ) ; final PatternToken patternTokenC = makeElement ( "c" ) ; final PatternRuleMatcher matcher = getMatcher ( patternTokenA , patternTokenB , patternTokenC ) ; final RuleMatch [ ] matches1 = getMatches ( "A B C ZZZ" , matcher ) ; assertThat ( matches1 . length , is ( 1 ) ) ; assertPosition ( matches1 [ 0 ] , 0 , 5 ) ; final RuleMatch [ ] matches2 = getMatches ( "A C ZZZ" , matcher ) ; assertThat ( matches2 . length , is ( 1 ) ) ; assertPosition ( matches2 [ 0 ] , 0 , 3 ) ; } @ Test public void testOptionalWithExplicitMarker ( ) throws Exception { final PatternToken patternTokenA = makeElement ( "a" ) ; patternTokenA . setInsideMarker ( true ) ; final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMinOccurrence ( 0 ) ; patternTokenB . setInsideMarker ( true ) ; final PatternToken patternTokenC = makeElement ( "c" ) ; patternTokenC . setInsideMarker ( false ) ; final PatternRuleMatcher matcher = getMatcher ( patternTokenA , patternTokenB , patternTokenC ) ; final RuleMatch [ ] matches1 = getMatches ( "A B C ZZZ" , matcher ) ; assertThat ( matches1 . length , is ( 1 ) ) ; assertPosition ( matches1 [ 0 ] , 0 , 3 ) ; final RuleMatch [ ] matches2 = getMatches ( "A C ZZZ" , matcher ) ; assertThat ( matches2 . length , is ( 1 ) ) ; assertPosition ( matches2 [ 0 ] , 0 , 1 ) ; } @ Test public void testOptionalAnyTokenWithExplicitMarker ( ) throws Exception { final PatternToken patternTokenA = makeElement ( "a" ) ; patternTokenA . setInsideMarker ( true ) ; final PatternToken patternTokenB = makeElement ( null ) ; patternTokenB . setMinOccurrence ( 0 ) ; patternTokenB . setInsideMarker ( true ) ; final PatternToken patternTokenC = makeElement ( "c" ) ; patternTokenC . setInsideMarker ( false ) ; final PatternRuleMatcher matcher = getMatcher ( patternTokenA , patternTokenB , patternTokenC ) ; final RuleMatch [ ] matches1 = getMatches ( "A x C ZZZ" , matcher ) ; assertThat ( matches1 . length , is ( 1 ) ) ; assertPosition ( matches1 [ 0 ] , 0 , 3 ) ; final RuleMatch [ ] matches2 = getMatches ( "A C ZZZ" , matcher ) ; assertThat ( matches2 . length , is ( 1 ) ) ; assertPosition ( matches2 [ 0 ] , 0 , 1 ) ; } @ Test public void testOptionalAnyTokenWithExplicitMarker2 ( ) throws Exception { final PatternToken patternTokenA = makeElement ( "the" ) ; patternTokenA . setInsideMarker ( true ) ; final PatternToken patternTokenB = makeElement ( null ) ; patternTokenB . setMinOccurrence ( 0 ) ; patternTokenB . setInsideMarker ( true ) ; final PatternToken patternTokenC = makeElement ( "bike" ) ; patternTokenC . setInsideMarker ( false ) ; final PatternRuleMatcher matcher = getMatcher ( patternTokenA , patternTokenB , patternTokenC ) ; final RuleMatch [ ] matches1 = getMatches ( "the nice bike ZZZ" , matcher ) ; assertThat ( matches1 . length , is ( 1 ) ) ; assertPosition ( matches1 [ 0 ] , 0 , 8 ) ; final RuleMatch [ ] matches2 = getMatches ( "the bike ZZZ" , matcher ) ; assertThat ( matches2 . length , is ( 1 ) ) ; assertPosition ( matches2 [ 0 ] , 0 , 3 ) ; } @ Test public void testUnlimitedMaxOccurrences ( ) throws Exception { final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMaxOccurrence ( - 1 ) ; final PatternRuleMatcher matcher = getMatcher ( makeElement ( "a" ) , patternTokenB , makeElement ( "c" ) ) ; assertNoMatch ( "a c" , matcher ) ; assertNoMatch ( "a b" , matcher ) ; assertNoMatch ( "b c" , matcher ) ; assertCompleteMatch ( "a b c" , matcher ) ; assertCompleteMatch ( "a b b c" , matcher ) ; assertCompleteMatch ( "a b b b b b b b b b b b b b b b b b b b b b b b b b c" , matcher ) ; } @ Test public void testMaxTwoAndThreeOccurrences ( ) throws Exception { final PatternToken patternTokenA = makeElement ( "a" ) ; patternTokenA . setMaxOccurrence ( 2 ) ; final PatternToken patternTokenB = makeElement ( "b" ) ; patternTokenB . setMaxOccurrence ( 3 ) ; final PatternRuleMatcher matcher = getMatcher ( patternTokenA , patternTokenB ) ; assertCompleteMatch ( "a b" , matcher ) ; assertCompleteMatch ( "a b b" , matcher ) ; assertCompleteMatch ( "a b b b" , matcher ) ; assertNoMatch ( "a a" , matcher ) ; assertNoMatch ( "a x b b b" , matcher ) ; final RuleMatch [ ] matches2 = getMatches ( "a a b" , matcher ) ; assertThat ( matches2 . length , is ( 1 ) ) ; assertPosition ( matches2 [ 0 ] , 0 , 5 ) ; final RuleMatch [ ] matches3 = getMatches ( "a a b b" , matcher ) ; assertThat ( matches3 . length , is ( 1 ) ) ; assertPosition ( matches3 [ 0 ] , 0 , 7 ) ; final RuleMatch [ ] matches4 = getMatches ( "a a b b b" , matcher ) ; assertThat ( matches4 . length , is ( 1 ) ) ; assertPosition ( matches4 [ 0 ] , 0 , 9 ) ; } @ Test public void testInfiniteSkip ( ) throws Exception { final PatternToken patternTokenA = makeElement ( "a" ) ; patternTokenA . setSkipNext ( - 1 ) ; final PatternRuleMatcher matcher = getMatcher ( patternTokenA , makeElement ( "b" ) ) ; assertCompleteMatch ( "a b" , matcher ) ; assertCompleteMatch ( "a x b" , matcher ) ; assertCompleteMatch ( "a x x b" , matcher ) ; assertCompleteMatch ( "a x x x b" , matcher ) ; } @ Test public void testInfiniteSkipWithMatchReference ( ) throws Exception { final PatternToken patternTokenAB = new PatternToken ( "a|b" , false , true , false ) ; patternTokenAB . setSkipNext ( - 1 ) ; final PatternToken patternTokenC = makeElement ( "\\0" ) ; Match match = new Match ( null , null , false , null , null , Match . CaseConversion . NONE , false , false , Match . IncludeRange . NONE ) ; match . setTokenRef ( 0 ) ; match . setInMessageOnly ( true ) ; patternTokenC . setMatch ( match ) ; final PatternRuleMatcher matcher = getMatcher ( patternTokenAB , patternTokenC ) ; assertCompleteMatch ( "a a" , matcher ) ; assertCompleteMatch ( "b b" , matcher ) ; assertCompleteMatch ( "a x a" , matcher ) ; assertCompleteMatch ( "b x b" , matcher ) ; assertCompleteMatch ( "a x x a" , matcher ) ; assertCompleteMatch ( "b x x b" , matcher ) ; assertNoMatch ( "a b" , matcher ) ; assertNoMatch ( "b a" , matcher ) ; assertNoMatch ( "b x a" , matcher ) ; assertNoMatch ( "b x a" , matcher ) ; assertNoMatch ( "a x x b" , matcher ) ; assertNoMatch ( "b x x a" , matcher ) ; final RuleMatch [ ] matches = getMatches ( "a foo a and b foo b" , matcher ) ; assertThat ( matches . length , is ( 2 ) ) ; assertPosition ( matches [ 0 ] , 0 , 7 ) ; assertPosition ( matches [ 1 ] , 12 , 19 ) ; final RuleMatch [ ] matches2 = getMatches ( "xx a b x x x b a" , matcher ) ; assertThat ( matches2 . length , is ( 1 ) ) ; assertPosition ( matches2 [ 0 ] , 3 , 16 ) ; } @ Test public void testEquals ( ) throws Exception { PatternRule patternRule1 = new PatternRule ( "id1" , Languages . getLanguageForShortName ( "xx" ) , Collections . < PatternToken > emptyList ( ) , "desc1" , "msg1" , "short1" ) ; RuleMatch ruleMatch1 = new RuleMatch ( patternRule1 , 0 , 1 , "message" ) ; RuleMatch ruleMatch2 = new RuleMatch ( patternRule1 , 0 , 1 , "message" ) ; assertTrue ( ruleMatch1 . equals ( ruleMatch2 ) ) ; RuleMatch ruleMatch3 = new RuleMatch ( patternRule1 , 0 , 9 , "message" ) ; assertFalse ( ruleMatch1 . equals ( ruleMatch3 ) ) ; assertFalse ( ruleMatch2 . equals ( ruleMatch3 ) ) ; } private RuleMatch [ ] getMatches ( String input , PatternRuleMatcher matcher ) throws IOException { return matcher . match ( langTool . getAnalyzedSentence ( input ) ) ; } private PatternRuleMatcher getMatcher ( PatternToken ... patternPatternTokens ) { return new PatternRuleMatcher ( getPatternRule ( Arrays . asList ( patternPatternTokens ) ) , false ) ; } private void assertPosition ( RuleMatch match , int expectedFromPos , int expectedToPos ) { assertThat ( "Wrong start position" , match . getFromPos ( ) , is ( expectedFromPos ) ) ; assertThat ( "Wrong end position" , match . getToPos ( ) , is ( expectedToPos ) ) ; } private void assertNoMatch ( String input , PatternRuleMatcher matcher ) throws IOException { final RuleMatch [ ] matches = getMatches ( input , matcher ) ; assertThat ( matches . length , is ( 0 ) ) ; } private void assertPartialMatch ( String input , PatternRuleMatcher matcher ) throws IOException { final RuleMatch [ ] matches = getMatches ( input , matcher ) ; assertThat ( matches . length , is ( 1 ) ) ; assertTrue ( "Expected partial match, got '" + matches [ 0 ] + "' for '" + input + "'" , matches [ 0 ] . getFromPos ( ) > 0 || matches [ 0 ] . getToPos ( ) < input . length ( ) ) ; } private void assertCompleteMatch ( String input , PatternRuleMatcher matcher ) throws IOException { final RuleMatch [ ] matches = getMatches ( input , matcher ) ; assertThat ( "Got matches: " + Arrays . toString ( matches ) , matches . length , is ( 1 ) ) ; assertThat ( "Wrong start position" , matches [ 0 ] . getFromPos ( ) , is ( 0 ) ) ; assertThat ( "Wrong end position" , matches [ 0 ] . getToPos ( ) , is ( input . length ( ) ) ) ; } private PatternToken makeElement ( String token ) { return new PatternToken ( token , false , false , false ) ; } private PatternRule getPatternRule ( String pattern ) { final String [ ] parts = pattern . split ( " " ) ; List < PatternToken > patternTokens = new ArrayList < > ( ) ; for ( String part : parts ) { patternTokens . add ( new PatternToken ( part , false , false , false ) ) ; } return getPatternRule ( patternTokens ) ; } private PatternRule getPatternRule ( List < PatternToken > patternTokens ) { return new PatternRule ( "" , new Demo ( ) , patternTokens , "my description" , "my message" , "short message" ) ; } }
package org . languagetool . rules . patterns ; import java . io . File ; import java . io . IOException ; import java . io . InputStream ; import java . lang . String ; import java . util . * ; import junit . framework . TestCase ; import org . languagetool . * ; import org . languagetool . databroker . ResourceDataBroker ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . spelling . SpellingCheckRule ; import org . languagetool . tagging . disambiguation . rules . DisambiguationPatternRule ; public class PatternRuleTest extends TestCase { private static final boolean CHECK_WITH_SENTENCE_SPLITTING = false ; public void testFake ( ) { } public void testSupportsLanguage ( ) { FakeLanguage fakeLanguage1 = new FakeLanguage ( "yy" ) ; FakeLanguage fakeLanguage2 = new FakeLanguage ( "zz" ) ; PatternRule patternRule1 = new PatternRule ( "ID" , fakeLanguage1 , Collections . < PatternToken > emptyList ( ) , "" , "" , "" ) ; assertTrue ( patternRule1 . supportsLanguage ( fakeLanguage1 ) ) ; assertFalse ( patternRule1 . supportsLanguage ( fakeLanguage2 ) ) ; FakeLanguage fakeLanguage1WithVariant1 = new FakeLanguage ( "zz" , "VAR1" ) ; FakeLanguage fakeLanguage1WithVariant2 = new FakeLanguage ( "zz" , "VAR2" ) ; PatternRule patternRuleVariant1 = new PatternRule ( "ID" , fakeLanguage1WithVariant1 , Collections . < PatternToken > emptyList ( ) , "" , "" , "" ) ; assertTrue ( patternRuleVariant1 . supportsLanguage ( fakeLanguage1WithVariant1 ) ) ; assertFalse ( patternRuleVariant1 . supportsLanguage ( fakeLanguage1 ) ) ; assertFalse ( patternRuleVariant1 . supportsLanguage ( fakeLanguage2 ) ) ; assertFalse ( patternRuleVariant1 . supportsLanguage ( fakeLanguage1WithVariant2 ) ) ; } protected void runGrammarRulesFromXmlTest ( Language ignoredLanguage ) throws IOException { int count = 0 ; for ( final Language lang : Languages . get ( ) ) { if ( ignoredLanguage . getShortNameWithCountryAndVariant ( ) . equals ( lang . getShortNameWithCountryAndVariant ( ) ) ) { continue ; } runGrammarRuleForLanguage ( lang ) ; count ++ ; } if ( count == 0 ) { System . err . println ( "Warning: no languages found in classpath - cannot run any grammar rule tests" ) ; } } protected void runGrammarRulesFromXmlTest ( ) throws IOException { for ( final Language lang : Languages . get ( ) ) { runGrammarRuleForLanguage ( lang ) ; } if ( Languages . get ( ) . size ( ) == 0 ) { System . err . println ( "Warning: no languages found in classpath - cannot run any grammar rule tests" ) ; } } private void runGrammarRuleForLanguage ( Language lang ) throws IOException { if ( skipCountryVariant ( lang ) ) { System . out . println ( "Skipping " + lang + " because there are no specific rules for that variant" ) ; return ; } runTestForLanguage ( lang ) ; } private boolean skipCountryVariant ( Language lang ) { final ResourceDataBroker dataBroker = JLanguageTool . getDataBroker ( ) ; boolean hasGrammarFiles = false ; for ( String grammarFile : getGrammarFileNames ( lang ) ) { if ( dataBroker . ruleFileExists ( grammarFile ) ) { hasGrammarFiles = true ; } } return ! hasGrammarFiles && Languages . get ( ) . size ( ) > 1 ; } private List < String > getGrammarFileNames ( Language lang ) { final String shortNameWithVariant = lang . getShortNameWithCountryAndVariant ( ) ; final List < String > fileNames = new ArrayList < > ( ) ; for ( String ruleFile : lang . getRuleFileNames ( ) ) { final String nameOnly = new File ( ruleFile ) . getName ( ) ; final String fileName ; if ( shortNameWithVariant . contains ( "-x-" ) ) { fileName = lang . getShortName ( ) + "/" + nameOnly ; } else if ( shortNameWithVariant . contains ( "-" ) && ! shortNameWithVariant . equals ( "xx-XX" ) && ! shortNameWithVariant . endsWith ( "-ANY" ) && Languages . get ( ) . size ( ) > 1 ) { fileName = lang . getShortName ( ) + "/" + shortNameWithVariant + "/" + nameOnly ; } else { fileName = lang . getShortName ( ) + "/" + nameOnly ; } if ( ! fileNames . contains ( fileName ) ) { fileNames . add ( fileName ) ; } } return fileNames ; } private void runGrammarRulesFromXmlTestIgnoringLanguages ( Set < Language > ignoredLanguages ) throws IOException { System . out . println ( "Known languages: " + Languages . getWithDemoLanguage ( ) ) ; for ( final Language lang : Languages . getWithDemoLanguage ( ) ) { if ( ignoredLanguages != null && ignoredLanguages . contains ( lang ) ) { continue ; } runTestForLanguage ( lang ) ; } } public void runTestForLanguage ( Language lang ) throws IOException { validatePatternFile ( lang ) ; System . out . print ( "Running pattern rule tests for " + lang . getName ( ) + "... " ) ; final MultiThreadedJLanguageTool languageTool = new MultiThreadedJLanguageTool ( lang ) ; if ( CHECK_WITH_SENTENCE_SPLITTING ) { disableSpellingRules ( languageTool ) ; } final MultiThreadedJLanguageTool allRulesLanguageTool = new MultiThreadedJLanguageTool ( lang ) ; validateRuleIds ( lang , allRulesLanguageTool ) ; final List < PatternRule > rules = new ArrayList < > ( ) ; for ( String patternRuleFileName : lang . getRuleFileNames ( ) ) { rules . addAll ( languageTool . loadPatternRules ( patternRuleFileName ) ) ; } for ( PatternRule rule : rules ) { PatternTestTools . warnIfRegexpSyntaxNotKosher ( rule . getPatternTokens ( ) , rule . getId ( ) , rule . getSubId ( ) , lang ) ; List < DisambiguationPatternRule > antiPatterns = rule . getAntiPatterns ( ) ; for ( DisambiguationPatternRule antiPattern : antiPatterns ) { PatternTestTools . warnIfRegexpSyntaxNotKosher ( antiPattern . getPatternTokens ( ) , antiPattern . getId ( ) , antiPattern . getSubId ( ) , lang ) ; } if ( rule . getCorrectExamples ( ) . size ( ) == 0 ) { boolean correctionExists = false ; for ( IncorrectExample incorrectExample : rule . getIncorrectExamples ( ) ) { if ( incorrectExample . getCorrections ( ) . size ( ) > 0 ) { correctionExists = true ; break ; } } if ( ! correctionExists ) { fail ( "Rule " + rule + " in language " + lang + " needs at least one <example> with a 'correction' attribute" + " or one <example> of type='correct'." ) ; } } } testGrammarRulesFromXML ( rules , languageTool , allRulesLanguageTool , lang ) ; System . out . println ( rules . size ( ) + " rules tested." ) ; allRulesLanguageTool . shutdown ( ) ; languageTool . shutdown ( ) ; } private void validatePatternFile ( Language lang ) throws IOException { final XMLValidator validator = new XMLValidator ( ) ; final List < String > grammarFiles = getGrammarFileNames ( lang ) ; for ( String grammarFile : grammarFiles ) { System . out . println ( "Running XML validation for " + grammarFile + "..." ) ; final String rulesDir = JLanguageTool . getDataBroker ( ) . getRulesDir ( ) ; final String ruleFilePath = rulesDir + "/" + grammarFile ; try ( InputStream xmlStream = this . getClass ( ) . getResourceAsStream ( ruleFilePath ) ) { if ( xmlStream == null ) { System . out . println ( "No rule file found at " + ruleFilePath + " in classpath" ) ; continue ; } if ( grammarFiles . size ( ) > 1 && ! grammarFiles . get ( 0 ) . equals ( grammarFile ) ) { validator . validateWithXmlSchema ( rulesDir + "/" + grammarFiles . get ( 0 ) , ruleFilePath , rulesDir + "/rules.xsd" ) ; } else { validator . validateWithXmlSchema ( ruleFilePath , rulesDir + "/rules.xsd" ) ; } } } } private void validateRuleIds ( Language lang , JLanguageTool languageTool ) { final List < Rule > allRules = languageTool . getAllRules ( ) ; final Set < String > ids = new HashSet < > ( ) ; final Set < Class > ruleClasses = new HashSet < > ( ) ; for ( Rule rule : allRules ) { assertIdUniqueness ( ids , ruleClasses , lang , rule ) ; if ( rule . getId ( ) . equalsIgnoreCase ( "ID" ) ) { System . err . println ( "WARNING: " + lang . getShortNameWithCountryAndVariant ( ) + " has a rule with id 'ID', this should probably be changed" ) ; } } } private void assertIdUniqueness ( Set < String > ids , Set < Class > ruleClasses , Language language , Rule rule ) { final String ruleId = rule . getId ( ) ; if ( ids . contains ( ruleId ) && ! ruleClasses . contains ( rule . getClass ( ) ) ) { throw new RuntimeException ( "Rule id occurs more than once: '" + ruleId + "', language: " + language ) ; } ids . add ( ruleId ) ; ruleClasses . add ( rule . getClass ( ) ) ; } private void disableSpellingRules ( JLanguageTool languageTool ) { final List < Rule > allRules = languageTool . getAllRules ( ) ; for ( Rule rule : allRules ) { if ( rule instanceof SpellingCheckRule ) { languageTool . disableRule ( rule . getId ( ) ) ; } } } public void testGrammarRulesFromXML ( final List < PatternRule > rules , final JLanguageTool languageTool , final JLanguageTool allRulesLanguageTool , final Language lang ) throws IOException { final Map < String , PatternRule > complexRules = new HashMap < > ( ) ; for ( final PatternRule rule : rules ) { testCorrectSentences ( languageTool , allRulesLanguageTool , lang , rule ) ; testBadSentences ( languageTool , allRulesLanguageTool , lang , complexRules , rule ) ; } if ( ! complexRules . isEmpty ( ) ) { final Set < String > set = complexRules . keySet ( ) ; final List < PatternRule > badRules = new ArrayList < > ( ) ; for ( String aSet : set ) { final PatternRule badRule = complexRules . get ( aSet ) ; if ( badRule != null ) { badRule . notComplexPhrase ( ) ; badRule . setMessage ( "The rule contains a phrase that never matched any incorrect example." ) ; badRules . add ( badRule ) ; } } if ( ! badRules . isEmpty ( ) ) { testGrammarRulesFromXML ( badRules , languageTool , allRulesLanguageTool , lang ) ; } } } private void testBadSentences ( JLanguageTool languageTool , JLanguageTool allRulesLanguageTool , Language lang , Map < String , PatternRule > complexRules , PatternRule rule ) throws IOException { final List < IncorrectExample > badSentences = rule . getIncorrectExamples ( ) ; if ( badSentences . size ( ) == 0 ) { fail ( "No incorrect examples found for rule " + rule ) ; } List < PatternRule > rules = allRulesLanguageTool . getPatternRulesByIdAndSubId ( rule . getId ( ) , rule . getSubId ( ) ) ; for ( IncorrectExample origBadExample : badSentences ) { final String origBadSentence = origBadExample . getExample ( ) . replaceAll ( "[\\n\\t]+" , "" ) ; final List < String > expectedCorrections = origBadExample . getCorrections ( ) ; final int expectedMatchStart = origBadSentence . indexOf ( "<marker>" ) ; final int expectedMatchEnd = origBadSentence . indexOf ( "</marker>" ) - "<marker>" . length ( ) ; if ( expectedMatchStart == - 1 || expectedMatchEnd == - 1 ) { fail ( lang + ": No error position markup ('<marker>...</marker>') in bad example in rule " + rule ) ; } final String badSentence = cleanXML ( origBadSentence ) ; assertTrue ( badSentence . trim ( ) . length ( ) > 0 ) ; List < RuleMatch > matches = new ArrayList < > ( ) ; for ( Rule auxRule : rules ) { matches . addAll ( getMatches ( auxRule , badSentence , languageTool ) ) ; } if ( ! rule . isWithComplexPhrase ( ) ) { if ( matches . size ( ) != 1 ) { final AnalyzedSentence analyzedSentence = languageTool . getAnalyzedSentence ( badSentence ) ; final StringBuilder sb = new StringBuilder ( "Analyzed token readings:" ) ; for ( AnalyzedTokenReadings atr : analyzedSentence . getTokens ( ) ) { sb . append ( " " ) . append ( atr ) ; } fail ( lang + " rule " + rule + ":\n\"" + badSentence + "\"\n" + "Errors expected: 1\n" + "Errors found : " + matches . size ( ) + "\n" + "Message: " + rule . getMessage ( ) + "\n" + sb + "\nMatches: " + matches ) ; } assertEquals ( lang + ": Incorrect match position markup (start) for rule " + rule + ", sentence: " + badSentence , expectedMatchStart , matches . get ( 0 ) . getFromPos ( ) ) ; assertEquals ( lang + ": Incorrect match position markup (end) for rule " + rule + ", sentence: " + badSentence , expectedMatchEnd , matches . get ( 0 ) . getToPos ( ) ) ; assertSuggestions ( badSentence , lang , expectedCorrections , rule , matches ) ; if ( matches . get ( 0 ) . getSuggestedReplacements ( ) . size ( ) > 0 ) { final int fromPos = matches . get ( 0 ) . getFromPos ( ) ; final int toPos = matches . get ( 0 ) . getToPos ( ) ; for ( final String replacement : matches . get ( 0 ) . getSuggestedReplacements ( ) ) { final String fixedSentence = badSentence . substring ( 0 , fromPos ) + replacement + badSentence . substring ( toPos ) ; matches = getMatches ( rule , fixedSentence , languageTool ) ; if ( matches . size ( ) > 0 ) { fail ( "Incorrect input:\n" + " " + badSentence + "\nCorrected sentence:\n" + " " + fixedSentence + "\nBy Rule:\n" + " " + rule + "\nThe correction triggered an error itself:\n" + " " + matches . get ( 0 ) + "\n" ) ; } } } } else { matches = getMatches ( rule , badSentence , languageTool ) ; if ( matches . size ( ) == 0 && ! complexRules . containsKey ( rule . getId ( ) + badSentence ) ) { complexRules . put ( rule . getId ( ) + badSentence , rule ) ; } if ( matches . size ( ) != 0 ) { complexRules . put ( rule . getId ( ) + badSentence , null ) ; assertTrue ( lang + ": Did expect one error in: \"" + badSentence + "\" (Rule: " + rule + "), got " + matches . size ( ) , matches . size ( ) == 1 ) ; assertEquals ( lang + ": Incorrect match position markup (start) for rule " + rule , expectedMatchStart , matches . get ( 0 ) . getFromPos ( ) ) ; assertEquals ( lang + ": Incorrect match position markup (end) for rule " + rule , expectedMatchEnd , matches . get ( 0 ) . getToPos ( ) ) ; assertSuggestions ( badSentence , lang , expectedCorrections , rule , matches ) ; assertSuggestionsDoNotCreateErrors ( badSentence , languageTool , rule , matches ) ; } } } } private boolean rangeIsOverlapping ( int a , int b , int x , int y ) { if ( a < x ) { return x <= b ; } else { return a <= y ; } } private void assertSuggestions ( String sentence , Language lang , List < String > expectedCorrections , PatternRule rule , List < RuleMatch > matches ) { if ( expectedCorrections != null && expectedCorrections . size ( ) > 0 ) { boolean expectedNonEmptyCorrection = expectedCorrections . get ( 0 ) . length ( ) > 0 ; if ( expectedNonEmptyCorrection ) { assertTrue ( "You specified a correction but your message has no suggestions in rule " + rule , rule . getMessage ( ) . contains ( "<suggestion>" ) || rule . getSuggestionsOutMsg ( ) . contains ( "<suggestion>" ) ) ; } List < String > realSuggestions = matches . get ( 0 ) . getSuggestedReplacements ( ) ; if ( realSuggestions . size ( ) == 0 ) { boolean expectedEmptyCorrection = expectedCorrections . size ( ) == 1 && expectedCorrections . get ( 0 ) . length ( ) == 0 ; assertTrue ( lang + ": Incorrect suggestions: " + expectedCorrections + " != " + " <no suggestion> for rule " + rule + " on input: " + sentence , expectedEmptyCorrection ) ; } else { assertEquals ( lang + ": Incorrect suggestions: " + expectedCorrections + " != " + realSuggestions + " for rule " + rule + " on input: " + sentence , expectedCorrections , realSuggestions ) ; } } } private void assertSuggestionsDoNotCreateErrors ( String badSentence , JLanguageTool languageTool , PatternRule rule , List < RuleMatch > matches ) throws IOException { if ( matches . get ( 0 ) . getSuggestedReplacements ( ) . size ( ) > 0 ) { final int fromPos = matches . get ( 0 ) . getFromPos ( ) ; final int toPos = matches . get ( 0 ) . getToPos ( ) ; for ( final String replacement : matches . get ( 0 ) . getSuggestedReplacements ( ) ) { final String fixedSentence = badSentence . substring ( 0 , fromPos ) + replacement + badSentence . substring ( toPos ) ; final List < RuleMatch > tempMatches = getMatches ( rule , fixedSentence , languageTool ) ; assertEquals ( "Corrected sentence for rule " + rule + " triggered error: " + fixedSentence , 0 , tempMatches . size ( ) ) ; } } } private void testCorrectSentences ( JLanguageTool languageTool , JLanguageTool allRulesLanguageTool , Language lang , PatternRule rule ) throws IOException { final List < String > goodSentences = rule . getCorrectExamples ( ) ; List < PatternRule > rules = allRulesLanguageTool . getPatternRulesByIdAndSubId ( rule . getId ( ) , rule . getSubId ( ) ) ; for ( String goodSentence : goodSentences ) { goodSentence = goodSentence . replaceAll ( "[\\n\\t]+" , "" ) ; goodSentence = cleanXML ( goodSentence ) ; assertTrue ( lang + ": Empty correct example in rule " + rule . getId ( ) , goodSentence . trim ( ) . length ( ) > 0 ) ; boolean isMatched = false ; for ( Rule auxRule : rules ) { isMatched = isMatched || match ( auxRule , goodSentence , languageTool ) ; } assertFalse ( lang + ": Did not expect error in:\n" + " " + goodSentence + "\n" + "Matching Rule: " + rule , isMatched ) ; } } protected String cleanXML ( final String str ) { return str . replaceAll ( "<([^<].*?)>" , "" ) ; } private boolean match ( final Rule rule , final String sentence , final JLanguageTool languageTool ) throws IOException { final AnalyzedSentence analyzedSentence = languageTool . getAnalyzedSentence ( sentence ) ; final RuleMatch [ ] matches = rule . match ( analyzedSentence ) ; return matches . length > 0 ; } private List < RuleMatch > getMatches ( final Rule rule , final String sentence , final JLanguageTool languageTool ) throws IOException { final AnalyzedSentence analyzedSentence = languageTool . getAnalyzedSentence ( sentence ) ; final RuleMatch [ ] matches = rule . match ( analyzedSentence ) ; if ( CHECK_WITH_SENTENCE_SPLITTING ) { for ( Rule r : languageTool . getAllActiveRules ( ) ) { languageTool . disableRule ( r . getId ( ) ) ; } languageTool . enableRule ( rule . getId ( ) ) ; final List < RuleMatch > realMatches = languageTool . check ( sentence ) ; final List < String > realMatchRuleIds = new ArrayList < > ( ) ; for ( RuleMatch realMatch : realMatches ) { realMatchRuleIds . add ( realMatch . getRule ( ) . getId ( ) ) ; } for ( RuleMatch match : matches ) { final String ruleId = match . getRule ( ) . getId ( ) ; if ( ! match . getRule ( ) . isDefaultOff ( ) && ! realMatchRuleIds . contains ( ruleId ) ) { System . err . println ( "WARNING: " + languageTool . getLanguage ( ) . getName ( ) + ": missing rule match " + ruleId + " when splitting sentences for test sentence '" + sentence + "'" ) ; } } } return Arrays . asList ( matches ) ; } protected PatternRule makePatternRule ( final String s , final boolean caseSensitive , final boolean regex ) { final List < PatternToken > patternTokens = new ArrayList < > ( ) ; final String [ ] parts = s . split ( " " ) ; boolean pos = false ; PatternToken pToken ; for ( final String element : parts ) { if ( element . equals ( JLanguageTool . SENTENCE_START_TAGNAME ) ) { pos = true ; } if ( ! pos ) { pToken = new PatternToken ( element , caseSensitive , regex , false ) ; } else { pToken = new PatternToken ( "" , caseSensitive , regex , false ) ; } if ( pos ) { pToken . setPosToken ( new PatternToken . PosToken ( element , false , false ) ) ; } patternTokens . add ( pToken ) ; pos = false ; } final PatternRule rule = new PatternRule ( "ID1" , TestTools . getDemoLanguage ( ) , patternTokens , "test rule" , "user visible message" , "short comment" ) ; return rule ; } public static void main ( final String [ ] args ) throws IOException { final PatternRuleTest test = new PatternRuleTest ( ) ; System . out . println ( "Running XML pattern tests..." ) ; if ( args . length == 0 ) { test . runGrammarRulesFromXmlTestIgnoringLanguages ( null ) ; } else { final Set < Language > ignoredLanguages = TestTools . getLanguagesExcept ( args ) ; test . runGrammarRulesFromXmlTestIgnoringLanguages ( ignoredLanguages ) ; } System . out . println ( "Tests finished!" ) ; } }
package org . languagetool . rules . patterns ; import org . junit . Test ; import static junit . framework . TestCase . assertNotNull ; public class RuleFilterCreatorTest { private final RuleFilterCreator creator = new RuleFilterCreator ( ) ; @ Test public void testMockFilter ( ) throws Exception { RuleFilter filter = creator . getFilter ( MockFilter . class . getName ( ) ) ; assertNotNull ( filter ) ; } @ Test ( expected = RuntimeException . class ) public void testInvalidClassName ( ) throws Exception { creator . getFilter ( "MyInvalidClassName" ) ; } }
package org . languagetool . rules . patterns ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; import static org . languagetool . JLanguageTool . PARAGRAPH_END_TAGNAME ; import static org . languagetool . JLanguageTool . SENTENCE_END_TAGNAME ; import static org . languagetool . JLanguageTool . SENTENCE_START_TAGNAME ; import static org . languagetool . rules . patterns . PatternToken . UNKNOWN_TAG ; public class PatternTokenTest extends TestCase { public void testSentenceStart ( ) { final PatternToken patternToken = new PatternToken ( "" , false , false , false ) ; patternToken . setPosToken ( new PatternToken . PosToken ( SENTENCE_START_TAGNAME , false , false ) ) ; assertTrue ( patternToken . isSentenceStart ( ) ) ; patternToken . setPosToken ( new PatternToken . PosToken ( SENTENCE_START_TAGNAME , false , true ) ) ; assertFalse ( patternToken . isSentenceStart ( ) ) ; patternToken . setPosToken ( new PatternToken . PosToken ( SENTENCE_START_TAGNAME , true , false ) ) ; assertTrue ( patternToken . isSentenceStart ( ) ) ; patternToken . setPosToken ( new PatternToken . PosToken ( SENTENCE_START_TAGNAME , true , true ) ) ; assertFalse ( patternToken . isSentenceStart ( ) ) ; final PatternToken patternToken2 = new PatternToken ( "bla|blah" , false , true , false ) ; patternToken2 . setPosToken ( new PatternToken . PosToken ( "foo" , true , true ) ) ; assertFalse ( patternToken2 . isSentenceStart ( ) ) ; } public void testUnknownTag ( ) { final PatternToken patternToken = new PatternToken ( "" , false , false , false ) ; patternToken . setPosToken ( new PatternToken . PosToken ( UNKNOWN_TAG , false , false ) ) ; final PatternToken patternToken2 = new PatternToken ( "" , false , false , false ) ; patternToken2 . setPosToken ( new PatternToken . PosToken ( UNKNOWN_TAG , false , true ) ) ; final PatternToken patternToken3 = new PatternToken ( "" , false , false , false ) ; patternToken3 . setPosToken ( new PatternToken . PosToken ( UNKNOWN_TAG + "|VBG" , true , false ) ) ; final PatternToken patternToken4 = new PatternToken ( "" , false , false , false ) ; patternToken4 . setPosToken ( new PatternToken . PosToken ( UNKNOWN_TAG + "|VBG" , true , true ) ) ; final PatternToken patternToken5 = new PatternToken ( "\\p{Ll}+" , false , true , false ) ; patternToken5 . setPosToken ( new PatternToken . PosToken ( UNKNOWN_TAG , false , false ) ) ; final AnalyzedToken an = new AnalyzedToken ( "schword" , null , null ) ; assertTrue ( patternToken . isMatched ( an ) ) ; assertFalse ( patternToken2 . isMatched ( an ) ) ; assertTrue ( patternToken3 . isMatched ( an ) ) ; assertFalse ( patternToken4 . isMatched ( an ) ) ; assertTrue ( patternToken5 . isMatched ( an ) ) ; an . setNoPOSTag ( false ) ; assertFalse ( patternToken . isMatched ( an ) ) ; assertTrue ( patternToken2 . isMatched ( an ) ) ; assertFalse ( patternToken3 . isMatched ( an ) ) ; assertTrue ( patternToken4 . isMatched ( an ) ) ; assertFalse ( patternToken5 . isMatched ( an ) ) ; final AnalyzedToken anSentEnd = new AnalyzedToken ( "schword" , SENTENCE_END_TAGNAME , null ) ; assertTrue ( patternToken . isMatched ( anSentEnd ) ) ; assertFalse ( patternToken2 . isMatched ( anSentEnd ) ) ; assertTrue ( patternToken3 . isMatched ( anSentEnd ) ) ; assertFalse ( patternToken4 . isMatched ( anSentEnd ) ) ; assertTrue ( patternToken5 . isMatched ( anSentEnd ) ) ; final PatternToken patternToken6 = new PatternToken ( "\\p{Ll}+" , false , true , false ) ; patternToken6 . setPosToken ( new PatternToken . PosToken ( SENTENCE_END_TAGNAME , false , false ) ) ; assertTrue ( patternToken6 . isMatched ( anSentEnd ) ) ; final PatternToken patternToken7 = new PatternToken ( "\\p{Ll}+" , false , true , false ) ; patternToken7 . setPosToken ( new PatternToken . PosToken ( SENTENCE_END_TAGNAME + "|BLABLA" , true , false ) ) ; assertTrue ( patternToken7 . isMatched ( anSentEnd ) ) ; anSentEnd . setNoPOSTag ( false ) ; assertFalse ( patternToken . isMatched ( anSentEnd ) ) ; assertTrue ( patternToken2 . isMatched ( anSentEnd ) ) ; assertFalse ( patternToken3 . isMatched ( anSentEnd ) ) ; assertTrue ( patternToken4 . isMatched ( anSentEnd ) ) ; assertFalse ( patternToken5 . isMatched ( anSentEnd ) ) ; final AnalyzedToken anParaEnd = new AnalyzedToken ( "schword" , PARAGRAPH_END_TAGNAME , null ) ; assertTrue ( patternToken . isMatched ( anParaEnd ) ) ; assertFalse ( patternToken2 . isMatched ( anParaEnd ) ) ; assertTrue ( patternToken3 . isMatched ( anParaEnd ) ) ; assertFalse ( patternToken4 . isMatched ( anParaEnd ) ) ; assertTrue ( patternToken5 . isMatched ( anParaEnd ) ) ; anParaEnd . setNoPOSTag ( false ) ; assertFalse ( patternToken . isMatched ( anParaEnd ) ) ; assertTrue ( patternToken2 . isMatched ( anParaEnd ) ) ; assertFalse ( patternToken3 . isMatched ( anParaEnd ) ) ; assertTrue ( patternToken4 . isMatched ( anParaEnd ) ) ; assertFalse ( patternToken5 . isMatched ( anParaEnd ) ) ; final AnalyzedToken anWithPOS = new AnalyzedToken ( "schword" , "POS" , null ) ; assertFalse ( patternToken . isMatched ( anWithPOS ) ) ; assertTrue ( patternToken2 . isMatched ( anWithPOS ) ) ; assertFalse ( patternToken3 . isMatched ( anWithPOS ) ) ; assertTrue ( patternToken4 . isMatched ( anWithPOS ) ) ; assertFalse ( patternToken5 . isMatched ( anWithPOS ) ) ; } }
package org . languagetool . rules . nl ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class DutchPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . patterns ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . RuleMatch ; import java . util . Map ; public class MockFilter implements RuleFilter { public MockFilter ( ) { } @ Override public RuleMatch acceptRuleMatch ( RuleMatch match , Map < String , String > arguments , AnalyzedTokenReadings [ ] patternTokens ) { return match ; } }
package org . languagetool . rules . patterns ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; public class UnifierTest extends TestCase { public void testUnificationCase ( ) { final UnifierConfiguration unifierConfig = new UnifierConfiguration ( ) ; final PatternToken elLower = new PatternToken ( "\\p{Ll}+" , true , true , false ) ; final PatternToken elUpper = new PatternToken ( "\\p{Lu}\\p{Ll}+" , true , true , false ) ; final PatternToken elAllUpper = new PatternToken ( "\\p{Lu}+$" , true , true , false ) ; unifierConfig . setEquivalence ( "case-sensitivity" , "lowercase" , elLower ) ; unifierConfig . setEquivalence ( "case-sensitivity" , "uppercase" , elUpper ) ; unifierConfig . setEquivalence ( "case-sensitivity" , "alluppercase" , elAllUpper ) ; final AnalyzedToken lower1 = new AnalyzedToken ( "lower" , "JJR" , "lower" ) ; final AnalyzedToken lower2 = new AnalyzedToken ( "lowercase" , "JJ" , "lowercase" ) ; final AnalyzedToken upper1 = new AnalyzedToken ( "Uppercase" , "JJ" , "Uppercase" ) ; final AnalyzedToken upper2 = new AnalyzedToken ( "John" , "NNP" , "John" ) ; final AnalyzedToken upperAll1 = new AnalyzedToken ( "JOHN" , "NNP" , "John" ) ; final AnalyzedToken upperAll2 = new AnalyzedToken ( "JAMES" , "NNP" , "James" ) ; final Unifier uni = unifierConfig . createUnifier ( ) ; final Map < String , List < String > > equiv = new HashMap < > ( ) ; final List < String > list1 = new ArrayList < > ( ) ; list1 . add ( "lowercase" ) ; equiv . put ( "case-sensitivity" , list1 ) ; boolean satisfied = uni . isSatisfied ( lower1 , equiv ) ; satisfied &= uni . isSatisfied ( lower2 , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( true , satisfied ) ; uni . reset ( ) ; satisfied = uni . isSatisfied ( upper2 , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( lower2 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( false , satisfied ) ; uni . reset ( ) ; satisfied = uni . isSatisfied ( upper1 , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( lower1 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( false , satisfied ) ; uni . reset ( ) ; satisfied = uni . isSatisfied ( upper2 , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( upper1 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( false , satisfied ) ; uni . reset ( ) ; equiv . clear ( ) ; list1 . clear ( ) ; list1 . add ( "uppercase" ) ; equiv . put ( "case-sensitivity" , list1 ) ; satisfied = uni . isSatisfied ( upper2 , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( upper1 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( true , satisfied ) ; uni . reset ( ) ; equiv . clear ( ) ; list1 . clear ( ) ; list1 . add ( "alluppercase" ) ; equiv . put ( "case-sensitivity" , list1 ) ; satisfied = uni . isSatisfied ( upper2 , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( upper1 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( false , satisfied ) ; uni . reset ( ) ; satisfied = uni . isSatisfied ( upperAll2 , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( upperAll1 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( true , satisfied ) ; } public void testUnificationNumber ( ) { final UnifierConfiguration unifierConfig = new UnifierConfiguration ( ) ; unifierConfig . setEquivalence ( "number" , "singular" , preparePOSElement ( ".*[\\.:]sg:.*" ) ) ; unifierConfig . setEquivalence ( "number" , "plural" , preparePOSElement ( ".*[\\.:]pl:.*" ) ) ; final Unifier uni = unifierConfig . createUnifier ( ) ; final AnalyzedToken sing1 = new AnalyzedToken ( "mały" , "adj:sg:blahblah" , "mały" ) ; final AnalyzedToken sing2 = new AnalyzedToken ( "człowiek" , "subst:sg:blahblah" , "człowiek" ) ; final Map < String , List < String > > equiv = new HashMap < > ( ) ; final List < String > list1 = new ArrayList < > ( ) ; list1 . add ( "singular" ) ; equiv . put ( "number" , list1 ) ; boolean satisfied = uni . isSatisfied ( sing1 , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( sing2 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( true , satisfied ) ; uni . reset ( ) ; AnalyzedToken sing1a = new AnalyzedToken ( "mały" , "adj:pl:blahblah" , "mały" ) ; satisfied = uni . isSatisfied ( sing1 , equiv ) ; satisfied |= uni . isSatisfied ( sing1a , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( sing2 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( true , satisfied ) ; uni . reset ( ) ; list1 . add ( "plural" ) ; equiv . clear ( ) ; equiv . put ( "number" , list1 ) ; sing1a = new AnalyzedToken ( "mały" , "adj:pl:blahblah" , "mały" ) ; satisfied = uni . isSatisfied ( sing1 , equiv ) ; satisfied |= uni . isSatisfied ( sing1a , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( sing2 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( true , satisfied ) ; uni . reset ( ) ; sing1a = new AnalyzedToken ( "mały" , "adj:pl:blahblah" , "mały" ) ; equiv . clear ( ) ; equiv . put ( "number" , null ) ; satisfied = uni . isSatisfied ( sing1 , equiv ) ; satisfied |= uni . isSatisfied ( sing1a , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( sing2 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( true , satisfied ) ; uni . reset ( ) ; satisfied = uni . isSatisfied ( sing1a , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( sing2 , equiv ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( false , satisfied ) ; uni . reset ( ) ; } public void testUnificationNumberGender ( ) { final UnifierConfiguration unifierConfig = new UnifierConfiguration ( ) ; final PatternToken sgPatternToken = new PatternToken ( "" , false , false , false ) ; sgPatternToken . setPosToken ( new PatternToken . PosToken ( ".*[\\.:]sg:.*" , true , false ) ) ; unifierConfig . setEquivalence ( "number" , "singular" , sgPatternToken ) ; final PatternToken plPatternToken = new PatternToken ( "" , false , false , false ) ; plPatternToken . setPosToken ( new PatternToken . PosToken ( ".*[\\.:]pl:.*" , true , false ) ) ; unifierConfig . setEquivalence ( "number" , "plural" , plPatternToken ) ; final PatternToken femPatternToken = new PatternToken ( "" , false , false , false ) ; femPatternToken . setPosToken ( new PatternToken . PosToken ( ".*[\\.:]f" , true , false ) ) ; unifierConfig . setEquivalence ( "gender" , "feminine" , femPatternToken ) ; final PatternToken mascPatternToken = new PatternToken ( "" , false , false , false ) ; mascPatternToken . setPosToken ( new PatternToken . PosToken ( ".*[\\.:]m" , true , false ) ) ; unifierConfig . setEquivalence ( "gender" , "masculine" , mascPatternToken ) ; final Unifier uni = unifierConfig . createUnifier ( ) ; final AnalyzedToken sing1 = new AnalyzedToken ( "mały" , "adj:sg:blahblah:m" , "mały" ) ; final AnalyzedToken sing1a = new AnalyzedToken ( "mała" , "adj:sg:blahblah:f" , "mały" ) ; final AnalyzedToken sing1b = new AnalyzedToken ( "małe" , "adj:pl:blahblah:m" , "mały" ) ; final AnalyzedToken sing2 = new AnalyzedToken ( "człowiek" , "subst:sg:blahblah:m" , "człowiek" ) ; final Map < String , List < String > > equiv = new HashMap < > ( ) ; equiv . put ( "number" , null ) ; equiv . put ( "gender" , null ) ; boolean satisfied = uni . isSatisfied ( sing1 , equiv ) ; satisfied |= uni . isSatisfied ( sing1a , equiv ) ; satisfied |= uni . isSatisfied ( sing1b , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( sing2 , equiv ) ; uni . startNextToken ( ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( true , satisfied ) ; assertEquals ( "[mały[mały/adj:sg:blahblah:m*], człowiek[człowiek/subst:sg:blahblah:m*]]" , Arrays . toString ( uni . getUnifiedTokens ( ) ) ) ; uni . reset ( ) ; } public void testMultipleFeats ( ) { final UnifierConfiguration unifierConfig = new UnifierConfiguration ( ) ; unifierConfig . setEquivalence ( "number" , "singular" , preparePOSElement ( ".*[\\.:]sg:.*" ) ) ; unifierConfig . setEquivalence ( "number" , "plural" , preparePOSElement ( ".*[\\.:]pl:.*" ) ) ; unifierConfig . setEquivalence ( "gender" , "feminine" , preparePOSElement ( ".*[\\.:]f([\\.:].*)?" ) ) ; unifierConfig . setEquivalence ( "gender" , "masculine" , preparePOSElement ( ".*[\\.:]m([\\.:].*)?" ) ) ; unifierConfig . setEquivalence ( "gender" , "neutral" , preparePOSElement ( ".*[\\.:]n([\\.:].*)?" ) ) ; final Unifier uni = unifierConfig . createUnifier ( ) ; final AnalyzedToken sing1 = new AnalyzedToken ( "mały" , "adj:sg:blahblah:m" , "mały" ) ; AnalyzedToken sing1a = new AnalyzedToken ( "mały" , "adj:pl:blahblah:f" , "mały" ) ; AnalyzedToken sing1b = new AnalyzedToken ( "mały" , "adj:pl:blahblah:f" , "mały" ) ; AnalyzedToken sing2 = new AnalyzedToken ( "zgarbiony" , "adj:pl:blahblah:f" , "zgarbiony" ) ; final AnalyzedToken sing3 = new AnalyzedToken ( "człowiek" , "subst:sg:blahblah:m" , "człowiek" ) ; final Map < String , List < String > > equiv = new HashMap < > ( ) ; equiv . put ( "number" , null ) ; equiv . put ( "gender" , null ) ; boolean satisfied = uni . isSatisfied ( sing1 , equiv ) ; satisfied |= uni . isSatisfied ( sing1a , equiv ) ; satisfied |= uni . isSatisfied ( sing1b , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( sing2 , equiv ) ; uni . startNextToken ( ) ; satisfied &= uni . isSatisfied ( sing3 , equiv ) ; uni . startNextToken ( ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( false , satisfied ) ; uni . reset ( ) ; uni . isUnified ( sing1 , equiv , false ) ; uni . isUnified ( sing1a , equiv , false ) ; uni . isUnified ( sing1b , equiv , true ) ; uni . isUnified ( sing2 , equiv , true ) ; assertEquals ( false , uni . isUnified ( sing3 , equiv , true ) ) ; uni . reset ( ) ; sing1a = new AnalyzedToken ( "osobiste" , "adj:pl:nom.acc.voc:f.n.m2.m3:pos:aff" , "osobisty" ) ; sing1b = new AnalyzedToken ( "osobiste" , "adj:sg:nom.acc.voc:n:pos:aff" , "osobisty" ) ; sing2 = new AnalyzedToken ( "godło" , "subst:sg:nom.acc.voc:n" , "godło" ) ; uni . isUnified ( sing1a , equiv , false ) ; uni . isUnified ( sing1b , equiv , true ) ; assertEquals ( true , uni . isUnified ( sing2 , equiv , true ) ) ; assertEquals ( "[osobiste[osobisty/adj:sg:nom.acc.voc:n:pos:aff*], godło[godło/subst:sg:nom.acc.voc:n*]]" , Arrays . toString ( uni . getFinalUnified ( ) ) ) ; uni . reset ( ) ; sing1a = new AnalyzedToken ( "osobiste" , "adj:pl:nom.acc.voc:f.n.m2.m3:pos:aff" , "osobisty" ) ; sing1b = new AnalyzedToken ( "osobiste" , "adj:sg:nom.acc.voc:n:pos:aff" , "osobisty" ) ; final AnalyzedToken sing2a = new AnalyzedToken ( "godło" , "subst:sg:nom.acc.voc:n" , "godło" ) ; final AnalyzedToken sing2b = new AnalyzedToken ( "godło" , "indecl" , "godło" ) ; uni . isUnified ( sing1a , equiv , false ) ; uni . isUnified ( sing1b , equiv , true ) ; uni . isUnified ( sing2a , equiv , false ) ; assertEquals ( true , uni . isUnified ( sing2b , equiv , true ) ) ; assertEquals ( "[osobiste[osobisty/adj:sg:nom.acc.voc:n:pos:aff*], godło[godło/subst:sg:nom.acc.voc:n*]]" , Arrays . toString ( uni . getFinalUnified ( ) ) ) ; uni . reset ( ) ; AnalyzedToken plur1 = new AnalyzedToken ( "zgarbieni" , "adj:pl:foobar:m" , "zgarbiony" ) ; AnalyzedToken plur2 = new AnalyzedToken ( "zgarbieni" , "adj:pl:blabla:m" , "zgarbiony" ) ; AnalyzedToken plur3 = new AnalyzedToken ( "ludzie" , "subst:pl:blabla:m" , "człowiek" ) ; AnalyzedToken plur4 = new AnalyzedToken ( "ludzie" , "subst:pl:pampam:m" , "człowiek" ) ; uni . isUnified ( plur1 , equiv , false ) ; uni . isUnified ( plur2 , equiv , true ) ; uni . isUnified ( plur3 , equiv , false ) ; assertTrue ( uni . isUnified ( plur4 , equiv , true ) ) ; assertEquals ( "[zgarbieni[zgarbiony/adj:pl:foobar:m*,zgarbiony/adj:pl:blabla:m*], " + "ludzie[człowiek/subst:pl:blabla:m*,człowiek/subst:pl:pampam:m*]]" , Arrays . toString ( uni . getFinalUnified ( ) ) ) ; uni . reset ( ) ; AnalyzedToken case1a = new AnalyzedToken ( "xx" , "abc:sg:f" , "xx" ) ; AnalyzedToken case1b = new AnalyzedToken ( "xx" , "cde:pl:f" , "xx" ) ; AnalyzedToken case2a = new AnalyzedToken ( "yy" , "abc:pl:f" , "yy" ) ; AnalyzedToken case2b = new AnalyzedToken ( "yy" , "cde:as:f" , "yy" ) ; AnalyzedToken case2c = new AnalyzedToken ( "yy" , "cde:pl:c" , "yy" ) ; AnalyzedToken case2d = new AnalyzedToken ( "yy" , "abc:sg:f" , "yy" ) ; AnalyzedToken case2e = new AnalyzedToken ( "yy" , "efg:aa:e" , "yy" ) ; uni . isUnified ( case1a , equiv , false ) ; uni . isUnified ( case1b , equiv , true ) ; uni . isUnified ( case2a , equiv , false ) ; uni . isUnified ( case2b , equiv , false ) ; uni . isUnified ( case2c , equiv , false ) ; uni . isUnified ( case2d , equiv , false ) ; assertTrue ( uni . isUnified ( case2e , equiv , true ) ) ; assertEquals ( "[xx[xx/abc:sg:f*,xx/cde:pl:f*], yy[yy/abc:pl:f*,yy/abc:sg:f*]]" , Arrays . toString ( uni . getFinalUnified ( ) ) ) ; uni . reset ( ) ; AnalyzedToken tokenComplex1_1 = new AnalyzedToken ( "xx" , "abc:sg:f" , "xx1" ) ; AnalyzedToken tokenComplex1_2 = new AnalyzedToken ( "xx" , "cde:pl:f" , "xx2" ) ; AnalyzedToken tokenComplex2_1 = new AnalyzedToken ( "yy" , "abc:sg:f" , "yy1" ) ; AnalyzedToken tokenComplex2_2 = new AnalyzedToken ( "yy" , "cde:pl:f" , "yy2" ) ; AnalyzedToken tokenComplex3 = new AnalyzedToken ( "zz" , "cde:sg:f" , "zz" ) ; uni . isUnified ( tokenComplex1_1 , equiv , false ) ; uni . isUnified ( tokenComplex1_2 , equiv , true ) ; uni . isUnified ( tokenComplex2_1 , equiv , false ) ; uni . isUnified ( tokenComplex2_2 , equiv , true ) ; assertEquals ( "[xx[xx1/abc:sg:f*,xx2/cde:pl:f*], yy[yy1/abc:sg:f*,yy2/cde:pl:f*]]" , Arrays . toString ( uni . getFinalUnified ( ) ) ) ; assertTrue ( uni . isUnified ( tokenComplex3 , equiv , true ) ) ; assertEquals ( "[xx[xx1/abc:sg:f*], yy[yy1/abc:sg:f*], zz[zz/cde:sg:f*]]" , Arrays . toString ( uni . getFinalUnified ( ) ) ) ; } public void testMultipleFeatsWithMultipleTypes ( ) { final UnifierConfiguration unifierConfig = new UnifierConfiguration ( ) ; unifierConfig . setEquivalence ( "number" , "singular" , preparePOSElement ( ".*[\\.:]sg:.*" ) ) ; unifierConfig . setEquivalence ( "number" , "plural" , preparePOSElement ( ".*[\\.:]pl:.*" ) ) ; unifierConfig . setEquivalence ( "gender" , "feminine" , preparePOSElement ( ".*[\\.:]f([\\.:].*)?" ) ) ; unifierConfig . setEquivalence ( "gender" , "masculine" , preparePOSElement ( ".*[\\.:]m1([\\.:].*)?" ) ) ; unifierConfig . setEquivalence ( "gender" , "masculine" , preparePOSElement ( ".*[\\.:]m2([\\.:].*)?" ) ) ; unifierConfig . setEquivalence ( "gender" , "masculine" , preparePOSElement ( ".*[\\.:]m3([\\.:].*)?" ) ) ; unifierConfig . setEquivalence ( "gender" , "neutral1" , preparePOSElement ( ".*[\\.:]n1(?:[\\.:].*)?" ) ) ; unifierConfig . setEquivalence ( "gender" , "neutral2" , preparePOSElement ( ".*[\\.:]n2(?:[\\.:].*)?" ) ) ; unifierConfig . setEquivalence ( "case" , "nominativus" , preparePOSElement ( ".*[\\.:]nom[\\.:]?.*" ) ) ; unifierConfig . setEquivalence ( "case" , "accusativus" , preparePOSElement ( ".*[\\.:]acc[\\.:]?.*" ) ) ; unifierConfig . setEquivalence ( "case" , "dativus" , preparePOSElement ( ".*[\\.:]dat[\\.:]?.*" ) ) ; unifierConfig . setEquivalence ( "case" , "vocativus" , preparePOSElement ( ".*[\\.:]voc[\\.:]?.*" ) ) ; final Unifier uni = unifierConfig . createUnifier ( ) ; final AnalyzedToken sing1 = new AnalyzedToken ( "niezgorsze" , "adj:sg:acc:n1.n2:pos" , "niezgorszy" ) ; final AnalyzedToken sing1a = new AnalyzedToken ( "niezgorsze" , "adj:pl:acc:m2.m3.f.n1.n2.p2.p3:pos" , "niezgorszy" ) ; final AnalyzedToken sing1b = new AnalyzedToken ( "niezgorsze" , "adj:pl:nom.voc:m2.m3.f.n1.n2.p2.p3:pos" , "niezgorszy" ) ; final AnalyzedToken sing1c = new AnalyzedToken ( "niezgorsze" , "adj:sg:nom.voc:n1.n2:pos" , "niezgorszy" ) ; final AnalyzedToken sing2 = new AnalyzedToken ( "lekarstwo" , "subst:sg:acc:n2" , "lekarstwo" ) ; final AnalyzedToken sing2b = new AnalyzedToken ( "lekarstwo" , "subst:sg:nom:n2" , "lekarstwo" ) ; final AnalyzedToken sing2c = new AnalyzedToken ( "lekarstwo" , "subst:sg:voc:n2" , "lekarstwo" ) ; final Map < String , List < String > > equiv = new HashMap < > ( ) ; equiv . put ( "number" , null ) ; equiv . put ( "gender" , null ) ; equiv . put ( "case" , null ) ; uni . isUnified ( sing1 , equiv , false ) ; uni . isUnified ( sing1a , equiv , false ) ; uni . isUnified ( sing1b , equiv , false ) ; uni . isUnified ( sing1c , equiv , true ) ; uni . isUnified ( sing2 , equiv , false ) ; uni . isUnified ( sing2b , equiv , false ) ; assertEquals ( true , uni . isUnified ( sing2c , equiv , true ) ) ; assertEquals ( "[niezgorsze[niezgorszy/adj:sg:acc:n1.n2:pos*,niezgorszy/adj:sg:nom.voc:n1.n2:pos*], " + "lekarstwo[lekarstwo/subst:sg:acc:n2*,lekarstwo/subst:sg:nom:n2*,lekarstwo/subst:sg:voc:n2*]]" , Arrays . toString ( uni . getUnifiedTokens ( ) ) ) ; uni . reset ( ) ; uni . isUnified ( sing1a , equiv , false ) ; uni . isUnified ( sing1 , equiv , false ) ; uni . isUnified ( sing1c , equiv , false ) ; uni . isUnified ( sing1b , equiv , true ) ; uni . isUnified ( sing2b , equiv , false ) ; uni . isUnified ( sing2c , equiv , false ) ; assertEquals ( true , uni . isUnified ( sing2 , equiv , true ) ) ; assertEquals ( "[niezgorsze[niezgorszy/adj:sg:acc:n1.n2:pos*,niezgorszy/adj:sg:nom.voc:n1.n2:pos*], " + "lekarstwo[lekarstwo/subst:sg:nom:n2*,lekarstwo/subst:sg:voc:n2*,lekarstwo/subst:sg:acc:n2*]]" , Arrays . toString ( uni . getUnifiedTokens ( ) ) ) ; uni . reset ( ) ; } private PatternToken preparePOSElement ( final String posString ) { final PatternToken pToken = new PatternToken ( "" , false , false , false ) ; pToken . setPosToken ( new PatternToken . PosToken ( posString , true , false ) ) ; return pToken ; } public void testNegation ( ) { final UnifierConfiguration unifierConfig = new UnifierConfiguration ( ) ; unifierConfig . setEquivalence ( "number" , "singular" , preparePOSElement ( ".*[\\.:]sg:.*" ) ) ; unifierConfig . setEquivalence ( "number" , "plural" , preparePOSElement ( ".*[\\.:]pl:.*" ) ) ; unifierConfig . setEquivalence ( "gender" , "feminine" , preparePOSElement ( ".*:f" ) ) ; unifierConfig . setEquivalence ( "gender" , "masculine" , preparePOSElement ( ".*:m" ) ) ; final Unifier uni = unifierConfig . createUnifier ( ) ; final AnalyzedToken sing_masc = new AnalyzedToken ( "parvus" , "adj:sg:blahblah:m" , "parvus" ) ; final AnalyzedToken plur_masc = new AnalyzedToken ( "parvi" , "adj:sg:blahblah:m" , "parvus" ) ; final AnalyzedToken plur_fem = new AnalyzedToken ( "parvae" , "adj:pl:blahblah:f" , "parvus" ) ; final AnalyzedToken sing_fem = new AnalyzedToken ( "parva" , "adj:sg:blahblah:f" , "parvus" ) ; final AnalyzedToken det_sing_fem = new AnalyzedToken ( "una" , "det:sg:blahblah:f" , "unus" ) ; final AnalyzedToken det_plur_fem = new AnalyzedToken ( "unae" , "det:pl:blahblah:f" , "unus" ) ; final AnalyzedToken det_sing_masc = new AnalyzedToken ( "unus" , "det:sg:blahblah:m" , "unus" ) ; final AnalyzedToken det_plur_masc = new AnalyzedToken ( "uni" , "det:sg:blahblah:m" , "unus" ) ; final AnalyzedToken subst_sing_fem = new AnalyzedToken ( "discrepatio" , "subst:sg:blahblah:f" , "discrepatio" ) ; final AnalyzedToken subst_plur_fem = new AnalyzedToken ( "discrepationes" , "subst:sg:blahblah:f" , "discrepatio" ) ; final AnalyzedToken subst_sing_masc = new AnalyzedToken ( "homo" , "sg:sg:blahblah:m" , "homo" ) ; final AnalyzedToken subst_plur_masc = new AnalyzedToken ( "homines" , "sg:sg:blahblah:m" , "homo" ) ; final Map < String , List < String > > equiv = new HashMap < > ( ) ; equiv . put ( "number" , null ) ; equiv . put ( "gender" , null ) ; boolean satisfied = uni . isSatisfied ( det_sing_masc , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( sing_masc , equiv ) ; uni . startNextToken ( ) ; satisfied &= uni . isSatisfied ( subst_sing_masc , equiv ) ; uni . startNextToken ( ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( true , satisfied ) ; uni . reset ( ) ; uni . isUnified ( det_sing_masc , equiv , true ) ; uni . isUnified ( sing_masc , equiv , true ) ; assertEquals ( true , uni . isUnified ( subst_sing_masc , equiv , true ) ) ; uni . reset ( ) ; satisfied = uni . isSatisfied ( det_sing_masc , equiv ) ; uni . startUnify ( ) ; satisfied &= uni . isSatisfied ( sing_masc , equiv ) ; uni . startNextToken ( ) ; satisfied &= uni . isSatisfied ( subst_sing_masc , equiv ) ; uni . startNextToken ( ) ; satisfied &= uni . getFinalUnificationValue ( equiv ) ; assertEquals ( false , ! satisfied ) ; uni . reset ( ) ; uni . isUnified ( det_sing_masc , equiv , true ) ; uni . isUnified ( sing_masc , equiv , true ) ; assertEquals ( false , ! uni . isUnified ( subst_sing_masc , equiv , true ) ) ; uni . reset ( ) ; uni . isUnified ( det_sing_fem , equiv , true ) ; uni . isUnified ( sing_masc , equiv , true ) ; assertEquals ( true , ! uni . isUnified ( subst_sing_masc , equiv , true ) ) ; uni . reset ( ) ; uni . isUnified ( det_sing_masc , equiv , true ) ; uni . isUnified ( sing_fem , equiv , true ) ; assertEquals ( true , ! uni . isUnified ( subst_sing_masc , equiv , true ) ) ; uni . reset ( ) ; uni . isUnified ( det_sing_masc , equiv , true ) ; uni . isUnified ( sing_masc , equiv , true ) ; assertEquals ( true , ! uni . isUnified ( subst_sing_fem , equiv , true ) ) ; uni . reset ( ) ; uni . isUnified ( det_sing_masc , equiv , true ) ; uni . isUnified ( plur_masc , equiv , true ) ; assertEquals ( true , ! uni . isUnified ( subst_sing_fem , equiv , true ) ) ; uni . reset ( ) ; uni . isUnified ( det_sing_masc , equiv , true ) ; uni . isUnified ( plur_fem , equiv , true ) ; assertEquals ( true , ! uni . isUnified ( subst_sing_fem , equiv , true ) ) ; uni . reset ( ) ; uni . isUnified ( det_plur_fem , equiv , true ) ; uni . isUnified ( plur_fem , equiv , true ) ; assertEquals ( true , ! uni . isUnified ( subst_sing_fem , equiv , true ) ) ; uni . reset ( ) ; uni . isUnified ( det_sing_fem , equiv , true ) ; uni . isUnified ( plur_fem , equiv , true ) ; assertEquals ( true , ! uni . isUnified ( subst_plur_fem , equiv , true ) ) ; uni . reset ( ) ; uni . isUnified ( det_sing_fem , equiv , true ) ; uni . isUnified ( plur_fem , equiv , true ) ; assertEquals ( true , ! uni . isUnified ( subst_plur_masc , equiv , true ) ) ; uni . reset ( ) ; uni . isUnified ( det_plur_masc , equiv , true ) ; uni . isUnified ( plur_fem , equiv , true ) ; assertEquals ( true , ! uni . isUnified ( subst_plur_masc , equiv , true ) ) ; uni . reset ( ) ; } public void testAddNeutralElement ( ) { final UnifierConfiguration unifierConfig = new UnifierConfiguration ( ) ; unifierConfig . setEquivalence ( "number" , "singular" , preparePOSElement ( ".*[\\.:]sg:.*" ) ) ; unifierConfig . setEquivalence ( "number" , "plural" , preparePOSElement ( ".*[\\.:]pl:.*" ) ) ; unifierConfig . setEquivalence ( "gender" , "feminine" , preparePOSElement ( ".*[\\.:]f([\\.:].*)?" ) ) ; unifierConfig . setEquivalence ( "gender" , "masculine" , preparePOSElement ( ".*[\\.:]m([\\.:].*)?" ) ) ; unifierConfig . setEquivalence ( "gender" , "neutral" , preparePOSElement ( ".*[\\.:]n([\\.:].*)?" ) ) ; final Unifier uni = unifierConfig . createUnifier ( ) ; final Map < String , List < String > > equiv = new HashMap < > ( ) ; equiv . put ( "number" , null ) ; equiv . put ( "gender" , null ) ; AnalyzedToken sing1a = new AnalyzedToken ( "osobiste" , "adj:pl:nom.acc.voc:f.n.m2.m3:pos:aff" , "osobisty" ) ; AnalyzedToken sing1b = new AnalyzedToken ( "osobiste" , "adj:sg:nom.acc.voc:n:pos:aff" , "osobisty" ) ; AnalyzedToken sing2 = new AnalyzedToken ( "godło" , "subst:sg:nom.acc.voc:n" , "godło" ) ; AnalyzedToken comma = new AnalyzedToken ( "," , "comma" , "," ) ; uni . isUnified ( sing1a , equiv , false ) ; uni . isUnified ( sing1b , equiv , true ) ; uni . addNeutralElement ( new AnalyzedTokenReadings ( comma , 0 ) ) ; assertEquals ( true , uni . isUnified ( sing2 , equiv , true ) ) ; assertEquals ( "[osobiste[osobisty/adj:sg:nom.acc.voc:n:pos:aff*], ,[,/comma*], godło[godło/subst:sg:nom.acc.voc:n*]]" , Arrays . toString ( uni . getFinalUnified ( ) ) ) ; uni . reset ( ) ; } }
package org . languagetool . rules . patterns ; import org . junit . Test ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . chunking . ChunkTag ; import org . languagetool . language . Demo ; import java . util . Collections ; import static junit . framework . TestCase . assertFalse ; import static junit . framework . TestCase . assertTrue ; public class AbstractPatternRulePerformerTest { @ Test public void testTestAllReadings ( ) throws Exception { PatternToken patternToken1 = new PatternToken ( "foo" , false , false , false ) ; PatternRule simpleRule = new PatternRule ( "FAKE" , new Demo ( ) , Collections . singletonList ( patternToken1 ) , "descr" , "message" , "short" ) ; PatternTokenMatcher elemMatcher = new PatternTokenMatcher ( patternToken1 ) ; AbstractPatternRulePerformer p = new MockAbstractPatternRulePerformer ( simpleRule , null ) ; assertTrue ( p . testAllReadings ( tokenReadings ( "foo" , null ) , elemMatcher , null , 0 , 0 , 0 ) ) ; assertFalse ( p . testAllReadings ( tokenReadings ( "bar" , null ) , elemMatcher , null , 0 , 0 , 0 ) ) ; assertTrue ( p . testAllReadings ( tokenReadings ( "foo" , "myChunk" ) , elemMatcher , null , 0 , 0 , 0 ) ) ; assertTrue ( p . testAllReadings ( tokenReadings ( "foo" , "otherChunk" ) , elemMatcher , null , 0 , 0 , 0 ) ) ; } @ Test public void testTestAllReadingsWithChunks ( ) throws Exception { PatternToken chunkPatternToken = new PatternToken ( null , false , false , false ) ; chunkPatternToken . setChunkTag ( new ChunkTag ( "myChunk" ) ) ; PatternRule simpleRule = new PatternRule ( "FAKE" , new Demo ( ) , Collections . singletonList ( chunkPatternToken ) , "descr" , "message" , "short" ) ; PatternTokenMatcher elemMatcher = new PatternTokenMatcher ( chunkPatternToken ) ; AbstractPatternRulePerformer p = new MockAbstractPatternRulePerformer ( simpleRule , null ) ; assertFalse ( p . testAllReadings ( tokenReadings ( "bar" , null ) , elemMatcher , null , 0 , 0 , 0 ) ) ; assertTrue ( p . testAllReadings ( tokenReadings ( "bar" , "myChunk" ) , elemMatcher , null , 0 , 0 , 0 ) ) ; assertFalse ( p . testAllReadings ( tokenReadings ( "bar" , "otherChunk" ) , elemMatcher , null , 0 , 0 , 0 ) ) ; } private AnalyzedTokenReadings [ ] tokenReadings ( String token , String chunkTag ) { AnalyzedTokenReadings tokenReadings1 = new AnalyzedTokenReadings ( new AnalyzedToken ( token , "pos" , "lemma" ) , 0 ) ; if ( chunkTag != null ) { tokenReadings1 . setChunkTags ( Collections . singletonList ( new ChunkTag ( chunkTag ) ) ) ; } return new AnalyzedTokenReadings [ ] { tokenReadings1 } ; } class MockAbstractPatternRulePerformer extends AbstractPatternRulePerformer { protected MockAbstractPatternRulePerformer ( AbstractPatternRule rule , Unifier unifier ) { super ( rule , unifier ) ; } } }
package org . languagetool . rules . patterns ; import java . io . ByteArrayInputStream ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Demo ; import org . languagetool . rules . patterns . Match . CaseConversion ; import org . languagetool . rules . patterns . Match . IncludeRange ; import org . languagetool . synthesis . ManualSynthesizer ; import org . languagetool . synthesis . ManualSynthesizerAdapter ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . tagging . ManualTagger ; import org . languagetool . tagging . Tagger ; import org . languagetool . tokenizers . ManualTaggerAdapter ; public class MatchTest extends TestCase { private static final String TEST_DATA = "# some test data\n" + "inflectedform11\tlemma1\tPOS1\n" + "inflectedform121\tlemma1\tPOS2\n" + "inflectedform122\tlemma1\tPOS2\n" + "inflectedform123\tlemma1\tPOS3\n" + "inflectedform2\tlemma2\tPOS1\n" ; private JLanguageTool languageTool ; private Synthesizer synthesizer ; private Tagger tagger ; private AnalyzedTokenReadings [ ] getAnalyzedTokenReadings ( final String input ) throws IOException { return languageTool . getAnalyzedSentence ( input ) . getTokensWithoutWhitespace ( ) ; } private AnalyzedTokenReadings getAnalyzedTokenReadings ( String token , String posTag , String lemma ) { return new AnalyzedTokenReadings ( new AnalyzedToken ( token , posTag , lemma ) , 0 ) ; } private Match getMatch ( String posTag , String posTagReplace , CaseConversion caseConversion ) { return new Match ( posTag , posTagReplace , true , null , null , caseConversion , false , false , IncludeRange . NONE ) ; } private Match getMatch ( String posTag , String posTagReplace , IncludeRange includeRange ) { return new Match ( posTag , posTagReplace , true , null , null , CaseConversion . NONE , false , false , includeRange ) ; } @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; tagger = new ManualTaggerAdapter ( new ManualTagger ( new ByteArrayInputStream ( TEST_DATA . getBytes ( "UTF-8" ) ) ) ) ; synthesizer = new ManualSynthesizerAdapter ( new ManualSynthesizer ( new ByteArrayInputStream ( TEST_DATA . getBytes ( "UTF-8" ) ) ) ) ; languageTool = new JLanguageTool ( new Demo ( ) { @ Override public String getName ( ) { return "TEST" ; } @ Override public Synthesizer getSynthesizer ( ) { return MatchTest . this . synthesizer ; } @ Override public Tagger getTagger ( ) { return MatchTest . this . tagger ; } } ) ; } public void testStartUpper ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . STARTUPPER ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "inflectedform11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[Inflectedform121, Inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testStartLower ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . STARTLOWER ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "InflectedForm11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[inflectedform121, inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testAllUpper ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . ALLUPPER ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "InflectedForm11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[INFLECTEDFORM121, INFLECTEDFORM122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testAllLower ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . ALLLOWER ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "InflectedForm11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[inflectedform121, inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testPreserveStartUpper ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . PRESERVE ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "InflectedForm11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[Inflectedform121, Inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testStaticLemmaPreserveStartLower ( ) throws Exception { final Match match = getMatch ( "POS2" , "POS1" , Match . CaseConversion . PRESERVE ) ; match . setLemmaString ( "lemma2" ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "inflectedform121" , "POS2" , "Lemma1" ) ) ; assertEquals ( "[inflectedform2]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testStaticLemmaPreserveStartUpper ( ) throws Exception { final Match match = getMatch ( "POS2" , "POS1" , Match . CaseConversion . PRESERVE ) ; match . setLemmaString ( "lemma2" ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "InflectedForm121" , "POS2" , "Lemma1" ) ) ; assertEquals ( "[Inflectedform2]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testStaticLemmaPreserveAllUpper ( ) throws Exception { final Match match = getMatch ( "POS2" , "POS1" , Match . CaseConversion . PRESERVE ) ; match . setLemmaString ( "lemma2" ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "INFLECTEDFORM121" , "POS2" , "Lemma1" ) ) ; assertEquals ( "[INFLECTEDFORM2]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testStaticLemmaPreserveMixed ( ) throws Exception { final Match match = getMatch ( "POS2" , "POS1" , Match . CaseConversion . PRESERVE ) ; match . setLemmaString ( "lemma2" ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "infleCtedForm121" , "POS2" , "Lemma1" ) ) ; assertEquals ( "[inflectedform2]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testPreserveStartLower ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . PRESERVE ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "inflectedForm11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[inflectedform121, inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testPreserveAllUpper ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . PRESERVE ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "INFLECTEDFORM11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[INFLECTEDFORM121, INFLECTEDFORM122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testPreserveMixed ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . PRESERVE ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "inflecTedForm11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[inflectedform121, inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testPreserveNoneUpper ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . NONE ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "INFLECTEDFORM11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[inflectedform121, inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testPreserveNoneLower ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . NONE ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "inflectedform11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[inflectedform121, inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testPreserveNoneMixed ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS2" , Match . CaseConversion . NONE ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "inFLectedFOrm11" , "POS1" , "Lemma1" ) ) ; assertEquals ( "[inflectedform121, inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testSimpleIncludeFollowing ( ) throws Exception { final Match match = getMatch ( null , null , Match . IncludeRange . FOLLOWING ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "inflectedform11 inflectedform2 inflectedform122 inflectedform122" ) , 1 , 3 ) ; assertEquals ( "[inflectedform2 inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testPOSIncludeFollowing ( ) throws Exception { final Match match = getMatch ( "POS2" , "POS33" , Match . IncludeRange . FOLLOWING ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "inflectedform11 inflectedform2 inflectedform122 inflectedform122" ) , 1 , 3 ) ; assertEquals ( "[inflectedform2 inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testIncludeAll ( ) throws Exception { final Match match = getMatch ( null , null , Match . IncludeRange . ALL ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "inflectedform11 inflectedform2 inflectedform122 inflectedform122" ) , 1 , 3 ) ; assertEquals ( "[inflectedform11 inflectedform2 inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } public void testPOSIncludeAll ( ) throws Exception { final Match match = getMatch ( "POS1" , "POS3" , Match . IncludeRange . ALL ) ; final MatchState state = match . createState ( synthesizer , getAnalyzedTokenReadings ( "inflectedform11 inflectedform2 inflectedform122 inflectedform122" ) , 1 , 3 ) ; assertEquals ( "[inflectedform123 inflectedform2 inflectedform122]" , Arrays . toString ( state . toFinalString ( null ) ) ) ; } }
package org . languagetool . rules . patterns ; import org . junit . Test ; import org . languagetool . FakeLanguage ; import static junit . framework . Assert . assertNull ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class MatchStateTest { @ Test public void testConvertCase ( ) { MatchState startUpper = getMatchState ( Match . CaseConversion . STARTUPPER ) ; assertNull ( startUpper . convertCase ( null , "Y" , new FakeLanguage ( "en" ) ) ) ; assertThat ( startUpper . convertCase ( "" , "Y" , new FakeLanguage ( "en" ) ) , is ( "" ) ) ; assertThat ( startUpper . convertCase ( "x" , "Y" , new FakeLanguage ( "en" ) ) , is ( "X" ) ) ; assertThat ( startUpper . convertCase ( "xxx" , "Yyy" , new FakeLanguage ( "en" ) ) , is ( "Xxx" ) ) ; assertThat ( startUpper . convertCase ( "ijsselmeer" , "Uppercase" , new FakeLanguage ( "nl" ) ) , is ( "IJsselmeer" ) ) ; assertThat ( startUpper . convertCase ( "ijsselmeer" , "lowercase" , new FakeLanguage ( "nl" ) ) , is ( "IJsselmeer" ) ) ; assertThat ( startUpper . convertCase ( "ij" , "Uppercase" , new FakeLanguage ( "nl" ) ) , is ( "IJ" ) ) ; MatchState preserve = getMatchState ( Match . CaseConversion . PRESERVE ) ; assertThat ( preserve . convertCase ( "xxx" , "Yyy" , new FakeLanguage ( "en" ) ) , is ( "Xxx" ) ) ; assertThat ( preserve . convertCase ( "xxx" , "yyy" , new FakeLanguage ( "en" ) ) , is ( "xxx" ) ) ; assertThat ( preserve . convertCase ( "xxx" , "YYY" , new FakeLanguage ( "en" ) ) , is ( "XXX" ) ) ; assertThat ( preserve . convertCase ( "ijsselmeer" , "Uppercase" , new FakeLanguage ( "nl" ) ) , is ( "IJsselmeer" ) ) ; assertThat ( preserve . convertCase ( "ijsselmeer" , "lowercase" , new FakeLanguage ( "nl" ) ) , is ( "ijsselmeer" ) ) ; assertThat ( preserve . convertCase ( "ijsselmeer" , "ALLUPPER" , new FakeLanguage ( "nl" ) ) , is ( "IJSSELMEER" ) ) ; MatchState startLower = getMatchState ( Match . CaseConversion . STARTLOWER ) ; assertThat ( startLower . convertCase ( "xxx" , "YYY" , new FakeLanguage ( "en" ) ) , is ( "xxx" ) ) ; assertThat ( startLower . convertCase ( "xxx" , "yyy" , new FakeLanguage ( "en" ) ) , is ( "xxx" ) ) ; assertThat ( startLower . convertCase ( "xxx" , "Yyy" , new FakeLanguage ( "en" ) ) , is ( "xxx" ) ) ; assertThat ( startLower . convertCase ( "XXX" , "Yyy" , new FakeLanguage ( "en" ) ) , is ( "xXX" ) ) ; assertThat ( startLower . convertCase ( "Xxx" , "Yyy" , new FakeLanguage ( "en" ) ) , is ( "xxx" ) ) ; } private MatchState getMatchState ( Match . CaseConversion conversion ) { return new MatchState ( new Match ( "" , "" , false , "" , "" , conversion , false , false , Match . IncludeRange . NONE ) , null ) ; } }
package org . languagetool . rules . patterns ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . language . Demo ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Collections ; import java . util . List ; public class DemoPatternRuleTest extends PatternRuleTest { private static final Language language = TestTools . getDemoLanguage ( ) ; public void testRules ( ) throws IOException { runTestForLanguage ( new Demo ( ) ) ; } public void testGrammarRulesFromXML2 ( ) throws IOException { new PatternRule ( "-1" , language , Collections . < PatternToken > emptyList ( ) , "" , "" , "" ) ; } public void testMakeSuggestionUppercase ( ) throws IOException { final JLanguageTool langTool = new JLanguageTool ( language ) ; final PatternToken patternToken = new PatternToken ( "Were" , false , false , false ) ; final String message = "Did you mean: <suggestion>where</suggestion> or <suggestion>we</suggestion>?" ; final PatternRule rule = new PatternRule ( "MY_ID" , language , Collections . singletonList ( patternToken ) , "desc" , message , "msg" ) ; final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "Were are in the process of ..." ) ) ; assertEquals ( 1 , matches . length ) ; final RuleMatch match = matches [ 0 ] ; final List < String > replacements = match . getSuggestedReplacements ( ) ; assertEquals ( 2 , replacements . size ( ) ) ; assertEquals ( "Where" , replacements . get ( 0 ) ) ; assertEquals ( "We" , replacements . get ( 1 ) ) ; } public void testRule ( ) throws IOException { PatternRule pr ; RuleMatch [ ] matches ; JLanguageTool langTool = new JLanguageTool ( language ) ; pr = makePatternRule ( "one" ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "A non-matching sentence." ) ) ; assertEquals ( 0 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "A matching sentence with one match." ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 25 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 28 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( - 1 , matches [ 0 ] . getColumn ( ) ) ; assertEquals ( - 1 , matches [ 0 ] . getLine ( ) ) ; assertEquals ( "ID1" , matches [ 0 ] . getRule ( ) . getId ( ) ) ; assertTrue ( matches [ 0 ] . getMessage ( ) . equals ( "user visible message" ) ) ; assertTrue ( matches [ 0 ] . getShortMessage ( ) . equals ( "short comment" ) ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "one one and one: three matches" ) ) ; assertEquals ( 3 , matches . length ) ; pr = makePatternRule ( "one two" ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "this is one not two" ) ) ; assertEquals ( 0 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "this is two one" ) ) ; assertEquals ( 0 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "this is one two three" ) ) ; assertEquals ( 1 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "one two" ) ) ; assertEquals ( 1 , matches . length ) ; pr = makePatternRule ( "one|foo|xxxx two" , false , true ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "one foo three" ) ) ; assertEquals ( 0 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "one two" ) ) ; assertEquals ( 1 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "foo two" ) ) ; assertEquals ( 1 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "one foo two" ) ) ; assertEquals ( 1 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "y x z one two blah foo" ) ) ; assertEquals ( 1 , matches . length ) ; pr = makePatternRule ( "one|foo|xxxx two|yyy" , false , true ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "one, yyy" ) ) ; assertEquals ( 0 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "one yyy" ) ) ; assertEquals ( 1 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "xxxx two" ) ) ; assertEquals ( 1 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "xxxx yyy" ) ) ; assertEquals ( 1 , matches . length ) ; } public void testSentenceStart ( ) throws IOException { JLanguageTool langTool = new JLanguageTool ( language ) ; final PatternRule pr = makePatternRule ( "SENT_START One" ) ; RuleMatch [ ] matches = pr . match ( langTool . getAnalyzedSentence ( "Not One word." ) ) ; assertEquals ( 0 , matches . length ) ; matches = pr . match ( langTool . getAnalyzedSentence ( "One word." ) ) ; assertEquals ( 1 , matches . length ) ; } public void testFormatMultipleSynthesis ( ) throws Exception { final String [ ] suggestions1 = { "blah blah" , "foo bar" } ; assertEquals ( "This is how you should write: <suggestion>blah blah</suggestion>, <suggestion>foo bar</suggestion>." , PatternRuleMatcher . formatMultipleSynthesis ( suggestions1 , "This is how you should write: <suggestion>" , "</suggestion>." ) ) ; final String [ ] suggestions2 = { "test" , " " } ; assertEquals ( "This is how you should write: <suggestion>test</suggestion>, <suggestion> </suggestion>." , PatternRuleMatcher . formatMultipleSynthesis ( suggestions2 , "This is how you should write: <suggestion>" , "</suggestion>." ) ) ; } private PatternRule makePatternRule ( final String s ) { return makePatternRule ( s , false , false ) ; } }
package org . languagetool . rules . patterns ; import junit . framework . TestCase ; import org . languagetool . language . Demo ; import java . io . IOException ; public class PatternRuleXmlCreatorTest extends TestCase { public void testToXML ( ) throws IOException { PatternRuleId ruleId = new PatternRuleId ( "DEMO_RULE" ) ; PatternRuleXmlCreator creator = new PatternRuleXmlCreator ( ) ; String xml = creator . toXML ( ruleId , new Demo ( ) ) ; assertEquals ( "<rule id=\"DEMO_RULE\" name=\"Find 'foo bar'\"><!-- a trivial demo rule that matches \"foo\" followed by \"bar\" -->\n" + " <pattern case_sensitive=\"no\">\n" + " <token>foo</token>\n" + " <token>bar</token>\n" + " </pattern>\n" + " <message>Did you mean <suggestion><match no=\"1\"/> fuu bah</suggestion>?</message>\n" + " <url>http://fake-server.org/foo-bar-error-explained</url>\n" + " <example>This is <marker>fuu bah</marker>.</example>\n" + " <example correction=\"foo fuu bah\">This is <marker>foo bar</marker>.</example>\n" + "</rule>" , xml ) ; } public void testToXMLWithRuleGroup ( ) { PatternRuleId ruleId = new PatternRuleId ( "test_spacebefore" ) ; PatternRuleXmlCreator creator = new PatternRuleXmlCreator ( ) ; String xml = creator . toXML ( ruleId , new Demo ( ) ) ; assertTrue ( xml . contains ( "<rulegroup id=\"test_spacebefore\"" ) ) ; assertTrue ( xml . contains ( "</rulegroup>" ) ) ; assertTrue ( xml . contains ( "<rule>" ) ) ; assertTrue ( xml . contains ( "<rule type=\"duplication\">" ) ) ; assertTrue ( xml . contains ( "<token>blah</token>" ) ) ; } public void testToXMLWithRuleGroupAndSubId1 ( ) { PatternRuleId ruleId = new PatternRuleId ( "test_spacebefore" , "1" ) ; PatternRuleXmlCreator creator = new PatternRuleXmlCreator ( ) ; String xml = creator . toXML ( ruleId , new Demo ( ) ) ; assertFalse ( xml . contains ( "<rulegroup" ) ) ; assertFalse ( xml . contains ( "</rulegroup>" ) ) ; assertTrue ( xml . contains ( "<message>This is a dummy message 1.</message>" ) ) ; } public void testToXMLWithRuleGroupAndSubId2 ( ) { PatternRuleId ruleId = new PatternRuleId ( "test_spacebefore" , "2" ) ; PatternRuleXmlCreator creator = new PatternRuleXmlCreator ( ) ; String xml = creator . toXML ( ruleId , new Demo ( ) ) ; assertFalse ( xml . contains ( "<rulegroup id=\"test_spacebefore\"" ) ) ; assertFalse ( xml . contains ( "</rulegroup>" ) ) ; assertTrue ( xml . contains ( "<message>This is a dummy message 2.</message>" ) ) ; } public void testToXMLWithAntiPattern ( ) { PatternRuleId ruleId = new PatternRuleId ( "DEMO_RULE_ANTIPATTERN" ) ; PatternRuleXmlCreator creator = new PatternRuleXmlCreator ( ) ; String xml = creator . toXML ( ruleId , new Demo ( ) ) ; assertTrue ( xml . contains ( " <antipattern>\n" + " <token>bar</token>\n" + " <token>,</token>\n" + " </antipattern>\n" ) ) ; } public void testToXMLInvalidRuleId ( ) { PatternRuleXmlCreator creator = new PatternRuleXmlCreator ( ) ; PatternRuleId fakeRuleId = new PatternRuleId ( "FAKE_ID" ) ; try { creator . toXML ( fakeRuleId , new Demo ( ) ) ; fail ( ) ; } catch ( RuntimeException ignored ) { } } }
package org . languagetool . rules . patterns ; import java . io . ByteArrayInputStream ; import java . io . FilePermission ; import java . security . * ; import java . util . * ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . chunking . ChunkTag ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . rules . Rule ; public class PatternRuleLoaderTest extends TestCase { public void testGetRules ( ) throws Exception { final PatternRuleLoader prg = new PatternRuleLoader ( ) ; final String name = "/xx/grammar.xml" ; final List < PatternRule > rules = prg . getRules ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( name ) , name ) ; assertTrue ( rules . size ( ) >= 30 ) ; final Rule demoRule1 = getRuleById ( "DEMO_RULE" , rules ) ; assertEquals ( "http://fake-server.org/foo-bar-error-explained" , demoRule1 . getUrl ( ) . toString ( ) ) ; assertEquals ( "[This is <marker>fuu bah</marker>.]" , demoRule1 . getCorrectExamples ( ) . toString ( ) ) ; final List < IncorrectExample > incorrectExamples = demoRule1 . getIncorrectExamples ( ) ; assertEquals ( 1 , incorrectExamples . size ( ) ) ; assertEquals ( "This is <marker>foo bar</marker>." , incorrectExamples . get ( 0 ) . getExample ( ) ) ; final Rule demoRule2 = getRuleById ( "API_OUTPUT_TEST_RULE" , rules ) ; assertNull ( demoRule2 . getUrl ( ) ) ; assertEquals ( ITSIssueType . Uncategorized , demoRule1 . getLocQualityIssueType ( ) ) ; assertEquals ( "tag inheritance failed" , ITSIssueType . Addition , getRuleById ( "TEST_GO" , rules ) . getLocQualityIssueType ( ) ) ; assertEquals ( "tag inheritance overwrite failed" , ITSIssueType . Uncategorized , getRuleById ( "TEST_PHRASES1" , rules ) . getLocQualityIssueType ( ) ) ; assertEquals ( "tag inheritance overwrite failed" , ITSIssueType . Characters , getRuleById ( "test_include" , rules ) . getLocQualityIssueType ( ) ) ; final List < Rule > groupRules1 = getRulesById ( "test_spacebefore" , rules ) ; assertEquals ( "tag inheritance form category failed" , ITSIssueType . Addition , groupRules1 . get ( 0 ) . getLocQualityIssueType ( ) ) ; assertEquals ( "tag inheritance overwrite failed" , ITSIssueType . Duplication , groupRules1 . get ( 1 ) . getLocQualityIssueType ( ) ) ; final List < Rule > groupRules2 = getRulesById ( "test_unification_with_negation" , rules ) ; assertEquals ( "tag inheritance from rulegroup failed" , ITSIssueType . Grammar , groupRules2 . get ( 0 ) . getLocQualityIssueType ( ) ) ; final Set < String > categories = getCategoryNames ( rules ) ; assertEquals ( 3 , categories . size ( ) ) ; assertTrue ( categories . contains ( "misc" ) ) ; assertTrue ( categories . contains ( "otherCategory" ) ) ; assertTrue ( categories . contains ( "Test tokens with min and max attributes" ) ) ; final PatternRule demoRuleWithChunk = ( PatternRule ) getRuleById ( "DEMO_CHUNK_RULE" , rules ) ; final List < PatternToken > patternTokens = demoRuleWithChunk . getPatternTokens ( ) ; assertEquals ( 2 , patternTokens . size ( ) ) ; assertEquals ( null , patternTokens . get ( 1 ) . getPOStag ( ) ) ; assertEquals ( new ChunkTag ( "B-NP-singular" ) , patternTokens . get ( 1 ) . getChunkTag ( ) ) ; final List < Rule > orRules = getRulesById ( "GROUP_WITH_URL" , rules ) ; assertEquals ( 3 , orRules . size ( ) ) ; assertEquals ( "http://fake-server.org/rule-group-url" , orRules . get ( 0 ) . getUrl ( ) . toString ( ) ) ; assertEquals ( "http://fake-server.org/rule-group-url-overwrite" , orRules . get ( 1 ) . getUrl ( ) . toString ( ) ) ; assertEquals ( "http://fake-server.org/rule-group-url" , orRules . get ( 2 ) . getUrl ( ) . toString ( ) ) ; assertEquals ( "short message on rule group" , ( ( PatternRule ) orRules . get ( 0 ) ) . getShortMessage ( ) ) ; assertEquals ( "overwriting short message" , ( ( PatternRule ) orRules . get ( 1 ) ) . getShortMessage ( ) ) ; assertEquals ( "short message on rule group" , ( ( PatternRule ) orRules . get ( 2 ) ) . getShortMessage ( ) ) ; final List < Rule > orRules2 = getRulesById ( "OR_GROUPS" , rules ) ; for ( Rule rule : orRules2 ) { assertNull ( "http://fake-server.org/rule-group-url" , rule . getUrl ( ) ) ; } final Rule nextRule = getRuleById ( "DEMO_CHUNK_RULE" , rules ) ; assertNull ( "http://fake-server.org/rule-group-url" , nextRule . getUrl ( ) ) ; } public void testPermissionManager ( ) throws Exception { Policy . setPolicy ( new MyPolicy ( ) ) ; System . setSecurityManager ( new SecurityManager ( ) ) ; try { PatternRuleLoader loader = new PatternRuleLoader ( ) ; loader . getRules ( new ByteArrayInputStream ( "<rules lang='xx'></rules>" . getBytes ( "utf-8" ) ) , "fakeName" ) ; } finally { System . setSecurityManager ( null ) ; } } private Set < String > getCategoryNames ( List < PatternRule > rules ) { final Set < String > categories = new HashSet < > ( ) ; for ( PatternRule rule : rules ) { categories . add ( rule . getCategory ( ) . getName ( ) ) ; } return categories ; } private Rule getRuleById ( String id , List < PatternRule > rules ) { for ( Rule rule : rules ) { if ( rule . getId ( ) . equals ( id ) ) { return rule ; } } throw new RuntimeException ( "No rule found for id '" + id + "'" ) ; } private List < Rule > getRulesById ( String id , List < PatternRule > rules ) { final List < Rule > result = new ArrayList < > ( ) ; for ( Rule rule : rules ) { if ( rule . getId ( ) . equals ( id ) ) { result . add ( rule ) ; } } return result ; } static class MyPolicy extends Policy { @ Override public PermissionCollection getPermissions ( CodeSource codesource ) { PermissionCollection perms = new MyPermissionCollection ( ) ; perms . add ( new RuntimePermission ( "setIO" ) ) ; perms . add ( new RuntimePermission ( "setSecurityManager" ) ) ; perms . add ( new FilePermission ( "<<ALL FILES>>" , "read" ) ) ; return perms ; } } static class MyPermissionCollection extends PermissionCollection { private final List < Permission > perms = new ArrayList < > ( ) ; @ Override public void add ( Permission p ) { perms . add ( p ) ; } @ Override public boolean implies ( Permission p ) { for ( Permission perm : perms ) { if ( perm . implies ( p ) ) { return true ; } } return false ; } @ Override public Enumeration < Permission > elements ( ) { return Collections . enumeration ( perms ) ; } @ Override public boolean isReadOnly ( ) { return false ; } } }
package org . languagetool . rules . patterns ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . HashSet ; import java . util . List ; import java . util . Set ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . Language ; public final class PatternTestTools { private static final Pattern TOKEN_SEPARATOR_PATTERN = Pattern . compile ( "[ .,:;…!?(){}<>«»\"]" ) ; private static final Pattern PROBABLE_PATTERN = Pattern . compile ( ".*([^*]\\*|[.+?{}()|\\[\\]].*|\\\\d).*" ) ; private static final Pattern PROBABLE_PATTERN_PL_POS = Pattern . compile ( ".*([^*]\\*|[+?{}()|\\[\\]].*|\\\\d).*" ) ; private static final Pattern CHAR_SET_PATTERN = Pattern . compile ( "(\\(\\?-i\\))?.*(?<!\\\\)\\[^?([^\\]]+)\\]" ) ; private PatternTestTools ( ) { } public static void warnIfRegexpSyntaxNotKosher ( final List < PatternToken > patternTokens , final String ruleId , final String ruleSubId , final Language lang ) { int i = 0 ; for ( final PatternToken pToken : patternTokens ) { i ++ ; if ( pToken . isReferenceElement ( ) ) { continue ; } warnIfElementNotKosher ( pToken . getString ( ) , pToken . isRegularExpression ( ) , pToken . isCaseSensitive ( ) , pToken . getNegation ( ) , pToken . isInflected ( ) , false , lang , ruleId + "[" + ruleSubId + "]" , i ) ; warnIfElementNotKosher ( pToken . getPOStag ( ) == null ? "" : pToken . getPOStag ( ) , pToken . isPOStagRegularExpression ( ) , pToken . isCaseSensitive ( ) , pToken . getPOSNegation ( ) , false , true , lang , ruleId + "[" + ruleSubId + "] (POS tag)" , i ) ; final List < PatternToken > exceptionPatternTokens = new ArrayList < > ( ) ; if ( pToken . getExceptionList ( ) != null ) { for ( final PatternToken exception : pToken . getExceptionList ( ) ) { if ( exception . hasNextException ( ) && pToken . getSkipNext ( ) == 0 ) { System . err . println ( "The " + lang + " rule: " + ruleId + "[" + ruleSubId + "]" + " (exception in token [" + i + "])" + " has no skip=\"...\" and yet contains scope=\"next\"" + " so the exception never applies. " + " Did you forget skip=\"...\"?" ) ; } if ( ! pToken . getString ( ) . isEmpty ( ) && ! exception . getString ( ) . isEmpty ( ) && ! pToken . getNegation ( ) && ! pToken . isInflected ( ) && ! exception . getNegation ( ) && ! exception . isInflected ( ) && pToken . getSkipNext ( ) == 0 && pToken . isCaseSensitive ( ) == exception . isCaseSensitive ( ) ) { if ( exception . isRegularExpression ( ) ) { if ( pToken . isRegularExpression ( ) ) { if ( exception . getString ( ) . indexOf ( '|' ) >= 0 ) { final String [ ] alt = exception . getString ( ) . split ( "\\|" ) ; for ( final String part : alt ) { if ( exception . getString ( ) . indexOf ( '(' ) >= 0 ) { break ; } if ( part . matches ( "[^.*?{}\\[\\]]+" ) ) { if ( ! part . matches ( "(?i)" + pToken . getString ( ) ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + "[" + ruleSubId + "]" + " has exception regexp [" + exception . getString ( ) + "] which contains disjunction part [" + part + "] which seems useless since it does not match " + "the regexp of token word [" + i + "] " + "[" + pToken . getString ( ) + "], or did you forget skip=\"...\" or scope=\"previous\"?" ) ; } } } } } else { System . err . println ( "The " + lang + " rule: " + ruleId + "[" + ruleSubId + "]" + " has exception regexp [" + exception . getString ( ) + "] in token word [" + i + "] [" + pToken . getString ( ) + "] which seems useless, or " + "did you forget skip=\"...\" or scope=\"previous\"?" ) ; } } else { if ( pToken . isRegularExpression ( ) ) { if ( ! exception . getString ( ) . matches ( ( exception . isCaseSensitive ( ) ? "" : "(?i)" ) + pToken . getString ( ) ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + "[" + ruleSubId + "] has exception word [" + exception . getString ( ) + "] which cannot match the" + "regexp token [" + i + "] [" + pToken . getString ( ) + "] so exception seems useless, " + "or did you forget skip=\"...\" or scope=\"previous\"?" ) ; } } else { System . err . println ( "The " + lang + " rule: " + ruleId + "[" + ruleSubId + "] has exception word [" + exception . getString ( ) + "] in token word [" + i + "] [" + pToken . getString ( ) + "] which seems useless, " + "or did you forget skip=\"...\" or scope=\"previous\"?" ) ; } } } if ( ! exception . getString ( ) . equals ( "." ) ) { warnIfElementNotKosher ( exception . getString ( ) , exception . isRegularExpression ( ) , exception . isCaseSensitive ( ) , exception . getNegation ( ) , exception . isInflected ( ) , false , lang , ruleId + "[" + ruleSubId + "] (exception in token [" + i + "])" , i ) ; } warnIfElementNotKosher ( exception . getPOStag ( ) == null ? "" : exception . getPOStag ( ) , exception . isPOStagRegularExpression ( ) , exception . isCaseSensitive ( ) , exception . getPOSNegation ( ) , false , true , lang , ruleId + "[" + ruleSubId + "] (exception in POS tag of token [" + i + "])" , i ) ; for ( final PatternToken otherException : exceptionPatternTokens ) { if ( equalException ( exception , otherException ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + "[" + ruleSubId + "]" + " in token [" + i + "]" + " contains duplicate exceptions with" + " string=[" + exception . getString ( ) + "]" + " POS tag=[" + exception . getPOStag ( ) + "]" + " negate=[" + exception . getNegation ( ) + "]" + " POS negate=[" + exception . getPOSNegation ( ) + "]" ) ; break ; } } exceptionPatternTokens . add ( exception ) ; } } } } private static boolean equalException ( final PatternToken exception1 , final PatternToken exception2 ) { String string1 = exception1 . getString ( ) == null ? "" : exception1 . getString ( ) ; String string2 = exception2 . getString ( ) == null ? "" : exception2 . getString ( ) ; if ( ! exception1 . isCaseSensitive ( ) || ! exception2 . isCaseSensitive ( ) ) { string1 = string1 . toLowerCase ( ) ; string2 = string2 . toLowerCase ( ) ; } if ( ! string1 . isEmpty ( ) && ! string2 . isEmpty ( ) ) { if ( ! string1 . equals ( string2 ) ) { return false ; } } final String posTag1 = exception1 . getPOStag ( ) == null ? "" : exception1 . getPOStag ( ) ; final String posTag2 = exception2 . getPOStag ( ) == null ? "" : exception2 . getPOStag ( ) ; if ( ! posTag1 . isEmpty ( ) && ! posTag2 . isEmpty ( ) ) { if ( ! posTag1 . equals ( posTag2 ) ) { return false ; } } if ( string1 . isEmpty ( ) != string2 . isEmpty ( ) && posTag1 . isEmpty ( ) != posTag2 . isEmpty ( ) ) { return false ; } return exception1 . getNegation ( ) == exception2 . getNegation ( ) && exception1 . getPOSNegation ( ) == exception2 . getPOSNegation ( ) && exception1 . hasNextException ( ) == exception2 . hasNextException ( ) && exception1 . hasPreviousException ( ) == exception2 . hasPreviousException ( ) ; } private static void warnIfElementNotKosher ( final String stringValue , final boolean isRegularExpression , final boolean isCaseSensitive , final boolean isNegated , final boolean isInflected , final boolean isPos , final Language lang , final String ruleId , final int tokenIndex ) { if ( ! isPos && ! isRegularExpression && stringValue . length ( ) > 1 ) { if ( TOKEN_SEPARATOR_PATTERN . matcher ( stringValue ) . find ( ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains " + "\"" + stringValue + "\" that contains token separators, so can't possibly be matched." ) ; } } final Pattern regexPattern = ( isPos && lang . getShortName ( ) . equals ( "pl" ) ) ? PROBABLE_PATTERN_PL_POS : PROBABLE_PATTERN ; if ( ! isRegularExpression && stringValue . length ( ) > 1 && regexPattern . matcher ( stringValue ) . find ( ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains " + "\"" + stringValue + "\" that is not marked as regular expression but probably is one." ) ; } if ( isRegularExpression && stringValue . isEmpty ( ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains an empty string " + "\"" + stringValue + "\" that is marked as regular expression." ) ; } else if ( isRegularExpression && stringValue . length ( ) > 1 && ! regexPattern . matcher ( stringValue ) . find ( ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains " + "\"" + stringValue + "\" that is marked as regular expression but probably is not one." ) ; } if ( isNegated && stringValue . isEmpty ( ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], marked as negated but is " + "empty so the negation is useless. Did you mix up " + "negate=\"yes\" and negate_pos=\"yes\"?" ) ; } if ( isInflected && stringValue . isEmpty ( ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains " + "\"" + stringValue + "\" that is marked as inflected but is empty, so the attribute is redundant." ) ; } if ( isRegularExpression && ".*" . equals ( stringValue ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], marked as regular expression contains " + "regular expression \".*\" which is useless: " + "(use an empty string without regexp=\"yes\" such as <token/>)" ) ; } if ( isRegularExpression ) { final Matcher matcher = CHAR_SET_PATTERN . matcher ( stringValue ) ; if ( matcher . find ( ) ) { final String s = matcher . group ( 2 ) . replaceAll ( "\\\\p\\{[^}]*\\}" , "" ) ; if ( s . indexOf ( '|' ) >= 0 ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains | (pipe) in " + " regexp bracket expression [" + matcher . group ( 2 ) + "] which is unlikely to be correct." ) ; } final char [ ] sorted = s . toCharArray ( ) ; Arrays . sort ( sorted ) ; for ( int i = 1 ; i < sorted . length ; ++ i ) { final char c = sorted [ i ] ; if ( "&\\-|" . indexOf ( c ) < 0 && sorted [ i - 1 ] == c ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains " + " regexp part [" + matcher . group ( 2 ) + "] which contains duplicated char [" + c + "]." ) ; break ; } } } if ( stringValue . contains ( "|" ) ) { if ( stringValue . contains ( "||" ) || stringValue . charAt ( 0 ) == '|' || stringValue . charAt ( stringValue . length ( ) - 1 ) == '|' ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains empty " + "disjunction | within " + "\"" + stringValue + "\"." ) ; } final String [ ] groups = stringValue . split ( "\\)" ) ; for ( final String group : groups ) { final String [ ] alt = group . split ( "\\|" ) ; final Set < String > partSet = new HashSet < > ( ) ; final Set < String > partSetNoCase = new HashSet < > ( ) ; boolean hasSingleChar = false ; boolean hasSingleDot = false ; for ( String part : alt ) { if ( part . length ( ) == 1 ) { if ( part . equals ( "." ) ) { hasSingleDot = true ; } else { hasSingleChar = true ; } } final String partNoCase = isCaseSensitive ? part : part . toLowerCase ( ) ; if ( partSetNoCase . contains ( partNoCase ) ) { if ( partSet . contains ( part ) ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains " + "duplicated disjunction part (" + part + ") within " + "\"" + stringValue + "\"." ) ; } else { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains duplicated " + "non case sensitive disjunction part (" + part + ") within " + "\"" + stringValue + "\". Did you " + "forget case_sensitive=\"yes\"?" ) ; } } partSetNoCase . add ( partNoCase ) ; partSet . add ( part ) ; } if ( hasSingleDot && hasSingleChar ) { System . err . println ( "The " + lang + " rule: " + ruleId + ", token [" + tokenIndex + "], contains a single dot (matching any char) " + "so other single char disjunction are useless within " + "\"" + stringValue + "\". Did you forget forget a backslash before the dot?" ) ; } } } } } }
package org . languagetool . rules . bitext ; import java . io . IOException ; import java . io . InputStream ; import java . util . List ; import java . util . Set ; import junit . framework . TestCase ; import org . languagetool . * ; import org . languagetool . bitext . StringPair ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . rules . patterns . bitext . BitextPatternRule ; import org . languagetool . rules . patterns . bitext . BitextPatternRuleLoader ; public class BitextPatternRuleTest extends TestCase { public void testBitextRulesFromXML ( ) throws IOException { testBitextRulesFromXML ( null ) ; } private void testBitextRulesFromXML ( final Set < Language > ignoredLanguages ) throws IOException { for ( final Language lang : Languages . getWithDemoLanguage ( ) ) { if ( ignoredLanguages != null && ignoredLanguages . contains ( lang ) ) { continue ; } final BitextPatternRuleLoader ruleLoader = new BitextPatternRuleLoader ( ) ; final String name = "/" + lang . getShortName ( ) + "/bitext.xml" ; final InputStream is ; try { is = JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( name ) ; } catch ( RuntimeException ignored ) { continue ; } System . out . println ( "Running tests for " + lang . getName ( ) + "..." ) ; final JLanguageTool languageTool = new JLanguageTool ( lang ) ; final List < BitextPatternRule > rules = ruleLoader . getRules ( is , name ) ; testBitextRulesFromXML ( rules , languageTool , lang ) ; } } private void testBitextRulesFromXML ( final List < BitextPatternRule > rules , final JLanguageTool languageTool , final Language lang ) throws IOException { for ( final BitextPatternRule rule : rules ) { testBitextRule ( rule , lang , languageTool ) ; } } private String cleanSentence ( String str ) { return cleanXML ( str . replaceAll ( "[\\n\\t]+" , "" ) ) ; } private void testMarker ( int expectedMatchStart , int expectedMatchEnd , Rule rule , Language lang ) { if ( expectedMatchStart == - 1 || expectedMatchEnd == - 1 ) { fail ( lang + ": No error position markup ('<marker>...</marker>') in bad example in rule " + rule ) ; } } private void testBadSentence ( final String origBadSentence , final List < String > suggestedCorrection , final int expectedMatchStart , final int expectedMatchEnd , final PatternRule rule , final Language lang , final JLanguageTool languageTool ) throws IOException { final String badSentence = cleanXML ( origBadSentence ) ; assertTrue ( badSentence . trim ( ) . length ( ) > 0 ) ; RuleMatch [ ] matches = getMatches ( rule , badSentence , languageTool ) ; assertTrue ( lang + ": Did expect one error in: \"" + badSentence + "\" (Rule: " + rule + "), got " + matches . length + ". Additional info:" + rule . getMessage ( ) , matches . length == 1 ) ; assertEquals ( lang + ": Incorrect match position markup (start) for rule " + rule , expectedMatchStart , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( lang + ": Incorrect match position markup (end) for rule " + rule , expectedMatchEnd , matches [ 0 ] . getToPos ( ) ) ; if ( suggestedCorrection != null && suggestedCorrection . size ( ) > 0 ) { assertTrue ( "You specified a correction but your message has no suggestions in rule " + rule , rule . getMessage ( ) . contains ( "<suggestion>" ) ) ; assertTrue ( lang + ": Incorrect suggestions: " + suggestedCorrection + " != " + matches [ 0 ] . getSuggestedReplacements ( ) + " for rule " + rule , suggestedCorrection . equals ( matches [ 0 ] . getSuggestedReplacements ( ) ) ) ; if ( matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) > 0 ) { final int fromPos = matches [ 0 ] . getFromPos ( ) ; final int toPos = matches [ 0 ] . getToPos ( ) ; for ( final String repl : matches [ 0 ] . getSuggestedReplacements ( ) ) { final String fixedSentence = badSentence . substring ( 0 , fromPos ) + repl + badSentence . substring ( toPos ) ; matches = getMatches ( rule , fixedSentence , languageTool ) ; if ( matches . length > 0 ) { fail ( "Incorrect input:\n" + " " + badSentence + "\nCorrected sentence:\n" + " " + fixedSentence + "\nBy Rule:\n" + " " + rule + "\nThe correction triggered an error itself:\n" + " " + matches [ 0 ] + "\n" ) ; } } } } } private void testBitextRule ( final BitextPatternRule rule , final Language lang , final JLanguageTool languageTool ) throws IOException { final JLanguageTool srcTool = new JLanguageTool ( rule . getSourceLanguage ( ) ) ; final List < StringPair > goodSentences = rule . getCorrectBitextExamples ( ) ; for ( StringPair goodSentence : goodSentences ) { assertTrue ( cleanSentence ( goodSentence . getSource ( ) ) . trim ( ) . length ( ) > 0 ) ; assertTrue ( cleanSentence ( goodSentence . getTarget ( ) ) . trim ( ) . length ( ) > 0 ) ; assertFalse ( lang + ": Did not expect error in: " + goodSentence + " (Rule: " + rule + ")" , match ( rule , goodSentence . getSource ( ) , goodSentence . getTarget ( ) , srcTool , languageTool ) ) ; } final List < IncorrectBitextExample > badSentences = rule . getIncorrectBitextExamples ( ) ; for ( IncorrectBitextExample origBadExample : badSentences ) { final String origBadSrcSentence = origBadExample . getExample ( ) . getSource ( ) . replaceAll ( "[\\n\\t]+" , "" ) ; final String origBadTrgSentence = origBadExample . getExample ( ) . getTarget ( ) . replaceAll ( "[\\n\\t]+" , "" ) ; final List < String > suggestedCorrection = origBadExample . getCorrections ( ) ; final int expectedSrcMatchStart = origBadSrcSentence . indexOf ( "<marker>" ) ; final int expectedSrcMatchEnd = origBadSrcSentence . indexOf ( "</marker>" ) - "<marker>" . length ( ) ; testMarker ( expectedSrcMatchStart , expectedSrcMatchEnd , rule , lang ) ; final int expectedTrgMatchStart = origBadTrgSentence . indexOf ( "<marker>" ) ; final int expectedTrgMatchEnd = origBadTrgSentence . indexOf ( "</marker>" ) - "<marker>" . length ( ) ; testMarker ( expectedTrgMatchStart , expectedTrgMatchEnd , rule , lang ) ; testBadSentence ( origBadSrcSentence , suggestedCorrection , expectedSrcMatchStart , expectedSrcMatchEnd , rule . getSrcRule ( ) , lang , srcTool ) ; testBadSentence ( origBadTrgSentence , suggestedCorrection , expectedTrgMatchStart , expectedTrgMatchEnd , rule . getTrgRule ( ) , lang , languageTool ) ; } } private String cleanXML ( final String str ) { return str . replaceAll ( "<([^<].*?)>" , "" ) ; } private boolean match ( final BitextPatternRule rule , final String src , final String trg , final JLanguageTool srcLanguageTool , final JLanguageTool trgLanguageTool ) throws IOException { final AnalyzedSentence srcText = srcLanguageTool . getAnalyzedSentence ( src ) ; final AnalyzedSentence trgText = trgLanguageTool . getAnalyzedSentence ( trg ) ; final RuleMatch [ ] matches = rule . match ( srcText , trgText ) ; return matches . length > 0 ; } private RuleMatch [ ] getMatches ( final Rule rule , final String sentence , final JLanguageTool languageTool ) throws IOException { final AnalyzedSentence analyzedSentence = languageTool . getAnalyzedSentence ( sentence ) ; final RuleMatch [ ] matches = rule . match ( analyzedSentence ) ; return matches ; } public static void main ( final String [ ] args ) throws IOException { final BitextPatternRuleTest prt = new BitextPatternRuleTest ( ) ; System . out . println ( "Running XML bitext pattern tests..." ) ; if ( args . length == 0 ) { prt . testBitextRulesFromXML ( null ) ; } else { final Set < Language > ignoredLanguages = TestTools . getLanguagesExcept ( args ) ; prt . testBitextRulesFromXML ( ignoredLanguages ) ; } System . out . println ( "Tests successful." ) ; } }
package org . languagetool . rules . nl ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Dutch ; import java . io . IOException ; import static org . junit . Assert . assertEquals ; public class MorfologikDutchSpellerRuleTest { @ Test public void testSpeller ( ) throws IOException { Dutch language = new Dutch ( ) ; MorfologikDutchSpellerRule rule = new MorfologikDutchSpellerRule ( TestTools . getEnglishMessages ( ) , language ) ; JLanguageTool langTool = new JLanguageTool ( language ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Amsterdam" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "ipv" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "voorzover" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "FoobarWrongxx" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "foobarwrong" ) ) . length ) ; } }
package org . languagetool . rules . bitext ; import junit . framework . TestCase ; import org . languagetool . FakeLanguage ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class DifferentPunctuationRuleTest extends TestCase { public void testRule ( ) throws IOException { final DifferentPunctuationRule rule = new DifferentPunctuationRule ( ) ; RuleMatch [ ] matches ; final JLanguageTool srcLangTool = new JLanguageTool ( TestTools . getDemoLanguage ( ) ) ; final JLanguageTool trgLangTool = new JLanguageTool ( new FakeLanguage ( ) ) ; rule . setSourceLanguage ( TestTools . getDemoLanguage ( ) ) ; matches = rule . match ( srcLangTool . getAnalyzedSentence ( "This is a test sentence!" ) , trgLangTool . getAnalyzedSentence ( "C'est la vie!" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( srcLangTool . getAnalyzedSentence ( "one sentence" ) , trgLangTool . getAnalyzedSentence ( "jedno zdanie" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( srcLangTool . getAnalyzedSentence ( "This this is a test sentence." ) , trgLangTool . getAnalyzedSentence ( "This this is a test sentence!" ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . rules . bitext ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . FakeLanguage ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . rules . RuleMatch ; public class SameTranslationRuleTest extends TestCase { public void testRule ( ) throws IOException { final SameTranslationRule rule = new SameTranslationRule ( ) ; RuleMatch [ ] matches ; final JLanguageTool srcLangTool = new JLanguageTool ( TestTools . getDemoLanguage ( ) ) ; final JLanguageTool trgLangTool = new JLanguageTool ( new FakeLanguage ( ) ) ; rule . setSourceLanguage ( TestTools . getDemoLanguage ( ) ) ; matches = rule . match ( srcLangTool . getAnalyzedSentence ( "This is a test sentence." ) , trgLangTool . getAnalyzedSentence ( "C'est la vie !" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( srcLangTool . getAnalyzedSentence ( "Elvis Presley" ) , trgLangTool . getAnalyzedSentence ( "Elvis Presley" ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( srcLangTool . getAnalyzedSentence ( "This this is a test sentence." ) , trgLangTool . getAnalyzedSentence ( "This this is a test sentence." ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . rules . bitext ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . FakeLanguage ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . rules . RuleMatch ; public class DifferentLengthRuleTest extends TestCase { public void testRule ( ) throws IOException { final DifferentLengthRule rule = new DifferentLengthRule ( ) ; RuleMatch [ ] matches ; final JLanguageTool trgLangTool = new JLanguageTool ( TestTools . getDemoLanguage ( ) ) ; final JLanguageTool srcLangTool = new JLanguageTool ( new FakeLanguage ( ) ) ; rule . setSourceLanguage ( TestTools . getDemoLanguage ( ) ) ; matches = rule . match ( srcLangTool . getAnalyzedSentence ( "This is a test sentence." ) , trgLangTool . getAnalyzedSentence ( "To zdanie testowe." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( srcLangTool . getAnalyzedSentence ( "Click this button." ) , trgLangTool . getAnalyzedSentence ( "Kliknij ten przycisk." ) ) ; assertEquals ( 0 , matches . length ) ; matches = rule . match ( srcLangTool . getAnalyzedSentence ( "Open a file, and check if it is corrupt." ) , trgLangTool . getAnalyzedSentence ( "Otwórz plik." ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . rules . spelling ; import junit . framework . TestCase ; import java . io . IOException ; public class SuggestionExtractorTest extends TestCase { public void testGetSuggestions ( ) throws IOException { final SuggestionExtractor extractor = new SuggestionExtractor ( ) ; assertEquals ( "[]" , extractor . getSimpleSuggestions ( "Did you mean foo?" ) . toString ( ) ) ; assertEquals ( "[foo bla]" , extractor . getSimpleSuggestions ( "Did you mean <suggestion>foo bla</suggestion>?" ) . toString ( ) ) ; assertEquals ( "[foo bla, xxx]" , extractor . getSimpleSuggestions ( "Did you mean <suggestion>foo bla</suggestion> or <suggestion>xxx</suggestion>?" ) . toString ( ) ) ; assertEquals ( "[foo bla, xxx]" , extractor . getSimpleSuggestions ( "Did you mean <suggestion suppress_misspelled=\"yes\">foo bla</suggestion>" + " or <suggestion>xxx</suggestion>?" ) . toString ( ) ) ; assertEquals ( "[]" , extractor . getSimpleSuggestions ( "Did you mean <suggestion>foo \\1</suggestion>?" ) . toString ( ) ) ; assertEquals ( "[]" , extractor . getSimpleSuggestions ( "Did you mean <suggestion>‚<match no=\"3\" include_skipped=\"following\"/></suggestion>?" ) . toString ( ) ) ; } }
package org . languagetool . rules . spelling . morfologik ; import org . junit . Test ; import java . io . IOException ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . * ; public class MorfologikMultiSpellerTest { @ Test public void testIsMisspelled ( ) throws IOException { MorfologikMultiSpeller speller = getSpeller ( ) ; assertFalse ( speller . isMisspelled ( "wordone" ) ) ; assertFalse ( speller . isMisspelled ( "wordtwo" ) ) ; assertFalse ( speller . isMisspelled ( "Abc" ) ) ; assertFalse ( speller . isMisspelled ( "wordthree" ) ) ; assertFalse ( speller . isMisspelled ( "wordfour" ) ) ; assertFalse ( speller . isMisspelled ( "üblich" ) ) ; assertFalse ( speller . isMisspelled ( "schön" ) ) ; assertFalse ( speller . isMisspelled ( "Fön" ) ) ; assertFalse ( speller . isMisspelled ( "Fün" ) ) ; assertFalse ( speller . isMisspelled ( "Fän" ) ) ; assertFalse ( speller . isMisspelled ( "Häuser" ) ) ; assertTrue ( speller . isMisspelled ( "notthere" ) ) ; assertTrue ( speller . isMisspelled ( "Fun" ) ) ; assertTrue ( speller . isMisspelled ( "Füns" ) ) ; assertTrue ( speller . isMisspelled ( "AFün" ) ) ; } @ Test public void testGetSuggestions ( ) throws IOException { MorfologikMultiSpeller speller = getSpeller ( ) ; assertThat ( speller . getSuggestions ( "wordone" ) . toString ( ) , is ( "[]" ) ) ; assertThat ( speller . getSuggestions ( "wordones" ) . toString ( ) , is ( "[wordone]" ) ) ; assertThat ( speller . getSuggestions ( "Abd" ) . toString ( ) , is ( "[Abc]" ) ) ; assertThat ( speller . getSuggestions ( "Fxn" ) . toString ( ) , is ( "[Fän, Fön, Fün]" ) ) ; assertThat ( speller . getSuggestions ( "Häusers" ) . toString ( ) , is ( "[Häuser]" ) ) ; } @ Test ( expected = RuntimeException . class ) public void testInvalidFileName ( ) throws IOException { new MorfologikMultiSpeller ( "/xx/spelling/test.dict.README" , "/xx/spelling/test2.txt" , 1 ) ; } @ Test ( expected = RuntimeException . class ) public void testInvalidFile ( ) throws IOException { new MorfologikMultiSpeller ( "/xx/spelling/no-such-file" , "/xx/spelling/test2.txt" , 1 ) ; } private MorfologikMultiSpeller getSpeller ( ) throws IOException { return new MorfologikMultiSpeller ( "/xx/spelling/test.dict" , "/xx/spelling/test2.txt" , 1 ) ; } }
package org . languagetool . rules . spelling . morfologik ; import org . junit . Test ; import java . io . IOException ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . * ; public class MorfologikSpellerTest { @ Test public void testIsMisspelled ( ) throws IOException { MorfologikSpeller speller = new MorfologikSpeller ( "/xx/spelling/test.dict" ) ; assertTrue ( speller . convertsCase ( ) ) ; assertFalse ( speller . isMisspelled ( "wordone" ) ) ; assertFalse ( speller . isMisspelled ( "Wordone" ) ) ; assertFalse ( speller . isMisspelled ( "wordtwo" ) ) ; assertFalse ( speller . isMisspelled ( "Wordtwo" ) ) ; assertFalse ( speller . isMisspelled ( "Uppercase" ) ) ; assertFalse ( speller . isMisspelled ( "Häuser" ) ) ; assertTrue ( speller . isMisspelled ( "Hauser" ) ) ; assertTrue ( speller . isMisspelled ( "wordones" ) ) ; assertTrue ( speller . isMisspelled ( "nosuchword" ) ) ; } @ Test public void testGetSuggestions ( ) throws IOException { MorfologikSpeller spellerDist1 = new MorfologikSpeller ( "/xx/spelling/test.dict" , 1 ) ; MorfologikSpeller spellerDist2 = new MorfologikSpeller ( "/xx/spelling/test.dict" , 2 ) ; assertThat ( spellerDist1 . getSuggestions ( "wordone" ) . toString ( ) , is ( "[]" ) ) ; assertThat ( spellerDist1 . getSuggestions ( "wordonex" ) . toString ( ) , is ( "[wordone]" ) ) ; assertThat ( spellerDist2 . getSuggestions ( "wordone" ) . toString ( ) , is ( "[]" ) ) ; assertThat ( spellerDist2 . getSuggestions ( "wordonex" ) . toString ( ) , is ( "[wordone]" ) ) ; assertThat ( spellerDist1 . getSuggestions ( "wordonix" ) . toString ( ) , is ( "[]" ) ) ; assertThat ( spellerDist2 . getSuggestions ( "wordonix" ) . toString ( ) , is ( "[wordone]" ) ) ; assertThat ( spellerDist2 . getSuggestions ( "wordoxix" ) . toString ( ) , is ( "[]" ) ) ; } }
package org . languagetool . tagging ; import org . junit . Test ; import java . net . URL ; import java . util . List ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . * ; public class MorfologikTaggerTest { @ Test public void testTag ( ) { URL url = MorfologikTaggerTest . class . getResource ( "/org/languagetool/tagging/test.dict" ) ; MorfologikTagger tagger = new MorfologikTagger ( url ) ; List < TaggedWord > result1 = tagger . tag ( "lowercase" ) ; assertThat ( result1 . size ( ) , is ( 2 ) ) ; assertThat ( result1 . get ( 0 ) . getLemma ( ) , is ( "lclemma" ) ) ; assertThat ( result1 . get ( 0 ) . getPosTag ( ) , is ( "POS1" ) ) ; assertThat ( result1 . get ( 1 ) . getLemma ( ) , is ( "lclemma2" ) ) ; assertThat ( result1 . get ( 1 ) . getPosTag ( ) , is ( "POS1a" ) ) ; List < TaggedWord > result2 = tagger . tag ( "Lowercase" ) ; assertThat ( result2 . size ( ) , is ( 0 ) ) ; List < TaggedWord > result3 = tagger . tag ( "schön" ) ; assertThat ( result3 . size ( ) , is ( 1 ) ) ; assertThat ( result3 . get ( 0 ) . getLemma ( ) , is ( "testlemma" ) ) ; assertThat ( result3 . get ( 0 ) . getPosTag ( ) , is ( "POSTEST" ) ) ; List < TaggedWord > noResult = tagger . tag ( "noSuchWord" ) ; assertThat ( noResult . size ( ) , is ( 0 ) ) ; } }
package org . languagetool . tagging ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import java . io . IOException ; import java . util . List ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; import static org . junit . Assert . assertTrue ; public class CombiningTaggerTest { @ Test public void testTagNoOverwrite ( ) throws Exception { CombiningTagger tagger = getCombiningTagger ( false ) ; assertThat ( tagger . tag ( "nosuchword" ) . size ( ) , is ( 0 ) ) ; List < TaggedWord > result = tagger . tag ( "fullform" ) ; assertThat ( result . size ( ) , is ( 2 ) ) ; String asString = getAsString ( result ) ; assertTrue ( asString . contains ( "baseform1/POSTAG1" ) ) ; assertTrue ( asString . contains ( "baseform2/POSTAG2" ) ) ; } @ Test public void testTagOverwrite ( ) throws Exception { CombiningTagger tagger = getCombiningTagger ( true ) ; assertThat ( tagger . tag ( "nosuchword" ) . size ( ) , is ( 0 ) ) ; List < TaggedWord > result = tagger . tag ( "fullform" ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; String asString = getAsString ( result ) ; assertTrue ( asString . contains ( "baseform2/POSTAG2" ) ) ; } private CombiningTagger getCombiningTagger ( boolean overwrite ) throws IOException { ManualTagger tagger1 = new ManualTagger ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( "/xx/added1.txt" ) ) ; ManualTagger tagger2 = new ManualTagger ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( "/xx/added2.txt" ) ) ; return new CombiningTagger ( tagger1 , tagger2 , overwrite ) ; } private String getAsString ( List < TaggedWord > result ) { StringBuilder sb = new StringBuilder ( ) ; for ( TaggedWord taggedWord : result ) { sb . append ( taggedWord . getLemma ( ) ) ; sb . append ( "/" ) ; sb . append ( taggedWord . getPosTag ( ) ) ; sb . append ( "\n" ) ; } return sb . toString ( ) ; } @ Test ( expected = IOException . class ) public void testInvalidFile ( ) throws Exception { new ManualTagger ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( "/xx/added-invalid.txt" ) ) ; } }
package org . languagetool . tagging . disambiguation . rules ; import java . io . IOException ; import java . io . InputStream ; import java . util . Arrays ; import java . util . List ; import java . util . Set ; import javax . xml . parsers . ParserConfigurationException ; import junit . framework . TestCase ; import org . languagetool . * ; import org . languagetool . rules . patterns . PatternTestTools ; import org . languagetool . tagging . disambiguation . xx . DemoDisambiguator ; import org . languagetool . tools . StringTools ; import org . xml . sax . SAXException ; public class DisambiguationRuleTest extends TestCase { public void testDisambiguationRulesFromXML ( ) throws Exception { testDisambiguationRulesFromXML ( null ) ; } private void testDisambiguationRulesFromXML ( final Set < Language > ignoredLanguages ) throws IOException , ParserConfigurationException , SAXException { for ( final Language lang : Languages . get ( ) ) { if ( ignoredLanguages != null && ignoredLanguages . contains ( lang ) ) { continue ; } System . out . println ( "Running disambiguation tests for " + lang . getName ( ) + "..." ) ; final DisambiguationRuleLoader ruleLoader = new DisambiguationRuleLoader ( ) ; final JLanguageTool languageTool = new JLanguageTool ( lang ) ; if ( ! ( languageTool . getLanguage ( ) . getDisambiguator ( ) instanceof DemoDisambiguator ) ) { final String name = JLanguageTool . getDataBroker ( ) . getResourceDir ( ) + "/" + lang . getShortName ( ) + "/disambiguation.xml" ; validateRuleFile ( name ) ; final List < DisambiguationPatternRule > rules = ruleLoader . getRules ( ruleLoader . getClass ( ) . getResourceAsStream ( name ) ) ; for ( DisambiguationPatternRule rule : rules ) { PatternTestTools . warnIfRegexpSyntaxNotKosher ( rule . getPatternTokens ( ) , rule . getId ( ) , rule . getSubId ( ) , lang ) ; } testDisambiguationRulesFromXML ( rules , languageTool , lang ) ; System . out . println ( rules . size ( ) + " rules tested." ) ; } } } private void validateRuleFile ( String filePath ) throws IOException { final XMLValidator validator = new XMLValidator ( ) ; try ( InputStream stream = this . getClass ( ) . getResourceAsStream ( filePath ) ) { if ( stream != null ) { validator . validateWithXmlSchema ( filePath , JLanguageTool . getDataBroker ( ) . getResourceDir ( ) + "/disambiguation.xsd" ) ; } } } private static String sortForms ( final String wordForms ) { if ( ",[,]" . equals ( wordForms ) ) { return wordForms ; } final String word = wordForms . substring ( 0 , wordForms . indexOf ( '[' ) + 1 ) ; final String forms = wordForms . substring ( wordForms . indexOf ( '[' ) + 1 , wordForms . length ( ) - 1 ) ; final String [ ] formToSort = forms . split ( "," ) ; Arrays . sort ( formToSort ) ; return word + StringTools . listToString ( Arrays . asList ( formToSort ) , "," ) + "]" ; } private void testDisambiguationRulesFromXML ( final List < DisambiguationPatternRule > rules , final JLanguageTool languageTool , final Language lang ) throws IOException { for ( final DisambiguationPatternRule rule : rules ) { final String id = rule . getId ( ) ; if ( rule . getUntouchedExamples ( ) != null ) { final List < String > goodSentences = rule . getUntouchedExamples ( ) ; for ( String goodSentence : goodSentences ) { goodSentence = goodSentence . replaceAll ( "[\\n\\t]+" , "" ) ; goodSentence = cleanXML ( goodSentence ) ; assertTrue ( goodSentence . trim ( ) . length ( ) > 0 ) ; final AnalyzedSentence sent = disambiguateUntil ( rules , id , languageTool . getRawAnalyzedSentence ( goodSentence ) ) ; final AnalyzedSentence sentToReplace = disambiguateUntil ( rules , id , languageTool . getRawAnalyzedSentence ( goodSentence ) ) ; assertEquals ( "The untouched example (" + goodSentence + ") for " + lang . getName ( ) + " rule " + rule + "] was touched!" , sent . toString ( ) , rule . replace ( sentToReplace ) . toString ( ) ) ; } } final List < DisambiguatedExample > examples = rule . getExamples ( ) ; if ( examples != null ) { for ( final DisambiguatedExample example : examples ) { final String outputForms = example . getDisambiguated ( ) ; assertTrue ( "No input form found for: " + id , outputForms != null ) ; assertTrue ( outputForms . trim ( ) . length ( ) > 0 ) ; final int expectedMatchStart = example . getExample ( ) . indexOf ( "<marker>" ) ; final int expectedMatchEnd = example . getExample ( ) . indexOf ( "</marker>" ) - "<marker>" . length ( ) ; if ( expectedMatchStart == - 1 || expectedMatchEnd == - 1 ) { fail ( lang + ": No position markup ('<marker>...</marker>') in disambiguated example in rule " + rule ) ; } final String inputForms = example . getAmbiguous ( ) ; assertTrue ( "No input form found for: " + id , inputForms != null ) ; assertTrue ( inputForms . trim ( ) . length ( ) > 0 ) ; assertTrue ( "Input and output forms for rule " + id + " are the same!" , ! outputForms . equals ( inputForms ) ) ; final AnalyzedSentence cleanInput = languageTool . getRawAnalyzedSentence ( cleanXML ( example . getExample ( ) ) ) ; final AnalyzedSentence sent = disambiguateUntil ( rules , id , languageTool . getRawAnalyzedSentence ( cleanXML ( example . getExample ( ) ) ) ) ; final AnalyzedSentence disambiguatedSent = rule . replace ( disambiguateUntil ( rules , id , languageTool . getRawAnalyzedSentence ( cleanXML ( example . getExample ( ) ) ) ) ) ; assertTrue ( "Disambiguated sentence is equal to the non-disambiguated sentence for rule: " + id , ! cleanInput . equals ( disambiguatedSent ) ) ; assertTrue ( "Disambiguated sentence is equal to the input sentence for rule: " + id + ". The sentence was: " + sent , ! sent . equals ( disambiguatedSent ) ) ; String reading = "" ; String annotations = "" ; for ( final AnalyzedTokenReadings readings : sent . getTokens ( ) ) { if ( readings . isSentenceStart ( ) && ! inputForms . contains ( "<S>" ) ) { continue ; } if ( readings . getStartPos ( ) == expectedMatchStart ) { final AnalyzedTokenReadings [ ] r = { readings } ; reading = new AnalyzedSentence ( r ) . toShortString ( "," ) ; annotations = readings . getHistoricalAnnotations ( ) ; int startPos = readings . getStartPos ( ) ; int endPos = readings . getEndPos ( ) ; assertTrue ( "Wrong marker position in the example for the rule " + id + ": got " + startPos + "-" + endPos + ", expected " + expectedMatchStart + "-" + expectedMatchEnd , startPos == expectedMatchStart && endPos == expectedMatchEnd ) ; break ; } } assertEquals ( "The input form for the rule " + id + " in the example: " + example + " is different than expected (expected " + inputForms + " but got " + sortForms ( reading ) + "). The token has been changed by the disambiguator: " + annotations , inputForms , sortForms ( reading ) ) ; for ( final AnalyzedTokenReadings readings : disambiguatedSent . getTokens ( ) ) { if ( readings . isSentenceStart ( ) && ! outputForms . contains ( "<S>" ) ) { continue ; } if ( readings . getStartPos ( ) == expectedMatchStart ) { final AnalyzedTokenReadings [ ] r = { readings } ; reading = new AnalyzedSentence ( r ) . toShortString ( "," ) ; assertTrue ( readings . getStartPos ( ) == expectedMatchStart && readings . getEndPos ( ) == expectedMatchEnd ) ; break ; } } assertEquals ( "The output form for the rule " + id + " in the example: " + example + " is different than expected (expected " + outputForms + " but got " + sortForms ( reading ) + "). The token has been changed by the disambiguator: " + annotations , outputForms , sortForms ( reading ) ) ; } } } } private static AnalyzedSentence disambiguateUntil ( final List < DisambiguationPatternRule > rules , final String ruleID , final AnalyzedSentence sentence ) throws IOException { AnalyzedSentence disambiguated = sentence ; for ( final DisambiguationPatternRule rule : rules ) { if ( ruleID . equals ( rule . getId ( ) ) ) { break ; } disambiguated = rule . replace ( disambiguated ) ; } return disambiguated ; } private static String cleanXML ( final String str ) { return str . replaceAll ( "<.*?>" , "" ) ; } public static void main ( final String [ ] args ) throws IOException , ParserConfigurationException , SAXException { final DisambiguationRuleTest test = new DisambiguationRuleTest ( ) ; System . out . println ( "Running disambiguator rule tests..." ) ; if ( args . length == 0 ) { test . testDisambiguationRulesFromXML ( null ) ; } else { final Set < Language > ignoredLanguages = TestTools . getLanguagesExcept ( args ) ; test . testDisambiguationRulesFromXML ( ignoredLanguages ) ; } System . out . println ( "Tests successful." ) ; } }
package org . languagetool . tokenizers ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tagging . ManualTagger ; import org . languagetool . tagging . TaggedWord ; import org . languagetool . tagging . Tagger ; public class ManualTaggerAdapter implements Tagger { private final ManualTagger manualTagger ; public ManualTaggerAdapter ( ManualTagger manualTagger ) { this . manualTagger = manualTagger ; } @ Override public List < AnalyzedTokenReadings > tag ( List < String > sentenceTokens ) throws IOException { final List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; int pos = 0 ; for ( final String word : sentenceTokens ) { final List < AnalyzedToken > l = new ArrayList < > ( ) ; final List < TaggedWord > manualTags = manualTagger . tag ( word . toLowerCase ( ) ) ; for ( TaggedWord manualTag : manualTags ) { l . add ( new AnalyzedToken ( word , manualTag . getPosTag ( ) , manualTag . getLemma ( ) ) ) ; } if ( l . isEmpty ( ) ) { l . add ( new AnalyzedToken ( word , null , null ) ) ; } tokenReadings . add ( new AnalyzedTokenReadings ( l , pos ) ) ; pos += word . length ( ) ; } return tokenReadings ; } @ Override public AnalyzedTokenReadings createNullToken ( String token , int startPos ) { return new AnalyzedTokenReadings ( new AnalyzedToken ( token , null , null ) , startPos ) ; } @ Override public AnalyzedToken createToken ( String token , String posTag ) { return new AnalyzedToken ( token , posTag , null ) ; } }
package org . languagetool . rules . nl ; import org . junit . Test ; import org . languagetool . rules . RuleMatch ; import java . util . HashMap ; import java . util . Map ; import static junit . framework . Assert . assertNull ; import static junit . framework . TestCase . assertNotNull ; public class DateCheckFilterTest { private final RuleMatch match = new RuleMatch ( null , 0 , 10 , "message" ) ; private final DateCheckFilter filter = new DateCheckFilter ( ) ; @ Test public void testAccept ( ) throws Exception { assertNull ( filter . acceptRuleMatch ( match , makeMap ( "2014" , "8" , "23" , "zaterdag" ) , null ) ) ; assertNotNull ( filter . acceptRuleMatch ( match , makeMap ( "2014" , "8" , "23" , "zondag" ) , null ) ) ; } private Map < String , String > makeMap ( String year , String month , String dayOfMonth , String weekDay ) { Map < String , String > map = new HashMap < > ( ) ; map . put ( "year" , year ) ; map . put ( "month" , month ) ; map . put ( "day" , dayOfMonth ) ; map . put ( "weekDay" , weekDay ) ; return map ; } }
package org . languagetool . tokenizers ; import java . util . List ; import junit . framework . TestCase ; import org . languagetool . tools . StringTools ; public class WordTokenizerTest extends TestCase { private final WordTokenizer wordTokenizer = new WordTokenizer ( ) ; public void testTokenize ( ) { final WordTokenizer wordTokenizer = new WordTokenizer ( ) ; final List < String > tokens = wordTokenizer . tokenize ( "This is\u00A0a test" ) ; assertEquals ( tokens . size ( ) , 7 ) ; assertEquals ( "[This, , is, \u00A0, a, , test]" , tokens . toString ( ) ) ; final List < String > tokens2 = wordTokenizer . tokenize ( "This\rbreaks" ) ; assertEquals ( 3 , tokens2 . size ( ) ) ; assertEquals ( "[This, \r, breaks]" , tokens2 . toString ( ) ) ; } public void testUrlTokenize ( ) { assertEquals ( "This| |http://foo.org| |blah" , tokenize ( "This http://foo.org blah" ) ) ; assertEquals ( "This| |http://foo.org| |and| |ftp://bla.com| |blah" , tokenize ( "This http://foo.org and ftp://bla.com blah" ) ) ; assertEquals ( "foo| |http://localhost:32000/?ch=1| |bar" , tokenize ( "foo http://localhost:32000/?ch=1 bar" ) ) ; assertEquals ( "foo| |ftp://localhost:32000/| |bar" , tokenize ( "foo ftp://localhost:32000/ bar" ) ) ; assertEquals ( "foo| |http://google.de/?aaa| |bar" , tokenize ( "foo http://google.de/?aaa bar" ) ) ; assertEquals ( "foo| |http://www.flickr.com/123@N04/hallo#test| |bar" , tokenize ( "foo http://www.flickr.com/123@N04/hallo#test bar" ) ) ; assertEquals ( "foo| |http://www.youtube.com/watch?v=wDN_EYUvUq0| |bar" , tokenize ( "foo http://www.youtube.com/watch?v=wDN_EYUvUq0 bar" ) ) ; assertEquals ( "foo| |http://example.net/index.html?s=A54C6FE2%23info| |bar" , tokenize ( "foo http://example.net/index.html?s=A54C6FE2%23info bar" ) ) ; assertEquals ( "foo| |https://joe:passwd@example.net:8080/index.html?action=x&session=A54C6FE2#info| |bar" , tokenize ( "foo https://joe:passwd@example.net:8080/index.html?action=x&session=A54C6FE2#info bar" ) ) ; } public void testUrlTokenizeWithAppendedCharacter ( ) { assertEquals ( "foo| |(|http://ex.net/p?a=x#i|)| |bar" , tokenize ( "foo (http://ex.net/p?a=x#i) bar" ) ) ; assertEquals ( "foo| |http://ex.net/p?a=x#i|,| |bar" , tokenize ( "foo http://ex.net/p?a=x#i, bar" ) ) ; assertEquals ( "foo| |http://ex.net/p?a=x#i|.| |bar" , tokenize ( "foo http://ex.net/p?a=x#i. bar" ) ) ; assertEquals ( "foo| |http://ex.net/p?a=x#i|:| |bar" , tokenize ( "foo http://ex.net/p?a=x#i: bar" ) ) ; assertEquals ( "foo| |http://ex.net/p?a=x#i|?| |bar" , tokenize ( "foo http://ex.net/p?a=x#i? bar" ) ) ; assertEquals ( "foo| |http://ex.net/p?a=x#i|!| |bar" , tokenize ( "foo http://ex.net/p?a=x#i! bar" ) ) ; } public void testIncompleteUrlTokenize ( ) { assertEquals ( "http|:|/" , tokenize ( "http:/" ) ) ; assertEquals ( "http://" , tokenize ( "http://" ) ) ; assertEquals ( "http://a" , tokenize ( "http://a" ) ) ; assertEquals ( "foo| |http| |bar" , tokenize ( "foo http bar" ) ) ; assertEquals ( "foo| |http|:| |bar" , tokenize ( "foo http: bar" ) ) ; assertEquals ( "foo| |http|:|/| |bar" , tokenize ( "foo http:/ bar" ) ) ; assertEquals ( "foo| |http://| |bar" , tokenize ( "foo http:// bar" ) ) ; assertEquals ( "foo| |http://a| |bar" , tokenize ( "foo http://a bar" ) ) ; assertEquals ( "foo| |http://|?| |bar" , tokenize ( "foo http://? bar" ) ) ; } private String tokenize ( String text ) { final List < String > tokens = wordTokenizer . tokenize ( text ) ; return StringTools . listToString ( tokens , "|" ) ; } }
package org . languagetool . tokenizers ; import org . junit . Test ; import org . languagetool . TestTools ; public class SimpleSentenceTokenizerTest { @ Test public void testTokenize ( ) throws Exception { testSplit ( "Hi! " , "This is a test. " , "Here's more. " , "And even more?? " , "Yes." ) ; } private void testSplit ( String ... sentences ) { SimpleSentenceTokenizer tokenizer = new SimpleSentenceTokenizer ( ) ; TestTools . testSplit ( sentences , tokenizer ) ; } }
package org . languagetool . tokenizers ; import org . junit . Test ; import org . languagetool . FakeLanguage ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class LocalSRXSentenceTokenizerTest { private final LocalSRXSentenceTokenizer tokenizer = new LocalSRXSentenceTokenizer ( new FakeLanguage ( "yy" ) , "/org/languagetool/tokenizers/segment-test.srx" ) ; @ Test public void testTokenize ( ) { assertTokenize ( "A sentence. Another one." , "[A sentence. , Another one.]" ) ; assertTokenize ( "A fooabbr. doesn't end a sentence." , "[A fooabbr. doesn't end a sentence.]" ) ; assertTokenize ( "A barabbr. doesn't end a sentence." , "[A barabbr. doesn't end a sentence.]" ) ; tokenizer . setSingleLineBreaksMarksParagraph ( true ) ; assertTokenize ( "A sentence.\nAnother one." , "[A sentence.\n, Another one.]" ) ; assertTokenize ( "A sentence.\n\nAnother one." , "[A sentence.\n, \n, Another one.]" ) ; tokenizer . setSingleLineBreaksMarksParagraph ( false ) ; assertTokenize ( "A sentence\nwhich goes on here." , "[A sentence\nwhich goes on here.]" ) ; assertTokenize ( "A sentence.\n\nAnother one." , "[A sentence.\n, \nAnother one.]" ) ; } private void assertTokenize ( String input , String output ) { assertThat ( tokenizer . tokenize ( input ) . toString ( ) , is ( output ) ) ; } }
package org . languagetool . tokenizers ; import java . io . ByteArrayInputStream ; import java . util . Arrays ; import java . util . List ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tagging . ManualTagger ; import org . languagetool . tagging . Tagger ; public class ManualTaggerAdapterTest extends TestCase { private static final String TEST_DATA = "# some test data\n" + "inflectedform11\tlemma1\tPOS1\n" + "inflectedform121\tlemma1\tPOS2\n" + "inflectedform122\tlemma1\tPOS2\n" + "inflectedform123\tlemma1\tPOS3\n" + "inflectedform2\tlemma2\tPOS1a\n" + "inflectedform2\tlemma2\tPOS1b\n" + "inflectedform2\tlemma2\tPOS1c\n" + "inflectedform3\tlemma3a\tPOS3a\n" + "inflectedform3\tlemma3b\tPOS3b\n" + "inflectedform3\tlemma3c\tPOS3c\n" + "inflectedform3\tlemma3d\tPOS3d\n" ; protected Tagger tagger ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; tagger = new ManualTaggerAdapter ( new ManualTagger ( new ByteArrayInputStream ( TEST_DATA . getBytes ( "UTF-8" ) ) ) ) ; } public void testMultipleLemma ( ) throws Exception { final List < String > l = Arrays . asList ( "inflectedform3" ) ; final List < AnalyzedTokenReadings > analyzedTokenReadings = tagger . tag ( l ) ; assertNotNull ( analyzedTokenReadings ) ; assertEquals ( 1 , analyzedTokenReadings . size ( ) ) ; final AnalyzedTokenReadings analyzedTokenReading = analyzedTokenReadings . get ( 0 ) ; assertEquals ( "inflectedform3" , analyzedTokenReading . getToken ( ) ) ; assertNotNull ( analyzedTokenReading . getReadings ( ) ) ; assertEquals ( 4 , analyzedTokenReading . getReadingsLength ( ) ) ; AnalyzedToken analyzedToken ; analyzedToken = analyzedTokenReading . getReadings ( ) . get ( 0 ) ; assertEquals ( "inflectedform3" , analyzedToken . getToken ( ) ) ; assertEquals ( "lemma3a" , analyzedToken . getLemma ( ) ) ; assertEquals ( "POS3a" , analyzedToken . getPOSTag ( ) ) ; analyzedToken = analyzedTokenReading . getReadings ( ) . get ( 1 ) ; assertEquals ( "inflectedform3" , analyzedToken . getToken ( ) ) ; assertEquals ( "lemma3b" , analyzedToken . getLemma ( ) ) ; assertEquals ( "POS3b" , analyzedToken . getPOSTag ( ) ) ; analyzedToken = analyzedTokenReading . getReadings ( ) . get ( 2 ) ; assertEquals ( "inflectedform3" , analyzedToken . getToken ( ) ) ; assertEquals ( "lemma3c" , analyzedToken . getLemma ( ) ) ; assertEquals ( "POS3c" , analyzedToken . getPOSTag ( ) ) ; analyzedToken = analyzedTokenReading . getReadings ( ) . get ( 3 ) ; assertEquals ( "inflectedform3" , analyzedToken . getToken ( ) ) ; assertEquals ( "lemma3d" , analyzedToken . getLemma ( ) ) ; assertEquals ( "POS3d" , analyzedToken . getPOSTag ( ) ) ; } public void testMultiplePOS ( ) throws Exception { final List < String > l = Arrays . asList ( "inflectedform2" ) ; final List < AnalyzedTokenReadings > analyzedTokenReadings = tagger . tag ( l ) ; assertNotNull ( analyzedTokenReadings ) ; assertEquals ( 1 , analyzedTokenReadings . size ( ) ) ; final AnalyzedTokenReadings analyzedTokenReading = analyzedTokenReadings . get ( 0 ) ; assertEquals ( "inflectedform2" , analyzedTokenReading . getToken ( ) ) ; assertNotNull ( analyzedTokenReading . getReadings ( ) ) ; assertEquals ( 3 , analyzedTokenReading . getReadingsLength ( ) ) ; AnalyzedToken analyzedToken ; analyzedToken = analyzedTokenReading . getReadings ( ) . get ( 0 ) ; assertEquals ( "POS1a" , analyzedToken . getPOSTag ( ) ) ; assertEquals ( "inflectedform2" , analyzedToken . getToken ( ) ) ; assertEquals ( "lemma2" , analyzedToken . getLemma ( ) ) ; analyzedToken = analyzedTokenReading . getReadings ( ) . get ( 1 ) ; assertEquals ( "POS1b" , analyzedToken . getPOSTag ( ) ) ; assertEquals ( "inflectedform2" , analyzedToken . getToken ( ) ) ; assertEquals ( "lemma2" , analyzedToken . getLemma ( ) ) ; analyzedToken = analyzedTokenReading . getReadings ( ) . get ( 2 ) ; assertEquals ( "POS1c" , analyzedToken . getPOSTag ( ) ) ; assertEquals ( "inflectedform2" , analyzedToken . getToken ( ) ) ; assertEquals ( "lemma2" , analyzedToken . getLemma ( ) ) ; } public void testMultipleWords ( ) throws Exception { final List < String > l = Arrays . asList ( "inflectedform2" , "inflectedform3" ) ; final List < AnalyzedTokenReadings > analyzedTokenReadings = tagger . tag ( l ) ; assertNotNull ( analyzedTokenReadings ) ; assertEquals ( 2 , analyzedTokenReadings . size ( ) ) ; AnalyzedTokenReadings analyzedTokenReading ; analyzedTokenReading = analyzedTokenReadings . get ( 0 ) ; assertEquals ( "inflectedform2" , analyzedTokenReading . getToken ( ) ) ; assertNotNull ( analyzedTokenReading . getReadings ( ) ) ; assertEquals ( 3 , analyzedTokenReading . getReadingsLength ( ) ) ; analyzedTokenReading = analyzedTokenReadings . get ( 1 ) ; assertEquals ( "inflectedform3" , analyzedTokenReading . getToken ( ) ) ; assertNotNull ( analyzedTokenReading . getReadings ( ) ) ; assertEquals ( 4 , analyzedTokenReading . getReadingsLength ( ) ) ; } }
package org . languagetool ; import java . util . Enumeration ; import java . util . ResourceBundle ; public class ResourceBundleWithFallback extends ResourceBundle { private final ResourceBundle bundle ; private final ResourceBundle fallbackBundle ; public ResourceBundleWithFallback ( ResourceBundle bundle , ResourceBundle fallbackBundle ) { this . bundle = bundle ; this . fallbackBundle = fallbackBundle ; } @ Override public Object handleGetObject ( String key ) { final String s = bundle . getString ( key ) ; if ( s . trim ( ) . isEmpty ( ) ) { return fallbackBundle . getString ( key ) ; } return s ; } @ Override public Enumeration < String > getKeys ( ) { return bundle . getKeys ( ) ; } }
package org . languagetool ; import java . lang . annotation . Documented ; @ Documented public @ interface Experimental { }
package org . languagetool ; import org . apache . commons . lang . StringUtils ; import org . jetbrains . annotations . Nullable ; import org . languagetool . tools . MultiKeyProperties ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . io . InputStream ; import java . lang . reflect . Constructor ; import java . net . URL ; import java . util . * ; public final class Languages { private static final List < Language > LANGUAGES = getAllLanguages ( ) ; private static final String PROPERTIES_PATH = "META-INF/org/languagetool/language-module.properties" ; private static final String PROPERTIES_KEY = "languageClasses" ; private Languages ( ) { } public static List < Language > get ( ) { List < Language > result = new ArrayList < > ( ) ; for ( Language lang : LANGUAGES ) { if ( ! "xx" . equals ( lang . getShortName ( ) ) ) { result . add ( lang ) ; } } return Collections . unmodifiableList ( result ) ; } public static List < Language > getWithDemoLanguage ( ) { return LANGUAGES ; } private static List < Language > getAllLanguages ( ) { final List < Language > languages = new ArrayList < > ( ) ; final Set < String > languageClassNames = new HashSet < > ( ) ; try { final Enumeration < URL > propertyFiles = Language . class . getClassLoader ( ) . getResources ( PROPERTIES_PATH ) ; while ( propertyFiles . hasMoreElements ( ) ) { final URL url = propertyFiles . nextElement ( ) ; try ( InputStream inputStream = url . openStream ( ) ) { final MultiKeyProperties props = new MultiKeyProperties ( inputStream ) ; final List < String > classNamesStr = props . getProperty ( PROPERTIES_KEY ) ; if ( classNamesStr == null ) { throw new RuntimeException ( "Key '" + PROPERTIES_KEY + "' not found in " + url ) ; } for ( String classNames : classNamesStr ) { final String [ ] classNamesSplit = classNames . split ( "\\s*,\\s*" ) ; for ( String className : classNamesSplit ) { if ( languageClassNames . contains ( className ) ) { continue ; } languages . add ( createLanguageObjects ( url , className ) ) ; languageClassNames . add ( className ) ; } } } } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } return Collections . unmodifiableList ( languages ) ; } private static Language createLanguageObjects ( URL url , String className ) { try { final Class < ? > aClass = Class . forName ( className ) ; final Constructor < ? > constructor = aClass . getConstructor ( ) ; return ( Language ) constructor . newInstance ( ) ; } catch ( ClassNotFoundException e ) { throw new RuntimeException ( "Class '" + className + "' specified in " + url + " could not be found in classpath" , e ) ; } catch ( Exception e ) { throw new RuntimeException ( "Object for class '" + className + "' specified in " + url + " could not created" , e ) ; } } @ Nullable public static Language getLanguageForName ( final String languageName ) { for ( Language element : LANGUAGES ) { if ( languageName . equals ( element . getName ( ) ) ) { return element ; } } return null ; } public static Language getLanguageForShortName ( final String langCode ) { final Language language = getLanguageForShortNameOrNull ( langCode ) ; if ( language == null ) { final List < String > codes = new ArrayList < > ( ) ; for ( Language realLanguage : LANGUAGES ) { codes . add ( realLanguage . getShortNameWithCountryAndVariant ( ) ) ; } Collections . sort ( codes ) ; throw new IllegalArgumentException ( "'" + langCode + "' is not a language code known to LanguageTool." + " Supported language codes are: " + StringUtils . join ( codes , ", " ) + ". The list of languages is read from " + PROPERTIES_PATH + " in the Java classpath. See http://wiki.languagetool.org/java-api for details." ) ; } return language ; } public static boolean isLanguageSupported ( final String langCode ) { return getLanguageForShortNameOrNull ( langCode ) != null ; } public static Language getLanguageForLocale ( final Locale locale ) { final Language language = getLanguageForLanguageNameAndCountry ( locale ) ; if ( language != null ) { return language ; } else { final Language firstFallbackLanguage = getLanguageForLanguageNameOnly ( locale ) ; if ( firstFallbackLanguage != null ) { return firstFallbackLanguage ; } } for ( Language aLanguage : LANGUAGES ) { if ( aLanguage . getShortNameWithCountryAndVariant ( ) . equals ( "en-US" ) ) { return aLanguage ; } } throw new RuntimeException ( "No appropriate language found, not even en-US. Supported languages: " + get ( ) ) ; } @ Nullable private static Language getLanguageForShortNameOrNull ( final String langCode ) { StringTools . assureSet ( langCode , "langCode" ) ; Language result = null ; if ( langCode . contains ( "-x-" ) ) { for ( Language element : LANGUAGES ) { if ( element . getShortName ( ) . equalsIgnoreCase ( langCode ) ) { return element ; } } } else if ( langCode . contains ( "-" ) ) { final String [ ] parts = langCode . split ( "-" ) ; if ( parts . length == 2 ) { for ( Language element : LANGUAGES ) { if ( parts [ 0 ] . equalsIgnoreCase ( element . getShortName ( ) ) && element . getCountries ( ) . length == 1 && parts [ 1 ] . equalsIgnoreCase ( element . getCountries ( ) [ 0 ] ) ) { result = element ; break ; } } } else if ( parts . length == 3 ) { for ( Language element : LANGUAGES ) { if ( parts [ 0 ] . equalsIgnoreCase ( element . getShortName ( ) ) && element . getCountries ( ) . length == 1 && parts [ 1 ] . equalsIgnoreCase ( element . getCountries ( ) [ 0 ] ) && parts [ 2 ] . equalsIgnoreCase ( element . getVariant ( ) ) ) { result = element ; break ; } } } else { throw new IllegalArgumentException ( "'" + langCode + "' isn't a valid language code" ) ; } } else { for ( Language element : LANGUAGES ) { if ( langCode . equalsIgnoreCase ( element . getShortName ( ) ) ) { result = element ; break ; } } } return result ; } @ Nullable private static Language getLanguageForLanguageNameAndCountry ( Locale locale ) { for ( Language language : LANGUAGES ) { if ( language . getShortName ( ) . equals ( locale . getLanguage ( ) ) ) { final List < String > countryVariants = Arrays . asList ( language . getCountries ( ) ) ; if ( countryVariants . contains ( locale . getCountry ( ) ) ) { return language ; } } } return null ; } @ Nullable private static Language getLanguageForLanguageNameOnly ( Locale locale ) { for ( Language language : LANGUAGES ) { if ( language . getShortName ( ) . equals ( locale . getLanguage ( ) ) && language . hasVariant ( ) ) { final Language defaultVariant = language . getDefaultLanguageVariant ( ) ; if ( defaultVariant != null ) { return defaultVariant ; } } } for ( Language language : LANGUAGES ) { if ( language . getShortName ( ) . equals ( locale . getLanguage ( ) ) && ! language . hasVariant ( ) ) { return language ; } } return null ; } }
package org . languagetool ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . concurrent . Callable ; import java . util . concurrent . ExecutionException ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . Future ; import java . util . concurrent . ThreadFactory ; import org . languagetool . markup . AnnotatedText ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public class MultiThreadedJLanguageTool extends JLanguageTool { private final int threadPoolSize ; private final ExecutorService threadPool ; public MultiThreadedJLanguageTool ( Language language ) { this ( language , null ) ; } public MultiThreadedJLanguageTool ( Language language , int threadPoolSize ) { this ( language , null , threadPoolSize ) ; } public MultiThreadedJLanguageTool ( Language language , Language motherTongue ) { this ( language , motherTongue , getDefaultThreadCount ( ) ) ; } public MultiThreadedJLanguageTool ( Language language , Language motherTongue , int threadPoolSize ) { super ( language , motherTongue ) ; if ( threadPoolSize < 1 ) { throw new IllegalArgumentException ( "threadPoolSize must be >= 1: " + threadPoolSize ) ; } this . threadPoolSize = threadPoolSize ; threadPool = Executors . newFixedThreadPool ( getThreadPoolSize ( ) , new DaemonThreadFactory ( ) ) ; } public void shutdown ( ) { threadPool . shutdownNow ( ) ; } private static int getDefaultThreadCount ( ) { String threadCountStr = System . getProperty ( "org.languagetool.thread_count_internal" , "-1" ) ; int threadPoolSize = Integer . parseInt ( threadCountStr ) ; if ( threadPoolSize == - 1 ) { threadPoolSize = Runtime . getRuntime ( ) . availableProcessors ( ) ; } return threadPoolSize ; } protected int getThreadPoolSize ( ) { return threadPoolSize ; } protected ExecutorService getExecutorService ( ) { return threadPool ; } @ Override protected List < AnalyzedSentence > analyzeSentences ( List < String > sentences ) throws IOException { final List < AnalyzedSentence > analyzedSentences = new ArrayList < > ( ) ; final ExecutorService executorService = getExecutorService ( ) ; int j = 0 ; List < Callable < AnalyzedSentence > > callables = new ArrayList < > ( ) ; for ( final String sentence : sentences ) { AnalyzeSentenceCallable analyzeSentenceCallable = ++ j < sentences . size ( ) ? new AnalyzeSentenceCallable ( sentence ) : new ParagraphEndAnalyzeSentenceCallable ( sentence ) ; callables . add ( analyzeSentenceCallable ) ; } try { List < Future < AnalyzedSentence > > futures = executorService . invokeAll ( callables ) ; for ( Future < AnalyzedSentence > future : futures ) { AnalyzedSentence analyzedSentence = future . get ( ) ; rememberUnknownWords ( analyzedSentence ) ; printSentenceInfo ( analyzedSentence ) ; analyzedSentences . add ( analyzedSentence ) ; } } catch ( InterruptedException | ExecutionException e ) { throw new RuntimeException ( e ) ; } return analyzedSentences ; } @ Override protected List < RuleMatch > performCheck ( final List < AnalyzedSentence > analyzedSentences , final List < String > sentences , final List < Rule > allRules , final ParagraphHandling paraMode , final AnnotatedText annotatedText ) throws IOException { int charCount = 0 ; int lineCount = 0 ; int columnCount = 1 ; final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final ExecutorService executorService = getExecutorService ( ) ; try { final List < Callable < List < RuleMatch > > > callables = createTextCheckCallables ( paraMode , annotatedText , analyzedSentences , sentences , allRules , charCount , lineCount , columnCount ) ; final List < Future < List < RuleMatch > > > futures = executorService . invokeAll ( callables ) ; for ( Future < List < RuleMatch > > future : futures ) { ruleMatches . addAll ( future . get ( ) ) ; } } catch ( InterruptedException | ExecutionException e ) { throw new RuntimeException ( e ) ; } return ruleMatches ; } private List < Callable < List < RuleMatch > > > createTextCheckCallables ( ParagraphHandling paraMode , AnnotatedText annotatedText , List < AnalyzedSentence > analyzedSentences , List < String > sentences , List < Rule > allRules , int charCount , int lineCount , int columnCount ) { final int threads = getThreadPoolSize ( ) ; final int totalRules = allRules . size ( ) ; final int chunkSize = totalRules / threads ; int firstItem = 0 ; final List < Callable < List < RuleMatch > > > callables = new ArrayList < > ( ) ; for ( int i = 0 ; i < threads ; i ++ ) { final List < Rule > subRules ; if ( i == threads - 1 ) { subRules = allRules . subList ( firstItem , totalRules ) ; } else { subRules = allRules . subList ( firstItem , firstItem + chunkSize ) ; } callables . add ( new TextCheckCallable ( subRules , sentences , analyzedSentences , paraMode , annotatedText , charCount , lineCount , columnCount ) ) ; firstItem = firstItem + chunkSize ; } return callables ; } private class AnalyzeSentenceCallable implements Callable < AnalyzedSentence > { private final String sentence ; private AnalyzeSentenceCallable ( String sentence ) { this . sentence = sentence ; } @ Override public AnalyzedSentence call ( ) throws Exception { return getAnalyzedSentence ( sentence ) ; } } private final class ParagraphEndAnalyzeSentenceCallable extends AnalyzeSentenceCallable { private ParagraphEndAnalyzeSentenceCallable ( String sentence ) { super ( sentence ) ; } @ Override public AnalyzedSentence call ( ) throws Exception { AnalyzedSentence analyzedSentence = super . call ( ) ; AnalyzedTokenReadings [ ] anTokens = analyzedSentence . getTokens ( ) ; anTokens [ anTokens . length - 1 ] . setParagraphEnd ( ) ; analyzedSentence = new AnalyzedSentence ( anTokens ) ; return analyzedSentence ; } } private static final class DaemonThreadFactory implements ThreadFactory { @ Override public Thread newThread ( Runnable r ) { Thread thread = new Thread ( r ) ; thread . setDaemon ( true ) ; return thread ; } } }
package org . languagetool ; import org . apache . commons . lang . StringUtils ; import org . jetbrains . annotations . Nullable ; import org . languagetool . databroker . DefaultResourceDataBroker ; import org . languagetool . databroker . ResourceDataBroker ; import org . languagetool . languagemodel . LanguageModel ; import org . languagetool . markup . AnnotatedText ; import org . languagetool . markup . AnnotatedTextBuilder ; import org . languagetool . rules . * ; import org . languagetool . rules . patterns . FalseFriendRuleLoader ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . rules . patterns . PatternRuleLoader ; import org . xml . sax . SAXException ; import javax . xml . parsers . ParserConfigurationException ; import java . io . File ; import java . io . IOException ; import java . io . InputStream ; import java . io . PrintStream ; import java . net . JarURLConnection ; import java . net . URL ; import java . util . * ; import java . util . concurrent . Callable ; import java . util . jar . Manifest ; import java . util . regex . Pattern ; public class JLanguageTool { public static final String VERSION = "3.0-SNAPSHOT" ; @ Nullable public static final String BUILD_DATE = getBuildDate ( ) ; public static final String PATTERN_FILE = "grammar.xml" ; public static final String FALSE_FRIEND_FILE = "false-friends.xml" ; public static final String SENTENCE_START_TAGNAME = "SENT_START" ; public static final String SENTENCE_END_TAGNAME = "SENT_END" ; public static final String PARAGRAPH_END_TAGNAME = "PARA_END" ; public static final String MESSAGE_BUNDLE = "org.languagetool.MessagesBundle" ; @ Nullable private static String getBuildDate ( ) { try { final URL res = JLanguageTool . class . getResource ( JLanguageTool . class . getSimpleName ( ) + ".class" ) ; if ( res == null ) { return null ; } final Object connObj = res . openConnection ( ) ; if ( connObj instanceof JarURLConnection ) { final JarURLConnection conn = ( JarURLConnection ) connObj ; final Manifest manifest = conn . getManifest ( ) ; return manifest . getMainAttributes ( ) . getValue ( "Implementation-Date" ) ; } else { return null ; } } catch ( IOException e ) { throw new RuntimeException ( "Could not get build date from JAR" , e ) ; } } private static ResourceDataBroker dataBroker = new DefaultResourceDataBroker ( ) ; private final List < Rule > builtinRules ; private final List < Rule > userRules = new ArrayList < > ( ) ; private final Set < String > disabledRules = new HashSet < > ( ) ; private final Set < String > enabledRules = new HashSet < > ( ) ; private final Set < String > disabledCategories = new HashSet < > ( ) ; private final Language language ; private final Language motherTongue ; private PrintStream printStream ; private int sentenceCount ; private boolean listUnknownWords ; private Set < String > unknownWords ; public enum ParagraphHandling { NORMAL , ONLYPARA , ONLYNONPARA } private static final List < File > temporaryFiles = new ArrayList < > ( ) ; public JLanguageTool ( final Language language ) { this ( language , null ) ; } public JLanguageTool ( final Language language , final Language motherTongue ) { this . language = Objects . requireNonNull ( language , "language cannot be null" ) ; this . motherTongue = motherTongue ; final ResourceBundle messages = ResourceBundleTools . getMessageBundle ( language ) ; builtinRules = getAllBuiltinRules ( language , messages ) ; try { activateDefaultPatternRules ( ) ; activateDefaultFalseFriendRules ( ) ; } catch ( Exception e ) { throw new RuntimeException ( "Could not activate rules" , e ) ; } } public static synchronized ResourceDataBroker getDataBroker ( ) { if ( JLanguageTool . dataBroker == null ) { JLanguageTool . dataBroker = new DefaultResourceDataBroker ( ) ; } return JLanguageTool . dataBroker ; } public static synchronized void setDataBroker ( ResourceDataBroker broker ) { JLanguageTool . dataBroker = broker ; } public void setListUnknownWords ( final boolean listUnknownWords ) { this . listUnknownWords = listUnknownWords ; } public static ResourceBundle getMessageBundle ( ) { return ResourceBundleTools . getMessageBundle ( ) ; } public static ResourceBundle getMessageBundle ( final Language lang ) { return ResourceBundleTools . getMessageBundle ( lang ) ; } private List < Rule > getAllBuiltinRules ( final Language language , ResourceBundle messages ) { try { return language . getRelevantRules ( messages ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not get rules of language " + language , e ) ; } } public void setOutput ( final PrintStream printStream ) { this . printStream = printStream ; } public List < PatternRule > loadPatternRules ( final String filename ) throws IOException { final PatternRuleLoader ruleLoader = new PatternRuleLoader ( ) ; try ( InputStream is = this . getClass ( ) . getResourceAsStream ( filename ) ) { if ( is == null ) { return ruleLoader . getRules ( new File ( filename ) ) ; } else { return ruleLoader . getRules ( is , filename ) ; } } } public List < PatternRule > loadFalseFriendRules ( final String filename ) throws ParserConfigurationException , SAXException , IOException { if ( motherTongue == null ) { return Collections . emptyList ( ) ; } final FalseFriendRuleLoader ruleLoader = new FalseFriendRuleLoader ( ) ; try ( InputStream is = this . getClass ( ) . getResourceAsStream ( filename ) ) { if ( is == null ) { return ruleLoader . getRules ( new File ( filename ) , language , motherTongue ) ; } else { return ruleLoader . getRules ( is , language , motherTongue ) ; } } } public void activateLanguageModelRules ( File indexDir ) throws IOException { LanguageModel languageModel = language . getLanguageModel ( indexDir ) ; if ( languageModel != null ) { ResourceBundle messages = getMessageBundle ( language ) ; List < Rule > rules = language . getRelevantLanguageModelRules ( messages , languageModel ) ; userRules . addAll ( rules ) ; } } private void activateDefaultPatternRules ( ) throws IOException { final List < PatternRule > patternRules = language . getPatternRules ( ) ; final List < String > enabledRules = language . getDefaultEnabledRulesForVariant ( ) ; final List < String > disabledRules = language . getDefaultDisabledRulesForVariant ( ) ; if ( ! enabledRules . isEmpty ( ) || ! disabledRules . isEmpty ( ) ) { for ( PatternRule patternRule : patternRules ) { if ( enabledRules . contains ( patternRule . getId ( ) ) ) { patternRule . setDefaultOn ( ) ; } if ( disabledRules . contains ( patternRule . getId ( ) ) ) { patternRule . setDefaultOff ( ) ; } } } userRules . addAll ( patternRules ) ; } private void activateDefaultFalseFriendRules ( ) throws ParserConfigurationException , SAXException , IOException { String falseFriendRulesFilename = JLanguageTool . getDataBroker ( ) . getRulesDir ( ) + "/" + FALSE_FRIEND_FILE ; userRules . addAll ( loadFalseFriendRules ( falseFriendRulesFilename ) ) ; } public void addRule ( final Rule rule ) { userRules . add ( rule ) ; } public void disableRule ( final String ruleId ) { disabledRules . add ( ruleId ) ; } public void disableRules ( final List < String > ruleIds ) { disabledRules . addAll ( ruleIds ) ; } public void disableCategory ( final String categoryName ) { disabledCategories . add ( categoryName ) ; } public Language getLanguage ( ) { return language ; } public Set < String > getDisabledRules ( ) { return disabledRules ; } public void enableDefaultOffRule ( final String ruleId ) { enabledRules . add ( ruleId ) ; } public Set < String > getDisabledCategories ( ) { return disabledCategories ; } public void enableRule ( final String ruleId ) { if ( disabledRules . contains ( ruleId ) ) { disabledRules . remove ( ruleId ) ; } } public List < String > sentenceTokenize ( final String text ) { return language . getSentenceTokenizer ( ) . tokenize ( text ) ; } public List < RuleMatch > check ( final String text ) throws IOException { return check ( text , true , ParagraphHandling . NORMAL ) ; } public List < RuleMatch > check ( final String text , boolean tokenizeText , final ParagraphHandling paraMode ) throws IOException { return check ( new AnnotatedTextBuilder ( ) . addText ( text ) . build ( ) , tokenizeText , paraMode ) ; } public List < RuleMatch > check ( final AnnotatedText text ) throws IOException { return check ( text , true , ParagraphHandling . NORMAL ) ; } public List < RuleMatch > check ( final AnnotatedText annotatedText , boolean tokenizeText , final ParagraphHandling paraMode ) throws IOException { final List < String > sentences ; if ( tokenizeText ) { sentences = sentenceTokenize ( annotatedText . getPlainText ( ) ) ; } else { sentences = new ArrayList < > ( ) ; sentences . add ( annotatedText . getPlainText ( ) ) ; } final List < Rule > allRules = getAllRules ( ) ; printIfVerbose ( allRules . size ( ) + " rules activated for language " + language ) ; for ( final Rule rule : allRules ) { rule . reset ( ) ; } sentenceCount = sentences . size ( ) ; unknownWords = new HashSet < > ( ) ; final List < AnalyzedSentence > analyzedSentences = analyzeSentences ( sentences ) ; List < RuleMatch > ruleMatches = performCheck ( analyzedSentences , sentences , allRules , paraMode , annotatedText ) ; ruleMatches = new SameRuleGroupFilter ( ) . filter ( ruleMatches ) ; return ruleMatches ; } public List < AnalyzedSentence > analyzeText ( String text ) throws IOException { final List < String > sentences = sentenceTokenize ( text ) ; return analyzeSentences ( sentences ) ; } protected List < AnalyzedSentence > analyzeSentences ( final List < String > sentences ) throws IOException { final List < AnalyzedSentence > analyzedSentences = new ArrayList < > ( ) ; int j = 0 ; for ( final String sentence : sentences ) { AnalyzedSentence analyzedSentence = getAnalyzedSentence ( sentence ) ; rememberUnknownWords ( analyzedSentence ) ; if ( ++ j == sentences . size ( ) ) { final AnalyzedTokenReadings [ ] anTokens = analyzedSentence . getTokens ( ) ; anTokens [ anTokens . length - 1 ] . setParagraphEnd ( ) ; analyzedSentence = new AnalyzedSentence ( anTokens ) ; } analyzedSentences . add ( analyzedSentence ) ; printSentenceInfo ( analyzedSentence ) ; } return analyzedSentences ; } protected void printSentenceInfo ( AnalyzedSentence analyzedSentence ) { if ( printStream != null ) { printIfVerbose ( analyzedSentence . toString ( ) ) ; printIfVerbose ( analyzedSentence . getAnnotations ( ) ) ; } } protected List < RuleMatch > performCheck ( final List < AnalyzedSentence > analyzedSentences , final List < String > sentences , final List < Rule > allRules , ParagraphHandling paraMode , final AnnotatedText annotatedText ) throws IOException { final Callable < List < RuleMatch > > matcher = new TextCheckCallable ( allRules , sentences , analyzedSentences , paraMode , annotatedText , 0 , 0 , 1 ) ; try { return matcher . call ( ) ; } catch ( IOException e ) { throw e ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } public List < RuleMatch > checkAnalyzedSentence ( final ParagraphHandling paraMode , final List < Rule > allRules , int charCount , int lineCount , int columnCount , final String sentence , final AnalyzedSentence analyzedSentence ) throws IOException { return checkAnalyzedSentence ( paraMode , allRules , charCount , lineCount , columnCount , sentence , analyzedSentence , null ) ; } public List < RuleMatch > checkAnalyzedSentence ( final ParagraphHandling paraMode , final List < Rule > rules , int charCount , int lineCount , int columnCount , final String sentence , final AnalyzedSentence analyzedSentence , final AnnotatedText annotatedText ) throws IOException { final List < RuleMatch > sentenceMatches = new ArrayList < > ( ) ; for ( final Rule rule : rules ) { if ( rule instanceof TextLevelRule ) { continue ; } if ( ignoreRule ( rule ) ) { continue ; } if ( rule instanceof PatternRule && ( ( PatternRule ) rule ) . canBeIgnoredFor ( analyzedSentence ) ) { continue ; } if ( paraMode == ParagraphHandling . ONLYPARA ) { continue ; } final RuleMatch [ ] thisMatches = rule . match ( analyzedSentence ) ; for ( final RuleMatch element1 : thisMatches ) { final RuleMatch thisMatch = adjustRuleMatchPos ( element1 , charCount , columnCount , lineCount , sentence , annotatedText ) ; sentenceMatches . add ( thisMatch ) ; } } return new SameRuleGroupFilter ( ) . filter ( sentenceMatches ) ; } private boolean ignoreRule ( Rule rule ) { if ( disabledRules . contains ( rule . getId ( ) ) ) { return true ; } if ( rule . isDefaultOff ( ) && ! enabledRules . contains ( rule . getId ( ) ) ) { return true ; } Category category = rule . getCategory ( ) ; if ( category != null && disabledCategories . contains ( category . getName ( ) ) ) { return true ; } return false ; } public RuleMatch adjustRuleMatchPos ( final RuleMatch match , int charCount , int columnCount , int lineCount , final String sentence , final AnnotatedText annotatedText ) { int fromPos = match . getFromPos ( ) + charCount ; int toPos = match . getToPos ( ) + charCount ; if ( annotatedText != null ) { fromPos = annotatedText . getOriginalTextPositionFor ( fromPos ) ; toPos = annotatedText . getOriginalTextPositionFor ( toPos - 1 ) + 1 ; } final RuleMatch thisMatch = new RuleMatch ( match . getRule ( ) , fromPos , toPos , match . getMessage ( ) , match . getShortMessage ( ) ) ; thisMatch . setSuggestedReplacements ( match . getSuggestedReplacements ( ) ) ; final String sentencePartToError = sentence . substring ( 0 , match . getFromPos ( ) ) ; final String sentencePartToEndOfError = sentence . substring ( 0 , match . getToPos ( ) ) ; final int lastLineBreakPos = sentencePartToError . lastIndexOf ( '\n' ) ; final int column ; final int endColumn ; if ( lastLineBreakPos == - 1 ) { column = sentencePartToError . length ( ) + columnCount ; } else { column = sentencePartToError . length ( ) - lastLineBreakPos ; } final int lastLineBreakPosInError = sentencePartToEndOfError . lastIndexOf ( '\n' ) ; if ( lastLineBreakPosInError == - 1 ) { endColumn = sentencePartToEndOfError . length ( ) + columnCount ; } else { endColumn = sentencePartToEndOfError . length ( ) - lastLineBreakPosInError ; } final int lineBreaksToError = countLineBreaks ( sentencePartToError ) ; final int lineBreaksToEndOfError = countLineBreaks ( sentencePartToEndOfError ) ; thisMatch . setLine ( lineCount + lineBreaksToError ) ; thisMatch . setEndLine ( lineCount + lineBreaksToEndOfError ) ; thisMatch . setColumn ( column ) ; thisMatch . setEndColumn ( endColumn ) ; return thisMatch ; } protected void rememberUnknownWords ( final AnalyzedSentence analyzedText ) { if ( listUnknownWords ) { final AnalyzedTokenReadings [ ] atr = analyzedText . getTokensWithoutWhitespace ( ) ; for ( final AnalyzedTokenReadings reading : atr ) { if ( ! reading . isTagged ( ) ) { unknownWords . add ( reading . getToken ( ) ) ; } } } } public List < String > getUnknownWords ( ) { if ( ! listUnknownWords ) { throw new IllegalStateException ( "listUnknownWords is set to false, unknown words not stored" ) ; } final List < String > words = new ArrayList < > ( unknownWords ) ; Collections . sort ( words ) ; return words ; } static int countLineBreaks ( final String s ) { int pos = - 1 ; int count = 0 ; while ( true ) { final int nextPos = s . indexOf ( '\n' , pos + 1 ) ; if ( nextPos == - 1 ) { break ; } pos = nextPos ; count ++ ; } return count ; } public AnalyzedSentence getAnalyzedSentence ( final String sentence ) throws IOException { AnalyzedSentence analyzedSentence = language . getDisambiguator ( ) . disambiguate ( getRawAnalyzedSentence ( sentence ) ) ; if ( language . getPostDisambiguationChunker ( ) != null ) { language . getPostDisambiguationChunker ( ) . addChunkTags ( Arrays . asList ( analyzedSentence . getTokens ( ) ) ) ; } return analyzedSentence ; } public AnalyzedSentence getRawAnalyzedSentence ( final String sentence ) throws IOException { final List < String > tokens = language . getWordTokenizer ( ) . tokenize ( sentence ) ; final Map < Integer , String > softHyphenTokens = replaceSoftHyphens ( tokens ) ; final List < AnalyzedTokenReadings > aTokens = language . getTagger ( ) . tag ( tokens ) ; if ( language . getChunker ( ) != null ) { language . getChunker ( ) . addChunkTags ( aTokens ) ; } final int numTokens = aTokens . size ( ) ; int posFix = 0 ; for ( int i = 1 ; i < numTokens ; i ++ ) { aTokens . get ( i ) . setWhitespaceBefore ( aTokens . get ( i - 1 ) . isWhitespace ( ) ) ; aTokens . get ( i ) . setStartPos ( aTokens . get ( i ) . getStartPos ( ) + posFix ) ; if ( ! softHyphenTokens . isEmpty ( ) ) { if ( softHyphenTokens . get ( i ) != null ) { aTokens . get ( i ) . addReading ( language . getTagger ( ) . createToken ( softHyphenTokens . get ( i ) , null ) ) ; posFix += softHyphenTokens . get ( i ) . length ( ) - aTokens . get ( i ) . getToken ( ) . length ( ) ; } } } final AnalyzedTokenReadings [ ] tokenArray = new AnalyzedTokenReadings [ tokens . size ( ) + 1 ] ; final AnalyzedToken [ ] startTokenArray = new AnalyzedToken [ 1 ] ; int toArrayCount = 0 ; final AnalyzedToken sentenceStartToken = new AnalyzedToken ( "" , SENTENCE_START_TAGNAME , null ) ; startTokenArray [ 0 ] = sentenceStartToken ; tokenArray [ toArrayCount ++ ] = new AnalyzedTokenReadings ( startTokenArray , 0 ) ; int startPos = 0 ; for ( final AnalyzedTokenReadings posTag : aTokens ) { posTag . setStartPos ( startPos ) ; tokenArray [ toArrayCount ++ ] = posTag ; startPos += posTag . getToken ( ) . length ( ) ; } int lastToken = toArrayCount - 1 ; for ( int i = 0 ; i < toArrayCount - 1 ; i ++ ) { if ( ! tokenArray [ lastToken - i ] . isWhitespace ( ) ) { lastToken -= i ; break ; } } tokenArray [ lastToken ] . setSentEnd ( ) ; if ( tokenArray . length == lastToken + 1 && tokenArray [ lastToken ] . isLinebreak ( ) ) { tokenArray [ lastToken ] . setParagraphEnd ( ) ; } return new AnalyzedSentence ( tokenArray ) ; } private Map < Integer , String > replaceSoftHyphens ( List < String > tokens ) { Pattern ignoredCharacterRegex = language . getIgnoredCharactersRegex ( ) ; final Map < Integer , String > ignoredCharsTokens = new HashMap < > ( ) ; if ( ignoredCharacterRegex == null ) { return ignoredCharsTokens ; } for ( int i = 0 ; i < tokens . size ( ) ; i ++ ) { if ( ignoredCharacterRegex . matcher ( tokens . get ( i ) ) . find ( ) ) { ignoredCharsTokens . put ( i , tokens . get ( i ) ) ; tokens . set ( i , ignoredCharacterRegex . matcher ( tokens . get ( i ) ) . replaceAll ( "" ) ) ; } } return ignoredCharsTokens ; } public List < Rule > getAllRules ( ) { final List < Rule > rules = new ArrayList < > ( ) ; rules . addAll ( builtinRules ) ; rules . addAll ( userRules ) ; return rules ; } public List < Rule > getAllActiveRules ( ) { final List < Rule > rules = new ArrayList < > ( ) ; final List < Rule > rulesActive = new ArrayList < > ( ) ; rules . addAll ( builtinRules ) ; rules . addAll ( userRules ) ; for ( final Rule rule : rules ) { boolean isDisabled = disabledRules . contains ( rule . getId ( ) ) || ( rule . isDefaultOff ( ) && ! enabledRules . contains ( rule . getId ( ) ) ) ; if ( ! isDisabled ) { rulesActive . add ( rule ) ; } } return rulesActive ; } public List < PatternRule > getPatternRulesByIdAndSubId ( String Id , String subId ) { final List < Rule > rules = getAllRules ( ) ; final List < PatternRule > rulesById = new ArrayList < > ( ) ; for ( final Rule rule : rules ) { if ( rule instanceof PatternRule ) { if ( rule . getId ( ) . equals ( Id ) && ( ( PatternRule ) rule ) . getSubId ( ) . equals ( subId ) ) { rulesById . add ( ( PatternRule ) rule ) ; } } } return rulesById ; } public int getSentenceCount ( ) { return sentenceCount ; } protected void printIfVerbose ( final String s ) { if ( printStream != null ) { printStream . println ( s ) ; } } public static void addTemporaryFile ( final File file ) { temporaryFiles . add ( file ) ; } public static void removeTemporaryFiles ( ) { for ( File file : temporaryFiles ) { file . delete ( ) ; } } class TextCheckCallable implements Callable < List < RuleMatch > > { private final List < Rule > rules ; private final ParagraphHandling paraMode ; private final AnnotatedText annotatedText ; private final List < String > sentences ; private final List < AnalyzedSentence > analyzedSentences ; private int charCount ; private int lineCount ; private int columnCount ; TextCheckCallable ( List < Rule > rules , List < String > sentences , List < AnalyzedSentence > analyzedSentences , ParagraphHandling paraMode , AnnotatedText annotatedText , int charCount , int lineCount , int columnCount ) { this . rules = rules ; if ( sentences . size ( ) != analyzedSentences . size ( ) ) { throw new IllegalArgumentException ( "sentences and analyzedSentences do not have the same length : " + sentences . size ( ) + " != " + analyzedSentences . size ( ) ) ; } this . sentences = sentences ; this . analyzedSentences = analyzedSentences ; this . paraMode = paraMode ; this . annotatedText = annotatedText ; this . charCount = charCount ; this . lineCount = lineCount ; this . columnCount = columnCount ; } @ Override public List < RuleMatch > call ( ) throws Exception { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; int i = 0 ; for ( Rule rule : rules ) { if ( rule instanceof TextLevelRule && ! ignoreRule ( rule ) && paraMode != ParagraphHandling . ONLYNONPARA ) { RuleMatch [ ] matches = ( ( TextLevelRule ) rule ) . match ( analyzedSentences ) ; for ( RuleMatch match : matches ) { LineColumnRange range = getLineColumnRange ( match ) ; match . setColumn ( range . from . column ) ; match . setEndColumn ( range . to . column ) ; match . setLine ( range . from . line ) ; match . setEndLine ( range . to . line ) ; } ruleMatches . addAll ( Arrays . asList ( matches ) ) ; } } for ( final AnalyzedSentence analyzedSentence : analyzedSentences ) { final String sentence = sentences . get ( i ++ ) ; try { final List < RuleMatch > sentenceMatches = checkAnalyzedSentence ( paraMode , rules , charCount , lineCount , columnCount , sentence , analyzedSentence , annotatedText ) ; ruleMatches . addAll ( sentenceMatches ) ; charCount += sentence . length ( ) ; lineCount += countLineBreaks ( sentence ) ; final int lineBreakPos = sentence . lastIndexOf ( '\n' ) ; if ( lineBreakPos == - 1 ) { columnCount += sentence . length ( ) ; } else { if ( lineBreakPos == 0 ) { columnCount = sentence . length ( ) ; if ( ! language . getSentenceTokenizer ( ) . singleLineBreaksMarksPara ( ) ) { columnCount -- ; } } else { columnCount = sentence . length ( ) - lineBreakPos ; } } } catch ( Exception e ) { throw new RuntimeException ( "Could not check sentence: '" + StringUtils . abbreviate ( analyzedSentence . toTextString ( ) , 200 ) + "'" , e ) ; } } return ruleMatches ; } private LineColumnRange getLineColumnRange ( RuleMatch match ) { LineColumnPosition fromPos = new LineColumnPosition ( - 1 , - 1 ) ; LineColumnPosition toPos = new LineColumnPosition ( - 1 , - 1 ) ; LineColumnPosition pos = new LineColumnPosition ( 0 , 0 ) ; int charCount = 0 ; for ( AnalyzedSentence analyzedSentence : analyzedSentences ) { for ( AnalyzedTokenReadings readings : analyzedSentence . getTokens ( ) ) { String token = readings . getToken ( ) ; if ( "\n" . equals ( token ) ) { pos . line ++ ; pos . column = 0 ; } pos . column += token . length ( ) ; charCount += token . length ( ) ; if ( charCount == match . getFromPos ( ) ) { fromPos = new LineColumnPosition ( pos . line , pos . column ) ; } if ( charCount == match . getToPos ( ) ) { toPos = new LineColumnPosition ( pos . line , pos . column ) ; } } } return new LineColumnRange ( fromPos , toPos ) ; } private class LineColumnPosition { int line ; int column ; private LineColumnPosition ( int line , int column ) { this . line = line ; this . column = column ; } } private class LineColumnRange { LineColumnPosition from ; LineColumnPosition to ; private LineColumnRange ( LineColumnPosition from , LineColumnPosition to ) { this . from = from ; this . to = to ; } } } }
package org . languagetool ; import java . util . Objects ; import org . apache . commons . lang . builder . EqualsBuilder ; import org . apache . commons . lang . builder . HashCodeBuilder ; import org . jetbrains . annotations . Nullable ; public final class AnalyzedToken { private final String token ; private final String posTag ; private final String lemma ; private final String tokenInflected ; private boolean isWhitespaceBefore ; private boolean hasNoPOSTag ; public AnalyzedToken ( final String token , final String posTag , final String lemma ) { this . token = Objects . requireNonNull ( token , "token cannot be null" ) ; this . posTag = posTag ; this . lemma = lemma ; if ( lemma == null ) { tokenInflected = token ; } else { tokenInflected = lemma ; } hasNoPOSTag = ( posTag == null || JLanguageTool . SENTENCE_END_TAGNAME . equals ( posTag ) || JLanguageTool . PARAGRAPH_END_TAGNAME . equals ( posTag ) ) ; } public String getToken ( ) { return token ; } @ Nullable public String getPOSTag ( ) { return posTag ; } @ Nullable public String getLemma ( ) { return lemma ; } public String getTokenInflected ( ) { return tokenInflected ; } public void setWhitespaceBefore ( boolean whitespaceBefore ) { isWhitespaceBefore = whitespaceBefore ; } public boolean isWhitespaceBefore ( ) { return isWhitespaceBefore ; } public boolean matches ( final AnalyzedToken an ) { if ( this . equals ( an ) ) { return true ; } if ( "" . equals ( an . getToken ( ) ) && an . getLemma ( ) == null && an . getPOSTag ( ) == null ) { return false ; } boolean found = true ; if ( ! "" . equals ( an . getToken ( ) ) ) { found = an . getToken ( ) . equals ( this . token ) ; } if ( an . getLemma ( ) != null ) { found &= an . getLemma ( ) . equals ( this . lemma ) ; } if ( an . getPOSTag ( ) != null ) { found &= an . getPOSTag ( ) . equals ( this . posTag ) ; } return found ; } public boolean hasNoTag ( ) { return hasNoPOSTag ; } public void setNoPOSTag ( boolean noTag ) { hasNoPOSTag = noTag ; } @ Override public String toString ( ) { return tokenInflected + '/' + posTag ; } @ Override public int hashCode ( ) { return new HashCodeBuilder ( ) . append ( isWhitespaceBefore ) . append ( lemma ) . append ( posTag ) . append ( token ) . toHashCode ( ) ; } @ Override public boolean equals ( final Object obj ) { if ( obj == null ) { return false ; } if ( obj == this ) { return true ; } if ( obj . getClass ( ) != getClass ( ) ) { return false ; } final AnalyzedToken rhs = ( AnalyzedToken ) obj ; return new EqualsBuilder ( ) . append ( token , rhs . token ) . append ( posTag , rhs . posTag ) . append ( lemma , rhs . lemma ) . append ( isWhitespaceBefore , rhs . isWhitespaceBefore ) . isEquals ( ) ; } }
package org . languagetool . rules . nl ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Dutch ; import org . languagetool . rules . patterns . PatternRule ; import java . io . IOException ; import java . util . Collections ; import java . util . List ; public class UppercaseSentenceStartRuleTest extends TestCase { public void testDutchSpecialCases ( ) throws IOException { final JLanguageTool lt = new JLanguageTool ( new Dutch ( ) { @ Override protected synchronized List < PatternRule > getPatternRules ( ) { return Collections . emptyList ( ) ; } } ) ; assertEquals ( 1 , lt . check ( "A sentence." ) . size ( ) ) ; assertEquals ( 0 , lt . check ( "'s Morgens..." ) . size ( ) ) ; assertEquals ( 2 , lt . check ( "a sentence." ) . size ( ) ) ; assertEquals ( 1 , lt . check ( "'s morgens..." ) . size ( ) ) ; assertEquals ( 2 , lt . check ( "s sentence." ) . size ( ) ) ; } }
package org . languagetool ; import java . util . * ; import java . util . concurrent . atomic . AtomicInteger ; import java . util . regex . Pattern ; import org . apache . commons . lang . StringUtils ; import org . apache . commons . lang . builder . EqualsBuilder ; import org . languagetool . chunking . ChunkTag ; import org . languagetool . tools . StringTools ; import static org . languagetool . JLanguageTool . * ; public final class AnalyzedTokenReadings implements Iterable < AnalyzedToken > { private final boolean isWhitespace ; private final boolean isLinebreak ; private final boolean isSentStart ; private AnalyzedToken [ ] anTokReadings ; private int startPos ; private String token ; private List < ChunkTag > chunkTags = new ArrayList < > ( ) ; private boolean isSentEnd ; private boolean isParaEnd ; private boolean isWhitespaceBefore ; private boolean isImmunized ; private boolean isIgnoredBySpeller ; private String historicalAnnotations = "" ; private boolean hasSameLemmas ; public AnalyzedTokenReadings ( final AnalyzedToken [ ] tokens , final int startPos ) { this ( Arrays . asList ( tokens ) , startPos ) ; } public AnalyzedTokenReadings ( final AnalyzedToken token , final int startPos ) { this ( Collections . singletonList ( token ) , startPos ) ; } public AnalyzedTokenReadings ( final List < AnalyzedToken > tokens , final int startPos ) { anTokReadings = tokens . toArray ( new AnalyzedToken [ tokens . size ( ) ] ) ; this . startPos = startPos ; token = anTokReadings [ 0 ] . getToken ( ) ; isWhitespace = StringTools . isWhitespace ( token ) ; isWhitespaceBefore = anTokReadings [ 0 ] . isWhitespaceBefore ( ) ; isLinebreak = "\n" . equals ( token ) || "\r\n" . equals ( token ) || "\r" . equals ( token ) || "\n\r" . equals ( token ) ; isSentStart = SENTENCE_START_TAGNAME . equals ( anTokReadings [ 0 ] . getPOSTag ( ) ) ; isParaEnd = hasPosTag ( PARAGRAPH_END_TAGNAME ) ; isSentEnd = hasPosTag ( SENTENCE_END_TAGNAME ) ; setNoRealPOStag ( ) ; hasSameLemmas = areLemmasSame ( ) ; } AnalyzedTokenReadings ( final AnalyzedToken token ) { this ( Collections . singletonList ( token ) , 0 ) ; } public List < AnalyzedToken > getReadings ( ) { return Arrays . asList ( anTokReadings ) ; } public AnalyzedToken getAnalyzedToken ( final int idx ) { return anTokReadings [ idx ] ; } public boolean hasPosTag ( final String posTag ) { boolean found = false ; for ( final AnalyzedToken reading : anTokReadings ) { if ( reading . getPOSTag ( ) != null ) { found = posTag . equals ( reading . getPOSTag ( ) ) ; if ( found ) { break ; } } } return found ; } public boolean hasLemma ( final String lemma ) { boolean found = false ; for ( final AnalyzedToken reading : anTokReadings ) { if ( reading . getLemma ( ) != null ) { found = lemma . equals ( reading . getLemma ( ) ) ; if ( found ) { break ; } } } return found ; } public boolean hasPartialPosTag ( final String posTag ) { boolean found = false ; for ( AnalyzedToken reading : anTokReadings ) { if ( reading . getPOSTag ( ) != null ) { found = reading . getPOSTag ( ) . contains ( posTag ) ; if ( found ) { break ; } } } return found ; } public boolean matchesPosTagRegex ( final String posTagRegex ) { Pattern pattern = Pattern . compile ( posTagRegex ) ; boolean found = false ; for ( AnalyzedToken reading : anTokReadings ) { if ( reading . getPOSTag ( ) != null ) { found = pattern . matcher ( reading . getPOSTag ( ) ) . matches ( ) ; if ( found ) { break ; } } } return found ; } public void addReading ( final AnalyzedToken token ) { final List < AnalyzedToken > l = new ArrayList < > ( ) ; l . addAll ( Arrays . asList ( anTokReadings ) . subList ( 0 , anTokReadings . length - 1 ) ) ; if ( anTokReadings [ anTokReadings . length - 1 ] . getPOSTag ( ) != null ) { l . add ( anTokReadings [ anTokReadings . length - 1 ] ) ; } token . setWhitespaceBefore ( isWhitespaceBefore ) ; l . add ( token ) ; anTokReadings = l . toArray ( new AnalyzedToken [ l . size ( ) ] ) ; if ( token . getToken ( ) . length ( ) > this . token . length ( ) ) { this . token = token . getToken ( ) ; } anTokReadings [ anTokReadings . length - 1 ] . setWhitespaceBefore ( isWhitespaceBefore ) ; isParaEnd = hasPosTag ( PARAGRAPH_END_TAGNAME ) ; isSentEnd = hasPosTag ( SENTENCE_END_TAGNAME ) ; setNoRealPOStag ( ) ; hasSameLemmas = areLemmasSame ( ) ; } public void removeReading ( final AnalyzedToken token ) { final List < AnalyzedToken > l = new ArrayList < > ( ) ; final AnalyzedToken tmpTok = new AnalyzedToken ( token . getToken ( ) , token . getPOSTag ( ) , token . getLemma ( ) ) ; tmpTok . setWhitespaceBefore ( isWhitespaceBefore ) ; for ( AnalyzedToken anTokReading : anTokReadings ) { if ( ! anTokReading . matches ( tmpTok ) ) { l . add ( anTokReading ) ; } } if ( l . isEmpty ( ) ) { l . add ( new AnalyzedToken ( this . token , null , null ) ) ; l . get ( 0 ) . setWhitespaceBefore ( isWhitespaceBefore ) ; } anTokReadings = l . toArray ( new AnalyzedToken [ l . size ( ) ] ) ; setNoRealPOStag ( ) ; hasSameLemmas = areLemmasSame ( ) ; } public void leaveReading ( final AnalyzedToken token ) { final List < AnalyzedToken > l = new ArrayList < > ( ) ; final AnalyzedToken tmpTok = new AnalyzedToken ( token . getToken ( ) , token . getPOSTag ( ) , token . getLemma ( ) ) ; tmpTok . setWhitespaceBefore ( isWhitespaceBefore ) ; for ( AnalyzedToken anTokReading : anTokReadings ) { if ( anTokReading . matches ( tmpTok ) ) { l . add ( anTokReading ) ; } } if ( l . isEmpty ( ) ) { l . add ( new AnalyzedToken ( this . token , null , null ) ) ; l . get ( 0 ) . setWhitespaceBefore ( isWhitespaceBefore ) ; } anTokReadings = l . toArray ( new AnalyzedToken [ l . size ( ) ] ) ; setNoRealPOStag ( ) ; hasSameLemmas = areLemmasSame ( ) ; } public int getReadingsLength ( ) { return anTokReadings . length ; } public boolean isWhitespace ( ) { return isWhitespace ; } public boolean isLinebreak ( ) { return isLinebreak ; } public boolean isSentenceStart ( ) { return isSentStart ; } public boolean isParagraphEnd ( ) { return isParaEnd ; } public void setParagraphEnd ( ) { if ( ! isParagraphEnd ( ) ) { final AnalyzedToken paragraphEnd = new AnalyzedToken ( getToken ( ) , PARAGRAPH_END_TAGNAME , getAnalyzedToken ( 0 ) . getLemma ( ) ) ; addReading ( paragraphEnd ) ; } } public boolean isSentenceEnd ( ) { return isSentEnd ; } public boolean isFieldCode ( ) { return "\u0001" . equals ( token ) || "\u0002" . equals ( token ) ; } public void setSentEnd ( ) { if ( ! isSentenceEnd ( ) ) { final AnalyzedToken sentenceEnd = new AnalyzedToken ( getToken ( ) , SENTENCE_END_TAGNAME , getAnalyzedToken ( 0 ) . getLemma ( ) ) ; addReading ( sentenceEnd ) ; } } public int getStartPos ( ) { return startPos ; } public int getEndPos ( ) { return startPos + token . length ( ) ; } public void setStartPos ( final int position ) { startPos = position ; } public String getToken ( ) { return token ; } public void setWhitespaceBefore ( final boolean isWhiteSpaceBefore ) { isWhitespaceBefore = isWhiteSpaceBefore ; for ( AnalyzedToken aTok : anTokReadings ) { aTok . setWhitespaceBefore ( isWhiteSpaceBefore ) ; } } public boolean isWhitespaceBefore ( ) { return isWhitespaceBefore ; } public void immunize ( ) { isImmunized = true ; } public boolean isImmunized ( ) { return isImmunized ; } public void ignoreSpelling ( ) { isIgnoredBySpeller = true ; } public boolean isIgnoredBySpeller ( ) { return isIgnoredBySpeller ; } private void setNoRealPOStag ( ) { boolean hasNoPOStag = ! isLinebreak ( ) ; for ( AnalyzedToken an : anTokReadings ) { String posTag = an . getPOSTag ( ) ; if ( PARAGRAPH_END_TAGNAME . equals ( posTag ) || SENTENCE_END_TAGNAME . equals ( posTag ) ) { continue ; } if ( posTag != null ) { hasNoPOStag = false ; } } for ( AnalyzedToken an : anTokReadings ) { an . setNoPOSTag ( hasNoPOStag ) ; } } public String getHistoricalAnnotations ( ) { return historicalAnnotations ; } public void setHistoricalAnnotations ( String historicalAnnotations ) { this . historicalAnnotations = historicalAnnotations ; } public void setChunkTags ( List < ChunkTag > chunkTags ) { this . chunkTags = Objects . requireNonNull ( chunkTags ) ; } public List < ChunkTag > getChunkTags ( ) { return chunkTags ; } @ Override public String toString ( ) { final StringBuilder sb = new StringBuilder ( ) ; sb . append ( token ) ; sb . append ( '[' ) ; for ( AnalyzedToken element : anTokReadings ) { sb . append ( element ) ; if ( ! element . isWhitespaceBefore ( ) ) { sb . append ( '*' ) ; } sb . append ( ',' ) ; } sb . delete ( sb . length ( ) - 1 , sb . length ( ) ) ; if ( chunkTags . size ( ) > 0 ) { sb . append ( ',' ) ; sb . append ( StringUtils . join ( chunkTags , "|" ) ) ; } sb . append ( ']' ) ; if ( isImmunized ( ) ) { sb . append ( "{!}," ) ; } return sb . toString ( ) ; } public boolean isTagged ( ) { for ( AnalyzedToken element : anTokReadings ) { if ( ! element . hasNoTag ( ) ) { return true ; } } return false ; } private boolean areLemmasSame ( ) { String previousLemma = anTokReadings [ 0 ] . getLemma ( ) ; if ( previousLemma == null ) { for ( AnalyzedToken element : anTokReadings ) { if ( element . getLemma ( ) != null ) { return false ; } } return true ; } for ( AnalyzedToken element : anTokReadings ) { if ( ! previousLemma . equals ( element . getLemma ( ) ) ) { return false ; } } return true ; } public boolean hasSameLemmas ( ) { return hasSameLemmas ; } @ Override public int hashCode ( ) { return Arrays . hashCode ( anTokReadings ) + Objects . hash ( isLinebreak , isParaEnd , isSentEnd , isSentStart , isWhitespace , isWhitespaceBefore , chunkTags , startPos , token ) ; } @ Override public boolean equals ( Object obj ) { if ( this == obj ) { return true ; } if ( obj == null ) { return false ; } if ( getClass ( ) != obj . getClass ( ) ) { return false ; } final AnalyzedTokenReadings other = ( AnalyzedTokenReadings ) obj ; return new EqualsBuilder ( ) . append ( anTokReadings , other . anTokReadings ) . append ( isLinebreak , other . isLinebreak ) . append ( isParaEnd , other . isParaEnd ) . append ( isSentEnd , other . isSentEnd ) . append ( isSentStart , other . isSentStart ) . append ( isWhitespace , other . isWhitespace ) . append ( isWhitespaceBefore , other . isWhitespaceBefore ) . append ( isImmunized , other . isImmunized ) . append ( startPos , other . startPos ) . append ( chunkTags , other . chunkTags ) . append ( hasSameLemmas , other . hasSameLemmas ) . append ( isIgnoredBySpeller , other . isIgnoredBySpeller ) . append ( token , other . token ) . isEquals ( ) ; } @ Override public Iterator < AnalyzedToken > iterator ( ) { final AtomicInteger i = new AtomicInteger ( 0 ) ; return new Iterator < AnalyzedToken > ( ) { @ Override public boolean hasNext ( ) { return i . get ( ) < getReadingsLength ( ) ; } @ Override public AnalyzedToken next ( ) { try { return anTokReadings [ i . getAndAdd ( 1 ) ] ; } catch ( ArrayIndexOutOfBoundsException e ) { throw new NoSuchElementException ( "No such element: " + i + ", element count: " + anTokReadings . length ) ; } } @ Override public void remove ( ) { throw new UnsupportedOperationException ( ) ; } } ; } }
package org . languagetool ; import org . jetbrains . annotations . Nullable ; import org . languagetool . chunking . Chunker ; import org . languagetool . databroker . ResourceDataBroker ; import org . languagetool . language . Contributor ; import org . languagetool . languagemodel . LanguageModel ; import org . languagetool . rules . Rule ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . rules . patterns . PatternRuleLoader ; import org . languagetool . rules . patterns . Unifier ; import org . languagetool . rules . patterns . UnifierConfiguration ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . xx . DemoDisambiguator ; import org . languagetool . tagging . xx . DemoTagger ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . SimpleSentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . io . InputStream ; import java . util . * ; import java . util . regex . Pattern ; public abstract class Language { private static final Disambiguator DEMO_DISAMBIGUATOR = new DemoDisambiguator ( ) ; private static final Tagger DEMO_TAGGER = new DemoTagger ( ) ; private static final SentenceTokenizer SENTENCE_TOKENIZER = new SimpleSentenceTokenizer ( ) ; private static final WordTokenizer WORD_TOKENIZER = new WordTokenizer ( ) ; private final UnifierConfiguration unifierConfig = new UnifierConfiguration ( ) ; private final UnifierConfiguration disambiguationUnifierConfig = new UnifierConfiguration ( ) ; private boolean isExternalLanguage = false ; private Pattern ignoredCharactersRegex = Pattern . compile ( "[\u00AD]" ) ; private List < PatternRule > patternRules ; public abstract String getShortName ( ) ; public abstract String getName ( ) ; public abstract String [ ] getCountries ( ) ; @ Nullable public abstract Contributor [ ] getMaintainers ( ) ; public abstract List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException ; @ Nullable public String getVariant ( ) { return null ; } public List < String > getDefaultEnabledRulesForVariant ( ) { return Collections . emptyList ( ) ; } public List < String > getDefaultDisabledRulesForVariant ( ) { return Collections . emptyList ( ) ; } @ Nullable public LanguageModel getLanguageModel ( File indexDir ) throws IOException { return null ; } public List < Rule > getRelevantLanguageModelRules ( ResourceBundle messages , LanguageModel languageModel ) throws IOException { return Collections . emptyList ( ) ; } public Locale getLocale ( ) { return new Locale ( getShortName ( ) ) ; } public Locale getLocaleWithCountryAndVariant ( ) { if ( getCountries ( ) . length > 0 ) { if ( getVariant ( ) != null ) { return new Locale ( getShortName ( ) , getCountries ( ) [ 0 ] , getVariant ( ) ) ; } else { return new Locale ( getShortName ( ) , getCountries ( ) [ 0 ] ) ; } } else { return getLocale ( ) ; } } public List < String > getRuleFileNames ( ) { final List < String > ruleFiles = new ArrayList < > ( ) ; final ResourceDataBroker dataBroker = JLanguageTool . getDataBroker ( ) ; ruleFiles . add ( dataBroker . getRulesDir ( ) + "/" + getShortName ( ) + "/" + JLanguageTool . PATTERN_FILE ) ; if ( getShortNameWithCountryAndVariant ( ) . length ( ) > 2 ) { final String fileName = getShortName ( ) + "/" + getShortNameWithCountryAndVariant ( ) + "/" + JLanguageTool . PATTERN_FILE ; if ( dataBroker . ruleFileExists ( fileName ) ) { ruleFiles . add ( dataBroker . getRulesDir ( ) + "/" + fileName ) ; } } return ruleFiles ; } @ Nullable public Language getDefaultLanguageVariant ( ) { return null ; } public Disambiguator getDisambiguator ( ) { return DEMO_DISAMBIGUATOR ; } public Tagger getTagger ( ) { return DEMO_TAGGER ; } public SentenceTokenizer getSentenceTokenizer ( ) { return SENTENCE_TOKENIZER ; } public Tokenizer getWordTokenizer ( ) { return WORD_TOKENIZER ; } @ Nullable public Chunker getChunker ( ) { return null ; } @ Nullable public Chunker getPostDisambiguationChunker ( ) { return null ; } @ Nullable public Synthesizer getSynthesizer ( ) { return null ; } public Unifier getUnifier ( ) { return unifierConfig . createUnifier ( ) ; } public Unifier getDisambiguationUnifier ( ) { return disambiguationUnifierConfig . createUnifier ( ) ; } public UnifierConfiguration getUnifierConfiguration ( ) { return unifierConfig ; } public UnifierConfiguration getDisambiguationUnifierConfiguration ( ) { return disambiguationUnifierConfig ; } public final String getTranslatedName ( final ResourceBundle messages ) { try { return messages . getString ( getShortNameWithCountryAndVariant ( ) ) ; } catch ( final MissingResourceException e ) { try { return messages . getString ( getShortName ( ) ) ; } catch ( final MissingResourceException e1 ) { return getName ( ) ; } } } public final String getShortNameWithCountryAndVariant ( ) { String name = getShortName ( ) ; if ( getCountries ( ) . length == 1 && ! name . contains ( "-x-" ) ) { name += "-" + getCountries ( ) [ 0 ] ; if ( getVariant ( ) != null ) { name += "-" + getVariant ( ) ; } } return name ; } @ SuppressWarnings ( "resource" ) protected synchronized List < PatternRule > getPatternRules ( ) throws IOException { if ( patternRules == null ) { List < PatternRule > rules = new ArrayList < > ( ) ; PatternRuleLoader ruleLoader = new PatternRuleLoader ( ) ; for ( String fileName : getRuleFileNames ( ) ) { InputStream is = null ; try { is = this . getClass ( ) . getResourceAsStream ( fileName ) ; if ( is == null ) { is = new FileInputStream ( fileName ) ; } rules . addAll ( ruleLoader . getRules ( is , fileName ) ) ; patternRules = Collections . unmodifiableList ( rules ) ; } finally { if ( is != null ) { is . close ( ) ; } } } } return patternRules ; } @ Override public final String toString ( ) { return getName ( ) ; } public final boolean isVariant ( ) { for ( Language language : Languages . get ( ) ) { final boolean skip = language . getShortNameWithCountryAndVariant ( ) . equals ( getShortNameWithCountryAndVariant ( ) ) ; if ( ! skip && language . getClass ( ) . isAssignableFrom ( getClass ( ) ) ) { return true ; } } return false ; } public final boolean hasVariant ( ) { for ( Language language : Languages . get ( ) ) { final boolean skip = language . getShortNameWithCountryAndVariant ( ) . equals ( getShortNameWithCountryAndVariant ( ) ) ; if ( ! skip && getClass ( ) . isAssignableFrom ( language . getClass ( ) ) ) { return true ; } } return false ; } public boolean isExternal ( ) { return isExternalLanguage ; } public void makeExternal ( ) { isExternalLanguage = true ; } public boolean equalsConsiderVariantsIfSpecified ( Language otherLanguage ) { if ( getShortName ( ) . equals ( otherLanguage . getShortName ( ) ) ) { final boolean thisHasCountry = hasCountry ( ) ; final boolean otherHasCountry = otherLanguage . hasCountry ( ) ; return ! ( thisHasCountry && otherHasCountry ) || getShortNameWithCountryAndVariant ( ) . equals ( otherLanguage . getShortNameWithCountryAndVariant ( ) ) ; } else { return false ; } } private boolean hasCountry ( ) { return getCountries ( ) . length == 1 ; } public Pattern getIgnoredCharactersRegex ( ) { return ignoredCharactersRegex ; } public void setIgnoredCharactersRegex ( String ignoredCharactersRegex ) { this . ignoredCharactersRegex = Pattern . compile ( ignoredCharactersRegex ) ; } }
package org . languagetool ; import org . apache . commons . lang . StringUtils ; import java . util . * ; public final class AnalyzedSentence { private final AnalyzedTokenReadings [ ] tokens ; private final AnalyzedTokenReadings [ ] nonBlankTokens ; private final int [ ] whPositions ; private final Set < String > tokenSet ; private final Set < String > lemmaSet ; public AnalyzedSentence ( AnalyzedTokenReadings [ ] tokens ) { this . tokens = tokens ; int whCounter = 0 ; int nonWhCounter = 0 ; final int [ ] mapping = new int [ tokens . length + 1 ] ; final List < AnalyzedTokenReadings > l = new ArrayList < > ( ) ; for ( final AnalyzedTokenReadings token : tokens ) { if ( ! token . isWhitespace ( ) || token . isSentenceStart ( ) || token . isSentenceEnd ( ) || token . isParagraphEnd ( ) ) { l . add ( token ) ; mapping [ nonWhCounter ] = whCounter ; nonWhCounter ++ ; } whCounter ++ ; } this . whPositions = mapping ; this . nonBlankTokens = l . toArray ( new AnalyzedTokenReadings [ l . size ( ) ] ) ; this . tokenSet = getTokenSet ( tokens ) ; this . lemmaSet = getLemmaSet ( tokens ) ; } private AnalyzedSentence ( AnalyzedTokenReadings [ ] tokens , int [ ] mapping , AnalyzedTokenReadings [ ] nonBlankTokens ) { this . tokens = tokens ; this . whPositions = mapping ; this . nonBlankTokens = nonBlankTokens ; this . tokenSet = getTokenSet ( tokens ) ; this . lemmaSet = getLemmaSet ( tokens ) ; } private Set < String > getTokenSet ( AnalyzedTokenReadings [ ] tokens ) { Set < String > tokenSet = new HashSet < > ( ) ; for ( AnalyzedTokenReadings token : tokens ) { tokenSet . add ( token . getToken ( ) . toLowerCase ( ) ) ; } return Collections . unmodifiableSet ( tokenSet ) ; } private Set < String > getLemmaSet ( AnalyzedTokenReadings [ ] tokens ) { Set < String > lemmaSet = new HashSet < > ( ) ; for ( AnalyzedTokenReadings token : tokens ) { for ( AnalyzedToken lemmaTok : token . getReadings ( ) ) { if ( lemmaTok . getLemma ( ) != null ) { lemmaSet . add ( lemmaTok . getLemma ( ) . toLowerCase ( ) ) ; } else { lemmaSet . add ( lemmaTok . getToken ( ) . toLowerCase ( ) ) ; } } } return Collections . unmodifiableSet ( lemmaSet ) ; } public AnalyzedSentence copy ( AnalyzedSentence sentence ) { AnalyzedTokenReadings [ ] copyTokens = new AnalyzedTokenReadings [ sentence . getTokens ( ) . length ] ; for ( int i = 0 ; i < copyTokens . length ; i ++ ) { AnalyzedTokenReadings analyzedTokens = sentence . getTokens ( ) [ i ] ; copyTokens [ i ] = new AnalyzedTokenReadings ( analyzedTokens . getReadings ( ) , analyzedTokens . getStartPos ( ) ) ; copyTokens [ i ] . setHistoricalAnnotations ( analyzedTokens . getHistoricalAnnotations ( ) ) ; copyTokens [ i ] . setChunkTags ( analyzedTokens . getChunkTags ( ) ) ; if ( analyzedTokens . isImmunized ( ) ) { copyTokens [ i ] . immunize ( ) ; } if ( analyzedTokens . isIgnoredBySpeller ( ) ) { copyTokens [ i ] . ignoreSpelling ( ) ; } copyTokens [ i ] . setWhitespaceBefore ( sentence . getTokens ( ) [ i ] . isWhitespaceBefore ( ) ) ; } return new AnalyzedSentence ( copyTokens , sentence . whPositions , sentence . getTokensWithoutWhitespace ( ) ) ; } public AnalyzedTokenReadings [ ] getTokens ( ) { return tokens ; } public AnalyzedTokenReadings [ ] getTokensWithoutWhitespace ( ) { return nonBlankTokens . clone ( ) ; } public int getOriginalPosition ( int nonWhPosition ) { return whPositions [ nonWhPosition ] ; } @ Override public String toString ( ) { return toString ( "," ) ; } public String toShortString ( String readingDelimiter ) { return toString ( readingDelimiter , false ) ; } public String getText ( ) { StringBuilder sb = new StringBuilder ( ) ; for ( AnalyzedTokenReadings element : tokens ) { sb . append ( element . getToken ( ) ) ; } return sb . toString ( ) ; } String toTextString ( ) { return getText ( ) ; } public String toString ( String readingDelimiter ) { return toString ( readingDelimiter , true ) ; } private String toString ( String readingDelimiter , boolean includeChunks ) { final StringBuilder sb = new StringBuilder ( ) ; for ( AnalyzedTokenReadings element : tokens ) { if ( ! element . isWhitespace ( ) ) { sb . append ( element . getToken ( ) ) ; sb . append ( '[' ) ; } Iterator < AnalyzedToken > iterator = element . iterator ( ) ; while ( iterator . hasNext ( ) ) { final AnalyzedToken token = iterator . next ( ) ; final String posTag = token . getPOSTag ( ) ; if ( element . isSentenceStart ( ) ) { sb . append ( "<S>" ) ; } else if ( JLanguageTool . SENTENCE_END_TAGNAME . equals ( posTag ) ) { sb . append ( "</S>" ) ; } else if ( JLanguageTool . PARAGRAPH_END_TAGNAME . equals ( posTag ) ) { sb . append ( "<P/>" ) ; } else if ( posTag == null && ! includeChunks ) { sb . append ( token . getToken ( ) ) ; } else { if ( ! element . isWhitespace ( ) ) { sb . append ( token ) ; if ( iterator . hasNext ( ) ) { sb . append ( readingDelimiter ) ; } } } } if ( ! element . isWhitespace ( ) ) { if ( includeChunks && element . getChunkTags ( ) . size ( ) > 0 ) { sb . append ( ',' ) ; sb . append ( StringUtils . join ( element . getChunkTags ( ) , "|" ) ) ; } if ( element . isImmunized ( ) ) { sb . append ( "{!}" ) ; } sb . append ( ']' ) ; } else { sb . append ( ' ' ) ; } } return sb . toString ( ) ; } public String getAnnotations ( ) { final StringBuilder sb = new StringBuilder ( 40 ) ; sb . append ( "Disambiguator log: \n" ) ; for ( AnalyzedTokenReadings element : tokens ) { if ( ! element . isWhitespace ( ) && ! "" . equals ( element . getHistoricalAnnotations ( ) ) ) { sb . append ( element . getHistoricalAnnotations ( ) ) ; sb . append ( '\n' ) ; } } return sb . toString ( ) ; } public Set < String > getTokenSet ( ) { return tokenSet ; } public Set < String > getLemmaSet ( ) { return lemmaSet ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( obj == null ) return false ; if ( getClass ( ) != obj . getClass ( ) ) return false ; final AnalyzedSentence other = ( AnalyzedSentence ) obj ; if ( ! Arrays . equals ( nonBlankTokens , other . nonBlankTokens ) ) return false ; if ( ! Arrays . equals ( tokens , other . tokens ) ) return false ; if ( ! Arrays . equals ( whPositions , other . whPositions ) ) return false ; return true ; } @ Override public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + Arrays . hashCode ( nonBlankTokens ) ; result = prime * result + Arrays . hashCode ( tokens ) ; result = prime * result + Arrays . hashCode ( whPositions ) ; return result ; } }
package org . languagetool ; import java . util . Locale ; import java . util . MissingResourceException ; import java . util . ResourceBundle ; import static org . languagetool . JLanguageTool . MESSAGE_BUNDLE ; final class ResourceBundleTools { private ResourceBundleTools ( ) { } public static ResourceBundle getMessageBundle ( ) { try { final ResourceBundle bundle = ResourceBundle . getBundle ( MESSAGE_BUNDLE ) ; final ResourceBundle fallbackBundle = ResourceBundle . getBundle ( MESSAGE_BUNDLE , Locale . ENGLISH ) ; return new ResourceBundleWithFallback ( bundle , fallbackBundle ) ; } catch ( final MissingResourceException e ) { return ResourceBundle . getBundle ( MESSAGE_BUNDLE , Locale . ENGLISH ) ; } } static ResourceBundle getMessageBundle ( final Language lang ) { try { ResourceBundle bundle = ResourceBundle . getBundle ( MESSAGE_BUNDLE , lang . getLocaleWithCountryAndVariant ( ) ) ; if ( ! isValidBundleFor ( lang , bundle ) ) { bundle = ResourceBundle . getBundle ( MESSAGE_BUNDLE , lang . getLocale ( ) ) ; if ( ! isValidBundleFor ( lang , bundle ) ) { final Language defaultVariant = lang . getDefaultLanguageVariant ( ) ; if ( defaultVariant != null && defaultVariant . getCountries ( ) . length > 0 ) { final Locale locale = new Locale ( defaultVariant . getShortName ( ) , defaultVariant . getCountries ( ) [ 0 ] ) ; bundle = ResourceBundle . getBundle ( MESSAGE_BUNDLE , locale ) ; } } } final ResourceBundle fallbackBundle = ResourceBundle . getBundle ( MESSAGE_BUNDLE , Locale . ENGLISH ) ; return new ResourceBundleWithFallback ( bundle , fallbackBundle ) ; } catch ( final MissingResourceException e ) { return ResourceBundle . getBundle ( MESSAGE_BUNDLE , Locale . ENGLISH ) ; } } private static boolean isValidBundleFor ( final Language lang , final ResourceBundle bundle ) { return lang . getLocale ( ) . getLanguage ( ) . equals ( bundle . getLocale ( ) . getLanguage ( ) ) ; } }
package org . languagetool . language ; import java . io . File ; import java . io . IOException ; import java . util . * ; import org . jetbrains . annotations . Nullable ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . chunking . Chunker ; import org . languagetool . languagemodel . LanguageModel ; import org . languagetool . rules . Rule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; public final class LanguageBuilder { private LanguageBuilder ( ) { } public static Language makeAdditionalLanguage ( final File file ) throws InstantiationException , IllegalAccessException { return makeLanguage ( file , true ) ; } private static Language makeLanguage ( final File file , final boolean isAdditional ) throws IllegalAccessException , InstantiationException { Objects . requireNonNull ( file , "file cannot be null" ) ; if ( ! file . getName ( ) . endsWith ( ".xml" ) ) { throw new RuleFilenameException ( file ) ; } final String [ ] parts = file . getName ( ) . split ( "-" ) ; final boolean startsWithRules = parts [ 0 ] . equals ( "rules" ) ; final boolean secondPartHasCorrectLength = parts . length == 3 && ( parts [ 1 ] . length ( ) == "en" . length ( ) || parts [ 1 ] . length ( ) == "ast" . length ( ) || parts [ 1 ] . length ( ) == "en_US" . length ( ) ) ; if ( ! startsWithRules || ! secondPartHasCorrectLength ) { throw new RuleFilenameException ( file ) ; } Language newLanguage ; if ( Languages . isLanguageSupported ( parts [ 1 ] ) ) { Language baseLanguage = Languages . getLanguageForShortName ( parts [ 1 ] ) . getClass ( ) . newInstance ( ) ; newLanguage = new ExtendedLanguage ( baseLanguage , parts [ 2 ] . replace ( ".xml" , "" ) , file ) ; } else { newLanguage = new Language ( ) { @ Override public Locale getLocale ( ) { return new Locale ( getShortName ( ) ) ; } @ Override public Contributor [ ] getMaintainers ( ) { return null ; } @ Override public String getShortName ( ) { if ( parts [ 1 ] . length ( ) == 2 ) { return parts [ 1 ] ; } return parts [ 1 ] . split ( "_" ) [ 0 ] ; } @ Override public String [ ] getCountries ( ) { if ( parts [ 1 ] . length ( ) == 2 ) { return new String [ ] { "" } ; } return new String [ ] { parts [ 1 ] . split ( "_" ) [ 1 ] } ; } @ Override public String getName ( ) { return parts [ 2 ] . replace ( ".xml" , "" ) ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Collections . emptyList ( ) ; } @ Override public List < String > getRuleFileNames ( ) { final List < String > ruleFiles = new ArrayList < > ( ) ; ruleFiles . add ( file . getAbsolutePath ( ) ) ; return ruleFiles ; } @ Override public boolean isExternal ( ) { return isAdditional ; } } ; } return newLanguage ; } static class ExtendedLanguage extends Language { private final Language baseLanguage ; private final String name ; private final File ruleFile ; ExtendedLanguage ( Language baseLanguage , String name , File ruleFile ) { this . baseLanguage = baseLanguage ; this . name = name ; this . ruleFile = ruleFile ; } @ Override public String getName ( ) { return name ; } @ Override public List < String > getRuleFileNames ( ) { final List < String > ruleFiles = new ArrayList < > ( ) ; ruleFiles . addAll ( baseLanguage . getRuleFileNames ( ) ) ; ruleFiles . add ( ruleFile . getAbsolutePath ( ) ) ; return ruleFiles ; } @ Override public boolean isExternal ( ) { return true ; } @ Override public Locale getLocale ( ) { return baseLanguage . getLocale ( ) ; } @ Override public Contributor [ ] getMaintainers ( ) { return baseLanguage . getMaintainers ( ) ; } @ Override public String getShortName ( ) { return baseLanguage . getShortName ( ) ; } @ Override public String [ ] getCountries ( ) { return baseLanguage . getCountries ( ) ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return baseLanguage . getRelevantRules ( messages ) ; } @ Nullable @ Override public String getVariant ( ) { return baseLanguage . getVariant ( ) ; } @ Override public List < String > getDefaultEnabledRulesForVariant ( ) { return baseLanguage . getDefaultEnabledRulesForVariant ( ) ; } @ Override public List < String > getDefaultDisabledRulesForVariant ( ) { return baseLanguage . getDefaultDisabledRulesForVariant ( ) ; } @ Nullable @ Override public LanguageModel getLanguageModel ( File indexDir ) throws IOException { return baseLanguage . getLanguageModel ( indexDir ) ; } @ Override public List < Rule > getRelevantLanguageModelRules ( ResourceBundle messages , LanguageModel languageModel ) throws IOException { return baseLanguage . getRelevantLanguageModelRules ( messages , languageModel ) ; } @ Override public Locale getLocaleWithCountryAndVariant ( ) { return baseLanguage . getLocaleWithCountryAndVariant ( ) ; } @ Nullable @ Override public Language getDefaultLanguageVariant ( ) { return baseLanguage . getDefaultLanguageVariant ( ) ; } @ Override public Disambiguator getDisambiguator ( ) { return baseLanguage . getDisambiguator ( ) ; } @ Override public Tagger getTagger ( ) { return baseLanguage . getTagger ( ) ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { return baseLanguage . getSentenceTokenizer ( ) ; } @ Override public Tokenizer getWordTokenizer ( ) { return baseLanguage . getWordTokenizer ( ) ; } @ Nullable @ Override public Chunker getChunker ( ) { return baseLanguage . getChunker ( ) ; } @ Nullable @ Override public Chunker getPostDisambiguationChunker ( ) { return baseLanguage . getPostDisambiguationChunker ( ) ; } @ Nullable @ Override public Synthesizer getSynthesizer ( ) { return baseLanguage . getSynthesizer ( ) ; } } }
package org . languagetool . language ; final class Contributors { private Contributors ( ) { } static final Contributor MARCIN_MILKOWSKI = new Contributor ( "Marcin Miłkowski" , "http://marcinmilkowski.pl" ) ; static final Contributor DANIEL_NABER = new Contributor ( "Daniel Naber" , "http://www.danielnaber.de" ) ; static final Contributor DOMINIQUE_PELLE = new Contributor ( "Dominique Pellé" , "http://dominiko.livejournal.com/tag/lingvoilo" ) ; }
package org . languagetool . language ; import java . io . File ; public class RuleFilenameException extends RuntimeException { private static final long serialVersionUID = 6642163394764392897L ; public RuleFilenameException ( File file ) { super ( "Rule file must be named rules-<xx>-<lang>.xml (<xx> = language code, " + "<lang> = language name),\n" + "for example: rules-en-English.xml\n" + "Current name: " + file . getName ( ) ) ; } }
package org . languagetool . language ; import com . google . common . base . Optional ; import com . optimaize . langdetect . LanguageDetector ; import com . optimaize . langdetect . LanguageDetectorBuilder ; import com . optimaize . langdetect . i18n . LdLocale ; import com . optimaize . langdetect . ngram . NgramExtractors ; import com . optimaize . langdetect . profiles . LanguageProfile ; import com . optimaize . langdetect . profiles . LanguageProfileReader ; import com . optimaize . langdetect . text . CommonTextObjectFactories ; import com . optimaize . langdetect . text . TextObject ; import com . optimaize . langdetect . text . TextObjectFactory ; import org . jetbrains . annotations . Nullable ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import java . io . IOException ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; public class LanguageIdentifier { private static final double MINIMAL_CONFIDENCE = 0.9 ; private static final List < String > ignoreLangCodes = Arrays . asList ( "ast" , "gl" ) ; private static final List < String > externalLangCodes = Arrays . asList ( "eo" ) ; private final LanguageDetector languageDetector ; private final TextObjectFactory textObjectFactory ; public LanguageIdentifier ( ) { try { List < LanguageProfile > profiles = loadProfiles ( getLanguageCodes ( ) ) ; languageDetector = LanguageDetectorBuilder . create ( NgramExtractors . standard ( ) ) . minimalConfidence ( MINIMAL_CONFIDENCE ) . withProfiles ( profiles ) . build ( ) ; textObjectFactory = CommonTextObjectFactories . forDetectingOnLargeText ( ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not set up language identifier" , e ) ; } } private static List < String > getLanguageCodes ( ) { List < String > langCodes = new ArrayList < > ( ) ; for ( Language lang : Languages . get ( ) ) { String langCode = lang . getShortName ( ) ; boolean ignore = lang . isVariant ( ) || ignoreLangCodes . contains ( langCode ) || externalLangCodes . contains ( langCode ) ; if ( ignore ) { continue ; } if ( "zh" . equals ( langCode ) ) { langCodes . add ( "zh-CN" ) ; langCodes . add ( "zh-TW" ) ; } else { langCodes . add ( langCode ) ; } } return langCodes ; } private List < LanguageProfile > loadProfiles ( List < String > langCodes ) throws IOException { LanguageProfileReader profileReader = new LanguageProfileReader ( ) ; List < LanguageProfile > profiles = profileReader . read ( langCodes ) ; for ( String externalLangCode : externalLangCodes ) { String profilePath = "/" + externalLangCode + "/" + externalLangCode + ".profile" ; if ( JLanguageTool . getDataBroker ( ) . resourceExists ( profilePath ) ) { try ( InputStream profile = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( profilePath ) ) { profiles . add ( new LanguageProfileReader ( ) . read ( profile ) ) ; } } } return profiles ; } @ Nullable public Language detectLanguage ( String text ) { String languageCode = detectLanguageCode ( text ) ; if ( languageCode != null ) { return Languages . getLanguageForShortName ( languageCode ) ; } else { return null ; } } @ Nullable private String detectLanguageCode ( String text ) { TextObject textObject = textObjectFactory . forText ( text ) ; Optional < LdLocale > lang = languageDetector . detect ( textObject ) ; if ( lang . isPresent ( ) ) { return lang . get ( ) . getLanguage ( ) ; } else { return null ; } } }
package org . languagetool . language ; import java . util . Objects ; public final class Contributor { private final String name ; private final String url ; Contributor ( String name , String url ) { this . name = Objects . requireNonNull ( name , "name cannot be null" ) ; this . url = url ; } Contributor ( String name ) { this ( name , null ) ; } public String getName ( ) { return name ; } public String getUrl ( ) { return url ; } @ Override public String toString ( ) { return name ; } }
package org . languagetool . markup ; import java . util . Objects ; class TextPart { enum Type { TEXT , MARKUP } private final String part ; private final Type typ ; TextPart ( String part , Type typ ) { this . part = Objects . requireNonNull ( part ) ; this . typ = Objects . requireNonNull ( typ ) ; } String getPart ( ) { return part ; } Type getType ( ) { return typ ; } @ Override public String toString ( ) { return part ; } }
package org . languagetool . tagging . nl ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Dutch ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; public class DutchTaggerTest extends TestCase { private DutchTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = new DutchTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Dutch ( ) ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "Dit is een Nederlandse zin om het programma'tje te testen." , "Dit/[dit]DTh -- is/[zijn]VB3 -- een/[een]DTe|een/[een]NM|een/[een]NM1|een/[een]NN1d -- Nederlandse/[Nederlandse]NN1 -- zin/[zin]NN1d|zin/[zinnen]VB1 -- om/[om]PRom -- het/[het]DTh -- programma/[programma]NN1h -- tje/[null]null -- te/[te]PRte -- testen/[test]NN2|testen/[testen]VBi" , tokenizer , tagger ) ; TestTools . myAssert ( "zwijnden" , "zwijnden/[zwijnen]VBh" , tokenizer , tagger ) ; } }
package org . languagetool . markup ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; public class AnnotatedTextBuilder { private final List < TextPart > parts = new ArrayList < > ( ) ; public AnnotatedTextBuilder ( ) { } public AnnotatedTextBuilder addText ( String text ) { parts . add ( new TextPart ( text , TextPart . Type . TEXT ) ) ; return this ; } public AnnotatedTextBuilder addMarkup ( String markup ) { parts . add ( new TextPart ( markup , TextPart . Type . MARKUP ) ) ; return this ; } public AnnotatedText build ( ) { int plainTextPosition = 0 ; int totalPosition = 0 ; Map < Integer , Integer > mapping = new HashMap < > ( ) ; mapping . put ( 0 , 0 ) ; for ( TextPart part : parts ) { if ( part . getType ( ) == TextPart . Type . TEXT ) { plainTextPosition += part . getPart ( ) . length ( ) ; totalPosition += part . getPart ( ) . length ( ) ; } else if ( part . getType ( ) == TextPart . Type . MARKUP ) { totalPosition += part . getPart ( ) . length ( ) ; } mapping . put ( plainTextPosition , totalPosition ) ; } return new AnnotatedText ( parts , mapping ) ; } }
package org . languagetool . markup ; import org . apache . commons . lang . StringUtils ; import java . util . List ; import java . util . Map ; import java . util . Objects ; public class AnnotatedText { private final List < TextPart > parts ; private final Map < Integer , Integer > mapping ; AnnotatedText ( List < TextPart > parts , Map < Integer , Integer > mapping ) { this . parts = Objects . requireNonNull ( parts ) ; this . mapping = Objects . requireNonNull ( mapping ) ; } public String getPlainText ( ) { StringBuilder sb = new StringBuilder ( ) ; for ( TextPart part : parts ) { if ( part . getType ( ) == TextPart . Type . TEXT ) { sb . append ( part . getPart ( ) ) ; } } return sb . toString ( ) ; } public int getOriginalTextPositionFor ( int plainTextPosition ) { if ( plainTextPosition < 0 ) { throw new RuntimeException ( "plainTextPosition must be >= 0: " + plainTextPosition ) ; } final Integer origPosition = mapping . get ( plainTextPosition ) ; if ( origPosition != null ) { return origPosition ; } int minDiff = Integer . MAX_VALUE ; Integer bestMatch = null ; for ( Map . Entry < Integer , Integer > entry : mapping . entrySet ( ) ) { int maybeClosePosition = entry . getKey ( ) ; if ( plainTextPosition > maybeClosePosition ) { int diff = plainTextPosition - maybeClosePosition ; if ( diff >= 0 && diff < minDiff ) { bestMatch = entry . getValue ( ) ; minDiff = diff ; } } } if ( bestMatch == null ) { throw new RuntimeException ( "Could not map " + plainTextPosition + " to original position" ) ; } return bestMatch + minDiff ; } @ Override public String toString ( ) { return StringUtils . join ( parts , "" ) ; } }
package org . languagetool . chunking ; public class ChunkTag { private final String chunkTag ; public ChunkTag ( String chunkTag ) { if ( chunkTag == null || chunkTag . trim ( ) . isEmpty ( ) ) { throw new NullPointerException ( "chunkTag cannot be null or empty: '" + chunkTag + "'" ) ; } this . chunkTag = chunkTag ; } public String getChunkTag ( ) { return chunkTag ; } @ Override public boolean equals ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; ChunkTag other = ( ChunkTag ) o ; return chunkTag . equals ( other . chunkTag ) ; } @ Override public int hashCode ( ) { return chunkTag . hashCode ( ) ; } @ Override public String toString ( ) { return chunkTag ; } }
package org . languagetool . chunking ; import org . languagetool . AnalyzedTokenReadings ; import java . util . List ; public interface Chunker { void addChunkTags ( List < AnalyzedTokenReadings > sentenceTokenReadings ) ; }
package org . languagetool . languagemodel ; import org . apache . commons . lang . StringUtils ; import org . apache . lucene . index . * ; import org . apache . lucene . search . * ; import org . apache . lucene . store . FSDirectory ; import java . io . File ; import java . io . IOException ; import java . util . * ; public class LuceneLanguageModel implements LanguageModel { private static final Map < File , LuceneSearcher > dirToSearcherMap = new HashMap < > ( ) ; private final List < File > indexes = new ArrayList < > ( ) ; private final Map < Integer , LuceneSearcher > luceneSearcherMap = new HashMap < > ( ) ; private final File topIndexDir ; public LuceneLanguageModel ( File topIndexDir ) throws IOException { if ( ! topIndexDir . exists ( ) || ! topIndexDir . isDirectory ( ) ) { throw new RuntimeException ( "Not found or is not a directory: " + topIndexDir ) ; } this . topIndexDir = topIndexDir ; addIndex ( topIndexDir , 1 ) ; addIndex ( topIndexDir , 2 ) ; addIndex ( topIndexDir , 3 ) ; addIndex ( topIndexDir , 4 ) ; if ( luceneSearcherMap . size ( ) == 0 ) { throw new RuntimeException ( "No directories '1grams' ... '3grams' found in " + topIndexDir ) ; } } private void addIndex ( File topIndexDir , int ngramSize ) throws IOException { File indexDir = new File ( topIndexDir , ngramSize + "grams" ) ; if ( indexDir . exists ( ) && indexDir . isDirectory ( ) ) { if ( luceneSearcherMap . containsKey ( ngramSize ) ) { throw new RuntimeException ( "Searcher for ngram size " + ngramSize + " already exists" ) ; } luceneSearcherMap . put ( ngramSize , getCachedLuceneSearcher ( indexDir ) ) ; indexes . add ( indexDir ) ; } } @ Override public long getCount ( List < String > tokens ) { Objects . requireNonNull ( tokens ) ; Term term = new Term ( "ngram" , StringUtils . join ( tokens , " " ) ) ; return getCount ( term , getLuceneSearcher ( tokens . size ( ) ) ) ; } @ Override public long getCount ( String token1 ) { Objects . requireNonNull ( token1 ) ; return getCount ( Arrays . asList ( token1 ) ) ; } @ Override public long getCount ( String token1 , String token2 ) { Objects . requireNonNull ( token1 ) ; Objects . requireNonNull ( token2 ) ; return getCount ( Arrays . asList ( token1 , token2 ) ) ; } @ Override public long getCount ( String token1 , String token2 , String token3 ) { Objects . requireNonNull ( token1 ) ; Objects . requireNonNull ( token2 ) ; Objects . requireNonNull ( token3 ) ; return getCount ( Arrays . asList ( token1 , token2 , token3 ) ) ; } @ Override public long getTotalTokenCount ( ) { LuceneSearcher luceneSearcher = getLuceneSearcher ( 1 ) ; try { RegexpQuery query = new RegexpQuery ( new Term ( "totalTokenCount" , ".*" ) ) ; TopDocs docs = luceneSearcher . searcher . search ( query , 1000 ) ; if ( docs . totalHits == 0 ) { throw new RuntimeException ( "Expected 'totalTokenCount' meta documents not found in 1grams index" ) ; } else if ( docs . totalHits > 1000 ) { throw new RuntimeException ( "Did not expect more than 1000 'totalTokenCount' meta documents" ) ; } else { long result = 0 ; for ( ScoreDoc scoreDoc : docs . scoreDocs ) { result += Long . parseLong ( luceneSearcher . reader . document ( scoreDoc . doc ) . get ( "totalTokenCount" ) ) ; } return result ; } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } protected LuceneSearcher getLuceneSearcher ( int ngramSize ) { LuceneSearcher luceneSearcher = luceneSearcherMap . get ( ngramSize ) ; if ( luceneSearcher == null ) { throw new RuntimeException ( "No " + ngramSize + "grams directory found in " + topIndexDir ) ; } return luceneSearcher ; } private LuceneSearcher getCachedLuceneSearcher ( File indexDir ) throws IOException { LuceneSearcher luceneSearcher = dirToSearcherMap . get ( indexDir ) ; if ( luceneSearcher == null ) { LuceneSearcher newSearcher = new LuceneSearcher ( indexDir ) ; dirToSearcherMap . put ( indexDir , newSearcher ) ; return newSearcher ; } else { return luceneSearcher ; } } private long getCount ( Term term , LuceneSearcher luceneSearcher ) { try { TopDocs docs = luceneSearcher . searcher . search ( new TermQuery ( term ) , 1 ) ; if ( docs . totalHits > 0 ) { int docId = docs . scoreDocs [ 0 ] . doc ; return Long . parseLong ( luceneSearcher . reader . document ( docId ) . get ( "count" ) ) ; } else { return 0 ; } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } @ Override public void close ( ) { for ( LuceneSearcher searcher : luceneSearcherMap . values ( ) ) { try { searcher . reader . close ( ) ; searcher . directory . close ( ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } } @ Override public String toString ( ) { return indexes . toString ( ) ; } protected static class LuceneSearcher { final FSDirectory directory ; final IndexReader reader ; final IndexSearcher searcher ; private LuceneSearcher ( File indexDir ) throws IOException { this . directory = FSDirectory . open ( indexDir ) ; this . reader = DirectoryReader . open ( directory ) ; this . searcher = new IndexSearcher ( reader ) ; } public IndexReader getReader ( ) { return reader ; } } }
package org . languagetool . languagemodel ; import java . util . List ; public interface LanguageModel extends AutoCloseable { static final String GOOGLE_SENTENCE_START = "_START_" ; static final String GOOGLE_SENTENCE_END = "." ; long getCount ( String token1 ) ; long getCount ( List < String > tokens ) ; long getCount ( String token1 , String token2 ) ; long getCount ( String token1 , String token2 , String token3 ) ; long getTotalTokenCount ( ) ; @ Override void close ( ) ; }
package org . languagetool . synthesis ; import java . io . IOException ; import org . languagetool . AnalyzedToken ; public interface Synthesizer { public String [ ] synthesize ( AnalyzedToken token , String posTag ) throws IOException ; public String [ ] synthesize ( AnalyzedToken token , String posTag , boolean posTagRegExp ) throws IOException ; public String getPosTagCorrection ( String posTag ) ; }
package org . languagetool . synthesis ; import java . io . IOException ; import java . io . InputStream ; import java . net . URL ; import java . util . ArrayList ; import java . util . List ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import morfologik . stemming . Dictionary ; import morfologik . stemming . DictionaryLookup ; import morfologik . stemming . IStemmer ; import morfologik . stemming . WordData ; import org . languagetool . AnalyzedToken ; import org . languagetool . JLanguageTool ; public class BaseSynthesizer implements Synthesizer { protected volatile List < String > possibleTags ; private final String tagFileName ; private final String resourceFileName ; private final IStemmer stemmer ; private volatile Dictionary dictionary ; public BaseSynthesizer ( final String resourceFileName , final String tagFileName ) { this . resourceFileName = resourceFileName ; this . tagFileName = tagFileName ; this . stemmer = createStemmer ( ) ; } protected Dictionary getDictionary ( ) throws IOException { Dictionary dict = this . dictionary ; if ( dict == null ) { synchronized ( this ) { dict = this . dictionary ; if ( dict == null ) { final URL url = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( resourceFileName ) ; this . dictionary = dict = Dictionary . read ( url ) ; } } } return dict ; } protected IStemmer createStemmer ( ) { try { return new DictionaryLookup ( getDictionary ( ) ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not load dictionary" , e ) ; } } protected void lookup ( String lemma , String posTag , List < String > results ) { synchronized ( this ) { final List < WordData > wordForms = stemmer . lookup ( lemma + "|" + posTag ) ; for ( WordData wd : wordForms ) { results . add ( wd . getStem ( ) . toString ( ) ) ; } } } @ Override public String [ ] synthesize ( final AnalyzedToken token , final String posTag ) throws IOException { final List < String > wordForms = new ArrayList < > ( ) ; lookup ( token . getLemma ( ) , posTag , wordForms ) ; return wordForms . toArray ( new String [ wordForms . size ( ) ] ) ; } @ Override public String [ ] synthesize ( final AnalyzedToken token , final String posTag , final boolean posTagRegExp ) throws IOException { if ( posTagRegExp ) { initPossibleTags ( ) ; final Pattern p = Pattern . compile ( posTag ) ; final List < String > results = new ArrayList < > ( ) ; for ( final String tag : possibleTags ) { final Matcher m = p . matcher ( tag ) ; if ( m . matches ( ) ) { lookup ( token . getLemma ( ) , tag , results ) ; } } return results . toArray ( new String [ results . size ( ) ] ) ; } return synthesize ( token , posTag ) ; } @ Override public String getPosTagCorrection ( final String posTag ) { return posTag ; } public IStemmer getStemmer ( ) { return stemmer ; } protected void initPossibleTags ( ) throws IOException { List < String > tags = possibleTags ; if ( tags == null ) { synchronized ( this ) { tags = possibleTags ; if ( tags == null ) { try ( InputStream stream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( tagFileName ) ) { possibleTags = SynthesizerTools . loadWords ( stream ) ; } } } } } }
package org . languagetool . synthesis ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . List ; import java . util . Scanner ; public final class SynthesizerTools { private SynthesizerTools ( ) { } public static List < String > loadWords ( final InputStream stream ) { final List < String > result = new ArrayList < > ( ) ; try ( Scanner scanner = new Scanner ( stream , "UTF-8" ) ) { while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) . trim ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } result . add ( line ) ; } } return result ; } }
package org . languagetool . synthesis ; import java . io . IOException ; import java . io . InputStream ; import java . util . * ; import org . languagetool . tagging . ManualTagger ; import org . languagetool . tools . StringTools ; public final class ManualSynthesizer { private final Map < String , List < String > > mapping ; private final Set < String > possibleTags ; public ManualSynthesizer ( final InputStream inputStream ) throws IOException { MappingAndTags mappingAndTags = loadMapping ( inputStream , "utf8" ) ; mapping = mappingAndTags . mapping ; possibleTags = Collections . unmodifiableSet ( mappingAndTags . tags ) ; } public Set < String > getPossibleTags ( ) { return possibleTags ; } public List < String > lookup ( final String lemma , final String posTag ) { return mapping . get ( lemma + "|" + posTag ) ; } private MappingAndTags loadMapping ( final InputStream inputStream , final String encoding ) throws IOException { final MappingAndTags result = new MappingAndTags ( ) ; try ( Scanner scanner = new Scanner ( inputStream , encoding ) ) { while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ; if ( StringTools . isEmpty ( line ) || line . charAt ( 0 ) == '#' ) { continue ; } final String [ ] parts = line . split ( "\t" ) ; if ( parts . length != 3 ) { throw new IOException ( "Unknown line format when loading manual synthesizer dictionary: " + line ) ; } final String key = parts [ 1 ] + "|" + parts [ 2 ] ; if ( ! result . mapping . containsKey ( key ) ) { result . mapping . put ( key , new ArrayList < String > ( ) ) ; } result . mapping . get ( key ) . add ( parts [ 0 ] ) ; result . tags . add ( parts [ 2 ] ) ; } } return result ; } static class MappingAndTags { Map < String , List < String > > mapping = new HashMap < > ( ) ; Set < String > tags = new HashSet < > ( ) ; } }
package org . languagetool . tokenizers . nl ; import java . util . List ; import junit . framework . TestCase ; public class DutchWordTokenizerTest extends TestCase { private final DutchWordTokenizer wordTokenizer = new DutchWordTokenizer ( ) ; public void testTokenize ( ) { assertTokenize ( "This is\u00A0a test" , "[This, , is,  , a, , test]" ) ; assertTokenize ( "Bla bla oma's bla bla 'test" , "[Bla, , bla, , oma's, , bla, , bla, , ', test]" ) ; assertTokenize ( "Bla bla oma`s bla bla 'test" , "[Bla, , bla, , oma`s, , bla, , bla, , ', test]" ) ; assertTokenize ( "Ik zie het''" , "[Ik, , zie, , het, ', ']" ) ; assertTokenize ( "Ik zie het``" , "[Ik, , zie, , het, `, `]" ) ; assertTokenize ( "''Ik zie het" , "[', ', Ik, , zie, , het]" ) ; assertTokenize ( "Ik 'zie' het" , "[Ik, , ', zie, ', , het]" ) ; assertTokenize ( "Ik `zie het" , "[Ik, , `, zie, , het]" ) ; assertTokenize ( "Ik ``zie het" , "[Ik, , `, `, zie, , het]" ) ; assertTokenize ( "'" , "[']" ) ; assertTokenize ( "''" , "[, ', ']" ) ; assertTokenize ( "'x'" , "[', x, ']" ) ; assertTokenize ( "`x`" , "[`, x, `]" ) ; } private void assertTokenize ( String input , String expected ) { List < String > result = wordTokenizer . tokenize ( input ) ; assertEquals ( expected , result . toString ( ) ) ; } }
package org . languagetool . tools ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . bitext . BitextRule ; import org . languagetool . rules . patterns . PasswordAuthenticator ; import org . languagetool . rules . patterns . bitext . BitextPatternRule ; import org . languagetool . rules . patterns . bitext . BitextPatternRuleLoader ; import org . languagetool . rules . patterns . bitext . FalseFriendsAsBitextLoader ; import org . xml . sax . SAXException ; import javax . xml . parsers . ParserConfigurationException ; import java . io . * ; import java . lang . reflect . Constructor ; import java . net . Authenticator ; import java . net . NetPermission ; import java . util . * ; public final class Tools { private Tools ( ) { } public static List < RuleMatch > checkBitext ( final String src , final String trg , final JLanguageTool srcLt , final JLanguageTool trgLt , final List < BitextRule > bRules ) throws IOException { final AnalyzedSentence srcText = srcLt . getAnalyzedSentence ( src ) ; final AnalyzedSentence trgText = trgLt . getAnalyzedSentence ( trg ) ; List < Rule > nonBitextRules = trgLt . getAllRules ( ) ; for ( Rule rule : nonBitextRules ) { rule . reset ( ) ; } final List < RuleMatch > ruleMatches = trgLt . checkAnalyzedSentence ( JLanguageTool . ParagraphHandling . NORMAL , nonBitextRules , 0 , 0 , 1 , trg , trgText , null ) ; for ( BitextRule bRule : bRules ) { final RuleMatch [ ] curMatch = bRule . match ( srcText , trgText ) ; if ( curMatch != null && curMatch . length > 0 ) { for ( RuleMatch match : curMatch ) { if ( match . getColumn ( ) < 0 ) { match . setColumn ( 1 ) ; } if ( match . getEndColumn ( ) < 0 ) { match . setEndColumn ( trg . length ( ) + 1 ) ; } if ( match . getLine ( ) < 0 ) { match . setLine ( 1 ) ; } if ( match . getEndLine ( ) < 0 ) { match . setEndLine ( 1 ) ; } ruleMatches . add ( match ) ; } } } return ruleMatches ; } public static List < BitextRule > getBitextRules ( final Language source , final Language target ) throws IOException , ParserConfigurationException , SAXException { return getBitextRules ( source , target , null ) ; } public static List < BitextRule > getBitextRules ( final Language source , final Language target , final File externalBitextRuleFile ) throws IOException , ParserConfigurationException , SAXException { final List < BitextRule > bRules = new ArrayList < > ( ) ; final BitextPatternRuleLoader ruleLoader = new BitextPatternRuleLoader ( ) ; final String name = "/" + target . getShortName ( ) + "/bitext.xml" ; if ( JLanguageTool . getDataBroker ( ) . ruleFileExists ( name ) ) { final InputStream is = JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( name ) ; if ( is != null ) { bRules . addAll ( ruleLoader . getRules ( is , name ) ) ; } } if ( externalBitextRuleFile != null ) { bRules . addAll ( ruleLoader . getRules ( new FileInputStream ( externalBitextRuleFile ) , externalBitextRuleFile . getAbsolutePath ( ) ) ) ; } final FalseFriendsAsBitextLoader fRuleLoader = new FalseFriendsAsBitextLoader ( ) ; final String falseFriendsFile = "/false-friends.xml" ; final List < BitextPatternRule > rules = fRuleLoader . getFalseFriendsAsBitext ( falseFriendsFile , source , target ) ; bRules . addAll ( rules ) ; bRules . addAll ( getAllBuiltinBitextRules ( source , null ) ) ; return bRules ; } private static List < BitextRule > getAllBuiltinBitextRules ( final Language language , final ResourceBundle messages ) { final List < BitextRule > rules = new ArrayList < > ( ) ; try { final List < Class < ? extends BitextRule > > classes = BitextRule . getRelevantRules ( ) ; for ( final Class class1 : classes ) { final Constructor [ ] constructors = class1 . getConstructors ( ) ; boolean foundConstructor = false ; for ( final Constructor constructor : constructors ) { final Class [ ] paramTypes = constructor . getParameterTypes ( ) ; if ( paramTypes . length == 0 ) { rules . add ( ( BitextRule ) constructor . newInstance ( ) ) ; foundConstructor = true ; break ; } if ( paramTypes . length == 1 && paramTypes [ 0 ] . equals ( ResourceBundle . class ) ) { rules . add ( ( BitextRule ) constructor . newInstance ( messages ) ) ; foundConstructor = true ; break ; } if ( paramTypes . length == 2 && paramTypes [ 0 ] . equals ( ResourceBundle . class ) && paramTypes [ 1 ] . equals ( Language . class ) ) { rules . add ( ( BitextRule ) constructor . newInstance ( messages , language ) ) ; foundConstructor = true ; break ; } } if ( ! foundConstructor ) { throw new RuntimeException ( "Unknown constructor type for rule class " + class1 . getName ( ) + ", it supports only these constructors: " + Arrays . toString ( constructors ) ) ; } } } catch ( final Exception e ) { throw new RuntimeException ( "Failed to load bitext rules" , e ) ; } return rules ; } public static int profileRulesOnLine ( final String contents , final JLanguageTool lt , final Rule rule ) throws IOException { int count = 0 ; for ( final String sentence : lt . sentenceTokenize ( contents ) ) { count += rule . match ( lt . getAnalyzedSentence ( sentence ) ) . length ; } return count ; } public static String correctText ( final String contents , final JLanguageTool lt ) throws IOException { final List < RuleMatch > ruleMatches = lt . check ( contents ) ; if ( ruleMatches . isEmpty ( ) ) { return contents ; } return correctTextFromMatches ( contents , ruleMatches ) ; } public static String correctTextFromMatches ( final String contents , final List < RuleMatch > matches ) { final StringBuilder sb = new StringBuilder ( contents ) ; final List < String > errors = new ArrayList < > ( ) ; for ( RuleMatch rm : matches ) { final List < String > replacements = rm . getSuggestedReplacements ( ) ; if ( ! replacements . isEmpty ( ) ) { errors . add ( sb . substring ( rm . getFromPos ( ) , rm . getToPos ( ) ) ) ; } } int offset = 0 ; int counter = 0 ; for ( RuleMatch rm : matches ) { final List < String > replacements = rm . getSuggestedReplacements ( ) ; if ( ! replacements . isEmpty ( ) ) { if ( errors . get ( counter ) . equals ( sb . substring ( rm . getFromPos ( ) - offset , rm . getToPos ( ) - offset ) ) ) { sb . replace ( rm . getFromPos ( ) - offset , rm . getToPos ( ) - offset , replacements . get ( 0 ) ) ; offset += ( rm . getToPos ( ) - rm . getFromPos ( ) ) - replacements . get ( 0 ) . length ( ) ; } counter ++ ; } } return sb . toString ( ) ; } public static String getFullStackTrace ( final Throwable e ) { final StringWriter sw = new StringWriter ( ) ; final PrintWriter pw = new PrintWriter ( sw ) ; e . printStackTrace ( pw ) ; return sw . toString ( ) ; } public static InputStream getStream ( final String path ) throws IOException { final InputStream is = Tools . class . getResourceAsStream ( path ) ; if ( is == null ) { throw new IOException ( "Could not load file from classpath: '" + path + "'" ) ; } return is ; } public static void selectRules ( final JLanguageTool lt , final String [ ] disabledRules , final String [ ] enabledRules ) { selectRules ( lt , disabledRules , enabledRules , true ) ; } public static void selectRules ( final JLanguageTool lt , final List < String > disabledRuleIds , final List < String > enabledRuleIds , boolean useEnabledOnly ) { selectRules ( lt , disabledRuleIds . toArray ( new String [ disabledRuleIds . size ( ) ] ) , enabledRuleIds . toArray ( new String [ enabledRuleIds . size ( ) ] ) , useEnabledOnly ) ; } public static void selectRules ( final JLanguageTool lt , final String [ ] disabledRules , final String [ ] enabledRules , boolean useEnabledOnly ) { for ( final String disabledRule : disabledRules ) { lt . disableRule ( disabledRule ) ; } if ( enabledRules . length > 0 ) { final Set < String > enabledRuleIDs = new HashSet < > ( Arrays . asList ( enabledRules ) ) ; for ( String ruleName : enabledRuleIDs ) { lt . enableDefaultOffRule ( ruleName ) ; lt . enableRule ( ruleName ) ; } if ( useEnabledOnly ) { List < String > rulesToBeDisabled = new ArrayList < > ( ) ; for ( Rule rule : lt . getAllRules ( ) ) { if ( ! enabledRuleIDs . contains ( rule . getId ( ) ) ) { rulesToBeDisabled . add ( rule . getId ( ) ) ; } } lt . disableRules ( rulesToBeDisabled ) ; } } } public static List < BitextRule > selectBitextRules ( final List < BitextRule > bRules , final List < String > disabledRules , final List < String > enabledRules , boolean useEnabledOnly ) { List < BitextRule > newBRules = new ArrayList < > ( bRules . size ( ) ) ; newBRules . addAll ( bRules ) ; List < BitextRule > rulesToDisable = new ArrayList < > ( ) ; if ( useEnabledOnly ) { for ( final String enabledRule : enabledRules ) { for ( BitextRule b : bRules ) { if ( ! b . getId ( ) . equals ( enabledRule ) ) { rulesToDisable . add ( b ) ; } } } } else { for ( final String disabledRule : disabledRules ) { for ( final BitextRule b : newBRules ) { if ( b . getId ( ) . equals ( disabledRule ) ) { rulesToDisable . add ( b ) ; } } } } newBRules . removeAll ( rulesToDisable ) ; return newBRules ; } public static void setPasswordAuthenticator ( ) { SecurityManager security = System . getSecurityManager ( ) ; if ( security != null ) { try { security . checkPermission ( new NetPermission ( "setDefaultAuthenticator" ) ) ; Authenticator . setDefault ( new PasswordAuthenticator ( ) ) ; } catch ( SecurityException e ) { } } else { Authenticator . setDefault ( new PasswordAuthenticator ( ) ) ; } } }
package org . languagetool . tools ; import com . google . common . xml . XmlEscapers ; import org . jetbrains . annotations . Nullable ; import org . languagetool . Language ; import java . io . * ; import java . lang . Character ; import java . util . Collection ; import java . util . Iterator ; import java . util . Locale ; import java . util . Objects ; import java . util . regex . Pattern ; public final class StringTools { public enum XmlPrintMode { NORMAL_XML , START_XML , END_XML , CONTINUE_XML } private static final Pattern XML_COMMENT_PATTERN = Pattern . compile ( "<!--.*?-->" , Pattern . DOTALL ) ; private static final Pattern XML_PATTERN = Pattern . compile ( "(?<!<)<[^<>]+>" , Pattern . DOTALL ) ; private StringTools ( ) { } public static void assureSet ( final String s , final String varName ) { Objects . requireNonNull ( varName ) ; if ( isEmpty ( s . trim ( ) ) ) { throw new IllegalArgumentException ( varName + " cannot be empty or whitespace only" ) ; } } public static String readStream ( final InputStream stream , final String encoding ) throws IOException { InputStreamReader isr = null ; final StringBuilder sb = new StringBuilder ( ) ; try { if ( encoding == null ) { isr = new InputStreamReader ( stream ) ; } else { isr = new InputStreamReader ( stream , encoding ) ; } try ( BufferedReader br = new BufferedReader ( isr ) ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { sb . append ( line ) ; sb . append ( '\n' ) ; } } } finally { if ( isr != null ) { isr . close ( ) ; } } return sb . toString ( ) ; } public static boolean isAllUppercase ( final String str ) { for ( int i = 0 ; i < str . length ( ) ; i ++ ) { char c = str . charAt ( i ) ; if ( Character . isLetter ( c ) && Character . isLowerCase ( c ) ) { return false ; } } return true ; } public static boolean isMixedCase ( final String str ) { return ! isAllUppercase ( str ) && ! isCapitalizedWord ( str ) && isNotAllLowercase ( str ) ; } public static boolean isNotAllLowercase ( final String str ) { for ( int i = 0 ; i < str . length ( ) ; i ++ ) { char c = str . charAt ( i ) ; if ( Character . isLetter ( c ) && ! Character . isLowerCase ( c ) ) { return true ; } } return false ; } public static boolean isCapitalizedWord ( final String str ) { if ( ! isEmpty ( str ) && Character . isUpperCase ( str . charAt ( 0 ) ) ) { for ( int i = 1 ; i < str . length ( ) ; i ++ ) { char c = str . charAt ( i ) ; if ( Character . isLetter ( c ) && ! Character . isLowerCase ( c ) ) { return false ; } } return true ; } return false ; } public static boolean startsWithUppercase ( final String str ) { if ( isEmpty ( str ) ) { return false ; } return Character . isUpperCase ( str . charAt ( 0 ) ) ; } @ Nullable public static String uppercaseFirstChar ( final String str ) { return changeFirstCharCase ( str , true ) ; } @ Nullable public static String uppercaseFirstChar ( final String str , Language language ) { if ( language != null && "nl" . equals ( language . getShortName ( ) ) && str != null && str . toLowerCase ( ) . startsWith ( "ij" ) ) { return "IJ" + str . substring ( 2 ) ; } else { return changeFirstCharCase ( str , true ) ; } } @ Nullable public static String lowercaseFirstChar ( final String str ) { return changeFirstCharCase ( str , false ) ; } @ Nullable private static String changeFirstCharCase ( final String str , final boolean toUpperCase ) { if ( isEmpty ( str ) ) { return str ; } if ( str . length ( ) == 1 ) { return toUpperCase ? str . toUpperCase ( Locale . ENGLISH ) : str . toLowerCase ( ) ; } int pos = 0 ; final int len = str . length ( ) - 1 ; while ( ! Character . isLetterOrDigit ( str . charAt ( pos ) ) && len > pos ) { pos ++ ; } final char firstChar = str . charAt ( pos ) ; return str . substring ( 0 , pos ) + ( toUpperCase ? Character . toUpperCase ( firstChar ) : Character . toLowerCase ( firstChar ) ) + str . substring ( pos + 1 ) ; } public static String readerToString ( final Reader reader ) throws IOException { final StringBuilder sb = new StringBuilder ( ) ; int readBytes = 0 ; final char [ ] chars = new char [ 4000 ] ; while ( readBytes >= 0 ) { readBytes = reader . read ( chars , 0 , 4000 ) ; if ( readBytes <= 0 ) { break ; } sb . append ( new String ( chars , 0 , readBytes ) ) ; } return sb . toString ( ) ; } public static String streamToString ( final InputStream is , String charsetName ) throws IOException { try ( InputStreamReader isr = new InputStreamReader ( is , charsetName ) ) { return readerToString ( isr ) ; } } public static String escapeXML ( final String s ) { return escapeHTML ( s ) ; } public static String escapeForXmlAttribute ( final String s ) { return XmlEscapers . xmlAttributeEscaper ( ) . escape ( s ) ; } public static String escapeForXmlContent ( final String s ) { return XmlEscapers . xmlContentEscaper ( ) . escape ( s ) ; } public static String escapeHTML ( final String s ) { final StringBuilder sb = new StringBuilder ( ) ; final int n = s . length ( ) ; for ( int i = 0 ; i < n ; i ++ ) { final char c = s . charAt ( i ) ; switch ( c ) { case '<' : sb . append ( "&lt;" ) ; break ; case '>' : sb . append ( "&gt;" ) ; break ; case '&' : sb . append ( "&amp;" ) ; break ; case '"' : sb . append ( "&quot;" ) ; break ; default : sb . append ( c ) ; break ; } } return sb . toString ( ) ; } public static String listToString ( final Collection < String > l , final String delimiter ) { final StringBuilder sb = new StringBuilder ( ) ; for ( final Iterator < String > iter = l . iterator ( ) ; iter . hasNext ( ) ; ) { final String str = iter . next ( ) ; sb . append ( str ) ; if ( iter . hasNext ( ) ) { sb . append ( delimiter ) ; } } return sb . toString ( ) ; } public static String trimWhitespace ( final String s ) { final StringBuilder filter = new StringBuilder ( ) ; String str = s . trim ( ) ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { while ( str . charAt ( i ) <= ' ' && i < str . length ( ) && ( str . charAt ( i + 1 ) <= ' ' || i > 1 && str . charAt ( i - 1 ) <= ' ' ) ) { i ++ ; } final char c = str . charAt ( i ) ; if ( c != '\n' && c != '\t' && c != '\r' ) { filter . append ( c ) ; } } return filter . toString ( ) ; } public static String addSpace ( final String word , final Language language ) { String space = " " ; if ( word . length ( ) == 1 ) { final char c = word . charAt ( 0 ) ; if ( "fr" . equals ( language . getShortName ( ) ) ) { if ( c == '.' || c == ',' ) { space = "" ; } } else { if ( c == '.' || c == ',' || c == ';' || c == ':' || c == '?' || c == '!' ) { space = "" ; } } } return space ; } public static boolean isWhitespace ( final String str ) { if ( "\u0002" . equals ( str ) || "\u0001" . equals ( str ) ) { return false ; } final String trimStr = str . trim ( ) ; if ( isEmpty ( trimStr ) ) { return true ; } if ( trimStr . length ( ) == 1 ) { if ( "\u200B" . equals ( str ) ) { return true ; } return Character . isWhitespace ( trimStr . charAt ( 0 ) ) ; } return false ; } public static boolean isNonBreakingWhitespace ( final String str ) { return "\u00A0" . equals ( str ) ; } public static boolean isPositiveNumber ( final char ch ) { return ch >= '1' && ch <= '9' ; } public static boolean isEmpty ( final String str ) { return str == null || str . length ( ) == 0 ; } public static String filterXML ( final String str ) { String s = str ; if ( s . contains ( "<" ) ) { s = XML_COMMENT_PATTERN . matcher ( s ) . replaceAll ( " " ) ; s = XML_PATTERN . matcher ( s ) . replaceAll ( "" ) ; } return s ; } @ Nullable public static String asString ( final CharSequence s ) { if ( s == null ) { return null ; } return s . toString ( ) ; } }
package org . languagetool . tools ; import org . jetbrains . annotations . Nullable ; import java . io . InputStream ; import java . util . * ; public class MultiKeyProperties { private final Map < String , List < String > > properties = new HashMap < > ( ) ; public MultiKeyProperties ( InputStream inStream ) { try ( Scanner scanner = new Scanner ( inStream ) ) { while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) . trim ( ) ; if ( line . startsWith ( "#" ) || line . isEmpty ( ) ) { continue ; } final String [ ] parts = line . split ( "\\s*=\\s*" ) ; if ( parts . length != 2 ) { continue ; } final String key = parts [ 0 ] ; final String value = parts [ 1 ] ; List < String > list = properties . get ( key ) ; if ( list == null ) { list = new ArrayList < > ( ) ; } list . add ( value ) ; properties . put ( key , list ) ; } } } @ Nullable public List < String > getProperty ( String key ) { return properties . get ( key ) ; } }
package org . languagetool . tools ; public final class JnaTools { private JnaTools ( ) { } public static void setBugWorkaroundProperty ( ) { System . setProperty ( "jna.nosys" , "true" ) ; } }
package org . languagetool . tools ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternRule ; import java . util . List ; import static org . languagetool . tools . StringTools . * ; public class RuleAsXmlSerializer { private static final int CAPACITY = 200 ; public String getXmlStart ( Language lang , Language motherTongue ) { StringBuilder xml = new StringBuilder ( CAPACITY ) ; xml . append ( "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n" ) . append ( "<matches software=\"LanguageTool\" version=\"" + JLanguageTool . VERSION + "\"" + " buildDate=\"" ) . append ( JLanguageTool . BUILD_DATE ) . append ( "\">\n" ) ; if ( lang != null || motherTongue != null ) { String languageXml = "<language " ; if ( lang != null ) { languageXml += "shortname=\"" + lang . getShortNameWithCountryAndVariant ( ) + "\" name=\"" + lang . getName ( ) + "\"" ; } if ( motherTongue != null && ( lang == null || ! motherTongue . getShortName ( ) . equals ( lang . getShortNameWithCountryAndVariant ( ) ) ) ) { languageXml += " mothertongueshortname=\"" + motherTongue . getShortName ( ) + "\" mothertonguename=\"" + motherTongue . getName ( ) + "\"" ; } languageXml += "/>\n" ; xml . append ( languageXml ) ; } return xml . toString ( ) ; } public String getXmlEnd ( ) { return "</matches>\n" ; } public String ruleMatchesToXmlSnippet ( List < RuleMatch > ruleMatches , String text , int contextSize ) { StringBuilder xml = new StringBuilder ( CAPACITY ) ; ContextTools contextTools = new ContextTools ( ) ; contextTools . setEscapeHtml ( false ) ; contextTools . setContextSize ( contextSize ) ; String startMarker = "__languagetool_start_marker" ; contextTools . setErrorMarkerStart ( startMarker ) ; contextTools . setErrorMarkerEnd ( "" ) ; for ( RuleMatch match : ruleMatches ) { String subId = "" ; if ( match . getRule ( ) instanceof PatternRule ) { PatternRule pRule = ( PatternRule ) match . getRule ( ) ; if ( pRule . getSubId ( ) != null ) { subId = " subId=\"" + escapeXMLForAPIOutput ( pRule . getSubId ( ) ) + "\" " ; } } xml . append ( "<error fromy=\"" ) . append ( match . getLine ( ) ) . append ( '"' ) . append ( " fromx=\"" ) . append ( match . getColumn ( ) - 1 ) . append ( '"' ) . append ( " toy=\"" ) . append ( match . getEndLine ( ) ) . append ( '"' ) . append ( " tox=\"" ) . append ( match . getEndColumn ( ) - 1 ) . append ( '"' ) . append ( " ruleId=\"" ) . append ( match . getRule ( ) . getId ( ) ) . append ( '"' ) ; String msg = match . getMessage ( ) . replaceAll ( "</?suggestion>" , "'" ) ; xml . append ( subId ) ; xml . append ( " msg=\"" ) . append ( escapeXMLForAPIOutput ( msg ) ) . append ( '"' ) ; String context = contextTools . getContext ( match . getFromPos ( ) , match . getToPos ( ) , text ) ; xml . append ( " replacements=\"" ) . append ( escapeXMLForAPIOutput ( listToString ( match . getSuggestedReplacements ( ) , "#" ) ) ) . append ( '"' ) ; int contextOffset = context . indexOf ( startMarker ) ; context = context . replaceFirst ( startMarker , "" ) ; context = context . replaceAll ( "[\n\r]" , " " ) ; xml . append ( " context=\"" ) . append ( escapeForXmlAttribute ( context ) ) . append ( '"' ) . append ( " contextoffset=\"" ) . append ( contextOffset ) . append ( '"' ) . append ( " offset=\"" ) . append ( match . getFromPos ( ) ) . append ( '"' ) . append ( " errorlength=\"" ) . append ( match . getToPos ( ) - match . getFromPos ( ) ) . append ( '"' ) ; if ( match . getRule ( ) . getUrl ( ) != null ) { xml . append ( " url=\"" ) . append ( escapeXMLForAPIOutput ( match . getRule ( ) . getUrl ( ) . toString ( ) ) ) . append ( '"' ) ; } Category category = match . getRule ( ) . getCategory ( ) ; if ( category != null ) { xml . append ( " category=\"" ) . append ( escapeXMLForAPIOutput ( category . getName ( ) ) ) . append ( '"' ) ; } ITSIssueType type = match . getRule ( ) . getLocQualityIssueType ( ) ; if ( type != null ) { xml . append ( " locqualityissuetype=\"" ) . append ( escapeXMLForAPIOutput ( type . toString ( ) ) ) . append ( '"' ) ; } xml . append ( "/>\n" ) ; } return xml . toString ( ) ; } public String ruleMatchesToXml ( List < RuleMatch > ruleMatches , String text , int contextSize , Language lang , Language motherTongue ) { return getXmlStart ( lang , motherTongue ) + ruleMatchesToXmlSnippet ( ruleMatches , text , contextSize ) + getXmlEnd ( ) ; } public String ruleMatchesToXml ( List < RuleMatch > ruleMatches , String text , int contextSize , Language lang ) { return getXmlStart ( lang , null ) + ruleMatchesToXmlSnippet ( ruleMatches , text , contextSize ) + getXmlEnd ( ) ; } public String ruleMatchesToXml ( List < RuleMatch > ruleMatches , String text , int contextSize , XmlPrintMode xmlMode , Language lang , List < String > unknownWords ) { String xmlSnippet = ruleMatchesToXmlSnippet ( ruleMatches , text , contextSize ) ; switch ( xmlMode ) { case START_XML : return getXmlStart ( lang , null ) + xmlSnippet ; case CONTINUE_XML : return xmlSnippet ; case END_XML : return xmlSnippet + getXmlUnknownWords ( unknownWords ) + getXmlEnd ( ) ; case NORMAL_XML : return getXmlStart ( lang , null ) + xmlSnippet + getXmlUnknownWords ( unknownWords ) + getXmlEnd ( ) ; } throw new IllegalArgumentException ( "Unknown XML mode: " + xmlMode ) ; } private String getXmlUnknownWords ( List < String > unknownWords ) { StringBuilder xml = new StringBuilder ( CAPACITY ) ; if ( ! unknownWords . isEmpty ( ) ) { xml . append ( "<unknown_words>\n" ) ; for ( String word : unknownWords ) { xml . append ( " <word>" ) ; xml . append ( escapeForXmlAttribute ( word ) ) ; xml . append ( "</word>\n" ) ; } xml . append ( "</unknown_words>\n" ) ; } return xml . toString ( ) ; } private static String escapeXMLForAPIOutput ( String s ) { return escapeForXmlAttribute ( s ) . replaceAll ( "[\n\r]" , " " ) ; } }
package org . languagetool . tools ; public class ContextTools { private int contextSize = 40 ; private boolean escapeHtml = true ; private String errorMarkerStart = "<b><font bgcolor=\"#ff8b8b\">" ; private String errorMarkerEnd = "</font></b>" ; public ContextTools ( ) { } public String getContext ( final int fromPos , final int toPos , final String contents ) { final String text = contents . replace ( '\n' , ' ' ) ; int startContent = fromPos - contextSize ; String prefix = "..." ; String postfix = "..." ; String markerPrefix = " " ; if ( startContent < 0 ) { prefix = "" ; markerPrefix = "" ; startContent = 0 ; } int endContent = toPos + contextSize ; final int textLength = text . length ( ) ; if ( endContent > textLength ) { postfix = "" ; endContent = textLength ; } final StringBuilder marker = getMarker ( fromPos , toPos , textLength + prefix . length ( ) ) ; final StringBuilder sb = new StringBuilder ( ) ; sb . append ( prefix ) ; sb . append ( text . substring ( startContent , endContent ) ) ; final String markerStr = markerPrefix + marker . substring ( startContent , endContent ) ; sb . append ( postfix ) ; final int startMark = markerStr . indexOf ( '^' ) ; final int endMark = markerStr . lastIndexOf ( '^' ) ; String result = sb . toString ( ) ; if ( escapeHtml ) { final String escapedErrorPart = StringTools . escapeHTML ( result . substring ( startMark , endMark + 1 ) ) . replace ( " " , "&nbsp;" ) ; result = StringTools . escapeHTML ( result . substring ( 0 , startMark ) ) + errorMarkerStart + escapedErrorPart + errorMarkerEnd + StringTools . escapeHTML ( result . substring ( endMark + 1 ) ) ; } else { result = result . substring ( 0 , startMark ) + errorMarkerStart + result . substring ( startMark , endMark + 1 ) + errorMarkerEnd + result . substring ( endMark + 1 ) ; } return result ; } public String getPlainTextContext ( final int fromPos , final int toPos , final String contents ) { final String text = contents . replace ( '\n' , ' ' ) ; int startContent = fromPos - contextSize ; String prefix = "..." ; String postfix = "..." ; String markerPrefix = " " ; if ( startContent < 0 ) { prefix = "" ; markerPrefix = "" ; startContent = 0 ; } int endContent = toPos + contextSize ; if ( endContent > text . length ( ) ) { postfix = "" ; endContent = text . length ( ) ; } final StringBuilder marker = getMarker ( fromPos , toPos , text . length ( ) + prefix . length ( ) ) ; return prefix + text . substring ( startContent , endContent ) + postfix + '\n' + markerPrefix + marker . substring ( startContent , endContent ) ; } public void setErrorMarkerStart ( String errorMarkerStart ) { this . errorMarkerStart = errorMarkerStart ; } public void setErrorMarkerEnd ( String errorMarkerEnd ) { this . errorMarkerEnd = errorMarkerEnd ; } public void setContextSize ( int contextSize ) { this . contextSize = contextSize ; } public void setEscapeHtml ( boolean escapeHtml ) { this . escapeHtml = escapeHtml ; } private StringBuilder getMarker ( int fromPos , int toPos , int textLength ) { final StringBuilder marker = new StringBuilder ( ) ; for ( int i = 0 ; i < textLength ; i ++ ) { if ( i >= fromPos && i < toPos ) { marker . append ( '^' ) ; } else { marker . append ( ' ' ) ; } } return marker ; } }
package org . languagetool . databroker ; import java . io . InputStream ; import java . net . URL ; import org . languagetool . JLanguageTool ; public class DefaultResourceDataBroker implements ResourceDataBroker { private final String resourceDir ; private final String rulesDir ; public DefaultResourceDataBroker ( ) { this ( ResourceDataBroker . RESOURCE_DIR , ResourceDataBroker . RULES_DIR ) ; } public DefaultResourceDataBroker ( final String resourceDir , final String rulesDir ) { this . resourceDir = ( resourceDir == null ) ? "" : resourceDir ; this . rulesDir = ( rulesDir == null ) ? "" : rulesDir ; } @ Override public InputStream getFromResourceDirAsStream ( final String path ) { final String completePath = getCompleteResourceUrl ( path ) ; final InputStream resourceAsStream = ResourceDataBroker . class . getResourceAsStream ( completePath ) ; assertNotNull ( resourceAsStream , path , completePath ) ; return resourceAsStream ; } @ Override public URL getFromResourceDirAsUrl ( final String path ) { final String completePath = getCompleteResourceUrl ( path ) ; final URL resource = ResourceDataBroker . class . getResource ( completePath ) ; assertNotNull ( resource , path , completePath ) ; return resource ; } private String getCompleteResourceUrl ( final String path ) { return appendPath ( resourceDir , path ) ; } @ Override public InputStream getFromRulesDirAsStream ( final String path ) { final String completePath = getCompleteRulesUrl ( path ) ; final InputStream resourceAsStream = ResourceDataBroker . class . getResourceAsStream ( completePath ) ; assertNotNull ( resourceAsStream , path , completePath ) ; return resourceAsStream ; } @ Override public URL getFromRulesDirAsUrl ( final String path ) { final String completePath = getCompleteRulesUrl ( path ) ; final URL resource = ResourceDataBroker . class . getResource ( completePath ) ; assertNotNull ( resource , path , completePath ) ; return resource ; } private void assertNotNull ( Object object , String path , String completePath ) { if ( object == null ) { throw new RuntimeException ( "Path " + path + " not found in class path at " + completePath ) ; } } private String getCompleteRulesUrl ( final String path ) { return appendPath ( rulesDir , path ) ; } private String appendPath ( String baseDir , String path ) { final StringBuilder completePath = new StringBuilder ( baseDir ) ; if ( ! this . rulesDir . endsWith ( "/" ) && ! path . startsWith ( "/" ) ) { completePath . append ( '/' ) ; } if ( this . rulesDir . endsWith ( "/" ) && path . startsWith ( "/" ) && path . length ( ) > 1 ) { completePath . append ( path . substring ( 1 ) ) ; } else { completePath . append ( path ) ; } return completePath . toString ( ) ; } @ Override public boolean resourceExists ( String path ) { final String completePath = getCompleteResourceUrl ( path ) ; return ResourceDataBroker . class . getResource ( completePath ) != null ; } @ Override public boolean ruleFileExists ( String path ) { final String completePath = getCompleteRulesUrl ( path ) ; return ResourceDataBroker . class . getResource ( completePath ) != null ; } @ Override public String getResourceDir ( ) { return resourceDir ; } @ Override public String getRulesDir ( ) { return rulesDir ; } }
package org . languagetool . databroker ; import java . io . InputStream ; import java . net . URL ; import org . languagetool . JLanguageTool ; public interface ResourceDataBroker { public static final String RESOURCE_DIR = "/org/languagetool/resource" ; public static final String RULES_DIR = "/org/languagetool/rules" ; public URL getFromResourceDirAsUrl ( String path ) ; public boolean resourceExists ( String path ) ; public boolean ruleFileExists ( String path ) ; public InputStream getFromResourceDirAsStream ( String path ) ; public URL getFromRulesDirAsUrl ( String path ) ; public InputStream getFromRulesDirAsStream ( String path ) ; public String getResourceDir ( ) ; public String getRulesDir ( ) ; }
package org . languagetool . bitext ; import org . jetbrains . annotations . Nullable ; import java . io . IOException ; import java . util . Iterator ; public class WordFastTMReader extends TabBitextReader { public WordFastTMReader ( final String filename , final String encoding ) throws IOException { super ( filename , encoding ) ; if ( nextLine != null ) { nextLine = in . readLine ( ) ; nextPair = tab2StringPair ( nextLine ) ; } } @ Nullable @ Override public final StringPair tab2StringPair ( final String line ) { if ( line == null ) { return null ; } final String [ ] fields = line . split ( "\t" ) ; sentencePos = fields [ 4 ] . length ( ) + 1 ; return new StringPair ( fields [ 4 ] , fields [ 6 ] ) ; } @ Override public Iterator < StringPair > iterator ( ) { return new TabReader ( ) ; } class TabReader implements Iterator < StringPair > { @ Override public boolean hasNext ( ) { return nextLine != null ; } @ Override public StringPair next ( ) { try { final StringPair result = nextPair ; if ( nextLine != null ) { nextLine = in . readLine ( ) ; nextPair = tab2StringPair ( nextLine ) ; if ( nextLine == null ) { in . close ( ) ; } } return result ; } catch ( IOException e ) { throw new IllegalArgumentException ( e ) ; } } @ Override public void remove ( ) { throw new UnsupportedOperationException ( ) ; } } }
package org . languagetool . bitext ; import org . jetbrains . annotations . Nullable ; import java . io . BufferedReader ; import java . io . FileInputStream ; import java . io . IOException ; import java . io . InputStreamReader ; import java . util . Iterator ; public class TabBitextReader implements BitextReader { protected BufferedReader in ; protected StringPair nextPair ; protected String nextLine ; protected int sentencePos ; private String prevLine ; private int lineCount = - 1 ; public TabBitextReader ( final String filename , final String encoding ) { try { if ( encoding == null ) { in = new BufferedReader ( new InputStreamReader ( new FileInputStream ( filename ) ) ) ; } else { in = new BufferedReader ( new InputStreamReader ( new FileInputStream ( filename ) , encoding ) ) ; } nextLine = in . readLine ( ) ; prevLine = "" ; nextPair = tab2StringPair ( nextLine ) ; } catch ( IOException e ) { throw new IllegalArgumentException ( e ) ; } } @ Nullable protected StringPair tab2StringPair ( final String line ) { if ( line == null ) { return null ; } final String [ ] fields = line . split ( "\t" ) ; if ( fields . length < 2 ) { throw new RuntimeException ( "Unexpected format, expected two tab-separated columns: " + line ) ; } return new StringPair ( fields [ 0 ] , fields [ 1 ] ) ; } @ Override public Iterator < StringPair > iterator ( ) { return new TabReader ( ) ; } class TabReader implements Iterator < StringPair > { @ Override public boolean hasNext ( ) { return nextLine != null ; } @ Override public StringPair next ( ) { try { final StringPair result = nextPair ; sentencePos = nextPair . getSource ( ) . length ( ) + 1 ; if ( nextLine != null ) { prevLine = nextLine ; nextLine = in . readLine ( ) ; nextPair = tab2StringPair ( nextLine ) ; lineCount ++ ; if ( nextLine == null ) { in . close ( ) ; } } return result ; } catch ( IOException e ) { throw new IllegalArgumentException ( e ) ; } } @ Override public void remove ( ) { throw new UnsupportedOperationException ( ) ; } } @ Override public int getColumnCount ( ) { return sentencePos ; } @ Override public int getTargetColumnCount ( ) { return 1 ; } @ Override public int getLineCount ( ) { return lineCount ; } @ Override public int getSentencePosition ( ) { return sentencePos ; } @ Override public String getCurrentLine ( ) { return prevLine ; } }
package org . languagetool . tokenizers . nl ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Dutch ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; public class DutchSRXSentenceTokenizerTest extends TestCase { private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer ( new Dutch ( ) ) ; public void testTokenize ( ) { testSplit ( "Dit is een zin." ) ; testSplit ( "Dit is een zin. " , "Nog een." ) ; testSplit ( "Een zin! " , "Nog een." ) ; testSplit ( "Een zin... " , "Nog een." ) ; testSplit ( "Op http://www.test.de vind je een website." ) ; testSplit ( "De brief is op 3.10 gedateerd." ) ; testSplit ( "De brief is op 31.1 gedateerd." ) ; testSplit ( "De breif is op 3.10.2000 gedateerd." ) ; testSplit ( "Vandaag is het 13.12.2004." ) ; testSplit ( "Op 24.09 begint het." ) ; testSplit ( "Om 17:00 begint het." ) ; testSplit ( "In paragraaf 3.9.1 is dat beschreven." ) ; testSplit ( "Januari jl. is dat vastgelegd." ) ; testSplit ( "Appel en pruimen enz. werden gekocht." ) ; testSplit ( "De afkorting n.v.t. betekent niet van toepassing." ) ; testSplit ( "Bla et al. blah blah." ) ; testSplit ( "Dat is,, of het is bla." ) ; testSplit ( "Dat is het.. " , "Zo gaat het verder." ) ; testSplit ( "Dit hier is een(!) zin." ) ; testSplit ( "Dit hier is een(!!) zin." ) ; testSplit ( "Dit hier is een(?) zin." ) ; testSplit ( "Dit hier is een(???) zin." ) ; testSplit ( "Dit hier is een(???) zin." ) ; testSplit ( "»De papagaai is groen.« " , "Dat was hij al." ) ; testSplit ( "»De papagaai is groen«, zei hij." ) ; testSplit ( "Als voetballer wordt hij nooit een prof. " , "Maar prof. N.A.W. Th.Ch. Janssen wordt dat wel." ) ; testSplit ( "Dat was het: helemaal niets." ) ; testSplit ( "Dat was het: het is een nieuwe zin." ) ; } private void testSplit ( String ... sentences ) { TestTools . testSplit ( sentences , stokenizer ) ; } }
package org . languagetool . bitext ; public final class StringPair { private final String sourceString ; private final String targetString ; public StringPair ( final String source , final String target ) { sourceString = source ; targetString = target ; } public String getSource ( ) { return sourceString ; } public String getTarget ( ) { return targetString ; } @ Override public String toString ( ) { return sourceString + " & " + targetString ; } }
package org . languagetool . bitext ; public interface BitextReader extends Iterable < StringPair > { public int getLineCount ( ) ; public int getColumnCount ( ) ; public int getTargetColumnCount ( ) ; public int getSentencePosition ( ) ; public String getCurrentLine ( ) ; }
package org . languagetool . rules ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import java . io . IOException ; import java . util . * ; public abstract class AbstractWordCoherencyRule extends Rule { protected abstract Map < String , String > getWordMap ( ) ; protected abstract String getMessage ( String word1 , String word2 ) ; private final Map < String , RuleMatch > shouldNotAppearWord = new HashMap < > ( ) ; public AbstractWordCoherencyRule ( ResourceBundle messages ) throws IOException { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; for ( AnalyzedTokenReadings tmpToken : tokens ) { String token = tmpToken . getToken ( ) ; final List < AnalyzedToken > readings = tmpToken . getReadings ( ) ; if ( readings . size ( ) > 0 ) { final String baseform = readings . get ( 0 ) . getLemma ( ) ; if ( baseform != null ) { token = baseform ; } } if ( shouldNotAppearWord . containsKey ( token ) ) { final RuleMatch otherMatch = shouldNotAppearWord . get ( token ) ; final String otherSpelling = otherMatch . getMessage ( ) ; final String msg = getMessage ( token , otherSpelling ) ; final RuleMatch ruleMatch = new RuleMatch ( this , tmpToken . getStartPos ( ) , tmpToken . getEndPos ( ) , msg ) ; ruleMatch . setSuggestedReplacement ( otherSpelling ) ; ruleMatches . add ( ruleMatch ) ; } else if ( getWordMap ( ) . containsKey ( token ) ) { final String shouldNotAppear = getWordMap ( ) . get ( token ) ; final RuleMatch potentialRuleMatch = new RuleMatch ( this , tmpToken . getStartPos ( ) , tmpToken . getEndPos ( ) , token ) ; shouldNotAppearWord . put ( shouldNotAppear , potentialRuleMatch ) ; } } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { shouldNotAppearWord . clear ( ) ; } }
package org . languagetool . rules ; import org . languagetool . rules . patterns . PatternRule ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; public class RuleWithMaxFilter implements RuleMatchFilter { @ Override public final List < RuleMatch > filter ( final List < RuleMatch > ruleMatches ) { Collections . sort ( ruleMatches ) ; final List < RuleMatch > filteredRules = new ArrayList < > ( ) ; for ( int i = 0 ; i < ruleMatches . size ( ) ; i ++ ) { final RuleMatch match = ruleMatches . get ( i ) ; if ( i < ruleMatches . size ( ) - 1 ) { RuleMatch nextMatch = ruleMatches . get ( i + 1 ) ; while ( includes ( match , nextMatch ) && haveSameRule ( match , nextMatch ) && i < ruleMatches . size ( ) ) { i ++ ; if ( i < ruleMatches . size ( ) - 1 ) { nextMatch = ruleMatches . get ( i + 1 ) ; } } } filteredRules . add ( match ) ; } return filteredRules ; } final boolean includes ( final RuleMatch match , final RuleMatch nextMatch ) { if ( match . getFromPos ( ) <= nextMatch . getFromPos ( ) && match . getToPos ( ) >= nextMatch . getToPos ( ) ) { return true ; } return false ; } private boolean haveSameRule ( final RuleMatch match , final RuleMatch nextMatch ) { if ( ! ( match . getRule ( ) instanceof PatternRule ) || ! ( nextMatch . getRule ( ) instanceof PatternRule ) ) { return false ; } final String id1 = match . getRule ( ) . getId ( ) ; final String subId1 = ( ( PatternRule ) match . getRule ( ) ) . getSubId ( ) ; final String subId2 = ( ( PatternRule ) nextMatch . getRule ( ) ) . getSubId ( ) ; if ( subId1 == null && subId2 != null ) { return false ; } if ( subId1 != null && subId2 == null ) { return false ; } return id1 != null && id1 . equals ( nextMatch . getRule ( ) . getId ( ) ) && ( subId1 == null && subId2 == null || subId1 != null && subId1 . equals ( subId2 ) ) ; } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; import java . util . Objects ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . apache . commons . lang . builder . EqualsBuilder ; import org . apache . commons . lang . builder . HashCodeBuilder ; import org . languagetool . tools . StringTools ; public class RuleMatch implements Comparable < RuleMatch > { private static final Pattern SUGGESTION_PATTERN = Pattern . compile ( "<suggestion>(.*?)</suggestion>" ) ; private final Rule rule ; private final OffsetPosition offsetPosition ; private final String message ; private final String shortMessage ; private LinePosition linePosition = new LinePosition ( - 1 , - 1 ) ; private ColumnPosition columnPosition = new ColumnPosition ( - 1 , - 1 ) ; private List < String > suggestedReplacements = new ArrayList < > ( ) ; public RuleMatch ( Rule rule , int fromPos , int toPos , String message ) { this ( rule , fromPos , toPos , message , null , false , null ) ; } public RuleMatch ( Rule rule , int fromPos , int toPos , String message , String shortMessage ) { this ( rule , fromPos , toPos , message , shortMessage , false , null ) ; } public RuleMatch ( Rule rule , int fromPos , int toPos , String message , String shortMessage , boolean startWithUppercase , String suggestionsOutMsg ) { this . rule = rule ; if ( toPos <= fromPos ) { throw new RuntimeException ( "fromPos (" + fromPos + ") must be less than toPos (" + toPos + ")" ) ; } this . offsetPosition = new OffsetPosition ( fromPos , toPos ) ; this . message = message ; this . shortMessage = shortMessage ; final Matcher matcher = SUGGESTION_PATTERN . matcher ( message + suggestionsOutMsg ) ; int pos = 0 ; while ( matcher . find ( pos ) ) { pos = matcher . end ( ) ; String replacement = matcher . group ( 1 ) ; if ( startWithUppercase ) { replacement = StringTools . uppercaseFirstChar ( replacement ) ; } suggestedReplacements . add ( replacement ) ; } } public Rule getRule ( ) { return rule ; } public void setLine ( final int fromLine ) { linePosition = new LinePosition ( fromLine , linePosition . getEnd ( ) ) ; } public int getLine ( ) { return linePosition . getStart ( ) ; } public void setEndLine ( final int endLine ) { linePosition = new LinePosition ( linePosition . getStart ( ) , endLine ) ; } public int getEndLine ( ) { return linePosition . getEnd ( ) ; } public void setColumn ( final int column ) { this . columnPosition = new ColumnPosition ( column , columnPosition . getEnd ( ) ) ; } public int getColumn ( ) { return columnPosition . getStart ( ) ; } public void setEndColumn ( final int endColumn ) { this . columnPosition = new ColumnPosition ( columnPosition . getStart ( ) , endColumn ) ; } public int getEndColumn ( ) { return columnPosition . getEnd ( ) ; } public int getFromPos ( ) { return offsetPosition . getStart ( ) ; } public int getToPos ( ) { return offsetPosition . getEnd ( ) ; } public String getMessage ( ) { return message ; } public String getShortMessage ( ) { return shortMessage ; } public void setSuggestedReplacement ( final String replacement ) { Objects . requireNonNull ( replacement , "replacement may be empty but not null" ) ; final List < String > replacements = new ArrayList < > ( ) ; replacements . add ( replacement ) ; setSuggestedReplacements ( replacements ) ; } public void setSuggestedReplacements ( final List < String > replacements ) { this . suggestedReplacements = Objects . requireNonNull ( replacements , "replacements may be empty but not null" ) ; } public List < String > getSuggestedReplacements ( ) { return Collections . unmodifiableList ( suggestedReplacements ) ; } @ Override public String toString ( ) { return rule . getId ( ) + ":" + offsetPosition + ":" + message ; } @ Override public int compareTo ( final RuleMatch other ) { Objects . requireNonNull ( other ) ; return Integer . compare ( getFromPos ( ) , other . getFromPos ( ) ) ; } @ Override public boolean equals ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; RuleMatch other = ( RuleMatch ) o ; return new EqualsBuilder ( ) . append ( rule . getId ( ) , other . rule . getId ( ) ) . append ( offsetPosition , other . offsetPosition ) . append ( message , other . message ) . append ( suggestedReplacements , other . suggestedReplacements ) . isEquals ( ) ; } @ Override public int hashCode ( ) { return new HashCodeBuilder ( ) . append ( rule . getId ( ) ) . append ( offsetPosition ) . append ( message ) . append ( suggestedReplacements ) . toHashCode ( ) ; } static class OffsetPosition extends MatchPosition { OffsetPosition ( int start , int end ) { super ( start , end ) ; } } static class LinePosition extends MatchPosition { LinePosition ( int start , int end ) { super ( start , end ) ; } } static class ColumnPosition extends MatchPosition { ColumnPosition ( int start , int end ) { super ( start , end ) ; } } }
package org . languagetool . rules ; import org . languagetool . JLanguageTool ; import java . io . InputStream ; import java . util . * ; public final class SimpleReplaceDataLoader { public Map < String , List < String > > loadWords ( String path ) { InputStream stream = JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( path ) ; Map < String , List < String > > map = new HashMap < > ( ) ; try ( Scanner scanner = new Scanner ( stream , "utf-8" ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } String [ ] parts = line . split ( "=" ) ; if ( parts . length != 2 ) { throw new RuntimeException ( "Could not load simple replacement data from: " + path + ". " + "Error in line '" + line + "', expected format 'word=replacement'" ) ; } String [ ] wrongForms = parts [ 0 ] . split ( "\\|" ) ; List < String > replacements = Arrays . asList ( parts [ 1 ] . split ( "\\|" ) ) ; for ( String wrongForm : wrongForms ) { map . put ( wrongForm , replacements ) ; } } } return Collections . unmodifiableMap ( map ) ; } }
package org . languagetool . rules ; import org . languagetool . tools . StringTools ; import java . util . * ; public class ConfusionSet { private final Set < ConfusionString > set = new HashSet < > ( ) ; private final long factor ; public ConfusionSet ( long factor , List < ConfusionString > confusionStrings ) { if ( factor < 1 ) { throw new IllegalArgumentException ( "factor must be >= 1: " + factor ) ; } this . factor = factor ; set . addAll ( Objects . requireNonNull ( confusionStrings ) ) ; } public ConfusionSet ( long factor , String ... words ) { if ( factor < 1 ) { throw new IllegalArgumentException ( "factor must be >= 1: " + factor ) ; } Objects . requireNonNull ( words ) ; this . factor = factor ; for ( String word : words ) { set . add ( new ConfusionString ( word , null ) ) ; } } public long getFactor ( ) { return factor ; } public Set < ConfusionString > getSet ( ) { return Collections . unmodifiableSet ( set ) ; } public Set < ConfusionString > getUppercaseFirstCharSet ( ) { Set < ConfusionString > result = new HashSet < > ( ) ; for ( ConfusionString s : set ) { ConfusionString newString = new ConfusionString ( StringTools . uppercaseFirstChar ( s . getString ( ) ) , s . getDescription ( ) ) ; result . add ( newString ) ; } return Collections . unmodifiableSet ( result ) ; } @ Override public String toString ( ) { return set . toString ( ) ; } @ Override public boolean equals ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; ConfusionSet other = ( ConfusionSet ) o ; if ( factor != other . factor ) return false ; if ( ! set . equals ( other . set ) ) return false ; return true ; } @ Override public int hashCode ( ) { int result = set . hashCode ( ) ; result = 31 * result + ( int ) ( factor ^ ( factor > > > 32 ) ) ; return result ; } }
package org . languagetool . rules ; import org . languagetool . AnalyzedSentence ; import org . languagetool . Experimental ; import java . io . IOException ; import java . util . List ; import java . util . ResourceBundle ; @ Experimental public abstract class TextLevelRule extends Rule { public TextLevelRule ( ResourceBundle messages ) { super ( messages ) ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { throw new RuntimeException ( "Not implemented for a text-level rule" ) ; } public RuleMatch [ ] match ( List < AnalyzedSentence > sentence ) throws IOException { return new RuleMatch [ 0 ] ; } @ Override public final void reset ( ) { } }
package org . languagetool . rules ; class MatchPosition { private final int start ; private final int end ; MatchPosition ( int start , int end ) { this . start = start ; this . end = end ; } int getStart ( ) { return start ; } int getEnd ( ) { return end ; } @ Override public String toString ( ) { return start + "-" + end ; } @ Override public boolean equals ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; MatchPosition position = ( MatchPosition ) o ; if ( end != position . end ) return false ; if ( start != position . start ) return false ; return true ; } @ Override public int hashCode ( ) { int result = start ; result = 31 * result + end ; return result ; } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; public class WordRepeatBeginningRule extends Rule { private String lastToken = "" ; private String beforeLastToken = "" ; public WordRepeatBeginningRule ( final ResourceBundle messages , final Language language ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setLocQualityIssueType ( ITSIssueType . Style ) ; } @ Override public String getId ( ) { return "WORD_REPEAT_BEGINNING_RULE" ; } @ Override public String getDescription ( ) { return messages . getString ( "desc_repetition_beginning" ) ; } protected boolean isAdverb ( AnalyzedTokenReadings token ) { return false ; } public boolean isException ( String token ) { return token . equals ( ":" ) || token . equals ( "–" ) || token . equals ( "-" ) ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; if ( tokens . length > 3 ) { final AnalyzedTokenReadings analyzedToken = tokens [ 1 ] ; final String token = analyzedToken . getToken ( ) ; boolean isWord = true ; if ( token . length ( ) == 1 ) { final char c = token . charAt ( 0 ) ; if ( ! Character . isLetter ( c ) ) { isWord = false ; } } if ( isWord && lastToken . equals ( token ) && ! isException ( token ) && ! isException ( tokens [ 2 ] . getToken ( ) ) && ! isException ( tokens [ 3 ] . getToken ( ) ) ) { final String shortMsg ; if ( isAdverb ( analyzedToken ) ) { shortMsg = messages . getString ( "desc_repetition_beginning_adv" ) ; } else if ( beforeLastToken . equals ( token ) ) { shortMsg = messages . getString ( "desc_repetition_beginning_word" ) ; } else { shortMsg = "" ; } if ( ! shortMsg . isEmpty ( ) ) { final String msg = shortMsg + " " + messages . getString ( "desc_repetition_beginning_thesaurus" ) ; final int startPos = analyzedToken . getStartPos ( ) ; final int endPos = startPos + token . length ( ) ; final RuleMatch ruleMatch = new RuleMatch ( this , startPos , endPos , msg , shortMsg ) ; ruleMatches . add ( ruleMatch ) ; } } beforeLastToken = lastToken ; lastToken = token ; } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { lastToken = "" ; beforeLastToken = "" ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . nl . CompoundRule ; import org . languagetool . rules . nl . DutchWrongWordInContextRule ; import org . languagetool . rules . nl . MorfologikDutchSpellerRule ; import org . languagetool . rules . nl . SimpleReplaceRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . nl . DutchSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . nl . DutchTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . nl . DutchWordTokenizer ; public class Dutch extends Language { private Tagger tagger ; private SentenceTokenizer sentenceTokenizer ; private Synthesizer synthesizer ; private Disambiguator disambiguator ; private Tokenizer wordTokenizer ; @ Override public String getName ( ) { return "Dutch" ; } @ Override public String getShortName ( ) { return "nl" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "NL" , "BE" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new DutchTagger ( ) ; } return tagger ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new DutchSynthesizer ( ) ; } return synthesizer ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new DutchWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new XmlRuleDisambiguator ( new Dutch ( ) ) ; } return disambiguator ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "OpenTaal" , "http://www.opentaal.org" ) , new Contributor ( "TaalTik" , "http://www.taaltik.nl" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new GenericUnpairedBracketsRule ( messages , Arrays . asList ( "[" , "(" , "{" , "“" , "‹" , "“" , "„" ) , Arrays . asList ( "]" , ")" , "}" , "”" , "›" , "”" , "”" ) ) , new UppercaseSentenceStartRule ( messages , this ) , new MorfologikDutchSpellerRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new CompoundRule ( messages ) , new DutchWrongWordInContextRule ( messages ) , new SimpleReplaceRule ( messages ) ) ; } }
package org . languagetool . rules . ca ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import static org . junit . Assert . assertEquals ; public class MorfologikCatalanSpellerRuleTest { @ Test public void testMorfologikSpeller ( ) throws IOException { MorfologikCatalanSpellerRule rule = new MorfologikCatalanSpellerRule ( TestTools . getMessages ( "ca" ) , new Catalan ( ) ) ; RuleMatch [ ] matches ; JLanguageTool langTool = new JLanguageTool ( new Catalan ( ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "S'autodefineixin com a populars." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "L'exdirigent del partit." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "S'autoprenia." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "S'autocanta." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "S'autopren." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Abacallanada" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Abatre-les-en" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Allò que més l'interessa." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Porta'n quatre al col·legi." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Has de portar-me'n moltes." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Francès i francés." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Viu al núm. 23 del carrer Nou." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "N'hi ha de color vermell, blau, verd, etc." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Era vox populi." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Aquell era l'statu quo." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Va ser la XIV edició." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "LanguageTool!" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "," ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "123454" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "1234,54" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "1.234,54" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "1 234,54" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "-1 234,54" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Fa una temperatura de 30°C" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Fa una temperatura de 30 °C" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Any2010" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "pH" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "McDonald" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "AixòÉsUnError" ) ) . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Bordoy" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "Bordó" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "Bordoi" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "Bordo" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; assertEquals ( "Bordon" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 3 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Mal'aysia" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Mala’ysia" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Malaysia" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "Malàisia" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 1 , matches [ 0 ] . getSuggestedReplacements ( ) . size ( ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "quna" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "que" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "una" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "quan" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Video" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "Vídeo" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "bànner" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "bàner" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "especialisats" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "especialitzats" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "colaborassió" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "col·laboració" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "colaboració" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "col·laboració" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "sssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss" ) ) ; assertEquals ( 1 , matches . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "plassa" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "plaça" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Deú" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "Deu" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "Déu" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "joan" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 4 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( "Joan" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "abatusats" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 9 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( "abatussats" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "L'statu" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 2 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 7 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( "tato" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "argüit" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( 0 , matches [ 0 ] . getFromPos ( ) ) ; assertEquals ( 6 , matches [ 0 ] . getToPos ( ) ) ; assertEquals ( "arguït" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "argüir" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "argüint" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "ángel" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "àngel" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "Àngel" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "caçessim" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "cacéssim" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "cassàssim" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "casséssim" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; assertEquals ( "casàssim" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 3 ) ) ; assertEquals ( "caséssim" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 4 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "coche" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "cotxe" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "cuixa" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "coixa" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "cantaríà" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "cantaria" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "cantera" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "poguem" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "puguem" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "PH" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "Ph" ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "MCDonald" ) ) . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "tAula" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "taula" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "TAula" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "Taula" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "col·Labora" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "col·labora" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "col·laborÀ" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "col·laborà" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "después" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "després" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "dessinstalasio" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "desinstal·làssiu" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "desinstal·lació" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "matitzàrem" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "matisarem" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "matisàrem" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "tamitzéssim" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "tamisàssim" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "adquireixquen" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "adquirisquen" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "adquiresquen" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "calificar" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "qualificar" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "desconte" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "descompte" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "atentats" ) ) ; assertEquals ( "atemptats" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "síntomes" ) ) ; assertEquals ( "símptomes" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "atentats" ) ) ; assertEquals ( "atemptats" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "contable" ) ) ; assertEquals ( "comptable" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "desició" ) ) ; assertEquals ( "decisió" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "España" ) ) ; assertEquals ( "Espanya" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "concenciosament" ) ) ; assertEquals ( "conscienciosament" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "excelent" ) ) ; assertEquals ( "excel·lent" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "exceleixquen" ) ) ; assertEquals ( "excel·lisquen" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "caligrafia" ) ) ; assertEquals ( "cal·ligrafia" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "calificaren" ) ) ; assertEquals ( "qualificaren" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Excelentissim" ) ) ; assertEquals ( "Excel·lentíssim" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "En la Pecra" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "Para" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "Pare" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "IVa" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "Iva" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "IVA" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Dvd" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "DVD" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "S'hi havien instaŀlat." ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "S'HI HAVIEN INSTAĿLAT." ) ) . length ) ; assertEquals ( 1 , rule . match ( langTool . getAnalyzedSentence ( "aõh" ) ) . length ) ; assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "a" ) ) . length ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Magradaria" ) ) ; assertEquals ( "M'agradaria" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "tenvio" ) ) ; assertEquals ( "t'envio" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "portan" ) ) ; assertEquals ( "porta'n" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "consultins" ) ) ; assertEquals ( "consulti'ns" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "portarvos" ) ) ; assertEquals ( "portar-vos" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "portemne" ) ) ; assertEquals ( "portem-ne" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "dacontentar" ) ) ; assertEquals ( "d'acontentar" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "devidents" ) ) ; assertEquals ( "de vidents" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "d'evidents" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "lacomplexat" ) ) ; assertEquals ( "la complexat" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "l'acomplexat" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "dacomplexats" ) ) ; assertEquals ( "d'acomplexats" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "lacomplexats" ) ) ; assertEquals ( "la complexats" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "acomplexats" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "veurehi" ) ) ; assertEquals ( "veure-hi" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "veurels" ) ) ; assertEquals ( "veure'ls" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "veureles" ) ) ; assertEquals ( "veure-les" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "lilla" ) ) ; assertEquals ( "l'illa" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "portas" ) ) ; assertEquals ( "portes" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "mantenir'me" ) ) ; assertEquals ( "mantenir-me" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "elcap" ) ) ; assertEquals ( "el cap" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "almeu" ) ) ; assertEquals ( "al meu" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "delteu" ) ) ; assertEquals ( "del teu" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "unshomes" ) ) ; assertEquals ( "uns homes" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "pelsseus" ) ) ; assertEquals ( "pels seus" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "daquesta" ) ) ; assertEquals ( "d'aquesta" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "daquelles" ) ) ; assertEquals ( "d'aquelles" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "lah" ) ) ; assertEquals ( "la" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "dela" ) ) ; assertEquals ( "de la" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "sha" ) ) ; assertEquals ( "s'ha" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "xe" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "xa" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "Sha" ) ) ; assertEquals ( "S'ha" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . EmptyStackException ; public class UnsyncStack < E > extends ArrayList < E > { private static final long serialVersionUID = - 4984830372178073605L ; UnsyncStack ( ) { } public E push ( E item ) { add ( item ) ; return item ; } public E pop ( ) { E obj ; int len = size ( ) ; obj = peek ( ) ; remove ( len - 1 ) ; return obj ; } public E peek ( ) { int len = size ( ) ; if ( len == 0 ) { throw new EmptyStackException ( ) ; } return get ( len - 1 ) ; } public boolean empty ( ) { return size ( ) == 0 ; } public int search ( Object o ) { int i = lastIndexOf ( o ) ; if ( i >= 0 ) { return size ( ) - i ; } return - 1 ; } }
package org . languagetool . rules ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import java . util . Scanner ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; public abstract class WrongWordInContextRule extends Rule { private final List < ContextWords > contextWordsSet ; public WrongWordInContextRule ( final ResourceBundle messages ) { super . setCategory ( new Category ( getCategoryString ( ) ) ) ; contextWordsSet = loadContextWords ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( getFilename ( ) ) ) ; setLocQualityIssueType ( ITSIssueType . Misspelling ) ; } protected abstract String getFilename ( ) ; protected String getCategoryString ( ) { return messages . getString ( "category_misc" ) ; } @ Override public String getId ( ) { return "WRONG_WORD_IN_CONTEXT" ; } @ Override public String getDescription ( ) { return "Confusion of words" ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; for ( ContextWords contextWords : contextWordsSet ) { final boolean [ ] matchedWord = { false , false } ; final Matcher [ ] matchers = { null , null } ; matchers [ 0 ] = contextWords . words [ 0 ] . matcher ( "" ) ; matchers [ 1 ] = contextWords . words [ 1 ] . matcher ( "" ) ; int i ; String token1 = "" ; for ( i = 1 ; i < tokens . length && ! matchedWord [ 0 ] ; i ++ ) { token1 = tokens [ i ] . getToken ( ) ; matchedWord [ 0 ] = matchers [ 0 ] . reset ( token1 ) . find ( ) ; } int j ; String token2 = "" ; for ( j = 1 ; j < tokens . length && ! matchedWord [ 1 ] ; j ++ ) { token2 = tokens [ j ] . getToken ( ) ; matchedWord [ 1 ] = matchers [ 1 ] . reset ( token2 ) . find ( ) ; } int foundWord = - 1 ; int notFoundWord = - 1 ; int startPos = 0 ; int endPos = 0 ; String matchedToken = "" ; if ( matchedWord [ 0 ] && ! matchedWord [ 1 ] ) { foundWord = 0 ; notFoundWord = 1 ; matchers [ 1 ] = contextWords . contexts [ 1 ] . matcher ( "" ) ; startPos = tokens [ i - 1 ] . getStartPos ( ) ; endPos = tokens [ i - 1 ] . getStartPos ( ) + token1 . length ( ) ; matchedToken = token1 ; } else if ( matchedWord [ 1 ] && ! matchedWord [ 0 ] ) { foundWord = 1 ; notFoundWord = 0 ; matchers [ 0 ] = contextWords . contexts [ 0 ] . matcher ( "" ) ; startPos = tokens [ j - 1 ] . getStartPos ( ) ; endPos = tokens [ j - 1 ] . getStartPos ( ) + token2 . length ( ) ; matchedToken = token2 ; } if ( foundWord != - 1 ) { final boolean [ ] matchedContext = { false , false } ; matchers [ foundWord ] = contextWords . contexts [ foundWord ] . matcher ( "" ) ; matchers [ notFoundWord ] = contextWords . contexts [ notFoundWord ] . matcher ( "" ) ; String token ; for ( i = 1 ; i < tokens . length && ! matchedContext [ foundWord ] ; i ++ ) { token = tokens [ i ] . getToken ( ) ; matchedContext [ foundWord ] = matchers [ foundWord ] . reset ( token ) . find ( ) ; } for ( i = 1 ; i < tokens . length && ! matchedContext [ notFoundWord ] ; i ++ ) { token = tokens [ i ] . getToken ( ) ; matchedContext [ notFoundWord ] = matchers [ notFoundWord ] . reset ( token ) . find ( ) ; } if ( matchedContext [ notFoundWord ] && ! matchedContext [ foundWord ] ) { final String msg = getMessage ( matchedToken , matchedToken . replaceFirst ( contextWords . matches [ foundWord ] , contextWords . matches [ notFoundWord ] ) , contextWords . explanations [ notFoundWord ] , contextWords . explanations [ foundWord ] ) ; final RuleMatch ruleMatch = new RuleMatch ( this , startPos , endPos , msg , getShortMessageString ( ) ) ; ruleMatches . add ( ruleMatch ) ; } } } return toRuleMatchArray ( ruleMatches ) ; } protected abstract String getMessageString ( ) ; protected abstract String getShortMessageString ( ) ; protected abstract String getLongMessageString ( ) ; private String getMessage ( String wrongWord , String suggestion , String explanationSuggestion , String explanationWrongWord ) { if ( explanationSuggestion . isEmpty ( ) || explanationWrongWord . isEmpty ( ) ) { return getMessageString ( ) . replaceFirst ( "\\$SUGGESTION" , suggestion ) . replaceFirst ( "\\$WRONGWORD" , wrongWord ) ; } else { return getLongMessageString ( ) . replaceFirst ( "\\$SUGGESTION" , suggestion ) . replaceFirst ( "\\$WRONGWORD" , wrongWord ) . replaceFirst ( "\\$EXPLANATION_SUGGESTION" , explanationSuggestion ) . replaceFirst ( "\\$EXPLANATION_WRONGWORD" , explanationWrongWord ) ; } } private List < ContextWords > loadContextWords ( final InputStream stream ) { final List < ContextWords > set = new ArrayList < > ( ) ; try ( Scanner scanner = new Scanner ( stream , "utf-8" ) ) { while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ; if ( line . trim ( ) . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } final String [ ] column = line . split ( "\t" ) ; if ( column . length >= 6 ) { final ContextWords contextWords = new ContextWords ( ) ; contextWords . setWord ( 0 , column [ 0 ] ) ; contextWords . setWord ( 1 , column [ 1 ] ) ; contextWords . matches [ 0 ] = column [ 2 ] ; contextWords . matches [ 1 ] = column [ 3 ] ; contextWords . setContext ( 0 , column [ 4 ] ) ; contextWords . setContext ( 1 , column [ 5 ] ) ; if ( column . length > 6 ) { contextWords . explanations [ 0 ] = column [ 6 ] ; if ( column . length > 7 ) { contextWords . explanations [ 1 ] = column [ 7 ] ; } } set . add ( contextWords ) ; } } } return set ; } static class ContextWords { String [ ] matches = { "" , "" } ; String [ ] explanations = { "" , "" } ; Pattern [ ] words ; Pattern [ ] contexts ; ContextWords ( ) { words = new Pattern [ 2 ] ; contexts = new Pattern [ 2 ] ; } private String addBoundaries ( String str ) { String ignoreCase = "" ; if ( str . startsWith ( "(?i)" ) ) { str = str . substring ( 4 ) ; ignoreCase = "(?i)" ; } return ignoreCase + "\\b(" + str + ")\\b" ; } public void setWord ( int i , String word ) { words [ i ] = Pattern . compile ( addBoundaries ( word ) ) ; } public void setContext ( int i , String context ) { contexts [ i ] = Pattern . compile ( addBoundaries ( context ) ) ; } } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; public abstract class AbstractSpaceBeforeRule extends Rule { protected abstract Pattern getConjunctions ( ) ; public AbstractSpaceBeforeRule ( final ResourceBundle messages , final Language language ) { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } @ Override public String getId ( ) { return "SPACE_BEFORE_CONJUNCTION" ; } @ Override public String getDescription ( ) { return "Checks for missing space before some conjunctions" ; } protected String getShort ( ) { return "Missing white space" ; } protected String getSuggestion ( ) { return "Missing white space before conjunction" ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokens ( ) ; for ( int i = 1 ; i < tokens . length ; i ++ ) { final String token = tokens [ i ] . getToken ( ) ; Matcher matcher = getConjunctions ( ) . matcher ( token ) ; if ( matcher . matches ( ) ) { final String previousToken = tokens [ i - 1 ] . getToken ( ) ; if ( ! ( previousToken . equals ( " " ) || previousToken . equals ( "(" ) ) ) { final String replacement = " " + token ; final String msg = getSuggestion ( ) ; final int pos = tokens [ i ] . getStartPos ( ) ; final RuleMatch potentialRuleMatch = new RuleMatch ( this , pos , pos + token . length ( ) , msg , getShort ( ) ) ; potentialRuleMatch . setSuggestedReplacement ( replacement ) ; ruleMatches . add ( potentialRuleMatch ) ; } } } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . util . * ; import java . util . concurrent . ArrayBlockingQueue ; public abstract class AbstractCompoundRule extends Rule { static final int MAX_TERMS = 5 ; private final String withHyphenMessage ; private final String withoutHyphenMessage ; private final String withOrWithoutHyphenMessage ; private final String shortDesc ; @ Override public abstract String getId ( ) ; @ Override public abstract String getDescription ( ) ; protected abstract CompoundRuleData getCompoundRuleData ( ) ; public AbstractCompoundRule ( ResourceBundle messages , String withHyphenMessage , String withoutHyphenMessage , String withOrWithoutHyphenMessage ) throws IOException { this ( messages , withHyphenMessage , withoutHyphenMessage , withOrWithoutHyphenMessage , null ) ; } public AbstractCompoundRule ( ResourceBundle messages , String withHyphenMessage , String withoutHyphenMessage , String withOrWithoutHyphenMessage , String shortMessage ) throws IOException { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; this . withHyphenMessage = withHyphenMessage ; this . withoutHyphenMessage = withoutHyphenMessage ; this . withOrWithoutHyphenMessage = withOrWithoutHyphenMessage ; this . shortDesc = shortMessage ; setLocQualityIssueType ( ITSIssueType . Misspelling ) ; } public boolean isHyphenIgnored ( ) { return true ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; RuleMatch prevRuleMatch = null ; final Queue < AnalyzedTokenReadings > prevTokens = new ArrayBlockingQueue < > ( MAX_TERMS ) ; for ( int i = 0 ; i < tokens . length + MAX_TERMS - 1 ; i ++ ) { final AnalyzedTokenReadings token ; if ( i >= tokens . length ) { token = new AnalyzedTokenReadings ( new AnalyzedToken ( "" , "" , null ) , prevTokens . peek ( ) . getStartPos ( ) ) ; } else { token = tokens [ i ] ; } if ( i == 0 ) { addToQueue ( token , prevTokens ) ; continue ; } if ( token . isImmunized ( ) ) { continue ; } final AnalyzedTokenReadings firstMatchToken = prevTokens . peek ( ) ; final List < String > stringsToCheck = new ArrayList < > ( ) ; final List < String > origStringsToCheck = new ArrayList < > ( ) ; final Map < String , AnalyzedTokenReadings > stringToToken = getStringToTokenMap ( prevTokens , stringsToCheck , origStringsToCheck ) ; for ( int k = stringsToCheck . size ( ) - 1 ; k >= 0 ; k -- ) { final String stringToCheck = stringsToCheck . get ( k ) ; final String origStringToCheck = origStringsToCheck . get ( k ) ; if ( getCompoundRuleData ( ) . getIncorrectCompounds ( ) . contains ( stringToCheck ) ) { final AnalyzedTokenReadings atr = stringToToken . get ( stringToCheck ) ; String msg = null ; final List < String > replacement = new ArrayList < > ( ) ; if ( ! getCompoundRuleData ( ) . getNoDashSuggestion ( ) . contains ( stringToCheck ) ) { replacement . add ( origStringToCheck . replace ( ' ' , '-' ) ) ; msg = withHyphenMessage ; } if ( isNotAllUppercase ( origStringToCheck ) && ! getCompoundRuleData ( ) . getOnlyDashSuggestion ( ) . contains ( stringToCheck ) ) { replacement . add ( mergeCompound ( origStringToCheck ) ) ; msg = withoutHyphenMessage ; } final String [ ] parts = stringToCheck . split ( " " ) ; if ( parts . length > 0 && parts [ 0 ] . length ( ) == 1 ) { replacement . clear ( ) ; replacement . add ( origStringToCheck . replace ( ' ' , '-' ) ) ; msg = withHyphenMessage ; } else if ( replacement . isEmpty ( ) || replacement . size ( ) == 2 ) { msg = withOrWithoutHyphenMessage ; } final RuleMatch ruleMatch = new RuleMatch ( this , firstMatchToken . getStartPos ( ) , atr . getEndPos ( ) , msg , shortDesc ) ; ruleMatch . setSuggestedReplacements ( replacement ) ; if ( prevRuleMatch != null && prevRuleMatch . getFromPos ( ) == ruleMatch . getFromPos ( ) ) { prevRuleMatch = ruleMatch ; break ; } prevRuleMatch = ruleMatch ; ruleMatches . add ( ruleMatch ) ; break ; } } addToQueue ( token , prevTokens ) ; } return toRuleMatchArray ( ruleMatches ) ; } private Map < String , AnalyzedTokenReadings > getStringToTokenMap ( Queue < AnalyzedTokenReadings > prevTokens , List < String > stringsToCheck , List < String > origStringsToCheck ) { final StringBuilder sb = new StringBuilder ( ) ; final Map < String , AnalyzedTokenReadings > stringToToken = new HashMap < > ( ) ; int j = 0 ; for ( AnalyzedTokenReadings atr : prevTokens ) { sb . append ( ' ' ) ; sb . append ( atr . getToken ( ) ) ; if ( j >= 1 ) { final String stringToCheck = normalize ( sb . toString ( ) ) ; stringsToCheck . add ( stringToCheck ) ; origStringsToCheck . add ( sb . toString ( ) . trim ( ) ) ; if ( ! stringToToken . containsKey ( stringToCheck ) ) { stringToToken . put ( stringToCheck , atr ) ; } } j ++ ; } return stringToToken ; } private String normalize ( final String inStr ) { String str = inStr . trim ( ) . toLowerCase ( ) ; if ( str . indexOf ( '-' ) != - 1 && str . indexOf ( ' ' ) != - 1 ) { if ( isHyphenIgnored ( ) ) { str = str . replace ( '-' , ' ' ) ; } else { str = str . replace ( " - " , " " ) ; } } return str ; } private boolean isNotAllUppercase ( final String str ) { final String [ ] parts = str . split ( " " ) ; for ( String part : parts ) { if ( isHyphenIgnored ( ) || ! "-" . equals ( part ) ) { if ( StringTools . isAllUppercase ( part ) ) { return false ; } } } return true ; } private String mergeCompound ( final String str ) { final String [ ] stringParts = str . split ( " " ) ; final StringBuilder sb = new StringBuilder ( ) ; for ( int k = 0 ; k < stringParts . length ; k ++ ) { if ( isHyphenIgnored ( ) || ! "-" . equals ( stringParts [ k ] ) ) { if ( k == 0 ) { sb . append ( stringParts [ k ] ) ; } else { sb . append ( stringParts [ k ] . toLowerCase ( ) ) ; } } } return sb . toString ( ) ; } private void addToQueue ( final AnalyzedTokenReadings token , final Queue < AnalyzedTokenReadings > prevTokens ) { final boolean inserted = prevTokens . offer ( token ) ; if ( ! inserted ) { prevTokens . poll ( ) ; prevTokens . offer ( token ) ; } } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; public class SameRuleGroupFilter implements RuleMatchFilter { @ Override public List < RuleMatch > filter ( List < RuleMatch > ruleMatches ) { Collections . sort ( ruleMatches ) ; final List < RuleMatch > filteredRules = new ArrayList < > ( ) ; for ( int i = 0 ; i < ruleMatches . size ( ) ; i ++ ) { final RuleMatch match = ruleMatches . get ( i ) ; while ( i < ruleMatches . size ( ) - 1 && overlapAndMatch ( match , ruleMatches . get ( i + 1 ) ) ) { i ++ ; } filteredRules . add ( match ) ; } return filteredRules ; } private boolean overlapAndMatch ( final RuleMatch match , RuleMatch nextMatch ) { return overlaps ( match , nextMatch ) && haveSameRuleGroup ( match , nextMatch ) ; } boolean overlaps ( RuleMatch match , RuleMatch nextMatch ) { if ( match . getFromPos ( ) <= nextMatch . getToPos ( ) && match . getToPos ( ) >= nextMatch . getFromPos ( ) ) { return true ; } return false ; } private boolean haveSameRuleGroup ( RuleMatch match , RuleMatch nextMatch ) { final String id1 = match . getRule ( ) . getId ( ) ; return id1 != null && id1 . equals ( nextMatch . getRule ( ) . getId ( ) ) ; } }
package org . languagetool . rules ; import java . util . List ; public interface RuleMatchFilter { List < RuleMatch > filter ( List < RuleMatch > ruleMatches ) ; }
package org . languagetool . rules ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . patterns . RuleFilter ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import java . util . Calendar ; import java . util . Map ; public abstract class AbstractDateCheckFilter implements RuleFilter { private static final Pattern DAY_OF_MONTH_PATTERN = Pattern . compile ( "(\\d+).*" ) ; protected abstract int getDayOfWeek ( String localizedWeekDayString ) ; protected abstract String getDayOfWeek ( Calendar date ) ; protected int getDayOfMonth ( String localizedDayOfMonth ) { return 0 ; } protected abstract int getMonth ( String localizedMonth ) ; protected abstract Calendar getCalendar ( ) ; @ Override public RuleMatch acceptRuleMatch ( RuleMatch match , Map < String , String > args , AnalyzedTokenReadings [ ] patternTokens ) { int dayOfWeekFromString = getDayOfWeek ( getRequired ( "weekDay" , args ) ) ; Calendar dateFromDate = getDate ( args ) ; int dayOfWeekFromDate ; try { dayOfWeekFromDate = dateFromDate . get ( Calendar . DAY_OF_WEEK ) ; } catch ( IllegalArgumentException ignore ) { return null ; } if ( dayOfWeekFromString != dayOfWeekFromDate ) { Calendar calFromDateString = Calendar . getInstance ( ) ; calFromDateString . set ( Calendar . DAY_OF_WEEK , dayOfWeekFromString ) ; String message = match . getMessage ( ) . replace ( "{realDay}" , getDayOfWeek ( dateFromDate ) ) . replace ( "{day}" , getDayOfWeek ( calFromDateString ) ) ; return new RuleMatch ( match . getRule ( ) , match . getFromPos ( ) , match . getToPos ( ) , message , match . getShortMessage ( ) ) ; } else { return null ; } } protected String getRequired ( String key , Map < String , String > map ) { String result = map . get ( key ) ; if ( result == null ) { throw new IllegalArgumentException ( "Missing key '" + key + "'" ) ; } return result ; } private Calendar getDate ( Map < String , String > args ) { int year = Integer . parseInt ( getRequired ( "year" , args ) ) ; int month = getMonthFromArguments ( args ) ; int dayOfMonth = getDayOfMonthFromArguments ( args ) ; Calendar calendar = getCalendar ( ) ; calendar . setLenient ( false ) ; calendar . set ( year , month , dayOfMonth , 0 , 0 , 0 ) ; return calendar ; } private int getDayOfMonthFromArguments ( Map < String , String > args ) { String dayOfMonthString = getRequired ( "day" , args ) ; int dayOfMonth ; Matcher matcherDayOfMonth = DAY_OF_MONTH_PATTERN . matcher ( dayOfMonthString ) ; if ( matcherDayOfMonth . matches ( ) ) { dayOfMonth = Integer . parseInt ( matcherDayOfMonth . group ( 1 ) ) ; } else { dayOfMonth = getDayOfMonth ( dayOfMonthString ) ; } return dayOfMonth ; } private int getMonthFromArguments ( Map < String , String > args ) { String monthStr = getRequired ( "month" , args ) ; int month ; if ( monthStr . matches ( "\\d+" ) ) { month = Integer . parseInt ( monthStr ) ; } else { month = getMonth ( monthStr ) ; } return month - 1 ; } }
package org . languagetool . rules ; import java . io . * ; import java . util . * ; public class ConfusionSetLoader { private static final String CHARSET = "utf-8" ; public ConfusionSetLoader ( ) { } public Map < String , List < ConfusionSet > > loadConfusionSet ( InputStream stream ) throws IOException { Map < String , List < ConfusionSet > > map = new HashMap < > ( ) ; try ( InputStreamReader reader = new InputStreamReader ( stream , CHARSET ) ; BufferedReader br = new BufferedReader ( reader ) ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { if ( line . startsWith ( "#" ) || line . trim ( ) . isEmpty ( ) ) { continue ; } String [ ] parts = line . replaceFirst ( "\\s*#.*" , "" ) . split ( ";\\s*" ) ; if ( parts . length != 3 ) { throw new RuntimeException ( "Unexpected format: '" + line + "' - expected three semicolon-separated values: word1; word2; factor" ) ; } List < ConfusionString > confusionStrings = new ArrayList < > ( ) ; for ( String part : Arrays . asList ( parts ) . subList ( 0 , parts . length - 1 ) ) { String [ ] subParts = part . split ( "\\|" ) ; String word = subParts [ 0 ] ; String description = subParts . length == 2 ? subParts [ 1 ] : null ; confusionStrings . add ( new ConfusionString ( word , description ) ) ; } ConfusionSet confusionSet = new ConfusionSet ( Integer . parseInt ( parts [ parts . length - 1 ] ) , confusionStrings ) ; for ( ConfusionString confusionString : confusionStrings ) { String key = confusionString . getString ( ) ; List < ConfusionSet > existingEntry = map . get ( key ) ; if ( existingEntry != null ) { existingEntry . add ( confusionSet ) ; } else { List < ConfusionSet > sets = new ArrayList < > ( ) ; sets . add ( confusionSet ) ; map . put ( key , sets ) ; } } } } return map ; } }
package org . languagetool . rules ; import org . jetbrains . annotations . Nullable ; import java . util . Objects ; public class ConfusionString { private final String str ; private final String description ; ConfusionString ( String str , String description ) { this . str = Objects . requireNonNull ( str ) ; this . description = description ; } public String getString ( ) { return str ; } @ Nullable public String getDescription ( ) { return description ; } @ Override public String toString ( ) { return str ; } @ Override public boolean equals ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; ConfusionString that = ( ConfusionString ) o ; if ( ! str . equals ( that . str ) ) return false ; if ( description != null ? ! description . equals ( that . description ) : that . description != null ) return false ; return true ; } @ Override public int hashCode ( ) { int result = str . hashCode ( ) ; result = 31 * result + ( description != null ? description . hashCode ( ) : 0 ) ; return result ; } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tools . StringTools ; public class WhitespaceBeforePunctuationRule extends Rule { public WhitespaceBeforePunctuationRule ( final ResourceBundle messages ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setLocQualityIssueType ( ITSIssueType . Whitespace ) ; } @ Override public final String getId ( ) { return "WHITESPACE_PUNCTUATION" ; } @ Override public final String getDescription ( ) { return messages . getString ( "desc_whitespace_before_punctuation" ) ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokens ( ) ; boolean prevWhite = false ; int prevLen = 0 ; for ( int i = 0 ; i < tokens . length ; i ++ ) { final String token = tokens [ i ] . getToken ( ) ; final boolean isWhitespace = tokens [ i ] . isWhitespace ( ) || StringTools . isNonBreakingWhitespace ( token ) || tokens [ i ] . isFieldCode ( ) ; String msg = null ; String suggestionText = null ; if ( prevWhite ) { if ( token . equals ( ":" ) ) { msg = messages . getString ( "no_space_before_colon" ) ; suggestionText = ":" ; if ( i + 2 < tokens . length && tokens [ i + 1 ] . isWhitespace ( ) && Character . isDigit ( tokens [ i + 2 ] . getToken ( ) . charAt ( 0 ) ) ) { msg = null ; } } else if ( token . equals ( ";" ) ) { msg = messages . getString ( "no_space_before_semicolon" ) ; suggestionText = ";" ; } else if ( i > 1 && token . equals ( "%" ) && Character . isDigit ( tokens [ i - 2 ] . getToken ( ) . charAt ( 0 ) ) ) { msg = messages . getString ( "no_space_before_percentage" ) ; suggestionText = "%" ; } } if ( msg != null ) { final int fromPos = tokens [ i - 1 ] . getStartPos ( ) ; final int toPos = tokens [ i - 1 ] . getStartPos ( ) + 1 + prevLen ; final RuleMatch ruleMatch = new RuleMatch ( this , fromPos , toPos , msg ) ; ruleMatch . setSuggestedReplacement ( suggestionText ) ; ruleMatches . add ( ruleMatch ) ; } prevWhite = isWhitespace && ! tokens [ i ] . isFieldCode ( ) ; prevLen = tokens [ i ] . getToken ( ) . length ( ) ; } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . synthesis . nl ; import org . languagetool . synthesis . BaseSynthesizer ; public class DutchSynthesizer extends BaseSynthesizer { private static final String RESOURCE_FILENAME = "/nl/dutch_synth.dict" ; private static final String TAGS_FILE_NAME = "/nl/dutch_tags.txt" ; public DutchSynthesizer ( ) { super ( RESOURCE_FILENAME , TAGS_FILE_NAME ) ; } }
package org . languagetool . rules ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . tools . StringTools ; import java . io . BufferedReader ; import java . io . IOException ; import java . io . InputStream ; import java . io . InputStreamReader ; import java . util . * ; import java . util . concurrent . ArrayBlockingQueue ; public abstract class AbstractSimpleReplaceRule2 extends Rule { private final Language language ; public abstract String getFileName ( ) ; @ Override public abstract String getId ( ) ; @ Override public abstract String getDescription ( ) ; public abstract String getShort ( ) ; public abstract String getSuggestion ( ) ; public abstract String getSuggestionsSeparator ( ) ; public abstract Locale getLocale ( ) ; private final List < Map < String , String > > wrongWords ; public AbstractSimpleReplaceRule2 ( final ResourceBundle messages , Language language ) throws IOException { super ( messages ) ; this . language = Objects . requireNonNull ( language ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; wrongWords = loadWords ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( getFileName ( ) ) ) ; } public boolean isCaseSensitive ( ) { return false ; } public List < Map < String , String > > getWrongWords ( ) { return wrongWords ; } private List < Map < String , String > > loadWords ( final InputStream stream ) throws IOException { final List < Map < String , String > > list = new ArrayList < > ( ) ; try ( InputStreamReader isr = new InputStreamReader ( stream , "utf-8" ) ; BufferedReader br = new BufferedReader ( isr ) ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { line = line . trim ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } final String [ ] parts = line . split ( "=" ) ; if ( parts . length != 2 ) { throw new IOException ( "Format error in file " + JLanguageTool . getDataBroker ( ) . getFromRulesDirAsUrl ( getFileName ( ) ) + ", line: " + line ) ; } final String [ ] wrongForms = parts [ 0 ] . split ( "\\|" ) ; for ( String wrongForm : wrongForms ) { int wordCount = 0 ; final List < String > tokens = language . getWordTokenizer ( ) . tokenize ( wrongForm ) ; for ( String token : tokens ) { if ( ! StringTools . isWhitespace ( token ) ) { wordCount ++ ; } } for ( int i = list . size ( ) ; i < wordCount ; i ++ ) { list . add ( new HashMap < String , String > ( ) ) ; } list . get ( wordCount - 1 ) . put ( wrongForm , parts [ 1 ] ) ; } } } final List < Map < String , String > > result = new ArrayList < > ( ) ; for ( Map < String , String > map : list ) { result . add ( Collections . unmodifiableMap ( map ) ) ; } return Collections . unmodifiableList ( result ) ; } private void addToQueue ( AnalyzedTokenReadings token , Queue < AnalyzedTokenReadings > prevTokens ) { final boolean inserted = prevTokens . offer ( token ) ; if ( ! inserted ) { prevTokens . poll ( ) ; prevTokens . offer ( token ) ; } } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; final Queue < AnalyzedTokenReadings > prevTokens = new ArrayBlockingQueue < > ( wrongWords . size ( ) ) ; for ( int i = 1 ; i < tokens . length ; i ++ ) { addToQueue ( tokens [ i ] , prevTokens ) ; final StringBuilder sb = new StringBuilder ( ) ; final List < String > variants = new ArrayList < > ( ) ; final List < AnalyzedTokenReadings > prevTokensList = Arrays . asList ( prevTokens . toArray ( new AnalyzedTokenReadings [ prevTokens . size ( ) ] ) ) ; for ( int j = prevTokensList . size ( ) - 1 ; j >= 0 ; j -- ) { if ( j != prevTokensList . size ( ) - 1 && prevTokensList . get ( j + 1 ) . isWhitespaceBefore ( ) ) { sb . insert ( 0 , " " ) ; } sb . insert ( 0 , prevTokensList . get ( j ) . getToken ( ) ) ; variants . add ( 0 , sb . toString ( ) ) ; } final int len = variants . size ( ) ; for ( int j = 0 ; j < len ; j ++ ) { final String crt = variants . get ( j ) ; final int crtWordCount = len - j ; final String crtMatch = isCaseSensitive ( ) ? wrongWords . get ( crtWordCount - 1 ) . get ( crt ) : wrongWords . get ( crtWordCount - 1 ) . get ( crt . toLowerCase ( getLocale ( ) ) ) ; if ( crtMatch != null ) { final List < String > replacements = Arrays . asList ( crtMatch . split ( "\\|" ) ) ; String msg = crt + getSuggestion ( ) ; for ( int k = 0 ; k < replacements . size ( ) ; k ++ ) { if ( k > 0 ) { msg = msg + ( k == replacements . size ( ) - 1 ? getSuggestionsSeparator ( ) : ", " ) ; } msg += "<suggestion>" + replacements . get ( k ) + "</suggestion>" ; } final int startPos = prevTokensList . get ( len - crtWordCount ) . getStartPos ( ) ; final int endPos = prevTokensList . get ( len - 1 ) . getEndPos ( ) ; final RuleMatch potentialRuleMatch = new RuleMatch ( this , startPos , endPos , msg , getShort ( ) ) ; if ( ! isCaseSensitive ( ) && StringTools . startsWithUppercase ( crt ) ) { for ( int k = 0 ; k < replacements . size ( ) ; k ++ ) { replacements . set ( k , StringTools . uppercaseFirstChar ( replacements . get ( k ) ) ) ; } } potentialRuleMatch . setSuggestedReplacements ( replacements ) ; ruleMatches . add ( potentialRuleMatch ) ; break ; } } } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . tools . StringTools ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; public class MultipleWhitespaceRule extends Rule { public MultipleWhitespaceRule ( final ResourceBundle messages , final Language language ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setLocQualityIssueType ( ITSIssueType . Whitespace ) ; } @ Override public String getId ( ) { return "WHITESPACE_RULE" ; } @ Override public final String getDescription ( ) { return messages . getString ( "desc_whitespacerepetition" ) ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokens ( ) ; boolean prevWhite = false ; int prevLen = 0 ; int prevPos = 0 ; int i = 1 ; while ( i < tokens . length ) { final boolean tokenIsTab = tokens [ i ] . getToken ( ) . equals ( "\t" ) ; final boolean prevTokenIsLinebreak = tokens [ i - 1 ] . isLinebreak ( ) ; if ( ( tokens [ i ] . isWhitespace ( ) || StringTools . isNonBreakingWhitespace ( tokens [ i ] . getToken ( ) ) ) && prevWhite && ! tokenIsTab && ! prevTokenIsLinebreak ) { final int pos = tokens [ i - 1 ] . getStartPos ( ) ; while ( i < tokens . length && ( tokens [ i ] . isWhitespace ( ) || StringTools . isNonBreakingWhitespace ( tokens [ i ] . getToken ( ) ) ) ) { prevLen += tokens [ i ] . getToken ( ) . length ( ) ; i ++ ; } final String message = messages . getString ( "whitespace_repetition" ) ; if ( prevLen > 0 ) { final RuleMatch ruleMatch = new RuleMatch ( this , prevPos , pos + prevLen , message ) ; ruleMatch . setSuggestedReplacement ( " " ) ; ruleMatches . add ( ruleMatch ) ; } } if ( i < tokens . length ) { prevWhite = tokens [ i ] . isWhitespace ( ) || StringTools . isNonBreakingWhitespace ( tokens [ i ] . getToken ( ) ) ; prevLen = tokens [ i ] . getToken ( ) . length ( ) ; prevPos = tokens [ i ] . getStartPos ( ) ; i ++ ; } } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import org . languagetool . JLanguageTool ; import java . io . BufferedReader ; import java . io . IOException ; import java . io . InputStream ; import java . io . InputStreamReader ; import java . util . Collections ; import java . util . HashMap ; import java . util . Map ; public class WordCoherencyDataLoader { public Map < String , String > loadWords ( String path ) { InputStream stream = JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( path ) ; Map < String , String > map = new HashMap < > ( ) ; try ( InputStreamReader reader = new InputStreamReader ( stream , "utf-8" ) ; BufferedReader br = new BufferedReader ( reader ) ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } String [ ] parts = line . split ( ";" ) ; if ( parts . length != 2 ) { throw new IOException ( "Format error in file " + path + ", line: " + line ) ; } map . put ( parts [ 0 ] , parts [ 1 ] ) ; map . put ( parts [ 1 ] , parts [ 0 ] ) ; } } catch ( IOException e ) { throw new RuntimeException ( "Could not load coherency data from " + path , e ) ; } return Collections . unmodifiableMap ( map ) ; } }
package org . languagetool . rules ; import java . text . MessageFormat ; import java . util . * ; import java . util . regex . Pattern ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; public class GenericUnpairedBracketsRule extends TextLevelRule { private static final Pattern NUMERALS_EN = Pattern . compile ( "(?i)\\d{1,2}?[a-z']*|M*(D?C{0,3}|C[DM])(L?X{0,3}|X[LC])(V?I{0,3}|I[VX])$" ) ; private static final Pattern PUNCTUATION = Pattern . compile ( "[\\p{Punct}…–—]" ) ; private static final Pattern PUNCTUATION_NO_DOT = Pattern . compile ( "[ldmnstLDMNST]'|[–—\\p{Punct}&&[^\\.]]" ) ; private final String [ ] startSymbols ; private final String [ ] endSymbols ; protected final UnsyncStack < SymbolLocator > symbolStack = new UnsyncStack < > ( ) ; private final Map < String , Boolean > uniqueMap = new HashMap < > ( ) ; private final String ruleId ; protected Pattern numerals ; public GenericUnpairedBracketsRule ( String ruleId , ResourceBundle messages , List < String > startSymbols , List < String > endSymbols ) { super ( messages ) ; this . ruleId = ruleId != null ? ruleId : "UNPAIRED_BRACKETS" ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; if ( startSymbols . size ( ) != endSymbols . size ( ) ) { throw new IllegalArgumentException ( "Different number of start and end symbols: " + startSymbols + " vs. " + endSymbols ) ; } this . startSymbols = startSymbols . toArray ( new String [ startSymbols . size ( ) ] ) ; this . endSymbols = endSymbols . toArray ( new String [ endSymbols . size ( ) ] ) ; numerals = NUMERALS_EN ; uniqueMapInit ( ) ; setLocQualityIssueType ( ITSIssueType . Typographical ) ; } public GenericUnpairedBracketsRule ( ResourceBundle messages , List < String > startSymbols , List < String > endSymbols ) { this ( null , messages , startSymbols , endSymbols ) ; } public GenericUnpairedBracketsRule ( ResourceBundle messages ) { this ( null , messages , Arrays . asList ( "[" , "(" , "{" , "\"" , "'" ) , Arrays . asList ( "]" , ")" , "}" , "\"" , "'" ) ) ; } @ Override public String getId ( ) { return ruleId ; } @ Override public String getDescription ( ) { return messages . getString ( "desc_unpaired_brackets" ) ; } protected void uniqueMapInit ( ) { for ( String endSymbol : endSymbols ) { int found = 0 ; for ( String endSymbol1 : endSymbols ) { if ( endSymbol1 . equals ( endSymbol ) ) { found ++ ; } } uniqueMap . put ( endSymbol , found == 1 ) ; } } protected boolean isNoException ( final String token , final AnalyzedTokenReadings [ ] tokens , final int i , final int j , final boolean precSpace , final boolean follSpace ) { if ( i >= 2 && tokens [ i - 2 ] . getToken ( ) . equals ( ":" ) && tokens [ i - 1 ] . getToken ( ) . equals ( "-" ) && tokens [ i ] . getToken ( ) . equals ( ")" ) ) { return false ; } return ! ( i >= 2 && tokens [ i - 2 ] . getToken ( ) . equals ( ";" ) && tokens [ i - 1 ] . getToken ( ) . equals ( "-" ) && tokens [ i ] . getToken ( ) . equals ( ")" ) ) ; } @ Override public final RuleMatch [ ] match ( List < AnalyzedSentence > sentences ) { UnsyncStack < SymbolLocator > ruleMatchStack = new UnsyncStack < > ( ) ; List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; int startPosBase = 0 ; for ( AnalyzedSentence sentence : sentences ) { AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; for ( int i = 1 ; i < tokens . length ; i ++ ) { for ( int j = 0 ; j < startSymbols . length ; j ++ ) { if ( fillSymbolStack ( startPosBase , tokens , i , j ) ) { break ; } } } for ( AnalyzedTokenReadings readings : sentence . getTokens ( ) ) { startPosBase += readings . getToken ( ) . length ( ) ; } } for ( final SymbolLocator sLoc : symbolStack ) { final RuleMatch rMatch = createMatch ( ruleMatches , ruleMatchStack , sLoc . getStartPos ( ) , sLoc . getSymbol ( ) ) ; if ( rMatch != null ) { ruleMatches . add ( rMatch ) ; } } symbolStack . clear ( ) ; return toRuleMatchArray ( ruleMatches ) ; } private boolean fillSymbolStack ( int startPosBase , AnalyzedTokenReadings [ ] tokens , int i , int j ) { String token = tokens [ i ] . getToken ( ) ; int startPos = startPosBase + tokens [ i ] . getStartPos ( ) ; if ( token . equals ( startSymbols [ j ] ) || token . equals ( endSymbols [ j ] ) ) { boolean precededByWhitespace = getPrecededByWhitespace ( tokens , i , j ) ; boolean followedByWhitespace = getFollowedByWhitespace ( tokens , i , j ) ; boolean noException = isNoException ( token , tokens , i , j , precededByWhitespace , followedByWhitespace ) ; if ( noException && precededByWhitespace && token . equals ( startSymbols [ j ] ) ) { symbolStack . push ( new SymbolLocator ( startSymbols [ j ] , i , startPos ) ) ; return true ; } else if ( noException && ( followedByWhitespace || tokens [ i ] . isSentenceEnd ( ) ) && token . equals ( endSymbols [ j ] ) ) { if ( i > 1 && endSymbols [ j ] . equals ( ")" ) && ( numerals . matcher ( tokens [ i - 1 ] . getToken ( ) ) . matches ( ) && ! ( ! symbolStack . empty ( ) && "(" . equals ( symbolStack . peek ( ) . getSymbol ( ) ) ) ) ) { } else { if ( symbolStack . empty ( ) ) { symbolStack . push ( new SymbolLocator ( endSymbols [ j ] , i , startPos ) ) ; return true ; } else { if ( symbolStack . peek ( ) . getSymbol ( ) . equals ( startSymbols [ j ] ) ) { symbolStack . pop ( ) ; return true ; } else { if ( isEndSymbolUnique ( endSymbols [ j ] ) ) { symbolStack . push ( new SymbolLocator ( endSymbols [ j ] , i , startPos ) ) ; return true ; } else { if ( j == endSymbols . length - 1 ) { symbolStack . push ( new SymbolLocator ( endSymbols [ j ] , i , startPos ) ) ; return true ; } } } } } } } return false ; } private boolean getPrecededByWhitespace ( AnalyzedTokenReadings [ ] tokens , int i , int j ) { boolean precededByWhitespace = true ; if ( startSymbols [ j ] . equals ( endSymbols [ j ] ) ) { precededByWhitespace = tokens [ i - 1 ] . isSentenceStart ( ) || tokens [ i ] . isWhitespaceBefore ( ) || PUNCTUATION_NO_DOT . matcher ( tokens [ i - 1 ] . getToken ( ) ) . matches ( ) || Arrays . asList ( startSymbols ) . contains ( tokens [ i - 1 ] . getToken ( ) ) ; } return precededByWhitespace ; } private boolean getFollowedByWhitespace ( AnalyzedTokenReadings [ ] tokens , int i , int j ) { boolean followedByWhitespace = true ; if ( i < tokens . length - 1 && startSymbols [ j ] . equals ( endSymbols [ j ] ) ) { followedByWhitespace = tokens [ i + 1 ] . isWhitespaceBefore ( ) || PUNCTUATION . matcher ( tokens [ i + 1 ] . getToken ( ) ) . matches ( ) || Arrays . asList ( endSymbols ) . contains ( tokens [ i + 1 ] . getToken ( ) ) ; } return followedByWhitespace ; } private boolean isEndSymbolUnique ( final String str ) { return uniqueMap . get ( str ) ; } @ Nullable private RuleMatch createMatch ( List < RuleMatch > ruleMatches , UnsyncStack < SymbolLocator > ruleMatchStack , int startPos , String symbol ) { if ( ! ruleMatchStack . empty ( ) ) { final int index = findSymbolNum ( symbol , endSymbols ) ; if ( index >= 0 ) { final SymbolLocator rLoc = ruleMatchStack . peek ( ) ; if ( rLoc . getSymbol ( ) . equals ( startSymbols [ index ] ) ) { if ( ruleMatches . size ( ) > rLoc . getIndex ( ) ) { ruleMatches . remove ( rLoc . getIndex ( ) ) ; ruleMatchStack . pop ( ) ; return null ; } } } } ruleMatchStack . push ( new SymbolLocator ( symbol , ruleMatches . size ( ) , startPos ) ) ; String otherSymbol = findCorrespondingSymbol ( symbol ) ; String message = MessageFormat . format ( messages . getString ( "unpaired_brackets" ) , otherSymbol ) ; return new RuleMatch ( this , startPos , startPos + symbol . length ( ) , message ) ; } private int findSymbolNum ( final String ch , String [ ] symbols ) { for ( int i = 0 ; i < symbols . length ; i ++ ) { if ( ch . equals ( symbols [ i ] ) ) { return i ; } } return - 1 ; } private String findCorrespondingSymbol ( final String symbol ) { int idx1 = findSymbolNum ( symbol , startSymbols ) ; if ( idx1 >= 0 ) { return endSymbols [ idx1 ] ; } else { int idx2 = findSymbolNum ( symbol , endSymbols ) ; return startSymbols [ idx2 ] ; } } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . tokenizers . WordTokenizer ; import org . languagetool . tools . StringTools ; public class UppercaseSentenceStartRule extends Rule { private static final Pattern NUMERALS_EN = Pattern . compile ( "[a-z]|(m{0,4}(cm|cd|d?c{0,3})(xc|xl|l?x{0,3})(ix|iv|v?i{0,3}))$" ) ; private static final Pattern WHITESPACE_OR_QUOTE = Pattern . compile ( "[ \"'„«»‘’“”\\n]" ) ; private static final Pattern QUOTE_START = Pattern . compile ( "[\"'„»«“‘]" ) ; private static final Pattern SENTENCE_END1 = Pattern . compile ( "[.?!…]|" ) ; private static final Pattern SENTENCE_END2 = Pattern . compile ( "[.?!…]" ) ; private static final Pattern DUTCH_SPECIAL_CASE = Pattern . compile ( "k|m|n|r|s|t" ) ; private final Language language ; private String lastParagraphString = "" ; public UppercaseSentenceStartRule ( final ResourceBundle messages , final Language language ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_case" ) ) ) ; this . language = language ; setLocQualityIssueType ( ITSIssueType . Typographical ) ; } @ Override public final String getId ( ) { return "UPPERCASE_SENTENCE_START" ; } @ Override public final String getDescription ( ) { return messages . getString ( "desc_uppercase_sentence" ) ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; if ( tokens . length < 2 ) { return toRuleMatchArray ( ruleMatches ) ; } int matchTokenPos = 1 ; final String firstToken = tokens [ matchTokenPos ] . getToken ( ) ; String secondToken = null ; String thirdToken = null ; if ( tokens . length >= 3 && QUOTE_START . matcher ( firstToken ) . matches ( ) ) { matchTokenPos = 2 ; secondToken = tokens [ matchTokenPos ] . getToken ( ) ; } final String firstDutchToken = dutchSpecialCase ( firstToken , secondToken , tokens ) ; if ( firstDutchToken != null ) { thirdToken = firstDutchToken ; matchTokenPos = 3 ; } String checkToken = firstToken ; if ( thirdToken != null ) { checkToken = thirdToken ; } else if ( secondToken != null ) { checkToken = secondToken ; } String lastToken = tokens [ tokens . length - 1 ] . getToken ( ) ; if ( tokens . length >= 2 && WHITESPACE_OR_QUOTE . matcher ( lastToken ) . matches ( ) ) { lastToken = tokens [ tokens . length - 2 ] . getToken ( ) ; } boolean preventError = false ; if ( lastParagraphString . equals ( "," ) || lastParagraphString . equals ( ";" ) ) { preventError = true ; } if ( ! SENTENCE_END1 . matcher ( lastParagraphString ) . matches ( ) && ! SENTENCE_END2 . matcher ( lastToken ) . matches ( ) ) { preventError = true ; } lastParagraphString = lastToken ; if ( matchTokenPos + 1 < tokens . length && NUMERALS_EN . matcher ( tokens [ matchTokenPos ] . getToken ( ) ) . matches ( ) && ( tokens [ matchTokenPos + 1 ] . getToken ( ) . equals ( "." ) || tokens [ matchTokenPos + 1 ] . getToken ( ) . equals ( ")" ) ) ) { preventError = true ; } if ( isUrl ( checkToken ) ) { preventError = true ; } if ( checkToken . length ( ) > 0 ) { final char firstChar = checkToken . charAt ( 0 ) ; if ( ! preventError && Character . isLowerCase ( firstChar ) ) { final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ matchTokenPos ] . getStartPos ( ) , tokens [ matchTokenPos ] . getEndPos ( ) , messages . getString ( "incorrect_case" ) ) ; ruleMatch . setSuggestedReplacement ( StringTools . uppercaseFirstChar ( checkToken ) ) ; ruleMatches . add ( ruleMatch ) ; } } return toRuleMatchArray ( ruleMatches ) ; } @ Nullable private String dutchSpecialCase ( final String firstToken , final String secondToken , final AnalyzedTokenReadings [ ] tokens ) { if ( ! language . getShortName ( ) . equals ( "nl" ) ) { return null ; } if ( tokens . length >= 3 && firstToken . equals ( "'" ) && DUTCH_SPECIAL_CASE . matcher ( secondToken ) . matches ( ) ) { return tokens [ 3 ] . getToken ( ) ; } return null ; } @ Override public void reset ( ) { lastParagraphString = "" ; } protected boolean isUrl ( String token ) { for ( String protocol : WordTokenizer . getProtocols ( ) ) { if ( token . startsWith ( protocol + "://" ) ) { return true ; } } return false ; } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; public class DoublePunctuationRule extends Rule { public DoublePunctuationRule ( final ResourceBundle messages ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setLocQualityIssueType ( ITSIssueType . Typographical ) ; } @ Override public String getId ( ) { return "DOUBLE_PUNCTUATION" ; } @ Override public final String getDescription ( ) { return messages . getString ( "desc_double_punct" ) ; } public String getCommaCharacter ( ) { return "," ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokens ( ) ; int startPos = 0 ; int dotCount = 0 ; int commaCount = 0 ; for ( int i = 1 ; i < tokens . length ; i ++ ) { final String token = tokens [ i ] . getToken ( ) ; String nextToken = null ; String prevToken = null ; if ( i < tokens . length - 1 ) { nextToken = tokens [ i + 1 ] . getToken ( ) ; } if ( i > 1 ) { prevToken = tokens [ i - 2 ] . getToken ( ) ; } if ( "." . equals ( token ) ) { dotCount ++ ; commaCount = 0 ; startPos = tokens [ i ] . getStartPos ( ) ; } else if ( getCommaCharacter ( ) . equals ( token ) ) { commaCount ++ ; dotCount = 0 ; startPos = tokens [ i ] . getStartPos ( ) ; } if ( dotCount == 2 && ! "." . equals ( nextToken ) && ! "?" . equals ( prevToken ) && ! "!" . equals ( prevToken ) ) { final int fromPos = Math . max ( 0 , startPos - 1 ) ; final RuleMatch ruleMatch = new RuleMatch ( this , fromPos , startPos + 1 , getDotMessage ( ) , messages . getString ( "double_dots_short" ) ) ; ruleMatch . setSuggestedReplacement ( "." ) ; ruleMatches . add ( ruleMatch ) ; dotCount = 0 ; } else if ( commaCount == 2 && ! getCommaCharacter ( ) . equals ( nextToken ) ) { final int fromPos = Math . max ( 0 , startPos - 1 ) ; final RuleMatch ruleMatch = new RuleMatch ( this , fromPos , startPos + 1 , getCommaMessage ( ) , messages . getString ( "double_commas_short" ) ) ; ruleMatch . setSuggestedReplacement ( getCommaCharacter ( ) ) ; ruleMatches . add ( ruleMatch ) ; commaCount = 0 ; } if ( ! "." . equals ( token ) && ! getCommaCharacter ( ) . equals ( token ) ) { dotCount = 0 ; commaCount = 0 ; } } return toRuleMatchArray ( ruleMatches ) ; } protected String getDotMessage ( ) { return messages . getString ( "two_dots" ) ; } protected String getCommaMessage ( ) { return messages . getString ( "two_commas" ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import org . apache . commons . lang . StringUtils ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . util . * ; public abstract class AbstractSimpleReplaceRule extends Rule { private static final String FILE_ENCODING = "utf-8" ; private boolean ignoreTaggedWords = false ; private boolean checkLemmas = true ; protected abstract Map < String , List < String > > getWrongWords ( ) ; protected static Map < String , List < String > > load ( String path ) { return new SimpleReplaceDataLoader ( ) . loadWords ( path ) ; } public String getEncoding ( ) { return FILE_ENCODING ; } public boolean isCaseSensitive ( ) { return true ; } public Locale getLocale ( ) { return Locale . getDefault ( ) ; } public void setIgnoreTaggedWords ( ) { ignoreTaggedWords = true ; } public AbstractSimpleReplaceRule ( final ResourceBundle messages ) throws IOException { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } @ Override public String getId ( ) { return "SIMPLE_REPLACE" ; } @ Override public String getDescription ( ) { return "Checks for wrong words/phrases" ; } public String getMessage ( String tokenStr , List < String > replacements ) { return tokenStr + " is not valid. Use: " + StringUtils . join ( replacements , ", " ) + "." ; } public String getShort ( ) { return "Wrong word" ; } private String cleanup ( String word ) { return isCaseSensitive ( ) ? word : word . toLowerCase ( getLocale ( ) ) ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) { List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; for ( AnalyzedTokenReadings tokenReadings : tokens ) { if ( tokenReadings . isImmunized ( ) || tokenReadings . isIgnoredBySpeller ( ) ) { continue ; } String originalTokenStr = tokenReadings . getToken ( ) ; if ( ignoreTaggedWords && isTagged ( tokenReadings ) ) { continue ; } String tokenString = cleanup ( originalTokenStr ) ; if ( ! getWrongWords ( ) . containsKey ( tokenString ) && checkLemmas ) { for ( AnalyzedToken analyzedToken : tokenReadings . getReadings ( ) ) { String lemma = analyzedToken . getLemma ( ) ; if ( lemma != null ) { lemma = cleanup ( lemma ) ; if ( getWrongWords ( ) . containsKey ( lemma ) ) { tokenString = lemma ; break ; } } } } List < String > possibleReplacements = getWrongWords ( ) . get ( originalTokenStr ) ; if ( possibleReplacements == null ) { possibleReplacements = getWrongWords ( ) . get ( tokenString ) ; } if ( possibleReplacements != null && possibleReplacements . size ( ) > 0 ) { List < String > replacements = new ArrayList < > ( ) ; replacements . addAll ( possibleReplacements ) ; if ( replacements . contains ( originalTokenStr ) ) { replacements . remove ( originalTokenStr ) ; } if ( replacements . size ( ) > 0 ) { RuleMatch potentialRuleMatch = createRuleMatch ( tokenReadings , replacements ) ; ruleMatches . add ( potentialRuleMatch ) ; } } } return toRuleMatchArray ( ruleMatches ) ; } protected boolean isTagged ( AnalyzedTokenReadings tokenReadings ) { return tokenReadings . isTagged ( ) ; } private RuleMatch createRuleMatch ( AnalyzedTokenReadings tokenReadings , List < String > replacements ) { String tokenString = tokenReadings . getToken ( ) ; int pos = tokenReadings . getStartPos ( ) ; RuleMatch potentialRuleMatch = new RuleMatch ( this , pos , pos + tokenString . length ( ) , getMessage ( tokenString , replacements ) , getShort ( ) ) ; if ( ! isCaseSensitive ( ) && StringTools . startsWithUppercase ( tokenString ) ) { for ( int i = 0 ; i < replacements . size ( ) ; i ++ ) { replacements . set ( i , StringTools . uppercaseFirstChar ( replacements . get ( i ) ) ) ; } } potentialRuleMatch . setSuggestedReplacements ( replacements ) ; return potentialRuleMatch ; } public boolean isCheckLemmas ( ) { return checkLemmas ; } public void setCheckLemmas ( boolean checkLemmas ) { this . checkLemmas = checkLemmas ; } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import java . io . IOException ; import java . text . MessageFormat ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; public class LongSentenceRule extends Rule { private static final int DEFAULT_MAX_WORDS = 40 ; private static final Pattern NON_WORD_REGEX = Pattern . compile ( "[.?!:;,~’'\"„“»«‚‘«»›‹()\\[\\]-]" ) ; private final int maxWords ; public LongSentenceRule ( final ResourceBundle messages , int maxSentenceLength ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; if ( maxSentenceLength <= 0 ) { throw new IllegalArgumentException ( "maxSentenceLength must be > 0: " + maxSentenceLength ) ; } maxWords = maxSentenceLength ; setDefaultOff ( ) ; setLocQualityIssueType ( ITSIssueType . Style ) ; } public LongSentenceRule ( final ResourceBundle messages ) { this ( messages , DEFAULT_MAX_WORDS ) ; } @ Override public String getDescription ( ) { return MessageFormat . format ( messages . getString ( "long_sentence_rule_desc" ) , maxWords ) ; } @ Override public String getId ( ) { return "TOO_LONG_SENTENCE" ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; final String msg = MessageFormat . format ( messages . getString ( "long_sentence_rule_msg" ) , maxWords ) ; int numWords = 0 ; int pos = 0 ; if ( tokens . length < maxWords + 1 ) { return toRuleMatchArray ( ruleMatches ) ; } else { for ( AnalyzedTokenReadings aToken : tokens ) { final String token = aToken . getToken ( ) ; pos += token . length ( ) ; if ( ! aToken . isSentenceStart ( ) && ! aToken . isSentenceEnd ( ) && ! NON_WORD_REGEX . matcher ( token ) . matches ( ) ) { numWords ++ ; } } } if ( numWords > maxWords ) { final RuleMatch ruleMatch = new RuleMatch ( this , 0 , pos , msg ) ; ruleMatches . add ( ruleMatch ) ; } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; public abstract class AbstractPunctuationCheckRule extends Rule { public AbstractPunctuationCheckRule ( final ResourceBundle messages ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } @ Override public String getId ( ) { return "PUNCTUATION_GENERIC_CHECK" ; } @ Override public String getDescription ( ) { return "Use of unusual combination of punctuation characters" ; } protected abstract boolean isPunctsJoinOk ( String tokens ) ; protected abstract boolean isPunctuation ( String token ) ; @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokens ( ) ; int startTokenIdx = - 1 ; String tkns = "" ; for ( int i = 0 ; i < tokens . length ; i ++ ) { final String tokenStr = tokens [ i ] . getToken ( ) ; if ( isPunctuation ( tokenStr ) ) { tkns += tokenStr ; if ( startTokenIdx == - 1 ) { startTokenIdx = i ; } if ( i < tokens . length - 1 ) { continue ; } } if ( tkns . length ( ) >= 2 && ! isPunctsJoinOk ( tkns ) ) { final String msg = "bad duplication or combination of punctuation signs" ; final RuleMatch ruleMatch = new RuleMatch ( this , tokens [ startTokenIdx ] . getStartPos ( ) , tokens [ startTokenIdx ] . getStartPos ( ) + tkns . length ( ) , msg , "Punctuation problem" ) ; ruleMatch . setSuggestedReplacement ( tkns . substring ( 0 , 1 ) ) ; ruleMatches . add ( ruleMatch ) ; } tkns = "" ; startTokenIdx = - 1 ; } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; public class SentenceWhitespaceRule extends Rule { private boolean isFirstSentence = true ; private boolean prevSentenceEndsWithWhitespace = false ; public SentenceWhitespaceRule ( ResourceBundle messages ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setLocQualityIssueType ( ITSIssueType . Whitespace ) ; } @ Override public String getId ( ) { return "SENTENCE_WHITESPACE" ; } @ Override public String getDescription ( ) { return messages . getString ( "missing_space_between_sentences" ) ; } public String getMessage ( ) { return messages . getString ( "addSpaceBetweenSentences" ) ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) { List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; AnalyzedTokenReadings [ ] tokens = sentence . getTokens ( ) ; if ( isFirstSentence ) { isFirstSentence = false ; } else { if ( ! prevSentenceEndsWithWhitespace && tokens . length > 1 ) { int startPos = 0 ; String firstToken = tokens [ 1 ] . getToken ( ) ; int endPos = firstToken . length ( ) ; RuleMatch ruleMatch = new RuleMatch ( this , startPos , endPos , getMessage ( ) ) ; ruleMatch . setSuggestedReplacement ( " " + firstToken ) ; ruleMatches . add ( ruleMatch ) ; } } if ( tokens . length > 0 ) { String lastToken = tokens [ tokens . length - 1 ] . getToken ( ) ; prevSentenceEndsWithWhitespace = lastToken . trim ( ) . isEmpty ( ) && lastToken . length ( ) == 1 ; } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { isFirstSentence = true ; prevSentenceEndsWithWhitespace = false ; } }
package org . languagetool . rules . nl ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; import java . io . IOException ; import java . util . ResourceBundle ; public class CompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/nl/compounds.txt" ) ; public CompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "Hier wordt een koppelteken verwacht." , "Dit woord hoort waarschijnlijk aaneengeschreven." , "Deze uitdrukking hoort mogelijk aan elkaar, eventueel met een koppelteken." , "Koppeltekenprobleem" ) ; } @ Override public String getId ( ) { return "NL_COMPOUNDS" ; } @ Override public String getDescription ( ) { return "Woorden die aaneen horen met koppeltekens, bijvoorbeeld 'zee-egel' i.p.v. 'zee egel'.\n" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . rules ; public final class Example { private Example ( ) { } public static IncorrectExample wrong ( String example ) { requireMarkup ( example ) ; return new IncorrectExample ( example ) ; } public static String fixed ( String example ) { requireMarkup ( example ) ; return example ; } private static void requireMarkup ( String example ) { if ( ! example . contains ( "<marker>" ) || ! example . contains ( "</marker>" ) ) { throw new IllegalArgumentException ( "Example text must contain '<marker>...</marker>': " + example ) ; } } }
package org . languagetool . rules ; import java . io . IOException ; import java . net . URL ; import java . util . * ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; public abstract class Rule { protected final ResourceBundle messages ; private List < String > correctExamples = new ArrayList < > ( ) ; private List < IncorrectExample > incorrectExamples = new ArrayList < > ( ) ; private ITSIssueType locQualityIssueType = ITSIssueType . Uncategorized ; private Category category ; private URL url ; private boolean defaultOff ; public Rule ( ) { this ( null ) ; } public Rule ( final ResourceBundle messages ) { this . messages = messages ; } public abstract String getId ( ) ; public abstract String getDescription ( ) ; public abstract RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException ; public abstract void reset ( ) ; public boolean supportsLanguage ( final Language language ) { try { List < Class < ? extends Rule > > relevantRuleClasses = new ArrayList < > ( ) ; List < Rule > relevantRules = language . getRelevantRules ( JLanguageTool . getMessageBundle ( ) ) ; for ( Rule relevantRule : relevantRules ) { relevantRuleClasses . add ( relevantRule . getClass ( ) ) ; } return relevantRuleClasses . contains ( this . getClass ( ) ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } public boolean isDictionaryBasedSpellingRule ( ) { return false ; } public boolean useInOffice ( ) { return false ; } public final void setCorrectExamples ( final List < String > correctExamples ) { this . correctExamples = Objects . requireNonNull ( correctExamples ) ; } public final List < String > getCorrectExamples ( ) { return Collections . unmodifiableList ( correctExamples ) ; } public final void setIncorrectExamples ( final List < IncorrectExample > incorrectExamples ) { this . incorrectExamples = Objects . requireNonNull ( incorrectExamples ) ; } public final List < IncorrectExample > getIncorrectExamples ( ) { return Collections . unmodifiableList ( incorrectExamples ) ; } public final Category getCategory ( ) { return category ; } public final void setCategory ( final Category category ) { this . category = category ; } protected final RuleMatch [ ] toRuleMatchArray ( final List < RuleMatch > ruleMatches ) { return ruleMatches . toArray ( new RuleMatch [ ruleMatches . size ( ) ] ) ; } public final boolean isDefaultOff ( ) { return defaultOff ; } public final void setDefaultOff ( ) { defaultOff = true ; } public final void setDefaultOn ( ) { defaultOff = false ; } @ Nullable public URL getUrl ( ) { return url ; } public void setUrl ( URL url ) { this . url = url ; } public ITSIssueType getLocQualityIssueType ( ) { return locQualityIssueType ; } public void setLocQualityIssueType ( ITSIssueType locQualityIssueType ) { this . locQualityIssueType = Objects . requireNonNull ( locQualityIssueType ) ; } protected void addExamplePair ( IncorrectExample incorrectSentence , String correctSentence ) { incorrectExamples . add ( incorrectSentence ) ; correctExamples . add ( correctSentence ) ; } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import java . util . Set ; import java . util . TreeSet ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . tools . StringTools ; public abstract class AdvancedWordRepeatRule extends Rule { public AdvancedWordRepeatRule ( final ResourceBundle messages ) { super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setDefaultOff ( ) ; setLocQualityIssueType ( ITSIssueType . Style ) ; } protected abstract Set < String > getExcludedWordsPattern ( ) ; protected abstract Pattern getExcludedNonWordsPattern ( ) ; protected abstract Pattern getExcludedPos ( ) ; protected abstract String getMessage ( ) ; protected abstract String getShortMessage ( ) ; @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; boolean repetition = false ; final Set < String > inflectedWords = new TreeSet < > ( ) ; String prevLemma ; int curToken = 0 ; for ( int i = 1 ; i < tokens . length ; i ++ ) { final String token = tokens [ i ] . getToken ( ) ; boolean isWord = true ; boolean hasLemma = true ; if ( token . length ( ) < 2 ) { isWord = false ; } for ( AnalyzedToken analyzedToken : tokens [ i ] ) { final String posTag = analyzedToken . getPOSTag ( ) ; if ( posTag != null ) { if ( StringTools . isEmpty ( posTag ) ) { isWord = false ; break ; } final String lemma = analyzedToken . getLemma ( ) ; if ( lemma == null ) { hasLemma = false ; break ; } if ( getExcludedWordsPattern ( ) . contains ( lemma ) ) { isWord = false ; break ; } final Matcher m2 = getExcludedPos ( ) . matcher ( posTag ) ; if ( m2 . matches ( ) ) { isWord = false ; break ; } } else { hasLemma = false ; } } final Matcher m1 = getExcludedNonWordsPattern ( ) . matcher ( tokens [ i ] . getToken ( ) ) ; if ( isWord && m1 . matches ( ) ) { isWord = false ; } prevLemma = "" ; if ( isWord ) { boolean notSentEnd = false ; for ( AnalyzedToken analyzedToken : tokens [ i ] ) { final String pos = analyzedToken . getPOSTag ( ) ; if ( pos != null ) { notSentEnd |= JLanguageTool . SENTENCE_END_TAGNAME . equals ( pos ) ; } if ( hasLemma ) { final String curLemma = analyzedToken . getLemma ( ) ; if ( ! prevLemma . equals ( curLemma ) && ! notSentEnd ) { if ( inflectedWords . contains ( curLemma ) && curToken != i ) { repetition = true ; } else { inflectedWords . add ( analyzedToken . getLemma ( ) ) ; curToken = i ; } } prevLemma = curLemma ; } else { if ( inflectedWords . contains ( tokens [ i ] . getToken ( ) ) && ! notSentEnd ) { repetition = true ; } else { inflectedWords . add ( tokens [ i ] . getToken ( ) ) ; } } } } if ( repetition ) { final int pos = tokens [ i ] . getStartPos ( ) ; final RuleMatch ruleMatch = new RuleMatch ( this , pos , pos + token . length ( ) , getMessage ( ) , getShortMessage ( ) ) ; ruleMatches . add ( ruleMatch ) ; repetition = false ; } } return toRuleMatchArray ( ruleMatches ) ; } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import org . languagetool . JLanguageTool ; import java . io . BufferedReader ; import java . io . IOException ; import java . io . InputStream ; import java . io . InputStreamReader ; import java . util . Collections ; import java . util . HashSet ; import java . util . Set ; public class CompoundRuleData { private final Set < String > incorrectCompounds = new HashSet < > ( ) ; private final Set < String > noDashSuggestion = new HashSet < > ( ) ; private final Set < String > onlyDashSuggestion = new HashSet < > ( ) ; public CompoundRuleData ( String path ) { this ( new String [ ] { path } ) ; } public CompoundRuleData ( String ... paths ) { for ( String path : paths ) { try { loadCompoundFile ( path ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not load compound data from " + path , e ) ; } } } Set < String > getIncorrectCompounds ( ) { return Collections . unmodifiableSet ( incorrectCompounds ) ; } Set < String > getNoDashSuggestion ( ) { return Collections . unmodifiableSet ( noDashSuggestion ) ; } Set < String > getOnlyDashSuggestion ( ) { return Collections . unmodifiableSet ( onlyDashSuggestion ) ; } private void loadCompoundFile ( final String path ) throws IOException { try ( InputStream stream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( path ) ; InputStreamReader reader = new InputStreamReader ( stream , "utf-8" ) ; BufferedReader br = new BufferedReader ( reader ) ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } line = line . replace ( '-' , ' ' ) ; validateLine ( path , line ) ; if ( line . endsWith ( "+" ) ) { line = removeLastCharacter ( line ) ; noDashSuggestion . add ( line . toLowerCase ( ) ) ; } else if ( line . endsWith ( "*" ) ) { line = removeLastCharacter ( line ) ; onlyDashSuggestion . add ( line . toLowerCase ( ) ) ; } incorrectCompounds . add ( line . toLowerCase ( ) ) ; } } } private void validateLine ( String path , String line ) throws IOException { final String [ ] parts = line . split ( " " ) ; if ( parts . length == 1 ) { throw new RuntimeException ( "Not a compound in file " + path + ": " + line ) ; } if ( parts . length > AbstractCompoundRule . MAX_TERMS ) { throw new RuntimeException ( "Too many compound parts in file " + path + ": " + line + ", maximum allowed: " + AbstractCompoundRule . MAX_TERMS ) ; } if ( incorrectCompounds . contains ( line . toLowerCase ( ) ) ) { throw new RuntimeException ( "Duplicated word in file " + path + ": " + line ) ; } } private String removeLastCharacter ( String str ) { return str . substring ( 0 , str . length ( ) - 1 ) ; } }
package org . languagetool . rules ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . patterns . RuleFilter ; import java . util . List ; import java . util . Map ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; public abstract class PartialPosTagFilter implements RuleFilter { @ Nullable protected abstract List < AnalyzedTokenReadings > tag ( String token ) ; @ Override public RuleMatch acceptRuleMatch ( RuleMatch match , Map < String , String > args , AnalyzedTokenReadings [ ] patternTokens ) { if ( ! ( args . containsKey ( "no" ) && args . containsKey ( "regexp" ) && args . containsKey ( "postag_regexp" ) ) ) { throw new RuntimeException ( "Set 'no', 'regexp' and 'postag_regexp' for filter " + PartialPosTagFilter . class . getSimpleName ( ) ) ; } int tokenPos = Integer . parseInt ( args . get ( "no" ) ) ; Pattern pattern = Pattern . compile ( args . get ( "regexp" ) ) ; String requiredTagRegexp = args . get ( "postag_regexp" ) ; String token = patternTokens [ tokenPos - 1 ] . getToken ( ) ; Matcher matcher = pattern . matcher ( token ) ; if ( matcher . matches ( ) ) { String partialToken = matcher . group ( 1 ) ; List < AnalyzedTokenReadings > tags = tag ( partialToken ) ; if ( tags != null && partialTagHasRequiredTag ( tags , requiredTagRegexp ) ) { return match ; } return null ; } return null ; } private boolean partialTagHasRequiredTag ( List < AnalyzedTokenReadings > tags , String requiredTagRegexp ) { for ( AnalyzedTokenReadings tag : tags ) { for ( AnalyzedToken analyzedToken : tag . getReadings ( ) ) { boolean tagFound = analyzedToken . getPOSTag ( ) != null && analyzedToken . getPOSTag ( ) . matches ( requiredTagRegexp ) ; if ( tagFound ) { return true ; } } } return false ; } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; public class WordRepeatRule extends Rule { public WordRepeatRule ( final ResourceBundle messages , final Language language ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setLocQualityIssueType ( ITSIssueType . Duplication ) ; } public boolean ignore ( final AnalyzedTokenReadings [ ] tokens , final int position ) { return false ; } @ Override public String getId ( ) { return "WORD_REPEAT_RULE" ; } @ Override public String getDescription ( ) { return messages . getString ( "desc_repetition" ) ; } @ Override public RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; String prevToken = "" ; for ( int i = 1 ; i < tokens . length ; i ++ ) { final String token = tokens [ i ] . getToken ( ) ; if ( tokens [ i ] . isImmunized ( ) ) { continue ; } if ( isWord ( token ) && prevToken . equalsIgnoreCase ( token ) && ! ignore ( tokens , i ) ) { final String msg = messages . getString ( "repetition" ) ; final int prevPos = tokens [ i - 1 ] . getStartPos ( ) ; final int pos = tokens [ i ] . getStartPos ( ) ; final RuleMatch ruleMatch = createRuleMatch ( prevToken , token , prevPos , pos , msg ) ; ruleMatches . add ( ruleMatch ) ; } prevToken = token ; } return toRuleMatchArray ( ruleMatches ) ; } protected RuleMatch createRuleMatch ( String prevToken , String token , final int prevPos , final int pos , final String msg ) { RuleMatch ruleMatch = new RuleMatch ( this , prevPos , pos + prevToken . length ( ) , msg , messages . getString ( "desc_repetition_short" ) ) ; ruleMatch . setSuggestedReplacement ( prevToken ) ; return ruleMatch ; } private boolean isWord ( String token ) { boolean isWord = true ; if ( token . length ( ) == 0 ) { isWord = false ; } else if ( token . length ( ) == 1 ) { final char c = token . charAt ( 0 ) ; if ( ! Character . isLetter ( c ) ) { isWord = false ; } } return isWord ; } @ Override public void reset ( ) { } }
package org . languagetool . rules ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . databroker . ResourceDataBroker ; import org . languagetool . languagemodel . LanguageModel ; import org . languagetool . tokenizers . WordTokenizer ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . io . InputStream ; import java . util . * ; public abstract class ConfusionProbabilityRule extends Rule { public static final float MIN_COVERAGE = 0.5f ; private static final boolean DEBUG = false ; private final Map < String , List < ConfusionSet > > wordToSets ; private final LanguageModel lm ; private final long totalTokenCount ; private final int grams ; public abstract String getMessage ( String suggestion , String description ) ; protected abstract WordTokenizer getTokenizer ( ) ; public ConfusionProbabilityRule ( ResourceBundle messages , LanguageModel languageModel , Language language ) { this ( messages , languageModel , language , 3 ) ; } public ConfusionProbabilityRule ( ResourceBundle messages , LanguageModel languageModel , Language language , int grams ) { super ( messages ) ; setCategory ( new Category ( messages . getString ( "category_typo" ) ) ) ; setLocQualityIssueType ( ITSIssueType . NonConformance ) ; ResourceDataBroker dataBroker = JLanguageTool . getDataBroker ( ) ; String path = "/" + language . getShortName ( ) + "/confusion_sets.txt" ; try ( InputStream confusionSetStream = dataBroker . getFromResourceDirAsStream ( path ) ) { ConfusionSetLoader confusionSetLoader = new ConfusionSetLoader ( ) ; this . wordToSets = confusionSetLoader . loadConfusionSet ( confusionSetStream ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } this . lm = Objects . requireNonNull ( languageModel ) ; if ( grams < 1 || grams > 5 ) { throw new IllegalArgumentException ( "grams must be between 1 and 5: " + grams ) ; } this . grams = grams ; totalTokenCount = languageModel . getTotalTokenCount ( ) ; } @ Override public String getId ( ) { return "CONFUSION_RULE" ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) { List < GoogleToken > tokens = getGoogleTokens ( sentence . getText ( ) ) ; List < RuleMatch > matches = new ArrayList < > ( ) ; int pos = 0 ; for ( GoogleToken googleToken : tokens ) { String token = googleToken . token ; List < ConfusionSet > confusionSets = wordToSets . get ( token ) ; boolean uppercase = false ; if ( confusionSets == null && token . length ( ) > 0 && Character . isUpperCase ( token . charAt ( 0 ) ) ) { confusionSets = wordToSets . get ( StringTools . lowercaseFirstChar ( token ) ) ; uppercase = true ; } if ( confusionSets != null ) { for ( ConfusionSet confusionSet : confusionSets ) { boolean isEasilyConfused = confusionSet != null ; if ( isEasilyConfused ) { Set < ConfusionString > set = uppercase ? confusionSet . getUppercaseFirstCharSet ( ) : confusionSet . getSet ( ) ; ConfusionString betterAlternative = getBetterAlternativeOrNull ( tokens . get ( pos ) , tokens , set , confusionSet . getFactor ( ) ) ; if ( betterAlternative != null ) { String message = getMessage ( betterAlternative . getString ( ) , betterAlternative . getDescription ( ) ) ; RuleMatch match = new RuleMatch ( this , googleToken . startPos , googleToken . endPos , message ) ; match . setSuggestedReplacement ( betterAlternative . getString ( ) ) ; matches . add ( match ) ; } } } } pos ++ ; } return matches . toArray ( new RuleMatch [ matches . size ( ) ] ) ; } private List < GoogleToken > getGoogleTokens ( String sentence ) { List < GoogleToken > result = new ArrayList < > ( ) ; List < String > tokens = getTokenizer ( ) . tokenize ( sentence ) ; int startPos = 0 ; for ( String token : tokens ) { if ( ! StringTools . isWhitespace ( token ) ) { result . add ( new GoogleToken ( token , startPos , startPos + token . length ( ) ) ) ; } startPos += token . length ( ) ; } return result ; } @ Override public void reset ( ) { } public void setConfusionSet ( ConfusionSet set ) { wordToSets . clear ( ) ; for ( ConfusionString word : set . getSet ( ) ) { wordToSets . put ( word . getString ( ) , Collections . singletonList ( set ) ) ; } } @ Nullable private ConfusionString getBetterAlternativeOrNull ( GoogleToken token , List < GoogleToken > tokens , Set < ConfusionString > confusionSet , long factor ) { if ( confusionSet . size ( ) != 2 ) { throw new RuntimeException ( "Confusion set must be of size 2: " + confusionSet ) ; } ConfusionString other = getAlternativeTerm ( confusionSet , token ) ; return getBetterAlternativeOrNull ( token , tokens , other , factor ) ; } private ConfusionString getAlternativeTerm ( Set < ConfusionString > confusionSet , GoogleToken token ) { ConfusionString other = null ; for ( ConfusionString s : confusionSet ) { if ( ! s . getString ( ) . equals ( token . token ) ) { other = s ; } } if ( other == null ) { throw new RuntimeException ( "No alternative found for: " + token ) ; } return other ; } private ConfusionString getBetterAlternativeOrNull ( GoogleToken token , List < GoogleToken > tokens , ConfusionString otherWord , long factor ) { String word = token . token ; double p1 ; double p2 ; if ( grams == 3 ) { p1 = get3gramProbabilityFor ( token , tokens , word ) ; p2 = get3gramProbabilityFor ( token , tokens , otherWord . getString ( ) ) ; } else if ( grams == 4 ) { p1 = get4gramProbabilityFor ( token , tokens , word ) ; p2 = get4gramProbabilityFor ( token , tokens , otherWord . getString ( ) ) ; } else { throw new RuntimeException ( "Only 3grams and 4grams are supported" ) ; } debug ( "P(" + word + ") = %.50f\n" , p1 ) ; debug ( "P(" + otherWord + ") = %.50f\n" , p2 ) ; return p2 > p1 * factor ? otherWord : null ; } List < String > getContext ( GoogleToken token , List < GoogleToken > tokens , String newToken , int toLeft , int toRight ) { int pos = tokens . indexOf ( token ) ; if ( pos == - 1 ) { throw new RuntimeException ( "Token not found: " + token ) ; } List < String > result = new ArrayList < > ( ) ; for ( int i = 1 , added = 0 ; added < toLeft ; i ++ ) { if ( pos - i < 0 ) { result . clear ( ) ; result . add ( newToken ) ; for ( int j = pos - 1 ; j >= 0 ; j -- ) { result . add ( 0 , tokens . get ( j ) . token ) ; } return result ; } else { if ( ! tokens . get ( pos - i ) . isWhitespace ( ) ) { result . add ( 0 , tokens . get ( pos - i ) . token ) ; added ++ ; } } } result . add ( newToken ) ; for ( int i = 1 , added = 0 ; added < toRight ; i ++ ) { if ( pos + i >= tokens . size ( ) ) { result . add ( "." ) ; added ++ ; } else { if ( ! tokens . get ( pos + i ) . isWhitespace ( ) ) { result . add ( tokens . get ( pos + i ) . token ) ; added ++ ; } } } return result ; } private double get3gramProbabilityFor ( GoogleToken token , List < GoogleToken > tokens , String term ) { Probability ngram3Left = getPseudoProbability ( getContext ( token , tokens , term , 0 , 2 ) ) ; Probability ngram3Middle = getPseudoProbability ( getContext ( token , tokens , term , 1 , 1 ) ) ; Probability ngram3Right = getPseudoProbability ( getContext ( token , tokens , term , 2 , 0 ) ) ; if ( ngram3Left . coverage < MIN_COVERAGE && ngram3Middle . coverage < MIN_COVERAGE && ngram3Right . coverage < MIN_COVERAGE ) { debug ( " Min coverage of %.2f not reached: %.2f, %.2f, %.2f, assuming p=0\n" , MIN_COVERAGE , ngram3Left . coverage , ngram3Middle . coverage , ngram3Right . coverage ) ; return 0.0 ; } else { return ngram3Left . prob * ngram3Middle . prob * ngram3Right . prob ; } } private double get4gramProbabilityFor ( GoogleToken token , List < GoogleToken > tokens , String term ) { Probability ngram4Left = getPseudoProbability ( getContext ( token , tokens , term , 0 , 3 ) ) ; Probability ngram4Middle = getPseudoProbability ( getContext ( token , tokens , term , 1 , 2 ) ) ; Probability ngram4Right = getPseudoProbability ( getContext ( token , tokens , term , 3 , 0 ) ) ; if ( ngram4Left . coverage < MIN_COVERAGE && ngram4Middle . coverage < MIN_COVERAGE && ngram4Right . coverage < MIN_COVERAGE ) { debug ( " Min coverage of %.2f not reached: %.2f, %.2f, %.2f, assuming p=0\n" , MIN_COVERAGE , ngram4Left . coverage , ngram4Middle . coverage , ngram4Right . coverage ) ; return 0.0 ; } else { return ngram4Left . prob * ngram4Middle . prob * ngram4Right . prob ; } } Probability getPseudoProbability ( List < String > context ) { int maxCoverage = 0 ; int coverage = 0 ; long firstWordCount = lm . getCount ( context . get ( 0 ) ) ; maxCoverage ++ ; if ( firstWordCount == 0 ) { debug ( " # zero matches for '%s'\n" , context . get ( 0 ) ) ; } else { coverage ++ ; } double p = ( double ) ( firstWordCount + 1 ) / ( totalTokenCount + 1 ) ; debug ( " P for %s: %.20f\n" , context . get ( 0 ) , p ) ; for ( int i = 2 ; i <= context . size ( ) ; i ++ ) { List < String > subList = context . subList ( 0 , i ) ; long phraseCount = lm . getCount ( subList ) ; double thisP = ( double ) ( phraseCount + 1 ) / ( firstWordCount + 1 ) ; maxCoverage ++ ; debug ( " P for " + subList + ": %.20f\n" , thisP ) ; if ( phraseCount == 0 ) { debug ( " # zero matches for '%s'\n" , subList ) ; } else { coverage ++ ; } p *= thisP ; } debug ( " " + StringTools . listToString ( context , " " ) + " => %.20f\n" , p ) ; return new Probability ( p , ( float ) coverage / maxCoverage ) ; } private void debug ( String message , Object ... vars ) { if ( DEBUG ) { System . out . printf ( Locale . ENGLISH , message , vars ) ; } } static class Probability { final double prob ; final float coverage ; Probability ( double prob , float coverage ) { this . prob = prob ; this . coverage = coverage ; } } static class GoogleToken { String token ; int startPos ; int endPos ; GoogleToken ( String token , int startPos , int endPos ) { this . token = token ; this . startPos = startPos ; this . endPos = endPos ; } boolean isWhitespace ( ) { return StringTools . isWhitespace ( token ) ; } } }
package org . languagetool . rules ; public class SymbolLocator { private final String symbol ; private final int index ; private final int startPos ; SymbolLocator ( final String symbol , final int index , final int startPos ) { this . symbol = symbol ; this . index = index ; this . startPos = startPos ; } public String getSymbol ( ) { return symbol ; } int getIndex ( ) { return index ; } int getStartPos ( ) { return startPos ; } @ Override public String toString ( ) { return symbol + "/" + index ; } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; public final class IncorrectExample { private final String example ; private final List < String > corrections ; public IncorrectExample ( final String example ) { this ( example , Collections . < String > emptyList ( ) ) ; } public IncorrectExample ( final String example , final List < String > corrections ) { this . example = example ; this . corrections = Collections . unmodifiableList ( new ArrayList < > ( corrections ) ) ; } public String getExample ( ) { return example ; } public List < String > getCorrections ( ) { return corrections ; } @ Override public String toString ( ) { return example + " " + corrections ; } }
package org . languagetool . rules ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tools . StringTools ; import static org . languagetool . tools . StringTools . isEmpty ; public class CommaWhitespaceRule extends Rule { public CommaWhitespaceRule ( final ResourceBundle messages ) { super ( messages ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; setLocQualityIssueType ( ITSIssueType . Whitespace ) ; } @ Override public String getId ( ) { return "COMMA_PARENTHESIS_WHITESPACE" ; } @ Override public final String getDescription ( ) { return messages . getString ( "desc_comma_whitespace" ) ; } public String getCommaCharacter ( ) { return "," ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokens ( ) ; String prevToken = "" ; String prevPrevToken = "" ; boolean prevWhite = false ; for ( int i = 0 ; i < tokens . length ; i ++ ) { final String token = tokens [ i ] . getToken ( ) ; final boolean isWhitespace = tokens [ i ] . isWhitespace ( ) || StringTools . isNonBreakingWhitespace ( token ) || tokens [ i ] . isFieldCode ( ) ; String msg = null ; String suggestionText = null ; if ( isWhitespace && isLeftBracket ( prevToken ) ) { msg = messages . getString ( "no_space_after" ) ; suggestionText = prevToken ; } else if ( ! isWhitespace && prevToken . equals ( getCommaCharacter ( ) ) && ! isQuoteOrHyphenOrComma ( token ) && ! containsDigit ( prevPrevToken ) && ! containsDigit ( token ) && ! "," . equals ( prevPrevToken ) ) { msg = messages . getString ( "missing_space_after_comma" ) ; suggestionText = getCommaCharacter ( ) + " " + tokens [ i ] . getToken ( ) ; } else if ( prevWhite ) { if ( isRightBracket ( token ) ) { msg = messages . getString ( "no_space_before" ) ; suggestionText = token ; } else if ( token . equals ( getCommaCharacter ( ) ) ) { msg = messages . getString ( "space_after_comma" ) ; suggestionText = getCommaCharacter ( ) ; if ( i + 1 < tokens . length && getCommaCharacter ( ) . equals ( tokens [ i + 1 ] . getToken ( ) ) ) { msg = null ; } } else if ( token . equals ( "." ) ) { msg = messages . getString ( "no_space_before_dot" ) ; suggestionText = "." ; if ( i + 1 < tokens . length && isDigitOrDot ( tokens [ i + 1 ] . getToken ( ) ) ) { msg = null ; } } } if ( msg != null ) { final int fromPos = tokens [ i - 1 ] . getStartPos ( ) ; final int toPos = tokens [ i ] . getEndPos ( ) ; final RuleMatch ruleMatch = new RuleMatch ( this , fromPos , toPos , msg ) ; ruleMatch . setSuggestedReplacement ( suggestionText ) ; ruleMatches . add ( ruleMatch ) ; } prevPrevToken = prevToken ; prevToken = token ; prevWhite = isWhitespace && ! tokens [ i ] . isFieldCode ( ) ; } return toRuleMatchArray ( ruleMatches ) ; } private static boolean isQuoteOrHyphenOrComma ( final String str ) { if ( str . length ( ) == 1 ) { final char c = str . charAt ( 0 ) ; if ( c == '\'' || c == '-' || c == '”' || c == '’' || c == '"' || c == '“' || c == ',' ) { return true ; } } return false ; } private static boolean isDigitOrDot ( final String str ) { if ( isEmpty ( str ) ) { return false ; } final char c = str . charAt ( 0 ) ; return c == '.' || Character . isDigit ( c ) ; } private static boolean isLeftBracket ( final String str ) { if ( isEmpty ( str ) ) { return false ; } final char c = str . charAt ( 0 ) ; return c == '(' || c == '[' || c == '{' ; } private static boolean isRightBracket ( final String str ) { if ( isEmpty ( str ) ) { return false ; } final char c = str . charAt ( 0 ) ; return c == ')' || c == ']' || c == '}' ; } private static boolean containsDigit ( final String str ) { for ( int i = 0 ; i < str . length ( ) ; i ++ ) { if ( Character . isDigit ( str . charAt ( i ) ) ) { return true ; } } return false ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . nl ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; import java . io . IOException ; import java . util . ResourceBundle ; public final class MorfologikDutchSpellerRule extends MorfologikSpellerRule { public MorfologikDutchSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return "/nl/spelling/nl_NL.dict" ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_NL_NL" ; } @ Override protected String getIgnoreFileName ( ) { return "/nl/spelling/ignore.txt" ; } @ Override protected String getSpellingFileName ( ) { return "/nl/spelling/spelling.txt" ; } @ Override protected String getProhibitFileName ( ) { return "/nl/spelling/prohibit.txt" ; } }
package org . languagetool . rules ; import java . util . Arrays ; import java . util . Locale ; public enum ITSIssueType { Terminology , Mistranslation , Omission , Untranslated , Addition , Duplication , Inconsistency , Grammar , Legal , Register , LocaleSpecificContent ( "locale-specific-content" ) , LocaleViolation ( "locale-violation" ) , Style , Characters , Misspelling , Typographical , Formatting , InconsistentEntities ( "inconsistent-entities" ) , Numbers , Markup , PatternProblem ( "pattern-problem" ) , Whitespace , Internationalization , Length , NonConformance ( "non-conformance" ) , Uncategorized , Other ; public static ITSIssueType getIssueType ( String name ) { for ( ITSIssueType issueType : values ( ) ) { if ( issueType . toString ( ) . equals ( name ) ) { return issueType ; } } throw new IllegalArgumentException ( "No IssueType found for name '" + name + "'. Valid values: " + Arrays . toString ( values ( ) ) ) ; } private final String name ; ITSIssueType ( ) { this . name = name ( ) ; } ITSIssueType ( String name ) { this . name = name ; } @ Override public String toString ( ) { return name . toLowerCase ( Locale . ENGLISH ) ; } }
package org . languagetool . rules ; public final class Category { public enum Location { INTERNAL , EXTERNAL } private static final int DEFAULT_PRIORITY = 50 ; private final int priority ; private final String name ; private final Location location ; private final boolean defaultOff ; public Category ( final String name , final int priority , Location location , boolean onByDefault ) { if ( priority < 0 || priority > 100 ) { throw new IllegalArgumentException ( "priority must be in range 0 - 100: " + priority ) ; } this . name = name ; this . priority = priority ; this . location = location ; this . defaultOff = ! onByDefault ; } Category ( final String name , final int priority ) { this ( name , priority , Location . INTERNAL , true ) ; } public Category ( final String name ) { this ( name , Location . INTERNAL ) ; } public Category ( String name , Location location ) { this ( name , DEFAULT_PRIORITY , location , true ) ; } public Category ( String name , Location location , boolean onByDefault ) { this ( name , DEFAULT_PRIORITY , location , onByDefault ) ; } public String getName ( ) { return name ; } public int getPriority ( ) { return priority ; } @ Override public String toString ( ) { return name ; } public boolean isDefaultOff ( ) { return defaultOff ; } public Location getLocation ( ) { return location ; } }
package org . languagetool . rules . patterns ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . xml . sax . SAXException ; import org . xml . sax . helpers . DefaultHandler ; import javax . xml . parsers . ParserConfigurationException ; import javax . xml . parsers . SAXParser ; import javax . xml . parsers . SAXParserFactory ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . io . InputStream ; import java . text . MessageFormat ; import java . util . Iterator ; import java . util . List ; import java . util . ResourceBundle ; public class FalseFriendRuleLoader extends DefaultHandler { public final List < PatternRule > getRules ( final File file , final Language language , final Language motherTongue ) throws IOException { try ( InputStream inputStream = new FileInputStream ( file ) ) { return getRules ( inputStream , language , motherTongue ) ; } catch ( ParserConfigurationException | SAXException e ) { throw new IOException ( "Could not load false friend rules from " + file , e ) ; } } public final List < PatternRule > getRules ( final InputStream stream , final Language textLanguage , final Language motherTongue ) throws ParserConfigurationException , SAXException , IOException { final FalseFriendRuleHandler handler = new FalseFriendRuleHandler ( textLanguage , motherTongue ) ; final SAXParserFactory factory = SAXParserFactory . newInstance ( ) ; final SAXParser saxParser = factory . newSAXParser ( ) ; saxParser . getXMLReader ( ) . setFeature ( "http://apache.org/xml/features/nonvalidating/load-external-dtd" , false ) ; saxParser . parse ( stream , handler ) ; final List < PatternRule > rules = handler . getRules ( ) ; final ResourceBundle messages = ResourceBundle . getBundle ( JLanguageTool . MESSAGE_BUNDLE , motherTongue . getLocale ( ) ) ; final MessageFormat msgFormat = new MessageFormat ( messages . getString ( "false_friend_suggestion" ) ) ; for ( final PatternRule rule : rules ) { final List < String > suggestions = handler . getSuggestionMap ( ) . get ( rule . getId ( ) ) ; if ( suggestions != null ) { final String [ ] msg = { formatSuggestions ( suggestions ) } ; rule . setMessage ( rule . getMessage ( ) + " " + msgFormat . format ( msg ) ) ; } } return rules ; } private String formatSuggestions ( final List < String > l ) { final StringBuilder sb = new StringBuilder ( ) ; for ( final Iterator < String > iter = l . iterator ( ) ; iter . hasNext ( ) ; ) { final String s = iter . next ( ) ; sb . append ( "<suggestion>" ) ; sb . append ( s ) ; sb . append ( "</suggestion>" ) ; if ( iter . hasNext ( ) ) { sb . append ( ", " ) ; } } return sb . toString ( ) ; } }
package org . languagetool . rules . patterns ; import org . apache . commons . lang . Validate ; import org . jetbrains . annotations . Nullable ; public final class PatternRuleId { private final String id ; private final String subId ; public PatternRuleId ( String id ) { Validate . notEmpty ( id , "id must be set" ) ; this . id = id ; this . subId = null ; } public PatternRuleId ( String id , String subId ) { Validate . notEmpty ( id , "id must be set" ) ; Validate . notEmpty ( subId , "subId must be set, if specified" ) ; this . id = id ; this . subId = subId ; } public String getId ( ) { return id ; } @ Nullable public String getSubId ( ) { return subId ; } @ Override public String toString ( ) { if ( subId != null ) { return id + "/" + subId ; } else { return id ; } } }
package org . languagetool . rules . patterns ; import java . util . regex . Pattern ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . tools . StringTools ; public final class Match { public enum CaseConversion { NONE , STARTLOWER , STARTUPPER , ALLLOWER , ALLUPPER , PRESERVE } public enum IncludeRange { NONE , FOLLOWING , ALL } private final String posTag ; private final boolean suppressMisspelled ; private final String regexReplace ; private final String posTagReplace ; private final CaseConversion caseConversionType ; private final IncludeRange includeSkipped ; private final Pattern pRegexMatch ; private final boolean setPos ; private boolean postagRegexp ; private boolean staticLemma ; private String lemma ; private int tokenRef ; private Pattern pPosRegexMatch ; private boolean inMessageOnly ; public Match ( final String posTag , final String posTagReplace , final boolean postagRegexp , final String regexMatch , final String regexReplace , final CaseConversion caseConversionType , final boolean setPOS , final boolean suppressMisspelled , final IncludeRange includeSkipped ) { this . posTag = posTag ; this . postagRegexp = postagRegexp ; this . caseConversionType = caseConversionType ; pRegexMatch = regexMatch != null ? Pattern . compile ( regexMatch ) : null ; if ( postagRegexp && posTag != null ) { pPosRegexMatch = Pattern . compile ( posTag ) ; } this . regexReplace = regexReplace ; this . posTagReplace = posTagReplace ; this . setPos = setPOS ; this . includeSkipped = includeSkipped ; this . suppressMisspelled = suppressMisspelled ; } public MatchState createState ( final Synthesizer synthesizer , final AnalyzedTokenReadings token ) { final MatchState state = new MatchState ( this , synthesizer ) ; state . setToken ( token ) ; return state ; } public MatchState createState ( final Synthesizer synthesizer , final AnalyzedTokenReadings [ ] tokens , final int index , final int next ) { final MatchState state = new MatchState ( this , synthesizer ) ; state . setToken ( tokens , index , next ) ; return state ; } public boolean setsPos ( ) { return setPos ; } public boolean posRegExp ( ) { return postagRegexp ; } public void setLemmaString ( final String lemmaString ) { if ( ! StringTools . isEmpty ( lemmaString ) ) { lemma = lemmaString ; staticLemma = true ; postagRegexp = true ; if ( posTag != null ) { pPosRegexMatch = Pattern . compile ( posTag ) ; } } } public String getLemma ( ) { return lemma ; } public boolean isStaticLemma ( ) { return staticLemma ; } public boolean checksSpelling ( ) { return suppressMisspelled ; } public void setTokenRef ( int i ) { tokenRef = i ; } public int getTokenRef ( ) { return tokenRef ; } public boolean convertsCase ( ) { return caseConversionType != CaseConversion . NONE ; } public CaseConversion getCaseConversionType ( ) { return caseConversionType ; } public void setInMessageOnly ( boolean inMessageOnly ) { this . inMessageOnly = inMessageOnly ; } public boolean isInMessageOnly ( ) { return inMessageOnly ; } public String getPosTag ( ) { return posTag ; } public Pattern getRegexMatch ( ) { return pRegexMatch ; } public String getRegexReplace ( ) { return regexReplace ; } public Pattern getPosRegexMatch ( ) { return pPosRegexMatch ; } public boolean isPostagRegexp ( ) { return postagRegexp ; } public String getPosTagReplace ( ) { return posTagReplace ; } public IncludeRange getIncludeSkipped ( ) { return includeSkipped ; } }
package org . languagetool . rules . patterns ; import java . net . MalformedURLException ; import java . net . URL ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . HashMap ; import java . util . List ; import org . apache . commons . lang . ObjectUtils ; import org . languagetool . Languages ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . tagging . disambiguation . rules . DisambiguationPatternRule ; import org . xml . sax . Attributes ; import org . xml . sax . SAXException ; public class PatternRuleHandler extends XMLRuleHandler { public static final String TYPE = "type" ; static final String MARKER_TAG = "<marker>" ; static final String PLEASE_SPELL_ME = "<pleasespellme/>" ; private static final String EXTERNAL = "external" ; protected Category category ; protected String categoryIssueType ; protected String ruleGroupIssueType ; protected String ruleIssueType ; protected String name ; protected String filterClassName ; protected String filterArgs ; private int subId ; private boolean defaultOff ; private boolean ruleGroupDefaultOff ; private boolean defaultOn ; private String ruleGroupDescription ; private int startPos = - 1 ; private int endPos = - 1 ; private int tokenCountForMarker ; private int antiPatternCounter ; private boolean inRule ; private List < DisambiguationPatternRule > rulegroupAntiPatterns ; private List < DisambiguationPatternRule > ruleAntiPatterns ; private boolean relaxedMode = false ; private boolean inAntiPattern ; void setRelaxedMode ( boolean relaxedMode ) { this . relaxedMode = relaxedMode ; } @ Override public void startElement ( final String namespaceURI , final String lName , final String qName , final Attributes attrs ) throws SAXException { switch ( qName ) { case "category" : final String catName = attrs . getValue ( NAME ) ; final String priorityStr = attrs . getValue ( "priority" ) ; Category . Location location = YES . equals ( attrs . getValue ( EXTERNAL ) ) ? Category . Location . EXTERNAL : Category . Location . INTERNAL ; final boolean onByDefault = ! OFF . equals ( attrs . getValue ( DEFAULT ) ) ; if ( priorityStr == null ) { category = new Category ( catName , location , onByDefault ) ; } else { category = new Category ( catName , Integer . parseInt ( priorityStr ) , location , onByDefault ) ; } if ( attrs . getValue ( TYPE ) != null ) { categoryIssueType = attrs . getValue ( TYPE ) ; } break ; case "rules" : final String languageStr = attrs . getValue ( "lang" ) ; language = Languages . getLanguageForShortName ( languageStr ) ; break ; case RULE : inRule = true ; shortMessage = new StringBuilder ( ) ; message = new StringBuilder ( ) ; suggestionsOutMsg = new StringBuilder ( ) ; url = new StringBuilder ( ) ; id = attrs . getValue ( ID ) ; name = attrs . getValue ( NAME ) ; if ( inRuleGroup ) { subId ++ ; if ( id == null ) { id = ruleGroupId ; } if ( name == null ) { name = ruleGroupDescription ; } } if ( inRuleGroup && ruleGroupDefaultOff && attrs . getValue ( DEFAULT ) != null ) { throw new RuntimeException ( "Rule group " + ruleGroupId + " is off by default, thus rule " + id + " cannot specify 'default=...'" ) ; } if ( inRuleGroup && ruleGroupDefaultOff ) { defaultOff = true ; defaultOn = false ; } else { defaultOff = OFF . equals ( attrs . getValue ( DEFAULT ) ) ; defaultOn = ON . equals ( attrs . getValue ( DEFAULT ) ) ; } correctExamples = new ArrayList < > ( ) ; incorrectExamples = new ArrayList < > ( ) ; if ( suggestionMatches != null ) { suggestionMatches . clear ( ) ; } if ( suggestionMatchesOutMsg != null ) { suggestionMatchesOutMsg . clear ( ) ; } if ( attrs . getValue ( TYPE ) != null ) { ruleIssueType = attrs . getValue ( TYPE ) ; } break ; case PATTERN : startPattern ( attrs ) ; tokenCountForMarker = 0 ; break ; case ANTIPATTERN : inAntiPattern = true ; antiPatternCounter ++ ; caseSensitive = YES . equals ( attrs . getValue ( CASE_SENSITIVE ) ) ; tokenCounter = 0 ; tokenCountForMarker = 0 ; break ; case AND : inAndGroup = true ; tokenCountForMarker ++ ; break ; case OR : inOrGroup = true ; tokenCountForMarker ++ ; break ; case UNIFY : inUnification = true ; uniNegation = YES . equals ( attrs . getValue ( NEGATE ) ) ; break ; case UNIFY_IGNORE : inUnificationNeutral = true ; break ; case FEATURE : uFeature = attrs . getValue ( ID ) ; break ; case TYPE : uType = attrs . getValue ( ID ) ; uTypeList . add ( uType ) ; break ; case TOKEN : setToken ( attrs ) ; if ( ! inAndGroup && ! inOrGroup ) { tokenCountForMarker ++ ; } break ; case EXCEPTION : setExceptions ( attrs ) ; break ; case EXAMPLE : String typeVal = attrs . getValue ( TYPE ) ; if ( "incorrect" . equals ( typeVal ) || attrs . getValue ( "correction" ) != null ) { inIncorrectExample = true ; incorrectExample = new StringBuilder ( ) ; exampleCorrection = new StringBuilder ( ) ; if ( attrs . getValue ( "correction" ) != null ) { exampleCorrection . append ( attrs . getValue ( "correction" ) ) ; } } else if ( "triggers_error" . equals ( typeVal ) ) { } else { inCorrectExample = true ; correctExample = new StringBuilder ( ) ; } break ; case "filter" : filterClassName = attrs . getValue ( "class" ) ; filterArgs = attrs . getValue ( "args" ) ; break ; case MESSAGE : inMessage = true ; inSuggestion = false ; message = new StringBuilder ( ) ; break ; case SUGGESTION : if ( YES . equals ( attrs . getValue ( "suppress_misspelled" ) ) ) { message . append ( PLEASE_SPELL_ME ) ; } if ( inMessage ) { message . append ( "<suggestion>" ) ; } else { suggestionsOutMsg . append ( "<suggestion>" ) ; } inSuggestion = true ; break ; case "short" : if ( inRule ) { inShortMessage = true ; shortMessage = new StringBuilder ( ) ; } else { inShortMessageForRuleGroup = true ; shortMessageForRuleGroup = new StringBuilder ( ) ; } break ; case "url" : if ( inRule ) { inUrl = true ; url = new StringBuilder ( ) ; } else { inUrlForRuleGroup = true ; urlForRuleGroup = new StringBuilder ( ) ; } break ; case RULEGROUP : ruleGroupId = attrs . getValue ( ID ) ; ruleGroupDescription = attrs . getValue ( NAME ) ; ruleGroupDefaultOff = OFF . equals ( attrs . getValue ( DEFAULT ) ) ; urlForRuleGroup = new StringBuilder ( ) ; shortMessageForRuleGroup = new StringBuilder ( ) ; inRuleGroup = true ; subId = 0 ; if ( attrs . getValue ( TYPE ) != null ) { ruleGroupIssueType = attrs . getValue ( TYPE ) ; } break ; case MATCH : setMatchElement ( attrs ) ; break ; case MARKER : if ( inIncorrectExample ) { incorrectExample . append ( MARKER_TAG ) ; } else if ( inCorrectExample ) { correctExample . append ( MARKER_TAG ) ; } else if ( inPattern || inAntiPattern ) { startPos = tokenCounter ; inMarker = true ; } break ; case UNIFICATION : uFeature = attrs . getValue ( "feature" ) ; inUnificationDef = true ; break ; case "equivalence" : uType = attrs . getValue ( TYPE ) ; break ; case PHRASES : inPhrases = true ; break ; case "includephrases" : phraseElementInit ( ) ; break ; case "phrase" : if ( inPhrases ) { phraseId = attrs . getValue ( ID ) ; } break ; case "phraseref" : if ( attrs . getValue ( "idref" ) != null ) { preparePhrase ( attrs ) ; tokenCountForMarker ++ ; } break ; } } @ Override public void endElement ( final String namespaceURI , final String sName , final String qName ) throws SAXException { switch ( qName ) { case "category" : categoryIssueType = null ; break ; case RULE : suggestionMatchesOutMsg = addLegacyMatches ( suggestionMatchesOutMsg , suggestionsOutMsg . toString ( ) , false ) ; phraseElementInit ( ) ; if ( relaxedMode && id == null ) { id = "" ; } if ( relaxedMode && name == null ) { name = "" ; } if ( phrasePatternTokens . isEmpty ( ) ) { final List < PatternToken > tmpPatternTokens = new ArrayList < > ( ) ; createRules ( new ArrayList < > ( patternTokens ) , tmpPatternTokens , 0 ) ; } else { if ( ! patternTokens . isEmpty ( ) ) { for ( List < PatternToken > ph : phrasePatternTokens ) { ph . addAll ( new ArrayList < > ( patternTokens ) ) ; } } for ( List < PatternToken > phrasePatternToken : phrasePatternTokens ) { processElement ( phrasePatternToken ) ; final List < PatternToken > tmpPatternTokens = new ArrayList < > ( ) ; createRules ( phrasePatternToken , tmpPatternTokens , 0 ) ; } } patternTokens . clear ( ) ; if ( phrasePatternTokens != null ) { phrasePatternTokens . clear ( ) ; } ruleIssueType = null ; inRule = false ; filterClassName = null ; filterArgs = null ; break ; case EXCEPTION : finalizeExceptions ( ) ; break ; case AND : inAndGroup = false ; andGroupCounter = 0 ; tokenCounter ++ ; break ; case OR : inOrGroup = false ; orGroupCounter = 0 ; tokenCounter ++ ; break ; case TOKEN : finalizeTokens ( ) ; break ; case PATTERN : inPattern = false ; if ( lastPhrase ) { patternTokens . clear ( ) ; } tokenCounter = 0 ; break ; case ANTIPATTERN : String antiId = id ; if ( inRuleGroup ) { if ( subId > 0 ) { antiId = ruleGroupId + "[" + subId + "]" ; } else { antiId = ruleGroupId ; } } final DisambiguationPatternRule rule = new DisambiguationPatternRule ( antiId + "_antipattern:" + antiPatternCounter , "antipattern" , language , patternTokens , null , null , DisambiguationPatternRule . DisambiguatorAction . IMMUNIZE ) ; if ( startPos != - 1 && endPos != - 1 ) { rule . setStartPositionCorrection ( startPos ) ; rule . setEndPositionCorrection ( endPos - tokenCountForMarker ) ; } else { for ( PatternToken patternToken : patternTokens ) { patternToken . setInsideMarker ( true ) ; } } patternTokens . clear ( ) ; if ( inRule ) { if ( ruleAntiPatterns == null ) { ruleAntiPatterns = new ArrayList < > ( ) ; } ruleAntiPatterns . add ( rule ) ; } else { if ( rulegroupAntiPatterns == null ) { rulegroupAntiPatterns = new ArrayList < > ( ) ; } rulegroupAntiPatterns . add ( rule ) ; } tokenCounter = 0 ; inAntiPattern = false ; break ; case EXAMPLE : if ( inCorrectExample ) { correctExamples . add ( correctExample . toString ( ) ) ; } else if ( inIncorrectExample ) { final IncorrectExample example ; final List < String > corrections = new ArrayList < > ( ) ; corrections . addAll ( Arrays . asList ( exampleCorrection . toString ( ) . split ( "\\|" ) ) ) ; if ( corrections . size ( ) > 0 ) { if ( exampleCorrection . toString ( ) . endsWith ( "|" ) ) { corrections . add ( "" ) ; } example = new IncorrectExample ( incorrectExample . toString ( ) , corrections ) ; } else { example = new IncorrectExample ( incorrectExample . toString ( ) ) ; } incorrectExamples . add ( example ) ; } inCorrectExample = false ; inIncorrectExample = false ; correctExample = new StringBuilder ( ) ; incorrectExample = new StringBuilder ( ) ; exampleCorrection = new StringBuilder ( ) ; break ; case MESSAGE : suggestionMatches = addLegacyMatches ( suggestionMatches , message . toString ( ) , true ) ; inMessage = false ; break ; case SUGGESTION : if ( inMessage ) { message . append ( "</suggestion>" ) ; } else { suggestionsOutMsg . append ( "</suggestion>" ) ; } inSuggestion = false ; break ; case "short" : inShortMessage = false ; inShortMessageForRuleGroup = false ; break ; case "url" : inUrl = false ; inUrlForRuleGroup = false ; break ; case MATCH : if ( inMessage ) { suggestionMatches . get ( suggestionMatches . size ( ) - 1 ) . setLemmaString ( match . toString ( ) ) ; } else if ( inSuggestion ) { suggestionMatchesOutMsg . get ( suggestionMatchesOutMsg . size ( ) - 1 ) . setLemmaString ( match . toString ( ) ) ; } else if ( inToken ) { tokenReference . setLemmaString ( match . toString ( ) ) ; } inMatch = false ; break ; case RULEGROUP : urlForRuleGroup = new StringBuilder ( ) ; shortMessageForRuleGroup = new StringBuilder ( ) ; inRuleGroup = false ; ruleGroupIssueType = null ; if ( rulegroupAntiPatterns != null ) { rulegroupAntiPatterns . clear ( ) ; } antiPatternCounter = 0 ; ruleGroupDefaultOff = false ; defaultOff = false ; defaultOn = false ; break ; case MARKER : if ( inCorrectExample ) { correctExample . append ( "</marker>" ) ; } else if ( inIncorrectExample ) { incorrectExample . append ( "</marker>" ) ; } else if ( inPattern || inAntiPattern ) { endPos = tokenCountForMarker ; inMarker = false ; } break ; case "phrase" : if ( inPhrases ) { finalizePhrase ( ) ; } break ; case "includephrases" : patternTokens . clear ( ) ; break ; case PHRASES : if ( inPhrases ) { inPhrases = false ; } break ; case UNIFICATION : inUnificationDef = false ; break ; case FEATURE : equivalenceFeatures . put ( uFeature , uTypeList ) ; uTypeList = new ArrayList < > ( ) ; break ; case UNIFY : inUnification = false ; equivalenceFeatures = new HashMap < > ( ) ; final int lastElement = patternTokens . size ( ) - 1 ; patternTokens . get ( lastElement ) . setLastInUnification ( ) ; if ( uniNegation ) { patternTokens . get ( lastElement ) . setUniNegation ( ) ; } break ; case UNIFY_IGNORE : inUnificationNeutral = false ; break ; } } private void createRules ( List < PatternToken > elemList , List < PatternToken > tmpPatternTokens , int numElement ) { String shortMessage = "" ; if ( this . shortMessage != null && this . shortMessage . length ( ) > 0 ) { shortMessage = this . shortMessage . toString ( ) ; } else if ( shortMessageForRuleGroup != null && shortMessageForRuleGroup . length ( ) > 0 ) { shortMessage = this . shortMessageForRuleGroup . toString ( ) ; } if ( numElement >= elemList . size ( ) ) { final PatternRule rule = new PatternRule ( id , language , tmpPatternTokens , name , message . toString ( ) , shortMessage , suggestionsOutMsg . toString ( ) , phrasePatternTokens . size ( ) > 1 ) ; if ( filterClassName != null && filterArgs != null ) { RuleFilterCreator creator = new RuleFilterCreator ( ) ; RuleFilter filter = creator . getFilter ( filterClassName ) ; rule . setFilter ( filter ) ; rule . setFilterArguments ( filterArgs ) ; } prepareRule ( rule ) ; rules . add ( rule ) ; } else { PatternToken patternToken = elemList . get ( numElement ) ; if ( patternToken . hasOrGroup ( ) ) { for ( PatternToken patternTokenOfOrGroup : patternToken . getOrGroup ( ) ) { final List < PatternToken > tmpElements2 = new ArrayList < > ( ) ; tmpElements2 . addAll ( tmpPatternTokens ) ; tmpElements2 . add ( ( PatternToken ) ObjectUtils . clone ( patternTokenOfOrGroup ) ) ; createRules ( elemList , tmpElements2 , numElement + 1 ) ; } } tmpPatternTokens . add ( ( PatternToken ) ObjectUtils . clone ( patternToken ) ) ; createRules ( elemList , tmpPatternTokens , numElement + 1 ) ; } } protected void prepareRule ( final PatternRule rule ) { if ( startPos != - 1 && endPos != - 1 ) { rule . setStartPositionCorrection ( startPos ) ; rule . setEndPositionCorrection ( endPos - tokenCountForMarker ) ; } startPos = - 1 ; endPos = - 1 ; rule . setCorrectExamples ( correctExamples ) ; rule . setIncorrectExamples ( incorrectExamples ) ; rule . setCategory ( category ) ; if ( rulegroupAntiPatterns != null && ! rulegroupAntiPatterns . isEmpty ( ) ) { rule . setAntiPatterns ( rulegroupAntiPatterns ) ; } if ( ruleAntiPatterns != null && ! ruleAntiPatterns . isEmpty ( ) ) { rule . setAntiPatterns ( ruleAntiPatterns ) ; ruleAntiPatterns . clear ( ) ; } if ( inRuleGroup ) { rule . setSubId ( Integer . toString ( subId ) ) ; } else { rule . setSubId ( "1" ) ; } caseSensitive = false ; if ( suggestionMatches != null ) { for ( final Match m : suggestionMatches ) { rule . addSuggestionMatch ( m ) ; } if ( phrasePatternTokens . size ( ) <= 1 ) { suggestionMatches . clear ( ) ; } } if ( suggestionMatchesOutMsg != null ) { for ( final Match m : suggestionMatchesOutMsg ) { rule . addSuggestionMatchOutMsg ( m ) ; } suggestionMatchesOutMsg . clear ( ) ; } if ( defaultOff ) { rule . setDefaultOff ( ) ; } if ( category == null ) { throw new RuntimeException ( "Cannot activate rule '" + id + "', it is outside of a <category>...</category>" ) ; } if ( category . isDefaultOff ( ) && ! defaultOn ) { rule . setDefaultOff ( ) ; } if ( url != null && url . length ( ) > 0 ) { try { rule . setUrl ( new URL ( url . toString ( ) ) ) ; } catch ( MalformedURLException e ) { throw new RuntimeException ( "Could not parse URL for rule: " + rule + ": '" + url + "'" , e ) ; } } else if ( urlForRuleGroup != null && urlForRuleGroup . length ( ) > 0 ) { try { rule . setUrl ( new URL ( urlForRuleGroup . toString ( ) ) ) ; } catch ( MalformedURLException e ) { throw new RuntimeException ( "Could not parse URL for rule: " + rule + ": '" + urlForRuleGroup + "'" , e ) ; } } if ( ruleIssueType != null ) { rule . setLocQualityIssueType ( ITSIssueType . getIssueType ( ruleIssueType ) ) ; } else if ( ruleGroupIssueType != null ) { rule . setLocQualityIssueType ( ITSIssueType . getIssueType ( ruleGroupIssueType ) ) ; } else if ( categoryIssueType != null ) { rule . setLocQualityIssueType ( ITSIssueType . getIssueType ( categoryIssueType ) ) ; } } @ Override public void characters ( final char [ ] buf , final int offset , final int len ) { final String s = new String ( buf , offset , len ) ; if ( inException ) { exceptions . append ( s ) ; } else if ( inToken ) { elements . append ( s ) ; } else if ( inCorrectExample ) { correctExample . append ( s ) ; } else if ( inIncorrectExample ) { incorrectExample . append ( s ) ; } else if ( inMatch ) { match . append ( s ) ; } else if ( inMessage ) { message . append ( s ) ; } else if ( inSuggestion ) { suggestionsOutMsg . append ( s ) ; } else if ( inShortMessage ) { shortMessage . append ( s ) ; } else if ( inShortMessageForRuleGroup ) { shortMessageForRuleGroup . append ( s ) ; } else if ( inUrl ) { url . append ( s ) ; } else if ( inUrlForRuleGroup ) { urlForRuleGroup . append ( s ) ; } } }
package org . languagetool . rules . patterns ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import java . util . Locale ; import java . util . TreeSet ; import java . util . regex . Pattern ; import org . apache . commons . lang . StringUtils ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . patterns . Match . IncludeRange ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . tools . StringTools ; import static org . languagetool . JLanguageTool . PARAGRAPH_END_TAGNAME ; import static org . languagetool . JLanguageTool . SENTENCE_END_TAGNAME ; import static org . languagetool . JLanguageTool . SENTENCE_START_TAGNAME ; public class MatchState { private final Match match ; private final Synthesizer synthesizer ; private AnalyzedTokenReadings formattedToken ; private AnalyzedTokenReadings matchedToken ; private String skippedTokens ; public MatchState ( Match match , Synthesizer synthesizer ) { this . match = match ; this . synthesizer = synthesizer ; final String lemma = match . getLemma ( ) ; if ( ! StringUtils . isEmpty ( lemma ) ) { formattedToken = new AnalyzedTokenReadings ( new AnalyzedToken ( lemma , match . getPosTag ( ) , lemma ) , 0 ) ; } } public void setToken ( AnalyzedTokenReadings token ) { if ( match . isStaticLemma ( ) ) { this . matchedToken = token ; } else { this . formattedToken = token ; } } public final void setToken ( final AnalyzedTokenReadings [ ] tokens , final int index , final int next ) { int idx = index ; if ( index >= tokens . length ) { idx = tokens . length - 1 ; } setToken ( tokens [ idx ] ) ; IncludeRange includeSkipped = match . getIncludeSkipped ( ) ; if ( next > 1 && includeSkipped != IncludeRange . NONE ) { final StringBuilder sb = new StringBuilder ( ) ; if ( includeSkipped == IncludeRange . FOLLOWING ) { formattedToken = null ; } for ( int k = index + 1 ; k < index + next ; k ++ ) { if ( tokens [ k ] . isWhitespaceBefore ( ) && ! ( k == index + 1 && includeSkipped == IncludeRange . FOLLOWING ) ) { sb . append ( ' ' ) ; } sb . append ( tokens [ k ] . getToken ( ) ) ; } skippedTokens = sb . toString ( ) ; } else { skippedTokens = "" ; } } public final AnalyzedTokenReadings filterReadings ( ) { final List < AnalyzedToken > l = new ArrayList < > ( ) ; if ( formattedToken != null ) { if ( match . isStaticLemma ( ) ) { matchedToken . leaveReading ( new AnalyzedToken ( matchedToken . getToken ( ) , match . getPosTag ( ) , formattedToken . getToken ( ) ) ) ; formattedToken = matchedToken ; } String token = formattedToken . getToken ( ) ; Pattern regexMatch = match . getRegexMatch ( ) ; String regexReplace = match . getRegexReplace ( ) ; if ( regexMatch != null && regexReplace != null ) { token = regexMatch . matcher ( token ) . replaceAll ( regexReplace ) ; } token = convertCase ( token , token , null ) ; String posTag = match . getPosTag ( ) ; if ( posTag != null ) { final int numRead = formattedToken . getReadingsLength ( ) ; if ( match . isPostagRegexp ( ) ) { Pattern pPosRegexMatch = match . getPosRegexMatch ( ) ; String posTagReplace = match . getPosTagReplace ( ) ; String targetPosTag ; for ( int i = 0 ; i < numRead ; i ++ ) { final String testTag = formattedToken . getAnalyzedToken ( i ) . getPOSTag ( ) ; if ( testTag != null && pPosRegexMatch . matcher ( testTag ) . matches ( ) ) { targetPosTag = testTag ; if ( posTagReplace != null ) { targetPosTag = pPosRegexMatch . matcher ( targetPosTag ) . replaceAll ( posTagReplace ) ; } l . add ( new AnalyzedToken ( token , targetPosTag , formattedToken . getAnalyzedToken ( i ) . getLemma ( ) ) ) ; l . get ( l . size ( ) - 1 ) . setWhitespaceBefore ( formattedToken . isWhitespaceBefore ( ) ) ; } } if ( l . isEmpty ( ) ) { l . addAll ( getNewToken ( numRead , token ) ) ; } } else { l . addAll ( getNewToken ( numRead , token ) ) ; } String lemma = formattedToken . getAnalyzedToken ( 0 ) . getLemma ( ) ; if ( formattedToken . isSentenceEnd ( ) ) { l . add ( new AnalyzedToken ( formattedToken . getToken ( ) , SENTENCE_END_TAGNAME , lemma ) ) ; } if ( formattedToken . isParagraphEnd ( ) ) { l . add ( new AnalyzedToken ( formattedToken . getToken ( ) , PARAGRAPH_END_TAGNAME , lemma ) ) ; } } } if ( l . isEmpty ( ) ) { return formattedToken ; } final AnalyzedTokenReadings anTkRead = new AnalyzedTokenReadings ( l . toArray ( new AnalyzedToken [ l . size ( ) ] ) , formattedToken . getStartPos ( ) ) ; anTkRead . setWhitespaceBefore ( formattedToken . isWhitespaceBefore ( ) ) ; if ( ! formattedToken . getChunkTags ( ) . isEmpty ( ) ) { anTkRead . setChunkTags ( formattedToken . getChunkTags ( ) ) ; } if ( formattedToken . isImmunized ( ) ) { anTkRead . immunize ( ) ; } return anTkRead ; } String convertCase ( final String s , String sample , Language lang ) { if ( StringTools . isEmpty ( s ) ) { return s ; } String token = s ; switch ( match . getCaseConversionType ( ) ) { case NONE : break ; case PRESERVE : if ( StringTools . startsWithUppercase ( sample ) ) { if ( StringTools . isAllUppercase ( sample ) ) { token = token . toUpperCase ( Locale . ENGLISH ) ; } else { token = StringTools . uppercaseFirstChar ( token , lang ) ; } } break ; case STARTLOWER : token = token . substring ( 0 , 1 ) . toLowerCase ( ) + token . substring ( 1 ) ; break ; case STARTUPPER : token = StringTools . uppercaseFirstChar ( token , lang ) ; break ; case ALLUPPER : token = token . toUpperCase ( Locale . ENGLISH ) ; break ; case ALLLOWER : token = token . toLowerCase ( ) ; break ; default : break ; } return token ; } private List < AnalyzedToken > getNewToken ( final int numRead , final String token ) { String posTag = match . getPosTag ( ) ; final List < AnalyzedToken > list = new ArrayList < > ( ) ; String lemma = "" ; for ( int j = 0 ; j < numRead ; j ++ ) { String tempPosTag = formattedToken . getAnalyzedToken ( j ) . getPOSTag ( ) ; if ( tempPosTag != null ) { if ( tempPosTag . equals ( posTag ) && formattedToken . getAnalyzedToken ( j ) . getLemma ( ) != null ) { lemma = formattedToken . getAnalyzedToken ( j ) . getLemma ( ) ; } if ( StringTools . isEmpty ( lemma ) ) { lemma = formattedToken . getAnalyzedToken ( 0 ) . getLemma ( ) ; } list . add ( new AnalyzedToken ( token , posTag , lemma ) ) ; list . get ( list . size ( ) - 1 ) . setWhitespaceBefore ( formattedToken . isWhitespaceBefore ( ) ) ; } } return list ; } public final String [ ] toFinalString ( Language lang ) throws IOException { String [ ] formattedString = new String [ 1 ] ; if ( formattedToken != null ) { final int readingCount = formattedToken . getReadingsLength ( ) ; formattedString [ 0 ] = formattedToken . getToken ( ) ; Pattern pRegexMatch = match . getRegexMatch ( ) ; String regexReplace = match . getRegexReplace ( ) ; if ( pRegexMatch != null ) { formattedString [ 0 ] = pRegexMatch . matcher ( formattedString [ 0 ] ) . replaceAll ( regexReplace ) ; } String posTag = match . getPosTag ( ) ; if ( posTag != null ) { if ( synthesizer == null ) { formattedString [ 0 ] = formattedToken . getToken ( ) ; } else if ( match . isPostagRegexp ( ) ) { final TreeSet < String > wordForms = new TreeSet < > ( ) ; boolean oneForm = false ; for ( int k = 0 ; k < readingCount ; k ++ ) { if ( formattedToken . getAnalyzedToken ( k ) . getLemma ( ) == null ) { final String posUnique = formattedToken . getAnalyzedToken ( k ) . getPOSTag ( ) ; if ( posUnique == null ) { wordForms . add ( formattedToken . getToken ( ) ) ; oneForm = true ; } else { if ( SENTENCE_START_TAGNAME . equals ( posUnique ) || SENTENCE_END_TAGNAME . equals ( posUnique ) || PARAGRAPH_END_TAGNAME . equals ( posUnique ) ) { if ( ! oneForm ) { wordForms . add ( formattedToken . getToken ( ) ) ; } oneForm = true ; } else { oneForm = false ; } } } } final String targetPosTag = getTargetPosTag ( ) ; if ( ! oneForm ) { for ( int i = 0 ; i < readingCount ; i ++ ) { final String [ ] possibleWordForms = synthesizer . synthesize ( formattedToken . getAnalyzedToken ( i ) , targetPosTag , true ) ; if ( possibleWordForms != null ) { wordForms . addAll ( Arrays . asList ( possibleWordForms ) ) ; } } } if ( wordForms . isEmpty ( ) ) { if ( match . checksSpelling ( ) ) { formattedString [ 0 ] = "" ; } else { formattedString [ 0 ] = "(" + formattedToken . getToken ( ) + ")" ; } } else { formattedString = wordForms . toArray ( new String [ wordForms . size ( ) ] ) ; } } else { final TreeSet < String > wordForms = new TreeSet < > ( ) ; for ( int i = 0 ; i < readingCount ; i ++ ) { final String [ ] possibleWordForms = synthesizer . synthesize ( formattedToken . getAnalyzedToken ( i ) , posTag ) ; if ( possibleWordForms != null ) { wordForms . addAll ( Arrays . asList ( possibleWordForms ) ) ; } } formattedString = wordForms . toArray ( new String [ wordForms . size ( ) ] ) ; } } } final String original ; if ( match . isStaticLemma ( ) ) { original = matchedToken != null ? matchedToken . getToken ( ) : "" ; } else { original = formattedToken != null ? formattedToken . getToken ( ) : "" ; } for ( int i = 0 ; i < formattedString . length ; i ++ ) { formattedString [ i ] = convertCase ( formattedString [ i ] , original , lang ) ; } IncludeRange includeSkipped = match . getIncludeSkipped ( ) ; if ( includeSkipped != IncludeRange . NONE && skippedTokens != null && ! skippedTokens . isEmpty ( ) ) { final String [ ] helper = new String [ formattedString . length ] ; for ( int i = 0 ; i < formattedString . length ; i ++ ) { if ( formattedString [ i ] == null ) { formattedString [ i ] = "" ; } helper [ i ] = formattedString [ i ] + skippedTokens ; } formattedString = helper ; } if ( match . checksSpelling ( ) && lang != null ) { final List < String > formattedStringElements = Arrays . asList ( formattedString ) ; final List < AnalyzedTokenReadings > analyzed = lang . getTagger ( ) . tag ( formattedStringElements ) ; for ( int i = 0 ; i < formattedString . length ; i ++ ) { final AnalyzedToken analyzedToken = analyzed . get ( i ) . getAnalyzedToken ( 0 ) ; if ( analyzedToken . getLemma ( ) == null && analyzedToken . hasNoTag ( ) ) { formattedString [ i ] = "" ; } } } return formattedString ; } public final String getTargetPosTag ( ) { String targetPosTag = match . getPosTag ( ) ; final List < String > posTags = new ArrayList < > ( ) ; Pattern pPosRegexMatch = match . getPosRegexMatch ( ) ; String posTagReplace = match . getPosTagReplace ( ) ; if ( match . isStaticLemma ( ) ) { for ( AnalyzedToken analyzedToken : matchedToken ) { final String tst = analyzedToken . getPOSTag ( ) ; if ( tst != null && pPosRegexMatch . matcher ( tst ) . matches ( ) ) { targetPosTag = analyzedToken . getPOSTag ( ) ; posTags . add ( targetPosTag ) ; } } if ( pPosRegexMatch != null && posTagReplace != null ) { targetPosTag = pPosRegexMatch . matcher ( targetPosTag ) . replaceAll ( posTagReplace ) ; } } else { for ( AnalyzedToken analyzedToken : formattedToken ) { final String tst = analyzedToken . getPOSTag ( ) ; if ( tst != null && pPosRegexMatch . matcher ( tst ) . matches ( ) ) { targetPosTag = analyzedToken . getPOSTag ( ) ; posTags . add ( targetPosTag ) ; } } if ( pPosRegexMatch != null && posTagReplace != null ) { if ( posTags . isEmpty ( ) ) { posTags . add ( targetPosTag ) ; } final StringBuilder sb = new StringBuilder ( ) ; final int posTagLen = posTags . size ( ) ; int l = 0 ; for ( String lPosTag : posTags ) { l ++ ; lPosTag = pPosRegexMatch . matcher ( lPosTag ) . replaceAll ( posTagReplace ) ; if ( match . setsPos ( ) ) { lPosTag = synthesizer . getPosTagCorrection ( lPosTag ) ; } sb . append ( lPosTag ) ; if ( l < posTagLen ) { sb . append ( '|' ) ; } } targetPosTag = sb . toString ( ) ; } } return targetPosTag ; } public final String toTokenString ( ) throws IOException { final StringBuilder output = new StringBuilder ( ) ; final String [ ] stringToFormat = toFinalString ( null ) ; for ( int i = 0 ; i < stringToFormat . length ; i ++ ) { output . append ( stringToFormat [ i ] ) ; if ( i + 1 < stringToFormat . length ) { output . append ( '|' ) ; } } return output . toString ( ) ; } public Match getMatch ( ) { return match ; } }
package org . languagetool . rules . patterns ; import java . util . * ; import java . util . concurrent . ConcurrentHashMap ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; public class Unifier { private static final String UNIFY_IGNORE = "unify-ignore" ; private final List < AnalyzedTokenReadings > tokSequence ; private final List < List < Map < String , Set < String > > > > tokSequenceEquivalences ; private final Map < EquivalenceTypeLocator , PatternToken > equivalenceTypes ; private final Map < String , List < String > > equivalenceFeatures ; private final List < Map < String , Set < String > > > equivalencesMatched ; private boolean allFeatsIn ; private int tokCnt ; private int readingsCounter ; private List < Boolean > featuresFound ; private List < Boolean > tmpFeaturesFound ; private final Map < String , Set < String > > equivalencesToBeKept ; private Map < String , List < String > > unificationFeats ; private boolean inUnification ; private boolean uniMatched ; private boolean uniAllMatched ; public Unifier ( Map < EquivalenceTypeLocator , PatternToken > equivalenceTypes , Map < String , List < String > > equivalenceFeatures ) { tokCnt = 0 ; readingsCounter = 1 ; equivalencesMatched = new ArrayList < > ( ) ; this . equivalenceTypes = equivalenceTypes ; this . equivalenceFeatures = equivalenceFeatures ; equivalencesToBeKept = new ConcurrentHashMap < > ( ) ; featuresFound = new ArrayList < > ( ) ; tmpFeaturesFound = new ArrayList < > ( ) ; tokSequence = new ArrayList < > ( ) ; tokSequenceEquivalences = new ArrayList < > ( ) ; } protected final boolean isSatisfied ( final AnalyzedToken aToken , final Map < String , List < String > > uFeatures ) { if ( allFeatsIn && equivalencesMatched . isEmpty ( ) ) { return false ; } if ( uFeatures == null ) { throw new RuntimeException ( "isSatisfied called without features being set" ) ; } unificationFeats = uFeatures ; boolean unified = true ; if ( allFeatsIn ) { unified = checkNext ( aToken , uFeatures ) ; } else { while ( equivalencesMatched . size ( ) <= tokCnt ) { equivalencesMatched . add ( new ConcurrentHashMap < String , Set < String > > ( ) ) ; } for ( final Map . Entry < String , List < String > > feat : uFeatures . entrySet ( ) ) { List < String > types = feat . getValue ( ) ; if ( types == null || types . isEmpty ( ) ) { types = equivalenceFeatures . get ( feat . getKey ( ) ) ; } for ( final String typeName : types ) { final PatternToken testElem = equivalenceTypes . get ( new EquivalenceTypeLocator ( feat . getKey ( ) , typeName ) ) ; if ( testElem == null ) { return false ; } if ( testElem . isMatched ( aToken ) ) { if ( ! equivalencesMatched . get ( tokCnt ) . containsKey ( feat . getKey ( ) ) ) { final Set < String > typeSet = new HashSet < > ( ) ; typeSet . add ( typeName ) ; equivalencesMatched . get ( tokCnt ) . put ( feat . getKey ( ) , typeSet ) ; } else { equivalencesMatched . get ( tokCnt ) . get ( feat . getKey ( ) ) . add ( typeName ) ; } } } unified = equivalencesMatched . get ( tokCnt ) . containsKey ( feat . getKey ( ) ) ; if ( ! unified ) { equivalencesMatched . remove ( tokCnt ) ; break ; } } if ( unified ) { if ( tokCnt == 0 || tokSequence . isEmpty ( ) ) { tokSequence . add ( new AnalyzedTokenReadings ( aToken , 0 ) ) ; List < Map < String , Set < String > > > equivList = new ArrayList < > ( ) ; equivList . add ( equivalencesMatched . get ( tokCnt ) ) ; tokSequenceEquivalences . add ( equivList ) ; } else { tokSequence . get ( 0 ) . addReading ( aToken ) ; tokSequenceEquivalences . get ( 0 ) . add ( equivalencesMatched . get ( tokCnt ) ) ; } tokCnt ++ ; } } return unified ; } private boolean checkNext ( final AnalyzedToken aToken , final Map < String , List < String > > uFeatures ) { boolean anyFeatUnified = false ; final List < Boolean > tokenFeaturesFound = new ArrayList < > ( tmpFeaturesFound ) ; final Map < String , Set < String > > equivalencesMatchedHere = new ConcurrentHashMap < > ( ) ; if ( allFeatsIn ) { for ( int i = 0 ; i < tokCnt ; i ++ ) { boolean allFeatsUnified = true ; for ( Map . Entry < String , List < String > > feat : uFeatures . entrySet ( ) ) { boolean featUnified = false ; List < String > types = feat . getValue ( ) ; if ( types == null || types . isEmpty ( ) ) { types = equivalenceFeatures . get ( feat . getKey ( ) ) ; } for ( final String typeName : types ) { if ( equivalencesMatched . get ( i ) . containsKey ( feat . getKey ( ) ) && equivalencesMatched . get ( i ) . get ( feat . getKey ( ) ) . contains ( typeName ) ) { final PatternToken testElem = equivalenceTypes . get ( new EquivalenceTypeLocator ( feat . getKey ( ) , typeName ) ) ; boolean matched = testElem . isMatched ( aToken ) ; featUnified = featUnified || matched ; if ( matched ) { if ( ! equivalencesToBeKept . containsKey ( feat . getKey ( ) ) ) { final Set < String > typeSet = new HashSet < > ( ) ; typeSet . add ( typeName ) ; equivalencesToBeKept . put ( feat . getKey ( ) , typeSet ) ; } else { equivalencesToBeKept . get ( feat . getKey ( ) ) . add ( typeName ) ; } if ( ! equivalencesMatchedHere . containsKey ( feat . getKey ( ) ) ) { final Set < String > typeSet = new HashSet < > ( ) ; typeSet . add ( typeName ) ; equivalencesMatchedHere . put ( feat . getKey ( ) , typeSet ) ; } else { equivalencesMatchedHere . get ( feat . getKey ( ) ) . add ( typeName ) ; } } } } allFeatsUnified &= featUnified ; } tokenFeaturesFound . set ( i , tokenFeaturesFound . get ( i ) || allFeatsUnified ) ; anyFeatUnified = anyFeatUnified || allFeatsUnified ; } if ( anyFeatUnified ) { if ( tokSequence . size ( ) == readingsCounter ) { tokSequence . add ( new AnalyzedTokenReadings ( aToken , 0 ) ) ; List < Map < String , Set < String > > > equivList = new ArrayList < > ( ) ; equivList . add ( equivalencesMatchedHere ) ; tokSequenceEquivalences . add ( equivList ) ; } else { if ( readingsCounter < tokSequence . size ( ) ) { tokSequence . get ( readingsCounter ) . addReading ( aToken ) ; tokSequenceEquivalences . get ( readingsCounter ) . add ( equivalencesMatchedHere ) ; } else { anyFeatUnified = false ; } } tmpFeaturesFound = tokenFeaturesFound ; } } return anyFeatUnified ; } public final void startNextToken ( ) { featuresFound = new ArrayList < > ( tmpFeaturesFound ) ; readingsCounter ++ ; for ( int j = 0 ; j < tokSequence . size ( ) ; j ++ ) { for ( int i = 0 ; i < tokSequenceEquivalences . get ( j ) . size ( ) ; i ++ ) { for ( Map . Entry < String , List < String > > feat : equivalenceFeatures . entrySet ( ) ) { if ( ! UNIFY_IGNORE . equals ( feat . getKey ( ) ) ) { if ( tokSequenceEquivalences . get ( j ) . get ( i ) . containsKey ( feat . getKey ( ) ) ) { if ( equivalencesToBeKept . containsKey ( feat . getKey ( ) ) ) { tokSequenceEquivalences . get ( j ) . get ( i ) . get ( feat . getKey ( ) ) . retainAll ( equivalencesToBeKept . get ( feat . getKey ( ) ) ) ; } else { tokSequenceEquivalences . get ( j ) . get ( i ) . remove ( feat . getKey ( ) ) ; } } else { tokSequenceEquivalences . get ( j ) . get ( i ) . remove ( feat . getKey ( ) ) ; } } } } } equivalencesToBeKept . clear ( ) ; } public final void startUnify ( ) { allFeatsIn = true ; for ( int i = 0 ; i < tokCnt ; i ++ ) { featuresFound . add ( false ) ; } tmpFeaturesFound = new ArrayList < > ( featuresFound ) ; } public final boolean getFinalUnificationValue ( final Map < String , List < String > > uFeatures ) { int tokUnified = 0 ; for ( int j = 0 ; j < tokSequence . size ( ) ; j ++ ) { boolean unifiedTokensFound = false ; for ( int i = 0 ; i < tokSequenceEquivalences . get ( j ) . size ( ) ; i ++ ) { int featUnified = 0 ; if ( tokSequenceEquivalences . get ( j ) . get ( i ) . containsKey ( UNIFY_IGNORE ) ) { if ( i == 0 ) { tokUnified ++ ; } unifiedTokensFound = true ; continue ; } else { for ( final Map . Entry < String , List < String > > feat : uFeatures . entrySet ( ) ) { if ( tokSequenceEquivalences . get ( j ) . get ( i ) . containsKey ( feat . getKey ( ) ) && tokSequenceEquivalences . get ( j ) . get ( i ) . get ( feat . getKey ( ) ) . isEmpty ( ) ) { featUnified = 0 ; } else { featUnified ++ ; } if ( featUnified == unificationFeats . entrySet ( ) . size ( ) && tokUnified <= j ) { tokUnified ++ ; unifiedTokensFound = true ; break ; } } } } if ( ! unifiedTokensFound ) return false ; } if ( tokUnified == tokSequence . size ( ) ) { return true ; } return false ; } public final void reset ( ) { equivalencesMatched . clear ( ) ; allFeatsIn = false ; tokCnt = 0 ; featuresFound . clear ( ) ; tmpFeaturesFound . clear ( ) ; tokSequence . clear ( ) ; tokSequenceEquivalences . clear ( ) ; readingsCounter = 1 ; uniMatched = false ; uniAllMatched = false ; inUnification = false ; } @ Nullable public final AnalyzedTokenReadings [ ] getUnifiedTokens ( ) { if ( tokSequence . isEmpty ( ) ) { return null ; } List < AnalyzedTokenReadings > uTokens = new ArrayList < > ( ) ; for ( int j = 0 ; j < tokSequence . size ( ) ; j ++ ) { boolean unifiedTokensFound = false ; for ( int i = 0 ; i < tokSequenceEquivalences . get ( j ) . size ( ) ; i ++ ) { int featUnified = 0 ; if ( tokSequenceEquivalences . get ( j ) . get ( i ) . containsKey ( UNIFY_IGNORE ) ) { addTokenToSequence ( uTokens , tokSequence . get ( j ) . getAnalyzedToken ( i ) , j ) ; unifiedTokensFound = true ; } else { for ( final Map . Entry < String , List < String > > feat : unificationFeats . entrySet ( ) ) { if ( tokSequenceEquivalences . get ( j ) . get ( i ) . containsKey ( feat . getKey ( ) ) && tokSequenceEquivalences . get ( j ) . get ( i ) . get ( feat . getKey ( ) ) . isEmpty ( ) ) { featUnified = 0 ; } else { featUnified ++ ; } if ( featUnified == unificationFeats . entrySet ( ) . size ( ) ) { addTokenToSequence ( uTokens , tokSequence . get ( j ) . getAnalyzedToken ( i ) , j ) ; unifiedTokensFound = true ; } } } } if ( ! unifiedTokensFound ) { return null ; } } return uTokens . toArray ( new AnalyzedTokenReadings [ uTokens . size ( ) ] ) ; } private void addTokenToSequence ( List < AnalyzedTokenReadings > tokenSequence , AnalyzedToken token , int pos ) { if ( tokenSequence . size ( ) <= pos || tokenSequence . isEmpty ( ) ) { AnalyzedTokenReadings tmpATR = new AnalyzedTokenReadings ( token , 0 ) ; tokenSequence . add ( tmpATR ) ; } else { tokenSequence . get ( pos ) . addReading ( token ) ; } } public final boolean isUnified ( final AnalyzedToken matchToken , final Map < String , List < String > > uFeatures , final boolean lastReading , final boolean isMatched ) { if ( inUnification ) { if ( isMatched ) { uniMatched |= isSatisfied ( matchToken , uFeatures ) ; } uniAllMatched = uniMatched ; if ( lastReading ) { startNextToken ( ) ; uniMatched = false ; } return uniAllMatched && getFinalUnificationValue ( uFeatures ) ; } else { if ( isMatched ) { isSatisfied ( matchToken , uFeatures ) ; } } if ( lastReading ) { inUnification = true ; uniMatched = false ; startUnify ( ) ; } return true ; } public final boolean isUnified ( final AnalyzedToken matchToken , final Map < String , List < String > > uFeatures , final boolean lastReading ) { return this . isUnified ( matchToken , uFeatures , lastReading , true ) ; } public final void addNeutralElement ( final AnalyzedTokenReadings analyzedTokenReadings ) { tokSequence . add ( analyzedTokenReadings ) ; List < Map < String , Set < String > > > tokEquivs = new ArrayList < > ( analyzedTokenReadings . getReadingsLength ( ) ) ; Map < String , Set < String > > dummy = new ConcurrentHashMap < > ( ) ; Set < String > dummySet = new HashSet < > ( ) ; dummy . put ( UNIFY_IGNORE , dummySet ) ; for ( int i = 0 ; i < analyzedTokenReadings . getReadingsLength ( ) ; i ++ ) { tokEquivs . add ( dummy ) ; } tokSequenceEquivalences . add ( tokEquivs ) ; readingsCounter ++ ; } @ Nullable public final AnalyzedTokenReadings [ ] getFinalUnified ( ) { if ( inUnification ) { return getUnifiedTokens ( ) ; } return null ; } }
package org . languagetool . rules . patterns ; import java . io . InputStream ; import java . io . StringWriter ; import java . util . List ; import javax . xml . transform . OutputKeys ; import javax . xml . transform . Transformer ; import javax . xml . transform . TransformerException ; import javax . xml . transform . TransformerFactory ; import javax . xml . transform . dom . DOMSource ; import javax . xml . transform . stream . StreamResult ; import javax . xml . xpath . XPath ; import javax . xml . xpath . XPathConstants ; import javax . xml . xpath . XPathFactory ; import org . languagetool . Language ; import org . w3c . dom . Document ; import org . w3c . dom . Node ; import org . w3c . dom . NodeList ; import org . w3c . dom . bootstrap . DOMImplementationRegistry ; import org . w3c . dom . ls . DOMImplementationLS ; import org . w3c . dom . ls . LSInput ; import org . w3c . dom . ls . LSParser ; public class PatternRuleXmlCreator { public final String toXML ( PatternRuleId ruleId , Language language ) { final List < String > filenames = language . getRuleFileNames ( ) ; final XPath xpath = XPathFactory . newInstance ( ) . newXPath ( ) ; for ( String filename : filenames ) { try ( InputStream is = this . getClass ( ) . getResourceAsStream ( filename ) ) { final Document doc = getDocument ( is ) ; final Node ruleNode = ( Node ) xpath . evaluate ( "/rules/category/rule[@id='" + ruleId . getId ( ) + "']" , doc , XPathConstants . NODE ) ; if ( ruleNode != null ) { return nodeToString ( ruleNode ) ; } final Node ruleNodeInGroup = ( Node ) xpath . evaluate ( "/rules/category/rulegroup/rule[@id='" + ruleId . getId ( ) + "']" , doc , XPathConstants . NODE ) ; if ( ruleNodeInGroup != null ) { return nodeToString ( ruleNodeInGroup ) ; } if ( ruleId . getSubId ( ) != null ) { final NodeList ruleGroupNodes = ( NodeList ) xpath . evaluate ( "/rules/category/rulegroup[@id='" + ruleId . getId ( ) + "']/rule" , doc , XPathConstants . NODESET ) ; if ( ruleGroupNodes != null ) { for ( int i = 0 ; i < ruleGroupNodes . getLength ( ) ; i ++ ) { if ( Integer . toString ( i + 1 ) . equals ( ruleId . getSubId ( ) ) ) { return nodeToString ( ruleGroupNodes . item ( i ) ) ; } } } } else { final Node ruleGroupNode = ( Node ) xpath . evaluate ( "/rules/category/rulegroup[@id='" + ruleId . getId ( ) + "']" , doc , XPathConstants . NODE ) ; if ( ruleGroupNode != null ) { return nodeToString ( ruleGroupNode ) ; } } } catch ( Exception e ) { throw new RuntimeException ( "Could not turn rule '" + ruleId + "' for language " + language + " into a string" , e ) ; } } throw new RuntimeException ( "Could not find rule '" + ruleId + "' for language " + language + " in files: " + filenames ) ; } private Document getDocument ( InputStream is ) throws InstantiationException , IllegalAccessException , ClassNotFoundException { final DOMImplementationRegistry registry = DOMImplementationRegistry . newInstance ( ) ; final DOMImplementationLS impl = ( DOMImplementationLS ) registry . getDOMImplementation ( "LS" ) ; final LSParser parser = impl . createLSParser ( DOMImplementationLS . MODE_SYNCHRONOUS , null ) ; parser . setFilter ( new IgnoreWhitespaceFilter ( ) ) ; LSInput domInput = impl . createLSInput ( ) ; domInput . setByteStream ( is ) ; return parser . parse ( domInput ) ; } private String nodeToString ( Node node ) { final StringWriter sw = new StringWriter ( ) ; try { final Transformer t = TransformerFactory . newInstance ( ) . newTransformer ( ) ; t . setOutputProperty ( OutputKeys . OMIT_XML_DECLARATION , "yes" ) ; t . transform ( new DOMSource ( node ) , new StreamResult ( sw ) ) ; } catch ( TransformerException e ) { throw new RuntimeException ( e ) ; } final String xml = sw . toString ( ) . replace ( "<token" , "\n <token" ) . replace ( "<and" , "\n <and" ) . replace ( "</and>" , "\n </and>" ) . replace ( "<phraseref" , "\n <phraseref" ) . replace ( "<antipattern" , "\n <antipattern" ) . replace ( "<pattern" , "\n <pattern" ) . replace ( "</pattern" , "\n </pattern" ) . replace ( "</antipattern" , "\n </antipattern" ) . replace ( "</rule>" , "\n</rule>" ) . replace ( "<filter" , "\n <filter" ) . replace ( "<message" , "\n <message" ) . replace ( "<short" , "\n <short" ) . replace ( "<url" , "\n <url" ) . replace ( "<example" , "\n <example" ) . replace ( "</suggestion><suggestion>" , "</suggestion>\n <suggestion>" ) . replace ( "</message><suggestion>" , "</message>\n <suggestion>" ) ; return xml ; } }
package org . languagetool . rules . patterns ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . io . InputStream ; import java . util . List ; import javax . xml . parsers . SAXParser ; import javax . xml . parsers . SAXParserFactory ; import org . languagetool . tools . Tools ; import org . xml . sax . helpers . DefaultHandler ; public class PatternRuleLoader extends DefaultHandler { private boolean relaxedMode = false ; public final List < PatternRule > getRules ( final File file ) throws IOException { try ( InputStream inputStream = new FileInputStream ( file ) ) { final PatternRuleLoader ruleLoader = new PatternRuleLoader ( ) ; return ruleLoader . getRules ( inputStream , file . getAbsolutePath ( ) ) ; } } public void setRelaxedMode ( boolean relaxedMode ) { this . relaxedMode = relaxedMode ; } public final List < PatternRule > getRules ( final InputStream is , final String filename ) throws IOException { try { final PatternRuleHandler handler = new PatternRuleHandler ( ) ; handler . setRelaxedMode ( relaxedMode ) ; final SAXParserFactory factory = SAXParserFactory . newInstance ( ) ; final SAXParser saxParser = factory . newSAXParser ( ) ; Tools . setPasswordAuthenticator ( ) ; saxParser . getXMLReader ( ) . setFeature ( "http://apache.org/xml/features/nonvalidating/load-external-dtd" , false ) ; saxParser . parse ( is , handler ) ; return handler . getRules ( ) ; } catch ( final Exception e ) { throw new IOException ( "Cannot load or parse input stream of '" + filename + "'" , e ) ; } } }
package org . languagetool . rules . nl ; import java . util . ResourceBundle ; import org . languagetool . rules . WrongWordInContextRule ; public class DutchWrongWordInContextRule extends WrongWordInContextRule { public DutchWrongWordInContextRule ( final ResourceBundle messages ) { super ( messages ) ; } @ Override protected String getCategoryString ( ) { return "Gemakkelijk te verwarren woorden" ; } @ Override public String getId ( ) { return "DUTCH_WRONG_WORD_IN_CONTEXT" ; } @ Override public String getDescription ( ) { return "Woordverwarring" ; } @ Override protected String getFilename ( ) { return "/nl/wrongWordInContext.txt" ; } @ Override protected String getMessageString ( ) { return "Mogelijk verwarring: Bedoelde u <suggestion>$SUGGESTION</suggestion> i.p.v. '$WRONGWORD'?" ; } @ Override protected String getShortMessageString ( ) { return "Mogelijk woorden verward" ; } @ Override protected String getLongMessageString ( ) { return "Mogelijk verwarring: Bedoelde u <suggestion>$SUGGESTION</suggestion> (= $EXPLANATION_SUGGESTION) i.p.v. '$WRONGWORD' (= $EXPLANATION_WRONGWORD)?" ; } }
package org . languagetool . rules . patterns ; import java . io . IOException ; import java . util . * ; import org . languagetool . AnalyzedSentence ; import org . languagetool . Language ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tagging . disambiguation . rules . DisambiguationPatternRule ; import org . languagetool . tools . StringTools ; public class PatternRule extends AbstractPatternRule { private final String shortMessage ; private final List < Integer > elementNo ; private final Set < String > simpleRuleTokens ; private final Set < String > inflectedRuleTokens ; private final List < DisambiguationPatternRule > antiPatterns = new ArrayList < > ( ) ; private final boolean useList ; private RuleFilter filter ; private String filterArgs ; private String message ; private String suggestionsOutMsg ; private List < Match > suggestionMatches ; private List < Match > suggestionMatchesOutMsg ; private Set < String > tokenSet ; private Set < String > lemmaSet ; private boolean isMemberOfDisjunctiveSet ; public PatternRule ( final String id , final Language language , final List < PatternToken > patternTokens , final String description , final String message , final String shortMessage ) { super ( id , description , language , patternTokens , false ) ; this . message = message ; this . shortMessage = shortMessage ; this . elementNo = new ArrayList < > ( ) ; this . suggestionsOutMsg = "" ; String prevName = "" ; String curName ; int cnt = 0 ; int loopCnt = 0 ; boolean tempUseList = false ; for ( final PatternToken pToken : this . patternTokens ) { if ( pToken . isPartOfPhrase ( ) ) { curName = pToken . getPhraseName ( ) ; if ( StringTools . isEmpty ( prevName ) || prevName . equals ( curName ) ) { cnt ++ ; tempUseList = true ; } else { elementNo . add ( cnt ) ; curName = "" ; cnt = 0 ; } prevName = curName ; loopCnt ++ ; if ( loopCnt == this . patternTokens . size ( ) && ! StringTools . isEmpty ( prevName ) ) { elementNo . add ( cnt ) ; } } else { if ( cnt > 0 ) { elementNo . add ( cnt ) ; } elementNo . add ( 1 ) ; loopCnt ++ ; } } useList = tempUseList ; simpleRuleTokens = getSimpleTokens ( ) ; inflectedRuleTokens = getInflectedTokens ( ) ; } public PatternRule ( final String id , final Language language , final List < PatternToken > patternTokens , final String description , final String message , final String shortMessage , final String suggestionsOutMsg ) { this ( id , language , patternTokens , description , message , shortMessage ) ; this . suggestionsOutMsg = suggestionsOutMsg ; } public PatternRule ( final String id , final Language language , final List < PatternToken > patternTokens , final String description , final String message , final String shortMessage , final String suggestionsOutMsg , final boolean isMember ) { this ( id , language , patternTokens , description , message , shortMessage , suggestionsOutMsg ) ; this . isMemberOfDisjunctiveSet = isMember ; } public final String getMessage ( ) { return message ; } public final void setMessage ( final String message ) { this . message = message ; } public final String getSuggestionsOutMsg ( ) { return suggestionsOutMsg ; } final boolean isWithComplexPhrase ( ) { return isMemberOfDisjunctiveSet ; } final void notComplexPhrase ( ) { isMemberOfDisjunctiveSet = false ; } public final String toPatternString ( ) { final List < String > strList = new ArrayList < > ( ) ; for ( PatternToken patternPatternToken : patternTokens ) { strList . add ( patternPatternToken . toString ( ) ) ; } return StringTools . listToString ( strList , ", " ) ; } public final String toXML ( ) { return new PatternRuleXmlCreator ( ) . toXML ( new PatternRuleId ( getId ( ) , getSubId ( ) ) , getLanguage ( ) ) ; } @ Override public final RuleMatch [ ] match ( final AnalyzedSentence sentence ) throws IOException { try { final PatternRuleMatcher matcher = new PatternRuleMatcher ( this , useList ) ; return matcher . match ( getSentenceWithImmunization ( sentence ) ) ; } catch ( IOException e ) { throw new IOException ( "Error analyzing sentence: '" + sentence + "'" , e ) ; } catch ( Exception e ) { throw new RuntimeException ( "Error analyzing sentence: '" + sentence + "'" , e ) ; } } public final void addSuggestionMatch ( final Match m ) { if ( suggestionMatches == null ) { suggestionMatches = new ArrayList < > ( ) ; } suggestionMatches . add ( m ) ; } public final void addSuggestionMatchOutMsg ( final Match m ) { if ( suggestionMatchesOutMsg == null ) { suggestionMatchesOutMsg = new ArrayList < > ( ) ; } suggestionMatchesOutMsg . add ( m ) ; } final List < DisambiguationPatternRule > getAntiPatterns ( ) { return antiPatterns ; } public boolean canBeIgnoredFor ( AnalyzedSentence sentence ) { return ( ! simpleRuleTokens . isEmpty ( ) && ! sentence . getTokenSet ( ) . containsAll ( simpleRuleTokens ) ) || ( ! inflectedRuleTokens . isEmpty ( ) && ! sentence . getLemmaSet ( ) . containsAll ( inflectedRuleTokens ) ) ; } private synchronized Set < String > getSimpleTokens ( ) { if ( tokenSet == null ) { tokenSet = new HashSet < > ( ) ; for ( PatternToken patternToken : patternTokens ) { if ( ! patternToken . getNegation ( ) && ! patternToken . isRegularExpression ( ) && ! patternToken . isReferenceElement ( ) && ! patternToken . isInflected ( ) && patternToken . getMinOccurrence ( ) > 0 ) { String str = patternToken . getString ( ) ; if ( ! StringTools . isEmpty ( str ) ) { tokenSet . add ( str . toLowerCase ( ) ) ; } } } } return tokenSet ; } private synchronized Set < String > getInflectedTokens ( ) { if ( lemmaSet == null ) { lemmaSet = new HashSet < > ( ) ; for ( PatternToken patternToken : patternTokens ) { if ( ! patternToken . getNegation ( ) && ! patternToken . isRegularExpression ( ) && ! patternToken . isReferenceElement ( ) && patternToken . isInflected ( ) && patternToken . getMinOccurrence ( ) > 0 ) { String str = patternToken . getString ( ) ; if ( ! StringTools . isEmpty ( str ) ) { lemmaSet . add ( str . toLowerCase ( ) ) ; } } } } return lemmaSet ; } List < Integer > getElementNo ( ) { return elementNo ; } String getShortMessage ( ) { return shortMessage ; } List < Match > getSuggestionMatches ( ) { return suggestionMatches ; } List < Match > getSuggestionMatchesOutMsg ( ) { return suggestionMatchesOutMsg ; } void setFilter ( RuleFilter filter ) { this . filter = filter ; } RuleFilter getFilter ( ) { return filter ; } void setFilterArguments ( String filterArgs ) { this . filterArgs = filterArgs ; } String getFilterArguments ( ) { return filterArgs ; } public void setAntiPatterns ( List < DisambiguationPatternRule > antiPatterns ) { this . antiPatterns . addAll ( antiPatterns ) ; } private AnalyzedSentence getSentenceWithImmunization ( AnalyzedSentence sentence ) throws IOException { if ( antiPatterns != null && ! antiPatterns . isEmpty ( ) ) { AnalyzedSentence immunizedSentence = sentence . copy ( sentence ) ; for ( final DisambiguationPatternRule patternRule : antiPatterns ) { immunizedSentence = patternRule . replace ( immunizedSentence ) ; } return immunizedSentence ; } return sentence ; } }
package org . languagetool . rules . patterns ; import java . util . Collections ; import java . util . List ; import java . util . Map ; import java . util . concurrent . ConcurrentHashMap ; import java . util . concurrent . CopyOnWriteArrayList ; public class UnifierConfiguration { private final Map < EquivalenceTypeLocator , PatternToken > equivalenceTypes ; private final Map < String , List < String > > equivalenceFeatures ; public UnifierConfiguration ( ) { equivalenceTypes = new ConcurrentHashMap < > ( ) ; equivalenceFeatures = new ConcurrentHashMap < > ( ) ; } public final void setEquivalence ( final String feature , final String type , final PatternToken elem ) { EquivalenceTypeLocator typeKey = new EquivalenceTypeLocator ( feature , type ) ; if ( equivalenceTypes . containsKey ( typeKey ) ) { return ; } equivalenceTypes . put ( typeKey , elem ) ; final List < String > lTypes ; if ( equivalenceFeatures . containsKey ( feature ) ) { lTypes = equivalenceFeatures . get ( feature ) ; } else { lTypes = new CopyOnWriteArrayList < > ( ) ; equivalenceFeatures . put ( feature , lTypes ) ; } lTypes . add ( type ) ; } public Map < EquivalenceTypeLocator , PatternToken > getEquivalenceTypes ( ) { return Collections . unmodifiableMap ( equivalenceTypes ) ; } public Map < String , List < String > > getEquivalenceFeatures ( ) { return Collections . unmodifiableMap ( equivalenceFeatures ) ; } public Unifier createUnifier ( ) { return new Unifier ( getEquivalenceTypes ( ) , getEquivalenceFeatures ( ) ) ; } }
package org . languagetool . rules . patterns ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . RuleMatchFilter ; import org . languagetool . rules . RuleWithMaxFilter ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; final class PatternRuleMatcher extends AbstractPatternRulePerformer { private static final String SUGGESTION_START_TAG = "<suggestion>" ; private static final String SUGGESTION_END_TAG = "</suggestion>" ; private static final String MISTAKE = "<mistake/>" ; private final boolean useList ; private final List < PatternTokenMatcher > patternTokenMatchers ; PatternRuleMatcher ( PatternRule rule , boolean useList ) { super ( rule , rule . getLanguage ( ) . getUnifier ( ) ) ; this . useList = useList ; this . patternTokenMatchers = createElementMatchers ( ) ; } RuleMatch [ ] match ( final AnalyzedSentence sentence ) throws IOException { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; final List < Integer > tokenPositions = new ArrayList < > ( tokens . length + 1 ) ; final int patternSize = patternTokenMatchers . size ( ) ; final int limit = Math . max ( 0 , tokens . length - patternSize + 1 ) ; PatternTokenMatcher pTokenMatcher = null ; int i = 0 ; int minOccurCorrection = getMinOccurrenceCorrection ( ) ; while ( i < limit + minOccurCorrection && ! ( rule . isSentStart ( ) && i > 0 ) ) { int skipShiftTotal = 0 ; boolean allElementsMatch = false ; int firstMatchToken = - 1 ; int lastMatchToken = - 1 ; int firstMarkerMatchToken = - 1 ; int lastMarkerMatchToken = - 1 ; int prevSkipNext = 0 ; if ( rule . isTestUnification ( ) ) { unifier . reset ( ) ; } tokenPositions . clear ( ) ; int minOccurSkip = 0 ; for ( int k = 0 ; k < patternSize ; k ++ ) { final PatternTokenMatcher prevTokenMatcher = pTokenMatcher ; pTokenMatcher = patternTokenMatchers . get ( k ) ; pTokenMatcher . resolveReference ( firstMatchToken , tokens , rule . getLanguage ( ) ) ; final int nextPos = i + k + skipShiftTotal - minOccurSkip ; prevMatched = false ; if ( prevSkipNext + nextPos >= tokens . length || prevSkipNext < 0 ) { prevSkipNext = tokens . length - ( nextPos + 1 ) ; } final int maxTok = Math . min ( nextPos + prevSkipNext , tokens . length - ( patternSize - k ) + minOccurCorrection ) ; for ( int m = nextPos ; m <= maxTok ; m ++ ) { allElementsMatch = ! tokens [ m ] . isImmunized ( ) && testAllReadings ( tokens , pTokenMatcher , prevTokenMatcher , m , firstMatchToken , prevSkipNext ) ; if ( pTokenMatcher . getPatternToken ( ) . getMinOccurrence ( ) == 0 ) { boolean foundNext = false ; for ( int k2 = k + 1 ; k2 < patternSize ; k2 ++ ) { final PatternTokenMatcher nextElement = patternTokenMatchers . get ( k2 ) ; final boolean nextElementMatch = ! tokens [ m ] . isImmunized ( ) && testAllReadings ( tokens , nextElement , pTokenMatcher , m , firstMatchToken , prevSkipNext ) ; if ( nextElementMatch ) { allElementsMatch = true ; minOccurSkip ++ ; tokenPositions . add ( 0 ) ; foundNext = true ; break ; } else if ( nextElement . getPatternToken ( ) . getMinOccurrence ( ) > 0 ) { break ; } } if ( foundNext ) { break ; } } if ( allElementsMatch ) { int skipForMax = skipMaxTokens ( tokens , pTokenMatcher , firstMatchToken , prevSkipNext , prevTokenMatcher , m , patternSize - k - 1 ) ; lastMatchToken = m + skipForMax ; final int skipShift = lastMatchToken - nextPos ; tokenPositions . add ( skipShift + 1 ) ; prevSkipNext = translateElementNo ( pTokenMatcher . getPatternToken ( ) . getSkipNext ( ) ) ; skipShiftTotal += skipShift ; if ( firstMatchToken == - 1 ) { firstMatchToken = lastMatchToken - skipForMax ; } if ( firstMarkerMatchToken == - 1 && pTokenMatcher . getPatternToken ( ) . isInsideMarker ( ) ) { firstMarkerMatchToken = lastMatchToken - skipForMax ; } if ( pTokenMatcher . getPatternToken ( ) . isInsideMarker ( ) ) { lastMarkerMatchToken = lastMatchToken ; } break ; } } if ( ! allElementsMatch ) { break ; } } if ( allElementsMatch && tokenPositions . size ( ) == patternSize ) { final RuleMatch ruleMatch = createRuleMatch ( tokenPositions , tokens , firstMatchToken , lastMatchToken , firstMarkerMatchToken , lastMarkerMatchToken ) ; if ( ruleMatch != null ) { ruleMatches . add ( ruleMatch ) ; } } i ++ ; } RuleMatchFilter maxFilter = new RuleWithMaxFilter ( ) ; List < RuleMatch > filteredMatches = maxFilter . filter ( ruleMatches ) ; return filteredMatches . toArray ( new RuleMatch [ filteredMatches . size ( ) ] ) ; } @ Nullable private RuleMatch createRuleMatch ( final List < Integer > tokenPositions , final AnalyzedTokenReadings [ ] tokens , final int firstMatchToken , final int lastMatchToken , int firstMarkerMatchToken , int lastMarkerMatchToken ) throws IOException { final PatternRule rule = ( PatternRule ) this . rule ; final String errMessage = formatMatches ( tokens , tokenPositions , firstMatchToken , rule . getMessage ( ) , rule . getSuggestionMatches ( ) ) ; final String shortErrMessage = formatMatches ( tokens , tokenPositions , firstMatchToken , rule . getShortMessage ( ) , rule . getSuggestionMatches ( ) ) ; final String suggestionsOutMsg = formatMatches ( tokens , tokenPositions , firstMatchToken , rule . getSuggestionsOutMsg ( ) , rule . getSuggestionMatchesOutMsg ( ) ) ; int correctedStPos = 0 ; if ( rule . startPositionCorrection > 0 ) { for ( int l = 0 ; l <= Math . min ( rule . startPositionCorrection , tokenPositions . size ( ) - 1 ) ; l ++ ) { correctedStPos += tokenPositions . get ( l ) ; } correctedStPos -- ; } int idx = firstMatchToken + correctedStPos ; if ( idx >= tokens . length ) { idx = tokens . length - 1 ; } AnalyzedTokenReadings firstMatchTokenObj = tokens [ idx ] ; boolean startsWithUppercase = StringTools . startsWithUppercase ( firstMatchTokenObj . getToken ( ) ) && matchPreservesCase ( rule . getSuggestionMatches ( ) , rule . getMessage ( ) ) && matchPreservesCase ( rule . getSuggestionMatchesOutMsg ( ) , rule . getSuggestionsOutMsg ( ) ) ; if ( firstMatchTokenObj . isSentenceStart ( ) && tokens . length > firstMatchToken + correctedStPos + 1 ) { firstMatchTokenObj = tokens [ firstMatchToken + correctedStPos + 1 ] ; startsWithUppercase = StringTools . startsWithUppercase ( firstMatchTokenObj . getToken ( ) ) ; } if ( firstMarkerMatchToken == - 1 ) { firstMarkerMatchToken = firstMatchToken ; } int fromPos = tokens [ firstMarkerMatchToken ] . getStartPos ( ) ; if ( errMessage . contains ( SUGGESTION_START_TAG + "," ) && firstMarkerMatchToken >= 1 ) { fromPos = tokens [ firstMarkerMatchToken - 1 ] . getStartPos ( ) + tokens [ firstMarkerMatchToken - 1 ] . getToken ( ) . length ( ) ; } if ( lastMarkerMatchToken == - 1 ) { lastMarkerMatchToken = lastMatchToken ; } final AnalyzedTokenReadings token = tokens [ Math . min ( lastMarkerMatchToken , tokens . length - 1 ) ] ; int toPos = token . getEndPos ( ) ; if ( fromPos < toPos ) { if ( ! ( errMessage . contains ( PatternRuleHandler . PLEASE_SPELL_ME ) && errMessage . contains ( MISTAKE ) ) ) { final String clearMsg = errMessage . replaceAll ( PatternRuleHandler . PLEASE_SPELL_ME , "" ) . replaceAll ( MISTAKE , "" ) ; final RuleMatch ruleMatch = new RuleMatch ( rule , fromPos , toPos , clearMsg , shortErrMessage , startsWithUppercase , suggestionsOutMsg ) ; if ( rule . getFilter ( ) != null ) { RuleFilterEvaluator evaluator = new RuleFilterEvaluator ( rule . getFilter ( ) ) ; AnalyzedTokenReadings [ ] patternTokens = Arrays . copyOfRange ( tokens , firstMatchToken , lastMatchToken + 1 ) ; return evaluator . runFilter ( rule . getFilterArguments ( ) , ruleMatch , patternTokens , tokenPositions ) ; } else { return ruleMatch ; } } } return null ; } private boolean matchPreservesCase ( List < Match > suggestionMatches , String msg ) { if ( suggestionMatches != null && ! suggestionMatches . isEmpty ( ) ) { final int sugStart = msg . indexOf ( SUGGESTION_START_TAG ) + SUGGESTION_START_TAG . length ( ) ; for ( Match sMatch : suggestionMatches ) { if ( ! sMatch . isInMessageOnly ( ) && sMatch . convertsCase ( ) && msg . charAt ( sugStart ) == '\\' ) { return false ; } } } return true ; } private int translateElementNo ( final int i ) { if ( ! useList || i < 0 ) { return i ; } int j = 0 ; final PatternRule rule = ( PatternRule ) this . rule ; for ( int k = 0 ; k < i ; k ++ ) { j += rule . getElementNo ( ) . get ( k ) ; } return j ; } private String formatMatches ( final AnalyzedTokenReadings [ ] tokenReadings , final List < Integer > positions , final int firstMatchTok , final String errorMsg , final List < Match > suggestionMatches ) throws IOException { String errorMessage = errorMsg ; int matchCounter = 0 ; final int [ ] numbersToMatches = new int [ errorMsg . length ( ) ] ; boolean newWay = false ; int errLen = errorMessage . length ( ) ; int errMarker = errorMessage . indexOf ( '\\' ) ; boolean numberFollows = false ; if ( errMarker >= 0 && errMarker < errLen - 1 ) { numberFollows = StringTools . isPositiveNumber ( errorMessage . charAt ( errMarker + 1 ) ) ; } while ( errMarker >= 0 && numberFollows ) { final int backslashPos = errorMessage . indexOf ( '\\' ) ; if ( backslashPos >= 0 && StringTools . isPositiveNumber ( errorMessage . charAt ( backslashPos + 1 ) ) ) { int numLen = 1 ; while ( backslashPos + numLen < errorMessage . length ( ) && StringTools . isPositiveNumber ( errorMessage . charAt ( backslashPos + numLen ) ) ) { numLen ++ ; } final int j = Integer . parseInt ( errorMessage . substring ( backslashPos + 1 , backslashPos + numLen ) ) - 1 ; int repTokenPos = 0 ; int nextTokenPos = 0 ; for ( int l = 0 ; l <= Math . min ( j , positions . size ( ) - 1 ) ; l ++ ) { repTokenPos += positions . get ( l ) ; } if ( j + 1 < positions . size ( ) ) { nextTokenPos = firstMatchTok + repTokenPos + positions . get ( j + 1 ) ; } if ( suggestionMatches != null ) { if ( matchCounter < suggestionMatches . size ( ) ) { numbersToMatches [ j ] = matchCounter ; if ( suggestionMatches . get ( matchCounter ) != null ) { final String [ ] matches = j >= positions . size ( ) || positions . get ( j ) != 0 ? concatMatches ( matchCounter , j , firstMatchTok + repTokenPos , tokenReadings , nextTokenPos , suggestionMatches ) : new String [ ] { "" } ; final String leftSide = errorMessage . substring ( 0 , backslashPos ) ; final String rightSide = errorMessage . substring ( backslashPos + numLen ) ; if ( matches . length == 1 ) { if ( matches [ 0 ] . isEmpty ( ) && leftSide . endsWith ( " " ) && rightSide . startsWith ( " " ) ) { errorMessage = leftSide . substring ( 0 , leftSide . length ( ) - 1 ) + rightSide ; } else { errorMessage = leftSide + matches [ 0 ] + rightSide ; } } else { errorMessage = formatMultipleSynthesis ( matches , leftSide , rightSide ) ; } matchCounter ++ ; newWay = true ; } } else { suggestionMatches . add ( suggestionMatches . get ( numbersToMatches [ j ] ) ) ; } } if ( ! newWay ) { errorMessage = errorMessage . replace ( "\\" + ( j + 1 ) , tokenReadings [ firstMatchTok + repTokenPos - 1 ] . getToken ( ) ) ; } } errMarker = errorMessage . indexOf ( '\\' ) ; numberFollows = false ; errLen = errorMessage . length ( ) ; if ( errMarker >= 0 && errMarker < errLen - 1 ) { numberFollows = StringTools . isPositiveNumber ( errorMessage . charAt ( errMarker + 1 ) ) ; } } return errorMessage ; } static String formatMultipleSynthesis ( final String [ ] matches , final String leftSide , final String rightSide ) { final String errorMessage ; String suggestionLeft = "" ; String suggestionRight = "" ; String rightSideNew = rightSide ; final int sPos = leftSide . lastIndexOf ( SUGGESTION_START_TAG ) ; if ( sPos >= 0 ) { suggestionLeft = leftSide . substring ( sPos + SUGGESTION_START_TAG . length ( ) ) ; } if ( StringTools . isEmpty ( suggestionLeft ) ) { errorMessage = leftSide ; } else { errorMessage = leftSide . substring ( 0 , leftSide . lastIndexOf ( SUGGESTION_START_TAG ) ) + SUGGESTION_START_TAG ; } final int rPos = rightSide . indexOf ( SUGGESTION_END_TAG ) ; if ( rPos >= 0 ) { suggestionRight = rightSide . substring ( 0 , rPos ) ; } if ( ! StringTools . isEmpty ( suggestionRight ) ) { rightSideNew = rightSide . substring ( rightSide . indexOf ( SUGGESTION_END_TAG ) ) ; } final int lastLeftSugEnd = leftSide . indexOf ( SUGGESTION_END_TAG ) ; final int lastLeftSugStart = leftSide . lastIndexOf ( SUGGESTION_START_TAG ) ; final StringBuilder sb = new StringBuilder ( ) ; sb . append ( errorMessage ) ; for ( int z = 0 ; z < matches . length ; z ++ ) { sb . append ( suggestionLeft ) ; sb . append ( matches [ z ] ) ; sb . append ( suggestionRight ) ; if ( z < matches . length - 1 && lastLeftSugEnd < lastLeftSugStart ) { sb . append ( SUGGESTION_END_TAG ) ; sb . append ( ", " ) ; sb . append ( SUGGESTION_START_TAG ) ; } } sb . append ( rightSideNew ) ; return sb . toString ( ) ; } private String [ ] concatMatches ( final int start , final int index , final int tokenIndex , final AnalyzedTokenReadings [ ] tokens , final int nextTokenPos , final List < Match > suggestionMatches ) throws IOException { String [ ] finalMatch = null ; if ( suggestionMatches . get ( start ) != null ) { final int len = phraseLen ( index ) ; final Language language = rule . language ; if ( len == 1 ) { final int skippedTokens = nextTokenPos - tokenIndex ; final MatchState matchState = suggestionMatches . get ( start ) . createState ( language . getSynthesizer ( ) , tokens , tokenIndex - 1 , skippedTokens ) ; finalMatch = matchState . toFinalString ( language ) ; if ( suggestionMatches . get ( start ) . checksSpelling ( ) && finalMatch . length == 1 && "" . equals ( finalMatch [ 0 ] ) ) { finalMatch = new String [ 1 ] ; finalMatch [ 0 ] = MISTAKE ; } } else { final List < String [ ] > matchList = new ArrayList < > ( ) ; for ( int i = 0 ; i < len ; i ++ ) { final int skippedTokens = nextTokenPos - ( tokenIndex + i ) ; final MatchState matchState = suggestionMatches . get ( start ) . createState ( language . getSynthesizer ( ) , tokens , tokenIndex - 1 + i , skippedTokens ) ; matchList . add ( matchState . toFinalString ( language ) ) ; } return combineLists ( matchList . toArray ( new String [ matchList . size ( ) ] [ ] ) , new String [ matchList . size ( ) ] , 0 , language ) ; } } return finalMatch ; } private int phraseLen ( final int i ) { final PatternRule rule = ( PatternRule ) this . rule ; final List < Integer > elementNo = rule . getElementNo ( ) ; if ( ! useList || i > elementNo . size ( ) - 1 ) { return 1 ; } return elementNo . get ( i ) ; } private static String [ ] combineLists ( final String [ ] [ ] input , final String [ ] output , final int r , final Language lang ) { final List < String > outputList = new ArrayList < > ( ) ; if ( r == input . length ) { final StringBuilder sb = new StringBuilder ( ) ; for ( int k = 0 ; k < output . length ; k ++ ) { sb . append ( output [ k ] ) ; if ( k < output . length - 1 ) { sb . append ( StringTools . addSpace ( output [ k + 1 ] , lang ) ) ; } } outputList . add ( sb . toString ( ) ) ; } else { for ( int c = 0 ; c < input [ r ] . length ; c ++ ) { output [ r ] = input [ r ] [ c ] ; final String [ ] sList = combineLists ( input , output , r + 1 , lang ) ; outputList . addAll ( Arrays . asList ( sList ) ) ; } } return outputList . toArray ( new String [ outputList . size ( ) ] ) ; } }
package org . languagetool . rules . patterns ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . RuleMatch ; import java . util . Map ; public interface RuleFilter { @ Nullable public RuleMatch acceptRuleMatch ( RuleMatch match , Map < String , String > arguments , AnalyzedTokenReadings [ ] patternTokens ) ; }
package org . languagetool . rules . patterns ; import org . languagetool . Language ; import java . util . List ; public class FalseFriendPatternRule extends PatternRule { public FalseFriendPatternRule ( String id , Language language , List < PatternToken > patternTokens , String description , String message , String shortMessage ) { super ( id , language , patternTokens , description , message , shortMessage ) ; } }
package org . languagetool . rules . patterns ; import org . w3c . dom . Node ; import org . w3c . dom . ls . LSParserFilter ; class IgnoreWhitespaceFilter implements LSParserFilter { @ Override public short acceptNode ( Node nodeArg ) { final String textContent = nodeArg . getTextContent ( ) ; if ( textContent . trim ( ) . isEmpty ( ) ) { return LSParserFilter . FILTER_REJECT ; } else { return LSParserFilter . FILTER_ACCEPT ; } } @ Override public short startElement ( org . w3c . dom . Element elementArg ) { return LSParserFilter . FILTER_ACCEPT ; } @ Override public int getWhatToShow ( ) { return Node . NOTATION_NODE ; } }
package org . languagetool . rules . patterns ; import java . util . Objects ; final class EquivalenceTypeLocator { private final String feature ; private final String type ; EquivalenceTypeLocator ( final String feature , final String type ) { this . feature = feature ; this . type = type ; } @ Override public int hashCode ( ) { return Objects . hash ( feature , type ) ; } @ Override public boolean equals ( final Object obj ) { if ( this == obj ) { return true ; } if ( obj == null ) { return false ; } if ( getClass ( ) != obj . getClass ( ) ) { return false ; } final EquivalenceTypeLocator other = ( EquivalenceTypeLocator ) obj ; return Objects . equals ( feature , other . feature ) && Objects . equals ( type , other . type ) ; } }
package org . languagetool . rules . patterns ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import org . apache . commons . lang . ObjectUtils ; import org . jetbrains . annotations . Nullable ; import org . languagetool . Language ; import org . languagetool . chunking . ChunkTag ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . tools . StringTools ; import org . xml . sax . Attributes ; import org . xml . sax . Locator ; import org . xml . sax . SAXException ; import org . xml . sax . SAXParseException ; import org . xml . sax . helpers . DefaultHandler ; public class XMLRuleHandler extends DefaultHandler { public static final String ID = "id" ; public static final String NAME = "name" ; protected static final String YES = "yes" ; protected static final String OFF = "off" ; protected static final String ON = "on" ; protected static final String POSTAG = "postag" ; protected static final String CHUNKTAG = "chunk" ; protected static final String POSTAG_REGEXP = "postag_regexp" ; protected static final String REGEXP = "regexp" ; protected static final String NEGATE = "negate" ; protected static final String INFLECTED = "inflected" ; protected static final String NEGATE_POS = "negate_pos" ; protected static final String MARKER = "marker" ; protected static final String DEFAULT = "default" ; protected static final String TYPE = "type" ; protected static final String SPACEBEFORE = "spacebefore" ; protected static final String EXAMPLE = "example" ; protected static final String SCOPE = "scope" ; protected static final String IGNORE = "ignore" ; protected static final String SKIP = "skip" ; protected static final String MIN = "min" ; protected static final String MAX = "max" ; protected static final String TOKEN = "token" ; protected static final String FEATURE = "feature" ; protected static final String UNIFY = "unify" ; protected static final String UNIFY_IGNORE = "unify-ignore" ; protected static final String AND = "and" ; protected static final String OR = "or" ; protected static final String EXCEPTION = "exception" ; protected static final String CASE_SENSITIVE = "case_sensitive" ; protected static final String PATTERN = "pattern" ; protected static final String ANTIPATTERN = "antipattern" ; protected static final String MATCH = "match" ; protected static final String UNIFICATION = "unification" ; protected static final String RULE = "rule" ; protected static final String RULES = "rules" ; protected static final String RULEGROUP = "rulegroup" ; protected static final String NO = "no" ; protected static final String PHRASES = "phrases" ; protected static final String MESSAGE = "message" ; protected static final String SUGGESTION = "suggestion" ; protected List < PatternRule > rules = new ArrayList < > ( ) ; protected Language language ; protected StringBuilder correctExample = new StringBuilder ( ) ; protected StringBuilder incorrectExample = new StringBuilder ( ) ; protected StringBuilder exampleCorrection = new StringBuilder ( ) ; protected StringBuilder message = new StringBuilder ( ) ; protected StringBuilder suggestionsOutMsg = new StringBuilder ( ) ; protected StringBuilder match = new StringBuilder ( ) ; protected StringBuilder elements ; protected StringBuilder exceptions ; protected List < String > correctExamples = new ArrayList < > ( ) ; protected List < IncorrectExample > incorrectExamples = new ArrayList < > ( ) ; protected boolean inPattern ; protected boolean inCorrectExample ; protected boolean inIncorrectExample ; protected boolean inMessage ; protected boolean inSuggestion ; protected boolean inMatch ; protected boolean inRuleGroup ; protected boolean inToken ; protected boolean inException ; protected boolean inPhrases ; protected boolean inAndGroup ; protected boolean inOrGroup ; protected boolean tokenSpaceBefore ; protected boolean tokenSpaceBeforeSet ; protected String posToken ; protected ChunkTag chunkTag ; protected boolean posNegation ; protected boolean posRegExp ; protected boolean caseSensitive ; protected boolean regExpression ; protected boolean tokenNegated ; protected boolean tokenInflected ; protected boolean tokenLevelCaseSensitive ; protected boolean tokenLevelCaseSet ; protected String exceptionPosToken ; protected boolean exceptionStringRegExp ; protected boolean exceptionStringNegation ; protected boolean exceptionStringInflected ; protected boolean exceptionPosNegation ; protected boolean exceptionPosRegExp ; protected boolean exceptionValidNext ; protected boolean exceptionValidPrev ; protected boolean exceptionSet ; protected boolean exceptionSpaceBefore ; protected boolean exceptionSpaceBeforeSet ; protected Boolean exceptionLevelCaseSensitive ; protected boolean exceptionLevelCaseSet ; protected List < PatternToken > patternTokens ; protected boolean lastPhrase ; protected String phraseIdRef ; protected String phraseId ; protected int skipPos ; protected int minOccurrence = 1 ; protected int maxOccurrence = 1 ; protected String ruleGroupId ; protected String id ; protected PatternToken patternToken ; protected Match tokenReference ; protected List < Match > suggestionMatches ; protected List < Match > suggestionMatchesOutMsg ; protected Locator pLocator ; protected int startPositionCorrection ; protected int endPositionCorrection ; protected int tokenCounter ; protected Map < String , List < List < PatternToken > > > phraseMap ; protected List < ArrayList < PatternToken > > phrasePatternTokens ; protected int andGroupCounter ; protected int orGroupCounter ; protected boolean inUrl ; protected boolean inUrlForRuleGroup ; protected StringBuilder url = new StringBuilder ( ) ; protected StringBuilder urlForRuleGroup = new StringBuilder ( ) ; protected boolean inShortMessage ; protected boolean inShortMessageForRuleGroup ; protected StringBuilder shortMessage = new StringBuilder ( ) ; protected StringBuilder shortMessageForRuleGroup = new StringBuilder ( ) ; protected boolean inUnification ; protected boolean inMarker ; protected boolean inUnificationDef ; protected boolean uniNegation ; protected boolean inUnificationNeutral ; protected String uFeature ; protected String uType = "" ; protected List < String > uTypeList ; protected Map < String , List < String > > equivalenceFeatures ; public XMLRuleHandler ( ) { patternTokens = new ArrayList < > ( ) ; equivalenceFeatures = new HashMap < > ( ) ; uTypeList = new ArrayList < > ( ) ; } public List < PatternRule > getRules ( ) { return rules ; } @ Override public void warning ( final SAXParseException e ) throws SAXException { throw e ; } @ Override public void error ( final SAXParseException e ) throws SAXException { throw e ; } @ Override public void setDocumentLocator ( final Locator locator ) { pLocator = locator ; super . setDocumentLocator ( locator ) ; } protected void resetToken ( ) { posNegation = false ; posRegExp = false ; inToken = false ; tokenSpaceBefore = false ; tokenSpaceBeforeSet = false ; resetException ( ) ; exceptionSet = false ; tokenReference = null ; } protected void resetException ( ) { exceptionStringNegation = false ; exceptionStringInflected = false ; exceptionPosNegation = false ; exceptionPosRegExp = false ; exceptionStringRegExp = false ; exceptionValidNext = false ; exceptionValidPrev = false ; exceptionSpaceBefore = false ; exceptionSpaceBeforeSet = false ; } protected void phraseElementInit ( ) { if ( phrasePatternTokens == null ) { phrasePatternTokens = new ArrayList < > ( ) ; } } protected void preparePhrase ( final Attributes attrs ) { phraseIdRef = attrs . getValue ( "idref" ) ; if ( phraseMap . containsKey ( phraseIdRef ) ) { for ( final List < PatternToken > curPhrTokens : phraseMap . get ( phraseIdRef ) ) { for ( final PatternToken pToken : curPhrTokens ) { pToken . setPhraseName ( phraseIdRef ) ; } final List < PatternToken > copy = ( List < PatternToken > ) ObjectUtils . clone ( curPhrTokens ) ; for ( PatternToken patternToken : copy ) { patternToken . setInsideMarker ( inMarker ) ; } if ( patternTokens . isEmpty ( ) ) { phrasePatternTokens . add ( new ArrayList < > ( copy ) ) ; } else { final List < PatternToken > prevList = new ArrayList < > ( patternTokens ) ; prevList . addAll ( copy ) ; phrasePatternTokens . add ( new ArrayList < > ( prevList ) ) ; prevList . clear ( ) ; } } lastPhrase = true ; } } protected void finalizePhrase ( ) { if ( phraseMap == null ) { phraseMap = new HashMap < > ( ) ; } phraseElementInit ( ) ; for ( PatternToken patternToken : patternTokens ) { patternToken . setInsideMarker ( inMarker ) ; } if ( phrasePatternTokens . isEmpty ( ) ) { phrasePatternTokens . add ( new ArrayList < > ( patternTokens ) ) ; } else { for ( List < PatternToken > ph : phrasePatternTokens ) { ph . addAll ( new ArrayList < > ( patternTokens ) ) ; } } phraseMap . put ( phraseId , new ArrayList < List < PatternToken > > ( phrasePatternTokens ) ) ; patternTokens . clear ( ) ; phrasePatternTokens . clear ( ) ; } protected void startPattern ( final Attributes attrs ) throws SAXException { tokenCounter = 0 ; inPattern = true ; caseSensitive = YES . equals ( attrs . getValue ( CASE_SENSITIVE ) ) ; } protected void processElement ( final List < PatternToken > patternTokens ) { int counter = 0 ; for ( final PatternToken pToken : patternTokens ) { if ( pToken . getPhraseName ( ) != null && counter > 0 && pToken . isReferenceElement ( ) ) { final int tokRef = pToken . getMatch ( ) . getTokenRef ( ) ; pToken . getMatch ( ) . setTokenRef ( tokRef + counter - 1 ) ; final String offsetToken = pToken . getString ( ) . replace ( "\\" + tokRef , "\\" + ( tokRef + counter - 1 ) ) ; pToken . setStringElement ( offsetToken ) ; } counter ++ ; } } protected void setMatchElement ( final Attributes attrs ) throws SAXException { inMatch = true ; match = new StringBuilder ( ) ; Match . CaseConversion caseConversion = Match . CaseConversion . NONE ; if ( attrs . getValue ( "case_conversion" ) != null ) { caseConversion = Match . CaseConversion . valueOf ( attrs . getValue ( "case_conversion" ) . toUpperCase ( Locale . ENGLISH ) ) ; } Match . IncludeRange includeRange = Match . IncludeRange . NONE ; if ( attrs . getValue ( "include_skipped" ) != null ) { includeRange = Match . IncludeRange . valueOf ( attrs . getValue ( "include_skipped" ) . toUpperCase ( Locale . ENGLISH ) ) ; } final Match mWorker = new Match ( attrs . getValue ( POSTAG ) , attrs . getValue ( "postag_replace" ) , YES . equals ( attrs . getValue ( POSTAG_REGEXP ) ) , attrs . getValue ( "regexp_match" ) , attrs . getValue ( "regexp_replace" ) , caseConversion , YES . equals ( attrs . getValue ( "setpos" ) ) , YES . equals ( attrs . getValue ( "suppress_misspelled" ) ) , includeRange ) ; mWorker . setInMessageOnly ( ! inSuggestion ) ; if ( inMessage ) { if ( suggestionMatches == null ) { suggestionMatches = new ArrayList < > ( ) ; } suggestionMatches . add ( mWorker ) ; message . append ( "\u0001\\" ) ; message . append ( attrs . getValue ( "no" ) ) ; checkNumber ( attrs ) ; } else if ( inSuggestion ) { if ( suggestionMatchesOutMsg == null ) { suggestionMatchesOutMsg = new ArrayList < > ( ) ; } suggestionMatchesOutMsg . add ( mWorker ) ; suggestionsOutMsg . append ( "\u0001\\" ) ; suggestionsOutMsg . append ( attrs . getValue ( "no" ) ) ; checkNumber ( attrs ) ; } else if ( inToken && attrs . getValue ( "no" ) != null ) { final int refNumber = Integer . parseInt ( attrs . getValue ( "no" ) ) ; checkRefNumber ( refNumber ) ; mWorker . setTokenRef ( refNumber ) ; tokenReference = mWorker ; elements . append ( '\\' ) ; elements . append ( refNumber ) ; } } private void checkNumber ( Attributes attrs ) throws SAXException { if ( StringTools . isEmpty ( attrs . getValue ( "no" ) ) ) { throw new SAXException ( "References cannot be empty: " + "\n Line: " + pLocator . getLineNumber ( ) + ", column: " + pLocator . getColumnNumber ( ) + "." ) ; } else if ( Integer . parseInt ( attrs . getValue ( "no" ) ) < 1 ) { throw new SAXException ( "References must be larger than 0: " + attrs . getValue ( "no" ) + "\n Line: " + pLocator . getLineNumber ( ) + ", column: " + pLocator . getColumnNumber ( ) + "." ) ; } } private void checkRefNumber ( int refNumber ) throws SAXException { if ( refNumber > patternTokens . size ( ) ) { throw new SAXException ( "Only backward references in match elements are possible, tried to specify token " + refNumber + "\n" + "Line: " + pLocator . getLineNumber ( ) + ", column: " + pLocator . getColumnNumber ( ) + "." ) ; } } protected void setExceptions ( final Attributes attrs ) { inException = true ; exceptions = new StringBuilder ( ) ; resetException ( ) ; exceptionStringNegation = YES . equals ( attrs . getValue ( NEGATE ) ) ; exceptionValidNext = "next" . equals ( attrs . getValue ( SCOPE ) ) ; exceptionValidPrev = "previous" . equals ( attrs . getValue ( SCOPE ) ) ; exceptionStringInflected = YES . equals ( attrs . getValue ( INFLECTED ) ) ; if ( attrs . getValue ( POSTAG ) != null ) { exceptionPosToken = attrs . getValue ( POSTAG ) ; exceptionPosRegExp = YES . equals ( attrs . getValue ( POSTAG_REGEXP ) ) ; exceptionPosNegation = YES . equals ( attrs . getValue ( NEGATE_POS ) ) ; } exceptionStringRegExp = YES . equals ( attrs . getValue ( REGEXP ) ) ; if ( attrs . getValue ( SPACEBEFORE ) != null ) { exceptionSpaceBefore = YES . equals ( attrs . getValue ( SPACEBEFORE ) ) ; exceptionSpaceBeforeSet = ! IGNORE . equals ( attrs . getValue ( SPACEBEFORE ) ) ; } if ( attrs . getValue ( CASE_SENSITIVE ) != null ) { exceptionLevelCaseSet = true ; exceptionLevelCaseSensitive = YES . equals ( attrs . getValue ( CASE_SENSITIVE ) ) ; } else { exceptionLevelCaseSet = false ; } } protected void finalizeExceptions ( ) { inException = false ; if ( ! exceptionSet ) { boolean tokenCase = caseSensitive ; if ( tokenLevelCaseSet ) { tokenCase = tokenLevelCaseSensitive ; } patternToken = new PatternToken ( elements . toString ( ) , tokenCase , regExpression , tokenInflected ) ; exceptionSet = true ; } patternToken . setNegation ( tokenNegated ) ; if ( ! StringTools . isEmpty ( exceptions . toString ( ) ) || exceptionPosToken != null ) { patternToken . setStringPosException ( exceptions . toString ( ) , exceptionStringRegExp , exceptionStringInflected , exceptionStringNegation , exceptionValidNext , exceptionValidPrev , exceptionPosToken , exceptionPosRegExp , exceptionPosNegation , exceptionLevelCaseSensitive ) ; exceptionPosToken = null ; exceptionLevelCaseSensitive = null ; } if ( exceptionSpaceBeforeSet ) { patternToken . setExceptionSpaceBefore ( exceptionSpaceBefore ) ; } resetException ( ) ; } protected void setToken ( final Attributes attrs ) { inToken = true ; if ( lastPhrase ) { patternTokens . clear ( ) ; } lastPhrase = false ; tokenNegated = YES . equals ( attrs . getValue ( NEGATE ) ) ; tokenInflected = YES . equals ( attrs . getValue ( INFLECTED ) ) ; if ( attrs . getValue ( SKIP ) != null ) { skipPos = Integer . parseInt ( attrs . getValue ( SKIP ) ) ; } if ( attrs . getValue ( MIN ) != null ) { minOccurrence = Integer . parseInt ( attrs . getValue ( MIN ) ) ; } if ( attrs . getValue ( MAX ) != null ) { maxOccurrence = Integer . parseInt ( attrs . getValue ( MAX ) ) ; } elements = new StringBuilder ( ) ; if ( attrs . getValue ( POSTAG ) != null ) { posToken = attrs . getValue ( POSTAG ) ; posRegExp = YES . equals ( attrs . getValue ( POSTAG_REGEXP ) ) ; posNegation = YES . equals ( attrs . getValue ( NEGATE_POS ) ) ; } if ( attrs . getValue ( CHUNKTAG ) != null ) { chunkTag = new ChunkTag ( attrs . getValue ( CHUNKTAG ) ) ; } regExpression = YES . equals ( attrs . getValue ( REGEXP ) ) ; if ( attrs . getValue ( SPACEBEFORE ) != null ) { tokenSpaceBefore = YES . equals ( attrs . getValue ( SPACEBEFORE ) ) ; tokenSpaceBeforeSet = ! IGNORE . equals ( attrs . getValue ( SPACEBEFORE ) ) ; } if ( ! inAndGroup && ! inOrGroup ) { tokenCounter ++ ; } if ( attrs . getValue ( CASE_SENSITIVE ) != null ) { tokenLevelCaseSet = true ; tokenLevelCaseSensitive = YES . equals ( attrs . getValue ( CASE_SENSITIVE ) ) ; } else { tokenLevelCaseSensitive = false ; tokenLevelCaseSet = false ; } } @ Nullable protected List < Match > addLegacyMatches ( final List < Match > existingSugMatches , final String messageStr , boolean inMessage ) { if ( existingSugMatches == null || existingSugMatches . isEmpty ( ) ) { return null ; } final List < Match > sugMatch = new ArrayList < > ( ) ; int pos = 0 ; int ind = 0 ; int matchCounter = 0 ; while ( pos != - 1 ) { pos = messageStr . indexOf ( '\\' , ind + 1 ) ; if ( pos != - 1 && messageStr . length ( ) > pos && Character . isDigit ( messageStr . charAt ( pos + 1 ) ) ) { if ( pos == 0 || messageStr . charAt ( pos - 1 ) != '\u0001' ) { final Match mWorker = new Match ( null , null , false , null , null , Match . CaseConversion . NONE , false , false , Match . IncludeRange . NONE ) ; mWorker . setInMessageOnly ( true ) ; sugMatch . add ( mWorker ) ; } else if ( messageStr . charAt ( pos - 1 ) == '\u0001' ) { sugMatch . add ( existingSugMatches . get ( matchCounter ) ) ; if ( inMessage ) { message . deleteCharAt ( pos - 1 - matchCounter ) ; } else { suggestionsOutMsg . deleteCharAt ( pos - 1 - matchCounter ) ; } matchCounter ++ ; } } ind = pos ; } if ( sugMatch . isEmpty ( ) ) { return existingSugMatches ; } return sugMatch ; } protected void finalizeTokens ( ) throws SAXException { if ( ! exceptionSet || patternToken == null ) { boolean tokenCase = caseSensitive ; if ( tokenLevelCaseSet ) { tokenCase = tokenLevelCaseSensitive ; } patternToken = new PatternToken ( elements . toString ( ) , tokenCase , regExpression , tokenInflected ) ; patternToken . setNegation ( tokenNegated ) ; } else { patternToken . setStringElement ( elements . toString ( ) ) ; } if ( skipPos != 0 ) { patternToken . setSkipNext ( skipPos ) ; skipPos = 0 ; } if ( minOccurrence == 0 ) { patternToken . setMinOccurrence ( 0 ) ; } if ( maxOccurrence != 1 ) { patternToken . setMaxOccurrence ( maxOccurrence ) ; maxOccurrence = 1 ; } if ( posToken != null ) { patternToken . setPosToken ( new PatternToken . PosToken ( posToken , posRegExp , posNegation ) ) ; posToken = null ; } if ( chunkTag != null ) { patternToken . setChunkTag ( chunkTag ) ; chunkTag = null ; } if ( tokenReference != null ) { patternToken . setMatch ( tokenReference ) ; } if ( inAndGroup && andGroupCounter > 0 ) { patternTokens . get ( patternTokens . size ( ) - 1 ) . setAndGroupElement ( patternToken ) ; if ( minOccurrence != 1 || maxOccurrence != 1 ) { throw new SAXException ( "Please set min and max attributes on the " + "first token in the AND group.\n You attempted to set these " + "attributes on the token no. " + ( andGroupCounter + 1 ) + "." + "\n Line: " + pLocator . getLineNumber ( ) + ", column: " + pLocator . getColumnNumber ( ) + "." ) ; } } else if ( inOrGroup && orGroupCounter > 0 ) { patternTokens . get ( patternTokens . size ( ) - 1 ) . setOrGroupElement ( patternToken ) ; } else { if ( minOccurrence < 1 ) { patternTokens . add ( patternToken ) ; } for ( int i = 1 ; i <= minOccurrence ; i ++ ) { patternTokens . add ( patternToken ) ; } minOccurrence = 1 ; } if ( inAndGroup ) { andGroupCounter ++ ; } if ( inOrGroup ) { orGroupCounter ++ ; } if ( inUnification ) { patternToken . setUnification ( equivalenceFeatures ) ; } if ( inUnificationNeutral ) { patternToken . setUnificationNeutral ( ) ; } patternToken . setInsideMarker ( inMarker ) ; if ( inUnificationDef ) { language . getUnifierConfiguration ( ) . setEquivalence ( uFeature , uType , patternToken ) ; patternTokens . clear ( ) ; } if ( tokenSpaceBeforeSet ) { patternToken . setWhitespaceBefore ( tokenSpaceBefore ) ; } resetToken ( ) ; } }
package org . languagetool . rules . patterns ; import org . apache . commons . lang . StringUtils ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . Category ; import org . languagetool . rules . IncorrectExample ; import org . xml . sax . Attributes ; import org . xml . sax . SAXException ; import java . text . MessageFormat ; import java . util . * ; class FalseFriendRuleHandler extends XMLRuleHandler { private static final String TRANSLATION = "translation" ; private final ResourceBundle messages ; private final MessageFormat formatter ; private final Language textLanguage ; private final Language motherTongue ; private final Map < String , List < String > > suggestionMap = new HashMap < > ( ) ; private final List < String > suggestions = new ArrayList < > ( ) ; private final List < StringBuilder > translations = new ArrayList < > ( ) ; private boolean defaultOff ; private Language language ; private Language translationLanguage ; private Language currentTranslationLanguage ; private StringBuilder translation = new StringBuilder ( ) ; private boolean inTranslation ; FalseFriendRuleHandler ( final Language textLanguage , final Language motherTongue ) { messages = ResourceBundle . getBundle ( JLanguageTool . MESSAGE_BUNDLE , motherTongue . getLocale ( ) ) ; formatter = new MessageFormat ( "" ) ; formatter . setLocale ( motherTongue . getLocale ( ) ) ; this . textLanguage = textLanguage ; this . motherTongue = motherTongue ; } public Map < String , List < String > > getSuggestionMap ( ) { return suggestionMap ; } @ Override public void startElement ( final String namespaceURI , final String lName , final String qName , final Attributes attrs ) throws SAXException { if ( qName . equals ( RULE ) ) { translations . clear ( ) ; id = attrs . getValue ( "id" ) ; if ( ! ( inRuleGroup && defaultOff ) ) { defaultOff = "off" . equals ( attrs . getValue ( "default" ) ) ; } if ( inRuleGroup && id == null ) { id = ruleGroupId ; } correctExamples = new ArrayList < > ( ) ; incorrectExamples = new ArrayList < > ( ) ; } else if ( qName . equals ( PATTERN ) ) { inPattern = true ; final String languageStr = attrs . getValue ( "lang" ) ; if ( Languages . isLanguageSupported ( languageStr ) ) { language = Languages . getLanguageForShortName ( languageStr ) ; } } else if ( qName . equals ( TOKEN ) ) { setToken ( attrs ) ; } else if ( qName . equals ( TRANSLATION ) ) { inTranslation = true ; final String languageStr = attrs . getValue ( "lang" ) ; if ( Languages . isLanguageSupported ( languageStr ) ) { final Language tmpLang = Languages . getLanguageForShortName ( languageStr ) ; currentTranslationLanguage = tmpLang ; if ( tmpLang . equalsConsiderVariantsIfSpecified ( motherTongue ) ) { translationLanguage = tmpLang ; } } } else if ( qName . equals ( EXAMPLE ) && attrs . getValue ( TYPE ) . equals ( "correct" ) ) { inCorrectExample = true ; correctExample = new StringBuilder ( ) ; } else if ( qName . equals ( EXAMPLE ) && attrs . getValue ( TYPE ) . equals ( "incorrect" ) ) { inIncorrectExample = true ; incorrectExample = new StringBuilder ( ) ; } else if ( qName . equals ( MESSAGE ) ) { inMessage = true ; message = new StringBuilder ( ) ; } else if ( qName . equals ( RULEGROUP ) ) { ruleGroupId = attrs . getValue ( "id" ) ; inRuleGroup = true ; defaultOff = "off" . equals ( attrs . getValue ( DEFAULT ) ) ; } } @ Override public void endElement ( final String namespaceURI , final String sName , final String qName ) throws SAXException { switch ( qName ) { case RULE : if ( language . equalsConsiderVariantsIfSpecified ( textLanguage ) && translationLanguage != null && translationLanguage . equalsConsiderVariantsIfSpecified ( motherTongue ) && language != motherTongue && ! translations . isEmpty ( ) ) { formatter . applyPattern ( messages . getString ( "false_friend_hint" ) ) ; final String tokensAsString = StringUtils . join ( patternTokens , " " ) . replace ( '|' , '/' ) ; final Object [ ] messageArguments = { tokensAsString , messages . getString ( textLanguage . getShortName ( ) ) , formatTranslations ( translations ) , messages . getString ( motherTongue . getShortName ( ) ) } ; final String description = formatter . format ( messageArguments ) ; final PatternRule rule = new FalseFriendPatternRule ( id , language , patternTokens , messages . getString ( "false_friend_desc" ) + " " + tokensAsString , description , messages . getString ( "false_friend" ) ) ; rule . setCorrectExamples ( correctExamples ) ; rule . setIncorrectExamples ( incorrectExamples ) ; rule . setCategory ( new Category ( messages . getString ( "category_false_friend" ) ) ) ; if ( defaultOff ) { rule . setDefaultOff ( ) ; } rules . add ( rule ) ; } if ( patternTokens != null ) { patternTokens . clear ( ) ; } break ; case TOKEN : finalizeTokens ( ) ; break ; case PATTERN : inPattern = false ; break ; case TRANSLATION : if ( currentTranslationLanguage != null && currentTranslationLanguage . equalsConsiderVariantsIfSpecified ( motherTongue ) ) { translations . add ( translation ) ; } if ( currentTranslationLanguage != null && currentTranslationLanguage . equalsConsiderVariantsIfSpecified ( textLanguage ) && language . equalsConsiderVariantsIfSpecified ( motherTongue ) ) { suggestions . add ( translation . toString ( ) ) ; } translation = new StringBuilder ( ) ; inTranslation = false ; currentTranslationLanguage = null ; break ; case EXAMPLE : if ( inCorrectExample ) { correctExamples . add ( correctExample . toString ( ) ) ; } else if ( inIncorrectExample ) { incorrectExamples . add ( new IncorrectExample ( incorrectExample . toString ( ) ) ) ; } inCorrectExample = false ; inIncorrectExample = false ; correctExample = new StringBuilder ( ) ; incorrectExample = new StringBuilder ( ) ; break ; case MESSAGE : inMessage = false ; break ; case RULEGROUP : if ( ! suggestions . isEmpty ( ) ) { final List < String > l = new ArrayList < > ( suggestions ) ; suggestionMap . put ( id , l ) ; suggestions . clear ( ) ; } inRuleGroup = false ; break ; } } private String formatTranslations ( final List < StringBuilder > translations ) { final StringBuilder sb = new StringBuilder ( ) ; for ( final Iterator < StringBuilder > iter = translations . iterator ( ) ; iter . hasNext ( ) ; ) { final StringBuilder trans = iter . next ( ) ; sb . append ( '"' ) ; sb . append ( trans ) ; sb . append ( '"' ) ; if ( iter . hasNext ( ) ) { sb . append ( ", " ) ; } } return sb . toString ( ) ; } @ Override public void characters ( final char [ ] buf , final int offset , final int len ) { final String s = new String ( buf , offset , len ) ; if ( inToken && inPattern ) { elements . append ( s ) ; } else if ( inCorrectExample ) { correctExample . append ( s ) ; } else if ( inIncorrectExample ) { incorrectExample . append ( s ) ; } else if ( inTranslation ) { translation . append ( s ) ; } } }
package org . languagetool . rules . patterns ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; public abstract class AbstractPatternRulePerformer { protected boolean prevMatched ; protected AbstractPatternRule rule ; protected Unifier unifier ; protected AnalyzedTokenReadings [ ] unifiedTokens ; protected AbstractPatternRulePerformer ( AbstractPatternRule rule , Unifier unifier ) { this . rule = rule ; this . unifier = unifier ; } protected List < PatternTokenMatcher > createElementMatchers ( ) { final List < PatternTokenMatcher > patternTokenMatchers = new ArrayList < > ( rule . patternTokens . size ( ) ) ; for ( PatternToken pToken : rule . patternTokens ) { final PatternTokenMatcher matcher = new PatternTokenMatcher ( pToken ) ; patternTokenMatchers . add ( matcher ) ; } return patternTokenMatchers ; } protected boolean testAllReadings ( final AnalyzedTokenReadings [ ] tokens , final PatternTokenMatcher matcher , final PatternTokenMatcher prevElement , final int tokenNo , final int firstMatchToken , final int prevSkipNext ) throws IOException { boolean thisMatched = false ; final int numberOfReadings = tokens [ tokenNo ] . getReadingsLength ( ) ; matcher . prepareAndGroup ( firstMatchToken , tokens , rule . getLanguage ( ) ) ; for ( int i = 0 ; i < numberOfReadings ; i ++ ) { final AnalyzedToken matchToken = tokens [ tokenNo ] . getAnalyzedToken ( i ) ; boolean tested = false ; prevMatched = prevMatched || prevSkipNext > 0 && prevElement != null && prevElement . isMatchedByScopeNextException ( matchToken ) ; if ( prevMatched ) { return false ; } if ( ! thisMatched ) { thisMatched = matcher . isMatched ( matchToken ) ; tested = true ; } if ( ! thisMatched && ( prevElement == null || prevElement . getPatternToken ( ) . getExceptionList ( ) == null ) ) { if ( matcher . getPatternToken ( ) . getPOStag ( ) == null ) { if ( matcher . getPatternToken ( ) . isInflected ( ) ) { if ( tokens [ tokenNo ] . hasSameLemmas ( ) ) { return false ; } } else { return false ; } } else if ( ! matcher . getPatternToken ( ) . getPOSNegation ( ) && ! tokens [ tokenNo ] . isTagged ( ) ) { return false ; } } if ( rule . isGroupsOrUnification ( ) ) { if ( ! matcher . getPatternToken ( ) . isUnificationNeutral ( ) ) { thisMatched &= testUnificationAndGroups ( thisMatched , i + 1 == numberOfReadings , matchToken , matcher , tested ) ; } } } if ( thisMatched ) { for ( int i = 0 ; i < numberOfReadings ; i ++ ) { if ( matcher . isExceptionMatchedCompletely ( tokens [ tokenNo ] . getAnalyzedToken ( i ) ) ) { return false ; } } if ( tokenNo > 0 && matcher . hasPreviousException ( ) ) { if ( matcher . isMatchedByPreviousException ( tokens [ tokenNo - 1 ] ) ) { return false ; } } if ( matcher . getPatternToken ( ) . isUnificationNeutral ( ) ) { unifier . addNeutralElement ( tokens [ tokenNo ] ) ; } } if ( matcher . getPatternToken ( ) . getChunkTag ( ) != null ) { thisMatched &= tokens [ tokenNo ] . getChunkTags ( ) . contains ( matcher . getPatternToken ( ) . getChunkTag ( ) ) ^ matcher . getPatternToken ( ) . getNegation ( ) ; } if ( matcher . getPatternToken ( ) . hasAndGroup ( ) ) { for ( PatternToken e : matcher . getPatternToken ( ) . getAndGroup ( ) ) { if ( e . getChunkTag ( ) != null ) { thisMatched &= tokens [ tokenNo ] . getChunkTags ( ) . contains ( e . getChunkTag ( ) ) ^ e . getNegation ( ) ; } } } return thisMatched ; } protected boolean testUnificationAndGroups ( final boolean matched , final boolean lastReading , final AnalyzedToken matchToken , final PatternTokenMatcher elemMatcher , boolean alreadyTested ) { boolean thisMatched = matched ; final boolean elemIsMatched = alreadyTested || elemMatcher . isMatched ( matchToken ) ; final PatternToken elem = elemMatcher . getPatternToken ( ) ; if ( rule . testUnification ) { if ( matched && elem . isUnified ( ) ) { if ( elem . isUniNegated ( ) ) { thisMatched = ! unifier . isUnified ( matchToken , elem . getUniFeatures ( ) , lastReading , elemIsMatched ) ; } else { if ( elem . isLastInUnification ( ) ) { thisMatched = unifier . isUnified ( matchToken , elem . getUniFeatures ( ) , lastReading , elemIsMatched ) ; if ( thisMatched && rule . isGetUnified ( ) ) { unifiedTokens = unifier . getFinalUnified ( ) ; } } else { unifier . isUnified ( matchToken , elem . getUniFeatures ( ) , lastReading , elemIsMatched ) ; } } } if ( ! elem . isUnified ( ) ) { unifier . reset ( ) ; } } elemMatcher . addMemberAndGroup ( matchToken ) ; if ( lastReading ) { thisMatched &= elemMatcher . checkAndGroup ( thisMatched ) ; } return thisMatched ; } protected int getMinOccurrenceCorrection ( ) { int minOccurCorrection = 0 ; for ( PatternToken patternToken : rule . getPatternTokens ( ) ) { if ( patternToken . getMinOccurrence ( ) == 0 ) { minOccurCorrection ++ ; } } return minOccurCorrection ; } protected int skipMaxTokens ( AnalyzedTokenReadings [ ] tokens , PatternTokenMatcher elem , int firstMatchToken , int prevSkipNext , PatternTokenMatcher prevElement , int m , int remainingElems ) throws IOException { int maxSkip = 0 ; int maxOccurrences = elem . getPatternToken ( ) . getMaxOccurrence ( ) == - 1 ? Integer . MAX_VALUE : elem . getPatternToken ( ) . getMaxOccurrence ( ) ; for ( int j = 1 ; j < maxOccurrences && m + j < tokens . length - remainingElems ; j ++ ) { boolean nextAllElementsMatch = ! tokens [ m + j ] . isImmunized ( ) && testAllReadings ( tokens , elem , prevElement , m + j , firstMatchToken , prevSkipNext ) ; if ( nextAllElementsMatch ) { maxSkip ++ ; } else { break ; } } return maxSkip ; } }
package org . languagetool . rules . nl ; import java . io . IOException ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; import org . apache . commons . lang . StringUtils ; import org . languagetool . rules . AbstractSimpleReplaceRule ; import org . languagetool . rules . Category ; import org . languagetool . rules . Example ; import org . languagetool . rules . ITSIssueType ; public class SimpleReplaceRule extends AbstractSimpleReplaceRule { public static final String DUTCH_SIMPLE_REPLACE_RULE = "NL_SIMPLE_REPLACE" ; private static final Map < String , List < String > > wrongWords = load ( "/nl/replace.txt" ) ; private static final Locale NL_LOCALE = new Locale ( "nl" ) ; @ Override protected Map < String , List < String > > getWrongWords ( ) { return wrongWords ; } public SimpleReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages ) ; setLocQualityIssueType ( ITSIssueType . Misspelling ) ; setCategory ( new Category ( "Vergissingen" ) ) ; setCheckLemmas ( false ) ; addExamplePair ( Example . wrong ( "<marker>ofzo</marker>." ) , Example . fixed ( "<marker>of zo</marker>." ) ) ; } @ Override public final String getId ( ) { return DUTCH_SIMPLE_REPLACE_RULE ; } @ Override public String getDescription ( ) { return "Snelle correctie van veel voorkomende vergissingen" ; } @ Override public String getShort ( ) { return "Vergissing" ; } @ Override public String getMessage ( String tokenStr , List < String > replacements ) { return tokenStr + " is een fout, juist is: " + StringUtils . join ( replacements , ", " ) + "." ; } @ Override public boolean isCaseSensitive ( ) { return false ; } @ Override public Locale getLocale ( ) { return NL_LOCALE ; } }
package org . languagetool . rules . patterns ; import org . jetbrains . annotations . Nullable ; import org . languagetool . tools . StringTools ; import java . net . Authenticator ; import java . net . PasswordAuthentication ; public class PasswordAuthenticator extends Authenticator { @ Override @ Nullable protected PasswordAuthentication getPasswordAuthentication ( ) { if ( getRequestingURL ( ) == null ) { return null ; } String userInfo = getRequestingURL ( ) . getUserInfo ( ) ; if ( StringTools . isEmpty ( userInfo ) ) { return null ; } String [ ] parts = userInfo . split ( ":" ) ; if ( parts . length != 2 ) { throw new RuntimeException ( "Invalid userInfo format, expected 'user:password': " + userInfo ) ; } String username = parts [ 0 ] ; String password = parts [ 1 ] ; return new PasswordAuthentication ( username , password . toCharArray ( ) ) ; } }
package org . languagetool . rules . patterns ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . Objects ; import org . languagetool . AnalyzedSentence ; import org . languagetool . Language ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public abstract class AbstractPatternRule extends Rule { protected final Language language ; protected final List < PatternToken > patternTokens ; protected final boolean testUnification ; protected final boolean sentStart ; protected String subId ; protected int startPositionCorrection ; protected int endPositionCorrection ; private final String id ; private final String description ; private final boolean getUnified ; private final boolean groupsOrUnification ; public AbstractPatternRule ( final String id , final String description , final Language language , final List < PatternToken > patternTokens , final boolean getUnified ) { this . id = Objects . requireNonNull ( id , "id cannot be null" ) ; this . description = Objects . requireNonNull ( description , "description cannot be null" ) ; this . patternTokens = new ArrayList < > ( Objects . requireNonNull ( patternTokens , "patternTokens cannot be null" ) ) ; this . language = Objects . requireNonNull ( language , "language cannot be null" ) ; this . getUnified = getUnified ; testUnification = initUnifier ( ) ; sentStart = this . patternTokens . size ( ) > 0 && this . patternTokens . get ( 0 ) . isSentenceStart ( ) ; if ( ! testUnification ) { boolean found = false ; for ( PatternToken elem : this . patternTokens ) { if ( elem . hasAndGroup ( ) ) { found = true ; break ; } } groupsOrUnification = found ; } else { groupsOrUnification = true ; } } @ Override public boolean supportsLanguage ( final Language language ) { return language . equalsConsiderVariantsIfSpecified ( this . language ) ; } private boolean initUnifier ( ) { for ( final PatternToken pToken : patternTokens ) { if ( pToken . isUnified ( ) ) { return true ; } } return false ; } @ Override public String toString ( ) { return id + "[" + subId + "]:" + patternTokens + ":" + description ; } @ Override public String getDescription ( ) { return description ; } @ Override public String getId ( ) { return id ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { return null ; } @ Override public void reset ( ) { } public final Language getLanguage ( ) { return language ; } public final void setStartPositionCorrection ( final int startPositionCorrection ) { this . startPositionCorrection = startPositionCorrection ; } public final int getStartPositionCorrection ( ) { return startPositionCorrection ; } public final void setEndPositionCorrection ( final int endPositionCorrection ) { this . endPositionCorrection = endPositionCorrection ; } public final int getEndPositionCorrection ( ) { return endPositionCorrection ; } public final String getSubId ( ) { return subId ; } public final void setSubId ( final String subId ) { this . subId = subId ; } public boolean isGroupsOrUnification ( ) { return groupsOrUnification ; } public boolean isGetUnified ( ) { return getUnified ; } public boolean isSentStart ( ) { return sentStart ; } public boolean isTestUnification ( ) { return testUnification ; } public List < PatternToken > getPatternTokens ( ) { return patternTokens ; } }
package org . languagetool . rules . patterns ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; public class PatternTokenMatcher { private final PatternToken basePatternToken ; private PatternToken patternToken ; private List < PatternTokenMatcher > andGroup ; private boolean [ ] andGroupCheck ; public PatternTokenMatcher ( PatternToken patternToken ) { basePatternToken = patternToken ; this . patternToken = basePatternToken ; resolveGroup ( ) ; } private void resolveGroup ( ) { if ( basePatternToken . hasAndGroup ( ) ) { List < PatternToken > patternTokenAndGroup = basePatternToken . getAndGroup ( ) ; andGroup = new ArrayList < > ( patternTokenAndGroup . size ( ) ) ; for ( PatternToken el : patternTokenAndGroup ) { PatternTokenMatcher matcher = new PatternTokenMatcher ( el ) ; andGroup . add ( matcher ) ; } } } public void resolveReference ( final int firstMatchToken , final AnalyzedTokenReadings [ ] tokens , Language language ) throws IOException { if ( basePatternToken . isReferenceElement ( ) ) { final int refPos = firstMatchToken + basePatternToken . getMatch ( ) . getTokenRef ( ) ; if ( refPos < tokens . length ) { patternToken = basePatternToken . compile ( tokens [ refPos ] , language . getSynthesizer ( ) ) ; } } } public PatternToken getPatternToken ( ) { return basePatternToken ; } public final boolean isMatched ( final AnalyzedToken token ) { boolean matched = patternToken . isMatched ( token ) ; if ( patternToken . hasAndGroup ( ) ) { andGroupCheck [ 0 ] |= matched ; } return matched ; } void prepareAndGroup ( int firstMatchToken , AnalyzedTokenReadings [ ] tokens , Language language ) throws IOException { if ( basePatternToken . hasAndGroup ( ) ) { for ( PatternTokenMatcher andMatcher : andGroup ) { andMatcher . resolveReference ( firstMatchToken , tokens , language ) ; } andGroupCheck = new boolean [ patternToken . getAndGroup ( ) . size ( ) + 1 ] ; Arrays . fill ( andGroupCheck , false ) ; } } public final void addMemberAndGroup ( final AnalyzedToken token ) { if ( patternToken . hasAndGroup ( ) ) { List < PatternTokenMatcher > andGroupList = andGroup ; for ( int i = 0 ; i < andGroupList . size ( ) ; i ++ ) { if ( ! andGroupCheck [ i + 1 ] ) { final PatternTokenMatcher testAndGroup = andGroupList . get ( i ) ; if ( testAndGroup . isMatched ( token ) ) { andGroupCheck [ i + 1 ] = true ; } } } } } public final boolean checkAndGroup ( final boolean previousValue ) { if ( patternToken . hasAndGroup ( ) ) { boolean allConditionsMatch = true ; for ( final boolean testValue : andGroupCheck ) { allConditionsMatch &= testValue ; } return allConditionsMatch ; } return previousValue ; } public final boolean isMatchedByScopeNextException ( final AnalyzedToken token ) { return patternToken . isMatchedByScopeNextException ( token ) ; } public final boolean isExceptionMatchedCompletely ( final AnalyzedToken token ) { return patternToken . isExceptionMatchedCompletely ( token ) ; } public boolean hasPreviousException ( ) { return patternToken . hasPreviousException ( ) ; } public boolean isMatchedByPreviousException ( AnalyzedTokenReadings token ) { return patternToken . isMatchedByPreviousException ( token ) ; } @ Override public String toString ( ) { return "PatternTokenMatcher for " + basePatternToken ; } }
package org . languagetool . rules . patterns ; import java . io . IOException ; import java . util . * ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . chunking . ChunkTag ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . tools . StringTools ; public class PatternToken implements Cloneable { public static final String UNKNOWN_TAG = "UNKNOWN" ; private static final String CASE_INSENSITIVE = "(?iu)" ; private final boolean caseSensitive ; private final boolean stringRegExp ; private final List < PatternToken > andGroupList = new ArrayList < > ( ) ; private final List < PatternToken > orGroupList = new ArrayList < > ( ) ; private final boolean inflected ; private String stringToken ; private PosToken posToken ; private ChunkTag chunkTag ; private boolean negation ; private boolean testWhitespace ; private boolean whitespaceBefore ; private boolean isInsideMarker = true ; private List < PatternToken > exceptionList ; private boolean exceptionValidNext ; private boolean exceptionSet ; private boolean exceptionValidPrevious ; private List < PatternToken > previousExceptionList ; private int skip ; private int minOccurrence = 1 ; private int maxOccurrence = 1 ; private Pattern pattern ; private Match tokenReference ; private String referenceString ; private String phraseName ; private boolean testString ; private boolean unificationNeutral ; private boolean uniNegation ; private Map < String , List < String > > unificationFeatures ; private boolean isLastUnified ; public PatternToken ( final String token , final boolean caseSensitive , final boolean regExp , final boolean inflected ) { this . caseSensitive = caseSensitive ; this . stringRegExp = regExp ; this . inflected = inflected ; setStringElement ( token ) ; } @ Override public Object clone ( ) throws CloneNotSupportedException { return super . clone ( ) ; } public final boolean isMatched ( final AnalyzedToken token ) { if ( testWhitespace && ! isWhitespaceBefore ( token ) ) { return false ; } boolean posNegation = posToken != null && posToken . negation ; if ( testString ) { return isStringTokenMatched ( token ) ^ negation && isPosTokenMatched ( token ) ^ posNegation ; } else { return ! negation && isPosTokenMatched ( token ) ^ posNegation ; } } public final boolean isExceptionMatched ( final AnalyzedToken token ) { if ( exceptionSet ) { for ( final PatternToken testException : exceptionList ) { if ( ! testException . exceptionValidNext ) { if ( testException . isMatched ( token ) ) { return true ; } } } } return false ; } public final boolean isAndExceptionGroupMatched ( final AnalyzedToken token ) { for ( final PatternToken testAndGroup : andGroupList ) { if ( testAndGroup . isExceptionMatched ( token ) ) { return true ; } } return false ; } public final boolean isExceptionMatchedCompletely ( final AnalyzedToken token ) { return isExceptionMatched ( token ) || isAndExceptionGroupMatched ( token ) ; } public final void setAndGroupElement ( PatternToken andToken ) { andGroupList . add ( Objects . requireNonNull ( andToken ) ) ; } public final boolean hasAndGroup ( ) { return andGroupList . size ( ) > 0 ; } public final List < PatternToken > getAndGroup ( ) { return Collections . unmodifiableList ( andGroupList ) ; } public final void setOrGroupElement ( PatternToken orToken ) { orGroupList . add ( Objects . requireNonNull ( orToken ) ) ; } public final boolean hasOrGroup ( ) { return orGroupList . size ( ) > 0 ; } public final List < PatternToken > getOrGroup ( ) { return Collections . unmodifiableList ( orGroupList ) ; } public final boolean isMatchedByScopeNextException ( final AnalyzedToken token ) { if ( exceptionSet ) { for ( final PatternToken testException : exceptionList ) { if ( testException . exceptionValidNext ) { if ( testException . isMatched ( token ) ) { return true ; } } } } return false ; } public final boolean isMatchedByPreviousException ( final AnalyzedToken token ) { if ( exceptionValidPrevious ) { for ( final PatternToken testException : previousExceptionList ) { if ( ! testException . exceptionValidNext ) { if ( testException . isMatched ( token ) ) { return true ; } } } } return false ; } public final boolean isMatchedByPreviousException ( final AnalyzedTokenReadings prevToken ) { for ( AnalyzedToken analyzedToken : prevToken ) { if ( isMatchedByPreviousException ( analyzedToken ) ) { return true ; } } return false ; } public final boolean isSentenceStart ( ) { return posToken != null && JLanguageTool . SENTENCE_START_TAGNAME . equals ( posToken . posTag ) && ! posToken . negation ; } public final void setPosToken ( PosToken posToken ) { this . posToken = posToken ; } public final void setChunkTag ( final ChunkTag chunkTag ) { this . chunkTag = chunkTag ; } @ Nullable public final String getString ( ) { return stringToken ; } public final void setStringElement ( final String token ) { if ( token != null ) { stringToken = StringTools . trimWhitespace ( token ) ; } else { stringToken = null ; } testString = ! StringTools . isEmpty ( stringToken ) ; if ( testString && stringRegExp ) { String regToken = stringToken ; if ( ! caseSensitive ) { regToken = CASE_INSENSITIVE + stringToken ; } if ( ! "\\0" . equals ( token ) ) { pattern = Pattern . compile ( regToken ) ; } } } public final void setStringPosException ( final String token , final boolean regExp , final boolean inflected , final boolean negation , final boolean scopeNext , final boolean scopePrevious , final String posToken , final boolean posRegExp , final boolean posNegation , final Boolean caseSensitivity ) { final PatternToken exception = new PatternToken ( token , caseSensitivity == null ? caseSensitive : caseSensitivity , regExp , inflected ) ; exception . setNegation ( negation ) ; exception . setPosToken ( new PosToken ( posToken , posRegExp , posNegation ) ) ; exception . exceptionValidNext = scopeNext ; setException ( exception , scopePrevious ) ; } private void setException ( final PatternToken pToken , final boolean scopePrevious ) { exceptionValidPrevious |= scopePrevious ; if ( exceptionList == null && ! scopePrevious ) { exceptionList = new ArrayList < > ( ) ; } if ( previousExceptionList == null && scopePrevious ) { previousExceptionList = new ArrayList < > ( ) ; } if ( scopePrevious ) { previousExceptionList . add ( pToken ) ; } else { if ( ! exceptionSet ) { exceptionSet = true ; } exceptionList . add ( pToken ) ; } } public final void setOptionalException ( final String token , final boolean regExp , final boolean inflected , final boolean negation , final String posToken , final boolean posRegExp , final boolean posNegation ) { final PatternToken exception = new PatternToken ( token , caseSensitive , regExp , inflected ) ; exception . setNegation ( negation ) ; exception . setPosToken ( new PosToken ( posToken , posRegExp , posNegation ) ) ; setException ( exception , false ) ; } private boolean isPosTokenMatched ( final AnalyzedToken token ) { if ( posToken == null || posToken . posTag == null ) { return true ; } if ( token . getPOSTag ( ) == null ) { return posToken . posUnknown && token . hasNoTag ( ) ; } boolean match ; if ( posToken . regExp ) { final Matcher mPos = posToken . posPattern . matcher ( token . getPOSTag ( ) ) ; match = mPos . matches ( ) ; } else { match = posToken . posTag . equals ( token . getPOSTag ( ) ) ; } if ( ! match && posToken . posUnknown ) { match = token . hasNoTag ( ) ; } return match ; } boolean isStringTokenMatched ( final AnalyzedToken token ) { final String testToken = getTestToken ( token ) ; if ( stringRegExp ) { final Matcher m = pattern . matcher ( testToken ) ; return m . matches ( ) ; } if ( caseSensitive ) { return stringToken . equals ( testToken ) ; } return stringToken . equalsIgnoreCase ( testToken ) ; } private String getTestToken ( final AnalyzedToken token ) { if ( inflected ) { return token . getTokenInflected ( ) ; } return token . getToken ( ) ; } public final int getSkipNext ( ) { return skip ; } public final int getMinOccurrence ( ) { return minOccurrence ; } public final int getMaxOccurrence ( ) { return maxOccurrence ; } public final void setSkipNext ( final int i ) { skip = i ; } public final void setMinOccurrence ( final int i ) { if ( i != 0 && i != 1 ) { throw new IllegalArgumentException ( "minOccurrences must be 0 or 1: " + i ) ; } minOccurrence = i ; } public final void setMaxOccurrence ( final int i ) { if ( i == 0 ) { throw new IllegalArgumentException ( "maxOccurrences may not be 0" ) ; } maxOccurrence = i ; } public final boolean hasPreviousException ( ) { return exceptionValidPrevious ; } public final boolean hasNextException ( ) { return exceptionValidNext ; } public final void setNegation ( final boolean negation ) { this . negation = negation ; } public final boolean getNegation ( ) { return negation ; } public final boolean isReferenceElement ( ) { return tokenReference != null ; } public final void setMatch ( final Match match ) { tokenReference = Objects . requireNonNull ( match ) ; } public final Match getMatch ( ) { return tokenReference ; } public final PatternToken compile ( final AnalyzedTokenReadings token , final Synthesizer synth ) throws IOException { final PatternToken compiledPatternToken ; try { compiledPatternToken = ( PatternToken ) clone ( ) ; } catch ( CloneNotSupportedException e ) { throw new IllegalStateException ( "Could not clone element" , e ) ; } compiledPatternToken . doCompile ( token , synth ) ; return compiledPatternToken ; } void doCompile ( final AnalyzedTokenReadings token , final Synthesizer synth ) throws IOException { final MatchState matchState = tokenReference . createState ( synth , token ) ; if ( StringTools . isEmpty ( referenceString ) ) { referenceString = stringToken ; } String reference = "\\" + tokenReference . getTokenRef ( ) ; if ( tokenReference . setsPos ( ) ) { final String posReference = matchState . getTargetPosTag ( ) ; if ( posReference != null ) { setPosToken ( new PosToken ( posReference , tokenReference . posRegExp ( ) , negation ) ) ; } setStringElement ( referenceString . replace ( reference , "" ) ) ; } else { setStringElement ( referenceString . replace ( reference , matchState . toTokenString ( ) ) ) ; } } public final void setPhraseName ( final String id ) { phraseName = id ; } public final boolean isPartOfPhrase ( ) { return phraseName != null ; } public final boolean isCaseSensitive ( ) { return caseSensitive ; } public final boolean isRegularExpression ( ) { return stringRegExp ; } public final boolean isPOStagRegularExpression ( ) { return posToken != null && posToken . regExp ; } @ Nullable public final String getPOStag ( ) { return posToken != null ? posToken . posTag : null ; } @ Nullable public final ChunkTag getChunkTag ( ) { return chunkTag ; } public final boolean getPOSNegation ( ) { return posToken != null && posToken . negation ; } public final boolean isInflected ( ) { return inflected ; } @ Nullable public final String getPhraseName ( ) { return phraseName ; } public final boolean isUnified ( ) { return unificationFeatures != null ; } public final void setUnification ( final Map < String , List < String > > uniFeatures ) { unificationFeatures = Objects . requireNonNull ( uniFeatures ) ; } @ Nullable public final Map < String , List < String > > getUniFeatures ( ) { return unificationFeatures ; } public final void setUniNegation ( ) { uniNegation = true ; } public final boolean isUniNegated ( ) { return uniNegation ; } public final boolean isLastInUnification ( ) { return isLastUnified ; } public final void setLastInUnification ( ) { isLastUnified = true ; } public boolean isUnificationNeutral ( ) { return unificationNeutral ; } public void setUnificationNeutral ( ) { this . unificationNeutral = true ; } public final void setWhitespaceBefore ( final boolean isWhite ) { whitespaceBefore = isWhite ; testWhitespace = true ; } public boolean isInsideMarker ( ) { return isInsideMarker ; } public void setInsideMarker ( boolean isInsideMarker ) { this . isInsideMarker = isInsideMarker ; } public final void setExceptionSpaceBefore ( final boolean isWhite ) { if ( previousExceptionList != null && exceptionValidPrevious ) { previousExceptionList . get ( previousExceptionList . size ( ) - 1 ) . setWhitespaceBefore ( isWhite ) ; } else { if ( exceptionList != null ) { exceptionList . get ( exceptionList . size ( ) - 1 ) . setWhitespaceBefore ( isWhite ) ; } } } public final boolean isWhitespaceBefore ( final AnalyzedToken token ) { return whitespaceBefore == token . isWhitespaceBefore ( ) ; } public final List < PatternToken > getExceptionList ( ) { return exceptionList ; } public final List < PatternToken > getPreviousExceptionList ( ) { return previousExceptionList ; } public final boolean hasExceptionList ( ) { return exceptionList != null || previousExceptionList != null ; } public final boolean testWhitespace ( ) { return testWhitespace ; } @ Override public final String toString ( ) { final StringBuilder sb = new StringBuilder ( ) ; if ( negation ) { sb . append ( '!' ) ; } sb . append ( stringToken ) ; if ( phraseName != null ) { sb . append ( " {" ) ; sb . append ( phraseName ) ; sb . append ( '}' ) ; } if ( posToken != null ) { sb . append ( '/' ) ; sb . append ( posToken ) ; } if ( chunkTag != null ) { sb . append ( '/' ) ; sb . append ( chunkTag ) ; } if ( exceptionList != null ) { sb . append ( "/exceptions=" ) ; sb . append ( exceptionList ) ; } return sb . toString ( ) ; } public static class PosToken { private final String posTag ; private final boolean regExp ; private final boolean negation ; private final Pattern posPattern ; private final boolean posUnknown ; public PosToken ( String posTag , boolean regExp , boolean negation ) { this . posTag = posTag ; this . regExp = regExp ; this . negation = negation ; if ( regExp ) { posPattern = Pattern . compile ( posTag ) ; posUnknown = posPattern . matcher ( UNKNOWN_TAG ) . matches ( ) ; } else { posPattern = null ; posUnknown = UNKNOWN_TAG . equals ( posTag ) ; } } @ Override public String toString ( ) { return posTag ; } } }
package org . languagetool . rules . patterns ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . RuleMatch ; import java . util . * ; class RuleFilterEvaluator { private final RuleFilter filter ; RuleFilterEvaluator ( RuleFilter filter ) { this . filter = filter ; } RuleMatch runFilter ( String filterArgs , RuleMatch ruleMatch , AnalyzedTokenReadings [ ] patternTokens , List < Integer > tokenPositions ) { Map < String , String > args = getResolvedArguments ( filterArgs , patternTokens , tokenPositions ) ; return filter . acceptRuleMatch ( ruleMatch , args , patternTokens ) ; } Map < String , String > getResolvedArguments ( String filterArgs , AnalyzedTokenReadings [ ] patternTokens , List < Integer > tokenPositions ) { Map < String , String > result = new HashMap < > ( ) ; String [ ] arguments = filterArgs . split ( "\\s+" ) ; for ( String arg : arguments ) { int delimPos = arg . indexOf ( ':' ) ; if ( delimPos == - 1 ) { throw new RuntimeException ( "Invalid syntax for key/value, expected 'key:value', got: '" + arg + "'" ) ; } String key = arg . substring ( 0 , delimPos ) ; String val = arg . substring ( delimPos + 1 ) ; if ( val . startsWith ( "\\" ) ) { int refNumber = Integer . parseInt ( val . replace ( "\\" , "" ) ) ; if ( refNumber > tokenPositions . size ( ) ) { throw new RuntimeException ( "Your reference number " + refNumber + " is bigger than the number of tokens: " + tokenPositions . size ( ) ) ; } int correctedRef = getSkipCorrectedReference ( tokenPositions , refNumber ) ; if ( correctedRef >= patternTokens . length ) { throw new RuntimeException ( "Your reference number " + refNumber + " is bigger than number of matching tokens: " + patternTokens . length ) ; } if ( result . containsKey ( key ) ) { throw new RuntimeException ( "Duplicate key '" + key + "'" ) ; } result . put ( key , patternTokens [ correctedRef ] . getToken ( ) ) ; } else { result . put ( key , val ) ; } } return result ; } private int getSkipCorrectedReference ( List < Integer > tokenPositions , int refNumber ) { int correctedRef = 0 ; int i = 0 ; for ( int tokenPosition : tokenPositions ) { if ( i ++ >= refNumber ) { break ; } correctedRef += tokenPosition ; } return correctedRef - 1 ; } }
package org . languagetool . rules . patterns ; import java . lang . reflect . Constructor ; class RuleFilterCreator { RuleFilter getFilter ( String className ) { try { Class < ? > aClass = Class . forName ( className ) ; Constructor < ? > [ ] constructors = aClass . getConstructors ( ) ; if ( constructors . length != 1 ) { throw new RuntimeException ( "Constructor of filter class '" + className + "' must have exactly one constructor, but it has " + constructors . length ) ; } Constructor < ? > constructor = constructors [ 0 ] ; try { if ( constructor . getParameterTypes ( ) . length != 0 ) { throw new RuntimeException ( "Constructor of filter class '" + className + "' must not have arguments: " + constructor ) ; } Object filter = constructor . newInstance ( ) ; if ( filter instanceof RuleFilter ) { return ( RuleFilter ) filter ; } else { throw new RuntimeException ( "Filter class '" + className + "' must implement interface " + RuleFilter . class . getSimpleName ( ) ) ; } } catch ( Exception e ) { throw new RuntimeException ( "Could not create filter class using constructor " + constructor , e ) ; } } catch ( ClassNotFoundException e ) { throw new RuntimeException ( "Could not find filter class: '" + className + "' - make sure to use a fully qualified class name like 'org.languagetool.rules.MyFilter'" ) ; } } }
package org . languagetool . rules . patterns . bitext ; import java . io . IOException ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import javax . xml . parsers . ParserConfigurationException ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . patterns . FalseFriendRuleLoader ; import org . languagetool . rules . patterns . PatternRule ; import org . xml . sax . SAXException ; public class FalseFriendsAsBitextLoader { public List < BitextPatternRule > getFalseFriendsAsBitext ( final String filename , final Language motherTongue , final Language language ) throws ParserConfigurationException , SAXException , IOException { final FalseFriendRuleLoader ruleLoader = new FalseFriendRuleLoader ( ) ; final List < BitextPatternRule > bRules = new ArrayList < > ( ) ; final List < PatternRule > rules1 = ruleLoader . getRules ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( filename ) , motherTongue , language ) ; final List < PatternRule > rules2 = ruleLoader . getRules ( JLanguageTool . getDataBroker ( ) . getFromRulesDirAsStream ( filename ) , language , motherTongue ) ; final Map < String , PatternRule > srcRules = new HashMap < > ( ) ; for ( PatternRule rule : rules1 ) { srcRules . put ( rule . getId ( ) , rule ) ; } for ( PatternRule rule : rules2 ) { if ( srcRules . containsKey ( rule . getId ( ) ) ) { final BitextPatternRule bRule = new BitextPatternRule ( srcRules . get ( rule . getId ( ) ) , rule ) ; bRule . setSourceLanguage ( motherTongue ) ; bRule . setCategory ( rule . getCategory ( ) ) ; bRules . add ( bRule ) ; } } return bRules ; } }
package org . languagetool . rules . patterns . bitext ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . bitext . StringPair ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . rules . bitext . IncorrectBitextExample ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . Match ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . rules . patterns . PatternRuleHandler ; import org . xml . sax . Attributes ; import org . xml . sax . SAXException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; class BitextPatternRuleHandler extends PatternRuleHandler { private static final String SOURCE = "source" ; private static final String TARGET = "target" ; private static final String SRC_EXAMPLE = "srcExample" ; private static final String TRG_EXAMPLE = "trgExample" ; private PatternRule srcRule ; private PatternRule trgRule ; private IncorrectExample trgExample ; private IncorrectExample srcExample ; private Language srcLang ; private List < StringPair > correctExamples = new ArrayList < > ( ) ; private List < IncorrectBitextExample > incorrectExamples = new ArrayList < > ( ) ; private final List < BitextPatternRule > rules = new ArrayList < > ( ) ; List < BitextPatternRule > getBitextRules ( ) { return rules ; } @ Override public void startElement ( final String namespaceURI , final String lName , final String qName , final Attributes attrs ) throws SAXException { switch ( qName ) { case RULES : final String languageStr = attrs . getValue ( "targetLang" ) ; language = Languages . getLanguageForShortName ( languageStr ) ; break ; case RULE : super . startElement ( namespaceURI , lName , qName , attrs ) ; correctExamples = new ArrayList < > ( ) ; incorrectExamples = new ArrayList < > ( ) ; break ; case TARGET : startPattern ( attrs ) ; break ; case SOURCE : srcLang = Languages . getLanguageForShortName ( attrs . getValue ( "lang" ) ) ; break ; default : super . startElement ( namespaceURI , lName , qName , attrs ) ; break ; } } @ Override public void endElement ( final String namespaceURI , final String sName , final String qName ) throws SAXException { switch ( qName ) { case RULE : trgRule . setMessage ( message . toString ( ) ) ; if ( suggestionMatches != null ) { for ( final Match m : suggestionMatches ) { trgRule . addSuggestionMatch ( m ) ; } if ( phrasePatternTokens . size ( ) <= 1 ) { suggestionMatches . clear ( ) ; } } final BitextPatternRule bRule = new BitextPatternRule ( srcRule , trgRule ) ; bRule . setCorrectBitextExamples ( correctExamples ) ; bRule . setIncorrectBitextExamples ( incorrectExamples ) ; bRule . setSourceLanguage ( srcLang ) ; rules . add ( bRule ) ; break ; case SRC_EXAMPLE : srcExample = setExample ( ) ; break ; case TRG_EXAMPLE : trgExample = setExample ( ) ; break ; case SOURCE : srcRule = finalizeRule ( ) ; break ; case TARGET : trgRule = finalizeRule ( ) ; break ; case EXAMPLE : if ( inCorrectExample ) { correctExamples . add ( new StringPair ( srcExample . getExample ( ) , trgExample . getExample ( ) ) ) ; } else if ( inIncorrectExample ) { final StringPair examplePair = new StringPair ( srcExample . getExample ( ) , trgExample . getExample ( ) ) ; if ( trgExample . getCorrections ( ) == null ) { incorrectExamples . add ( new IncorrectBitextExample ( examplePair ) ) ; } else { final List < String > corrections = trgExample . getCorrections ( ) ; incorrectExamples . add ( new IncorrectBitextExample ( examplePair , corrections ) ) ; } } inCorrectExample = false ; inIncorrectExample = false ; break ; default : super . endElement ( namespaceURI , sName , qName ) ; break ; } } private IncorrectExample setExample ( ) { IncorrectExample example = null ; if ( inCorrectExample ) { example = new IncorrectExample ( correctExample . toString ( ) ) ; } else if ( inIncorrectExample ) { final String [ ] corrections = exampleCorrection . toString ( ) . split ( "\\|" ) ; if ( corrections . length > 0 && corrections [ 0 ] . length ( ) > 0 ) { example = new IncorrectExample ( incorrectExample . toString ( ) , Arrays . asList ( corrections ) ) ; } else { example = new IncorrectExample ( incorrectExample . toString ( ) ) ; } } correctExample = new StringBuilder ( ) ; incorrectExample = new StringBuilder ( ) ; exampleCorrection = new StringBuilder ( ) ; return example ; } private PatternRule finalizeRule ( ) { PatternRule rule = null ; phraseElementInit ( ) ; if ( phrasePatternTokens . isEmpty ( ) ) { rule = new PatternRule ( id , language , patternTokens , name , "" , shortMessage . toString ( ) ) ; prepareRule ( rule ) ; } else { if ( ! patternTokens . isEmpty ( ) ) { for ( List < PatternToken > ph : phrasePatternTokens ) { ph . addAll ( new ArrayList < > ( patternTokens ) ) ; } } for ( List < PatternToken > phrasePatternToken : phrasePatternTokens ) { processElement ( phrasePatternToken ) ; rule = new PatternRule ( id , language , phrasePatternToken , name , message . toString ( ) , shortMessage . toString ( ) , "" , phrasePatternTokens . size ( ) > 1 ) ; prepareRule ( rule ) ; } } patternTokens . clear ( ) ; if ( phrasePatternTokens != null ) { phrasePatternTokens . clear ( ) ; } startPositionCorrection = 0 ; endPositionCorrection = 0 ; return rule ; } }
package org . languagetool . rules . patterns . bitext ; import org . languagetool . rules . patterns . PatternRule ; import org . xml . sax . helpers . DefaultHandler ; import javax . xml . parsers . SAXParser ; import javax . xml . parsers . SAXParserFactory ; import java . io . IOException ; import java . io . InputStream ; import java . util . List ; public class BitextPatternRuleLoader extends DefaultHandler { public final List < BitextPatternRule > getRules ( final InputStream is , final String filename ) throws IOException { final List < BitextPatternRule > rules ; try { final BitextPatternRuleHandler handler = new BitextPatternRuleHandler ( ) ; final SAXParserFactory factory = SAXParserFactory . newInstance ( ) ; final SAXParser saxParser = factory . newSAXParser ( ) ; saxParser . getXMLReader ( ) . setFeature ( "http://apache.org/xml/features/nonvalidating/load-external-dtd" , false ) ; saxParser . parse ( is , handler ) ; rules = handler . getBitextRules ( ) ; return rules ; } catch ( final Exception e ) { throw new IOException ( "Cannot load or parse '" + filename + "'" , e ) ; } } }
package org . languagetool . rules . patterns . bitext ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . bitext . BitextRule ; import org . languagetool . rules . patterns . PatternRule ; public class BitextPatternRule extends BitextRule { private final PatternRule srcRule ; private final PatternRule trgRule ; BitextPatternRule ( final PatternRule src , final PatternRule trg ) { srcRule = src ; trgRule = trg ; } public PatternRule getSrcRule ( ) { return srcRule ; } public PatternRule getTrgRule ( ) { return trgRule ; } @ Override public String getDescription ( ) { return srcRule . getDescription ( ) ; } @ Override public String getMessage ( ) { return trgRule . getMessage ( ) ; } @ Override public String getId ( ) { return srcRule . getId ( ) ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { return new RuleMatch [ 0 ] ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sourceSentence , AnalyzedSentence targetSentence ) throws IOException { if ( srcRule . match ( sourceSentence ) . length > 0 ) { return trgRule . match ( targetSentence ) ; } return new RuleMatch [ 0 ] ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . nl ; import org . languagetool . rules . AbstractDateCheckFilter ; import java . util . Calendar ; import java . util . Locale ; public class DateCheckFilter extends AbstractDateCheckFilter { @ Override protected Calendar getCalendar ( ) { return Calendar . getInstance ( Locale . UK ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected int getDayOfWeek ( String dayStr ) { String day = dayStr . toLowerCase ( ) ; if ( day . equals ( "zo" ) || day . equals ( "zondag" ) ) return Calendar . SUNDAY ; if ( day . equals ( "ma" ) || day . equals ( "maandag" ) ) return Calendar . MONDAY ; if ( day . equals ( "di" ) || day . equals ( "dinsdag" ) ) return Calendar . TUESDAY ; if ( day . equals ( "wo" ) || day . equals ( "woensdag" ) ) return Calendar . WEDNESDAY ; if ( day . equals ( "do" ) || day . equals ( "donderdag" ) ) return Calendar . THURSDAY ; if ( day . equals ( "vr" ) || day . equals ( "vrijdag" ) ) return Calendar . FRIDAY ; if ( day . equals ( "za" ) || day . equals ( "zaterdag" ) ) return Calendar . SATURDAY ; throw new RuntimeException ( "Could not find day of week for '" + dayStr + "'" ) ; } @ SuppressWarnings ( "ControlFlowStatementWithoutBraces" ) @ Override protected String getDayOfWeek ( Calendar date ) { String englishDay = date . getDisplayName ( Calendar . DAY_OF_WEEK , Calendar . LONG , Locale . UK ) ; if ( englishDay . equals ( "Sunday" ) ) return "zondag" ; if ( englishDay . equals ( "Monday" ) ) return "maandag" ; if ( englishDay . equals ( "Tuesday" ) ) return "dinsdag" ; if ( englishDay . equals ( "Wednesday" ) ) return "woensdag" ; if ( englishDay . equals ( "Thursday" ) ) return "donderdag" ; if ( englishDay . equals ( "Friday" ) ) return "vrijdag" ; if ( englishDay . equals ( "Saturday" ) ) return "zaterdag" ; return "" ; } @ SuppressWarnings ( { "ControlFlowStatementWithoutBraces" , "MagicNumber" } ) @ Override protected int getMonth ( String monthStr ) { String mon = monthStr . toLowerCase ( ) ; if ( mon . startsWith ( "jan" ) ) return 1 ; if ( mon . startsWith ( "feb" ) ) return 2 ; if ( mon . startsWith ( "maa" ) ) return 3 ; if ( mon . startsWith ( "mrt" ) ) return 3 ; if ( mon . startsWith ( "mar" ) ) return 3 ; if ( mon . startsWith ( "apr" ) ) return 4 ; if ( mon . startsWith ( "mei" ) ) return 5 ; if ( mon . startsWith ( "jun" ) ) return 6 ; if ( mon . startsWith ( "jul" ) ) return 7 ; if ( mon . startsWith ( "aug" ) ) return 8 ; if ( mon . startsWith ( "sep" ) ) return 9 ; if ( mon . startsWith ( "okt" ) ) return 10 ; if ( mon . startsWith ( "nov" ) ) return 11 ; if ( mon . startsWith ( "dec" ) ) return 12 ; throw new RuntimeException ( "Could not find month '" + monthStr + "'" ) ; } }
package org . languagetool . rules . bitext ; import java . util . Collections ; import java . util . List ; import org . jetbrains . annotations . Nullable ; import org . languagetool . bitext . StringPair ; public class IncorrectBitextExample { private final StringPair example ; private final List < String > corrections ; public IncorrectBitextExample ( final StringPair example ) { this ( example , ( List < String > ) null ) ; } public IncorrectBitextExample ( final StringPair example , final List < String > corrections ) { this . example = example ; this . corrections = Collections . unmodifiableList ( corrections ) ; } public StringPair getExample ( ) { return example ; } @ Nullable public List < String > getCorrections ( ) { return corrections ; } @ Override public String toString ( ) { return example . getSource ( ) + "/ " + example . getTarget ( ) + " " + corrections ; } }
package org . languagetool . rules . bitext ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . RuleMatch ; public class DifferentLengthRule extends BitextRule { private static final int MAX_SKEW = 250 ; private static final int MIN_SKEW = 30 ; public DifferentLengthRule ( ) { setLocQualityIssueType ( ITSIssueType . Length ) ; } @ Override public String getDescription ( ) { return "Check if translation length is similar to source length" ; } @ Override public String getId ( ) { return "TRANSLATION_LENGTH" ; } @ Override public String getMessage ( ) { return "Source and target translation lengths are very different" ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sourceText , AnalyzedSentence targetText ) throws IOException { if ( isLengthDifferent ( getPureText ( sourceText ) , getPureText ( targetText ) ) ) { final AnalyzedTokenReadings [ ] tokens = targetText . getTokens ( ) ; final int endPos = tokens [ tokens . length - 1 ] . getStartPos ( ) + tokens [ tokens . length - 1 ] . getToken ( ) . length ( ) ; return new RuleMatch [ ] { new RuleMatch ( this , 0 , endPos , getMessage ( ) ) } ; } return new RuleMatch [ 0 ] ; } private boolean isLengthDifferent ( final String src , final String trg ) { final double skew = ( ( double ) src . length ( ) / ( double ) trg . length ( ) ) * 100.00 ; return skew > MAX_SKEW || skew < MIN_SKEW ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . bitext ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . RuleMatch ; public class SameTranslationRule extends BitextRule { public SameTranslationRule ( ) { setLocQualityIssueType ( ITSIssueType . Untranslated ) ; } @ Override public String getDescription ( ) { return "Check if translation is the same as source" ; } @ Override public String getId ( ) { return "SAME_TRANSLATION" ; } @ Override public String getMessage ( ) { return "Source and target translation are the same" ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sourceText , AnalyzedSentence targetText ) throws IOException { if ( sourceText . getTokensWithoutWhitespace ( ) . length > 3 && getPureText ( sourceText ) . equals ( getPureText ( targetText ) ) ) { final AnalyzedTokenReadings [ ] tokens = targetText . getTokens ( ) ; final int endPos = tokens [ tokens . length - 1 ] . getEndPos ( ) ; return new RuleMatch [ ] { new RuleMatch ( this , 1 , endPos , getMessage ( ) ) } ; } return new RuleMatch [ 0 ] ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . bitext ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class DifferentPunctuationRule extends BitextRule { public DifferentPunctuationRule ( ) { setLocQualityIssueType ( ITSIssueType . Typographical ) ; } @ Override public String getDescription ( ) { return "Check if translation has ending punctuation different from the source" ; } @ Override public String getId ( ) { return "DIFFERENT_PUNCTUATION" ; } @ Override public String getMessage ( ) { return "Source and target translation have different ending punctuation" ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sourceText , AnalyzedSentence targetText ) throws IOException { final AnalyzedTokenReadings [ ] translationTokens = targetText . getTokens ( ) ; final AnalyzedTokenReadings [ ] sourceTokens = sourceText . getTokens ( ) ; AnalyzedTokenReadings lastTransTokenObj = translationTokens [ translationTokens . length - 1 ] ; String lastTransToken = lastTransTokenObj . getToken ( ) ; if ( ( "." . equals ( lastTransToken ) || "?" . equals ( lastTransToken ) || "!" . equals ( lastTransToken ) ) && ! lastTransToken . equals ( sourceTokens [ sourceTokens . length - 1 ] . getToken ( ) ) ) { final int endPos = lastTransTokenObj . getEndPos ( ) ; return new RuleMatch [ ] { new RuleMatch ( this , 1 , endPos , getMessage ( ) ) } ; } return new RuleMatch [ 0 ] ; } @ Override public void reset ( ) { } }
package org . languagetool . rules . bitext ; import java . io . IOException ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . bitext . StringPair ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; public abstract class BitextRule extends Rule { public static List < Class < ? extends BitextRule > > getRelevantRules ( ) { return Arrays . asList ( DifferentLengthRule . class , SameTranslationRule . class , DifferentPunctuationRule . class ) ; } @ Override public abstract String getDescription ( ) ; @ Override public abstract String getId ( ) ; @ Override public abstract void reset ( ) ; public abstract String getMessage ( ) ; public abstract RuleMatch [ ] match ( AnalyzedSentence sourceText , AnalyzedSentence targetText ) throws IOException ; private List < StringPair > correctExamples ; private List < IncorrectBitextExample > incorrectExamples ; private Language sourceLanguage ; @ Nullable @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { return null ; } public final void setSourceLanguage ( final Language lang ) { sourceLanguage = lang ; } public final Language getSourceLanguage ( ) { return sourceLanguage ; } public final void setCorrectBitextExamples ( final List < StringPair > correctExamples ) { this . correctExamples = correctExamples ; } public final List < StringPair > getCorrectBitextExamples ( ) { return correctExamples ; } public final void setIncorrectBitextExamples ( final List < IncorrectBitextExample > incorrectExamples ) { this . incorrectExamples = Collections . unmodifiableList ( incorrectExamples ) ; } public final List < IncorrectBitextExample > getIncorrectBitextExamples ( ) { return incorrectExamples ; } protected String getPureText ( AnalyzedSentence sentence ) { final StringBuilder sb = new StringBuilder ( ) ; for ( AnalyzedTokenReadings token : sentence . getTokens ( ) ) { sb . append ( token . getToken ( ) ) ; } return sb . toString ( ) ; } }
package org . languagetool . rules . spelling ; import org . languagetool . Language ; import org . languagetool . rules . Rule ; import org . languagetool . rules . patterns . PatternRule ; import java . util . * ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; public class SuggestionExtractor { private static final Pattern SUGGESTION_PATTERN = Pattern . compile ( "<suggestion.*?>(.*?)</suggestion>" ) ; private static final Pattern BACK_REFERENCE_PATTERN = Pattern . compile ( "\\\\" + "\\d+" ) ; public SuggestionExtractor ( ) { } public List < String > getSuggestionTokens ( Rule rule , Language language ) { final List < String > wordsToBeIgnored = new ArrayList < > ( ) ; if ( rule instanceof PatternRule ) { final PatternRule patternRule = ( PatternRule ) rule ; final String message = patternRule . getMessage ( ) ; final List < String > suggestions = getSimpleSuggestions ( message ) ; final List < String > tokens = getSuggestionTokens ( suggestions , language ) ; wordsToBeIgnored . addAll ( tokens ) ; } return wordsToBeIgnored ; } List < String > getSimpleSuggestions ( String message ) { final Matcher matcher = SUGGESTION_PATTERN . matcher ( message ) ; int startPos = 0 ; final List < String > suggestions = new ArrayList < > ( ) ; while ( matcher . find ( startPos ) ) { final String suggestion = matcher . group ( 1 ) ; startPos = matcher . end ( ) ; if ( isSimpleSuggestion ( suggestion ) ) { suggestions . add ( suggestion ) ; } } return suggestions ; } private boolean isSimpleSuggestion ( String suggestion ) { if ( suggestion . contains ( "<match" ) ) { return false ; } final Matcher matcher = BACK_REFERENCE_PATTERN . matcher ( suggestion ) ; return ! matcher . find ( ) ; } private List < String > getSuggestionTokens ( List < String > suggestions , Language language ) { final List < String > tokens = new ArrayList < > ( ) ; for ( String suggestion : suggestions ) { final List < String > suggestionTokens = language . getWordTokenizer ( ) . tokenize ( suggestion ) ; for ( String suggestionToken : suggestionTokens ) { if ( ! suggestionToken . trim ( ) . isEmpty ( ) ) { tokens . add ( suggestionToken ) ; } } } return tokens ; } }
package org . languagetool . rules . spelling ; import java . io . IOException ; import java . io . InputStream ; import java . util . * ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tokenizers . WordTokenizer ; public abstract class SpellingCheckRule extends Rule { public static final String LANGUAGETOOL = "LanguageTool" ; public static final String LANGUAGETOOL_FX = "LanguageToolFx" ; protected final Language language ; private static final String SPELLING_IGNORE_FILE = "/hunspell/ignore.txt" ; private static final String SPELLING_FILE = "/hunspell/spelling.txt" ; private static final String SPELLING_PROHIBIT_FILE = "/hunspell/prohibit.txt" ; private final Set < String > wordsToBeIgnored = new HashSet < > ( ) ; private final Set < String > wordsToBeProhibited = new HashSet < > ( ) ; private boolean wordsWithDotsPresent = false ; private boolean considerIgnoreWords = true ; private boolean convertsCase = false ; public SpellingCheckRule ( final ResourceBundle messages , final Language language ) { super ( messages ) ; this . language = language ; setLocQualityIssueType ( ITSIssueType . Misspelling ) ; } @ Override public abstract String getId ( ) ; @ Override public abstract String getDescription ( ) ; @ Override public abstract RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException ; @ Override public boolean isDictionaryBasedSpellingRule ( ) { return true ; } @ Override public void reset ( ) { } public void addIgnoreTokens ( List < String > tokens ) { wordsToBeIgnored . addAll ( tokens ) ; } public void setConsiderIgnoreWords ( boolean considerIgnoreWords ) { this . considerIgnoreWords = considerIgnoreWords ; } protected List < String > getAdditionalTopSuggestions ( List < String > suggestions , String word ) throws IOException { List < String > moreSuggestions = new ArrayList < > ( ) ; if ( "Languagetool" . equals ( word ) && ! suggestions . contains ( LANGUAGETOOL ) ) { moreSuggestions . add ( LANGUAGETOOL ) ; } return moreSuggestions ; } protected List < String > getAdditionalSuggestions ( List < String > suggestions , String word ) { return Collections . emptyList ( ) ; } protected boolean ignoreToken ( AnalyzedTokenReadings [ ] tokens , int idx ) throws IOException { List < String > words = new ArrayList < > ( ) ; for ( AnalyzedTokenReadings token : tokens ) { words . add ( token . getToken ( ) ) ; } return ignoreWord ( words , idx ) ; } protected boolean ignoreWord ( String word ) throws IOException { if ( ! considerIgnoreWords ) { return false ; } if ( ! wordsWithDotsPresent ) { word = word . endsWith ( "." ) ? word . substring ( 0 , word . length ( ) - 1 ) : word ; } return ( wordsToBeIgnored . contains ( word ) || ( convertsCase && wordsToBeIgnored . contains ( word . toLowerCase ( language . getLocale ( ) ) ) ) ) ; } protected boolean ignoreWord ( List < String > words , int idx ) throws IOException { return ignoreWord ( words . get ( idx ) ) ; } public boolean isConvertsCase ( ) { return convertsCase ; } public void setConvertsCase ( boolean convertsCase ) { this . convertsCase = convertsCase ; } protected boolean isUrl ( String token ) { for ( String protocol : WordTokenizer . getProtocols ( ) ) { if ( token . startsWith ( protocol + "://" ) ) { return true ; } } return false ; } protected void init ( ) throws IOException { loadWordsToBeIgnored ( getIgnoreFileName ( ) ) ; loadWordsToBeIgnored ( getSpellingFileName ( ) ) ; loadWordsToBeProhibited ( getProhibitFileName ( ) ) ; } protected String getIgnoreFileName ( ) { return language . getShortName ( ) + SPELLING_IGNORE_FILE ; } protected String getSpellingFileName ( ) { return language . getShortName ( ) + SPELLING_FILE ; } protected String getProhibitFileName ( ) { return language . getShortName ( ) + SPELLING_PROHIBIT_FILE ; } protected boolean isProhibited ( String word ) { return wordsToBeProhibited . contains ( word ) ; } protected void filterSuggestions ( List < String > suggestions ) { for ( int i = 0 ; i < suggestions . size ( ) ; i ++ ) { if ( isProhibited ( suggestions . get ( i ) ) ) { suggestions . remove ( i ) ; } } } private void loadWordsToBeIgnored ( String ignoreFile ) throws IOException { if ( ! JLanguageTool . getDataBroker ( ) . resourceExists ( ignoreFile ) ) { return ; } try ( InputStream inputStream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( ignoreFile ) ; Scanner scanner = new Scanner ( inputStream , "utf-8" ) ) { while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ; if ( isComment ( line ) ) { continue ; } failOnSpace ( ignoreFile , line ) ; addIgnoreWords ( line , wordsToBeIgnored ) ; if ( line . endsWith ( "." ) ) { wordsWithDotsPresent = true ; } } } } protected void addIgnoreWords ( String line , Set < String > wordsToBeIgnored ) { wordsToBeIgnored . add ( line ) ; } protected List < String > expandLine ( String line ) { return Collections . singletonList ( line ) ; } private void loadWordsToBeProhibited ( String prohibitFile ) throws IOException { if ( ! JLanguageTool . getDataBroker ( ) . resourceExists ( prohibitFile ) ) { return ; } try ( InputStream inputStream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( prohibitFile ) ; Scanner scanner = new Scanner ( inputStream , "utf-8" ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; if ( isComment ( line ) ) { continue ; } failOnSpace ( prohibitFile , line ) ; wordsToBeProhibited . addAll ( expandLine ( line ) ) ; } } } private boolean isComment ( String line ) { return line . startsWith ( "#" ) ; } private void failOnSpace ( String fileName , String line ) { if ( line . contains ( " " ) ) { throw new RuntimeException ( "No space expected in " + fileName + ": '" + line + "'" ) ; } } }
package org . languagetool . rules . spelling . morfologik ; import morfologik . speller . Speller ; import morfologik . stemming . Dictionary ; import org . languagetool . JLanguageTool ; import org . languagetool . rules . spelling . SpellingCheckRule ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . nio . charset . CharacterCodingException ; import java . util . ArrayList ; import java . util . List ; public class MorfologikSpeller { private final Dictionary dictionary ; private final Speller speller ; public MorfologikSpeller ( String fileInClassPath , int maxEditDistance ) throws IOException { this ( Dictionary . read ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( fileInClassPath ) ) , maxEditDistance ) ; } public MorfologikSpeller ( String fileInClassPath ) throws IOException { this ( fileInClassPath , 1 ) ; } MorfologikSpeller ( Dictionary dictionary , int maxEditDistance ) { if ( maxEditDistance <= 0 ) { throw new RuntimeException ( "maxEditDistance must be > 0: " + maxEditDistance ) ; } this . dictionary = dictionary ; speller = new Speller ( dictionary , maxEditDistance ) ; } public boolean isMisspelled ( String word ) { return word . length ( ) > 0 && ! SpellingCheckRule . LANGUAGETOOL . equals ( word ) && ! SpellingCheckRule . LANGUAGETOOL_FX . equals ( word ) && speller . isMisspelled ( word ) ; } public List < String > getSuggestions ( String word ) { final List < String > suggestions = new ArrayList < > ( ) ; try { suggestions . addAll ( speller . findReplacements ( word ) ) ; suggestions . addAll ( speller . replaceRunOnWords ( word ) ) ; } catch ( CharacterCodingException e ) { throw new RuntimeException ( e ) ; } if ( dictionary . metadata . isConvertingCase ( ) && StringTools . startsWithUppercase ( word ) ) { for ( int i = 0 ; i < suggestions . size ( ) ; i ++ ) { String uppercaseFirst = StringTools . uppercaseFirstChar ( suggestions . get ( i ) ) ; int auxIndex = suggestions . indexOf ( uppercaseFirst ) ; if ( auxIndex > i ) { suggestions . remove ( auxIndex ) ; } if ( auxIndex > - 1 && auxIndex < i ) { suggestions . remove ( i ) ; i -- ; } else { suggestions . set ( i , uppercaseFirst ) ; } } } return suggestions ; } public boolean convertsCase ( ) { return speller . convertsCase ( ) ; } }
package org . languagetool . rules . spelling . morfologik ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . Category ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . spelling . SpellingCheckRule ; import java . io . IOException ; import java . util . * ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; public abstract class MorfologikSpellerRule extends SpellingCheckRule { protected MorfologikMultiSpeller speller1 ; protected MorfologikMultiSpeller speller2 ; protected Locale conversionLocale ; private boolean ignoreTaggedWords = false ; private boolean checkCompound = false ; private Pattern compoundRegex = Pattern . compile ( "-" ) ; public abstract String getFileName ( ) ; @ Override public abstract String getId ( ) ; public MorfologikSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; super . setCategory ( new Category ( messages . getString ( "category_typo" ) ) ) ; this . conversionLocale = conversionLocale != null ? conversionLocale : Locale . getDefault ( ) ; init ( ) ; setLocQualityIssueType ( ITSIssueType . Misspelling ) ; } @ Override public String getDescription ( ) { return messages . getString ( "desc_spelling" ) ; } public void setLocale ( Locale locale ) { conversionLocale = locale ; } public void setIgnoreTaggedWords ( ) { ignoreTaggedWords = true ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; if ( speller1 == null ) { String binaryDict = null ; if ( JLanguageTool . getDataBroker ( ) . resourceExists ( getFileName ( ) ) ) { binaryDict = getFileName ( ) ; } if ( binaryDict != null ) { initSpeller ( binaryDict ) ; } else { return toRuleMatchArray ( ruleMatches ) ; } } int idx = - 1 ; for ( AnalyzedTokenReadings token : tokens ) { idx ++ ; if ( canBeIgnored ( tokens , idx , token ) ) { continue ; } final String word = token . getAnalyzedToken ( 0 ) . getToken ( ) ; if ( tokenizingPattern ( ) == null ) { ruleMatches . addAll ( getRuleMatches ( word , token . getStartPos ( ) ) ) ; } else { int index = 0 ; final Matcher m = tokenizingPattern ( ) . matcher ( word ) ; while ( m . find ( ) ) { final String match = word . subSequence ( index , m . start ( ) ) . toString ( ) ; ruleMatches . addAll ( getRuleMatches ( match , token . getStartPos ( ) + index ) ) ; index = m . end ( ) ; } if ( index == 0 ) { ruleMatches . addAll ( getRuleMatches ( word , token . getStartPos ( ) ) ) ; } else { ruleMatches . addAll ( getRuleMatches ( word . subSequence ( index , word . length ( ) ) . toString ( ) , token . getStartPos ( ) + index ) ) ; } } } return toRuleMatchArray ( ruleMatches ) ; } private void initSpeller ( String binaryDict ) throws IOException { String plainTextDict = null ; if ( JLanguageTool . getDataBroker ( ) . resourceExists ( getSpellingFileName ( ) ) ) { plainTextDict = getSpellingFileName ( ) ; } if ( plainTextDict != null ) { speller1 = new MorfologikMultiSpeller ( binaryDict , plainTextDict , 1 ) ; speller2 = new MorfologikMultiSpeller ( binaryDict , plainTextDict , 2 ) ; setConvertsCase ( speller1 . convertsCase ( ) ) ; } else { throw new RuntimeException ( "Could not find ignore spell file in path: " + getSpellingFileName ( ) ) ; } } private boolean canBeIgnored ( AnalyzedTokenReadings [ ] tokens , int idx , AnalyzedTokenReadings token ) throws IOException { return token . isSentenceStart ( ) || token . isImmunized ( ) || token . isIgnoredBySpeller ( ) || isUrl ( token . getToken ( ) ) || ( ignoreTaggedWords && token . isTagged ( ) ) || ignoreToken ( tokens , idx ) ; } protected boolean isMisspelled ( MorfologikMultiSpeller speller , String word ) { if ( ! speller . isMisspelled ( word ) ) { return false ; } if ( checkCompound ) { if ( compoundRegex . matcher ( word ) . find ( ) ) { String [ ] words = compoundRegex . split ( word ) ; for ( String singleWord : words ) { if ( speller . isMisspelled ( singleWord ) ) { return true ; } } return false ; } } return true ; } protected List < RuleMatch > getRuleMatches ( final String word , final int startPos ) throws IOException { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; if ( isMisspelled ( speller1 , word ) || isProhibited ( word ) ) { final RuleMatch ruleMatch = new RuleMatch ( this , startPos , startPos + word . length ( ) , messages . getString ( "spelling" ) , messages . getString ( "desc_spelling_short" ) ) ; List < String > suggestions = speller1 . getSuggestions ( word ) ; if ( suggestions . size ( ) == 0 && word . length ( ) >= 5 ) { suggestions . addAll ( speller2 . getSuggestions ( word ) ) ; } suggestions . addAll ( 0 , getAdditionalTopSuggestions ( suggestions , word ) ) ; suggestions . addAll ( getAdditionalSuggestions ( suggestions , word ) ) ; if ( ! suggestions . isEmpty ( ) ) { filterSuggestions ( suggestions ) ; ruleMatch . setSuggestedReplacements ( orderSuggestions ( suggestions , word ) ) ; } ruleMatches . add ( ruleMatch ) ; } return ruleMatches ; } @ Nullable public Pattern tokenizingPattern ( ) { return null ; } protected List < String > orderSuggestions ( List < String > suggestions , String word ) { return suggestions ; } protected void setCheckCompound ( boolean checkCompound ) { this . checkCompound = checkCompound ; } protected void setCompoundRegex ( String compoundRegex ) { this . compoundRegex = Pattern . compile ( compoundRegex ) ; } }
package org . languagetool . rules . spelling . morfologik ; import morfologik . fsa . CFSA2Serializer ; import morfologik . fsa . FSA ; import morfologik . fsa . FSABuilder ; import morfologik . stemming . Dictionary ; import org . jetbrains . annotations . Nullable ; import org . languagetool . JLanguageTool ; import java . io . * ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; public class MorfologikMultiSpeller { private final List < MorfologikSpeller > spellers = new ArrayList < > ( ) ; private final boolean convertsCase ; public MorfologikMultiSpeller ( String binaryDictPath , String plainTextPath , int maxEditDistance ) throws IOException { this ( binaryDictPath , new BufferedReader ( new InputStreamReader ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( plainTextPath ) , "utf-8" ) ) , maxEditDistance ) ; if ( ! plainTextPath . endsWith ( ".txt" ) ) { throw new RuntimeException ( "Unsupported dictionary, plain text file needs to have suffix .txt: " + plainTextPath ) ; } } public MorfologikMultiSpeller ( String binaryDictPath , BufferedReader plainTextReader , int maxEditDistance ) throws IOException { MorfologikSpeller speller = getBinaryDict ( binaryDictPath , maxEditDistance ) ; spellers . add ( speller ) ; convertsCase = speller . convertsCase ( ) ; String infoFile = binaryDictPath . replace ( ".dict" , ".info" ) ; MorfologikSpeller plainTextDict = getPlainTextDictOrNull ( plainTextReader , infoFile , maxEditDistance ) ; if ( plainTextDict != null ) { spellers . add ( plainTextDict ) ; } } private MorfologikSpeller getBinaryDict ( String binaryDictPath , int maxEditDistance ) throws IOException { if ( binaryDictPath . endsWith ( ".dict" ) ) { return new MorfologikSpeller ( binaryDictPath , maxEditDistance ) ; } else { throw new RuntimeException ( "Unsupported dictionary, binary Morfologik file needs to have suffix .dict: " + binaryDictPath ) ; } } @ Nullable private MorfologikSpeller getPlainTextDictOrNull ( BufferedReader plainTextReader , String infoFile , int maxEditDistance ) throws IOException { List < byte [ ] > lines = getLines ( plainTextReader ) ; if ( lines . size ( ) == 0 ) { return null ; } Dictionary dictionary = getDictionary ( lines , infoFile ) ; return new MorfologikSpeller ( dictionary , maxEditDistance ) ; } private List < byte [ ] > getLines ( BufferedReader br ) throws IOException { List < byte [ ] > lines = new ArrayList < > ( ) ; String line ; while ( ( line = br . readLine ( ) ) != null ) { if ( ! line . startsWith ( "#" ) ) { lines . add ( line . getBytes ( "utf-8" ) ) ; } } return lines ; } private Dictionary getDictionary ( List < byte [ ] > lines , String infoFile ) throws IOException { Collections . sort ( lines , FSABuilder . LEXICAL_ORDERING ) ; FSA fsa = FSABuilder . build ( lines ) ; ByteArrayOutputStream fsaOutStream = new CFSA2Serializer ( ) . serialize ( fsa , new ByteArrayOutputStream ( ) ) ; ByteArrayInputStream fsaInStream = new ByteArrayInputStream ( fsaOutStream . toByteArray ( ) ) ; return Dictionary . readAndClose ( fsaInStream , JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( infoFile ) ) ; } public boolean isMisspelled ( String word ) { for ( MorfologikSpeller speller : spellers ) { if ( ! speller . isMisspelled ( word ) ) { return false ; } } return true ; } public List < String > getSuggestions ( String word ) { List < String > result = new ArrayList < > ( ) ; for ( MorfologikSpeller speller : spellers ) { List < String > suggestions = speller . getSuggestions ( word ) ; for ( String suggestion : suggestions ) { if ( ! result . contains ( suggestion ) ) { result . add ( suggestion ) ; } } } return result ; } public boolean convertsCase ( ) { return convertsCase ; } }
package org . languagetool . tagging . nl ; import java . util . Locale ; import org . languagetool . tagging . BaseTagger ; public class DutchTagger extends BaseTagger { @ Override public String getManualAdditionsFileName ( ) { return "/nl/added.txt" ; } public DutchTagger ( ) { super ( "/nl/dutch.dict" , new Locale ( "nl" ) ) ; } }
package org . languagetool . rules . spelling . hunspell ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikMultiSpeller ; import org . languagetool . tokenizers . CompoundWordTokenizer ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . util . * ; public abstract class CompoundAwareHunspellRule extends HunspellRule { private static final int MAX_SUGGESTIONS = 20 ; private final CompoundWordTokenizer wordSplitter ; private final MorfologikMultiSpeller morfoSpeller ; protected abstract void filterForLanguage ( List < String > suggestions ) ; public CompoundAwareHunspellRule ( ResourceBundle messages , Language language , CompoundWordTokenizer wordSplitter , MorfologikMultiSpeller morfoSpeller ) { super ( messages , language ) ; this . wordSplitter = wordSplitter ; this . morfoSpeller = morfoSpeller ; } @ Override public List < String > getSuggestions ( String word ) throws IOException { if ( needsInit ) { init ( ) ; } final List < String > candidates = getCandidates ( word ) ; final List < String > suggestions = getCorrectWords ( candidates ) ; final List < String > noSplitSuggestions = morfoSpeller . getSuggestions ( word ) ; if ( StringTools . startsWithUppercase ( word ) && ! StringTools . isAllUppercase ( word ) ) { final List < String > noSplitLowercaseSuggestions = morfoSpeller . getSuggestions ( word . toLowerCase ( ) ) ; int pos = noSplitSuggestions . size ( ) == 0 ? 0 : 1 ; for ( String suggestion : noSplitLowercaseSuggestions ) { noSplitSuggestions . add ( pos , StringTools . uppercaseFirstChar ( suggestion ) ) ; pos = Math . min ( pos + 2 , noSplitSuggestions . size ( ) ) ; } } suggestions . addAll ( 0 , noSplitSuggestions ) ; filterDupes ( suggestions ) ; filterForLanguage ( suggestions ) ; final List < String > sortedSuggestions = sortSuggestionByQuality ( word , suggestions ) ; return sortedSuggestions . subList ( 0 , Math . min ( MAX_SUGGESTIONS , sortedSuggestions . size ( ) ) ) ; } protected List < String > getCandidates ( String word ) { return wordSplitter . tokenize ( word ) ; } protected List < String > getCandidates ( List < String > parts ) { int partCount = 0 ; final List < String > candidates = new ArrayList < > ( ) ; for ( String part : parts ) { if ( hunspellDict . misspelled ( part ) ) { boolean doUpperCase = partCount > 0 && ! StringTools . startsWithUppercase ( part ) ; List < String > suggestions = morfoSpeller . getSuggestions ( doUpperCase ? StringTools . uppercaseFirstChar ( part ) : part ) ; if ( suggestions . size ( ) == 0 ) { suggestions = morfoSpeller . getSuggestions ( doUpperCase ? StringTools . lowercaseFirstChar ( part ) : part ) ; } for ( String suggestion : suggestions ) { final List < String > partsCopy = new ArrayList < > ( parts ) ; if ( partCount > 0 && parts . get ( partCount ) . startsWith ( "-" ) && parts . get ( partCount ) . length ( ) > 1 ) { partsCopy . set ( partCount , "-" + StringTools . uppercaseFirstChar ( suggestion . substring ( 1 ) ) ) ; } else if ( partCount > 0 && ! parts . get ( partCount - 1 ) . endsWith ( "-" ) ) { partsCopy . set ( partCount , suggestion . toLowerCase ( ) ) ; } else { partsCopy . set ( partCount , suggestion ) ; } String candidate = StringTools . listToString ( partsCopy , "" ) ; if ( ! isMisspelled ( candidate ) ) { candidates . add ( candidate ) ; } } } partCount ++ ; } return candidates ; } protected List < String > sortSuggestionByQuality ( String misspelling , List < String > suggestions ) { return suggestions ; } private void filterDupes ( List < String > words ) { final Set < String > seen = new HashSet < > ( ) ; final Iterator < String > iterator = words . iterator ( ) ; while ( iterator . hasNext ( ) ) { final String word = iterator . next ( ) ; if ( seen . contains ( word ) ) { iterator . remove ( ) ; } seen . add ( word ) ; } } private List < String > getCorrectWords ( List < String > wordsOrPhrases ) { final List < String > result = new ArrayList < > ( ) ; for ( String wordOrPhrase : wordsOrPhrases ) { final String [ ] words = tokenizeText ( wordOrPhrase ) ; boolean wordIsOkay = true ; for ( String word : words ) { if ( hunspellDict . misspelled ( word ) ) { wordIsOkay = false ; break ; } } if ( wordIsOkay ) { result . add ( wordOrPhrase ) ; } } return result ; } }
package org . languagetool . rules . spelling . hunspell ; import java . io . File ; import java . io . FileNotFoundException ; import java . io . FileOutputStream ; import java . io . IOException ; import java . io . InputStream ; import java . io . UnsupportedEncodingException ; import java . nio . CharBuffer ; import java . nio . charset . CharacterCodingException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . HashMap ; import java . util . List ; import java . util . Scanner ; import com . sun . jna . Native ; import com . sun . jna . Pointer ; import com . sun . jna . ptr . PointerByReference ; public class Hunspell { private static Hunspell hunspell = null ; private HunspellLibrary hsl = null ; private String libFile ; public static Hunspell getInstance ( ) throws UnsatisfiedLinkError , UnsupportedOperationException { return getInstance ( null ) ; } public static Hunspell getInstance ( String libDir ) throws UnsatisfiedLinkError , UnsupportedOperationException { if ( hunspell != null ) { return hunspell ; } hunspell = new Hunspell ( libDir ) ; return hunspell ; } protected void tryLoad ( String libFile ) throws UnsupportedOperationException { hsl = ( HunspellLibrary ) Native . loadLibrary ( libFile , HunspellLibrary . class ) ; } protected Hunspell ( String libDir ) throws UnsatisfiedLinkError , UnsupportedOperationException { libFile = libDir != null ? libDir + "/" + libName ( ) : libNameBare ( ) ; try { hsl = ( HunspellLibrary ) Native . loadLibrary ( libFile , HunspellLibrary . class ) ; } catch ( UnsatisfiedLinkError urgh ) { libFile = libName ( ) ; InputStream is = Hunspell . class . getResourceAsStream ( "/" + libFile ) ; if ( is == null ) { throw new UnsatisfiedLinkError ( "Can't find " + libFile + " in the filesystem nor in the classpath\n" + urgh ) ; } File lib ; FileOutputStream fos = null ; try { lib = File . createTempFile ( "jna" , "." + libFile ) ; lib . deleteOnExit ( ) ; fos = new FileOutputStream ( lib ) ; int count ; byte [ ] buf = new byte [ 1024 ] ; while ( ( count = is . read ( buf , 0 , buf . length ) ) > 0 ) { fos . write ( buf , 0 , count ) ; } } catch ( IOException e ) { throw new Error ( "Failed to create temporary file for " + libFile , e ) ; } finally { try { is . close ( ) ; } catch ( IOException e ) { } if ( fos != null ) { try { fos . close ( ) ; } catch ( IOException e ) { } } } hsl = ( HunspellLibrary ) Native . loadLibrary ( lib . getAbsolutePath ( ) , HunspellLibrary . class ) ; } } public String getLibFile ( ) { return libFile ; } public static String libName ( ) throws UnsupportedOperationException { String os = System . getProperty ( "os.name" ) . toLowerCase ( ) ; if ( os . startsWith ( "windows" ) ) { return libNameBare ( ) + ".dll" ; } else if ( os . startsWith ( "mac os x" ) ) { return libNameBare ( ) + ".jnilib" ; } else { return "lib" + libNameBare ( ) + ".so" ; } } public static String libNameBare ( ) throws UnsupportedOperationException { String os = System . getProperty ( "os.name" ) . toLowerCase ( ) ; String arch = System . getProperty ( "os.arch" ) . toLowerCase ( ) ; boolean x86 = arch . equals ( "x86" ) || arch . equals ( "i386" ) || arch . equals ( "i686" ) ; boolean amd64 = arch . equals ( "x86_64" ) || arch . equals ( "amd64" ) || arch . equals ( "ia64n" ) ; if ( os . startsWith ( "windows" ) ) { if ( x86 ) { return "hunspell-win-x86-32" ; } if ( amd64 ) { return "hunspell-win-x86-64" ; } } else if ( os . startsWith ( "mac os x" ) ) { if ( x86 ) { return "hunspell-darwin-x86-32" ; } if ( amd64 ) { return "hunspell-darwin-x86-64" ; } if ( arch . equals ( "ppc" ) ) { return "hunspell-darwin-ppc-32" ; } } else if ( os . startsWith ( "linux" ) ) { if ( x86 ) { return "hunspell-linux-x86-32" ; } if ( amd64 ) { return "hunspell-linux-x86-64" ; } } else if ( os . startsWith ( "sunos" ) ) { } throw new UnsupportedOperationException ( "Unknown OS/arch: " + os + "/" + arch ) ; } private HashMap < String , Dictionary > map = new HashMap < > ( ) ; private static CharBuffer ensureCapacity ( CharBuffer buffer , int capacity ) { if ( buffer == null || buffer . capacity ( ) < capacity ) { buffer = CharBuffer . allocate ( capacity ) ; } return buffer ; } public Dictionary getDictionary ( String baseFileName ) throws IOException { if ( map . containsKey ( baseFileName ) ) { return map . get ( baseFileName ) ; } else { Dictionary d = new Dictionary ( baseFileName ) ; map . put ( baseFileName , d ) ; return d ; } } public void destroyDictionary ( String baseFileName ) { if ( map . containsKey ( baseFileName ) ) { map . remove ( baseFileName ) ; } } public class Dictionary { private Pointer hunspellDict = null ; private String encoding ; private final String wordChars ; Dictionary ( String baseFileName ) throws IOException { File dic = new File ( baseFileName + ".dic" ) ; File aff = new File ( baseFileName + ".aff" ) ; if ( ! dic . canRead ( ) || ! aff . canRead ( ) ) { throw new FileNotFoundException ( "The dictionary files " + baseFileName + "(.aff|.dic) could not be read" ) ; } hunspellDict = hsl . Hunspell_create ( aff . toString ( ) , dic . toString ( ) ) ; encoding = hsl . Hunspell_get_dic_encoding ( hunspellDict ) ; if ( "microsoft1251" . equals ( encoding ) ) { encoding = "windows-1251" ; } else if ( "ISCII-DEVANAGARI" . equals ( encoding ) ) { encoding = "ISCII91" ; } wordChars = getWordCharsFromFile ( aff ) ; } public void destroy ( ) { if ( hsl != null && hunspellDict != null ) { hsl . Hunspell_destroy ( hunspellDict ) ; hunspellDict = null ; } } public String getWordChars ( ) { return wordChars ; } public boolean misspelled ( String word ) { try { final byte [ ] wordAsBytes = stringToBytes ( word ) ; if ( wordAsBytes . length == 0 && word . length ( ) > 0 ) { return true ; } return ( hsl . Hunspell_spell ( hunspellDict , wordAsBytes ) == 0 ) ; } catch ( UnsupportedEncodingException e ) { return true ; } } protected byte [ ] stringToBytes ( String str ) throws UnsupportedEncodingException { byte [ ] strBytes = str . getBytes ( encoding ) ; byte [ ] zeroTerminated = Arrays . copyOf ( strBytes , strBytes . length + 1 ) ; zeroTerminated [ zeroTerminated . length - 1 ] = '\u0000' ; return zeroTerminated ; } public List < String > suggest ( String word ) throws CharacterCodingException { List < String > res = new ArrayList < > ( ) ; try { int suggestionsCount = 0 ; PointerByReference suggestions = new PointerByReference ( ) ; final byte [ ] wordAsBytes = stringToBytes ( word ) ; if ( wordAsBytes . length == 0 && word . length ( ) > 0 ) { return res ; } suggestionsCount = hsl . Hunspell_suggest ( hunspellDict , suggestions , stringToBytes ( word ) ) ; if ( suggestionsCount == 0 ) { return res ; } Pointer [ ] pointerArray = suggestions . getValue ( ) . getPointerArray ( 0 , suggestionsCount ) ; for ( int i = 0 ; i < suggestionsCount ; i ++ ) { long len = pointerArray [ i ] . indexOf ( 0 , ( byte ) 0 ) ; if ( len != - 1 ) { if ( len > Integer . MAX_VALUE ) { throw new RuntimeException ( "String improperly terminated: " + len ) ; } byte [ ] data = pointerArray [ i ] . getByteArray ( 0 , ( int ) len ) ; res . add ( new String ( data , encoding ) ) ; } } } catch ( UnsupportedEncodingException ex ) { } return res ; } private String getWordCharsFromFile ( final File affixFile ) throws IOException { String affixWordChars = "" ; try ( Scanner scanner = new Scanner ( affixFile , encoding ) ) { while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) . trim ( ) ; if ( line . startsWith ( "WORDCHARS " ) ) { affixWordChars = line . substring ( "WORDCHARS " . length ( ) ) ; } } } return affixWordChars ; } public void addWord ( final String word ) throws UnsupportedEncodingException { hsl . Hunspell_add ( hunspellDict , stringToBytes ( word ) ) ; } } }
package org . languagetool . rules . spelling . hunspell ; import com . sun . jna . Library ; import com . sun . jna . Pointer ; import com . sun . jna . ptr . PointerByReference ; public interface HunspellLibrary extends Library { public Pointer Hunspell_create ( String affpath , String dpath ) ; public void Hunspell_destroy ( Pointer pHunspell ) ; public int Hunspell_spell ( Pointer pHunspell , byte [ ] word ) ; public String Hunspell_get_dic_encoding ( Pointer pHunspell ) ; public int Hunspell_suggest ( Pointer pHunspell , PointerByReference slst , byte [ ] word ) ; public int Hunspell_add ( Pointer pHunspell , byte [ ] word ) ; }
package org . languagetool . rules . spelling . hunspell ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; public class HunspellNoSuggestionRule extends HunspellRule { public static final String RULE_ID = "HUNSPELL_NO_SUGGEST_RULE" ; public HunspellNoSuggestionRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; } @ Override public String getId ( ) { return RULE_ID ; } @ Override public String getDescription ( ) { return messages . getString ( "desc_spelling_no_suggestions" ) ; } @ Override public List < String > getSuggestions ( String word ) throws IOException { return new ArrayList < > ( ) ; } }
package org . languagetool . rules . spelling . hunspell ; import java . io . File ; import java . io . FileOutputStream ; import java . io . IOException ; import java . io . InputStream ; import java . io . OutputStream ; import java . net . URISyntaxException ; import java . net . URL ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import java . util . regex . Pattern ; import com . google . common . base . Charsets ; import com . google . common . io . Resources ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . Category ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . spelling . SpellingCheckRule ; public class HunspellRule extends SpellingCheckRule { public static final String RULE_ID = "HUNSPELL_RULE" ; protected boolean needsInit = true ; protected Hunspell . Dictionary hunspellDict = null ; private static final String NON_ALPHABETIC = "[^\\p{L}]" ; private Pattern nonWordPattern ; public HunspellRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; super . setCategory ( new Category ( messages . getString ( "category_typo" ) ) ) ; } @ Override public String getId ( ) { return RULE_ID ; } @ Override public String getDescription ( ) { return messages . getString ( "desc_spelling" ) ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; if ( needsInit ) { init ( ) ; } if ( hunspellDict == null ) { return toRuleMatchArray ( ruleMatches ) ; } final String [ ] tokens = tokenizeText ( getSentenceTextWithoutUrlsAndImmunizedTokens ( sentence ) ) ; int len = sentence . getTokens ( ) [ 1 ] . getStartPos ( ) ; for ( int i = 0 ; i < tokens . length ; i ++ ) { String word = tokens [ i ] ; if ( ignoreWord ( Arrays . asList ( tokens ) , i ) || ignoreWord ( word ) ) { len += word . length ( ) + 1 ; continue ; } if ( isMisspelled ( word ) ) { final RuleMatch ruleMatch = new RuleMatch ( this , len , len + word . length ( ) , messages . getString ( "spelling" ) , messages . getString ( "desc_spelling_short" ) ) ; final List < String > suggestions = getSuggestions ( word ) ; suggestions . addAll ( 0 , getAdditionalTopSuggestions ( suggestions , word ) ) ; suggestions . addAll ( getAdditionalSuggestions ( suggestions , word ) ) ; if ( ! suggestions . isEmpty ( ) ) { filterSuggestions ( suggestions ) ; ruleMatch . setSuggestedReplacements ( suggestions ) ; } ruleMatches . add ( ruleMatch ) ; } len += word . length ( ) + 1 ; } return toRuleMatchArray ( ruleMatches ) ; } boolean isMisspelled ( String word ) { boolean isAlphabetic = true ; if ( word . length ( ) == 1 ) { isAlphabetic = Character . isAlphabetic ( word . charAt ( 0 ) ) ; } return ( isAlphabetic && ! word . equals ( "--" ) && hunspellDict . misspelled ( word ) ) || isProhibited ( removeTrailingDot ( word ) ) ; } private String removeTrailingDot ( String word ) { if ( word . endsWith ( "." ) ) { return word . substring ( 0 , word . length ( ) - 1 ) ; } return word ; } public List < String > getSuggestions ( String word ) throws IOException { if ( needsInit ) { init ( ) ; } return hunspellDict . suggest ( word ) ; } protected String [ ] tokenizeText ( final String sentence ) { return nonWordPattern . split ( sentence ) ; } private String getSentenceTextWithoutUrlsAndImmunizedTokens ( final AnalyzedSentence sentence ) { final StringBuilder sb = new StringBuilder ( ) ; final AnalyzedTokenReadings [ ] sentenceTokens = sentence . getTokens ( ) ; for ( int i = 1 ; i < sentenceTokens . length ; i ++ ) { final String token = sentenceTokens [ i ] . getToken ( ) ; if ( isUrl ( token ) || sentenceTokens [ i ] . isImmunized ( ) || sentenceTokens [ i ] . isIgnoredBySpeller ( ) ) { for ( int j = 0 ; j < token . length ( ) ; j ++ ) { sb . append ( ' ' ) ; } } else { sb . append ( token ) ; } } return sb . toString ( ) ; } @ Override protected void init ( ) throws IOException { super . init ( ) ; final String langCountry ; if ( language . getCountries ( ) . length > 0 ) { langCountry = language . getShortName ( ) + "_" + language . getCountries ( ) [ 0 ] ; } else { langCountry = language . getShortName ( ) ; } final String shortDicPath = "/" + language . getShortName ( ) + "/hunspell/" + langCountry + ".dic" ; String wordChars = "" ; if ( JLanguageTool . getDataBroker ( ) . resourceExists ( shortDicPath ) ) { final String path = getDictionaryPath ( langCountry , shortDicPath ) ; if ( "" . equals ( path ) ) { hunspellDict = null ; } else { hunspellDict = Hunspell . getInstance ( ) . getDictionary ( path ) ; if ( ! "" . equals ( hunspellDict . getWordChars ( ) ) ) { wordChars = "(?![" + hunspellDict . getWordChars ( ) . replace ( "-" , "\\-" ) + "])" ; } addIgnoreWords ( ) ; } } nonWordPattern = Pattern . compile ( wordChars + NON_ALPHABETIC ) ; needsInit = false ; } private void addIgnoreWords ( ) throws IOException { hunspellDict . addWord ( SpellingCheckRule . LANGUAGETOOL ) ; hunspellDict . addWord ( SpellingCheckRule . LANGUAGETOOL_FX ) ; URL ignoreUrl = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( getIgnoreFileName ( ) ) ; List < String > ignoreLines = Resources . readLines ( ignoreUrl , Charsets . UTF_8 ) ; for ( String ignoreLine : ignoreLines ) { if ( ! ignoreLine . startsWith ( "#" ) ) { hunspellDict . addWord ( ignoreLine ) ; } } } private String getDictionaryPath ( final String dicName , final String originalPath ) throws IOException { final URL dictURL = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( originalPath ) ; String dictionaryPath ; if ( "jar" . equals ( dictURL . getProtocol ( ) ) || "vfs" . equals ( dictURL . getProtocol ( ) ) ) { final File tempDir = new File ( System . getProperty ( "java.io.tmpdir" ) ) ; File tempDicFile = new File ( tempDir , dicName + ".dic" ) ; JLanguageTool . addTemporaryFile ( tempDicFile ) ; try ( InputStream dicStream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( originalPath ) ) { fileCopy ( dicStream , tempDicFile ) ; } File tempAffFile = new File ( tempDir , dicName + ".aff" ) ; JLanguageTool . addTemporaryFile ( tempAffFile ) ; try ( InputStream affStream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( originalPath . replaceFirst ( ".dic$" , ".aff" ) ) ) { fileCopy ( affStream , tempAffFile ) ; } dictionaryPath = tempDir . getAbsolutePath ( ) + "/" + dicName ; } else { final int suffixLength = ".dic" . length ( ) ; try { dictionaryPath = new File ( dictURL . toURI ( ) ) . getAbsolutePath ( ) ; dictionaryPath = dictionaryPath . substring ( 0 , dictionaryPath . length ( ) - suffixLength ) ; } catch ( URISyntaxException e ) { return "" ; } } return dictionaryPath ; } private void fileCopy ( final InputStream in , final File targetFile ) throws IOException { try ( OutputStream out = new FileOutputStream ( targetFile ) ) { final byte [ ] buf = new byte [ 1024 ] ; int len ; while ( ( len = in . read ( buf ) ) > 0 ) { out . write ( buf , 0 , len ) ; } in . close ( ) ; } } }
package org . languagetool . tagging ; import java . io . BufferedReader ; import java . io . IOException ; import java . io . InputStream ; import java . io . InputStreamReader ; import java . util . * ; import org . languagetool . synthesis . ManualSynthesizer ; import org . languagetool . tools . StringTools ; public class ManualTagger implements WordTagger { private final Map < String , List < TaggedWord > > mapping ; public ManualTagger ( final InputStream inputStream ) throws IOException { mapping = loadMapping ( inputStream , "utf8" ) ; } private Map < String , List < TaggedWord > > loadMapping ( final InputStream inputStream , final String encoding ) throws IOException { final Map < String , List < TaggedWord > > map = new HashMap < > ( ) ; try ( InputStreamReader reader = new InputStreamReader ( inputStream , encoding ) ; BufferedReader br = new BufferedReader ( reader ) ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { if ( StringTools . isEmpty ( line ) || line . charAt ( 0 ) == '#' ) { continue ; } final String [ ] parts = line . split ( "\t" ) ; if ( parts . length != 3 ) { throw new IOException ( "Unknown line format when loading manual tagger dictionary, expected three tab-separated fields: '" + line + "'" ) ; } List < TaggedWord > terms = map . get ( parts [ 0 ] ) ; if ( terms == null ) { terms = new ArrayList < > ( ) ; } terms . add ( new TaggedWord ( parts [ 1 ] , parts [ 2 ] ) ) ; map . put ( parts [ 0 ] , terms ) ; } } return map ; } @ Override public List < TaggedWord > tag ( String word ) { List < TaggedWord > lookedUpTerms = mapping . get ( word ) ; if ( lookedUpTerms != null ) { return Collections . unmodifiableList ( lookedUpTerms ) ; } else { return Collections . emptyList ( ) ; } } }
package org . languagetool . tagging ; public final class TaggedWord { private final String lemma ; private final String posTag ; public TaggedWord ( String lemma , String posTag ) { this . lemma = lemma ; this . posTag = posTag ; } public String getLemma ( ) { return lemma ; } public String getPosTag ( ) { return posTag ; } @ Override public String toString ( ) { return lemma + "/" + posTag ; } }
package org . languagetool . tagging ; import morfologik . stemming . Dictionary ; import morfologik . stemming . DictionaryLookup ; import morfologik . stemming . IStemmer ; import morfologik . stemming . WordData ; import org . languagetool . JLanguageTool ; import java . io . IOException ; import java . net . URL ; import java . util . ArrayList ; import java . util . List ; import java . util . Objects ; public class MorfologikTagger implements WordTagger { private final URL dictUrl ; private Dictionary dictionary ; public MorfologikTagger ( String dictPath ) { dictUrl = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( Objects . requireNonNull ( dictPath ) ) ; } MorfologikTagger ( URL dictUrl ) { this . dictUrl = Objects . requireNonNull ( dictUrl ) ; } private synchronized Dictionary getDictionary ( ) throws IOException { if ( dictionary == null ) { dictionary = Dictionary . read ( dictUrl ) ; } return dictionary ; } @ Override public List < TaggedWord > tag ( String word ) { List < TaggedWord > result = new ArrayList < > ( ) ; try { IStemmer dictLookup = new DictionaryLookup ( getDictionary ( ) ) ; List < WordData > lookup = dictLookup . lookup ( word ) ; for ( WordData wordData : lookup ) { String tag = wordData . getTag ( ) == null ? null : wordData . getTag ( ) . toString ( ) ; if ( dictionary . metadata . isFrequencyIncluded ( ) && tag != null && tag . length ( ) > 2 ) { tag = tag . substring ( 0 , tag . length ( ) - 2 ) ; } String stem = wordData . getStem ( ) == null ? null : wordData . getStem ( ) . toString ( ) ; TaggedWord taggedWord = new TaggedWord ( stem , tag ) ; result . add ( taggedWord ) ; } } catch ( IOException e ) { throw new RuntimeException ( "Could not tag word '" + word + "'" , e ) ; } return result ; } }
package org . languagetool . tagging ; import java . util . ArrayList ; import java . util . List ; public class CombiningTagger implements WordTagger { private final WordTagger tagger1 ; private final WordTagger tagger2 ; private final boolean overwriteWithSecondTagger ; public CombiningTagger ( WordTagger tagger1 , WordTagger tagger2 , boolean overwriteWithSecondTagger ) { this . tagger1 = tagger1 ; this . tagger2 = tagger2 ; this . overwriteWithSecondTagger = overwriteWithSecondTagger ; } @ Override public List < TaggedWord > tag ( String word ) { List < TaggedWord > result = new ArrayList < > ( ) ; result . addAll ( tagger2 . tag ( word ) ) ; if ( ! ( overwriteWithSecondTagger && result . size ( ) > 0 ) ) { result . addAll ( tagger1 . tag ( word ) ) ; } return result ; } }
package org . languagetool . tagging ; import java . io . IOException ; import java . io . InputStream ; import java . net . URL ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; import morfologik . stemming . Dictionary ; import morfologik . stemming . WordData ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . tools . StringTools ; public abstract class BaseTagger implements Tagger { protected final WordTagger wordTagger ; protected final Locale conversionLocale ; private final boolean tagLowercaseWithUppercase ; private final String dictionaryPath ; private final Dictionary dictionary ; @ Nullable public abstract String getManualAdditionsFileName ( ) ; public BaseTagger ( String filename ) { this ( filename , Locale . getDefault ( ) , true ) ; } public BaseTagger ( String filename , Locale conversionLocale ) { this ( filename , conversionLocale , true ) ; } public BaseTagger ( String filename , Locale locale , boolean tagLowercaseWithUppercase ) { this . dictionaryPath = filename ; this . conversionLocale = locale ; this . tagLowercaseWithUppercase = tagLowercaseWithUppercase ; this . wordTagger = initWordTagger ( filename ) ; try { URL url = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( filename ) ; this . dictionary = Dictionary . read ( url ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not load dictionary from " + filename , e ) ; } } public String getDictionaryPath ( ) { return dictionaryPath ; } public boolean overwriteWithManualTagger ( ) { return false ; } protected WordTagger getWordTagger ( ) { return wordTagger ; } private WordTagger initWordTagger ( String filename ) { MorfologikTagger morfologikTagger = new MorfologikTagger ( filename ) ; try { String manualFileName = getManualAdditionsFileName ( ) ; if ( manualFileName != null ) { try ( InputStream stream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( manualFileName ) ) { ManualTagger manualTagger = new ManualTagger ( stream ) ; return new CombiningTagger ( morfologikTagger , manualTagger , overwriteWithManualTagger ( ) ) ; } } else { return morfologikTagger ; } } catch ( IOException e ) { throw new RuntimeException ( "Could not load manual tagger data from " + getManualAdditionsFileName ( ) , e ) ; } } protected Dictionary getDictionary ( ) { return dictionary ; } @ Override public List < AnalyzedTokenReadings > tag ( final List < String > sentenceTokens ) throws IOException { final List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; int pos = 0 ; for ( String word : sentenceTokens ) { final List < AnalyzedToken > l = getAnalyzedTokens ( word ) ; tokenReadings . add ( new AnalyzedTokenReadings ( l , pos ) ) ; pos += word . length ( ) ; } return tokenReadings ; } protected List < AnalyzedTokenReadings > tag ( String token ) throws IOException { final List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; final List < AnalyzedToken > l = getAnalyzedTokens ( token ) ; tokenReadings . add ( new AnalyzedTokenReadings ( l , 0 ) ) ; return tokenReadings ; } protected List < AnalyzedToken > getAnalyzedTokens ( String word ) { final List < AnalyzedToken > result = new ArrayList < > ( ) ; final String lowerWord = word . toLowerCase ( conversionLocale ) ; final boolean isLowercase = word . equals ( lowerWord ) ; final boolean isMixedCase = StringTools . isMixedCase ( word ) ; List < AnalyzedToken > taggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( word ) ) ; List < AnalyzedToken > lowerTaggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( lowerWord ) ) ; addTokens ( taggerTokens , result ) ; if ( ! isLowercase && ! isMixedCase ) { addTokens ( lowerTaggerTokens , result ) ; } if ( tagLowercaseWithUppercase ) { if ( lowerTaggerTokens . isEmpty ( ) && taggerTokens . isEmpty ( ) ) { if ( isLowercase ) { List < AnalyzedToken > upperTaggerTokens = asAnalyzedTokenListForTaggedWords ( word , getWordTagger ( ) . tag ( StringTools . uppercaseFirstChar ( word ) ) ) ; if ( ! upperTaggerTokens . isEmpty ( ) ) { addTokens ( upperTaggerTokens , result ) ; } } } } if ( result . isEmpty ( ) ) { List < AnalyzedToken > additionalTaggedTokens = additionalTags ( word , getWordTagger ( ) ) ; addTokens ( additionalTaggedTokens , result ) ; } if ( result . isEmpty ( ) ) { result . add ( new AnalyzedToken ( word , null , null ) ) ; } return result ; } protected List < AnalyzedToken > asAnalyzedTokenList ( final String word , final List < WordData > wdList ) { final List < AnalyzedToken > aTokenList = new ArrayList < > ( ) ; for ( WordData wd : wdList ) { aTokenList . add ( asAnalyzedToken ( word , wd ) ) ; } return aTokenList ; } protected List < AnalyzedToken > asAnalyzedTokenListForTaggedWords ( final String word , List < TaggedWord > taggedWords ) { final List < AnalyzedToken > aTokenList = new ArrayList < > ( ) ; for ( TaggedWord taggedWord : taggedWords ) { aTokenList . add ( asAnalyzedToken ( word , taggedWord ) ) ; } return aTokenList ; } protected AnalyzedToken asAnalyzedToken ( final String word , final WordData wd ) { String tag = StringTools . asString ( wd . getTag ( ) ) ; if ( dictionary . metadata . isFrequencyIncluded ( ) && tag . length ( ) > 2 ) { tag = tag . substring ( 0 , tag . length ( ) - 2 ) ; } return new AnalyzedToken ( word , tag , StringTools . asString ( wd . getStem ( ) ) ) ; } private AnalyzedToken asAnalyzedToken ( String word , TaggedWord taggedWord ) { return new AnalyzedToken ( word , taggedWord . getPosTag ( ) , taggedWord . getLemma ( ) ) ; } private void addTokens ( final List < AnalyzedToken > taggedTokens , final List < AnalyzedToken > l ) { if ( taggedTokens != null ) { for ( AnalyzedToken at : taggedTokens ) { l . add ( at ) ; } } } @ Override public final AnalyzedTokenReadings createNullToken ( final String token , final int startPos ) { return new AnalyzedTokenReadings ( new AnalyzedToken ( token , null , null ) , startPos ) ; } @ Override public AnalyzedToken createToken ( String token , String posTag ) { return new AnalyzedToken ( token , posTag , null ) ; } @ Nullable protected List < AnalyzedToken > additionalTags ( String word , WordTagger wordTagger ) { return null ; } }
package org . languagetool . tokenizers . nl ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import java . util . StringTokenizer ; import org . languagetool . tokenizers . WordTokenizer ; public class DutchWordTokenizer extends WordTokenizer { private static final List < String > QUOTES = Arrays . asList ( "'" , "`" , "’" , "‘" , "´" ) ; private final String nlTokenizingChars ; public DutchWordTokenizer ( ) { String chars = super . getTokenizingCharacters ( ) ; for ( String quote : QUOTES ) { chars = chars . replace ( quote , "" ) ; } nlTokenizingChars = chars ; } @ Override public List < String > tokenize ( final String text ) { final List < String > l = new ArrayList < > ( ) ; final StringTokenizer st = new StringTokenizer ( text , nlTokenizingChars , true ) ; while ( st . hasMoreElements ( ) ) { String token = st . nextToken ( ) ; String origToken = token ; if ( token . length ( ) > 1 ) { if ( startsWithQuote ( token ) && endsWithQuote ( token ) && token . length ( ) > 2 ) { l . add ( token . substring ( 0 , 1 ) ) ; l . add ( token . substring ( 1 , token . length ( ) - 1 ) ) ; l . add ( token . substring ( token . length ( ) - 1 , token . length ( ) ) ) ; } else if ( endsWithQuote ( token ) ) { int cnt = 0 ; while ( endsWithQuote ( token ) ) { token = token . substring ( 0 , token . length ( ) - 1 ) ; cnt ++ ; } l . add ( token ) ; for ( int i = origToken . length ( ) - cnt ; i < origToken . length ( ) ; i ++ ) { l . add ( origToken . substring ( i , i + 1 ) ) ; } } else if ( startsWithQuote ( token ) ) { while ( startsWithQuote ( token ) ) { l . add ( token . substring ( 0 , 1 ) ) ; token = token . substring ( 1 , token . length ( ) ) ; } l . add ( token ) ; } else { l . add ( token ) ; } } else { l . add ( token ) ; } } return joinUrls ( l ) ; } private boolean startsWithQuote ( String token ) { for ( String quote : QUOTES ) { if ( token . startsWith ( quote ) ) { return true ; } } return false ; } private boolean endsWithQuote ( String token ) { for ( String quote : QUOTES ) { if ( token . endsWith ( quote ) ) { return true ; } } return false ; } @ Override public String getTokenizingCharacters ( ) { return nlTokenizingChars ; } }
package org . languagetool . tagging ; import java . io . IOException ; import java . util . List ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; public interface Tagger { public List < AnalyzedTokenReadings > tag ( List < String > sentenceTokens ) throws IOException ; public AnalyzedTokenReadings createNullToken ( String token , int startPos ) ; public AnalyzedToken createToken ( String token , String posTag ) ; }
package org . languagetool . tagging ; import java . util . List ; public interface WordTagger { List < TaggedWord > tag ( String word ) ; }
package org . languagetool . tagging . disambiguation ; import java . io . IOException ; import org . languagetool . AnalyzedSentence ; public interface Disambiguator { AnalyzedSentence disambiguate ( AnalyzedSentence input ) throws IOException ; }
package org . languagetool . tagging . disambiguation ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . tools . StringTools ; import java . io . BufferedReader ; import java . io . IOException ; import java . io . InputStream ; import java . io . InputStreamReader ; import java . util . * ; public class MultiWordChunker implements Disambiguator { private final String filename ; private final boolean allowFirstCapitalized ; private Map < String , Integer > mStartSpace ; private Map < String , Integer > mStartNoSpace ; private Map < String , String > mFull ; public MultiWordChunker ( final String filename ) { this ( filename , false ) ; } public MultiWordChunker ( final String filename , boolean allowFirstCapitalized ) { this . filename = filename ; this . allowFirstCapitalized = allowFirstCapitalized ; } private void lazyInit ( ) { if ( mStartSpace != null ) { return ; } Map < String , Integer > mStartSpace = new HashMap < > ( ) ; Map < String , Integer > mStartNoSpace = new HashMap < > ( ) ; Map < String , String > mFull = new HashMap < > ( ) ; try ( InputStream stream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( filename ) ) { final List < String > posTokens = loadWords ( stream ) ; for ( String posToken : posTokens ) { final String [ ] tokenAndTag = posToken . split ( "\t" ) ; if ( tokenAndTag . length != 2 ) { throw new RuntimeException ( "Invalid format in " + filename + ": '" + posToken + "', expected two tab-separated parts" ) ; } final boolean containsSpace = tokenAndTag [ 0 ] . indexOf ( ' ' ) > 0 ; String firstToken ; final String [ ] firstTokens ; if ( ! containsSpace ) { firstTokens = new String [ tokenAndTag [ 0 ] . length ( ) ] ; firstToken = tokenAndTag [ 0 ] . substring ( 0 , 1 ) ; for ( int i = 1 ; i < tokenAndTag [ 0 ] . length ( ) ; i ++ ) { firstTokens [ i ] = tokenAndTag [ 0 ] . substring ( i - 1 , i ) ; } if ( mStartNoSpace . containsKey ( firstToken ) ) { if ( mStartNoSpace . get ( firstToken ) < firstTokens . length ) { mStartNoSpace . put ( firstToken , firstTokens . length ) ; } } else { mStartNoSpace . put ( firstToken , firstTokens . length ) ; } } else { firstTokens = tokenAndTag [ 0 ] . split ( " " ) ; firstToken = firstTokens [ 0 ] ; if ( mStartSpace . containsKey ( firstToken ) ) { if ( mStartSpace . get ( firstToken ) < firstTokens . length ) { mStartSpace . put ( firstToken , firstTokens . length ) ; } } else { mStartSpace . put ( firstToken , firstTokens . length ) ; } } mFull . put ( tokenAndTag [ 0 ] , tokenAndTag [ 1 ] ) ; } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } this . mStartSpace = mStartSpace ; this . mStartNoSpace = mStartNoSpace ; this . mFull = mFull ; } @ Override public final AnalyzedSentence disambiguate ( final AnalyzedSentence input ) { lazyInit ( ) ; final AnalyzedTokenReadings [ ] anTokens = input . getTokens ( ) ; final AnalyzedTokenReadings [ ] output = anTokens ; for ( int i = 0 ; i < anTokens . length ; i ++ ) { String tok = output [ i ] . getToken ( ) ; if ( tok . length ( ) < 1 ) { continue ; } if ( i + 1 < anTokens . length && ! anTokens [ i + 1 ] . isWhitespace ( ) ) { tok = tok + output [ i + 1 ] . getToken ( ) ; } int myCount = 0 ; while ( myCount < 2 ) { final StringBuilder tokens = new StringBuilder ( ) ; int finalLen = 0 ; if ( mStartSpace . containsKey ( tok ) ) { final int len = mStartSpace . get ( tok ) ; int j = i ; int lenCounter = 0 ; while ( j < anTokens . length ) { if ( ! anTokens [ j ] . isWhitespace ( ) ) { if ( j == i && myCount == 1 ) { tokens . append ( anTokens [ j ] . getToken ( ) . toLowerCase ( ) ) ; } else { tokens . append ( anTokens [ j ] . getToken ( ) ) ; } final String toks = tokens . toString ( ) ; if ( mFull . containsKey ( toks ) ) { output [ i ] = prepareNewReading ( toks , output [ i ] . getToken ( ) , output [ i ] , false ) ; output [ finalLen ] = prepareNewReading ( toks , anTokens [ finalLen ] . getToken ( ) , output [ finalLen ] , true ) ; } } else { if ( j > 1 && ! anTokens [ j - 1 ] . isWhitespace ( ) ) { tokens . append ( ' ' ) ; lenCounter ++ ; } if ( lenCounter == len ) { break ; } } j ++ ; finalLen = j ; } } if ( mStartNoSpace . containsKey ( tok . substring ( 0 , 1 ) ) ) { int j = i ; while ( j < anTokens . length && ! anTokens [ j ] . isWhitespace ( ) ) { if ( j == i && myCount == 1 ) { tokens . append ( anTokens [ j ] . getToken ( ) . toLowerCase ( ) ) ; } else { tokens . append ( anTokens [ j ] . getToken ( ) ) ; } final String toks = tokens . toString ( ) ; if ( mFull . containsKey ( toks ) ) { output [ i ] = prepareNewReading ( toks , anTokens [ i ] . getToken ( ) , output [ i ] , false ) ; output [ j ] = prepareNewReading ( toks , anTokens [ j ] . getToken ( ) , output [ j ] , true ) ; } j ++ ; } } myCount ++ ; if ( allowFirstCapitalized && StringTools . isCapitalizedWord ( tok ) && myCount == 1 ) { tok = tok . toLowerCase ( ) ; } else { myCount = 2 ; } } } return new AnalyzedSentence ( output ) ; } private AnalyzedTokenReadings prepareNewReading ( final String tokens , final String tok , final AnalyzedTokenReadings token , final boolean isLast ) { final StringBuilder sb = new StringBuilder ( ) ; sb . append ( '<' ) ; if ( isLast ) { sb . append ( '/' ) ; } sb . append ( mFull . get ( tokens ) ) ; sb . append ( '>' ) ; final AnalyzedToken tokenStart = new AnalyzedToken ( tok , sb . toString ( ) , tokens ) ; return setAndAnnotate ( token , tokenStart ) ; } private AnalyzedTokenReadings setAndAnnotate ( final AnalyzedTokenReadings oldReading , final AnalyzedToken newReading ) { final String old = oldReading . toString ( ) ; final String prevAnot = oldReading . getHistoricalAnnotations ( ) ; final AnalyzedTokenReadings newAtr = new AnalyzedTokenReadings ( oldReading . getReadings ( ) , oldReading . getStartPos ( ) ) ; newAtr . setWhitespaceBefore ( oldReading . isWhitespaceBefore ( ) ) ; newAtr . addReading ( newReading ) ; newAtr . setHistoricalAnnotations ( annotateToken ( prevAnot , old , newAtr . toString ( ) ) ) ; newAtr . setChunkTags ( oldReading . getChunkTags ( ) ) ; return newAtr ; } private String annotateToken ( final String prevAnot , final String oldReading , final String newReading ) { return prevAnot + "\nMULTIWORD_CHUNKER: " + oldReading + " -> " + newReading ; } private List < String > loadWords ( final InputStream stream ) { final List < String > lines = new ArrayList < > ( ) ; try ( BufferedReader reader = new BufferedReader ( new InputStreamReader ( stream , "UTF-8" ) ) ) { String line ; while ( ( line = reader . readLine ( ) ) != null ) { line = line . trim ( ) ; if ( line . isEmpty ( ) || line . charAt ( 0 ) == '#' ) { continue ; } lines . add ( line ) ; } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } return lines ; } }
package org . languagetool . tagging . disambiguation . rules ; import org . languagetool . tools . Tools ; import org . xml . sax . SAXException ; import org . xml . sax . helpers . DefaultHandler ; import javax . xml . parsers . ParserConfigurationException ; import javax . xml . parsers . SAXParser ; import javax . xml . parsers . SAXParserFactory ; import java . io . IOException ; import java . io . InputStream ; import java . util . List ; public class DisambiguationRuleLoader extends DefaultHandler { public final List < DisambiguationPatternRule > getRules ( final InputStream stream ) throws ParserConfigurationException , SAXException , IOException { final DisambiguationRuleHandler handler = new DisambiguationRuleHandler ( ) ; final SAXParserFactory factory = SAXParserFactory . newInstance ( ) ; final SAXParser saxParser = factory . newSAXParser ( ) ; Tools . setPasswordAuthenticator ( ) ; saxParser . parse ( stream , handler ) ; return handler . getDisambRules ( ) ; } }
package org . languagetool . tagging . disambiguation . rules ; import org . languagetool . AnalyzedToken ; import org . languagetool . Languages ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . Match ; import org . languagetool . rules . patterns . XMLRuleHandler ; import org . xml . sax . Attributes ; import org . xml . sax . SAXException ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Locale ; class DisambiguationRuleHandler extends XMLRuleHandler { private static final String WD = "wd" ; private static final String ACTION = "action" ; private static final String DISAMBIG = "disambig" ; private final List < DisambiguationPatternRule > rules = new ArrayList < > ( ) ; private boolean inDisambiguation ; private int subId ; private String name ; private String ruleGroupId ; private String ruleGroupName ; private StringBuilder disamb = new StringBuilder ( ) ; private StringBuilder wd = new StringBuilder ( ) ; private StringBuilder example = new StringBuilder ( ) ; private boolean inWord ; private String disambiguatedPOS ; private int startPos = - 1 ; private int endPos = - 1 ; private int tokenCountForMarker ; private Match posSelector ; private int uniCounter ; private List < AnalyzedToken > newWdList ; private String wdLemma ; private String wdPos ; private boolean inExample ; private boolean untouched ; private List < String > untouchedExamples ; private List < DisambiguatedExample > disambExamples ; private String input ; private String output ; private DisambiguationPatternRule . DisambiguatorAction disambigAction ; List < DisambiguationPatternRule > getDisambRules ( ) { return rules ; } @ Override public void startElement ( final String namespaceURI , final String lName , final String qName , final Attributes attrs ) throws SAXException { switch ( qName ) { case RULE : id = attrs . getValue ( ID ) ; if ( inRuleGroup ) { subId ++ ; } name = attrs . getValue ( NAME ) ; if ( inRuleGroup && id == null ) { id = ruleGroupId ; } if ( inRuleGroup && name == null ) { name = ruleGroupName ; } break ; case "rules" : language = Languages . getLanguageForShortName ( attrs . getValue ( "lang" ) ) ; break ; case PATTERN : inPattern = true ; tokenCountForMarker = 0 ; if ( attrs . getValue ( CASE_SENSITIVE ) != null && YES . equals ( attrs . getValue ( CASE_SENSITIVE ) ) ) { caseSensitive = true ; } break ; case EXCEPTION : setExceptions ( attrs ) ; break ; case AND : inAndGroup = true ; tokenCountForMarker ++ ; if ( inUnification ) { uniCounter ++ ; } break ; case UNIFY : inUnification = true ; uniNegation = YES . equals ( attrs . getValue ( NEGATE ) ) ; uniCounter = 0 ; break ; case UNIFY_IGNORE : inUnificationNeutral = true ; break ; case "feature" : uFeature = attrs . getValue ( ID ) ; break ; case TYPE : uType = attrs . getValue ( ID ) ; uTypeList . add ( uType ) ; break ; case TOKEN : setToken ( attrs ) ; if ( ! inAndGroup ) { tokenCountForMarker ++ ; } break ; case DISAMBIG : inDisambiguation = true ; disambiguatedPOS = attrs . getValue ( POSTAG ) ; if ( attrs . getValue ( ACTION ) == null ) { disambigAction = DisambiguationPatternRule . DisambiguatorAction . REPLACE ; } else { disambigAction = DisambiguationPatternRule . DisambiguatorAction . valueOf ( attrs . getValue ( ACTION ) . toUpperCase ( Locale . ENGLISH ) ) ; } disamb = new StringBuilder ( ) ; break ; case MATCH : inMatch = true ; match = new StringBuilder ( ) ; Match . CaseConversion caseConversion = Match . CaseConversion . NONE ; if ( attrs . getValue ( "case_conversion" ) != null ) { caseConversion = Match . CaseConversion . valueOf ( attrs . getValue ( "case_conversion" ) . toUpperCase ( Locale . ENGLISH ) ) ; } Match . IncludeRange includeRange = Match . IncludeRange . NONE ; if ( attrs . getValue ( "include_skipped" ) != null ) { includeRange = Match . IncludeRange . valueOf ( attrs . getValue ( "include_skipped" ) . toUpperCase ( Locale . ENGLISH ) ) ; } final Match mWorker = new Match ( attrs . getValue ( POSTAG ) , attrs . getValue ( "postag_replace" ) , YES . equals ( attrs . getValue ( POSTAG_REGEXP ) ) , attrs . getValue ( "regexp_match" ) , attrs . getValue ( "regexp_replace" ) , caseConversion , YES . equals ( attrs . getValue ( "setpos" ) ) , YES . equals ( attrs . getValue ( "suppress_mispelled" ) ) , includeRange ) ; if ( inDisambiguation ) { if ( attrs . getValue ( NO ) != null ) { final int refNumber = Integer . parseInt ( attrs . getValue ( NO ) ) ; refNumberSanityCheck ( refNumber ) ; mWorker . setTokenRef ( refNumber ) ; posSelector = mWorker ; } } else if ( inToken ) { if ( attrs . getValue ( NO ) != null ) { final int refNumber = Integer . parseInt ( attrs . getValue ( NO ) ) ; refNumberSanityCheck ( refNumber ) ; mWorker . setTokenRef ( refNumber ) ; tokenReference = mWorker ; elements . append ( '\\' ) ; elements . append ( refNumber ) ; } } break ; case RULEGROUP : ruleGroupId = attrs . getValue ( ID ) ; ruleGroupName = attrs . getValue ( NAME ) ; inRuleGroup = true ; subId = 0 ; break ; case UNIFICATION : uFeature = attrs . getValue ( FEATURE ) ; inUnificationDef = true ; break ; case "equivalence" : uType = attrs . getValue ( TYPE ) ; break ; case WD : wdLemma = attrs . getValue ( "lemma" ) ; wdPos = attrs . getValue ( "pos" ) ; inWord = true ; wd = new StringBuilder ( ) ; break ; case EXAMPLE : inExample = true ; if ( untouchedExamples == null ) { untouchedExamples = new ArrayList < > ( ) ; } if ( disambExamples == null ) { disambExamples = new ArrayList < > ( ) ; } untouched = attrs . getValue ( TYPE ) . equals ( "untouched" ) ; if ( attrs . getValue ( TYPE ) . equals ( "ambiguous" ) ) { input = attrs . getValue ( "inputform" ) ; output = attrs . getValue ( "outputform" ) ; } example = new StringBuilder ( ) ; break ; case MARKER : example . append ( "<marker>" ) ; if ( inPattern ) { startPos = tokenCounter ; inMarker = true ; } break ; } } private void refNumberSanityCheck ( int refNumber ) throws SAXException { if ( refNumber > patternTokens . size ( ) ) { throw new SAXException ( "Only backward references in match elements are possible, tried to specify token " + refNumber + "\n Line: " + pLocator . getLineNumber ( ) + ", column: " + pLocator . getColumnNumber ( ) + "." ) ; } } @ Override public void endElement ( final String namespaceURI , final String sName , final String qName ) throws SAXException { switch ( qName ) { case RULE : final DisambiguationPatternRule rule = new DisambiguationPatternRule ( id , name , language , patternTokens , disambiguatedPOS , posSelector , disambigAction ) ; endPositionCorrection = endPos - tokenCountForMarker ; if ( startPos != - 1 && endPos != - 1 ) { rule . setStartPositionCorrection ( startPos ) ; rule . setEndPositionCorrection ( endPositionCorrection ) ; } else { startPos = 0 ; endPos = tokenCountForMarker ; } rule . setSubId ( inRuleGroup ? Integer . toString ( subId ) : "1" ) ; final int matchedTokenCount = endPos - startPos ; if ( newWdList != null ) { if ( disambigAction == DisambiguationPatternRule . DisambiguatorAction . ADD || disambigAction == DisambiguationPatternRule . DisambiguatorAction . REMOVE || disambigAction == DisambiguationPatternRule . DisambiguatorAction . REPLACE ) { if ( ( ! newWdList . isEmpty ( ) && disambigAction == DisambiguationPatternRule . DisambiguatorAction . REPLACE ) && newWdList . size ( ) != matchedTokenCount ) { throw new SAXException ( language . getName ( ) + " rule error. The number of interpretations specified with wd: " + newWdList . size ( ) + " must be equal to the number of matched tokens (" + matchedTokenCount + ")" + "\n Line: " + pLocator . getLineNumber ( ) + ", column: " + pLocator . getColumnNumber ( ) + "." ) ; } rule . setNewInterpretations ( newWdList . toArray ( new AnalyzedToken [ newWdList . size ( ) ] ) ) ; } newWdList . clear ( ) ; } caseSensitive = false ; if ( disambExamples != null ) { rule . setExamples ( disambExamples ) ; } if ( untouchedExamples != null ) { rule . setUntouchedExamples ( untouchedExamples ) ; } rules . add ( rule ) ; if ( disambigAction == DisambiguationPatternRule . DisambiguatorAction . UNIFY && matchedTokenCount != uniCounter ) { throw new SAXException ( language . getName ( ) + " rule error. The number unified tokens: " + uniCounter + " must be equal to the number of matched tokens: " + matchedTokenCount + "\n Line: " + pLocator . getLineNumber ( ) + ", column: " + pLocator . getColumnNumber ( ) + "." ) ; } final boolean singleTokenCorrection = endPos - startPos > 1 ; if ( ( ! singleTokenCorrection && ( disambigAction == DisambiguationPatternRule . DisambiguatorAction . FILTER || disambigAction == DisambiguationPatternRule . DisambiguatorAction . REPLACE ) ) && ( matchedTokenCount > 1 ) ) { throw new SAXException ( language . getName ( ) + " rule error. Cannot replace or filter more than one token at a time." + "\n Line: " + pLocator . getLineNumber ( ) + ", column: " + pLocator . getColumnNumber ( ) + "." ) ; } patternTokens . clear ( ) ; posSelector = null ; disambExamples = null ; untouchedExamples = null ; startPos = - 1 ; endPos = - 1 ; break ; case EXCEPTION : finalizeExceptions ( ) ; break ; case AND : inAndGroup = false ; andGroupCounter = 0 ; tokenCounter ++ ; break ; case TOKEN : if ( ! exceptionSet || patternToken == null ) { boolean tokenCase = caseSensitive ; if ( tokenLevelCaseSet ) { tokenCase = tokenLevelCaseSensitive ; } patternToken = new PatternToken ( elements . toString ( ) , tokenCase , regExpression , tokenInflected ) ; patternToken . setNegation ( tokenNegated ) ; } else { patternToken . setStringElement ( elements . toString ( ) ) ; } if ( skipPos != 0 ) { patternToken . setSkipNext ( skipPos ) ; skipPos = 0 ; } if ( minOccurrence == 0 ) { patternToken . setMinOccurrence ( 0 ) ; } if ( maxOccurrence != 1 ) { patternToken . setMaxOccurrence ( maxOccurrence ) ; maxOccurrence = 1 ; } if ( posToken != null ) { patternToken . setPosToken ( new PatternToken . PosToken ( posToken , posRegExp , posNegation ) ) ; posToken = null ; } if ( chunkTag != null ) { patternToken . setChunkTag ( chunkTag ) ; chunkTag = null ; } if ( tokenReference != null ) { patternToken . setMatch ( tokenReference ) ; } if ( inAndGroup && andGroupCounter > 0 ) { patternTokens . get ( patternTokens . size ( ) - 1 ) . setAndGroupElement ( patternToken ) ; if ( minOccurrence != 1 || maxOccurrence != 1 ) { throw new SAXException ( "Please set min and max attributes on the " + "first token in the AND group.\n You attempted to set these " + "attributes on the token no. " + ( andGroupCounter + 1 ) + "." + "\n Line: " + pLocator . getLineNumber ( ) + ", column: " + pLocator . getColumnNumber ( ) + "." ) ; } } else { if ( minOccurrence < 1 ) { patternTokens . add ( patternToken ) ; } for ( int i = 1 ; i <= minOccurrence ; i ++ ) { patternTokens . add ( patternToken ) ; } minOccurrence = 1 ; } if ( inAndGroup ) { andGroupCounter ++ ; } if ( inUnification ) { patternToken . setUnification ( equivalenceFeatures ) ; if ( ! inAndGroup ) { uniCounter ++ ; } if ( inUnificationNeutral ) { patternToken . setUnificationNeutral ( ) ; } } if ( inUnificationDef ) { language . getDisambiguationUnifierConfiguration ( ) . setEquivalence ( uFeature , uType , patternToken ) ; patternTokens . clear ( ) ; } patternToken . setInsideMarker ( inMarker ) ; if ( tokenSpaceBeforeSet ) { patternToken . setWhitespaceBefore ( tokenSpaceBefore ) ; } resetToken ( ) ; break ; case PATTERN : inPattern = false ; tokenCounter = 0 ; break ; case MATCH : if ( inDisambiguation ) { posSelector . setLemmaString ( match . toString ( ) ) ; } else if ( inToken ) { tokenReference . setLemmaString ( match . toString ( ) ) ; } inMatch = false ; break ; case DISAMBIG : inDisambiguation = false ; break ; case RULEGROUP : inRuleGroup = false ; break ; case UNIFICATION : if ( inUnificationDef ) { inUnificationDef = false ; tokenCounter = 0 ; } break ; case "feature" : equivalenceFeatures . put ( uFeature , uTypeList ) ; uTypeList = new ArrayList < > ( ) ; break ; case UNIFY : inUnification = false ; equivalenceFeatures = new HashMap < > ( ) ; final int lastElement = patternTokens . size ( ) - 1 ; patternTokens . get ( lastElement ) . setLastInUnification ( ) ; if ( uniNegation ) { patternTokens . get ( lastElement ) . setUniNegation ( ) ; } break ; case UNIFY_IGNORE : inUnificationNeutral = false ; break ; case WD : addNewWord ( wd . toString ( ) , wdLemma , wdPos ) ; inWord = false ; break ; case EXAMPLE : inExample = false ; if ( untouched ) { untouchedExamples . add ( example . toString ( ) ) ; } else { disambExamples . add ( new DisambiguatedExample ( example . toString ( ) , input , output ) ) ; } break ; case MARKER : example . append ( "</marker>" ) ; if ( inPattern ) { endPos = tokenCountForMarker ; inMarker = false ; } break ; } } private void addNewWord ( final String word , final String lemma , final String pos ) { final AnalyzedToken newWd = new AnalyzedToken ( word , pos , lemma ) ; if ( newWdList == null ) { newWdList = new ArrayList < > ( ) ; } newWdList . add ( newWd ) ; } @ Override public final void characters ( final char [ ] buf , final int offset , final int len ) { final String s = new String ( buf , offset , len ) ; if ( inException ) { exceptions . append ( s ) ; } else if ( inToken && inPattern ) { elements . append ( s ) ; } else if ( inMatch ) { match . append ( s ) ; } else if ( inWord ) { wd . append ( s ) ; } else if ( inDisambiguation ) { disamb . append ( s ) ; } else if ( inExample ) { example . append ( s ) ; } } }
package org . languagetool . tagging . disambiguation . rules ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; import java . util . Objects ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . Language ; import org . languagetool . rules . patterns . AbstractPatternRule ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . Match ; public class DisambiguationPatternRule extends AbstractPatternRule { public enum DisambiguatorAction { ADD , FILTER , REMOVE , REPLACE , UNIFY , IMMUNIZE , IGNORE_SPELLING , FILTERALL } private final String disambiguatedPOS ; private final Match matchElement ; private final DisambiguatorAction disAction ; private AnalyzedToken [ ] newTokenReadings ; private List < DisambiguatedExample > examples = new ArrayList < > ( ) ; private List < String > untouchedExamples = new ArrayList < > ( ) ; public DisambiguationPatternRule ( final String id , final String description , final Language language , final List < PatternToken > patternTokens , final String disamb , final Match posSelect , final DisambiguatorAction disambAction ) { super ( id , description , language , patternTokens , true ) ; if ( disamb == null && posSelect == null && disambAction != DisambiguatorAction . UNIFY && disambAction != DisambiguatorAction . ADD && disambAction != DisambiguatorAction . REMOVE && disambAction != DisambiguatorAction . IMMUNIZE && disambAction != DisambiguatorAction . REPLACE && disambAction != DisambiguatorAction . FILTERALL && disambAction != DisambiguatorAction . IGNORE_SPELLING ) { throw new NullPointerException ( "disambiguated POS cannot be null" ) ; } this . disambiguatedPOS = disamb ; this . matchElement = posSelect ; this . disAction = disambAction ; } public final void setNewInterpretations ( final AnalyzedToken [ ] newReadings ) { newTokenReadings = newReadings . clone ( ) ; } public final AnalyzedSentence replace ( final AnalyzedSentence sentence ) throws IOException { final DisambiguationPatternRuleReplacer replacer = new DisambiguationPatternRuleReplacer ( this ) ; return replacer . replace ( sentence ) ; } public void setExamples ( final List < DisambiguatedExample > examples ) { this . examples = Objects . requireNonNull ( examples ) ; } public List < DisambiguatedExample > getExamples ( ) { return Collections . unmodifiableList ( examples ) ; } public void setUntouchedExamples ( final List < String > untouchedExamples ) { this . untouchedExamples = Objects . requireNonNull ( untouchedExamples ) ; } public List < String > getUntouchedExamples ( ) { return Collections . unmodifiableList ( untouchedExamples ) ; } public DisambiguatorAction getAction ( ) { return disAction ; } public AnalyzedToken [ ] getNewTokenReadings ( ) { return newTokenReadings ; } public Match getMatchElement ( ) { return matchElement ; } public String getDisambiguatedPOS ( ) { return disambiguatedPOS ; } }
package org . languagetool . tagging . disambiguation . rules ; import java . io . IOException ; import java . util . List ; import java . util . Objects ; import javax . xml . parsers . ParserConfigurationException ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tools . Tools ; import org . xml . sax . SAXException ; public class XmlRuleDisambiguator implements Disambiguator { private static final String DISAMBIGUATION_FILE = "disambiguation.xml" ; private final List < DisambiguationPatternRule > disambiguationRules ; public XmlRuleDisambiguator ( final Language language ) { Objects . requireNonNull ( language ) ; final String disambiguationFile = JLanguageTool . getDataBroker ( ) . getResourceDir ( ) + "/" + language . getShortName ( ) + "/" + DISAMBIGUATION_FILE ; try { disambiguationRules = loadPatternRules ( disambiguationFile ) ; } catch ( Exception e ) { throw new RuntimeException ( "Problems with loading disambiguation file: " + disambiguationFile , e ) ; } } @ Override public AnalyzedSentence disambiguate ( final AnalyzedSentence input ) throws IOException { AnalyzedSentence sentence = input ; for ( final DisambiguationPatternRule patternRule : disambiguationRules ) { sentence = patternRule . replace ( sentence ) ; } return sentence ; } protected List < DisambiguationPatternRule > loadPatternRules ( final String filename ) throws ParserConfigurationException , SAXException , IOException { final DisambiguationRuleLoader ruleLoader = new DisambiguationRuleLoader ( ) ; return ruleLoader . getRules ( Tools . getStream ( filename ) ) ; } }
package org . languagetool . tagging . disambiguation . rules ; import org . jetbrains . annotations . Nullable ; public class DisambiguatedExample { private final String example ; private final String input ; private final String output ; public DisambiguatedExample ( final String example ) { this ( example , null , null ) ; } public DisambiguatedExample ( final String example , final String input , final String output ) { this . example = example ; this . input = input ; this . output = output ; } public String getExample ( ) { return example ; } public String getAmbiguous ( ) { return input ; } @ Nullable public String getDisambiguated ( ) { return output ; } @ Override public String toString ( ) { return example + ": " + input + " -> " + output ; } }
package org . languagetool . tagging . disambiguation . rules ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . chunking . ChunkTag ; import org . languagetool . rules . patterns . * ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; class DisambiguationPatternRuleReplacer extends AbstractPatternRulePerformer { private final List < Boolean > pTokensMatched ; DisambiguationPatternRuleReplacer ( DisambiguationPatternRule rule ) { super ( rule , rule . getLanguage ( ) . getDisambiguationUnifier ( ) ) ; pTokensMatched = new ArrayList < > ( rule . getPatternTokens ( ) . size ( ) ) ; } public final AnalyzedSentence replace ( final AnalyzedSentence sentence ) throws IOException { List < PatternTokenMatcher > patternTokenMatchers = createElementMatchers ( ) ; final AnalyzedTokenReadings [ ] tokens = sentence . getTokensWithoutWhitespace ( ) ; AnalyzedTokenReadings [ ] whTokens = sentence . getTokens ( ) ; final int [ ] tokenPositions = new int [ tokens . length + 1 ] ; final int patternSize = patternTokenMatchers . size ( ) ; final int limit = Math . max ( 0 , tokens . length - patternSize + 1 ) ; PatternTokenMatcher pTokenMatcher = null ; boolean changed = false ; pTokensMatched . clear ( ) ; for ( PatternTokenMatcher patternTokenMatcher : patternTokenMatchers ) { pTokensMatched . add ( false ) ; } int i = 0 ; int minOccurCorrection = getMinOccurrenceCorrection ( ) ; while ( i < limit + minOccurCorrection && ! ( rule . isSentStart ( ) && i > 0 ) ) { int skipShiftTotal = 0 ; boolean allElementsMatch = false ; unifiedTokens = null ; int matchingTokens = 0 ; int firstMatchToken = - 1 ; int lastMatchToken = - 1 ; int firstMarkerMatchToken = - 1 ; int lastMarkerMatchToken = - 1 ; int prevSkipNext = 0 ; if ( rule . isTestUnification ( ) ) { unifier . reset ( ) ; } int minOccurSkip = 0 ; for ( int k = 0 ; k < patternSize ; k ++ ) { final PatternTokenMatcher prevTokenMatcher = pTokenMatcher ; pTokenMatcher = patternTokenMatchers . get ( k ) ; pTokenMatcher . resolveReference ( firstMatchToken , tokens , rule . getLanguage ( ) ) ; final int nextPos = i + k + skipShiftTotal - minOccurSkip ; prevMatched = false ; if ( prevSkipNext + nextPos >= tokens . length || prevSkipNext < 0 ) { prevSkipNext = tokens . length - ( nextPos + 1 ) ; } final int maxTok = Math . min ( nextPos + prevSkipNext , tokens . length - ( patternSize - k ) + minOccurCorrection ) ; for ( int m = nextPos ; m <= maxTok ; m ++ ) { allElementsMatch = testAllReadings ( tokens , pTokenMatcher , prevTokenMatcher , m , firstMatchToken , prevSkipNext ) ; if ( pTokenMatcher . getPatternToken ( ) . getMinOccurrence ( ) == 0 ) { final PatternTokenMatcher nextElement = patternTokenMatchers . get ( k + 1 ) ; final boolean nextElementMatch = testAllReadings ( tokens , nextElement , pTokenMatcher , m , firstMatchToken , prevSkipNext ) ; if ( nextElementMatch ) { allElementsMatch = true ; minOccurSkip ++ ; pTokensMatched . set ( k , false ) ; break ; } } if ( allElementsMatch ) { pTokensMatched . set ( k , true ) ; int skipForMax = skipMaxTokens ( tokens , pTokenMatcher , firstMatchToken , prevSkipNext , prevTokenMatcher , m , patternSize - k - 1 ) ; lastMatchToken = m + skipForMax ; final int skipShift = lastMatchToken - nextPos ; tokenPositions [ matchingTokens ] = skipShift + 1 ; prevSkipNext = pTokenMatcher . getPatternToken ( ) . getSkipNext ( ) ; matchingTokens ++ ; skipShiftTotal += skipShift ; if ( firstMatchToken == - 1 ) { firstMatchToken = lastMatchToken - skipForMax ; } if ( firstMarkerMatchToken == - 1 && pTokenMatcher . getPatternToken ( ) . isInsideMarker ( ) ) { firstMarkerMatchToken = lastMatchToken - skipForMax ; } if ( pTokenMatcher . getPatternToken ( ) . isInsideMarker ( ) ) { lastMarkerMatchToken = lastMatchToken ; } break ; } } if ( ! allElementsMatch ) { break ; } } if ( allElementsMatch && matchingTokens == patternSize || matchingTokens == patternSize - minOccurSkip && firstMatchToken != - 1 ) { whTokens = executeAction ( sentence , whTokens , unifiedTokens , firstMatchToken , lastMarkerMatchToken , matchingTokens , tokenPositions ) ; changed = true ; } i ++ ; } if ( changed ) { return new AnalyzedSentence ( whTokens ) ; } return sentence ; } @ Override protected int skipMaxTokens ( AnalyzedTokenReadings [ ] tokens , PatternTokenMatcher matcher , int firstMatchToken , int prevSkipNext , PatternTokenMatcher prevElement , int m , int remainingElems ) throws IOException { int maxSkip = 0 ; int maxOccurrences = matcher . getPatternToken ( ) . getMaxOccurrence ( ) == - 1 ? Integer . MAX_VALUE : matcher . getPatternToken ( ) . getMaxOccurrence ( ) ; for ( int j = 1 ; j < maxOccurrences && m + j < tokens . length - remainingElems ; j ++ ) { boolean nextAllElementsMatch = testAllReadings ( tokens , matcher , prevElement , m + j , firstMatchToken , prevSkipNext ) ; if ( nextAllElementsMatch ) { maxSkip ++ ; } else { break ; } } return maxSkip ; } private AnalyzedTokenReadings [ ] executeAction ( final AnalyzedSentence sentence , final AnalyzedTokenReadings [ ] whiteTokens , final AnalyzedTokenReadings [ ] unifiedTokens , final int firstMatchToken , int lastMatchToken , final int matchingTokens , final int [ ] tokenPositions ) { final AnalyzedTokenReadings [ ] whTokens = whiteTokens . clone ( ) ; final DisambiguationPatternRule rule = ( DisambiguationPatternRule ) this . rule ; int correctedStPos = 0 ; int startPositionCorrection = rule . getStartPositionCorrection ( ) ; int endPositionCorrection = rule . getEndPositionCorrection ( ) ; int matchingTokensWithCorrection = matchingTokens ; List < Integer > tokenPositionList = new ArrayList < > ( ) ; for ( int i : tokenPositions ) { tokenPositionList . add ( i ) ; } if ( startPositionCorrection > 0 ) { correctedStPos -- ; for ( int j = 0 ; j < pTokensMatched . size ( ) ; j ++ ) { if ( ! pTokensMatched . get ( j ) ) { tokenPositionList . add ( j , 0 ) ; } } for ( int l = 0 ; l <= startPositionCorrection ; l ++ ) { correctedStPos += tokenPositionList . get ( l ) ; } int w = startPositionCorrection ; for ( int j = 0 ; j <= w ; j ++ ) { if ( j < pTokensMatched . size ( ) && ! pTokensMatched . get ( j ) ) { startPositionCorrection -- ; } } } if ( endPositionCorrection < 0 ) { for ( int d = startPositionCorrection ; d < pTokensMatched . size ( ) ; d ++ ) { if ( ! pTokensMatched . get ( d ) ) { endPositionCorrection ++ ; } } } if ( lastMatchToken != - 1 ) { int maxPosCorrection = Math . max ( ( lastMatchToken + 1 - ( firstMatchToken + correctedStPos ) ) - matchingTokens , 0 ) ; matchingTokensWithCorrection += maxPosCorrection ; } final int fromPos = sentence . getOriginalPosition ( firstMatchToken + correctedStPos ) ; final boolean spaceBefore = whTokens [ fromPos ] . isWhitespaceBefore ( ) ; final DisambiguationPatternRule . DisambiguatorAction disAction = rule . getAction ( ) ; final AnalyzedToken [ ] newTokenReadings = rule . getNewTokenReadings ( ) ; final Match matchElement = rule . getMatchElement ( ) ; final String disambiguatedPOS = rule . getDisambiguatedPOS ( ) ; switch ( disAction ) { case UNIFY : if ( unifiedTokens != null ) { if ( unifiedTokens . length == matchingTokensWithCorrection - startPositionCorrection + endPositionCorrection ) { if ( whTokens [ sentence . getOriginalPosition ( firstMatchToken + correctedStPos + unifiedTokens . length - 1 ) ] . isSentenceEnd ( ) ) { unifiedTokens [ unifiedTokens . length - 1 ] . setSentEnd ( ) ; } for ( int i = 0 ; i < unifiedTokens . length ; i ++ ) { final int position = sentence . getOriginalPosition ( firstMatchToken + correctedStPos + i ) ; unifiedTokens [ i ] . setStartPos ( whTokens [ position ] . getStartPos ( ) ) ; final String prevValue = whTokens [ position ] . toString ( ) ; final String prevAnot = whTokens [ position ] . getHistoricalAnnotations ( ) ; List < ChunkTag > chTags = whTokens [ position ] . getChunkTags ( ) ; whTokens [ position ] = unifiedTokens [ i ] ; whTokens [ position ] . setChunkTags ( chTags ) ; annotateChange ( whTokens [ position ] , prevValue , prevAnot ) ; } } } break ; case REMOVE : if ( newTokenReadings != null && newTokenReadings . length > 0 ) { if ( newTokenReadings . length == matchingTokensWithCorrection - startPositionCorrection + endPositionCorrection ) { for ( int i = 0 ; i < newTokenReadings . length ; i ++ ) { final int position = sentence . getOriginalPosition ( firstMatchToken + correctedStPos + i ) ; final String prevValue = whTokens [ position ] . toString ( ) ; final String prevAnot = whTokens [ position ] . getHistoricalAnnotations ( ) ; whTokens [ position ] . removeReading ( newTokenReadings [ i ] ) ; annotateChange ( whTokens [ position ] , prevValue , prevAnot ) ; } } } else if ( ! StringTools . isEmpty ( disambiguatedPOS ) ) { Pattern p = Pattern . compile ( disambiguatedPOS ) ; AnalyzedTokenReadings tmp = new AnalyzedTokenReadings ( whTokens [ fromPos ] . getReadings ( ) , whTokens [ fromPos ] . getStartPos ( ) ) ; for ( AnalyzedToken analyzedToken : tmp ) { if ( analyzedToken . getPOSTag ( ) != null ) { final Matcher mPos = p . matcher ( analyzedToken . getPOSTag ( ) ) ; if ( mPos . matches ( ) ) { final int position = sentence . getOriginalPosition ( firstMatchToken + correctedStPos ) ; final String prevValue = whTokens [ position ] . toString ( ) ; final String prevAnot = whTokens [ position ] . getHistoricalAnnotations ( ) ; whTokens [ position ] . removeReading ( analyzedToken ) ; annotateChange ( whTokens [ position ] , prevValue , prevAnot ) ; } } } } break ; case ADD : if ( newTokenReadings != null ) { if ( newTokenReadings . length == matchingTokensWithCorrection - startPositionCorrection + endPositionCorrection ) { for ( int i = 0 ; i < newTokenReadings . length ; i ++ ) { final String token ; final int position = sentence . getOriginalPosition ( firstMatchToken + correctedStPos + i ) ; if ( "" . equals ( newTokenReadings [ i ] . getToken ( ) ) ) { token = whTokens [ position ] . getToken ( ) ; } else { token = newTokenReadings [ i ] . getToken ( ) ; } final String lemma ; if ( newTokenReadings [ i ] . getLemma ( ) == null ) { lemma = token ; } else { lemma = newTokenReadings [ i ] . getLemma ( ) ; } final AnalyzedToken newTok = new AnalyzedToken ( token , newTokenReadings [ i ] . getPOSTag ( ) , lemma ) ; final String prevValue = whTokens [ position ] . toString ( ) ; final String prevAnot = whTokens [ position ] . getHistoricalAnnotations ( ) ; whTokens [ position ] . addReading ( newTok ) ; annotateChange ( whTokens [ position ] , prevValue , prevAnot ) ; } } } break ; case FILTERALL : for ( int i = 0 ; i < matchingTokensWithCorrection - startPositionCorrection + endPositionCorrection ; i ++ ) { final int position = sentence . getOriginalPosition ( firstMatchToken + correctedStPos + i ) ; PatternToken pToken ; if ( pTokensMatched . get ( i + startPositionCorrection ) ) { pToken = rule . getPatternTokens ( ) . get ( i + startPositionCorrection ) ; } else { int k = 1 ; while ( i + startPositionCorrection + k < rule . getPatternTokens ( ) . size ( ) + endPositionCorrection && ! pTokensMatched . get ( i + startPositionCorrection + k ) ) { k ++ ; } pToken = rule . getPatternTokens ( ) . get ( i + k + startPositionCorrection ) ; } final Match tmpMatchToken = new Match ( pToken . getPOStag ( ) , null , true , pToken . getPOStag ( ) , null , Match . CaseConversion . NONE , false , false , Match . IncludeRange . NONE ) ; MatchState matchState = tmpMatchToken . createState ( rule . getLanguage ( ) . getSynthesizer ( ) , whTokens [ position ] ) ; final String prevValue = whTokens [ position ] . toString ( ) ; final String prevAnot = whTokens [ position ] . getHistoricalAnnotations ( ) ; whTokens [ position ] = matchState . filterReadings ( ) ; annotateChange ( whTokens [ position ] , prevValue , prevAnot ) ; } break ; case IMMUNIZE : for ( int i = 0 ; i < matchingTokensWithCorrection - startPositionCorrection + endPositionCorrection ; i ++ ) { whTokens [ sentence . getOriginalPosition ( firstMatchToken + correctedStPos + i ) ] . immunize ( ) ; } break ; case IGNORE_SPELLING : for ( int i = 0 ; i < matchingTokensWithCorrection - startPositionCorrection + endPositionCorrection ; i ++ ) { whTokens [ sentence . getOriginalPosition ( firstMatchToken + correctedStPos + i ) ] . ignoreSpelling ( ) ; } break ; case FILTER : if ( matchElement == null ) { final Match tmpMatchToken = new Match ( disambiguatedPOS , null , true , disambiguatedPOS , null , Match . CaseConversion . NONE , false , false , Match . IncludeRange . NONE ) ; boolean newPOSmatches = false ; for ( int i = 0 ; i < whTokens [ fromPos ] . getReadingsLength ( ) ; i ++ ) { if ( ! whTokens [ fromPos ] . getAnalyzedToken ( i ) . hasNoTag ( ) && whTokens [ fromPos ] . getAnalyzedToken ( i ) . getPOSTag ( ) . matches ( disambiguatedPOS ) ) { newPOSmatches = true ; break ; } } if ( newPOSmatches ) { final MatchState matchState = tmpMatchToken . createState ( rule . getLanguage ( ) . getSynthesizer ( ) , whTokens [ fromPos ] ) ; final String prevValue = whTokens [ fromPos ] . toString ( ) ; final String prevAnot = whTokens [ fromPos ] . getHistoricalAnnotations ( ) ; whTokens [ fromPos ] = matchState . filterReadings ( ) ; annotateChange ( whTokens [ fromPos ] , prevValue , prevAnot ) ; } break ; } case REPLACE : default : if ( newTokenReadings != null && newTokenReadings . length > 0 ) { if ( newTokenReadings . length == matchingTokensWithCorrection - startPositionCorrection + endPositionCorrection ) { for ( int i = 0 ; i < newTokenReadings . length ; i ++ ) { final String token ; final int position = sentence . getOriginalPosition ( firstMatchToken + correctedStPos + i ) ; if ( "" . equals ( newTokenReadings [ i ] . getToken ( ) ) ) { token = whTokens [ position ] . getToken ( ) ; } else { token = newTokenReadings [ i ] . getToken ( ) ; } final String lemma ; if ( newTokenReadings [ i ] . getLemma ( ) == null ) { lemma = token ; } else { lemma = newTokenReadings [ i ] . getLemma ( ) ; } final AnalyzedToken analyzedToken = new AnalyzedToken ( token , newTokenReadings [ i ] . getPOSTag ( ) , lemma ) ; final AnalyzedTokenReadings toReplace = new AnalyzedTokenReadings ( analyzedToken , whTokens [ fromPos ] . getStartPos ( ) ) ; whTokens [ position ] = replaceTokens ( whTokens [ position ] , toReplace ) ; } } } else if ( matchElement == null ) { String lemma = "" ; for ( AnalyzedToken analyzedToken : whTokens [ fromPos ] ) { if ( analyzedToken . getPOSTag ( ) != null && analyzedToken . getPOSTag ( ) . equals ( disambiguatedPOS ) && analyzedToken . getLemma ( ) != null ) { lemma = analyzedToken . getLemma ( ) ; } } if ( StringTools . isEmpty ( lemma ) ) { lemma = whTokens [ fromPos ] . getAnalyzedToken ( 0 ) . getLemma ( ) ; } final AnalyzedToken analyzedToken = new AnalyzedToken ( whTokens [ fromPos ] . getToken ( ) , disambiguatedPOS , lemma ) ; final AnalyzedTokenReadings toReplace = new AnalyzedTokenReadings ( analyzedToken , whTokens [ fromPos ] . getStartPos ( ) ) ; whTokens [ fromPos ] = replaceTokens ( whTokens [ fromPos ] , toReplace ) ; } else { final MatchState matchElementState = matchElement . createState ( rule . getLanguage ( ) . getSynthesizer ( ) , whTokens [ fromPos ] ) ; final String prevValue = whTokens [ fromPos ] . toString ( ) ; final String prevAnot = whTokens [ fromPos ] . getHistoricalAnnotations ( ) ; whTokens [ fromPos ] = matchElementState . filterReadings ( ) ; whTokens [ fromPos ] . setWhitespaceBefore ( spaceBefore ) ; annotateChange ( whTokens [ fromPos ] , prevValue , prevAnot ) ; } } return whTokens ; } private void annotateChange ( AnalyzedTokenReadings atr , final String prevValue , String prevAnot ) { atr . setHistoricalAnnotations ( prevAnot + "\n" + rule . getId ( ) + ":" + rule . getSubId ( ) + " " + prevValue + " -> " + atr ) ; } private AnalyzedTokenReadings replaceTokens ( AnalyzedTokenReadings oldAtr , final AnalyzedTokenReadings newAtr ) { final String prevValue = oldAtr . toString ( ) ; final String prevAnot = oldAtr . getHistoricalAnnotations ( ) ; final boolean isSentEnd = oldAtr . isSentenceEnd ( ) ; final boolean isParaEnd = oldAtr . isParagraphEnd ( ) ; final boolean spaceBefore = oldAtr . isWhitespaceBefore ( ) ; final int startPosition = oldAtr . getStartPos ( ) ; final List < ChunkTag > chunkTags = oldAtr . getChunkTags ( ) ; if ( isSentEnd ) { newAtr . setSentEnd ( ) ; } if ( isParaEnd ) { newAtr . setParagraphEnd ( ) ; } newAtr . setWhitespaceBefore ( spaceBefore ) ; newAtr . setStartPos ( startPosition ) ; newAtr . setChunkTags ( chunkTags ) ; if ( oldAtr . isImmunized ( ) ) { newAtr . immunize ( ) ; } annotateChange ( newAtr , prevValue , prevAnot ) ; return newAtr ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Romanian ; public class RomanianConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Romanian ( ) ; } @ Override protected String createSampleText ( ) { return "Puteți adăuga un articol în lista de articole cerute pentru ca un alt colaborator să-l înceapă." ; } }
package org . languagetool . tagging . disambiguation . xx ; import org . languagetool . AnalyzedSentence ; import org . languagetool . tagging . disambiguation . Disambiguator ; public class DemoDisambiguator implements Disambiguator { @ Override public final AnalyzedSentence disambiguate ( final AnalyzedSentence input ) { return input ; } }
package org . languagetool . tagging . xx ; import java . util . ArrayList ; import java . util . List ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . tagging . Tagger ; public class DemoTagger implements Tagger { @ Override public List < AnalyzedTokenReadings > tag ( final List < String > sentenceTokens ) { final List < AnalyzedTokenReadings > tokenReadings = new ArrayList < > ( ) ; for ( String word : sentenceTokens ) { final List < AnalyzedToken > l = new ArrayList < > ( ) ; l . add ( new AnalyzedToken ( word , null , null ) ) ; tokenReadings . add ( new AnalyzedTokenReadings ( l , 0 ) ) ; } return tokenReadings ; } @ Override public AnalyzedTokenReadings createNullToken ( String token , int startPos ) { return new AnalyzedTokenReadings ( new AnalyzedToken ( token , null , null ) , startPos ) ; } @ Override public AnalyzedToken createToken ( String token , String posTag ) { return new AnalyzedToken ( token , posTag , null ) ; } }
package org . languagetool . tokenizers ; public interface CompoundWordTokenizer extends Tokenizer { }
package org . languagetool . tokenizers ; import net . sourceforge . segment . srx . SrxDocument ; import org . languagetool . Language ; import java . util . List ; import java . util . Objects ; public class LocalSRXSentenceTokenizer implements SentenceTokenizer { private final SrxDocument srxDocument ; private final Language language ; private String parCode ; public LocalSRXSentenceTokenizer ( Language language , String srxInClassPath ) { this . language = Objects . requireNonNull ( language ) ; this . srxDocument = SrxTools . createSrxDocument ( srxInClassPath ) ; setSingleLineBreaksMarksParagraph ( false ) ; } @ Override public final List < String > tokenize ( final String text ) { return SrxTools . tokenize ( text , srxDocument , language . getShortName ( ) + parCode ) ; } @ Override public final boolean singleLineBreaksMarksPara ( ) { return "_one" . equals ( parCode ) ; } @ Override public final void setSingleLineBreaksMarksParagraph ( final boolean lineBreakParagraphs ) { if ( lineBreakParagraphs ) { parCode = "_one" ; } else { parCode = "_two" ; } } }
package org . languagetool . tokenizers ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import java . util . StringTokenizer ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . tools . StringTools ; public class WordTokenizer implements Tokenizer { private static final List < String > PROTOCOLS = Collections . unmodifiableList ( Arrays . asList ( "http" , "https" , "ftp" ) ) ; private static final Pattern URL_CHARS = Pattern . compile ( "[a-zA-Z0-9/%$-_.+!*'(),\\?]+" ) ; private static final String TOKENIZING_CHARACTERS = "\u0020\u00A0\u115f" + "\u1160\u1680" + "\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007" + "\u2008\u2009\u200A\u200B\u200c\u200d\u200e\u200f" + "\u2028\u2029\u202a\u202b\u202c\u202d\u202e\u202f" + "\u205F\u2060\u2061\u2062\u2063\u206A\u206b\u206c\u206d" + "\u206E\u206F\u3000\u3164\ufeff\uffa0\ufff9\ufffa\ufffb" + ",.;()[]{}=*#∗×·+÷<>!?:/|\\\"'«»„”“`´‘’‛′…¿¡→‼⁇⁈⁉" + "—" + "\t\n\r" ; public static List < String > getProtocols ( ) { return PROTOCOLS ; } public WordTokenizer ( ) { } @ Override public List < String > tokenize ( final String text ) { final List < String > l = new ArrayList < > ( ) ; final StringTokenizer st = new StringTokenizer ( text , getTokenizingCharacters ( ) , true ) ; while ( st . hasMoreElements ( ) ) { l . add ( st . nextToken ( ) ) ; } return joinUrls ( l ) ; } public String getTokenizingCharacters ( ) { return TOKENIZING_CHARACTERS ; } protected List < String > joinUrls ( List < String > l ) { final List < String > newList = new ArrayList < > ( ) ; boolean inUrl = false ; final StringBuilder url = new StringBuilder ( ) ; for ( int i = 0 ; i < l . size ( ) ; i ++ ) { if ( urlStartsAt ( i , l ) ) { inUrl = true ; url . append ( l . get ( i ) ) ; } else if ( inUrl && urlEndsAt ( i , l ) ) { inUrl = false ; newList . add ( url . toString ( ) ) ; url . setLength ( 0 ) ; newList . add ( l . get ( i ) ) ; } else if ( inUrl ) { url . append ( l . get ( i ) ) ; } else { newList . add ( l . get ( i ) ) ; } } if ( url . length ( ) > 0 ) { newList . add ( url . toString ( ) ) ; } return newList ; } private boolean urlStartsAt ( int i , List < String > l ) { final String token = l . get ( i ) ; if ( isProtocol ( token ) && l . size ( ) > i + 3 ) { final String nToken = l . get ( i + 1 ) ; final String nnToken = l . get ( i + 2 ) ; final String nnnToken = l . get ( i + 3 ) ; if ( nToken . equals ( ":" ) && nnToken . equals ( "/" ) && nnnToken . equals ( "/" ) ) { return true ; } } return false ; } private boolean isProtocol ( String token ) { for ( String protocol : PROTOCOLS ) { if ( token . equals ( protocol ) ) { return true ; } } return false ; } private boolean urlEndsAt ( int i , List < String > l ) { final String token = l . get ( i ) ; if ( StringTools . isWhitespace ( token ) ) { return true ; } else if ( token . equals ( ")" ) ) { return true ; } else if ( l . size ( ) > i + 1 ) { final String nToken = l . get ( i + 1 ) ; if ( StringTools . isWhitespace ( nToken ) && ( token . equals ( "." ) || token . equals ( "," ) || token . equals ( ";" ) || token . equals ( ":" ) || token . equals ( "!" ) || token . equals ( "?" ) ) ) { return true ; } } else { final Matcher matcher = URL_CHARS . matcher ( token ) ; if ( ! matcher . matches ( ) ) { return true ; } } return false ; } }
package org . languagetool . tokenizers ; import org . languagetool . Language ; import org . languagetool . language . Contributor ; import org . languagetool . rules . Rule ; import java . util . Collections ; import java . util . List ; import java . util . ResourceBundle ; public class SimpleSentenceTokenizer extends LocalSRXSentenceTokenizer { public SimpleSentenceTokenizer ( ) { super ( new AnyLanguage ( ) , "/org/languagetool/tokenizers/segment-simple.srx" ) ; } static class AnyLanguage extends Language { @ Override public String getShortName ( ) { return "xx" ; } @ Override public String getName ( ) { return "FakeLanguage" ; } @ Override public String [ ] getCountries ( ) { return new String [ 0 ] ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ 0 ] ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) { return Collections . emptyList ( ) ; } } }
package org . languagetool . tokenizers ; import java . util . List ; public interface Tokenizer { public abstract List < String > tokenize ( String text ) ; }
package org . languagetool . tokenizers ; import java . util . List ; public interface SentenceTokenizer extends Tokenizer { @ Override public List < String > tokenize ( String text ) ; public void setSingleLineBreaksMarksParagraph ( final boolean lineBreakParagraphs ) ; public boolean singleLineBreaksMarksPara ( ) ; }
package org . languagetool . tokenizers ; import net . sourceforge . segment . TextIterator ; import net . sourceforge . segment . srx . SrxDocument ; import net . sourceforge . segment . srx . SrxParser ; import net . sourceforge . segment . srx . SrxTextIterator ; import net . sourceforge . segment . srx . io . Srx2SaxParser ; import org . languagetool . JLanguageTool ; import java . io . * ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; final class SrxTools { private SrxTools ( ) { } static SrxDocument createSrxDocument ( String path ) { try { try ( InputStream inputStream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( path ) ; BufferedReader srxReader = new BufferedReader ( new InputStreamReader ( inputStream , "utf-8" ) ) ) { Map < String , Object > parserParameters = new HashMap < > ( ) ; parserParameters . put ( Srx2SaxParser . VALIDATE_PARAMETER , true ) ; SrxParser srxParser = new Srx2SaxParser ( parserParameters ) ; return srxParser . parse ( srxReader ) ; } } catch ( IOException e ) { throw new RuntimeException ( "Could not load SRX rules" , e ) ; } } static List < String > tokenize ( String text , SrxDocument srxDocument , String code ) { List < String > segments = new ArrayList < > ( ) ; TextIterator textIterator = new SrxTextIterator ( srxDocument , code , text ) ; while ( textIterator . hasNext ( ) ) { segments . add ( textIterator . next ( ) ) ; } return segments ; } }
package org . languagetool . tokenizers ; import net . sourceforge . segment . srx . SrxDocument ; import org . languagetool . Language ; import java . util . List ; public class SRXSentenceTokenizer implements SentenceTokenizer { private static final SrxDocument DOCUMENT = SrxTools . createSrxDocument ( "/segment.srx" ) ; private final String languageCode ; private String parCode ; public SRXSentenceTokenizer ( final Language language ) { this . languageCode = language . getShortName ( ) ; setSingleLineBreaksMarksParagraph ( false ) ; } @ Override public final List < String > tokenize ( final String text ) { return SrxTools . tokenize ( text , DOCUMENT , languageCode + parCode ) ; } @ Override public final boolean singleLineBreaksMarksPara ( ) { return "_one" . equals ( parCode ) ; } @ Override public final void setSingleLineBreaksMarksParagraph ( final boolean lineBreakParagraphs ) { if ( lineBreakParagraphs ) { parCode = "_one" ; } else { parCode = "_two" ; } } }
package org . languagetool . synthesis . ro ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; public class RomanianSynthesizerTest extends TestCase { public final void testSynthesizeStringString ( ) throws IOException { RomanianSynthesizer synth = new RomanianSynthesizer ( ) ; assertEquals ( synth . synthesize ( dummyToken ( "blablabla" ) , "blablabla" ) . length , 0 ) ; assertEquals ( "[alege]" , Arrays . toString ( synth . synthesize ( dummyToken ( "alege" ) , "V000000f00" ) ) ) ; assertEquals ( "[alegeți]" , Arrays . toString ( synth . synthesize ( dummyToken ( "alege" ) , "V0p2000cz0" ) ) ) ; assertEquals ( "[fi]" , Arrays . toString ( synth . synthesize ( dummyToken ( "fi" ) , "V000000f0f" ) ) ) ; assertEquals ( "[sunteți]" , Arrays . toString ( synth . synthesize ( dummyToken ( "fi" ) , "V0p2000izf" ) ) ) ; assertEquals ( "[sunt]" , Arrays . toString ( synth . synthesize ( dummyToken ( "fi" ) , "V0p3000izf" ) ) ) ; assertEquals ( "[sunt]" , Arrays . toString ( synth . synthesize ( dummyToken ( "fi" ) , "V0s1000izf" ) ) ) ; assertEquals ( "[sunteți, sunt]" , Arrays . toString ( synth . synthesize ( dummyToken ( "fi" ) , "V0p2000izf|V0p3000izf" , true ) ) ) ; assertEquals ( "[merseserăm]" , Arrays . toString ( synth . synthesize ( dummyToken ( "merge" ) , "V0p1000im0" ) ) ) ; assertEquals ( "[mersesem]" , Arrays . toString ( synth . synthesize ( dummyToken ( "merge" ) , "V0s1000im0" ) ) ) ; assertEquals ( "[legătura]" , Arrays . toString ( synth . synthesize ( dummyToken ( "legătură" ) , "Sfs3aac000" ) ) ) ; assertEquals ( "[legătură]" , Arrays . toString ( synth . synthesize ( dummyToken ( "legătură" ) , "Sfs3anc000" ) ) ) ; assertEquals ( "[configurați]" , Arrays . toString ( synth . synthesize ( dummyToken ( "configura" ) , "V0p2000cz0" ) ) ) ; assertEquals ( "[configurați, configurezi]" , Arrays . toString ( synth . synthesize ( dummyToken ( "configura" ) , "V0.2000cz0" , true ) ) ) ; } private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } }
package org . languagetool . rules . ca ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class ComplexAdjectiveConcordanceRuleTest extends TestCase { private ComplexAdjectiveConcordanceRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new ComplexAdjectiveConcordanceRule ( TestTools . getEnglishMessages ( ) ) ; langTool = new JLanguageTool ( new Catalan ( ) ) ; } public void testRule ( ) throws IOException { assertCorrect ( "Som els més antisistema" ) ; assertCorrect ( "En un entorn de prova segur" ) ; assertCorrect ( "Amb un termini d'execució de nou mesos aproximadament." ) ; assertCorrect ( "les causes per primera vegada explicades" ) ; assertCorrect ( "per les causes explicades fa molt difícil" ) ; assertCorrect ( "a França mateix" ) ; assertCorrect ( "tenen moltes més dificultats" ) ; assertCorrect ( "l'endeutament que generà fou força elevat" ) ; assertCorrect ( "el text de més àmplia i persistent influència" ) ; assertCorrect ( "el text de més àmplia influència" ) ; assertCorrect ( "Ell i jo som una altra vegada partidaris del rei" ) ; assertCorrect ( "despres de la revolta contra el poder pontifici iniciada a Bolonya" ) ; assertCorrect ( "-Així, ¿viatges sola? -va dir" ) ; assertCorrect ( "El riu passa engorjat en aquest sector " ) ; assertCorrect ( "i ronda amagat pels carrers" ) ; assertCorrect ( "Setmanari il·lustrat d'art, literatura i actualitats fundat a Barcelona" ) ; assertCorrect ( "Entitat oficial de crèdit a mitjà i llarg termini constituïda l'any 1920" ) ; assertCorrect ( "edificacions superposades d'època romana republicanes i imperials" ) ; assertCorrect ( "Fou un dels primers barris de barraques sorgit després del 1939" ) ; assertCorrect ( "i el premi a la investigació mèdica atorgat per la Funadació" ) ; assertCorrect ( "no arriben als 300 mm de pluja anuals" ) ; assertCorrect ( "un dibuix de colors vius d'un noi ben plantat i una noia preciosa drets" ) ; assertCorrect ( "de la captura i l'assassinat recents" ) ; assertCorrect ( "la captura i l'assassinat recents" ) ; assertCorrect ( "era la defensa i seguretat mútues" ) ; assertCorrect ( "la revolta contra el poder pontifici iniciada a Bolonya" ) ; assertCorrect ( "donar estocades sense ordre ni concert mal dirigides" ) ; assertCorrect ( "trobarien un dels nanos mort de fred" ) ; assertCorrect ( "aquest text, el més antic de l'obra fins ara conegut" ) ; assertCorrect ( "va reaccionar, la molt astuta, així" ) ; assertCorrect ( "Són de barba i cabellera blanques" ) ; assertCorrect ( "per a dur a terme tota la lectura i escriptura requerides" ) ; assertCorrect ( "al camí va trobar una branca de roure sòlida" ) ; assertCorrect ( "Tesis doctorals" ) ; assertCorrect ( "Va veure una cara rosada i arrugada, una boca sense dents oberta" ) ; assertCorrect ( "la vista en el magnífic ocell de potes i bec vermells" ) ; assertCorrect ( "-Maleït ximple! -va exclamar Tom" ) ; assertCorrect ( "amb alguns motllurats de guixeria classicitzants" ) ; assertCorrect ( "amb alguns motllurats de guixeria classicitzant" ) ; assertCorrect ( "amb alguns motllurats de guixeria retallats" ) ; assertCorrect ( "amb alguns motllurats de guixeria retallada" ) ; assertCorrect ( "a confondre en un mateix amor amics i enemics" ) ; assertCorrect ( "En l'eix esquerra-dreta." ) ; assertCorrect ( "podrien també esdevenir correlacionades" ) ; assertCorrect ( "Cada polinomi en forma expandida" ) ; assertCorrect ( "El 1967 una partida de liberals rebel al govern" ) ; assertCorrect ( "El 1640 una junta de nobles reunida a Lisboa" ) ; assertCorrect ( "amb una expressió de dolor i de por barrejats." ) ; assertCorrect ( "un tram més tou, amb morfologia i color diferents." ) ; assertCorrect ( "Especialment en matèria de policia i finançament autonòmics" ) ; assertCorrect ( "Especialment en matèria de policia i justícia autonòmiques" ) ; assertCorrect ( "l'obra de Boeci amb espontaneïtat i vigor notables" ) ; assertCorrect ( "tenen en canvi altres parts de llur estructura certament molt anormals:" ) ; assertCorrect ( "constitueix l'única comunitat autònoma amb menys aturats" ) ; assertCorrect ( "durant tot l'any, i del sud-est, més notoris a la primavera" ) ; assertCorrect ( "amb la veu i el posat cada cop més agressius" ) ; assertCorrect ( "l'experiència sensitiva i la raó, degudament combinades." ) ; assertCorrect ( "a la infermeria, d'allò més interessat" ) ; assertCorrect ( "el record, i absolutament fascinats" ) ; assertCorrect ( "no s'atorguen drets de visita tret que ho consenta el progenitor" ) ; assertCorrect ( "La meua filla viu amb mi la major part del temps" ) ; assertCorrect ( "que en l'actualitat viu a la ciutat de Santa Cruz" ) ; assertCorrect ( "són submarines i la nostra gent viu al fons del mar." ) ; assertCorrect ( "la meitat mascles i la meitat femelles" ) ; assertCorrect ( "És força amarg" ) ; assertCorrect ( "Era poderós, força estrabul·lat" ) ; assertCorrect ( "Són força desconegudes" ) ; assertCorrect ( "Zeus, força cansat de tot" ) ; assertCorrect ( "un caràcter fix, per molt extraordinària que sigui la manera" ) ; assertCorrect ( "una quantitat copiosa de llavors olioses" ) ; assertCorrect ( "que criï sense variació, per molt lleugers que fossin" ) ; assertCorrect ( "Bernabé i Saule, un cop acomplerta la seva missió a Jerusalem" ) ; assertCorrect ( "Bernabé i Saule, un colp acomplerta la seva missió a Jerusalem" ) ; assertIncorrect ( "Bernabé i Saule, el colp acomplerta la seva missió a Jerusalem" ) ; assertCorrect ( "Bernabé i Saule, una vegada acomplert el seu viatge a Jerusalem" ) ; assertCorrect ( "Bernabé i Saule, una volta acomplert el seu viatge a Jerusalem" ) ; assertCorrect ( "he passat una nit i un dia sencers a la deriva" ) ; assertCorrect ( "L'olor dels teus perfums, més agradable que tots els bàlsams." ) ; assertCorrect ( "La part superior esquerra" ) ; assertCorrect ( "I sí, la crisi serà llarga, molt llarga, potser eterna." ) ; assertCorrect ( "El rei ha trobat l'excusa i l'explicació adequada." ) ; assertCorrect ( "des de la tradicional divisió en dos regnes establida per Linnaeus" ) ; assertCorrect ( "aquestes activitats avui residuals donada ja la manca de territori" ) ; assertCorrect ( "instruments de càlcul basats en boles anomenats yupana." ) ; assertCorrect ( "El rei ha trobat l'excusa i l'explicació adequades." ) ; assertCorrect ( "Copa del món femenina." ) ; assertCorrect ( "Batalla entre asteques i espanyols coneguda com la Nit Trista." ) ; assertCorrect ( "És un informe sobre la cultura japonesa realitzat per encàrrec de l'exèrcit d'Estats Units." ) ; assertCorrect ( "Les perspectives de futur immediat." ) ; assertCorrect ( "Les perspectives de futur immediates." ) ; assertCorrect ( "la tècnica i l'art cinematogràfiques." ) ; assertCorrect ( "la tècnica i l'art cinematogràfic." ) ; assertCorrect ( "la tècnica i l'art cinematogràfics." ) ; assertCorrect ( "la tècnica i l'art cinematogràfica." ) ; assertCorrect ( "Les perspectives i el futur immediats." ) ; assertCorrect ( "Un punt de densitat i gravetat infinites." ) ; assertCorrect ( "De la literatura i la cultura catalanes." ) ; assertCorrect ( "Es fa segons regles de lectura constants i regulars." ) ; assertCorrect ( "Les meitats dreta i esquerra de la mandíbula." ) ; assertCorrect ( "Els períodes clàssic i medieval." ) ; assertCorrect ( "En una molècula de glucosa i una de fructosa unides." ) ; assertCorrect ( "Índex de desenvolupament humà i qualitat de vida elevat" ) ; assertCorrect ( "Índex de desenvolupament humà i qualitat de vida elevats" ) ; assertCorrect ( "Índex de desenvolupament humà i qualitat de vida elevada" ) ; assertCorrect ( "La massa, el radi i la lluminositat llistats per ell." ) ; assertCorrect ( "La massa, el radi i la lluminositat llistada per ell." ) ; assertCorrect ( "L'origen de l'àbac està literalment perdut en el temps." ) ; assertCorrect ( "L'origen ha esdevingut literalment perdut en el temps." ) ; assertCorrect ( "En efecte, hi ha consideracions racistes, llavors força comunes" ) ; assertCorrect ( "el personatge canvià físicament: més alt i prim que el seu germà" ) ; assertCorrect ( "un a baix i un altre a dalt identificat amb el símbol" ) ; assertCorrect ( "un a baix i un altre a dalt identificats amb el símbol" ) ; assertCorrect ( "El tabaquisme és l'addicció al tabac provocada per components." ) ; assertCorrect ( "El \"treball\" en qüestió, normalment associat a un lloc de treball pagat" ) ; assertCorrect ( "una organització paramilitar de protecció civil típicament catalana" ) ; assertCorrect ( "un Do dues octaves més alt que l'anterior" ) ; assertCorrect ( "són pràcticament dos graus més baixes" ) ; assertCorrect ( "és unes vint vegades més gran que l'espermatozou." ) ; assertCorrect ( "és unes 20 vegades més gran que l'espermatozou." ) ; assertCorrect ( "eren quatre vegades més alts" ) ; assertCorrect ( "eren uns fets cada volta més inexplicables" ) ; assertCorrect ( "El castell està totalment en ruïnes i completament cobert de vegetació." ) ; assertCorrect ( "han estat tant elogiades per la crítica teatral, com polèmiques" ) ; assertCorrect ( "Del segle XVIII però reconstruïda recentment" ) ; assertCorrect ( "La indústria, tradicionalment dedicada al tèxtil i ara molt diversificada," ) ; assertCorrect ( "oficialment la comarca[2] del Moianès, molt reivindicada" ) ; assertCorrect ( "En l'actualitat està del tot despoblada de residència permanent." ) ; assertCorrect ( "amb la terra repartida entre diversos propietaris, bé que encara poc poblada" ) ; assertCorrect ( "al capdamunt de les Costes d'en Quintanes, sota mateix del Turó" ) ; assertCorrect ( "el Moviment per l’Autodeterminació cors" ) ; assertCorrect ( "amb una taula de logaritmes davant meu." ) ; assertCorrect ( "la denominació valencià per a la llengua pròpia" ) ; assertCorrect ( "Com més petita és l'obertura de diafragma, més grans són la profunditat de camp i la profunditat" ) ; assertCorrect ( "es movien mitjançant filferros, tot projectant ombres" ) ; assertCorrect ( "sota les grans persianes de color verd recalcades" ) ; assertCorrect ( "que seria en pocs anys força hegemònica a Catalunya" ) ; assertCorrect ( "Era un home força misteriós" ) ; assertIncorrect ( "França mateix ho necessita." ) ; assertIncorrect ( "recull de llegendes i cançons populars en part inventats per ell" ) ; assertIncorrect ( "amb dos conjunts territorial diferents entre si" ) ; assertIncorrect ( "per mitjà de gàmetes haploides obtingudes per meiosi" ) ; assertIncorrect ( "és tan ple d'urgències, tan ple de desitjós materials" ) ; assertIncorrect ( "Tesis doctoral" ) ; assertIncorrect ( "vaig posar mans a l'obra: a dins de casa mateix vaig cavar un sot per enterrar" ) ; assertIncorrect ( "amb alguns motllurats de guixeria retallat" ) ; assertIncorrect ( "amb alguns motllurats de guixeria retallades" ) ; assertIncorrect ( "Aquella va ser la seva peça mestre." ) ; assertIncorrect ( "La petició de tramitar el cas per lesions dolosa." ) ; assertIncorrect ( "Especialment en matèria de policia i justícia autonòmics" ) ; assertIncorrect ( "amb rigor i honor barrejades." ) ; assertIncorrect ( "hi ha hagut una certa recuperació (3,2%), efecte en part de la descongestió madrilenya cap a les províncies limítrofs de Toledo i Guadalajara." ) ; assertIncorrect ( "Son molt boniques" ) ; assertIncorrect ( "pantalons curt o llargs" ) ; assertIncorrect ( "sota les grans persianes de color verd recalcada" ) ; assertIncorrect ( "sota les grans persianes de color verd recalcat" ) ; assertIncorrect ( "sota les grans persianes de color verd recalcats" ) ; assertIncorrect ( "Són unes corbes de llum complexos." ) ; assertIncorrect ( "fets moltes vegades inexplicable." ) ; assertIncorrect ( "eren uns fets cada volta més inexplicable" ) ; assertIncorrect ( "Unes explotacions ramaderes porcina." ) ; assertIncorrect ( "En efecte, hi ha consideracions llavors força comuns" ) ; assertIncorrect ( "amb una alineació impròpiament habituals" ) ; assertIncorrect ( "amb una alineació poc habituals" ) ; assertIncorrect ( "amb una alineació molt poc habituals" ) ; assertIncorrect ( "Era un home força misteriosos" ) ; assertIncorrect ( "El rei ha trobat l'excusa perfecte." ) ; assertIncorrect ( "El rei ha trobat l'excusa i l'explicació adequats." ) ; assertIncorrect ( "El rei ha trobat l'excusa i l'explicació adequat." ) ; assertIncorrect ( "Les perspectives de futur immediata." ) ; assertIncorrect ( "Les perspectives de futur immediats." ) ; assertIncorrect ( "la llengua i la cultura catalans." ) ; assertIncorrect ( "En una molècula de glucosa i una de fructosa units." ) ; assertIncorrect ( "Un punt de densitat i gravetat infinits." ) ; assertIncorrect ( "Índex de desenvolupament humà i qualitat de vida elevades." ) ; assertIncorrect ( "La massa, el radi i la lluminositat llistat per ell." ) ; assertIncorrect ( "La massa, el radi i la lluminositat llistades per ell." ) ; } private void assertCorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( 0 , matches . length ) ; } private void assertIncorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( 1 , matches . length ) ; } }
package org . languagetool . server ; import org . junit . Test ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class AtDXmlSerializerTest { @ Test public void testGetPreContext ( ) { AtDXmlSerializer serializer = new AtDXmlSerializer ( ) ; assertThat ( serializer . getPreContext ( "test" , 0 ) , is ( "" ) ) ; assertThat ( serializer . getPreContext ( "a hour" , 0 ) , is ( "" ) ) ; assertThat ( serializer . getPreContext ( "is a hour" , 3 ) , is ( "is" ) ) ; assertThat ( serializer . getPreContext ( "an test" , 0 ) , is ( "" ) ) ; assertThat ( serializer . getPreContext ( "is an test" , 3 ) , is ( "is" ) ) ; assertThat ( serializer . getPreContext ( " an test" , 1 ) , is ( "" ) ) ; assertThat ( serializer . getPreContext ( " an test" , 2 ) , is ( "" ) ) ; assertThat ( serializer . getPreContext ( " is an test" , 5 ) , is ( "is" ) ) ; assertThat ( serializer . getPreContext ( "This is an test" , 8 ) , is ( "is" ) ) ; assertThat ( serializer . getPreContext ( "This is an test" , 9 ) , is ( "is" ) ) ; assertThat ( serializer . getPreContext ( "This is an test" , 10 ) , is ( "is" ) ) ; assertThat ( serializer . getPreContext ( "This was a hour ago." , 9 ) , is ( "was" ) ) ; assertThat ( serializer . getPreContext ( "This was a hour ago." , 11 ) , is ( "was" ) ) ; assertThat ( serializer . getPreContext ( "This is, an test" , 9 ) , is ( "" ) ) ; assertThat ( serializer . getPreContext ( "This is: an test" , 9 ) , is ( "" ) ) ; assertThat ( serializer . getPreContext ( "Das hier hier ist ein Test." , 4 ) , is ( "Das" ) ) ; } }
package org . languagetool . server ; import org . junit . Test ; import org . languagetool . Language ; import org . languagetool . language . German ; import java . io . File ; import java . io . IOException ; import java . io . UnsupportedEncodingException ; import java . net . SocketException ; import java . net . URL ; import java . net . URLEncoder ; import static org . junit . Assert . assertTrue ; import static org . junit . Assert . fail ; public class HTTPSServerTest { private static final String KEYSTORE = "/org/languagetool/server/test-keystore.jks" ; private static final String KEYSTORE_PASSWORD = "mytest" ; @ Test public void runRequestLimitationTest ( ) throws Exception { HTTPTools . disableCertChecks ( ) ; final HTTPSServerConfig serverConfig = new HTTPSServerConfig ( HTTPTools . getDefaultPort ( ) , false , getKeystoreFile ( ) , KEYSTORE_PASSWORD , 2 , 120 ) ; final HTTPSServer server = new HTTPSServer ( serverConfig , false , HTTPServerConfig . DEFAULT_HOST , null ) ; try { server . run ( ) ; check ( new German ( ) , "foo" ) ; check ( new German ( ) , "foo" ) ; try { System . out . println ( "=== Testing too many requests now, please ignore the following error ===" ) ; String result = check ( new German ( ) , "foo" ) ; fail ( "Expected exception not thrown, got this result instead: '" + result + "'" ) ; } catch ( IOException expected ) { } } finally { server . stop ( ) ; } } @ Test public void testHTTPSServer ( ) throws Exception { HTTPTools . disableCertChecks ( ) ; final HTTPSServerConfig config = new HTTPSServerConfig ( HTTPTools . getDefaultPort ( ) , false , getKeystoreFile ( ) , KEYSTORE_PASSWORD ) ; config . setMaxTextLength ( 500 ) ; final HTTPSServer server = new HTTPSServer ( config , false , HTTPServerConfig . DEFAULT_HOST , null ) ; try { server . run ( ) ; runTests ( ) ; } finally { server . stop ( ) ; } } private File getKeystoreFile ( ) { final URL keystore = HTTPSServerTest . class . getResource ( KEYSTORE ) ; if ( keystore == null ) { throw new RuntimeException ( "Not found in classpath : " + KEYSTORE ) ; } return new File ( keystore . getFile ( ) ) ; } private void runTests ( ) throws IOException { try { final String httpPrefix = "http://localhost:" + HTTPTools . getDefaultPort ( ) + "/" ; HTTPTools . checkAtUrl ( new URL ( httpPrefix + "?text=a+test&language=en" ) ) ; fail ( "HTTP should not work, only HTTPS" ) ; } catch ( SocketException expected ) { } final String httpsPrefix = "https://localhost:" + HTTPTools . getDefaultPort ( ) + "/" ; final String result = HTTPTools . checkAtUrl ( new URL ( httpsPrefix + "?text=a+test.&language=en" ) ) ; assertTrue ( "Got " + result , result . contains ( "UPPERCASE_SENTENCE_START" ) ) ; final StringBuilder longText = new StringBuilder ( ) ; while ( longText . length ( ) < 490 ) { longText . append ( "B " ) ; } final String result2 = HTTPTools . checkAtUrl ( new URL ( httpsPrefix + "?text=" + encode ( longText . toString ( ) ) + "&language=en" ) ) ; assertTrue ( "Got " + result2 , ! result2 . contains ( "UPPERCASE_SENTENCE_START" ) ) ; assertTrue ( "Got " + result2 , result2 . contains ( "PHRASE_REPETITION" ) ) ; final String overlyLongText = longText + " and some more to get over the limit of 500" ; try { System . out . println ( "=== Now checking text that is too long, please ignore the following exception ===" ) ; HTTPTools . checkAtUrl ( new URL ( httpsPrefix + "?text=" + encode ( overlyLongText ) + "&language=en" ) ) ; fail ( ) ; } catch ( IOException expected ) { if ( ! expected . toString ( ) . contains ( " 413 " ) ) { fail ( "Expected exception with error 413, got: " + expected ) ; } } } private String check ( Language lang , String text ) throws IOException { String urlOptions = "/?language=" + lang . getShortName ( ) ; urlOptions += "&disabled=HUNSPELL_RULE&text=" + URLEncoder . encode ( text , "UTF-8" ) ; final URL url = new URL ( "https://localhost:" + HTTPTools . getDefaultPort ( ) + urlOptions ) ; return HTTPTools . checkAtUrl ( url ) ; } private String encode ( String text ) throws UnsupportedEncodingException { return URLEncoder . encode ( text , "utf-8" ) ; } }
package org . languagetool . server ; import org . junit . Test ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; public class RequestLimiterTest { @ Test public void testIsAccessOkay ( ) throws Exception { final RequestLimiter limiter = new RequestLimiter ( 3 , 2 ) ; final String firstIp = "192.168.10.1" ; final String secondIp = "192.168.10.2" ; assertTrue ( limiter . isAccessOkay ( firstIp ) ) ; assertTrue ( limiter . isAccessOkay ( firstIp ) ) ; assertTrue ( limiter . isAccessOkay ( firstIp ) ) ; assertFalse ( limiter . isAccessOkay ( firstIp ) ) ; assertTrue ( limiter . isAccessOkay ( secondIp ) ) ; Thread . sleep ( 2500 ) ; assertTrue ( limiter . isAccessOkay ( firstIp ) ) ; assertTrue ( limiter . isAccessOkay ( secondIp ) ) ; assertTrue ( limiter . isAccessOkay ( secondIp ) ) ; assertTrue ( limiter . isAccessOkay ( secondIp ) ) ; assertFalse ( limiter . isAccessOkay ( secondIp ) ) ; } }
package org . languagetool . server ; import org . junit . Test ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . assertThat ; public class HTTPServerConfigTest { @ Test public void testArgumentParsing ( ) { final HTTPServerConfig config1 = new HTTPServerConfig ( new String [ ] { } ) ; assertThat ( config1 . getPort ( ) , is ( HTTPServerConfig . DEFAULT_PORT ) ) ; assertThat ( config1 . isPublicAccess ( ) , is ( false ) ) ; assertThat ( config1 . isVerbose ( ) , is ( false ) ) ; final HTTPServerConfig config2 = new HTTPServerConfig ( "--public" . split ( " " ) ) ; assertThat ( config2 . getPort ( ) , is ( HTTPServerConfig . DEFAULT_PORT ) ) ; assertThat ( config2 . isPublicAccess ( ) , is ( true ) ) ; assertThat ( config2 . isVerbose ( ) , is ( false ) ) ; final HTTPServerConfig config3 = new HTTPServerConfig ( "--port 80" . split ( " " ) ) ; assertThat ( config3 . getPort ( ) , is ( 80 ) ) ; assertThat ( config3 . isPublicAccess ( ) , is ( false ) ) ; assertThat ( config3 . isVerbose ( ) , is ( false ) ) ; final HTTPServerConfig config4 = new HTTPServerConfig ( "--port 80 --public" . split ( " " ) ) ; assertThat ( config4 . getPort ( ) , is ( 80 ) ) ; assertThat ( config4 . isPublicAccess ( ) , is ( true ) ) ; assertThat ( config4 . isVerbose ( ) , is ( false ) ) ; } }
package org . languagetool . server ; import org . junit . Test ; import static org . hamcrest . core . Is . is ; import static org . junit . Assert . assertThat ; import static org . junit . Assert . fail ; public class HTTPSServerConfigTest { @ Test public void testArgumentParsing ( ) { try { new HTTPSServerConfig ( new String [ ] { } ) ; fail ( ) ; } catch ( IllegalConfigurationException ignored ) { } final String propertyFile = HTTPSServerConfigTest . class . getResource ( "/org/languagetool/server/https-server.properties" ) . getFile ( ) ; final HTTPSServerConfig config1 = new HTTPSServerConfig ( ( "--public --config " + propertyFile ) . split ( " " ) ) ; assertThat ( config1 . getPort ( ) , is ( HTTPServerConfig . DEFAULT_PORT ) ) ; assertThat ( config1 . isPublicAccess ( ) , is ( true ) ) ; assertThat ( config1 . isVerbose ( ) , is ( false ) ) ; assertThat ( config1 . getKeystore ( ) . toString ( ) . replace ( '\\' , '/' ) , is ( "src/test/resources/org/languagetool/server/test-keystore.jks" ) ) ; assertThat ( config1 . getKeyStorePassword ( ) , is ( "mytest" ) ) ; assertThat ( config1 . getMaxTextLength ( ) , is ( 50000 ) ) ; final HTTPSServerConfig config2 = new HTTPSServerConfig ( ( "-p 9999 --config " + propertyFile ) . split ( " " ) ) ; assertThat ( config2 . getPort ( ) , is ( 9999 ) ) ; assertThat ( config2 . isPublicAccess ( ) , is ( false ) ) ; assertThat ( config2 . isVerbose ( ) , is ( false ) ) ; assertThat ( config2 . getKeystore ( ) . toString ( ) . replace ( '\\' , '/' ) , is ( "src/test/resources/org/languagetool/server/test-keystore.jks" ) ) ; assertThat ( config2 . getKeyStorePassword ( ) , is ( "mytest" ) ) ; assertThat ( config2 . getMaxTextLength ( ) , is ( 50000 ) ) ; } @ Test public void testMinimalPropertyFile ( ) { final String propertyFile = HTTPSServerConfigTest . class . getResource ( "/org/languagetool/server/https-server-minimal.properties" ) . getFile ( ) ; final HTTPSServerConfig config = new HTTPSServerConfig ( ( "--config " + propertyFile ) . split ( " " ) ) ; assertThat ( config . getPort ( ) , is ( 8081 ) ) ; assertThat ( config . isPublicAccess ( ) , is ( false ) ) ; assertThat ( config . isVerbose ( ) , is ( false ) ) ; assertThat ( config . getKeystore ( ) . toString ( ) . replace ( '\\' , '/' ) , is ( "src/test/resources/org/languagetool/server/test-keystore.jks" ) ) ; assertThat ( config . getKeyStorePassword ( ) , is ( "mytest" ) ) ; assertThat ( config . getMaxTextLength ( ) , is ( Integer . MAX_VALUE ) ) ; } @ Test public void testMissingPropertyFile ( ) { final String propertyFile = "/does-not-exist" ; try { new HTTPSServerConfig ( ( "--config " + propertyFile ) . split ( " " ) ) ; fail ( ) ; } catch ( Exception ignored ) { } } @ Test public void testIncompletePropertyFile ( ) { final String propertyFile = HTTPSServerConfigTest . class . getResource ( "/org/languagetool/server/https-server-incomplete.properties" ) . getFile ( ) ; try { new HTTPSServerConfig ( ( "--config " + propertyFile ) . split ( " " ) ) ; fail ( ) ; } catch ( IllegalConfigurationException ignored ) { } } }
package org . languagetool . server ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . Language ; import org . languagetool . Languages ; import java . io . IOException ; import java . net . URL ; import java . net . URLEncoder ; import java . util . ArrayList ; import java . util . List ; import java . util . Random ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . Future ; import static org . junit . Assert . assertTrue ; public class HTTPSServerTesting { private static final String SERVER_URL = "https://localhost:8081" ; private static final int REPEAT_COUNT = 100 ; private static final int THREAD_COUNT = 3 ; private final ExampleSentenceProvider provider = new ExampleSentenceProvider ( 1 , 500 ) ; private final Random rnd = new Random ( 10 ) ; private int checkCount = 0 ; @ Ignore ( "For interactive testing, thus ignored for unit tests" ) @ Test public void interactiveHTTPServerTest ( ) throws Exception { HTTPTools . disableCertChecks ( ) ; final long startTime = System . currentTimeMillis ( ) ; try { final ExecutorService executorService = Executors . newFixedThreadPool ( THREAD_COUNT ) ; final List < Future > futures = new ArrayList < > ( ) ; for ( int i = 0 ; i < THREAD_COUNT ; i ++ ) { final Future < ? > future = executorService . submit ( new TestRunnable ( i ) ) ; futures . add ( future ) ; } for ( Future future : futures ) { future . get ( ) ; } } finally { final long runtime = System . currentTimeMillis ( ) - startTime ; System . out . println ( "Running with " + THREAD_COUNT + " threads in " + runtime + "ms for " + checkCount + " checks" ) ; if ( checkCount > 0 ) { final long timePerCheck = runtime / checkCount ; System . out . println ( " => on average " + timePerCheck + "ms per check" ) ; } } } private class TestRunnable implements Runnable { private final int threadNumber ; TestRunnable ( int threadNumber ) { this . threadNumber = threadNumber ; } @ Override public void run ( ) { try { for ( int i = 0 ; i < REPEAT_COUNT ; i ++ ) { runTests ( threadNumber ) ; } } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } } private void runTests ( int threadNumber ) throws IOException { final List < Language > languages = Languages . get ( ) ; final Language lang = languages . get ( rnd . nextInt ( languages . size ( ) ) ) ; final List < ExampleSentence > sentences = provider . getRandomSentences ( lang ) ; final String text = getSentencesAsText ( sentences ) ; final String data = "language=" + lang . getShortNameWithCountryAndVariant ( ) + "&text=" + URLEncoder . encode ( text , "utf-8" ) ; final String resultXml = checkAtUrl ( new URL ( SERVER_URL ) , data , threadNumber ) ; for ( ExampleSentence sentence : sentences ) { assertTrue ( "Expected " + sentence . getRuleId ( ) + " for '" + text + "' (" + sentences . size ( ) + " sentences)" , resultXml . contains ( sentence . getRuleId ( ) ) ) ; } } private String getSentencesAsText ( List < ExampleSentence > sentences ) { final StringBuilder sb = new StringBuilder ( ) ; for ( ExampleSentence sentence : sentences ) { final String sentenceStr = sentence . getSentence ( ) . replace ( "<marker>" , "" ) . replace ( "</marker>" , "" ) ; final String cleanSentenceStr = sentenceStr . replaceAll ( "[\\n\\t]+" , "" ) ; sb . append ( cleanSentenceStr ) ; sb . append ( "\n\n" ) ; } return sb . toString ( ) ; } private String checkAtUrl ( URL url , String data , int threadNumber ) throws IOException { final long startTime = System . currentTimeMillis ( ) ; final String startOfData = data . substring ( 0 , Math . min ( 30 , data . length ( ) ) ) ; synchronized ( this ) { checkCount ++ ; } final String result = HTTPTools . checkAtUrlByPost ( url , data ) ; System . out . println ( checkCount + ". [" + threadNumber + "] Got " + url + " with data (" + data . length ( ) + " bytes) " + startOfData + "...: " + ( System . currentTimeMillis ( ) - startTime ) + "ms" ) ; return result ; } }
package org . languagetool . server ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . tools . StringTools ; import org . xml . sax . SAXException ; import javax . xml . parsers . ParserConfigurationException ; import java . io . File ; import java . io . FileReader ; import java . io . IOException ; import java . util . HashMap ; import java . util . Map ; import java . util . Random ; import java . util . concurrent . atomic . AtomicInteger ; @ Ignore ( "for interactive use; requires local Tatoeba data" ) public class HTTPServerMultiLangLoadTest extends HTTPServerLoadTest { private static final int MAX_TEXT_LENGTH = 5000 ; private static final int MAX_SLEEP_MILLIS = 10 ; private final Map < Language , String > langCodeToText = new HashMap < > ( ) ; private final Random random = new Random ( 1234 ) ; private final AtomicInteger counter = new AtomicInteger ( ) ; @ Test @ Override public void testHTTPServer ( ) throws Exception { File dir = new File ( "/media/Data/tatoeba/" ) ; for ( Language language : Languages . get ( ) ) { File file = new File ( dir , "tatoeba-" + language . getShortName ( ) + ".txt" ) ; if ( ! file . exists ( ) ) { System . err . println ( "No data found for " + language + ", language will not be tested" ) ; } else { String content = StringTools . readerToString ( new FileReader ( file ) ) ; langCodeToText . put ( language , content ) ; System . err . println ( "Using " + content . length ( ) + " bytes of data for " + language ) ; } } super . testHTTPServer ( ) ; } @ Override protected int getThreadCount ( ) { return 4 ; } @ Override protected int getRepeatCount ( ) { return Integer . MAX_VALUE ; } @ Override void runTests ( ) throws IOException , SAXException , ParserConfigurationException { Language language = getRandomLanguage ( ) ; String text = langCodeToText . get ( language ) ; int fromPos = random . nextInt ( text . length ( ) ) ; int toPos = fromPos + random . nextInt ( MAX_TEXT_LENGTH ) ; String textSubstring = text . substring ( fromPos , Math . min ( toPos , text . length ( ) ) ) ; long sleepTime = random . nextInt ( MAX_SLEEP_MILLIS ) ; try { Thread . sleep ( sleepTime ) ; } catch ( InterruptedException e ) { throw new RuntimeException ( e ) ; } long startTime = System . currentTimeMillis ( ) ; counter . incrementAndGet ( ) ; checkByPOST ( language , textSubstring ) ; System . out . println ( counter . get ( ) + ". Sleep: " + sleepTime + "ms, Lang: " + language . getShortNameWithCountryAndVariant ( ) + ", Time: " + ( System . currentTimeMillis ( ) - startTime ) + "ms" ) ; } private Language getRandomLanguage ( ) { Random rnd = new Random ( ) ; int randomNumber = rnd . nextInt ( langCodeToText . size ( ) ) ; int i = 0 ; for ( Language lang : langCodeToText . keySet ( ) ) { if ( i ++ == randomNumber ) { return lang ; } } throw new RuntimeException ( "Could not find a random language (" + i + ")" ) ; } }
package org . languagetool . server ; import org . languagetool . tools . StringTools ; import javax . net . ssl . HttpsURLConnection ; import javax . net . ssl . SSLContext ; import javax . net . ssl . TrustManager ; import javax . net . ssl . X509TrustManager ; import java . io . IOException ; import java . io . InputStream ; import java . io . OutputStreamWriter ; import java . net . URL ; import java . net . URLConnection ; import java . security . KeyManagementException ; import java . security . NoSuchAlgorithmException ; import java . security . SecureRandom ; import java . security . cert . X509Certificate ; final class HTTPTools { private HTTPTools ( ) { } public static int getDefaultPort ( ) { String defaultPort = System . getProperty ( "lt.default.port" ) ; return defaultPort != null ? Integer . parseInt ( defaultPort ) : HTTPServerConfig . DEFAULT_PORT ; } static void disableCertChecks ( ) throws NoSuchAlgorithmException , KeyManagementException { final TrustManager [ ] trustAllCerts = { new X509TrustManager ( ) { @ Override public X509Certificate [ ] getAcceptedIssuers ( ) { return null ; } @ Override public void checkClientTrusted ( X509Certificate [ ] certs , String authType ) { } @ Override public void checkServerTrusted ( X509Certificate [ ] certs , String authType ) { } } } ; final SSLContext sc = SSLContext . getInstance ( "SSL" ) ; sc . init ( null , trustAllCerts , new SecureRandom ( ) ) ; HttpsURLConnection . setDefaultSSLSocketFactory ( sc . getSocketFactory ( ) ) ; } static String checkAtUrl ( URL url ) throws IOException { final InputStream stream = ( InputStream ) url . getContent ( ) ; return StringTools . streamToString ( stream , "UTF-8" ) ; } static String checkAtUrlByPost ( URL url , String postData ) throws IOException { final String keepAlive = System . getProperty ( "http.keepAlive" ) ; try { System . setProperty ( "http.keepAlive" , "false" ) ; final URLConnection connection = url . openConnection ( ) ; connection . setDoOutput ( true ) ; try ( OutputStreamWriter writer = new OutputStreamWriter ( connection . getOutputStream ( ) ) ) { writer . write ( postData ) ; writer . flush ( ) ; return StringTools . streamToString ( connection . getInputStream ( ) , "UTF-8" ) ; } } finally { if ( keepAlive != null ) { System . setProperty ( "http.keepAlive" , keepAlive ) ; } } } }
package org . languagetool . server ; import org . apache . commons . lang . StringUtils ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . XMLValidator ; import org . languagetool . language . * ; import org . languagetool . tools . StringTools ; import org . xml . sax . SAXException ; import javax . xml . parsers . ParserConfigurationException ; import java . io . IOException ; import java . io . InputStream ; import java . net . URL ; import java . net . URLEncoder ; import java . util . HashSet ; import static org . junit . Assert . * ; public class HTTPServerTest { @ Ignore ( "already gets tested by sub class HTTPServerLoadTest" ) @ Test public void testHTTPServer ( ) throws Exception { final HTTPServer server = new HTTPServer ( ) ; assertFalse ( server . isRunning ( ) ) ; try { server . run ( ) ; assertTrue ( server . isRunning ( ) ) ; runTests ( ) ; } finally { server . stop ( ) ; assertFalse ( server . isRunning ( ) ) ; } } void runTests ( ) throws IOException , SAXException , ParserConfigurationException { final String matchAttr = "software=\"LanguageTool\" version=\"[1-9].*?\" buildDate=\".*?\"" ; final String emptyResultPattern = "<\\?xml version=\"1.0\" encoding=\"UTF-8\"\\?>\n<matches " + matchAttr + ">\n<language shortname=\"de\" name=\"German\"/>\n</matches>\n" ; final German german = new German ( ) ; final String result1 = check ( german , "" ) ; assertTrue ( "Got " + result1 + ", expected " + emptyResultPattern , result1 . matches ( emptyResultPattern ) ) ; final String result2 = check ( german , "Ein kleiner test" ) ; assertTrue ( "Got " + result2 + ", expected " + emptyResultPattern , result2 . matches ( emptyResultPattern ) ) ; assertTrue ( check ( german , "ein kleiner test." ) . contains ( "UPPERCASE_SENTENCE_START" ) ) ; final String result = check ( german , "ein kleiner test. Und wieder Erwarten noch was: \u00f6\u00e4\u00fc\u00df." ) ; assertTrue ( "Got result without 'UPPERCASE_SENTENCE_START': " + result , result . contains ( "UPPERCASE_SENTENCE_START" ) ) ; assertTrue ( "Got result without 'WIEDER_WILLEN': " + result , result . contains ( "WIEDER_WILLEN" ) ) ; assertTrue ( "Expected special chars, got: '" + result + "'" , result . contains ( "\u00f6\u00e4\u00fc\u00df" ) ) ; final XMLValidator validator = new XMLValidator ( ) ; validator . validateXMLString ( result , JLanguageTool . getDataBroker ( ) . getResourceDir ( ) + "/api-output.dtd" , "matches" ) ; validator . checkSimpleXMLString ( result ) ; assertTrue ( ! check ( german , "bla <script>" ) . contains ( "<script>" ) ) ; final String germanSpecialChars = check ( german , "ein kleiner test. Und wieder Erwarten noch was: öäüß+ öäüß." ) ; assertTrue ( "Expected special chars, got: '" + germanSpecialChars + "'" , germanSpecialChars . contains ( "öäüß+" ) ) ; final String romanianSpecialChars = check ( new Romanian ( ) , "bla bla șțîâă șțîâă și câteva caractere speciale" ) ; assertTrue ( "Expected special chars, got: '" + romanianSpecialChars + "'" , romanianSpecialChars . contains ( "șțîâă" ) ) ; final Polish polish = new Polish ( ) ; final String polishSpecialChars = check ( polish , "Mówiła długo, żeby tylko mówić mówić długo." ) ; assertTrue ( "Expected special chars, got: '" + polishSpecialChars + "'" , polishSpecialChars . contains ( "mówić" ) ) ; assertTrue ( checkByPOST ( new Romanian ( ) , "greșit greșit" ) . contains ( "greșit" ) ) ; final URL url = new URL ( "http://localhost:" + HTTPTools . getDefaultPort ( ) + "/Languages" ) ; final String languagesXML = StringTools . streamToString ( ( InputStream ) url . getContent ( ) , "UTF-8" ) ; if ( ! languagesXML . contains ( "Romanian" ) || ! languagesXML . contains ( "English" ) ) { fail ( "Error getting supported languages: " + languagesXML ) ; } if ( ! languagesXML . contains ( "abbr=\"de\"" ) || ! languagesXML . contains ( "abbrWithVariant=\"de-DE\"" ) ) { fail ( "Error getting supported languages: " + languagesXML ) ; } final English english = new English ( ) ; assertTrue ( check ( english , "Me & you you" ) . contains ( "&" ) ) ; assertTrue ( check ( english , german , "We will berate you" ) . contains ( "BERATE" ) ) ; assertTrue ( check ( german , english , "Man sollte ihn nicht so beraten." ) . contains ( "BERATE" ) ) ; assertTrue ( check ( polish , english , "To jest frywolne." ) . contains ( "FRIVOLOUS" ) ) ; assertTrue ( bitextCheck ( polish , english , "This is frivolous." , "To jest frywolne." ) . contains ( "FRIVOLOUS" ) ) ; assertTrue ( ! bitextCheck ( polish , english , "This is something else." , "To jest frywolne." ) . contains ( "FRIVOLOUS" ) ) ; final String [ ] nothing = { } ; assertEquals ( check ( english , german , "We will berate you" ) , checkWithOptions ( english , german , "We will berate you" , nothing , nothing , false ) ) ; final String [ ] disableAvsAn = { "EN_A_VS_AN" } ; assertTrue ( ! checkWithOptions ( english , german , "This is an test" , nothing , disableAvsAn , false ) . contains ( "an test" ) ) ; assertTrue ( checkWithOptions ( english , german , "This is an test" , disableAvsAn , nothing , false ) . contains ( "an test" ) ) ; assertTrue ( checkWithOptions ( english , german , "We will berate you" , disableAvsAn , nothing , false ) . contains ( "BERATE" ) ) ; assertTrue ( ! checkWithOptions ( english , german , "We will berate you" , disableAvsAn , nothing , true ) . contains ( "BERATE" ) ) ; final String [ ] twoRules = { "EN_A_VS_AN" , "BERATE" } ; String resultEn = checkWithOptions ( english , german , "This is an test. We will berate you." , twoRules , nothing , false ) ; assertTrue ( "Result: " + resultEn , resultEn . contains ( "EN_A_VS_AN" ) ) ; assertTrue ( "Result: " + resultEn , resultEn . contains ( "BERATE" ) ) ; String result3 = checkWithOptions ( english , german , "This is an test. We will berate you." , nothing , twoRules , false ) ; assertFalse ( "Result: " + result3 , result3 . contains ( "EN_A_VS_AN" ) ) ; assertFalse ( "Result: " + result3 , result3 . contains ( "BERATE" ) ) ; String result4 = checkWithOptions ( english , german , "This is an test. We will berate you." , disableAvsAn , twoRules , false ) ; assertTrue ( "Result: " + result4 , result4 . contains ( "EN_A_VS_AN" ) ) ; assertFalse ( "Result: " + result4 , result4 . contains ( "BERATE" ) ) ; String result5 = bitextCheckDisabled ( polish , english , "a" , "To jest okropnie długi tekst, naprawdę!" , nothing ) ; assertTrue ( "Result: " + result5 , result5 . contains ( "TRANSLATION_LENGTH" ) ) ; assertFalse ( "Result: " + result5 , result5 . contains ( "\"-2\"" ) ) ; final String [ ] disableTranslationLen = { "TRANSLATION_LENGTH" } ; String result6 = bitextCheckDisabled ( polish , english , "a" , "This is a very long text. Really!" , disableTranslationLen ) ; assertFalse ( "Result: " + result6 , result6 . contains ( "TRANSLATION_LENGTH" ) ) ; } @ Test public void testTimeout ( ) throws Exception { HTTPServerConfig config = new HTTPServerConfig ( HTTPTools . getDefaultPort ( ) , false ) ; config . setMaxCheckTimeMillis ( 1 ) ; final HTTPServer server = new HTTPServer ( config , false ) ; try { server . run ( ) ; try { System . out . println ( "=== Testing timeout now, please ignore the following exception ===" ) ; check ( new GermanyGerman ( ) , "Einq Tesz miit fieln Fehlan, desshalb sehee laagnsam bee dr Rechtschriebpürfung" ) ; fail ( "Check was expected to be stopped because it took too long" ) ; } catch ( IOException expected ) { if ( ! expected . toString ( ) . contains ( " 503 " ) ) { fail ( "Expected exception with error 503, got: " + expected ) ; } } } finally { server . stop ( ) ; } } @ Test public void testAccessDenied ( ) throws Exception { final HTTPServer server = new HTTPServer ( new HTTPServerConfig ( HTTPTools . getDefaultPort ( ) ) , false , new HashSet < String > ( ) ) ; try { server . run ( ) ; try { System . out . println ( "=== Testing 'access denied' check now, please ignore the following exception ===" ) ; check ( new German ( ) , "no ip address allowed, so this cannot work" ) ; fail ( ) ; } catch ( IOException expected ) { if ( ! expected . toString ( ) . contains ( " 403 " ) ) { fail ( "Expected exception with error 403, got: " + expected ) ; } } } finally { server . stop ( ) ; } } @ Test public void testEnabledOnlyParameter ( ) throws Exception { final HTTPServer server = new HTTPServer ( new HTTPServerConfig ( HTTPTools . getDefaultPort ( ) ) , false ) ; try { server . run ( ) ; try { System . out . println ( "=== Testing 'enabledOnly parameter' now, please ignore the following exception ===" ) ; final URL url = new URL ( "http://localhost:" + HTTPTools . getDefaultPort ( ) + "/?text=foo&language=en-US&disabled=EN_A_VS_AN&enabledOnly=yes" ) ; HTTPTools . checkAtUrl ( url ) ; fail ( ) ; } catch ( IOException expected ) { if ( ! expected . toString ( ) . contains ( " 500 " ) ) { fail ( "Expected exception with error 500, got: " + expected ) ; } } } finally { server . stop ( ) ; } } @ Test public void testMissingLanguageParameter ( ) throws Exception { final HTTPServer server = new HTTPServer ( new HTTPServerConfig ( HTTPTools . getDefaultPort ( ) ) , false ) ; try { server . run ( ) ; try { System . out . println ( "=== Testing 'missing language parameter' now, please ignore the following exception ===" ) ; final URL url = new URL ( "http://localhost:" + HTTPTools . getDefaultPort ( ) + "/?text=foo" ) ; HTTPTools . checkAtUrl ( url ) ; fail ( ) ; } catch ( IOException expected ) { if ( ! expected . toString ( ) . contains ( " 500 " ) ) { fail ( "Expected exception with error 500, got: " + expected ) ; } } } finally { server . stop ( ) ; } } private String bitextCheck ( Language lang , Language motherTongue , String sourceText , String text ) throws IOException { String urlOptions = "/?language=" + lang . getShortName ( ) ; urlOptions += "&srctext=" + URLEncoder . encode ( sourceText , "UTF-8" ) ; urlOptions += "&text=" + URLEncoder . encode ( text , "UTF-8" ) ; if ( motherTongue != null ) { urlOptions += "&motherTongue=" + motherTongue . getShortName ( ) ; } final URL url = new URL ( "http://localhost:" + HTTPTools . getDefaultPort ( ) + urlOptions ) ; return HTTPTools . checkAtUrl ( url ) ; } private String bitextCheckDisabled ( Language lang , Language motherTongue , String sourceText , String text , String [ ] disabled ) throws IOException { String urlOptions = "/?language=" + lang . getShortName ( ) ; urlOptions += "&srctext=" + URLEncoder . encode ( sourceText , "UTF-8" ) ; urlOptions += "&text=" + URLEncoder . encode ( text , "UTF-8" ) ; if ( motherTongue != null ) { urlOptions += "&motherTongue=" + motherTongue . getShortName ( ) ; } if ( disabled . length > 0 ) { urlOptions += "&disabled=" + StringUtils . join ( disabled , "," ) ; } final URL url = new URL ( "http://localhost:" + HTTPTools . getDefaultPort ( ) + urlOptions ) ; return HTTPTools . checkAtUrl ( url ) ; } private String check ( Language lang , String text ) throws IOException { return check ( lang , null , text ) ; } protected String check ( Language lang , Language motherTongue , String text ) throws IOException { String urlOptions = "/?language=" + lang . getShortName ( ) ; urlOptions += "&disabled=HUNSPELL_RULE&text=" + URLEncoder . encode ( text , "UTF-8" ) ; if ( motherTongue != null ) { urlOptions += "&motherTongue=" + motherTongue . getShortName ( ) ; } final URL url = new URL ( "http://localhost:" + HTTPTools . getDefaultPort ( ) + urlOptions ) ; return HTTPTools . checkAtUrl ( url ) ; } private String checkWithOptions ( Language lang , Language motherTongue , String text , String [ ] enabledRules , String [ ] disabledRules , boolean useEnabledOnly ) throws IOException { String urlOptions = "/?language=" + lang . getShortName ( ) ; urlOptions += "&text=" + URLEncoder . encode ( text , "UTF-8" ) ; if ( motherTongue != null ) { urlOptions += "&motherTongue=" + motherTongue . getShortName ( ) ; } if ( disabledRules . length > 0 ) { urlOptions += "&disabled=" + StringUtils . join ( disabledRules , "," ) ; } if ( enabledRules . length > 0 ) { urlOptions += "&enabled=" + StringUtils . join ( enabledRules , "," ) ; } if ( useEnabledOnly ) { urlOptions += "&enabledOnly=yes" ; } final URL url = new URL ( "http://localhost:" + HTTPTools . getDefaultPort ( ) + urlOptions ) ; return HTTPTools . checkAtUrl ( url ) ; } protected String checkByPOST ( Language lang , String text ) throws IOException { final String postData = "language=" + lang . getShortName ( ) + "&text=" + URLEncoder . encode ( text , "UTF-8" ) ; final URL url = new URL ( "http://localhost:" + HTTPTools . getDefaultPort ( ) ) ; return HTTPTools . checkAtUrlByPost ( url , postData ) ; } }
package org . languagetool . server ; import org . junit . Test ; import java . util . ArrayList ; import java . util . List ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . Future ; import java . util . concurrent . atomic . AtomicInteger ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; public class HTTPServerLoadTest extends HTTPServerTest { private static final int REPEAT_COUNT = 1 ; private static final int THREAD_COUNT = 2 ; private final AtomicInteger runningTests = new AtomicInteger ( ) ; @ Test @ Override public void testHTTPServer ( ) throws Exception { final long startTime = System . currentTimeMillis ( ) ; HTTPServerConfig config = new HTTPServerConfig ( HTTPTools . getDefaultPort ( ) , true ) ; final HTTPServer server = new HTTPServer ( config ) ; assertFalse ( server . isRunning ( ) ) ; try { server . run ( ) ; assertTrue ( server . isRunning ( ) ) ; final ExecutorService executorService = Executors . newFixedThreadPool ( getThreadCount ( ) ) ; final List < Future > futures = new ArrayList < > ( ) ; for ( int i = 0 ; i < getThreadCount ( ) ; i ++ ) { final Future < ? > future = executorService . submit ( new TestRunnable ( ) ) ; futures . add ( future ) ; } for ( Future future : futures ) { future . get ( ) ; } } finally { server . stop ( ) ; assertFalse ( server . isRunning ( ) ) ; final long runtime = System . currentTimeMillis ( ) - startTime ; System . out . println ( "Running with " + getThreadCount ( ) + " threads in " + runtime + "ms" ) ; } } protected int getThreadCount ( ) { return THREAD_COUNT ; } protected int getRepeatCount ( ) { return REPEAT_COUNT ; } @ Override public void testAccessDenied ( ) throws Exception { } private class TestRunnable implements Runnable { @ Override public void run ( ) { for ( int i = 0 ; i < getRepeatCount ( ) ; i ++ ) { runningTests . incrementAndGet ( ) ; try { runTests ( ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } finally { int count = runningTests . decrementAndGet ( ) ; System . out . println ( "Tests currently running " + count ) ; } } } } }
package org . languagetool . rules . ro ; import java . io . IOException ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Romanian ; import org . languagetool . rules . AbstractCompoundRuleTest ; public class CompoundRuleTest extends AbstractCompoundRuleTest { @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; langTool = new JLanguageTool ( new Romanian ( ) ) ; rule = new CompoundRule ( TestTools . getMessages ( "ro" ) ) ; } public void testRule ( ) throws IOException { check ( 0 , "Au plecat câteșitrei." ) ; check ( 1 , "câte și trei" , new String [ ] { "câteșitrei" } ) ; check ( 1 , "Câte și trei" , new String [ ] { "Câteșitrei" } ) ; check ( 1 , "câte-și-trei" , new String [ ] { "câteșitrei" } ) ; check ( 1 , "tus trei" , new String [ ] { "tustrei" } ) ; check ( 1 , "tus-trei" , new String [ ] { "tustrei" } ) ; } }
package org . languagetool . server ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . rules . Rule ; import org . languagetool . rules . patterns . PatternRule ; import java . io . IOException ; import java . util . * ; class ExampleSentenceProvider { private final int minSentences ; private final int maxSentences ; private final Random rnd = new Random ( 12345 ) ; private final Map < Language , List < ExampleSentence > > languageToExamples = new HashMap < > ( ) ; ExampleSentenceProvider ( int minSentences , int maxSentences ) { if ( minSentences > maxSentences ) { throw new IllegalArgumentException ( "min > max: " + minSentences + " > " + maxSentences ) ; } this . minSentences = minSentences ; this . maxSentences = maxSentences ; for ( Language language : Languages . get ( ) ) { try { initExampleSentences ( language ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } } private void initExampleSentences ( Language language ) throws IOException { final JLanguageTool lt = new JLanguageTool ( language ) ; final List < Rule > rules = lt . getAllActiveRules ( ) ; final List < ExampleSentence > sentences = new ArrayList < > ( ) ; for ( Rule rule : rules ) { if ( rule instanceof PatternRule && ! rule . isDefaultOff ( ) ) { final List < IncorrectExample > incorrectExamples = rule . getIncorrectExamples ( ) ; for ( IncorrectExample incorrectExample : incorrectExamples ) { final ExampleSentence sentence = new ExampleSentence ( incorrectExample . getExample ( ) , rule . getId ( ) ) ; sentences . add ( sentence ) ; } } } languageToExamples . put ( language , sentences ) ; } List < ExampleSentence > getRandomSentences ( Language lang ) { final List < ExampleSentence > sentences = new ArrayList < > ( languageToExamples . get ( lang ) ) ; final int sentenceCount = rnd . nextInt ( Math . max ( 1 , maxSentences - minSentences ) ) + minSentences ; Collections . shuffle ( sentences , rnd ) ; return sentences . subList ( 0 , Math . min ( sentences . size ( ) , sentenceCount ) ) ; } }
package org . languagetool . server ; class ExampleSentence { private final String sentence ; private final String ruleId ; ExampleSentence ( String sentence , String ruleId ) { this . sentence = sentence ; this . ruleId = ruleId ; } public String getSentence ( ) { return sentence ; } public String getRuleId ( ) { return ruleId ; } }
package org . languagetool . server ; import com . sun . net . httpserver . HttpsConfigurator ; import com . sun . net . httpserver . HttpsParameters ; import com . sun . net . httpserver . HttpsServer ; import org . languagetool . JLanguageTool ; import org . languagetool . gui . Tools ; import javax . net . ssl . KeyManagerFactory ; import javax . net . ssl . SSLContext ; import javax . net . ssl . SSLParameters ; import javax . net . ssl . TrustManagerFactory ; import java . io . File ; import java . io . FileInputStream ; import java . net . BindException ; import java . net . InetSocketAddress ; import java . security . KeyStore ; import java . util . ResourceBundle ; import java . util . Set ; import java . util . concurrent . * ; import static org . languagetool . server . HTTPServerConfig . DEFAULT_HOST ; public class HTTPSServer extends Server { private final ExecutorService executorService ; public HTTPSServer ( HTTPSServerConfig config , boolean runInternally , String host , Set < String > allowedIps ) { this . port = config . getPort ( ) ; this . host = host ; try { if ( host == null ) { server = HttpsServer . create ( new InetSocketAddress ( port ) , 0 ) ; } else { server = HttpsServer . create ( new InetSocketAddress ( host , port ) , 0 ) ; } final SSLContext sslContext = getSslContext ( config . getKeystore ( ) , config . getKeyStorePassword ( ) ) ; final HttpsConfigurator configurator = getConfigurator ( sslContext ) ; ( ( HttpsServer ) server ) . setHttpsConfigurator ( configurator ) ; final RequestLimiter limiter = getRequestLimiterOrNull ( config ) ; final LinkedBlockingQueue < Runnable > workQueue = new LinkedBlockingQueue < > ( ) ; httpHandler = new LanguageToolHttpHandler ( config . isVerbose ( ) , allowedIps , runInternally , limiter , workQueue ) ; httpHandler . setMaxTextLength ( config . getMaxTextLength ( ) ) ; httpHandler . setAllowOriginUrl ( config . getAllowOriginUrl ( ) ) ; httpHandler . setMaxCheckTimeMillis ( config . getMaxCheckTimeMillis ( ) ) ; httpHandler . setTrustXForwardForHeader ( config . getTrustXForwardForHeader ( ) ) ; if ( config . getMode ( ) == HTTPServerConfig . Mode . AfterTheDeadline ) { httpHandler . setAfterTheDeadlineMode ( config . getAfterTheDeadlineLanguage ( ) ) ; } httpHandler . setLanguageModel ( config . getLanguageModelDir ( ) ) ; httpHandler . setMaxWorkQueueSize ( config . getMaxWorkQueueSize ( ) ) ; server . createContext ( "/" , httpHandler ) ; executorService = getExecutorService ( workQueue , config ) ; server . setExecutor ( executorService ) ; } catch ( BindException e ) { final ResourceBundle messages = JLanguageTool . getMessageBundle ( ) ; final String message = Tools . makeTexti18n ( messages , "https_server_start_failed" , host , Integer . toString ( port ) ) ; throw new PortBindingException ( message , e ) ; } catch ( Exception e ) { final ResourceBundle messages = JLanguageTool . getMessageBundle ( ) ; final String message = Tools . makeTexti18n ( messages , "https_server_start_failed_unknown_reason" , host , Integer . toString ( port ) ) ; throw new RuntimeException ( message , e ) ; } } private SSLContext getSslContext ( File keyStoreFile , String passPhrase ) { try ( FileInputStream keyStoreStream = new FileInputStream ( keyStoreFile ) ) { final KeyStore keystore = KeyStore . getInstance ( "JKS" ) ; keystore . load ( keyStoreStream , passPhrase . toCharArray ( ) ) ; final KeyManagerFactory kmf = KeyManagerFactory . getInstance ( "SunX509" ) ; kmf . init ( keystore , passPhrase . toCharArray ( ) ) ; final TrustManagerFactory tmf = TrustManagerFactory . getInstance ( "SunX509" ) ; tmf . init ( keystore ) ; final SSLContext sslContext = SSLContext . getInstance ( "TLS" ) ; sslContext . init ( kmf . getKeyManagers ( ) , tmf . getTrustManagers ( ) , null ) ; return sslContext ; } catch ( Exception e ) { throw new RuntimeException ( "Could not set up SSL context" , e ) ; } } private HttpsConfigurator getConfigurator ( final SSLContext sslContext ) { return new HttpsConfigurator ( sslContext ) { @ Override public void configure ( HttpsParameters params ) { final SSLContext context = getSSLContext ( ) ; final SSLParameters sslParams = context . getDefaultSSLParameters ( ) ; params . setNeedClientAuth ( false ) ; params . setSSLParameters ( sslParams ) ; } } ; } @ Override public void stop ( ) { super . stop ( ) ; if ( executorService != null ) { executorService . shutdownNow ( ) ; } } public static void main ( String [ ] args ) { if ( args . length == 0 || args . length > 7 || usageRequested ( args ) ) { System . out . println ( "Usage: " + HTTPSServer . class . getSimpleName ( ) + " --config propertyFile [--port|-p port] [--public]" ) ; System . out . println ( " --config file a Java property file (one key=value entry per line) with values for:" ) ; System . out . println ( " 'keystore' - a Java keystore with an SSL certificate" ) ; System . out . println ( " 'password' - the keystore's password" ) ; printCommonConfigFileOptions ( ) ; printCommonOptions ( ) ; System . exit ( 1 ) ; } final boolean runInternal = false ; try { final HTTPSServerConfig config = new HTTPSServerConfig ( args ) ; try { final HTTPSServer server ; if ( config . isPublicAccess ( ) ) { System . out . println ( "WARNING: running in public mode, LanguageTool API can be accessed without restrictions!" ) ; server = new HTTPSServer ( config , runInternal , null , null ) ; } else { server = new HTTPSServer ( config , runInternal , DEFAULT_HOST , DEFAULT_ALLOWED_IPS ) ; } server . run ( ) ; } catch ( Exception e ) { throw new RuntimeException ( "Could not start LanguageTool HTTPS server on " + HTTPServerConfig . DEFAULT_HOST + ", port " + config . getPort ( ) , e ) ; } } catch ( IllegalConfigurationException e ) { System . out . println ( e . getMessage ( ) ) ; System . out . println ( "Note: this is the HTTPS server - if you want to use plain HTTP instead, please see http://languagetool.org/http-server/" ) ; System . exit ( 1 ) ; } } @ Override protected String getProtocol ( ) { return "https" ; } }
package org . languagetool . server ; import java . io . * ; import java . net . * ; import java . text . SimpleDateFormat ; import java . util . * ; import java . util . concurrent . * ; import org . apache . commons . lang . StringUtils ; import org . jetbrains . annotations . Nullable ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . gui . Configuration ; import org . languagetool . language . LanguageIdentifier ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . bitext . BitextRule ; import org . languagetool . tools . RuleAsXmlSerializer ; import org . languagetool . tools . StringTools ; import org . languagetool . tools . Tools ; import com . sun . net . httpserver . HttpExchange ; import com . sun . net . httpserver . HttpHandler ; import static org . languagetool . tools . StringTools . escapeForXmlContent ; class LanguageToolHttpHandler implements HttpHandler { private static final String CONTENT_TYPE_VALUE = "text/xml; charset=UTF-8" ; private static final String ENCODING = "utf-8" ; private static final int CONTEXT_SIZE = 40 ; private static int handleCount = 0 ; private final Set < String > allowedIps ; private final boolean verbose ; private final boolean internalServer ; private final RequestLimiter requestLimiter ; private final LinkedBlockingQueue < Runnable > workQueue ; private final ExecutorService executorService ; private final LanguageIdentifier identifier ; private long maxCheckTimeMillis = - 1 ; private int maxTextLength = Integer . MAX_VALUE ; private String allowOriginUrl ; private boolean afterTheDeadlineMode ; private Language afterTheDeadlineLanguage ; private File languageModelDir ; private int maxWorkQueueSize ; private boolean trustXForwardForHeader = false ; private Set < String > ownIps ; LanguageToolHttpHandler ( boolean verbose , Set < String > allowedIps , boolean internal , RequestLimiter requestLimiter , LinkedBlockingQueue < Runnable > workQueue ) { this . verbose = verbose ; this . allowedIps = allowedIps ; this . internalServer = internal ; this . requestLimiter = requestLimiter ; this . workQueue = workQueue ; this . executorService = Executors . newCachedThreadPool ( ) ; this . identifier = new LanguageIdentifier ( ) ; } void shutdown ( ) { executorService . shutdownNow ( ) ; } void setMaxTextLength ( int maxTextLength ) { this . maxTextLength = maxTextLength ; } void setMaxCheckTimeMillis ( long maxCheckTimeMillis ) { this . maxCheckTimeMillis = maxCheckTimeMillis ; } void setTrustXForwardForHeader ( boolean trustXForwardForHeader ) { this . trustXForwardForHeader = trustXForwardForHeader ; if ( trustXForwardForHeader ) { this . ownIps = getServersOwnIps ( ) ; } } void setAllowOriginUrl ( String allowOriginUrl ) { this . allowOriginUrl = allowOriginUrl ; } void setAfterTheDeadlineMode ( Language defaultLanguage ) { System . out . println ( "Running in After the Deadline mode, default language: " + defaultLanguage ) ; this . afterTheDeadlineMode = true ; this . afterTheDeadlineLanguage = defaultLanguage ; } void setLanguageModel ( File languageModelDir ) { this . languageModelDir = languageModelDir ; } void setMaxWorkQueueSize ( int size ) { if ( size < 0 ) { throw new IllegalArgumentException ( "Max queue size must be >= 0: " + size ) ; } this . maxWorkQueueSize = size ; } @ Override public void handle ( HttpExchange httpExchange ) throws IOException { synchronized ( this ) { handleCount ++ ; } String text = null ; try { final URI requestedUri = httpExchange . getRequestURI ( ) ; final String origAddress = httpExchange . getRemoteAddress ( ) . getAddress ( ) . getHostAddress ( ) ; final String realAddressOrNull = getRealRemoteAddressOrNull ( httpExchange ) ; final String remoteAddress = realAddressOrNull != null ? realAddressOrNull : origAddress ; final Map < String , String > parameters = getRequestQuery ( httpExchange , requestedUri ) ; if ( requestLimiter != null && ! requestLimiter . isAccessOkay ( remoteAddress ) ) { final String errorMessage = "Error: Access from " + remoteAddress + " denied - too many requests. Allowed maximum requests: " + requestLimiter . getRequestLimit ( ) + " requests per " + requestLimiter . getRequestLimitPeriodInSeconds ( ) + " seconds" ; sendError ( httpExchange , HttpURLConnection . HTTP_FORBIDDEN , errorMessage ) ; print ( errorMessage ) ; return ; } if ( maxWorkQueueSize != 0 && workQueue . size ( ) > maxWorkQueueSize ) { String response = "Error: There are currently too many parallel requests. Please try again later." ; print ( response + " Queue size: " + workQueue . size ( ) + ", maximum size: " + maxWorkQueueSize ) ; sendError ( httpExchange , HttpURLConnection . HTTP_UNAVAILABLE , "Error: " + response ) ; return ; } if ( allowedIps == null || allowedIps . contains ( origAddress ) ) { if ( requestedUri . getRawPath ( ) . endsWith ( "/Languages" ) ) { printListOfLanguages ( httpExchange ) ; } else { if ( afterTheDeadlineMode ) { text = parameters . get ( "data" ) ; if ( text == null ) { throw new IllegalArgumentException ( "Missing 'data' parameter" ) ; } text = text . replaceAll ( "</p>" , "\n\n" ) . replaceAll ( "<.*?>" , "" ) ; } else { text = parameters . get ( "text" ) ; if ( text == null ) { throw new IllegalArgumentException ( "Missing 'text' parameter" ) ; } } checkText ( text , httpExchange , parameters ) ; } } else { final String errorMessage = "Error: Access from " + StringTools . escapeXML ( origAddress ) + " denied" ; sendError ( httpExchange , HttpURLConnection . HTTP_FORBIDDEN , errorMessage ) ; throw new RuntimeException ( errorMessage ) ; } } catch ( Exception e ) { print ( "An error has occurred. Stacktrace follows:" , System . err ) ; if ( verbose && text != null ) { print ( "Exception was caused by this text (" + text . length ( ) + " chars, showing up to 500):\n" + StringUtils . abbreviate ( text , 500 ) , System . err ) ; } e . printStackTrace ( ) ; String response ; int errorCode ; if ( e instanceof TextTooLongException ) { errorCode = HttpURLConnection . HTTP_ENTITY_TOO_LARGE ; response = e . getMessage ( ) ; } else if ( e . getCause ( ) != null && e . getCause ( ) instanceof TimeoutException ) { errorCode = HttpURLConnection . HTTP_UNAVAILABLE ; response = "Checking took longer than " + maxCheckTimeMillis / 1000 + " seconds, which is this server's limit. " + "Please make sure you have selected the proper language or consider submitting a shorter text." ; } else { response = Tools . getFullStackTrace ( e ) ; errorCode = HttpURLConnection . HTTP_INTERNAL_ERROR ; } sendError ( httpExchange , errorCode , "Error: " + response ) ; } finally { synchronized ( this ) { handleCount -- ; } httpExchange . close ( ) ; } } private Set < String > getServersOwnIps ( ) { Set < String > ownIps = new HashSet < > ( ) ; try { Enumeration e = NetworkInterface . getNetworkInterfaces ( ) ; while ( e . hasMoreElements ( ) ) { NetworkInterface netInterface = ( NetworkInterface ) e . nextElement ( ) ; Enumeration addresses = netInterface . getInetAddresses ( ) ; while ( addresses . hasMoreElements ( ) ) { InetAddress address = ( InetAddress ) addresses . nextElement ( ) ; ownIps . add ( address . getHostAddress ( ) ) ; } } } catch ( SocketException e1 ) { throw new RuntimeException ( "Could not get the servers own IP addresses" , e1 ) ; } return ownIps ; } @ Nullable private String getRealRemoteAddressOrNull ( HttpExchange httpExchange ) { if ( trustXForwardForHeader ) { List < String > forwardedIpsStr = httpExchange . getRequestHeaders ( ) . get ( "X-forwarded-for" ) ; if ( forwardedIpsStr != null ) { String allForwardedIpsStr = StringUtils . join ( forwardedIpsStr , ", " ) ; List < String > allForwardedIps = Arrays . asList ( allForwardedIpsStr . split ( ", " ) ) ; return getLastIpIgnoringOwn ( allForwardedIps ) ; } } return null ; } private String getLastIpIgnoringOwn ( List < String > forwardedIps ) { String lastIp = null ; for ( String ip : forwardedIps ) { if ( ownIps . contains ( ip ) ) { continue ; } lastIp = ip ; } return lastIp ; } private void sendError ( HttpExchange httpExchange , int httpReturnCode , String response ) throws IOException { if ( afterTheDeadlineMode ) { String xmlResponse = "<results><message>" + escapeForXmlContent ( response ) + "</message></results>" ; httpExchange . sendResponseHeaders ( httpReturnCode , xmlResponse . getBytes ( ENCODING ) . length ) ; httpExchange . getResponseBody ( ) . write ( xmlResponse . getBytes ( ENCODING ) ) ; } else { httpExchange . sendResponseHeaders ( httpReturnCode , response . getBytes ( ENCODING ) . length ) ; httpExchange . getResponseBody ( ) . write ( response . getBytes ( ENCODING ) ) ; } } private Map < String , String > getRequestQuery ( HttpExchange httpExchange , URI requestedUri ) throws IOException { final String query ; if ( "post" . equalsIgnoreCase ( httpExchange . getRequestMethod ( ) ) ) { query = StringTools . streamToString ( httpExchange . getRequestBody ( ) , ENCODING ) ; } else { query = requestedUri . getRawQuery ( ) ; } return parseQuery ( query ) ; } private void printListOfLanguages ( HttpExchange httpExchange ) throws IOException { setCommonHeaders ( httpExchange ) ; final String response = getSupportedLanguagesAsXML ( ) ; httpExchange . sendResponseHeaders ( HttpURLConnection . HTTP_OK , response . getBytes ( ENCODING ) . length ) ; httpExchange . getResponseBody ( ) . write ( response . getBytes ( ENCODING ) ) ; } private void setCommonHeaders ( HttpExchange httpExchange ) { httpExchange . getResponseHeaders ( ) . set ( "Content-Type" , CONTENT_TYPE_VALUE ) ; if ( allowOriginUrl != null ) { httpExchange . getResponseHeaders ( ) . set ( "Access-Control-Allow-Origin" , allowOriginUrl ) ; } } private Language detectLanguageOfString ( final String text , final String fallbackLanguage ) { Language lang = identifier . detectLanguage ( text ) ; if ( lang == null ) { lang = Languages . getLanguageForShortName ( fallbackLanguage != null ? fallbackLanguage : "en" ) ; } if ( lang . getDefaultLanguageVariant ( ) != null ) { lang = lang . getDefaultLanguageVariant ( ) ; } return lang ; } private void checkText ( final String text , final HttpExchange httpExchange , final Map < String , String > parameters ) throws Exception { final long timeStart = System . currentTimeMillis ( ) ; if ( text . length ( ) > maxTextLength ) { throw new TextTooLongException ( "Your text exceeds this server's limit of " + maxTextLength + " characters (it's " + text . length ( ) + " characters). Please submit a shorter text." ) ; } final boolean autoDetectLanguage = getLanguageAutoDetect ( parameters ) ; final Language lang = getLanguage ( text , parameters . get ( "language" ) , autoDetectLanguage ) ; final String motherTongueParam = parameters . get ( "motherTongue" ) ; final Language motherTongue = motherTongueParam != null ? Languages . getLanguageForShortName ( motherTongueParam ) : null ; final boolean useEnabledOnly = "yes" . equals ( parameters . get ( "enabledOnly" ) ) ; final String enabledParam = parameters . get ( "enabled" ) ; final List < String > enabledRules = new ArrayList < > ( ) ; if ( enabledParam != null ) { enabledRules . addAll ( Arrays . asList ( enabledParam . split ( "," ) ) ) ; } final String disabledParam = parameters . get ( "disabled" ) ; final List < String > disabledRules = new ArrayList < > ( ) ; if ( disabledParam != null ) { disabledRules . addAll ( Arrays . asList ( disabledParam . split ( "," ) ) ) ; } if ( disabledRules . size ( ) > 0 && useEnabledOnly ) { throw new IllegalArgumentException ( "You cannot specify disabled rules using enabledOnly=yes" ) ; } final boolean useQuerySettings = enabledRules . size ( ) > 0 || disabledRules . size ( ) > 0 ; final QueryParams params = new QueryParams ( enabledRules , disabledRules , useEnabledOnly , useQuerySettings ) ; final Future < List < RuleMatch > > future = executorService . submit ( new Callable < List < RuleMatch > > ( ) { @ Override public List < RuleMatch > call ( ) throws Exception { return getRuleMatches ( text , parameters , lang , motherTongue , params ) ; } } ) ; final List < RuleMatch > matches ; if ( maxCheckTimeMillis < 0 ) { matches = future . get ( ) ; } else { try { matches = future . get ( maxCheckTimeMillis , TimeUnit . MILLISECONDS ) ; } catch ( TimeoutException e ) { throw new RuntimeException ( "Text checking took longer than allowed maximum of " + maxCheckTimeMillis + " milliseconds (handleCount: " + handleCount + ", queue size: " + workQueue . size ( ) + ", language: " + lang . getShortNameWithCountryAndVariant ( ) + ", " + text . length ( ) + " characters of text)" , e ) ; } } setCommonHeaders ( httpExchange ) ; String xmlResponse = getXmlResponse ( text , lang , motherTongue , matches ) ; String messageSent = "sent" ; String languageMessage = lang . getShortNameWithCountryAndVariant ( ) ; final String referrer = httpExchange . getRequestHeaders ( ) . getFirst ( "Referer" ) ; try { httpExchange . sendResponseHeaders ( HttpURLConnection . HTTP_OK , xmlResponse . getBytes ( ENCODING ) . length ) ; httpExchange . getResponseBody ( ) . write ( xmlResponse . getBytes ( ENCODING ) ) ; if ( motherTongue != null ) { languageMessage += " (mother tongue: " + motherTongue . getShortNameWithCountryAndVariant ( ) + ")" ; } } catch ( IOException exception ) { messageSent = "notSent: " + exception . getMessage ( ) ; } print ( "Check done: " + text . length ( ) + " chars, " + languageMessage + ", " + referrer + ", " + "handlers:" + handleCount + ", queue:" + workQueue . size ( ) + ", " + matches . size ( ) + " matches, " + ( System . currentTimeMillis ( ) - timeStart ) + "ms" + ", " + messageSent ) ; } private boolean getLanguageAutoDetect ( Map < String , String > parameters ) { if ( afterTheDeadlineMode ) { return "true" . equals ( parameters . get ( "guess" ) ) ; } else { boolean autoDetect = "1" . equals ( parameters . get ( "autodetect" ) ) ; if ( parameters . get ( "language" ) == null && ! autoDetect ) { throw new IllegalArgumentException ( "Missing 'language' parameter. Specify language or use autodetect=1 for auto-detecting the language of the input text." ) ; } return autoDetect ; } } private Language getLanguage ( String text , String langParam , boolean autoDetect ) { final Language lang ; if ( autoDetect ) { lang = detectLanguageOfString ( text , langParam ) ; print ( "Auto-detected language: " + lang . getShortNameWithCountryAndVariant ( ) ) ; } else { if ( afterTheDeadlineMode ) { lang = afterTheDeadlineLanguage ; } else { lang = Languages . getLanguageForShortName ( langParam ) ; } } return lang ; } private List < RuleMatch > getRuleMatches ( String text , Map < String , String > parameters , Language lang , Language motherTongue , QueryParams params ) throws Exception { final String sourceText = parameters . get ( "srctext" ) ; if ( sourceText == null ) { final JLanguageTool lt = getLanguageToolInstance ( lang , motherTongue , params ) ; return lt . check ( text ) ; } else { if ( parameters . get ( "motherTongue" ) == null ) { throw new IllegalArgumentException ( "Missing 'motherTongue' parameter for bilingual checks" ) ; } print ( "Checking bilingual text, with source length " + sourceText . length ( ) + " and target length " + text . length ( ) + " (characters), source language " + motherTongue + " and target language " + lang . getShortNameWithCountryAndVariant ( ) ) ; final JLanguageTool sourceLt = getLanguageToolInstance ( motherTongue , null , params ) ; final JLanguageTool targetLt = getLanguageToolInstance ( lang , null , params ) ; final List < BitextRule > bRules = Tools . selectBitextRules ( Tools . getBitextRules ( motherTongue , lang ) , params . disabledRules , params . enabledRules , params . useEnabledOnly ) ; return Tools . checkBitext ( sourceText , text , sourceLt , targetLt , bRules ) ; } } private String getXmlResponse ( String text , Language lang , Language motherTongue , List < RuleMatch > matches ) { if ( afterTheDeadlineMode ) { AtDXmlSerializer serializer = new AtDXmlSerializer ( ) ; return serializer . ruleMatchesToXml ( matches , text ) ; } else { RuleAsXmlSerializer serializer = new RuleAsXmlSerializer ( ) ; return serializer . ruleMatchesToXml ( matches , text , CONTEXT_SIZE , lang , motherTongue ) ; } } private Map < String , String > parseQuery ( String query ) throws UnsupportedEncodingException { final Map < String , String > parameters = new HashMap < > ( ) ; if ( query != null ) { final String [ ] pairs = query . split ( "[&]" ) ; final Map < String , String > parameterMap = getParameterMap ( pairs ) ; parameters . putAll ( parameterMap ) ; } return parameters ; } private Map < String , String > getParameterMap ( String [ ] pairs ) throws UnsupportedEncodingException { final Map < String , String > parameters = new HashMap < > ( ) ; for ( String pair : pairs ) { final int delimPos = pair . indexOf ( '=' ) ; if ( delimPos != - 1 ) { final String param = pair . substring ( 0 , delimPos ) ; final String key = URLDecoder . decode ( param , ENCODING ) ; final String value = URLDecoder . decode ( pair . substring ( delimPos + 1 ) , ENCODING ) ; parameters . put ( key , value ) ; } } return parameters ; } private static void print ( String s ) { print ( s , System . out ) ; } private static void print ( String s , PrintStream outputStream ) { final SimpleDateFormat dateFormat = new SimpleDateFormat ( "yyyy-MM-dd HH:mm:ss" ) ; final String now = dateFormat . format ( new Date ( ) ) ; outputStream . println ( now + " " + s ) ; } private JLanguageTool getLanguageToolInstance ( Language lang , Language motherTongue , QueryParams params ) throws Exception { final JLanguageTool newLanguageTool = new JLanguageTool ( lang , motherTongue ) ; if ( languageModelDir != null ) { newLanguageTool . activateLanguageModelRules ( languageModelDir ) ; } final Configuration config = new Configuration ( lang ) ; if ( ! params . useQuerySettings && internalServer && config . getUseGUIConfig ( ) ) { configureFromGUI ( newLanguageTool , config ) ; } if ( params . useQuerySettings ) { Tools . selectRules ( newLanguageTool , params . disabledRules , params . enabledRules , params . useEnabledOnly ) ; } return newLanguageTool ; } private void configureFromGUI ( JLanguageTool langTool , Configuration config ) { print ( "Using options configured in the GUI" ) ; final Set < String > disabledRules = config . getDisabledRuleIds ( ) ; if ( disabledRules != null ) { for ( final String ruleId : disabledRules ) { langTool . disableRule ( ruleId ) ; } } final Set < String > disabledCategories = config . getDisabledCategoryNames ( ) ; if ( disabledCategories != null ) { for ( final String categoryName : disabledCategories ) { langTool . disableCategory ( categoryName ) ; } } final Set < String > enabledRules = config . getEnabledRuleIds ( ) ; if ( enabledRules != null ) { for ( String ruleName : enabledRules ) { langTool . enableDefaultOffRule ( ruleName ) ; langTool . enableRule ( ruleName ) ; } } } public static String getSupportedLanguagesAsXML ( ) { final List < Language > languages = new ArrayList < > ( Languages . get ( ) ) ; Collections . sort ( languages , new Comparator < Language > ( ) { @ Override public int compare ( Language o1 , Language o2 ) { return o1 . getName ( ) . compareTo ( o2 . getName ( ) ) ; } } ) ; final StringBuilder xmlBuffer = new StringBuilder ( "<?xml version='1.0' encoding='" + ENCODING + "'?>\n<languages>\n" ) ; for ( Language lang : languages ) { xmlBuffer . append ( String . format ( "\t<language name=\"%s\" abbr=\"%s\" abbrWithVariant=\"%s\"/> \n" , lang . getName ( ) , lang . getShortName ( ) , lang . getShortNameWithCountryAndVariant ( ) ) ) ; } xmlBuffer . append ( "</languages>\n" ) ; return xmlBuffer . toString ( ) ; } private class QueryParams { final List < String > enabledRules ; final List < String > disabledRules ; final boolean useEnabledOnly ; final boolean useQuerySettings ; QueryParams ( List < String > enabledRules , List < String > disabledRules , boolean useEnabledOnly , boolean useQuerySettings ) { this . enabledRules = enabledRules ; this . disabledRules = disabledRules ; this . useEnabledOnly = useEnabledOnly ; this . useQuerySettings = useQuerySettings ; } } }
package org . languagetool . server ; import java . util . Date ; import java . util . List ; import java . util . concurrent . CopyOnWriteArrayList ; class RequestLimiter { private static final int API_REQUEST_QUEUE_SIZE = 1000 ; private final List < RequestEvent > requestEvents = new CopyOnWriteArrayList < > ( ) ; private final int requestLimit ; private final int requestLimitPeriodInSeconds ; RequestLimiter ( int requestLimit , int requestLimitPeriodInSeconds ) { this . requestLimit = requestLimit ; this . requestLimitPeriodInSeconds = requestLimitPeriodInSeconds ; } int getRequestLimit ( ) { return requestLimit ; } int getRequestLimitPeriodInSeconds ( ) { return requestLimitPeriodInSeconds ; } boolean isAccessOkay ( String ipAddress ) { while ( requestEvents . size ( ) > API_REQUEST_QUEUE_SIZE ) { requestEvents . remove ( 0 ) ; } requestEvents . add ( new RequestEvent ( ipAddress , new Date ( ) ) ) ; return ! limitReached ( ipAddress ) ; } private boolean limitReached ( String ipAddress ) { int requestsByIp = 0 ; Date thresholdDate = new Date ( System . currentTimeMillis ( ) - requestLimitPeriodInSeconds * 1000 ) ; for ( RequestEvent requestEvent : requestEvents ) { if ( requestEvent . ip . equals ( ipAddress ) && requestEvent . date . after ( thresholdDate ) ) { requestsByIp ++ ; if ( requestsByIp > requestLimit ) { return true ; } } } return false ; } class RequestEvent { private final String ip ; private final Date date ; RequestEvent ( String ip , Date date ) { this . ip = ip ; this . date = date ; } } }
package org . languagetool . server ; public class PortBindingException extends RuntimeException { private static final long serialVersionUID = - 8416700513887041339L ; PortBindingException ( String message ) { super ( message ) ; } PortBindingException ( String message , Throwable cause ) { super ( message , cause ) ; } }
package org . languagetool . server ; import com . sun . net . httpserver . HttpServer ; import org . languagetool . JLanguageTool ; import org . languagetool . gui . Tools ; import java . net . InetSocketAddress ; import java . util . ResourceBundle ; import java . util . Set ; import java . util . concurrent . * ; import static org . languagetool . server . HTTPServerConfig . DEFAULT_HOST ; public class HTTPServer extends Server { private final ExecutorService executorService ; public HTTPServer ( ) { this ( new HTTPServerConfig ( ) ) ; } public HTTPServer ( HTTPServerConfig config ) { this ( config , false , DEFAULT_ALLOWED_IPS ) ; } public HTTPServer ( HTTPServerConfig config , boolean runInternally ) { this ( config , runInternally , DEFAULT_HOST , DEFAULT_ALLOWED_IPS ) ; } public HTTPServer ( HTTPServerConfig config , boolean runInternally , Set < String > allowedIps ) { this ( config , runInternally , DEFAULT_HOST , allowedIps ) ; } public HTTPServer ( HTTPServerConfig config , boolean runInternally , String host , Set < String > allowedIps ) { this . port = config . getPort ( ) ; this . host = host ; try { InetSocketAddress address = host != null ? new InetSocketAddress ( host , port ) : new InetSocketAddress ( port ) ; server = HttpServer . create ( address , 0 ) ; final RequestLimiter limiter = getRequestLimiterOrNull ( config ) ; final LinkedBlockingQueue < Runnable > workQueue = new LinkedBlockingQueue < > ( ) ; httpHandler = new LanguageToolHttpHandler ( config . isVerbose ( ) , allowedIps , runInternally , limiter , workQueue ) ; httpHandler . setMaxTextLength ( config . getMaxTextLength ( ) ) ; httpHandler . setAllowOriginUrl ( config . getAllowOriginUrl ( ) ) ; httpHandler . setMaxCheckTimeMillis ( config . getMaxCheckTimeMillis ( ) ) ; httpHandler . setTrustXForwardForHeader ( config . getTrustXForwardForHeader ( ) ) ; if ( config . getMode ( ) == HTTPServerConfig . Mode . AfterTheDeadline ) { httpHandler . setAfterTheDeadlineMode ( config . getAfterTheDeadlineLanguage ( ) ) ; } httpHandler . setLanguageModel ( config . getLanguageModelDir ( ) ) ; httpHandler . setMaxWorkQueueSize ( config . getMaxWorkQueueSize ( ) ) ; server . createContext ( "/" , httpHandler ) ; executorService = getExecutorService ( workQueue , config ) ; server . setExecutor ( executorService ) ; } catch ( Exception e ) { final ResourceBundle messages = JLanguageTool . getMessageBundle ( ) ; final String message = Tools . makeTexti18n ( messages , "http_server_start_failed" , host , Integer . toString ( port ) ) ; throw new PortBindingException ( message , e ) ; } } @ Override public void stop ( ) { super . stop ( ) ; if ( executorService != null ) { executorService . shutdownNow ( ) ; } } public static void main ( String [ ] args ) { if ( args . length > 5 || usageRequested ( args ) ) { System . out . println ( "Usage: " + HTTPServer . class . getSimpleName ( ) + " [--config propertyFile] [--port|-p port] [--public]" ) ; System . out . println ( " --config file a Java property file (one key=value entry per line) with values for:" ) ; printCommonConfigFileOptions ( ) ; printCommonOptions ( ) ; System . exit ( 1 ) ; } final boolean runInternal = false ; final HTTPServerConfig config = new HTTPServerConfig ( args ) ; try { final HTTPServer server ; System . out . println ( "WARNING: running in HTTP mode, consider using SSL by running " + HTTPSServer . class . getName ( ) + " instead" ) ; if ( config . isPublicAccess ( ) ) { System . out . println ( "WARNING: running in public mode, LanguageTool API can be accessed without restrictions!" ) ; server = new HTTPServer ( config , runInternal , null , null ) ; } else { server = new HTTPServer ( config , runInternal , DEFAULT_HOST , DEFAULT_ALLOWED_IPS ) ; } server . run ( ) ; } catch ( Exception e ) { throw new RuntimeException ( "Could not start LanguageTool HTTP server on " + DEFAULT_HOST + ", port " + config . getPort ( ) , e ) ; } } @ Override protected String getProtocol ( ) { return "http" ; } }
package org . languagetool . server ; import org . languagetool . Experimental ; import org . languagetool . JLanguageTool ; import org . languagetool . rules . RuleMatch ; import java . util . List ; import static org . languagetool . tools . StringTools . escapeForXmlContent ; @ Experimental public class AtDXmlSerializer { public String ruleMatchesToXml ( List < RuleMatch > matches , String text ) { StringBuilder sb = new StringBuilder ( ) ; sb . append ( "<results>\n" ) ; sb . append ( "<!-- Server: LanguageTool " + JLanguageTool . VERSION + " (" ) . append ( JLanguageTool . BUILD_DATE ) . append ( ") -->\n" ) ; for ( RuleMatch match : matches ) { addRuleMatch ( sb , match , text ) ; } sb . append ( "</results>\n" ) ; return sb . toString ( ) ; } private void addRuleMatch ( StringBuilder sb , RuleMatch match , String text ) { String errorText = text . substring ( match . getFromPos ( ) , match . getToPos ( ) ) ; if ( errorText . contains ( "(" ) || errorText . contains ( ")" ) ) { return ; } sb . append ( " <error>\n" ) ; sb . append ( " <string>" ) . append ( escapeForXmlContent ( errorText ) ) . append ( "</string>\n" ) ; boolean hasShortMessage = match . getShortMessage ( ) != null && match . getShortMessage ( ) . length ( ) > 0 ; String cleanMessage = hasShortMessage ? match . getShortMessage ( ) : match . getMessage ( ) . replace ( "<suggestion>" , "'" ) . replace ( "</suggestion>" , "'" ) ; sb . append ( " <description>" ) . append ( escapeForXmlContent ( cleanMessage ) ) . append ( "</description>\n" ) ; String preContext = getPreContext ( text , match . getFromPos ( ) ) ; if ( preContext . isEmpty ( ) ) { sb . append ( " <precontext/>\n" ) ; } else { sb . append ( " <precontext>" ) . append ( escapeForXmlContent ( preContext ) ) . append ( "</precontext>\n" ) ; } if ( match . getSuggestedReplacements ( ) . size ( ) > 0 ) { sb . append ( " <suggestions>\n" ) ; for ( String suggestion : match . getSuggestedReplacements ( ) ) { sb . append ( " <option>" ) . append ( escapeForXmlContent ( suggestion ) ) . append ( "</option>\n" ) ; } sb . append ( " </suggestions>\n" ) ; } String type = match . getRule ( ) . isDictionaryBasedSpellingRule ( ) ? "spelling" : "grammar" ; sb . append ( " <type>" ) . append ( escapeForXmlContent ( type ) ) . append ( "</type>\n" ) ; sb . append ( " </error>\n" ) ; } String getPreContext ( String text , int fromPos ) { String preText = text . substring ( 0 , fromPos ) ; String [ ] parts = preText . trim ( ) . split ( "\\s" ) ; if ( parts . length == 0 ) { return "" ; } else { String lastPart = parts [ parts . length - 1 ] ; if ( lastPart . matches ( ".*[()\\[\\],;:/-].*" ) ) { return "" ; } else { return lastPart ; } } } }
package org . languagetool . server ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . util . Properties ; public class HTTPSServerConfig extends HTTPServerConfig { private final File keystore ; private final String keyStorePassword ; public HTTPSServerConfig ( File keystore , String keyStorePassword ) { super ( DEFAULT_PORT , false ) ; this . keystore = keystore ; this . keyStorePassword = keyStorePassword ; } public HTTPSServerConfig ( int serverPort , boolean verbose , File keystore , String keyStorePassword ) { super ( serverPort , verbose ) ; this . keystore = keystore ; this . keyStorePassword = keyStorePassword ; } HTTPSServerConfig ( int serverPort , boolean verbose , File keystore , String keyStorePassword , int requestLimit , int requestLimitPeriodInSeconds ) { super ( serverPort , verbose ) ; this . keystore = keystore ; this . keyStorePassword = keyStorePassword ; this . requestLimit = requestLimit ; this . requestLimitPeriodInSeconds = requestLimitPeriodInSeconds ; } HTTPSServerConfig ( String [ ] args ) { super ( args ) ; File config = null ; for ( int i = 0 ; i < args . length ; i ++ ) { if ( "--config" . equals ( args [ i ] ) ) { config = new File ( args [ ++ i ] ) ; } } if ( config == null ) { throw new IllegalConfigurationException ( "Parameter --config must be set and point to a property file" ) ; } try { final Properties props = new Properties ( ) ; try ( FileInputStream fis = new FileInputStream ( config ) ) { props . load ( fis ) ; keystore = new File ( getProperty ( props , "keystore" , config ) ) ; keyStorePassword = getProperty ( props , "password" , config ) ; } } catch ( IOException e ) { throw new RuntimeException ( "Could not load properties from '" + config + "'" , e ) ; } } File getKeystore ( ) { return keystore ; } String getKeyStorePassword ( ) { return keyStorePassword ; } }
package org . languagetool . server ; class IllegalConfigurationException extends RuntimeException { IllegalConfigurationException ( String message ) { super ( message ) ; } }
package org . languagetool . rules . ro ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . Romanian ; import org . languagetool . rules . GenericUnpairedBracketsRule ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . Collections ; public class GenericUnpairedBracketsRuleTest extends TestCase { private GenericUnpairedBracketsRule rule ; private JLanguageTool langTool ; public void testRomanianRule ( ) throws IOException { langTool = new JLanguageTool ( new Romanian ( ) ) ; rule = org . languagetool . rules . GenericUnpairedBracketsRuleTest . getBracketsRule ( langTool ) ; assertMatches ( "A fost plecat (pentru puțin timp)." , 0 ) ; assertMatches ( "Nu's de prin locurile astea." , 0 ) ; assertMatches ( "A fost plecat pentru „puțin timp”." , 0 ) ; assertMatches ( "A fost plecat „pentru... puțin timp”." , 0 ) ; assertMatches ( "A fost plecat „pentru... «puțin» timp”." , 0 ) ; assertMatches ( "A fost plecat \"pentru puțin timp." , 0 ) ; assertMatches ( "A fost )plecat( pentru (puțin timp)." , 2 ) ; assertMatches ( "A fost {plecat) pentru (puțin timp}." , 4 ) ; assertMatches ( "A fost plecat „pentru... puțin timp." , 1 ) ; assertMatches ( "A fost plecat «puțin." , 1 ) ; assertMatches ( "A fost plecat „pentru «puțin timp”." , 3 ) ; assertMatches ( "A fost plecat „pentru puțin» timp”." , 3 ) ; assertMatches ( "A fost plecat „pentru... puțin» timp”." , 3 ) ; assertMatches ( "A fost plecat „pentru... «puțin” timp»." , 4 ) ; } private void assertMatches ( String input , int expectedMatches ) throws IOException { final RuleMatch [ ] matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( input ) ) ) ; assertEquals ( expectedMatches , matches . length ) ; } }
package org . languagetool . server ; class TextTooLongException extends RuntimeException { TextTooLongException ( String message ) { super ( message ) ; } }
package org . languagetool . server ; import com . sun . net . httpserver . HttpServer ; import org . jetbrains . annotations . Nullable ; import org . languagetool . JLanguageTool ; import java . util . Arrays ; import java . util . HashSet ; import java . util . Set ; import java . util . concurrent . LinkedBlockingQueue ; import java . util . concurrent . ThreadPoolExecutor ; import java . util . concurrent . TimeUnit ; import static org . languagetool . server . HTTPServerConfig . DEFAULT_PORT ; abstract class Server { protected abstract String getProtocol ( ) ; protected static final Set < String > DEFAULT_ALLOWED_IPS = new HashSet < > ( Arrays . asList ( "0:0:0:0:0:0:0:1" , "0:0:0:0:0:0:0:1%0" , "127.0.0.1" ) ) ; protected int port ; protected String host ; protected HttpServer server ; protected LanguageToolHttpHandler httpHandler ; private boolean isRunning ; public void run ( ) { final String hostName = host != null ? host : "localhost" ; System . out . println ( "Starting LanguageTool " + JLanguageTool . VERSION + " (build date: " + JLanguageTool . BUILD_DATE + ") server on " + getProtocol ( ) + "://" + hostName + ":" + port + "..." ) ; server . start ( ) ; isRunning = true ; System . out . println ( "Server started" ) ; } public void stop ( ) { if ( httpHandler != null ) { httpHandler . shutdown ( ) ; } if ( server != null ) { System . out . println ( "Stopping server" ) ; server . stop ( 0 ) ; isRunning = false ; System . out . println ( "Server stopped" ) ; } } public boolean isRunning ( ) { return isRunning ; } @ Nullable protected RequestLimiter getRequestLimiterOrNull ( HTTPServerConfig config ) { final int requestLimit = config . getRequestLimit ( ) ; final int requestLimitPeriodInSeconds = config . getRequestLimitPeriodInSeconds ( ) ; if ( requestLimit > 0 || requestLimitPeriodInSeconds > 0 ) { return new RequestLimiter ( requestLimit , requestLimitPeriodInSeconds ) ; } return null ; } protected static boolean usageRequested ( String [ ] args ) { return args . length == 1 && ( args [ 0 ] . equals ( "-h" ) || args [ 0 ] . equals ( "--help" ) ) ; } protected static void printCommonConfigFileOptions ( ) { System . out . println ( " 'mode' - 'LanguageTool' or 'AfterTheDeadline' for emulation of After the Deadline output (optional, experimental)" ) ; System . out . println ( " 'afterTheDeadlineLanguage' - language code like 'en' or 'en-GB' (required if mode is 'AfterTheDeadline')" ) ; System . out . println ( " 'maxTextLength' - maximum text length, longer texts will cause an error (optional)" ) ; System . out . println ( " 'maxCheckTimeMillis' - maximum time in milliseconds allowed per check (optional)" ) ; System . out . println ( " 'maxCheckThreads' - maximum number of threads working in parallel (optional)" ) ; System . out . println ( " 'requestLimit' - maximum number of requests (optional)" ) ; System . out . println ( " 'requestLimitPeriodInSeconds' - time period to which requestLimit applies (optional)" ) ; System . out . println ( " 'languageModel' - a directory with '1grams', '2grams', '3grams' sub directories which contain a Lucene index" ) ; System . out . println ( " each with ngram occurrence counts; activates the confusion rule if supported (optional)" ) ; System . out . println ( " 'maxWorkQueueSize' - reject request if request queue gets larger than this (optional)" ) ; } protected static void printCommonOptions ( ) { System . out . println ( " --port, -p port to bind to, defaults to " + DEFAULT_PORT + " if not specified" ) ; System . out . println ( " --public allow this server process to be connected from anywhere; if not set," ) ; System . out . println ( " it can only be connected from the computer it was started on" ) ; System . out . println ( " --allow-origin ORIGIN set the Access-Control-Allow-Origin header in the HTTP response," ) ; System . out . println ( " used for direct (non-proxy) JavaScript-based access from browsers;" ) ; System . out . println ( " example: --allow-origin \"*\"" ) ; System . out . println ( " --verbose, -v in case of exceptions, log the input text (up to 500 characters)" ) ; } protected ThreadPoolExecutor getExecutorService ( LinkedBlockingQueue < Runnable > workQueue , HTTPServerConfig config ) { int threadPoolSize = config . getMaxCheckThreads ( ) ; System . out . println ( "Setting up thread pool with " + threadPoolSize + " threads" ) ; return new ThreadPoolExecutor ( threadPoolSize , threadPoolSize , 0L , TimeUnit . MILLISECONDS , workQueue ) ; } }
package org . languagetool . server ; import org . jetbrains . annotations . Nullable ; import org . languagetool . Language ; import org . languagetool . Languages ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . util . Properties ; public class HTTPServerConfig { enum Mode { LanguageTool , AfterTheDeadline } public static final String DEFAULT_HOST = "localhost" ; public static final int DEFAULT_PORT = 8081 ; protected boolean verbose = false ; protected boolean publicAccess = false ; protected int port = DEFAULT_PORT ; protected String allowOriginUrl = null ; protected int maxTextLength = Integer . MAX_VALUE ; protected long maxCheckTimeMillis = - 1 ; protected int maxCheckThreads = 10 ; protected Mode mode ; protected Language atdLanguage ; protected File languageModelDir = null ; protected int requestLimit ; protected int requestLimitPeriodInSeconds ; protected boolean trustXForwardForHeader ; protected int maxWorkQueueSize ; public HTTPServerConfig ( ) { this ( DEFAULT_PORT , false ) ; } public HTTPServerConfig ( int serverPort ) { this ( serverPort , false ) ; } public HTTPServerConfig ( int serverPort , boolean verbose ) { this . port = serverPort ; this . verbose = verbose ; } HTTPServerConfig ( String [ ] args ) { for ( int i = 0 ; i < args . length ; i ++ ) { switch ( args [ i ] ) { case "--config" : parseConfigFile ( new File ( args [ ++ i ] ) ) ; break ; case "-p" : case "--port" : port = Integer . parseInt ( args [ ++ i ] ) ; break ; case "-v" : case "--verbose" : verbose = true ; break ; case "--public" : publicAccess = true ; break ; case "--allow-origin" : allowOriginUrl = args [ ++ i ] ; break ; } } } private void parseConfigFile ( File file ) { try { final Properties props = new Properties ( ) ; try ( FileInputStream fis = new FileInputStream ( file ) ) { props . load ( fis ) ; maxTextLength = Integer . parseInt ( getOptionalProperty ( props , "maxTextLength" , Integer . toString ( Integer . MAX_VALUE ) ) ) ; maxCheckTimeMillis = Long . parseLong ( getOptionalProperty ( props , "maxCheckTimeMillis" , "-1" ) ) ; requestLimit = Integer . parseInt ( getOptionalProperty ( props , "requestLimit" , "0" ) ) ; requestLimitPeriodInSeconds = Integer . parseInt ( getOptionalProperty ( props , "requestLimitPeriodInSeconds" , "0" ) ) ; trustXForwardForHeader = Boolean . valueOf ( getOptionalProperty ( props , "trustXForwardForHeader" , "false" ) ) ; maxWorkQueueSize = Integer . parseInt ( getOptionalProperty ( props , "maxWorkQueueSize" , "0" ) ) ; String langModel = getOptionalProperty ( props , "languageModel" , null ) ; if ( langModel != null ) { languageModelDir = new File ( langModel ) ; if ( ! languageModelDir . exists ( ) || ! languageModelDir . isDirectory ( ) ) { throw new RuntimeException ( "LanguageModel directory not found or is not a directory: " + languageModelDir ) ; } } maxCheckThreads = Integer . parseInt ( getOptionalProperty ( props , "maxCheckThreads" , "10" ) ) ; if ( maxCheckThreads < 1 ) { throw new IllegalArgumentException ( "Invalid value for maxCheckThreads: " + maxCheckThreads ) ; } mode = getOptionalProperty ( props , "mode" , "LanguageTool" ) . equalsIgnoreCase ( "AfterTheDeadline" ) ? Mode . AfterTheDeadline : Mode . LanguageTool ; if ( mode == Mode . AfterTheDeadline ) { atdLanguage = Languages . getLanguageForShortName ( getProperty ( props , "afterTheDeadlineLanguage" , file ) ) ; } } } catch ( IOException e ) { throw new RuntimeException ( "Could not load properties from '" + file + "'" , e ) ; } } public boolean isVerbose ( ) { return verbose ; } public boolean isPublicAccess ( ) { return publicAccess ; } public int getPort ( ) { return port ; } @ Nullable public String getAllowOriginUrl ( ) { return allowOriginUrl ; } public void setMaxTextLength ( int maxTextLength ) { this . maxTextLength = maxTextLength ; } int getMaxTextLength ( ) { return maxTextLength ; } int getRequestLimit ( ) { return requestLimit ; } int getRequestLimitPeriodInSeconds ( ) { return requestLimitPeriodInSeconds ; } void setMaxCheckTimeMillis ( int maxCheckTimeMillis ) { this . maxCheckTimeMillis = maxCheckTimeMillis ; } long getMaxCheckTimeMillis ( ) { return maxCheckTimeMillis ; } @ Nullable File getLanguageModelDir ( ) { return languageModelDir ; } Mode getMode ( ) { return mode ; } @ Nullable Language getAfterTheDeadlineLanguage ( ) { return atdLanguage ; } void setMaxCheckThreads ( int maxCheckThreads ) { this . maxCheckThreads = maxCheckThreads ; } int getMaxCheckThreads ( ) { return maxCheckThreads ; } void setTrustXForwardForHeader ( boolean trustXForwardForHeader ) { this . trustXForwardForHeader = trustXForwardForHeader ; } boolean getTrustXForwardForHeader ( ) { return trustXForwardForHeader ; } int getMaxWorkQueueSize ( ) { return maxWorkQueueSize ; } protected String getProperty ( Properties props , String propertyName , File config ) { final String propertyValue = ( String ) props . get ( propertyName ) ; if ( propertyValue == null || propertyValue . trim ( ) . isEmpty ( ) ) { throw new IllegalConfigurationException ( "Property '" + propertyName + "' must be set in " + config ) ; } return propertyValue ; } protected String getOptionalProperty ( Properties props , String propertyName , String defaultValue ) { final String propertyValue = ( String ) props . get ( propertyName ) ; if ( propertyValue == null ) { return defaultValue ; } return propertyValue ; } }
package org . languagetool ; import org . junit . Test ; import org . languagetool . language . AmericanEnglish ; import org . languagetool . language . Demo ; import org . languagetool . language . English ; import org . languagetool . language . German ; import org . languagetool . markup . AnnotatedText ; import org . languagetool . markup . AnnotatedTextBuilder ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import static junit . framework . Assert . assertEquals ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertThat ; public class JLanguageToolTest { private static final English english = new English ( ) ; @ Test public void testGetAllActiveRules ( ) throws Exception { JLanguageTool langTool = new JLanguageTool ( new Demo ( ) ) ; List < String > ruleIds = getActiveRuleIds ( langTool ) ; assertTrue ( ruleIds . contains ( "DEMO_RULE" ) ) ; assertFalse ( ruleIds . contains ( "DEMO_RULE_OFF" ) ) ; for ( Rule rule : langTool . getAllRules ( ) ) { if ( rule . getId ( ) . equals ( "DEMO_RULE_OFF" ) ) { rule . setDefaultOn ( ) ; } } List < String > ruleIds2 = getActiveRuleIds ( langTool ) ; assertTrue ( ruleIds2 . contains ( "DEMO_RULE_OFF" ) ) ; } private List < String > getActiveRuleIds ( JLanguageTool langTool ) { List < String > ruleIds = new ArrayList < > ( ) ; for ( Rule rule : langTool . getAllActiveRules ( ) ) { ruleIds . add ( rule . getId ( ) ) ; } return ruleIds ; } @ Test public void testGetMessageBundle ( ) throws Exception { final ResourceBundle bundle1 = JLanguageTool . getMessageBundle ( new German ( ) ) ; assertThat ( bundle1 . getString ( "de" ) , is ( "Deutsch" ) ) ; final ResourceBundle bundle2 = JLanguageTool . getMessageBundle ( english ) ; assertThat ( bundle2 . getString ( "de" ) , is ( "German" ) ) ; final ResourceBundle bundle3 = JLanguageTool . getMessageBundle ( new AmericanEnglish ( ) ) ; assertThat ( bundle3 . getString ( "de" ) , is ( "German" ) ) ; } @ Test public void testCountLines ( ) { assertEquals ( 0 , JLanguageTool . countLineBreaks ( "" ) ) ; assertEquals ( 1 , JLanguageTool . countLineBreaks ( "Hallo,\nnächste Zeile" ) ) ; assertEquals ( 2 , JLanguageTool . countLineBreaks ( "\nZweite\nDritte" ) ) ; assertEquals ( 4 , JLanguageTool . countLineBreaks ( "\nZweite\nDritte\n\n" ) ) ; } @ Test public void testSentenceTokenize ( ) throws IOException { JLanguageTool languageTool = new JLanguageTool ( english ) ; List < String > sentences = languageTool . sentenceTokenize ( "This is a sentence! This is another one." ) ; assertEquals ( 2 , sentences . size ( ) ) ; assertEquals ( "This is a sentence! " , sentences . get ( 0 ) ) ; assertEquals ( "This is another one." , sentences . get ( 1 ) ) ; } @ Test public void testAnnotateTextCheck ( ) throws IOException { JLanguageTool languageTool = new JLanguageTool ( english ) ; AnnotatedText annotatedText = new AnnotatedTextBuilder ( ) . addMarkup ( "<b>" ) . addText ( "here" ) . addMarkup ( "</b>" ) . addText ( " is an error" ) . build ( ) ; List < RuleMatch > matches = languageTool . check ( annotatedText ) ; assertThat ( matches . size ( ) , is ( 1 ) ) ; assertThat ( matches . get ( 0 ) . getFromPos ( ) , is ( 3 ) ) ; assertThat ( matches . get ( 0 ) . getToPos ( ) , is ( 7 ) ) ; } @ Test public void testAnnotateTextCheckMultipleSentences ( ) throws IOException { JLanguageTool languageTool = new JLanguageTool ( english ) ; AnnotatedText annotatedText = new AnnotatedTextBuilder ( ) . addMarkup ( "<b>" ) . addText ( "here" ) . addMarkup ( "</b>" ) . addText ( " is an error. And " ) . addMarkup ( "<i attr='foo'>" ) . addText ( "here is also" ) . addMarkup ( "</i>" ) . addText ( " a error." ) . build ( ) ; List < RuleMatch > matches = languageTool . check ( annotatedText ) ; assertThat ( matches . size ( ) , is ( 2 ) ) ; assertThat ( matches . get ( 0 ) . getFromPos ( ) , is ( 3 ) ) ; assertThat ( matches . get ( 0 ) . getToPos ( ) , is ( 7 ) ) ; assertThat ( matches . get ( 1 ) . getFromPos ( ) , is ( 60 ) ) ; assertThat ( matches . get ( 1 ) . getToPos ( ) , is ( 61 ) ) ; } @ Test public void testAnnotateTextCheckMultipleSentences2 ( ) throws IOException { JLanguageTool languageTool = new JLanguageTool ( english ) ; AnnotatedText annotatedText = new AnnotatedTextBuilder ( ) . addText ( "here" ) . addText ( " is an error. And " ) . addMarkup ( "<i attr='foo'/>" ) . addText ( "here is also " ) . addMarkup ( "<i>" ) . addText ( "a" ) . addMarkup ( "</i>" ) . addText ( " error." ) . build ( ) ; List < RuleMatch > matches = languageTool . check ( annotatedText ) ; assertThat ( matches . size ( ) , is ( 2 ) ) ; assertThat ( matches . get ( 0 ) . getFromPos ( ) , is ( 0 ) ) ; assertThat ( matches . get ( 0 ) . getToPos ( ) , is ( 4 ) ) ; assertThat ( matches . get ( 1 ) . getFromPos ( ) , is ( 53 ) ) ; assertThat ( matches . get ( 1 ) . getToPos ( ) , is ( 54 ) ) ; } @ Test public void testAnnotateTextCheckPlainText ( ) throws IOException { JLanguageTool languageTool = new JLanguageTool ( english ) ; AnnotatedText annotatedText = new AnnotatedTextBuilder ( ) . addText ( "A good sentence. But here's a error." ) . build ( ) ; List < RuleMatch > matches = languageTool . check ( annotatedText ) ; assertThat ( matches . size ( ) , is ( 1 ) ) ; assertThat ( matches . get ( 0 ) . getFromPos ( ) , is ( 28 ) ) ; assertThat ( matches . get ( 0 ) . getToPos ( ) , is ( 29 ) ) ; } @ Test public void testStrangeInput ( ) throws IOException { JLanguageTool languageTool = new JLanguageTool ( english ) ; List < RuleMatch > matches = languageTool . check ( "­" ) ; assertThat ( matches . size ( ) , is ( 0 ) ) ; } }
package org . languagetool ; import junit . framework . TestCase ; import org . languagetool . tools . StringTools ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . util . * ; public class TranslationTest extends TestCase { public void testTranslationKeyExistence ( ) throws IOException { final File englishFile = getEnglishTranslationFile ( ) ; final Properties enProps = new Properties ( ) ; enProps . load ( new FileInputStream ( englishFile ) ) ; final Set < Object > englishKeys = enProps . keySet ( ) ; for ( Language lang : Languages . get ( ) ) { if ( lang . getShortName ( ) . equals ( "en" ) ) { continue ; } final Properties langProps = new Properties ( ) ; final File langFile = getTranslationFile ( lang ) ; if ( ! langFile . exists ( ) ) { continue ; } try ( FileInputStream stream = new FileInputStream ( langFile ) ) { langProps . load ( stream ) ; final Set < Object > langKeys = langProps . keySet ( ) ; for ( Object englishKey : englishKeys ) { if ( ! langKeys . contains ( englishKey ) ) { System . err . println ( "***** No key '" + englishKey + "' in file " + langFile ) ; } } } } } public void testTranslationsAreNotEmpty ( ) throws IOException { for ( Language lang : Languages . get ( ) ) { final File file1 = getTranslationFile ( lang ) ; final File file2 = getTranslationFileWithVariant ( lang ) ; if ( ! file1 . exists ( ) && ! file2 . exists ( ) ) { System . err . println ( "Note: no translation available for " + lang ) ; continue ; } final File file = file1 . exists ( ) ? file1 : file2 ; final List < String > lines = loadFile ( file ) ; for ( String line : lines ) { line = line . trim ( ) ; if ( StringTools . isEmpty ( line ) || line . charAt ( 0 ) == '#' ) { continue ; } final String [ ] parts = line . split ( "=" ) ; if ( parts . length < 2 ) { System . err . println ( "***** Empty translation: '" + line + "' in file " + file ) ; } } } } private List < String > loadFile ( File file ) throws IOException { final List < String > l = new ArrayList < > ( ) ; try ( Scanner scanner = new Scanner ( file ) ) { while ( scanner . hasNextLine ( ) ) { l . add ( scanner . nextLine ( ) ) ; } } return l ; } private File getEnglishTranslationFile ( ) { final String name = "../languagetool-core/src/main/resources/org/languagetool/MessagesBundle_en.properties" ; return new File ( name . replace ( "/" , File . separator ) ) ; } private File getTranslationFile ( Language lang ) { final String langCode = lang . getShortName ( ) ; final String name = "../languagetool-language-modules/" + langCode + "/src/main/resources/org/languagetool" + "/MessagesBundle_" + langCode + ".properties" ; return new File ( name . replace ( "/" , File . separator ) ) ; } private File getTranslationFileWithVariant ( Language lang ) { final String langCode = lang . getShortName ( ) ; final String name = "../languagetool-language-modules/" + langCode + "/src/main/resources/org/languagetool" + "/MessagesBundle_" + lang . getShortNameWithCountryAndVariant ( ) . replace ( '-' , '_' ) + ".properties" ; return new File ( name . replace ( "/" , File . separator ) ) ; } }
package org . languagetool ; import org . junit . Test ; import org . languagetool . language . * ; import static org . junit . Assert . * ; public class LanguageTest { @ Test public void testRuleFileName ( ) { assertEquals ( "[/org/languagetool/rules/en/grammar.xml, /org/languagetool/rules/en/en-GB/grammar.xml]" , new BritishEnglish ( ) . getRuleFileNames ( ) . toString ( ) ) ; assertEquals ( "[/org/languagetool/rules/en/grammar.xml, /org/languagetool/rules/en/en-US/grammar.xml]" , new AmericanEnglish ( ) . getRuleFileNames ( ) . toString ( ) ) ; assertEquals ( "[/org/languagetool/rules/en/grammar.xml]" , new English ( ) . getRuleFileNames ( ) . toString ( ) ) ; assertEquals ( "[/org/languagetool/rules/de/grammar.xml]" , new German ( ) . getRuleFileNames ( ) . toString ( ) ) ; } @ Test public void testGetTranslatedName ( ) { assertEquals ( "English" , new English ( ) . getTranslatedName ( TestTools . getMessages ( "en" ) ) ) ; assertEquals ( "English (British)" , new BritishEnglish ( ) . getTranslatedName ( TestTools . getMessages ( "en" ) ) ) ; assertEquals ( "Englisch" , new English ( ) . getTranslatedName ( TestTools . getMessages ( "de" ) ) ) ; assertEquals ( "Englisch (Großbritannien)" , new BritishEnglish ( ) . getTranslatedName ( TestTools . getMessages ( "de" ) ) ) ; assertEquals ( "Deutsch" , new German ( ) . getTranslatedName ( TestTools . getMessages ( "de" ) ) ) ; assertEquals ( "Deutsch (Schweiz)" , new SwissGerman ( ) . getTranslatedName ( TestTools . getMessages ( "de" ) ) ) ; } @ Test public void testGetShortNameWithVariant ( ) { assertEquals ( "en-US" , new AmericanEnglish ( ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "de" , new German ( ) . getShortNameWithCountryAndVariant ( ) ) ; } @ Test public void testEqualsConsiderVariantIfSpecified ( ) { assertTrue ( new German ( ) . equalsConsiderVariantsIfSpecified ( new German ( ) ) ) ; assertTrue ( new GermanyGerman ( ) . equalsConsiderVariantsIfSpecified ( new GermanyGerman ( ) ) ) ; assertTrue ( new English ( ) . equalsConsiderVariantsIfSpecified ( new English ( ) ) ) ; assertTrue ( new AmericanEnglish ( ) . equalsConsiderVariantsIfSpecified ( new AmericanEnglish ( ) ) ) ; assertTrue ( new AmericanEnglish ( ) . equalsConsiderVariantsIfSpecified ( new English ( ) ) ) ; assertTrue ( new English ( ) . equalsConsiderVariantsIfSpecified ( new AmericanEnglish ( ) ) ) ; assertFalse ( new AmericanEnglish ( ) . equalsConsiderVariantsIfSpecified ( new BritishEnglish ( ) ) ) ; assertFalse ( new English ( ) . equalsConsiderVariantsIfSpecified ( new German ( ) ) ) ; } }
package org . languagetool ; import org . junit . Assert ; import org . junit . Test ; import java . util . List ; import java . util . Locale ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . * ; public class LanguagesTest { @ Test public void testGet ( ) { List < Language > languages = Languages . get ( ) ; List < Language > languagesWithDemo = Languages . getWithDemoLanguage ( ) ; assertThat ( languages . size ( ) + 1 , is ( languagesWithDemo . size ( ) ) ) ; } @ Test ( expected = UnsupportedOperationException . class ) public void testGetIsUnmodifiable ( ) { List < Language > languages = Languages . get ( ) ; languages . add ( languages . get ( 0 ) ) ; } @ Test ( expected = UnsupportedOperationException . class ) public void testGetWithDemoLanguageIsUnmodifiable ( ) { List < Language > languages = Languages . getWithDemoLanguage ( ) ; languages . add ( languages . get ( 0 ) ) ; } @ Test public void testGetLanguageForShortName ( ) { assertEquals ( "en-US" , Languages . getLanguageForShortName ( "en-us" ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "en-US" , Languages . getLanguageForShortName ( "EN-US" ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "en-US" , Languages . getLanguageForShortName ( "en-US" ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "de" , Languages . getLanguageForShortName ( "de" ) . getShortNameWithCountryAndVariant ( ) ) ; try { Languages . getLanguageForShortName ( "xy" ) ; fail ( ) ; } catch ( IllegalArgumentException ignored ) { } try { Languages . getLanguageForShortName ( "YY-KK" ) ; fail ( ) ; } catch ( IllegalArgumentException ignored ) { } } @ Test public void testIsLanguageSupported ( ) { Assert . assertTrue ( Languages . isLanguageSupported ( "xx" ) ) ; Assert . assertTrue ( Languages . isLanguageSupported ( "XX" ) ) ; Assert . assertTrue ( Languages . isLanguageSupported ( "en-US" ) ) ; Assert . assertTrue ( Languages . isLanguageSupported ( "en-us" ) ) ; Assert . assertTrue ( Languages . isLanguageSupported ( "EN-US" ) ) ; Assert . assertTrue ( Languages . isLanguageSupported ( "de" ) ) ; Assert . assertTrue ( Languages . isLanguageSupported ( "de-DE" ) ) ; Assert . assertTrue ( Languages . isLanguageSupported ( "de-DE-x-simple-language" ) ) ; Assert . assertTrue ( Languages . isLanguageSupported ( "de-DE-x-simple-LANGUAGE" ) ) ; assertFalse ( Languages . isLanguageSupported ( "yy-ZZ" ) ) ; assertFalse ( Languages . isLanguageSupported ( "zz" ) ) ; assertFalse ( Languages . isLanguageSupported ( "somthing totally invalid" ) ) ; } @ Test ( expected = IllegalArgumentException . class ) public void testIsLanguageSupportedInvalidCode ( ) { Languages . isLanguageSupported ( "somthing-totally-inv-alid" ) ; } @ Test ( expected = IllegalArgumentException . class ) public void testInvalidShortName1 ( ) { Languages . getLanguageForShortName ( "de-" ) ; } @ Test ( expected = IllegalArgumentException . class ) public void testInvalidShortName2 ( ) { Languages . getLanguageForShortName ( "dexx" ) ; } @ Test ( expected = IllegalArgumentException . class ) public void testInvalidShortName3 ( ) { Languages . getLanguageForShortName ( "xyz-xx" ) ; } @ Test public void testGetLanguageForName ( ) { assertEquals ( "en-US" , Languages . getLanguageForName ( "English (US)" ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "de" , Languages . getLanguageForName ( "German" ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( null , Languages . getLanguageForName ( "Foobar" ) ) ; } @ Test public void testIsVariant ( ) { Assert . assertTrue ( Languages . getLanguageForShortName ( "en-US" ) . isVariant ( ) ) ; Assert . assertTrue ( Languages . getLanguageForShortName ( "de-CH" ) . isVariant ( ) ) ; assertFalse ( Languages . getLanguageForShortName ( "en" ) . isVariant ( ) ) ; assertFalse ( Languages . getLanguageForShortName ( "de" ) . isVariant ( ) ) ; } @ Test public void testHasVariant ( ) { Assert . assertTrue ( Languages . getLanguageForShortName ( "en" ) . hasVariant ( ) ) ; Assert . assertTrue ( Languages . getLanguageForShortName ( "de" ) . hasVariant ( ) ) ; assertFalse ( Languages . getLanguageForShortName ( "en-US" ) . hasVariant ( ) ) ; assertFalse ( Languages . getLanguageForShortName ( "de-CH" ) . hasVariant ( ) ) ; assertFalse ( Languages . getLanguageForShortName ( "ast" ) . hasVariant ( ) ) ; assertFalse ( Languages . getLanguageForShortName ( "pl" ) . hasVariant ( ) ) ; for ( Language language : Languages . getWithDemoLanguage ( ) ) { if ( language . hasVariant ( ) ) { assertNotNull ( "Language " + language + " needs a default variant" , language . getDefaultLanguageVariant ( ) ) ; } } } @ Test public void testGetLanguageForLocale ( ) { assertEquals ( "de" , Languages . getLanguageForLocale ( Locale . GERMAN ) . getShortName ( ) ) ; assertEquals ( "de" , Languages . getLanguageForLocale ( Locale . GERMANY ) . getShortName ( ) ) ; assertEquals ( "de-DE" , Languages . getLanguageForLocale ( new Locale ( "de" , "DE" ) ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "de-AT" , Languages . getLanguageForLocale ( new Locale ( "de" , "AT" ) ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "en-US" , Languages . getLanguageForLocale ( new Locale ( "en" , "US" ) ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "en-GB" , Languages . getLanguageForLocale ( new Locale ( "en" , "GB" ) ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "en-US" , Languages . getLanguageForLocale ( new Locale ( "en" ) ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "de-DE" , Languages . getLanguageForLocale ( new Locale ( "de" ) ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "pl-PL" , Languages . getLanguageForLocale ( new Locale ( "pl" ) ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "en-US" , Languages . getLanguageForLocale ( Locale . KOREAN ) . getShortNameWithCountryAndVariant ( ) ) ; assertEquals ( "en-US" , Languages . getLanguageForLocale ( new Locale ( "zz" ) ) . getShortNameWithCountryAndVariant ( ) ) ; } }
package org . languagetool . dev ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . language . GermanyGerman ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . * ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . Future ; import static junit . framework . TestCase . fail ; public class MultiThreadingTest2 { private static final Language LANG = new GermanyGerman ( ) ; private static final int THREADS = 5 ; private static final int RUNS = 50 ; private static final List < String > sentences = Arrays . asList ( "oder nutzen Sie diesen Text als Beispiel für ein Paar Fehler , die LanguageTool erkennen kann." , "Ihm wurde Angst und bange, als er davon hörte. ( Eine Rechtschreibprüfun findet findet übrigens auch statt." , "Eine Rechtschreibprüfun findet findet übrigens auch statt." , "Eine Rechtschreibprüfung findet findet übrigens auch statt." , "Eine rechtschreibprüfung findet übrigends auch statt." , "Eine rechtschreibprüfung findet übrigens auch auch statt." , "Ein ökonomischer Gottesdienst." ) ; private final Random rnd = new Random ( 1234 ) ; private final Map < String , String > expectedResults = new HashMap < > ( ) ; @ Test @ Ignore ( "for interactive use only" ) public void test ( ) throws Exception { initExpectedResults ( ) ; ExecutorService executor = Executors . newFixedThreadPool ( THREADS ) ; for ( int i = 0 ; i < RUNS ; i ++ ) { System . out . println ( "Run #" + i ) ; Collections . shuffle ( sentences , rnd ) ; List < Future > futures = new ArrayList < > ( ) ; for ( String sentence : sentences ) { futures . add ( executor . submit ( new Handler ( LANG , sentence ) ) ) ; } for ( Future future : futures ) { future . get ( ) ; } } } private void initExpectedResults ( ) throws IOException { JLanguageTool lt = new JLanguageTool ( LANG ) ; for ( String sentence : sentences ) { List < RuleMatch > matches = lt . check ( sentence ) ; expectedResults . put ( sentence , matches . toString ( ) ) ; } } class Handler implements Runnable { private final Language lang ; private final String sentence ; Handler ( Language lang , String sentence ) { this . lang = lang ; this . sentence = sentence ; } @ Override public void run ( ) { try { JLanguageTool lt = new JLanguageTool ( lang ) ; List < RuleMatch > matches = lt . check ( sentence ) ; String expected = expectedResults . get ( sentence ) ; String real = matches . toString ( ) ; if ( ! expectedResults . get ( sentence ) . equals ( real ) ) { fail ( "Got '" + real + "', expected '" + expected + "' for input: " + sentence ) ; } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } } }
package org . languagetool . dev ; import org . apache . commons . lang . StringUtils ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . * ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . Future ; import static junit . framework . TestCase . fail ; public class MultiThreadingTest1 { private static final int THREADS = 10 ; private static final int RUNS = 50 ; private static final Map < String , String > examples = new HashMap < > ( ) ; static { examples . put ( "de-DE" , "oder nutzen Sie diesen Text als Beispiel für ein Paar Fehler , die LanguageTool erkennen kann: Ihm wurde Angst und bange, als er davon hörte. ( Eine Rechtschreibprüfun findet findet übrigens auch statt." ) ; examples . put ( "en-GB" , "Paste your own text here and click the 'Check Text' button. Click the colored phrases for details on potential errors. or use this text too see an few of of the problems that LanguageTool can detecd. What do you thinks of grammar checkers? Please not that they are not perfect." ) ; examples . put ( "en-US" , "Paste your own text here and click the 'Check Text' button. Click the colored phrases for details on potential errors. or use this text too see an few of of the problems that LanguageTool can detecd. What do you thinks of grammar checkers? Please not that they are not perfect." ) ; examples . put ( "ast-ES" , "Apega testu equí. o revisa toes les pallabres de esti testu pa ver dalgún de los problemis que LanguageTool ye pa deteutar. ¿Afáyeste con los correutores gramaticales? Has date cuenta de que entá nun son perfeutos." ) ; examples . put ( "be-BY" , "Паспрабуйце напісаць нейкі тэкст з памылкамі, а LanguageTool паспрабуе паказаць нейкия найбольш распаусюджаныя памылки." ) ; examples . put ( "br-FR" , "Lakait amañ ho testenn vrezhonek da vezañ gwiriet. Pe implijit an frazenn-mañ gant meur a fazioù yezhadurel." ) ; examples . put ( "ca-ES" , "Introduïu açí el vostre text. o feu servir aquest texts com a a exemple per a alguns errades que LanguageTool hi pot detectat." ) ; examples . put ( "zh-CN" , "将文本粘贴在此，或者检测以下文本：我和她去看了二部电影。" ) ; examples . put ( "da-DK" , "Indsæt din egen tekst her , eller brug denne tekst til at se nogle af de fejl LanguageTool fanger. vær opmærksom på at den langtfra er er perfect, men skal være en hjælp til at få standartfejl frem i lyset." ) ; examples . put ( "nl" , "Een ieder kan fouten maken, tikvouten bij voorbeeld." ) ; examples . put ( "eo" , "Alglui vian kontrolendan tekston ĉi tie... Aŭ nur kontrolu tiun ekzemplon. Ĉu vi vi rimarkis, ke estas gramatikaj eraro en tiu frazo? Rimarku, ke Lingvoilo ankaux atentigas pri literumaj erraroj kiel ĉi-tiu." ) ; examples . put ( "fr" , "Copiez votre texte ici ou vérifiez cet exemple contenant plusieurs erreur que LanguageTool doit doit pouvoir detecter." ) ; examples . put ( "gl-ES" , "Esta vai a ser unha mostra de de exemplo para amosar o funcionamento de LanguageTool." ) ; examples . put ( "is-IS" , "Þetta er dæmi um texta sem á að sína farm á hvernig LanguageTool virkar. Það er þó hérmeð gert ljóst að forritið framkvæmir ekki hefðbundna ritvilluleit." ) ; examples . put ( "km-KH" , "ឃ្លា​នេះ​បង្ហាញ​ពី​ពី​កំហុស​វេយ្យាករណ៍ ដើម្បី​បញ្ជាក់​ពី​ប្រសិទ្ធភាព​របស់​កម្មវិធី LanguageTool សំរាប់​ភាសាខ្មែរ។" ) ; examples . put ( "pl-PL" , "Wpisz tekst lub użyj istniejącego przykładu. To jest przykładowy tekst który pokazuje, jak jak działa LanguageTool. LanguageTool ma jusz korektor psowni, który wyrurznia bledy na czewrono." ) ; examples . put ( "it" , "Inserite qui lo vostro testo... oppure controlate direttamente questo ed avrete un assaggio di quali errori possono essere identificati con LanguageTool." ) ; examples . put ( "fa" , "لطفا متن خود را اینجا قرار دهید . یا بررسی کنید که این متن را‌ برای دیدن بعضی بعضی از اشکال هایی که ابزار زبان توانسته تشخیس هدد. درباره ی نرم افزارهای بررسی کننده های گرامر چه فکر می کنید؟ لطفا در نظر داشته باشید که آن‌ها بی نقص نمی باشند.‎" ) ; examples . put ( "pt-PT" , "Cola o teu próprio texto aqui... ou verifica este texto, afim de ver alguns dos dos problemas que o LanguageTool consegue detectar. Isto tal vez permita corrigir os teus erros à última da hora." ) ; examples . put ( "ru-RU" , "Вставьте ваш текст сюда .. или проверьте этот текстт." ) ; examples . put ( "sk-SK" , "Toto je ukážkový vstup, na predvedenie funkčnosti LanguageTool. Pamätajte si si, že neobsahuje \"kontrolu\" preklepo." ) ; examples . put ( "es-ES" , "Escriba un texto aquí. LanguageTool le ayudará a afrentar algunas dificultades propias de la escritura. Se a hecho un esfuerzo para detectar errores tipográficos, ortograficos y incluso gramaticales. También algunos errores de estilo, a grosso modo." ) ; examples . put ( "ta-IN" , "இந்த பெட்டியில் உங்கள் உரையை ஒட்டி சரிவர சோதிக்கிறதா என பாருங்கள். 'லேங்குவேஜ் டூல்' சில இலக்கணப் பிழைகளைச் சரியாக கண்டுபிடிக்கும். பல பிழைகளைப் பிடிக்க தடுமாறலாம்." ) ; examples . put ( "tl-PH" , "Ang LanguageTool ay maganda gamit sa araw-araw. Ang talatang ito ay nagpapakita ng ng kakayahan ng LanguageTool at hinahalimbawa kung paano ito gamitin. Litaw rin sa talatang ito na may mga bagaybagay na hindii pa kayang itama nng LanguageTool." ) ; examples . put ( "uk-UA" , "Будь-ласка, вставте тутт ваш текст, або перевірте цей текст на предмет помилок. Знайти всі помилки для LanguageTool є не по силах з багатьох причин але дещо він вам все таки підкаже. Порівняно з засобами перевірки орфографії LanguageTool також змайде граматичні та стильові проблеми. LanguageTool — ваш самий кращий помічник." ) ; } private final Random rnd = new Random ( 1234 ) ; private final Map < String , String > expectedResults = new HashMap < > ( ) ; @ Test @ Ignore ( "for interactive use only" ) public void test ( ) throws Exception { List < Language > languages1 = new ArrayList < > ( Languages . get ( ) ) ; initExpectedResults ( languages1 ) ; List < Language > languages2 = new ArrayList < > ( Languages . get ( ) ) ; ExecutorService executor = Executors . newFixedThreadPool ( THREADS ) ; for ( int i = 0 ; i < RUNS ; i ++ ) { System . out . println ( "Run #" + i ) ; Collections . shuffle ( languages1 , rnd ) ; Collections . shuffle ( languages2 , rnd ) ; List < Future > futures = new ArrayList < > ( ) ; for ( int j = 0 ; j < languages1 . size ( ) ; j ++ ) { Language lang1 = languages1 . get ( j ) ; Language lang2 = languages2 . get ( j ) ; futures . add ( executor . submit ( new Handler ( lang1 ) ) ) ; futures . add ( executor . submit ( new Handler ( lang2 ) ) ) ; } for ( Future future : futures ) { future . get ( ) ; } } } private void initExpectedResults ( List < Language > languages ) throws IOException { for ( Language lang : languages ) { JLanguageTool lt = new JLanguageTool ( lang ) ; String input = examples . get ( lang . getShortNameWithCountryAndVariant ( ) ) ; if ( input != null ) { List < RuleMatch > matches = lt . check ( input ) ; expectedResults . put ( lang . getShortNameWithCountryAndVariant ( ) , toString ( matches ) ) ; } } } private static String toString ( List < RuleMatch > matches ) { List < String > result = new ArrayList < > ( ) ; for ( RuleMatch match : matches ) { result . add ( toString ( match ) ) ; } return StringUtils . join ( result , "," ) ; } private static String toString ( RuleMatch match ) { return match . getRule ( ) . getId ( ) + "/" + match . getFromPos ( ) + "-" + match . getToPos ( ) ; } class Handler implements Runnable { private final Language lang ; Handler ( Language lang ) { this . lang = lang ; } @ Override public void run ( ) { String input = examples . get ( lang . getShortNameWithCountryAndVariant ( ) ) ; if ( input != null ) { try { JLanguageTool lt = new JLanguageTool ( lang ) ; List < RuleMatch > matches = lt . check ( input ) ; String expected = expectedResults . get ( lang . getShortNameWithCountryAndVariant ( ) ) ; String real = MultiThreadingTest1 . toString ( matches ) ; if ( ! expectedResults . get ( lang . getShortNameWithCountryAndVariant ( ) ) . equals ( real ) ) { fail ( lang + ": got '" + real + "', expected '" + expected + "'" ) ; } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } else { } } } }
package org . languagetool . dev ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . Language ; import org . languagetool . Languages ; import java . io . File ; public class SynthDictionaryBuilderTest extends DictionaryBuilderTestHelper { @ Test @ Ignore ( "for interactive use only" ) public void testExportPosDictAndCreateSynth ( ) throws Exception { for ( Language language : Languages . get ( ) ) { String langCode = language . getShortName ( ) ; File dir = new File ( "./languagetool-language-modules/" + langCode + "/src/main/resources/org/languagetool/resource/" + langCode ) ; File oldBinarySynthFile = new File ( dir , language . getName ( ) . toLowerCase ( ) + "_synth.dict" ) ; if ( ! oldBinarySynthFile . exists ( ) ) { System . out . println ( "Ignoring " + language + ", no synth file found" ) ; continue ; } File oldBinaryFile = new File ( dir , language . getName ( ) . toLowerCase ( ) + ".dict" ) ; File infoFile = new File ( dir , language . getName ( ) . toLowerCase ( ) + "_synth.info" ) ; File exportFile = exportDictionaryContents ( oldBinaryFile ) ; if ( exportFile . length ( ) == 0 ) { System . out . println ( "Zero-size output for " + language + ", skipping dictionary generation" ) ; exportFile . delete ( ) ; continue ; } SynthDictionaryBuilder builder = new SynthDictionaryBuilder ( infoFile ) ; File newBinarySynthFile = builder . build ( exportFile , infoFile ) ; exportFile . delete ( ) ; System . out . println ( language + " old binary file size: " + oldBinarySynthFile . length ( ) + " bytes (" + oldBinarySynthFile . getName ( ) + ")" ) ; System . out . println ( language + " new binary file size: " + newBinarySynthFile . length ( ) + " bytes (" + newBinarySynthFile . getAbsolutePath ( ) + ")" ) ; System . out . println ( "" ) ; } } }
package org . languagetool . rules . ro ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . Map ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Romanian ; import org . languagetool . rules . RuleMatch ; public class SimpleReplaceRuleTest extends TestCase { private SimpleReplaceRule rule ; private JLanguageTool langTool ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; rule = new SimpleReplaceRule ( TestTools . getMessages ( "ro" ) ) ; langTool = new JLanguageTool ( new Romanian ( ) ) ; } public void testInvalidSuggestion ( ) { final List < String > invalidSuggestions = new ArrayList < > ( ) ; final List < Map < String , String > > wrongWords = rule . getWrongWords ( ) ; for ( Map < String , String > ruleEntry : wrongWords ) { for ( Map . Entry < String , String > entry : ruleEntry . entrySet ( ) ) { final String fromWord = entry . getKey ( ) ; final String toWord = entry . getValue ( ) ; if ( toWord == null || fromWord . equals ( toWord ) ) { invalidSuggestions . add ( toWord ) ; } } } if ( ! invalidSuggestions . isEmpty ( ) ) { fail ( "Invalid suggestions found for: " + invalidSuggestions ) ; } } public void testRule ( ) throws IOException { assertEquals ( 0 , rule . match ( langTool . getAnalyzedSentence ( "Paisprezece case." ) ) . length ) ; checkSimpleReplaceRule ( "Patrusprezece case." , "Paisprezece" ) ; checkSimpleReplaceRule ( "Satul are patrusprezece case." , "paisprezece" ) ; checkSimpleReplaceRule ( "Satul are (patrusprezece) case." , "paisprezece" ) ; checkSimpleReplaceRule ( "Satul are «patrusprezece» case." , "paisprezece" ) ; checkSimpleReplaceRule ( "El are șasesprezece ani." , "șaisprezece" ) ; checkSimpleReplaceRule ( "El a luptat pentru întâiele cărți." , "întâile" ) ; checkSimpleReplaceRule ( "El are cinsprezece cărți." , "cincisprezece" ) ; checkSimpleReplaceRule ( "El a fost patruzecioptist." , "pașoptist" ) ; checkSimpleReplaceRule ( "M-am adresat întâiei venite." , "întâii" ) ; checkSimpleReplaceRule ( "M-am adresat întâielor venite." , "întâilor" ) ; checkSimpleReplaceRule ( "A ajuns al douăzecelea." , "douăzecilea" ) ; checkSimpleReplaceRule ( "A ajuns al zecilea." , "zecelea" ) ; checkSimpleReplaceRule ( "A primit jumate de litru de lapte." , "jumătate" ) ; checkSimpleReplaceRule ( "aqua forte" , "acvaforte" ) ; checkSimpleReplaceRule ( "aqua forte." , "acvaforte" ) ; checkSimpleReplaceRule ( "A folosit «aqua forte»." , "acvaforte" ) ; checkSimpleReplaceRule ( "Aqua forte." , "Acvaforte" ) ; checkSimpleReplaceRule ( "este aqua forte" , "acvaforte" ) ; checkSimpleReplaceRule ( "este aqua forte." , "acvaforte" ) ; checkSimpleReplaceRule ( "este Aqua Forte." , "Acvaforte" ) ; checkSimpleReplaceRule ( "este AquA Forte." , "Acvaforte" ) ; checkSimpleReplaceRule ( "A primit jumate de litru de lapte și este aqua forte." , "jumătate" , "acvaforte" ) ; checkSimpleReplaceRule ( "du-te vino" , "du-te-vino" ) ; checkSimpleReplaceRule ( "cou-boi" , "cowboy" ) ; checkSimpleReplaceRule ( "cow-boy" , "cowboy" ) ; checkSimpleReplaceRule ( "cau-boi" , "cowboy" ) ; checkSimpleReplaceRule ( "Cau-boi" , "Cowboy" ) ; checkSimpleReplaceRule ( "cowboy" ) ; checkSimpleReplaceRule ( "Iată un cau-boi" , "cowboy" ) ; checkSimpleReplaceRule ( "Iată un cau-boi." , "cowboy" ) ; checkSimpleReplaceRule ( "Iată un (cau-boi)." , "cowboy" ) ; checkSimpleReplaceRule ( "văcar=cau-boi" , "cowboy" ) ; checkSimpleReplaceRule ( "A fost adăogită o altă regulă." , "adăugită/adăugată" ) ; checkSimpleReplaceRule ( "A venit adinioarea." , "adineaori/adineauri" ) ; checkSimpleReplaceRule ( "A pus axterix." , "asterisc" ) ; checkSimpleReplaceRule ( "A pus axterics." , "asterisc" ) ; checkSimpleReplaceRule ( "A pus asterics." , "asterisc" ) ; } private void checkSimpleReplaceRule ( String sentence , String ... words ) throws IOException { final RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( sentence ) ) ; assertEquals ( "Invalid matches.length while checking sentence: " + sentence , words . length , matches . length ) ; for ( int i = 0 ; i < words . length ; i ++ ) { final String word = words [ i ] ; final String [ ] replacements = word . split ( "\\/" ) ; assertEquals ( "Invalid replacement count wile checking sentence: " + sentence , replacements . length , matches [ i ] . getSuggestedReplacements ( ) . size ( ) ) ; for ( int j = 0 ; j < replacements . length ; j ++ ) { assertEquals ( "Invalid suggested replacement while checking sentence: " + sentence , replacements [ j ] , matches [ i ] . getSuggestedReplacements ( ) . get ( j ) ) ; } } } }
package org . languagetool . dev ; import java . io . ByteArrayOutputStream ; import java . io . File ; import java . io . FileOutputStream ; import java . io . PrintStream ; public class DictionaryBuilderTestHelper { private ByteArrayOutputStream out ; private PrintStream stdout ; private PrintStream stderr ; protected File exportDictionaryContents ( File file ) throws Exception { File outputFile ; trackOutput ( ) ; try { DictionaryExporter . main ( new String [ ] { file . getAbsolutePath ( ) } ) ; } finally { resetOutput ( ) ; } outputFile = File . createTempFile ( POSDictionaryBuilder . class . getSimpleName ( ) , ".export" ) ; FileOutputStream fos = new FileOutputStream ( outputFile ) ; fos . write ( out . toByteArray ( ) ) ; fos . close ( ) ; return outputFile ; } private void trackOutput ( ) { this . stdout = System . out ; this . stderr = System . err ; this . out = new ByteArrayOutputStream ( ) ; final ByteArrayOutputStream err = new ByteArrayOutputStream ( ) ; System . setOut ( new PrintStream ( this . out ) ) ; System . setErr ( new PrintStream ( err ) ) ; } private void resetOutput ( ) { System . setOut ( this . stdout ) ; System . setErr ( this . stderr ) ; } }
package org . languagetool . dev ; import org . junit . Ignore ; import org . junit . Test ; import org . languagetool . Language ; import org . languagetool . Languages ; import java . io . File ; public class POSDictionaryBuilderTest extends DictionaryBuilderTestHelper { @ Test @ Ignore ( "for interactive use only" ) public void testExportAndImport ( ) throws Exception { for ( Language language : Languages . get ( ) ) { String langCode = language . getShortName ( ) ; File dir = new File ( "./languagetool-language-modules/" + langCode + "/src/main/resources/org/languagetool/resource/" + langCode ) ; File oldBinaryFile = new File ( dir , language . getName ( ) . toLowerCase ( ) + ".dict" ) ; File infoFile = new File ( dir , language . getName ( ) . toLowerCase ( ) + ".info" ) ; File exportFile = exportDictionaryContents ( oldBinaryFile ) ; if ( exportFile . length ( ) == 0 ) { System . out . println ( "Zero-size output for " + language + ", skipping dictionary generation" ) ; exportFile . delete ( ) ; continue ; } POSDictionaryBuilder builder = new POSDictionaryBuilder ( infoFile ) ; File newBinaryFile = builder . build ( exportFile ) ; exportFile . delete ( ) ; System . out . println ( language + " old binary file size: " + oldBinaryFile . length ( ) + " bytes (" + oldBinaryFile . getName ( ) + ")" ) ; System . out . println ( language + " new binary file size: " + newBinaryFile . length ( ) + " bytes (" + newBinaryFile . getAbsolutePath ( ) + ")" ) ; System . out . println ( "" ) ; } } }
package org . languagetool . language ; import org . junit . Test ; import org . languagetool . Language ; import org . languagetool . Languages ; import java . util . Objects ; import static org . junit . Assert . fail ; public class LanguageIdentifierTest { private final LanguageIdentifier identifier = new LanguageIdentifier ( ) ; @ Test public void testDetection ( ) { langAssert ( null , "" ) ; langAssert ( null , "X" ) ; langAssert ( "de" , "Das ist ein deutscher Text" ) ; langAssert ( "en" , "This is an English text" ) ; langAssert ( "fr" , "Le mont Revard est un sommet du département français ..." ) ; langAssert ( "be" , "Першапачаткова Linux распрацоўваўся і выкарыстоўваўся асобнымі аматарамі на сваіх персанальных камп'ютарах." ) ; langAssert ( "ca" , "Aquest sistema operatiu va créixer gràcies al treball col·laboratiu de programadors de tot el món ..." ) ; langAssert ( "zh" , "Linux最初是作为支持英特尔x86架构的个人电脑的一个自由操作系统。目前Linux已经被移植到更多的计算机硬件平台" ) ; langAssert ( "da" , "Linux-distributionerne har traditionelt deres største udbredelse på servere, men er hastigt på vej på almindelige pc'er." ) ; langAssert ( "nl" , "Linux is een verzameling van open source Unix-achtige besturingssystemen gebaseerd op de POSIX-standaard." ) ; langAssert ( "el" , "Το Linux μπορεί να εγκατασταθεί και να λειτουργήσει σε μεγάλη ποικιλία υπολογιστικών συστημάτων, από μικρές συσκευές όπως κινητά τηλέφωνα ..." ) ; langAssert ( "is" , "Linux er frjáls stýrikerfiskjarni sem Linus Torvalds byrjaði að skrifa árið 1991, ..." ) ; langAssert ( "it" , "Grazie alla portabilità del kernel Linux sono stati sviluppati sistemi operativi Linux per un'ampia gamma di dispositivi:" ) ; langAssert ( "ja" , "Linuxは、狭義ではLinuxカーネルを意味し、広義ではそれをカーネルとして用いたオペレーティングシステム (OS) を意味する。" ) ; langAssert ( "km" , "បច្ចុប្បន្នគ្មានអត្ថបទក្នុងទំព័រនេះទេ។អ្នកអាច ស្វែងរក​ចំណងជើង​នៃទំព័រនេះក្នុងទំព័រដទៃទៀត​​ ឬ ស្វែង​រក​កំណត់​ហេតុ​ដែល​ពាក់ព័ន្ធ ឬ កែប្រែ​ទំព័រនេះ" ) ; langAssert ( "lt" , "Linux – laisvos (atviro kodo) operacinės sistemos branduolio (kernel) pavadinimas." ) ; langAssert ( "ml" , "വളരെ പ്രശസ്തമായ ഒരു ഓപ്പറേറ്റിംഗ് സിസ്റ്റമാണ് ഗ്നു/ലിനക്സ് (ആംഗലേയം:GNU/Linux)." ) ; langAssert ( "fa" , "این صفحه حذف شده\u200Cاست. در زیر سیاههٔ حذف و انتقال این صفحه نمایش داده شده\u200Cاست." ) ; langAssert ( "pl" , "Linux – rodzina uniksopodobnych systemów operacyjnych opartych na jądrze Linux." ) ; langAssert ( "pt" , "Linux é um termo utilizado para se referir a sistemas operativos ou sistemas operacionais que utilizem o núcleo Linux." ) ; langAssert ( "ro" , "Linux este o familie de sisteme de operare de tip Unix care folosesc Nucleul Linux (în engleză kernel)." ) ; langAssert ( "ru" , "Linux, также Ли́нукс — общее название Unix-подобных операционных систем, основанных на одноимённом ядре." ) ; langAssert ( "sk" , "Linux je počítačový operačný systém a jeho jadro." ) ; langAssert ( "sl" , "Linux je prost operacijski sistem podoben Unixu s prosto dostopno izvorno kodo ..." ) ; langAssert ( "es" , "GNU/Linux es uno de los términos empleados para referirse a la combinación del núcleo o kernel libre ..." ) ; langAssert ( "sv" , "Linux eller GNU/Linux är ett Unix-liknande operativsystem som till största delen" ) ; langAssert ( "tl" , "Ang Linux ay isang operating system kernel para sa mga operating system na humahalintulad sa Unix." ) ; langAssert ( "ta" , "Linux பற்றி பிற கட்டுரைகளில் தேடிப்பாருங்கள்." ) ; langAssert ( "uk" , "Лі́нукс — загальна назва UNIX-подібних операційних систем на основі однойменного ядра." ) ; langAssert ( "km" , "អ្នក\u200Bអាច\u200Bជួយ\u200Bលើក\u200Bស្ទួយ\u200Bវិគីភីឌាភាសាខ្មែរ\u200Bនេះ\u200Bឱ្យ\u200Bមាន\u200Bលក្ខណៈ" ) ; langAssert ( "eo" , "Imperiestraj pingvenoj manĝas ĉefe krustacojn kaj malgrandajn ..." ) ; } @ Test public void testKnownLimitations ( ) { langAssert ( "es" , "L'Iberorrománicu o Iberromance ye un subgrupu de llingües romances que posiblemente ..." ) ; langAssert ( null , "Dodro é un concello da provincia da Coruña pertencente á comarca do Sar ..." ) ; langAssert ( "tl" , "Dhammaan garoomada caalamka ayaa loo isticmaalaa. Ururku waxa uu qabtaa ama uu ku shaqaleeyahay " + "isusocodka diyaaradaha aduunka ee iskaga gooshaya xuduudaha iyo ka hortagga wixii qalad ah iyo baaritaanka " + "marka ay dhacdo dhibaato la xiriirta dulimaad." ) ; } private void langAssert ( String expectedLangCode , String text ) { Language expectedLang = expectedLangCode != null ? Languages . getLanguageForShortName ( expectedLangCode ) : null ; Language detectedLang = identifier . detectLanguage ( text ) ; if ( ! Objects . equals ( expectedLang , detectedLang ) ) { fail ( "Got '" + detectedLang + "', expected '" + expectedLangCode + "' for '" + text + "'" ) ; } } }
package org . languagetool . gui ; import java . io . File ; import java . util . Arrays ; import java . util . HashSet ; import java . util . Set ; import junit . framework . TestCase ; import org . languagetool . Language ; import org . languagetool . language . AmericanEnglish ; import org . languagetool . language . Belarusian ; public class ConfigurationTest extends TestCase { public void testSaveAndLoadConfiguration ( ) throws Exception { final File tempFile = File . createTempFile ( ConfigurationTest . class . getSimpleName ( ) , ".cfg" ) ; createConfiguration ( tempFile , null ) ; try { final Configuration conf = new Configuration ( tempFile . getParentFile ( ) , tempFile . getName ( ) , null ) ; final Set < String > disabledRuleIds = conf . getDisabledRuleIds ( ) ; assertTrue ( disabledRuleIds . contains ( "FOO1" ) ) ; assertTrue ( disabledRuleIds . contains ( "Foo2" ) ) ; assertEquals ( 2 , disabledRuleIds . size ( ) ) ; final Set < String > enabledRuleIds = conf . getEnabledRuleIds ( ) ; assertTrue ( enabledRuleIds . contains ( "enabledRule" ) ) ; assertEquals ( 1 , enabledRuleIds . size ( ) ) ; } finally { tempFile . delete ( ) ; } } private void createConfiguration ( File configFile , Language lang ) throws Exception { final Configuration conf = new Configuration ( configFile . getParentFile ( ) , configFile . getName ( ) , lang ) ; conf . setDisabledRuleIds ( new HashSet < > ( Arrays . asList ( "FOO1" , "Foo2" ) ) ) ; conf . setEnabledRuleIds ( new HashSet < > ( Arrays . asList ( "enabledRule" ) ) ) ; conf . saveConfiguration ( lang ) ; } public void testSaveAndLoadConfigurationForManyLanguages ( ) throws Exception { final File tempFile = File . createTempFile ( ConfigurationTest . class . getSimpleName ( ) , ".cfg" ) ; createConfiguration ( tempFile , new AmericanEnglish ( ) ) ; try { Configuration conf = new Configuration ( tempFile . getParentFile ( ) , tempFile . getName ( ) , new AmericanEnglish ( ) ) ; Set < String > disabledRuleIds = conf . getDisabledRuleIds ( ) ; assertTrue ( disabledRuleIds . contains ( "FOO1" ) ) ; assertTrue ( disabledRuleIds . contains ( "Foo2" ) ) ; assertEquals ( 2 , disabledRuleIds . size ( ) ) ; Set < String > enabledRuleIds = conf . getEnabledRuleIds ( ) ; assertTrue ( enabledRuleIds . contains ( "enabledRule" ) ) ; assertEquals ( 1 , enabledRuleIds . size ( ) ) ; conf = new Configuration ( tempFile . getParentFile ( ) , tempFile . getName ( ) , new Belarusian ( ) ) ; disabledRuleIds = conf . getDisabledRuleIds ( ) ; assertTrue ( disabledRuleIds . isEmpty ( ) ) ; enabledRuleIds = conf . getEnabledRuleIds ( ) ; assertTrue ( enabledRuleIds . isEmpty ( ) ) ; conf . setEnabledRuleIds ( new HashSet < > ( Arrays . asList ( "enabledBYRule" ) ) ) ; conf . saveConfiguration ( new Belarusian ( ) ) ; conf = new Configuration ( tempFile . getParentFile ( ) , tempFile . getName ( ) , new AmericanEnglish ( ) ) ; disabledRuleIds = conf . getDisabledRuleIds ( ) ; assertTrue ( disabledRuleIds . contains ( "FOO1" ) ) ; assertTrue ( disabledRuleIds . contains ( "Foo2" ) ) ; assertEquals ( 2 , disabledRuleIds . size ( ) ) ; enabledRuleIds = conf . getEnabledRuleIds ( ) ; assertTrue ( enabledRuleIds . contains ( "enabledRule" ) ) ; assertEquals ( 1 , enabledRuleIds . size ( ) ) ; } finally { tempFile . delete ( ) ; } } }
package org . languagetool . gui ; import junit . framework . TestCase ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . language . English ; import org . languagetool . rules . WordRepeatRule ; public class RuleLinkTest extends TestCase { public void testBuildDeactivationLink ( ) { final Language language = new English ( ) ; final RuleLink ruleLink = RuleLink . buildDeactivationLink ( new WordRepeatRule ( TestTools . getMessages ( language . getShortName ( ) ) , language ) ) ; assertEquals ( "WORD_REPEAT_RULE" , ruleLink . getId ( ) ) ; assertEquals ( "http://languagetool.org/deactivate/WORD_REPEAT_RULE" , ruleLink . toString ( ) ) ; } public void testBuildReactivationLink ( ) { final Language language = new English ( ) ; final RuleLink ruleLink = RuleLink . buildReactivationLink ( new WordRepeatRule ( TestTools . getMessages ( language . getShortName ( ) ) , language ) ) ; assertEquals ( "WORD_REPEAT_RULE" , ruleLink . getId ( ) ) ; assertEquals ( "http://languagetool.org/reactivate/WORD_REPEAT_RULE" , ruleLink . toString ( ) ) ; } public void testGetFromString ( ) { final RuleLink ruleLink1 = RuleLink . getFromString ( "http://languagetool.org/reactivate/FOO_BAR_ID" ) ; assertEquals ( "FOO_BAR_ID" , ruleLink1 . getId ( ) ) ; assertEquals ( "http://languagetool.org/reactivate/FOO_BAR_ID" , ruleLink1 . toString ( ) ) ; final RuleLink ruleLink2 = RuleLink . getFromString ( "http://languagetool.org/deactivate/FOO_BAR_ID2" ) ; assertEquals ( "FOO_BAR_ID2" , ruleLink2 . getId ( ) ) ; assertEquals ( "http://languagetool.org/deactivate/FOO_BAR_ID2" , ruleLink2 . toString ( ) ) ; } }
package org . languagetool . tools ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . English ; import org . languagetool . language . Polish ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . bitext . BitextRule ; import org . xml . sax . SAXException ; import javax . xml . parsers . ParserConfigurationException ; import java . io . ByteArrayOutputStream ; import java . io . IOException ; import java . io . PrintStream ; import java . util . List ; public class ToolsTest extends TestCase { private PrintStream stdout ; private PrintStream stderr ; @ Override public void setUp ( ) throws Exception { super . setUp ( ) ; this . stdout = System . out ; this . stderr = System . err ; ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; ByteArrayOutputStream err = new ByteArrayOutputStream ( ) ; System . setOut ( new PrintStream ( out ) ) ; System . setErr ( new PrintStream ( err ) ) ; } @ Override public void tearDown ( ) throws Exception { super . tearDown ( ) ; System . setOut ( this . stdout ) ; System . setErr ( this . stderr ) ; } public void testBitextCheck ( ) throws IOException , ParserConfigurationException , SAXException { final English english = new English ( ) ; final JLanguageTool srcTool = new JLanguageTool ( english ) ; final Polish polish = new Polish ( ) ; final JLanguageTool trgTool = new JLanguageTool ( polish ) ; final List < BitextRule > rules = Tools . getBitextRules ( english , polish ) ; int matches1 = Tools . checkBitext ( "This is a perfectly good sentence." , "To jest całkowicie prawidłowe zdanie." , srcTool , trgTool , rules ) . size ( ) ; assertEquals ( 0 , matches1 ) ; List < RuleMatch > matches = Tools . checkBitext ( "This is not actual." , "To nie jest aktualne." , srcTool , trgTool , rules ) ; assertEquals ( 1 , matches . size ( ) ) ; assertTrue ( matches . get ( 0 ) . getRule ( ) . getId ( ) . equals ( "ACTUAL" ) ) ; } }
package org . languagetool . rules ; import java . io . IOException ; import java . util . HashSet ; import java . util . List ; import java . util . Set ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . patterns . PatternRule ; public class RuleTest extends TestCase { public void testJavaRules ( ) throws IOException { final Set < String > ids = new HashSet < > ( ) ; final Set < Class > ruleClasses = new HashSet < > ( ) ; if ( Languages . getWithDemoLanguage ( ) . size ( ) <= 1 ) { System . err . println ( "***************************************************************************" ) ; System . err . println ( "WARNING: found only these languages - the tests might not be complete:" ) ; System . err . println ( Languages . getWithDemoLanguage ( ) ) ; System . err . println ( "***************************************************************************" ) ; } for ( Language language : Languages . getWithDemoLanguage ( ) ) { final JLanguageTool lt = new JLanguageTool ( language ) ; final List < Rule > allRules = lt . getAllRules ( ) ; for ( Rule rule : allRules ) { if ( ! ( rule instanceof PatternRule ) ) { assertIdUniqueness ( ids , ruleClasses , language , rule ) ; assertIdValidity ( language , rule ) ; assertTrue ( rule . supportsLanguage ( language ) ) ; testExamples ( rule , lt ) ; } } } } private void assertIdUniqueness ( Set < String > ids , Set < Class > ruleClasses , Language language , Rule rule ) { final String ruleId = rule . getId ( ) ; if ( ids . contains ( ruleId ) && ! ruleClasses . contains ( rule . getClass ( ) ) ) { throw new RuntimeException ( "Rule id occurs more than once: '" + ruleId + "', language: " + language ) ; } ids . add ( ruleId ) ; ruleClasses . add ( rule . getClass ( ) ) ; } private void assertIdValidity ( Language language , Rule rule ) { final String ruleId = rule . getId ( ) ; if ( ! ruleId . matches ( "^[A-Z_]+$" ) ) { throw new RuntimeException ( "Invalid character in rule id: '" + ruleId + "', language: " + language + ", only [A-Z_] are allowed" ) ; } } private void testExamples ( Rule rule , JLanguageTool lt ) throws IOException { testCorrectExamples ( rule , lt ) ; testIncorrectExamples ( rule , lt ) ; } private void testCorrectExamples ( Rule rule , JLanguageTool lt ) throws IOException { List < String > correctExamples = rule . getCorrectExamples ( ) ; for ( String correctExample : correctExamples ) { String input = cleanMarkers ( correctExample ) ; enableOnlyOneRule ( lt , rule ) ; List < RuleMatch > ruleMatches = lt . check ( input ) ; assertEquals ( "Got unexpected rule match for correct example sentence:\n" + "Text: " + input + "\n" + "Rule: " + rule . getId ( ) + "\n" + "Matches: " + ruleMatches , 0 , ruleMatches . size ( ) ) ; } } private void testIncorrectExamples ( Rule rule , JLanguageTool lt ) throws IOException { List < IncorrectExample > incorrectExamples = rule . getIncorrectExamples ( ) ; for ( IncorrectExample incorrectExample : incorrectExamples ) { String input = cleanMarkers ( incorrectExample . getExample ( ) ) ; enableOnlyOneRule ( lt , rule ) ; List < RuleMatch > ruleMatches = lt . check ( input ) ; assertEquals ( "Did not get the expected rule match for the incorrect example sentence:\n" + "Text: " + input + "\n" + "Rule: " + rule . getId ( ) + "\n" + "Matches: " + ruleMatches , 1 , ruleMatches . size ( ) ) ; } } private void enableOnlyOneRule ( JLanguageTool lt , Rule ruleToActivate ) { for ( Rule rule : lt . getAllRules ( ) ) { lt . disableRule ( rule . getId ( ) ) ; } lt . enableRule ( ruleToActivate . getId ( ) ) ; lt . enableDefaultOffRule ( ruleToActivate . getId ( ) ) ; } private String cleanMarkers ( String example ) { return example . replace ( "<marker>" , "" ) . replace ( "</marker>" , "" ) ; } }
package org . languagetool . rules . patterns ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . MultiThreadedJLanguageTool ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tools . StringTools ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . util . List ; import java . util . Random ; final class PerformanceTest2 { private static final int RUNS = 100 ; private static final int SKIP = 3 ; private static final int MAX_TEXT_LENGTH = 150 ; private void run ( String languageCode , File textFile ) throws IOException { String text = StringTools . readStream ( new FileInputStream ( textFile ) , "utf-8" ) ; System . out . println ( "Text length: " + text . length ( ) ) ; Random rnd = new Random ( 42 ) ; Language language = Languages . getLanguageForShortName ( languageCode ) ; long totalTime = 0 ; for ( int i = 0 ; i < RUNS ; i ++ ) { int beginIndex = rnd . nextInt ( text . length ( ) ) ; int endIndex = Math . min ( beginIndex + MAX_TEXT_LENGTH , text . length ( ) - 1 ) ; String subText = text . substring ( beginIndex , endIndex ) ; long startTime = System . currentTimeMillis ( ) ; MultiThreadedJLanguageTool langTool = new MultiThreadedJLanguageTool ( language ) ; List < RuleMatch > matches = langTool . check ( subText ) ; long runTime = System . currentTimeMillis ( ) - startTime ; langTool . shutdown ( ) ; if ( i >= SKIP ) { totalTime += runTime ; System . out . println ( "Time: " + runTime + "ms (" + matches . size ( ) + " matches)" ) ; } else { System . out . println ( "Time: " + runTime + "ms (" + matches . size ( ) + " matches) - skipped because of warm-up" ) ; } } System . out . println ( "Avg. Time: " + ( float ) totalTime / RUNS ) ; } public static void main ( String [ ] args ) throws IOException { if ( args . length != 2 ) { System . out . println ( "Usage: " + PerformanceTest2 . class . getSimpleName ( ) + " <languageCode> <text_file>" ) ; System . exit ( 1 ) ; } PerformanceTest2 test = new PerformanceTest2 ( ) ; File textFile = new File ( args [ 1 ] ) ; test . run ( args [ 0 ] , textFile ) ; } }
package org . languagetool . rules . patterns ; import java . io . IOException ; import java . util . Collections ; import java . util . List ; import javax . xml . parsers . ParserConfigurationException ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . language . * ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . en . MorfologikAmericanSpellerRule ; import org . languagetool . rules . en . MorfologikBritishSpellerRule ; import org . xml . sax . SAXException ; public class FalseFriendRuleTest extends TestCase { public void testHintsForGermanSpeakers ( ) throws IOException , ParserConfigurationException , SAXException { final JLanguageTool langTool = new JLanguageTool ( new English ( ) , new German ( ) ) ; final List < RuleMatch > matches = assertErrors ( 1 , "We will berate you." , langTool ) ; assertEquals ( matches . get ( 0 ) . getSuggestedReplacements ( ) . toString ( ) , "[provide advice, give advice]" ) ; assertErrors ( 0 , "We will give you advice." , langTool ) ; assertErrors ( 1 , "I go to high school in Foocity." , langTool ) ; final List < RuleMatch > matches2 = assertErrors ( 1 , "The chef" , langTool ) ; assertEquals ( "[boss, chief]" , matches2 . get ( 0 ) . getSuggestedReplacements ( ) . toString ( ) ) ; } public void testHintsForGermanSpeakersWithVariant ( ) throws IOException , ParserConfigurationException , SAXException { final JLanguageTool langTool = new JLanguageTool ( new BritishEnglish ( ) , new SwissGerman ( ) ) ; final List < RuleMatch > matches = assertErrors ( 1 , "We will berate you." , langTool ) ; assertEquals ( matches . get ( 0 ) . getSuggestedReplacements ( ) . toString ( ) , "[provide advice, give advice]" ) ; assertErrors ( 0 , "We will give you advice." , langTool ) ; assertErrors ( 1 , "I go to high school in Berlin." , langTool ) ; final List < RuleMatch > matches2 = assertErrors ( 1 , "The chef" , langTool ) ; assertEquals ( "[boss, chief]" , matches2 . get ( 0 ) . getSuggestedReplacements ( ) . toString ( ) ) ; } public void testHintsForDemoLanguage ( ) throws IOException , ParserConfigurationException , SAXException { final JLanguageTool langTool1 = new JLanguageTool ( new BritishEnglish ( ) , new German ( ) ) ; langTool1 . disableRule ( MorfologikBritishSpellerRule . RULE_ID ) ; final List < RuleMatch > matches1 = assertErrors ( 1 , "And forDemoOnly." , langTool1 ) ; assertEquals ( "DEMO_ENTRY" , matches1 . get ( 0 ) . getRule ( ) . getId ( ) ) ; final JLanguageTool langTool2 = new JLanguageTool ( new English ( ) , new German ( ) ) ; langTool2 . disableRule ( MorfologikBritishSpellerRule . RULE_ID ) ; final List < RuleMatch > matches2 = assertErrors ( 1 , "And forDemoOnly." , langTool2 ) ; assertEquals ( "DEMO_ENTRY" , matches2 . get ( 0 ) . getRule ( ) . getId ( ) ) ; final JLanguageTool langTool3 = new JLanguageTool ( new AmericanEnglish ( ) , new German ( ) ) ; langTool3 . disableRule ( MorfologikAmericanSpellerRule . RULE_ID ) ; assertErrors ( 0 , "And forDemoOnly." , langTool3 ) ; } public void testHintsForEnglishSpeakers ( ) throws IOException , ParserConfigurationException , SAXException { final JLanguageTool langTool = new JLanguageTool ( new German ( ) , new English ( ) ) ; assertErrors ( 1 , "Man sollte ihn nicht so beraten." , langTool ) ; assertErrors ( 0 , "Man sollte ihn nicht so beschimpfen." , langTool ) ; assertErrors ( 1 , "Ich gehe in Blubbstadt zur Hochschule." , langTool ) ; } public void testHintsForPolishSpeakers ( ) throws IOException , ParserConfigurationException , SAXException { final JLanguageTool langTool = new JLanguageTool ( new English ( ) { @ Override protected synchronized List < PatternRule > getPatternRules ( ) { return Collections . emptyList ( ) ; } } , new Polish ( ) ) ; assertErrors ( 1 , "This is an absurd." , langTool ) ; assertErrors ( 0 , "This is absurdity." , langTool ) ; assertSuggestions ( 0 , "This is absurdity." , langTool ) ; assertErrors ( 1 , "I have to speak to my advocate." , langTool ) ; assertSuggestions ( 3 , "My brother is politic." , langTool ) ; } private List < RuleMatch > assertErrors ( int errorCount , String s , JLanguageTool langTool ) throws IOException { final List < RuleMatch > matches = langTool . check ( s ) ; assertEquals ( "Matches found: " + matches , errorCount , matches . size ( ) ) ; return matches ; } private void assertSuggestions ( final int suggestionCount , final String text , final JLanguageTool langTool ) throws IOException { final List < RuleMatch > matches = langTool . check ( text ) ; int suggestionsFound = 0 ; for ( final RuleMatch match : matches ) { int pos = 0 ; while ( pos != - 1 ) { pos = match . getMessage ( ) . indexOf ( "<suggestion>" , pos + 1 ) ; suggestionsFound ++ ; } } if ( suggestionsFound > 0 ) { suggestionsFound -- ; } assertEquals ( suggestionCount , suggestionsFound ) ; } }
package org . languagetool . rules . patterns ; import org . languagetool . JLanguageTool ; import org . languagetool . Languages ; import org . languagetool . MultiThreadedJLanguageTool ; import org . languagetool . tools . StringTools ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; final class PerformanceTest { private PerformanceTest ( ) { } private void run ( JLanguageTool langTool , File textFile ) throws IOException { String text = StringTools . readStream ( new FileInputStream ( textFile ) , "utf-8" ) ; int sentenceCount = langTool . sentenceTokenize ( text ) . size ( ) ; System . out . println ( "Language: " + langTool . getLanguage ( ) + ", Text length: " + text . length ( ) + " chars, " + sentenceCount + " sentences" ) ; System . out . println ( "Warmup..." ) ; long startTime1 = System . currentTimeMillis ( ) ; langTool . check ( text ) ; long runTime1 = System . currentTimeMillis ( ) - startTime1 ; float timePerSentence1 = ( float ) runTime1 / sentenceCount ; System . out . printf ( "Check time on first run: " + runTime1 + "ms = %.1fms per sentence\n" , timePerSentence1 ) ; System . out . println ( "Checking text..." ) ; long startTime2 = System . currentTimeMillis ( ) ; langTool . check ( text ) ; long runTime2 = System . currentTimeMillis ( ) - startTime2 ; float timePerSentence2 = ( float ) runTime2 / sentenceCount ; System . out . printf ( "Check time after warmup: " + runTime2 + "ms = %.1fms per sentence\n" , timePerSentence2 ) ; } public static void main ( String [ ] args ) throws IOException { if ( args . length != 2 ) { System . out . println ( "Usage: " + PerformanceTest . class . getSimpleName ( ) + " <languageCode> <text_file>" ) ; System . exit ( 1 ) ; } PerformanceTest test = new PerformanceTest ( ) ; String languageCode = args [ 0 ] ; File textFile = new File ( args [ 1 ] ) ; MultiThreadedJLanguageTool langTool = new MultiThreadedJLanguageTool ( Languages . getLanguageForShortName ( languageCode ) ) ; test . run ( langTool , textFile ) ; langTool . shutdown ( ) ; } }
package org . languagetool . rules . ro ; import org . languagetool . rules . patterns . PatternRuleTest ; import java . io . IOException ; public class RomanianPatternRuleTest extends PatternRuleTest { public void testRules ( ) throws IOException { runGrammarRulesFromXmlTest ( ) ; } }
package org . languagetool . rules . patterns ; import org . languagetool . JLanguageTool ; import org . languagetool . Languages ; import org . languagetool . rules . Rule ; import org . languagetool . tools . StringTools ; import java . io . FileInputStream ; import java . io . IOException ; final class RuleNumberScalabilityTest { public static void main ( String [ ] args ) throws IOException { if ( args . length != 2 ) { System . out . println ( "Usage: " + RuleNumberScalabilityTest . class . getSimpleName ( ) + " <languageCode> <text_file>" ) ; System . exit ( 1 ) ; } JLanguageTool langTool = new JLanguageTool ( Languages . getLanguageForShortName ( args [ 0 ] ) ) ; String text = StringTools . readStream ( new FileInputStream ( args [ 1 ] ) , "utf-8" ) ; System . out . println ( "Warmup..." ) ; langTool . check ( text ) ; langTool . check ( text ) ; long baselineTime = getBaselineTime ( langTool , text ) ; System . out . println ( "Baseline: " + baselineTime + "ms (time with no pattern rules active)" ) ; int ruleNumber = langTool . getAllActiveRules ( ) . size ( ) ; System . out . println ( "Total rules: " + ruleNumber ) ; int steps = 5 ; int prevActiveRules = - 1 ; long prevCleanRunTime = - 1 ; for ( int i = steps ; i > 0 ; i -- ) { int targetActiveRules = ruleNumber / i ; deactivateAllRules ( langTool ) ; for ( Rule rule : langTool . getAllRules ( ) ) { langTool . enableRule ( rule . getId ( ) ) ; if ( langTool . getAllActiveRules ( ) . size ( ) > targetActiveRules ) { break ; } } int activeRules = langTool . getAllActiveRules ( ) . size ( ) ; long startTime = System . currentTimeMillis ( ) ; langTool . check ( text ) ; long runTime = System . currentTimeMillis ( ) - startTime ; long cleanRunTime = runTime - baselineTime ; if ( prevActiveRules != - 1 && prevCleanRunTime != - 1 ) { float ruleFactor = ( float ) activeRules / prevActiveRules ; float cleanRuntimeFactor = ( float ) cleanRunTime / prevCleanRunTime ; System . out . println ( "Active rules: " + activeRules + ", runtime: " + runTime + "ms, cleanRunTime: " + cleanRunTime + ", ruleFactor: " + ruleFactor + ", cleanRuntimeFactor: " + cleanRuntimeFactor ) ; } else { System . out . println ( "Active rules: " + activeRules + ", runtime: " + runTime + "ms, cleanRunTime: " + cleanRunTime ) ; } prevActiveRules = activeRules ; prevCleanRunTime = cleanRunTime ; } System . out . println ( "ruleFactor = the number of rules compared to the previous run" ) ; System . out . println ( "cleanRuntimeFactor = the runtime (without baseline) compared to the previous run" ) ; System . out . println ( " => cleanRuntimeFactor should not grow much more than ruleFactor, otherwise we scale" ) ; System . out . println ( " => badly with respect to the number of rules" ) ; } private static long getBaselineTime ( JLanguageTool langTool , String text ) throws IOException { deactivateAllRules ( langTool ) ; long baselineStartTime = System . currentTimeMillis ( ) ; langTool . check ( text ) ; long baselineTime = System . currentTimeMillis ( ) - baselineStartTime ; if ( langTool . getAllActiveRules ( ) . size ( ) > 0 ) { throw new RuntimeException ( "Did not expect to get any pattern rules: " + langTool . getAllActiveRules ( ) . size ( ) ) ; } for ( Rule rule : langTool . getAllRules ( ) ) { langTool . enableRule ( rule . getId ( ) ) ; } return baselineTime ; } private static void deactivateAllRules ( JLanguageTool langTool ) { for ( Rule rule : langTool . getAllActiveRules ( ) ) { langTool . disableRule ( rule . getId ( ) ) ; } } }
package org . languagetool . rules . bitext ; import junit . framework . TestCase ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . language . English ; import org . languagetool . language . Polish ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . bitext . BitextPatternRule ; import org . languagetool . rules . patterns . bitext . FalseFriendsAsBitextLoader ; import org . xml . sax . SAXException ; import javax . xml . parsers . ParserConfigurationException ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; public class FalseFriendsAsBitextLoaderTest extends TestCase { public void testHintsForPolishTranslators ( ) throws IOException , ParserConfigurationException , SAXException { final Polish polish = new Polish ( ) ; final English english = new English ( ) ; final JLanguageTool langTool = new JLanguageTool ( english , polish ) ; final JLanguageTool trgTool = new JLanguageTool ( polish ) ; final FalseFriendsAsBitextLoader ruleLoader = new FalseFriendsAsBitextLoader ( ) ; final String name = "/false-friends.xml" ; final List < BitextPatternRule > rules = ruleLoader . getFalseFriendsAsBitext ( name , english , polish ) ; assertErrors ( 1 , rules , "This is an absurd." , "To absurd." , langTool , trgTool ) ; assertErrors ( 1 , rules , "I have to speak to my advocate." , "Muszę porozmawiać z adwokatem." , langTool , trgTool ) ; assertErrors ( 1 , rules , "This is not actual." , "To nie jest aktualne." , langTool , trgTool ) ; assertErrors ( 0 , rules , "This is not actual." , "To nie jest rzeczywiste." , langTool , trgTool ) ; } private List < RuleMatch > check ( final List < BitextPatternRule > bRules , final String src , final String trg , final JLanguageTool srcTool , final JLanguageTool trgTool ) throws IOException { final List < RuleMatch > allMatches = new ArrayList < > ( ) ; for ( BitextPatternRule bRule : bRules ) { final RuleMatch [ ] matches = match ( bRule , src , trg , srcTool , trgTool ) ; if ( matches != null ) { Collections . addAll ( allMatches , matches ) ; } } return allMatches ; } private RuleMatch [ ] match ( final BitextPatternRule rule , final String src , final String trg , final JLanguageTool srcLanguageTool , final JLanguageTool trgLanguageTool ) throws IOException { final AnalyzedSentence srcText = srcLanguageTool . getAnalyzedSentence ( src ) ; final AnalyzedSentence trgText = trgLanguageTool . getAnalyzedSentence ( trg ) ; return rule . match ( srcText , trgText ) ; } private void assertErrors ( int errorCount , final List < BitextPatternRule > rules , final String src , final String trg , JLanguageTool srcTool , JLanguageTool trgTool ) throws IOException { final List < RuleMatch > matches = check ( rules , src , trg , srcTool , trgTool ) ; assertEquals ( errorCount , matches . size ( ) ) ; } }
package org . languagetool . rules . bitext ; import junit . framework . TestCase ; public class StandaloneBitextPatternRuleTest extends TestCase { public void testBitextPatternRuleTest ( ) throws Exception { final BitextPatternRuleTest test = new BitextPatternRuleTest ( ) ; test . testBitextRulesFromXML ( ) ; } }
package org . languagetool . tagging ; import org . junit . Test ; import org . languagetool . JLanguageTool ; import java . io . IOException ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertThat ; public class ManualTaggerTest { private static final String MANUAL_DICT_FILENAME = "/de/added.txt" ; @ Test public void testTag ( ) throws IOException { ManualTagger tagger = new ManualTagger ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( MANUAL_DICT_FILENAME ) ) ; assertThat ( tagger . tag ( "" ) . size ( ) , is ( 0 ) ) ; assertThat ( tagger . tag ( "gibtsnicht" ) . size ( ) , is ( 0 ) ) ; assertEquals ( "[Ableitung/SUB:NOM:PLU:FEM, Ableitung/SUB:GEN:PLU:FEM, Ableitung/SUB:DAT:PLU:FEM, Ableitung/SUB:AKK:PLU:FEM]" , tagger . tag ( "Ableitungen" ) . toString ( ) ) ; assertThat ( tagger . tag ( "ableitungen" ) . size ( ) , is ( 0 ) ) ; } }
package org . languagetool . tagging . disambiguation ; import junit . framework . TestCase ; import org . languagetool . AnalyzedSentence ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . language . English ; import org . languagetool . language . Ukrainian ; public class MultiWordChunkerTest extends TestCase { public void testDisambiguate ( ) throws Exception { final Disambiguator chunker = new MultiWordChunker ( "/pl/multiwords.txt" ) ; final JLanguageTool lt = new JLanguageTool ( new English ( ) ) ; final AnalyzedSentence analyzedSentence = lt . getAnalyzedSentence ( "A test... More." ) ; final AnalyzedSentence disambiguated = chunker . disambiguate ( analyzedSentence ) ; final AnalyzedTokenReadings [ ] tokens = disambiguated . getTokens ( ) ; assertTrue ( tokens [ 4 ] . getReadings ( ) . toString ( ) . contains ( "<ELLIPSIS>" ) ) ; assertTrue ( tokens [ 6 ] . getReadings ( ) . toString ( ) . contains ( "</ELLIPSIS>" ) ) ; } public void testDisambiguateMultiSpace ( ) throws Exception { final Disambiguator chunker = new MultiWordChunker ( "/uk/multiwords.txt" ) ; final JLanguageTool lt = new JLanguageTool ( new Ukrainian ( ) ) ; final AnalyzedSentence analyzedSentence = lt . getAnalyzedSentence ( "для годиться." ) ; final AnalyzedSentence disambiguated = chunker . disambiguate ( analyzedSentence ) ; final AnalyzedTokenReadings [ ] tokens = disambiguated . getTokens ( ) ; assertTrue ( tokens [ 1 ] . getReadings ( ) . toString ( ) . contains ( "<adv>" ) ) ; assertTrue ( tokens [ 4 ] . getReadings ( ) . toString ( ) . contains ( "</adv>" ) ) ; } }
package org . languagetool . tagging . disambiguation . rules ; import junit . framework . TestCase ; public class StandaloneDisambiguationRuleTest extends TestCase { public void testDisambiguationRuleTest ( ) throws Exception { final DisambiguationRuleTest test = new DisambiguationRuleTest ( ) ; test . testDisambiguationRulesFromXML ( ) ; } }
package org . languagetool . tokenizers ; import junit . framework . TestCase ; import org . languagetool . Language ; import org . languagetool . Languages ; public class SRXSentenceTokenizerTest extends TestCase { public void testOfficeFootnoteTokenize ( ) { int count = 0 ; for ( Language language : Languages . get ( ) ) { if ( language . getSentenceTokenizer ( ) . getClass ( ) != SRXSentenceTokenizer . class ) { continue ; } if ( language . getShortName ( ) . equals ( "km" ) || language . getShortName ( ) . equals ( "ml" ) ) { continue ; } final String input = "A sentence.\u0002 And another one." ; final SentenceTokenizer tokenizer = new SRXSentenceTokenizer ( language ) ; assertEquals ( "Sentence not split correctly for " + language + ": '" + input + "'" , "[A sentence.\u0002 , And another one.]" , tokenizer . tokenize ( input ) . toString ( ) ) ; count ++ ; } if ( count == 0 ) { fail ( "No languages found for testing" ) ; } } }
package org . languagetool . dev ; import org . apache . lucene . index . Fields ; import org . apache . lucene . index . MultiFields ; import org . apache . lucene . index . Terms ; import org . apache . lucene . index . TermsEnum ; import org . apache . lucene . util . BytesRef ; import org . languagetool . JLanguageTool ; import org . languagetool . languagemodel . LuceneLanguageModel ; import org . languagetool . rules . ConfusionSet ; import org . languagetool . rules . ConfusionSetLoader ; import java . io . File ; import java . io . IOException ; import java . io . InputStream ; import java . util . * ; class HomophoneOccurrenceDumper extends LuceneLanguageModel { private static final int MIN_COUNT = 1000 ; HomophoneOccurrenceDumper ( File topIndexDir ) throws IOException { super ( topIndexDir ) ; } Map < String , Long > getContext ( String ... tokens ) throws IOException { Objects . requireNonNull ( tokens ) ; TermsEnum iterator = getIterator ( ) ; Map < String , Long > result = new HashMap < > ( ) ; BytesRef byteRef ; int i = 0 ; while ( ( byteRef = iterator . next ( ) ) != null ) { String term = new String ( byteRef . bytes , byteRef . offset , byteRef . length ) ; for ( String token : tokens ) { if ( term . contains ( " " + token + " " ) ) { String [ ] split = term . split ( " " ) ; if ( split . length == 3 ) { long count = getCount ( split [ 0 ] , split [ 1 ] , split [ 2 ] ) ; result . put ( term , count ) ; } } } } return result ; } private void run ( String confusionSetPath ) throws IOException { System . err . println ( "Loading confusion sets from " + confusionSetPath + ", minimum occurrence: " + MIN_COUNT ) ; ConfusionSetLoader confusionSetLoader = new ConfusionSetLoader ( ) ; InputStream inputStream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( confusionSetPath ) ; Map < String , List < ConfusionSet > > map = confusionSetLoader . loadConfusionSet ( inputStream ) ; Set < String > confusionTerms = map . keySet ( ) ; dumpOccurrences ( confusionTerms ) ; } private void dumpOccurrences ( Set < String > tokens ) throws IOException { Objects . requireNonNull ( tokens ) ; TermsEnum iterator = getIterator ( ) ; BytesRef byteRef ; int i = 0 ; while ( ( byteRef = iterator . next ( ) ) != null ) { String term = new String ( byteRef . bytes , byteRef . offset , byteRef . length ) ; String [ ] split = term . split ( " " ) ; if ( split . length == 3 ) { String token = split [ 1 ] ; if ( tokens . contains ( token ) ) { long count = getCount ( split [ 0 ] , split [ 1 ] , split [ 2 ] ) ; if ( count >= MIN_COUNT ) { System . out . println ( token + "\t" + count + "\t" + split [ 0 ] + " " + split [ 1 ] + " " + split [ 2 ] ) ; } } } if ( i % 10_000 == 0 ) { System . err . println ( i + "..." ) ; } i ++ ; } } private TermsEnum getIterator ( ) throws IOException { LuceneSearcher luceneSearcher = getLuceneSearcher ( 3 ) ; Fields fields = MultiFields . getFields ( luceneSearcher . getReader ( ) ) ; Terms terms = fields . terms ( "ngram" ) ; return terms . iterator ( null ) ; } public static void main ( String [ ] args ) throws IOException { if ( args . length != 1 ) { System . out . println ( "Usage: " + HomophoneOccurrenceDumper . class . getSimpleName ( ) + " <indexDir>" ) ; System . exit ( 1 ) ; } try ( HomophoneOccurrenceDumper dumper = new HomophoneOccurrenceDumper ( new File ( args [ 0 ] ) ) ) { dumper . run ( "/en/confusion_sets.txt" ) ; } } @ Override public long getTotalTokenCount ( ) { throw new RuntimeException ( "not implemented" ) ; } }
package org . languagetool . dev ; import java . io . File ; import java . io . IOException ; import java . util . * ; class NGramStats { private void lookup ( File dir , String phrase ) throws IOException { try ( HomophoneOccurrenceDumper lm = new HomophoneOccurrenceDumper ( dir ) ) { String [ ] tokens = phrase . split ( " " ) ; if ( tokens . length > 3 ) { throw new RuntimeException ( "Phrases of length " + tokens . length + " are not yet supported: '" + phrase + "'" ) ; } else { long count = lm . getCount ( Arrays . asList ( tokens ) ) ; System . out . println ( phrase + ": " + count ) ; } } } public static void main ( String [ ] args ) throws IOException { if ( args . length != 1 && args . length != 2 ) { System . out . println ( "Usage: " + NGramStats . class . getSimpleName ( ) + " <dir> <phrase>" ) ; System . out . println ( " 'dir' is a directory with '1grams' etc sub directories with a Lucene index of ngrams" ) ; System . out . println ( " 'phrase' is a 1 to 3 word case-sensitive phrase, e.g. \"the tall boy\" (include the quotes)" ) ; System . exit ( 1 ) ; } String dir = args [ 0 ] ; String phrase = args [ 1 ] ; NGramStats stats = new NGramStats ( ) ; stats . lookup ( new File ( dir ) , phrase ) ; } }
package org . languagetool . dev ; import java . io . BufferedWriter ; import java . io . File ; import java . io . FileOutputStream ; import java . io . IOException ; import java . io . OutputStreamWriter ; import java . io . Writer ; import java . util . List ; import java . util . Scanner ; import org . apache . commons . cli . BasicParser ; import org . apache . commons . cli . CommandLine ; import org . apache . commons . cli . CommandLineParser ; import org . apache . commons . cli . Option ; import org . apache . commons . cli . Options ; import org . apache . commons . cli . ParseException ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . tokenizers . Tokenizer ; final class SpellDictionaryBuilder extends DictionaryBuilder { SpellDictionaryBuilder ( File infoFile ) throws IOException { super ( infoFile ) ; } private static CommandLine parseArguments ( String [ ] args ) throws ParseException { Options options = new Options ( ) ; Option option = new Option ( "o" , true , "output file" ) ; option . setRequired ( true ) ; options . addOption ( option ) ; CommandLineParser parser = new BasicParser ( ) ; CommandLine cmd = parser . parse ( options , args ) ; return cmd ; } public static void main ( String [ ] args ) throws Exception { CommandLine cmdLine = null ; try { cmdLine = SpellDictionaryBuilder . parseArguments ( args ) ; } catch ( ParseException e ) { System . err . println ( e . getMessage ( ) ) ; printUsage ( ) ; System . exit ( 1 ) ; } checkUsageOrExit ( cmdLine ) ; String languageCode = args [ 0 ] ; String plainTextFile = args [ 1 ] ; String infoFile = args [ 2 ] ; SpellDictionaryBuilder builder = new SpellDictionaryBuilder ( new File ( infoFile ) ) ; builder . setOutputFilename ( cmdLine . getOptionValue ( "o" ) ) ; String freqListFile = args [ 3 ] ; if ( ! freqListFile . equals ( "-" ) ) { builder . readFreqList ( new File ( freqListFile ) ) ; builder . build ( languageCode , builder . addFreqData ( new File ( plainTextFile ) ) ) ; } else { builder . build ( languageCode , new File ( plainTextFile ) ) ; } } private static void checkUsageOrExit ( CommandLine cmdLine ) throws IOException { String [ ] args = cmdLine . getArgs ( ) ; if ( args . length < 4 || ! cmdLine . hasOption ( "o" ) ) { printUsage ( ) ; } File dictFile = new File ( args [ 2 ] ) ; if ( ! dictFile . exists ( ) ) { throw new IOException ( "File does not exist: " + dictFile ) ; } } private static void printUsage ( ) { System . out . println ( "Usage: " + SpellDictionaryBuilder . class . getSimpleName ( ) + " <languageCode> <dictionary> <infoFile> <frequencyList> -o <outputFile>" ) ; System . out . println ( " <languageCode> like 'en-US' or 'de-DE'" ) ; System . out . println ( " <dictionary> is a plain text dictionary file, e.g. created from a Hunspell dictionary by 'unmunch'" ) ; System . out . println ( " <infoFile> is the *.info properties file, see http://wiki.languagetool.org/developing-a-tagger-dictionary" ) ; System . out . println ( " <frequencyList> is the *.xml file with a frequency wordlist or '-' for no frequency list, see http://wiki.languagetool.org/developing-a-tagger-dictionary" ) ; System . exit ( 1 ) ; } File build ( String languageCode , File plainTextDictFile ) throws Exception { Language language = Languages . getLanguageForShortName ( languageCode ) ; File tempFile = null ; try { tempFile = tokenizeInput ( plainTextDictFile , language ) ; return buildDict ( tempFile , language ) ; } finally { if ( tempFile != null ) { tempFile . delete ( ) ; } } } private File tokenizeInput ( File plainTextDictFile , Language language ) throws IOException { Tokenizer wordTokenizer = language . getWordTokenizer ( ) ; String encoding = getOption ( "fsa.dict.encoding" ) ; String separatorChar = hasOption ( "fsa.dict.separator" ) ? getOption ( "fsa.dict.separator" ) : "" ; File tempFile = File . createTempFile ( SpellDictionaryBuilder . class . getSimpleName ( ) , ".txt" ) ; try ( Scanner scanner = new Scanner ( plainTextDictFile , encoding ) ) { try ( Writer out = new BufferedWriter ( new OutputStreamWriter ( new FileOutputStream ( tempFile ) , encoding ) ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; int sepPos = separatorChar . isEmpty ( ) ? - 1 : line . indexOf ( separatorChar ) ; String occurrences = sepPos != - 1 ? line . substring ( sepPos + separatorChar . length ( ) ) : "" ; String lineWithoutOcc = sepPos != - 1 ? line . substring ( 0 , sepPos ) : line ; List < String > tokens = wordTokenizer . tokenize ( lineWithoutOcc ) ; for ( String token : tokens ) { if ( token . length ( ) > 0 ) { out . write ( token ) ; if ( sepPos != - 1 ) { out . write ( separatorChar ) ; if ( tokens . size ( ) == 1 ) { out . write ( occurrences ) ; } else { out . write ( "A" ) ; } } out . write ( "\n" ) ; } } } } } return tempFile ; } }
package org . languagetool . tagging . ro ; import java . io . IOException ; import org . languagetool . TestTools ; public class RomanianTaggerTest extends AbstractRomanianTaggerTest { public void testTaggerMerge ( ) throws Exception { assertHasLemmaAndPos ( "mergeam" , "merge" , "V0s1000ii0" ) ; assertHasLemmaAndPos ( "mergeam" , "merge" , "V0p1000ii0" ) ; } public void testTaggerMerseseram ( ) throws Exception { assertHasLemmaAndPos ( "merseserăm" , "merge" , null ) ; assertHasLemmaAndPos ( "merseserăm" , "merge" , "V0p1000im0" ) ; TestTools . myAssert ( "merseserăm" , "merseserăm/[merge]V0p1000im0" , getTokenizer ( ) , getTagger ( ) ) ; } public void testTagger_Fi ( ) throws Exception { assertHasLemmaAndPos ( "sunt" , "fi" , "V0s1000izf" ) ; assertHasLemmaAndPos ( "sunt" , "fi" , "V0p3000izf" ) ; } public void testTaggerUserDict ( ) throws Exception { assertHasLemmaAndPos ( "configurați" , "configura" , "V0p2000cz0" ) ; } public void testTagger ( ) throws IOException { TestTools . myAssert ( "Cartea este frumoasă." , "Cartea/[carte]Sfs3aac000 -- este/[fi]V0s3000izb -- frumoasă/[frumos]Afs3an0000" , getTokenizer ( ) , getTagger ( ) ) ; } }
package org . languagetool . dev ; import org . jetbrains . annotations . Nullable ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . spelling . SpellingCheckRule ; import org . languagetool . rules . spelling . SuggestionExtractor ; import java . io . * ; import java . util . * ; public class SuggestionExtractorTool { private void writeIgnoreTokensForLanguages ( ) throws IOException { final Map < Language , Set < String > > map = getLanguageToIgnoreTokensMapping ( ) ; for ( Map . Entry < Language , Set < String > > entry : map . entrySet ( ) ) { final Language language = entry . getKey ( ) ; final File langDir = getLanguageDir ( language ) ; final File hunspellDir = new File ( langDir , "hunspell" ) ; if ( ! hunspellDir . exists ( ) ) { System . out . println ( "No directory " + hunspellDir + " found, ignoring language " + language ) ; continue ; } final File ignoreFile ; if ( language . isVariant ( ) ) { ignoreFile = new File ( hunspellDir , "ignore-" + language . getCountries ( ) [ 0 ] + ".txt" ) ; } else { ignoreFile = new File ( hunspellDir , "ignore.txt" ) ; } final Set < String > tokens = entry . getValue ( ) ; try ( FileOutputStream fos = new FileOutputStream ( ignoreFile ) ) { try ( OutputStreamWriter writer = new OutputStreamWriter ( fos , "utf-8" ) ) { writeIntro ( writer , language ) ; for ( String token : tokens ) { writer . write ( token ) ; writer . write ( "\n" ) ; } } } System . out . println ( "Wrote " + tokens . size ( ) + " words to " + ignoreFile ) ; } } private Map < Language , Set < String > > getLanguageToIgnoreTokensMapping ( ) throws IOException { final Map < Language , Set < String > > langToIgnoreTokens = new HashMap < > ( ) ; SuggestionExtractor extractor = new SuggestionExtractor ( ) ; for ( Language lang : Languages . get ( ) ) { final Set < String > suggestionTokens = new HashSet < > ( ) ; final JLanguageTool languageTool = new JLanguageTool ( lang ) ; final Rule spellcheckRule = getSpellcheckRule ( languageTool ) ; if ( spellcheckRule == null ) { System . out . println ( "No spellchecker rule found for " + lang ) ; continue ; } final List < Rule > rules = languageTool . getAllRules ( ) ; int tokenCount = 0 ; int noErrorCount = 0 ; for ( Rule rule : rules ) { final List < String > tokens = extractor . getSuggestionTokens ( rule , lang ) ; tokenCount += tokens . size ( ) ; for ( String token : tokens ) { final AnalyzedSentence sentence = languageTool . getAnalyzedSentence ( token ) ; final RuleMatch [ ] matches = spellcheckRule . match ( sentence ) ; if ( matches . length > 0 ) { suggestionTokens . add ( token ) ; } else { noErrorCount ++ ; } } } System . out . println ( lang + ": " + noErrorCount + " out of " + tokenCount + " words ignored because they are known to spellchecker anyway" ) ; final Language noVariantLanguage = lang . getDefaultLanguageVariant ( ) == null ? lang : lang . getDefaultLanguageVariant ( ) ; final Set < String > existingTokens = langToIgnoreTokens . get ( noVariantLanguage ) ; if ( existingTokens != null ) { existingTokens . addAll ( suggestionTokens ) ; } else { langToIgnoreTokens . put ( noVariantLanguage , suggestionTokens ) ; } } return langToIgnoreTokens ; } private File getLanguageDir ( Language language ) { final String langCode = language . getShortName ( ) ; final File dir = new File ( "org/languagetool/resource" , langCode ) ; if ( dir . exists ( ) ) { return dir ; } else { return new File ( langCode + "/src/main/resources/org/languagetool/resource/" , langCode ) ; } } @ Nullable private Rule getSpellcheckRule ( JLanguageTool languageTool ) { final List < Rule > allActiveRules = languageTool . getAllActiveRules ( ) ; for ( Rule activeRule : allActiveRules ) { if ( activeRule instanceof SpellingCheckRule ) { ( ( SpellingCheckRule ) activeRule ) . setConsiderIgnoreWords ( false ) ; return activeRule ; } } return null ; } private void writeIntro ( Writer writer , Language language ) throws IOException { writer . write ( "# words to be ignored by the spellchecker (auto-generated)\n" ) ; writeArtificialTestCaseItems ( writer , language ) ; } private void writeArtificialTestCaseItems ( Writer writer , Language language ) throws IOException { if ( language . getShortName ( ) . equals ( "en-US" ) ) { writer . write ( "anArtificialTestWordForLanguageTool\n" ) ; } else if ( language . getShortName ( ) . equals ( "de-DE" ) ) { writer . write ( "einPseudoWortFürLanguageToolTests\n" ) ; } } public static void main ( String [ ] args ) throws IOException { if ( Languages . get ( ) . size ( ) < 5 ) { throw new RuntimeException ( "Found only " + Languages . get ( ) . size ( ) + " languages in classpath. " + "Please run this class with the classpath of 'languagetool-standalone' to have access to all languages." ) ; } final List < String > dirs = Arrays . asList ( new File ( "." ) . list ( ) ) ; if ( ! dirs . contains ( "en" ) || ! dirs . contains ( "de" ) ) { throw new RuntimeException ( "Please set the working directory to 'languagetool-language-modules' when running this class" ) ; } final SuggestionExtractorTool extractor = new SuggestionExtractorTool ( ) ; extractor . writeIgnoreTokensForLanguages ( ) ; } }
package org . languagetool . dev ; import morfologik . tools . FSADumpTool ; import java . io . File ; final class DictionaryExporter { public static void main ( String [ ] args ) throws Exception { if ( args . length != 1 ) { System . out . println ( "Usage: " + DictionaryExporter . class . getSimpleName ( ) + " <dictionary>" ) ; System . out . println ( " <dictionary> is a binary dictionary file, typically ending with .dict" ) ; System . exit ( 1 ) ; } String filename = args [ 0 ] ; String path = new File ( filename ) . getAbsolutePath ( ) ; if ( path . contains ( "hunspell" ) || path . contains ( "spelling" ) ) { FSADumpTool . main ( "--raw-data" , "-d" , args [ 0 ] ) ; } else { FSADumpTool . main ( "--raw-data" , "-x" , "-d" , args [ 0 ] ) ; } } }
package org . languagetool . dev ; import org . jetbrains . annotations . Nullable ; import java . io . * ; import java . util . * ; import java . util . regex . Pattern ; final class SynthDictionaryBuilder extends DictionaryBuilder { private static final String POLISH_IGNORE_REGEX = ":neg|qub|depr" ; SynthDictionaryBuilder ( File infoFile ) throws IOException { super ( infoFile ) ; } public static void main ( String [ ] args ) throws Exception { checkUsageOrExit ( SynthDictionaryBuilder . class . getSimpleName ( ) , args ) ; File infoFile = new File ( args [ 1 ] ) ; SynthDictionaryBuilder builder = new SynthDictionaryBuilder ( infoFile ) ; builder . build ( new File ( args [ 0 ] ) , infoFile ) ; } File build ( File plainTextDictFile , File infoFile ) throws Exception { File tempFile = File . createTempFile ( SynthDictionaryBuilder . class . getSimpleName ( ) , ".txt" ) ; File reversedFile = null ; try { Set < String > itemsToBeIgnored = getIgnoreItems ( new File ( infoFile . getParent ( ) , "filter-archaic.txt" ) ) ; Pattern ignorePosRegex = getPosTagIgnoreRegex ( infoFile ) ; reversedFile = reverseLineContent ( plainTextDictFile , itemsToBeIgnored , ignorePosRegex ) ; List < String > tab2morphOptions = getTab2MorphOptions ( reversedFile , tempFile ) ; tab2morphOptions . add ( 0 , "tab2morph" ) ; tab2morphOptions . add ( 1 , "-nw" ) ; prepare ( tab2morphOptions ) ; writePosTagsToFile ( plainTextDictFile , getTagFile ( tempFile ) ) ; return buildDict ( tempFile ) ; } finally { tempFile . delete ( ) ; if ( reversedFile != null ) { reversedFile . delete ( ) ; } } } private Set < String > getIgnoreItems ( File file ) throws FileNotFoundException { Set < String > result = new HashSet < > ( ) ; if ( file . exists ( ) ) { try ( Scanner scanner = new Scanner ( file , getOption ( "fsa.dict.encoding" ) ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; if ( ! line . startsWith ( "#" ) ) { result . add ( line ) ; } } } System . out . println ( "Loaded " + result . size ( ) + " words to be ignored from " + file ) ; } else { System . out . println ( "File " + file . getAbsolutePath ( ) + " does not exist, no items will be ignored" ) ; } return result ; } @ Nullable private Pattern getPosTagIgnoreRegex ( File infoFile ) { String fileName = infoFile . getName ( ) ; int underscorePos = fileName . indexOf ( '_' ) ; if ( underscorePos == - 1 ) { throw new IllegalArgumentException ( "Please specify an .info file for a synthesizer as the second parameter, named '<xyz>_synth.info', with <xyz> being a language'" ) ; } String baseName = fileName . substring ( 0 , underscorePos ) ; if ( baseName . equals ( "polish" ) ) { return Pattern . compile ( POLISH_IGNORE_REGEX ) ; } return null ; } private File reverseLineContent ( File plainTextDictFile , Set < String > itemsToBeIgnored , Pattern ignorePosRegex ) throws IOException { File reversedFile = File . createTempFile ( SynthDictionaryBuilder . class . getSimpleName ( ) + "_reversed" , ".txt" ) ; String encoding = getOption ( "fsa.dict.encoding" ) ; int posIgnoreCount = 0 ; Scanner scanner = new Scanner ( plainTextDictFile , encoding ) ; try ( Writer out = new BufferedWriter ( new OutputStreamWriter ( new FileOutputStream ( reversedFile ) , encoding ) ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; if ( itemsToBeIgnored . contains ( line ) ) { System . out . println ( "Ignoring: " + line ) ; continue ; } String [ ] parts = line . split ( "\t" ) ; if ( parts . length == 3 ) { String posTag = parts [ 2 ] ; if ( ignorePosRegex != null && ignorePosRegex . matcher ( posTag ) . find ( ) ) { posIgnoreCount ++ ; continue ; } out . write ( parts [ 1 ] + "|" + posTag + "\t" + parts [ 0 ] ) ; out . write ( "\n" ) ; } else { System . err . println ( "Invalid input, expected three tab-separated columns in " + plainTextDictFile + ": " + line + " => ignoring" ) ; } } scanner . close ( ) ; } System . out . println ( "Number of lines ignored due to POS tag filter ('" + ignorePosRegex + "'): " + posIgnoreCount ) ; return reversedFile ; } private File getTagFile ( File tempFile ) { String name = tempFile . getAbsolutePath ( ) + "_tags.txt" ; return new File ( name ) ; } private void writePosTagsToFile ( File plainTextDictFile , File tagFile ) throws IOException { Set < String > posTags = collectTags ( plainTextDictFile ) ; List < String > sortedTags = new ArrayList < > ( posTags ) ; Collections . sort ( sortedTags ) ; System . out . println ( "Writing tag file to " + tagFile ) ; try ( FileWriter out = new FileWriter ( tagFile ) ) { for ( String tag : sortedTags ) { out . write ( tag ) ; out . write ( "\n" ) ; } } } private Set < String > collectTags ( File plainTextDictFile ) throws IOException { Set < String > posTags = new HashSet < > ( ) ; try ( Scanner scanner = new Scanner ( plainTextDictFile , getOption ( "fsa.dict.encoding" ) ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; String [ ] parts = line . split ( "\t" ) ; if ( parts . length == 3 ) { String posTag = parts [ 2 ] ; posTags . add ( posTag ) ; } else { System . err . println ( "Invalid input, expected three tab-separated columns in " + plainTextDictFile + ": " + line + " => ignoring" ) ; } } } return posTags ; } }
package org . languagetool . dev ; import org . apache . commons . lang . StringUtils ; import org . languagetool . JLanguageTool ; import org . languagetool . language . English ; import org . languagetool . rules . ConfusionSet ; import org . languagetool . rules . ConfusionSetLoader ; import org . languagetool . rules . ConfusionString ; import org . languagetool . tokenizers . WordTokenizer ; import org . languagetool . tools . StringTools ; import java . io . * ; import java . util . * ; public class RuleCreator { private static final boolean XML_MODE = true ; private final Map < String , List < OccurrenceInfo > > occurrenceInfos = new HashMap < > ( ) ; private final Map < String , Long > ngramToOccurrence = new HashMap < > ( ) ; private final WordTokenizer wordTokenizer = new English ( ) . getWordTokenizer ( ) ; private final float minErrorProb ; private int ruleCount = 0 ; private int tokenFilteredRules = 0 ; private int probFilteredRules = 0 ; public RuleCreator ( float minErrorProb ) { this . minErrorProb = minErrorProb ; } private void run ( File homophoneOccurrences , String homophonePath ) throws IOException { ConfusionSetLoader confusionSetLoader = new ConfusionSetLoader ( ) ; InputStream inputStream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( homophonePath ) ; Map < String , List < ConfusionSet > > confusionSetMap = confusionSetLoader . loadConfusionSet ( inputStream ) ; initMaps ( homophoneOccurrences ) ; int groupCount = 0 ; if ( XML_MODE ) { System . out . println ( "<rules lang='en'>\n" ) ; System . out . println ( "<category name='Auto-generated rules'>\n" ) ; } for ( Map . Entry < String , List < ConfusionSet > > entry : confusionSetMap . entrySet ( ) ) { System . err . println ( " === " + entry + " === " ) ; if ( entry . getValue ( ) . size ( ) > 1 ) { System . err . println ( "WARN: will use only first pair of " + entry . getValue ( ) . size ( ) + ": " + entry . getValue ( ) . get ( 0 ) ) ; } List < OccurrenceInfo > infos = occurrenceInfos . get ( entry . getKey ( ) ) ; if ( infos == null ) { System . err . println ( "Could not find occurrence infos for '" + entry . getKey ( ) + "', skipping" ) ; continue ; } Set cleanSet = new HashSet < > ( entry . getValue ( ) . get ( 0 ) . getSet ( ) ) ; cleanSet . remove ( entry . getKey ( ) ) ; String name = StringUtils . join ( cleanSet , "/" ) + " -> " + entry . getKey ( ) ; if ( XML_MODE ) { System . out . println ( "<rulegroup id='R" + groupCount + "' name=\"" + StringTools . escapeXML ( name ) + "\">\n" ) ; } groupCount ++ ; for ( OccurrenceInfo occurrenceInfo : infos ) { String [ ] parts = occurrenceInfo . ngram . split ( " " ) ; for ( ConfusionString variant : entry . getValue ( ) . get ( 0 ) . getSet ( ) ) { if ( variant . getString ( ) . equals ( entry . getKey ( ) ) ) { continue ; } printRule ( occurrenceInfo , parts , variant . getString ( ) ) ; } } if ( XML_MODE ) { System . out . println ( "</rulegroup>\n" ) ; } } if ( XML_MODE ) { System . out . println ( "</category>" ) ; System . out . println ( "</rules>" ) ; } System . err . println ( "Done. Wrote " + ruleCount + " rules." ) ; System . err . println ( "Rules ignored because of different tokenization: " + tokenFilteredRules ) ; System . err . println ( "Rules ignored because of error probability limit (" + minErrorProb + "): " + probFilteredRules ) ; } private void printRule ( OccurrenceInfo occurrenceInfo , String [ ] parts , String variant ) { String term = parts [ 1 ] ; String termPhrase = parts [ 0 ] + " " + parts [ 1 ] + " " + parts [ 2 ] ; String variantPhrase = parts [ 0 ] + " " + variant + " " + parts [ 2 ] ; List < String > tokens = wordTokenizer . tokenize ( variantPhrase ) ; if ( tokens . size ( ) != 3 + 2 ) { System . err . println ( "Skipping '" + variantPhrase + "', does not tokenize to 3 tokens: " + tokens ) ; tokenFilteredRules ++ ; return ; } Long variantOccObj = ngramToOccurrence . get ( variantPhrase ) ; long variantOcc = variantOccObj != null ? variantOccObj : 0 ; long totalOcc = occurrenceInfo . occurrence + variantOcc ; float variantProb = ( float ) variantOcc / totalOcc ; float variantErrorProb = 1.0f - variantProb ; if ( variantErrorProb < minErrorProb ) { System . err . println ( "Skipping '" + variantPhrase + "', error probability too low: " + variantErrorProb + " < " + minErrorProb ) ; probFilteredRules ++ ; return ; } if ( XML_MODE ) { System . out . printf ( Locale . ENGLISH , " <rule case_sensitive='yes'>\n" + " <!-- auto-generated, error probability: %.3f, correct phrase occurrences: %d -->\n" + " <pattern>\n" + " <token>%s</token>\n" + " <marker><token>%s</token></marker>\n" + " <token>%s</token>\n" + " </pattern>\n" + " <message>Did you mean <suggestion>%s</suggestion>?</message>\n" + " <example type='incorrect'>%s</example>\n" + " <example type='correct'>%s</example>\n" + " </rule>\n\n" , variantErrorProb , occurrenceInfo . occurrence , StringTools . escapeXML ( parts [ 0 ] ) , StringTools . escapeXML ( variant ) , StringTools . escapeXML ( parts [ 2 ] ) , StringTools . escapeXML ( term ) , StringTools . escapeXML ( variantPhrase ) , StringTools . escapeXML ( termPhrase ) ) ; } else { System . out . printf ( Locale . ENGLISH , "%.2f\t%s\t%s\n" , variantErrorProb , variantPhrase , term ) ; } ruleCount ++ ; } private void initMaps ( File homophoneOccurrenceFile ) throws FileNotFoundException { try ( Scanner s = new Scanner ( homophoneOccurrenceFile ) ) { while ( s . hasNextLine ( ) ) { String line = s . nextLine ( ) ; String [ ] parts = line . split ( "\t" ) ; if ( parts . length != 3 ) { throw new RuntimeException ( "Unexpected format: '" + line + "'" ) ; } long occurrenceCount = Integer . parseInt ( parts [ 1 ] ) ; OccurrenceInfo occurrenceInfo = new OccurrenceInfo ( parts [ 2 ] , occurrenceCount ) ; List < OccurrenceInfo > list ; if ( occurrenceInfos . containsKey ( parts [ 0 ] ) ) { list = occurrenceInfos . get ( parts [ 0 ] ) ; } else { list = new ArrayList < > ( ) ; } list . add ( occurrenceInfo ) ; occurrenceInfos . put ( parts [ 0 ] , list ) ; ngramToOccurrence . put ( parts [ 2 ] , occurrenceCount ) ; } } } static class OccurrenceInfo { private final String ngram ; private final long occurrence ; OccurrenceInfo ( String ngram , long occurrence ) { this . ngram = ngram ; this . occurrence = occurrence ; } @ Override public String toString ( ) { return ngram + "/" + occurrence ; } } public static void main ( String [ ] args ) throws IOException { if ( args . length < 1 || args . length > 2 ) { System . out . println ( "Usage: " + RuleCreator . class . getSimpleName ( ) + " <homophoneResultFile> [minErrorProbability]" ) ; System . out . println ( " homophoneResultFile the output of org.languagetool.dev.HomophoneOccurrenceDumper" ) ; System . out . println ( " minErrorProbability the minimal error probability (0.0-1.0), other rules will be ignored" ) ; System . exit ( 1 ) ; } float minErrorProb = args . length >= 2 ? Float . parseFloat ( args [ 1 ] ) : 0.0f ; RuleCreator creator = new RuleCreator ( minErrorProb ) ; creator . run ( new File ( args [ 0 ] ) , "/en/confusion_sets_subset.txt" ) ; } }
package org . languagetool . dev ; import morfologik . tools . FSABuildTool ; import morfologik . tools . Launcher ; import org . jetbrains . annotations . Nullable ; import org . languagetool . Language ; import java . io . BufferedReader ; import java . io . BufferedWriter ; import java . io . File ; import java . io . FileInputStream ; import java . io . FileOutputStream ; import java . io . IOException ; import java . io . InputStreamReader ; import java . io . OutputStreamWriter ; import java . util . * ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; class DictionaryBuilder { private final Properties props = new Properties ( ) ; private static final int FREQ_RANGES_IN = 256 ; private static final int FREQ_RANGES_OUT = 26 ; private static final int FIRST_RANGE_CODE = 65 ; private final Map < String , Integer > freqList = new HashMap < > ( ) ; private final Pattern pFreqEntry = Pattern . compile ( ".*<w f=\"(\\d+)\" flags=\"(.*)\">(.+)</w>.*" ) ; private final Pattern pTaggerEntry = Pattern . compile ( "^([^\t]+).*$" ) ; private String outputFilename ; protected DictionaryBuilder ( File infoFile ) throws IOException { props . load ( new FileInputStream ( infoFile ) ) ; } protected void setOutputFilename ( String outputFilename ) { this . outputFilename = outputFilename ; } protected static void checkUsageOrExit ( String className , String [ ] args ) throws IOException { if ( args . length < 2 || args . length > 3 ) { System . out . println ( "Usage: " + className + " <dictionary> <infoFile> [frequencyList]" ) ; System . out . println ( " <dictionary> is a plain text dictionary file" ) ; System . out . println ( " <infoFile> is the *.info properties file, see http://wiki.languagetool.org/developing-a-tagger-dictionary" ) ; System . out . println ( " [frequencyList] is the *.xml file with a frequency wordlist, see http://wiki.languagetool.org/developing-a-tagger-dictionary" ) ; System . exit ( 1 ) ; } File dictFile = new File ( args [ 0 ] ) ; if ( ! dictFile . exists ( ) ) { throw new IOException ( "File does not exist: " + dictFile ) ; } } protected List < String > getTab2MorphOptions ( File dictFile , File outputFile ) throws IOException { List < String > tab2morphOptions = new ArrayList < > ( ) ; String separator = getOption ( "fsa.dict.separator" ) ; if ( separator != null && ! separator . trim ( ) . isEmpty ( ) ) { tab2morphOptions . add ( "--annotation" ) ; tab2morphOptions . add ( separator ) ; } if ( ( isOptionTrue ( "fsa.dict.uses-prefixes" ) || isOptionTrue ( "fsa.dict.uses-infixes" ) ) && hasOption ( "fsa.dict.encoder" ) ) { throw new IOException ( ".info file must specify either fsa.dict.encoder (preferred) or fsa.dict.uses-* properties." ) ; } if ( hasOption ( "fsa.dict.encoder" ) ) { tab2morphOptions . add ( "--encoder" ) ; tab2morphOptions . add ( getOption ( "fsa.dict.encoder" ) ) ; } else { if ( isOptionTrue ( "fsa.dict.uses-prefixes" ) ) { tab2morphOptions . add ( "--encoder" ) ; tab2morphOptions . add ( "prefix" ) ; } else if ( isOptionTrue ( "fsa.dict.uses-infixes" ) ) { tab2morphOptions . add ( "--encoder" ) ; tab2morphOptions . add ( "infix" ) ; } } tab2morphOptions . add ( "-i" ) ; tab2morphOptions . add ( dictFile . getAbsolutePath ( ) ) ; tab2morphOptions . add ( "-o" ) ; tab2morphOptions . add ( outputFile . getAbsolutePath ( ) ) ; return tab2morphOptions ; } protected void prepare ( List < String > tab2morphOptions ) throws Exception { System . out . println ( "Running Morfologik Launcher.main with these options: " + tab2morphOptions ) ; Launcher . main ( tab2morphOptions . toArray ( new String [ tab2morphOptions . size ( ) ] ) ) ; } protected File buildDict ( File tempFile ) throws Exception { return buildDict ( tempFile , null ) ; } protected File buildDict ( File tempFile , Language language ) throws Exception { String suffix = language != null ? "-" + language . getShortNameWithCountryAndVariant ( ) + ".dict" : ".dict" ; File resultFile = outputFilename != null ? new File ( outputFilename ) : File . createTempFile ( DictionaryBuilder . class . getSimpleName ( ) , suffix ) ; String [ ] buildToolOptions = { "-f" , "cfsa2" , "-i" , tempFile . getAbsolutePath ( ) , "-o" , resultFile . getAbsolutePath ( ) } ; System . out . println ( "Running Morfologik FSABuildTool.main with these options: " + Arrays . toString ( buildToolOptions ) ) ; FSABuildTool . main ( buildToolOptions ) ; System . out . println ( "Done. The binary dictionary has been written to " + resultFile . getAbsolutePath ( ) ) ; return resultFile ; } @ Nullable protected String getOption ( String option ) { String property = props . getProperty ( option ) ; if ( property == null ) { return null ; } return property . trim ( ) ; } protected boolean hasOption ( String option ) { return props . getProperty ( option ) != null ; } private boolean isOptionTrue ( String option ) { return hasOption ( option ) && "true" . equals ( getOption ( option ) ) ; } protected void readFreqList ( File freqListFile ) { try ( FileInputStream fis = new FileInputStream ( freqListFile . getAbsoluteFile ( ) ) ; InputStreamReader reader = new InputStreamReader ( fis , "utf-8" ) ; BufferedReader br = new BufferedReader ( reader ) ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { Matcher m = pFreqEntry . matcher ( line ) ; if ( m . matches ( ) ) { freqList . put ( m . group ( 3 ) , Integer . parseInt ( m . group ( 1 ) ) ) ; } } } catch ( IOException e ) { throw new RuntimeException ( "Cannot read file: " + freqListFile . getAbsolutePath ( ) ) ; } } protected File addFreqData ( File dictFile ) throws IOException { if ( ! isOptionTrue ( "fsa.dict.frequency-included" ) ) { throw new IOException ( "In order to use frequency data add the line 'fsa.dict.frequency-included=true' to the dictionary info file." ) ; } String separator = getOption ( "fsa.dict.separator" ) ; if ( separator == null || separator . trim ( ) . isEmpty ( ) ) { throw new IOException ( "A separator character (fsa.dict.separator) must be defined in the dictionary info file." ) ; } File tempFile = File . createTempFile ( DictionaryBuilder . class . getSimpleName ( ) , "WithFrequencies.txt" ) ; BufferedWriter bw = new BufferedWriter ( new OutputStreamWriter ( new FileOutputStream ( tempFile . getAbsoluteFile ( ) ) , getOption ( "fsa.dict.encoding" ) ) ) ; int freqValuesApplied = 0 ; try { BufferedReader br = new BufferedReader ( new InputStreamReader ( new FileInputStream ( dictFile . getAbsoluteFile ( ) ) , getOption ( "fsa.dict.encoding" ) ) ) ; String line ; int maxFreq = Collections . max ( freqList . values ( ) ) ; double maxFreqLog = Math . log ( maxFreq ) ; while ( ( line = br . readLine ( ) ) != null ) { Matcher m = pTaggerEntry . matcher ( line ) ; if ( m . matches ( ) ) { int freq = 0 ; String key = m . group ( 1 ) ; if ( freqList . containsKey ( key ) ) { freq = freqList . get ( key ) ; freqValuesApplied ++ ; } int normalizedFreq = freq ; if ( freq > 0 && maxFreq > 255 ) { double freqZeroToOne = Math . log ( freq ) / maxFreqLog ; normalizedFreq = ( int ) ( freqZeroToOne * ( FREQ_RANGES_IN - 1 ) ) ; } if ( normalizedFreq < 0 || normalizedFreq > 255 ) { throw new RuntimeException ( "Frequency out of range (0-255): " + normalizedFreq + " in word " + key ) ; } String freqChar = Character . toString ( ( char ) ( FIRST_RANGE_CODE + normalizedFreq * FREQ_RANGES_OUT / FREQ_RANGES_IN ) ) ; bw . write ( line + separator + freqChar + "\n" ) ; } } br . close ( ) ; bw . close ( ) ; System . out . println ( freqList . size ( ) + " frequency values applied in " + freqValuesApplied + " word forms." ) ; } catch ( IOException e ) { throw new RuntimeException ( "Cannot read file: " + dictFile . getAbsolutePath ( ) ) ; } tempFile . deleteOnExit ( ) ; return tempFile ; } }
package org . languagetool . dev ; import java . io . File ; import java . io . IOException ; import java . util . List ; public final class POSDictionaryBuilder extends DictionaryBuilder { public POSDictionaryBuilder ( File infoFile ) throws IOException { super ( infoFile ) ; } public static void main ( String [ ] args ) throws Exception { checkUsageOrExit ( POSDictionaryBuilder . class . getSimpleName ( ) , args ) ; POSDictionaryBuilder builder = new POSDictionaryBuilder ( new File ( args [ 1 ] ) ) ; if ( args . length == 3 ) { builder . readFreqList ( new File ( args [ 2 ] ) ) ; builder . build ( builder . addFreqData ( new File ( args [ 0 ] ) ) ) ; } else { builder . build ( new File ( args [ 0 ] ) ) ; } } public File build ( File dictFile ) throws Exception { File tempFile = File . createTempFile ( POSDictionaryBuilder . class . getSimpleName ( ) , ".txt" ) ; try { List < String > tab2morphOptions = getTab2MorphOptions ( dictFile , tempFile ) ; tab2morphOptions . add ( 0 , "tab2morph" ) ; prepare ( tab2morphOptions ) ; return buildDict ( tempFile ) ; } finally { tempFile . delete ( ) ; } } }
package org . languagetool . gui ; import java . awt . Component ; import java . util . ResourceBundle ; import javax . swing . ImageIcon ; import javax . swing . JLabel ; import javax . swing . JList ; import javax . swing . ListCellRenderer ; import javax . swing . border . Border ; import javax . swing . border . EmptyBorder ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . databroker . ResourceDataBroker ; class LanguageComboBoxRenderer extends JLabel implements ListCellRenderer < Language > { private static final Border BORDER = new EmptyBorder ( 1 , 3 , 1 , 1 ) ; private final ResourceBundle messages ; private final String extLangSuffix ; LanguageComboBoxRenderer ( ResourceBundle messages , String extLangSuffix ) { super ( ) ; setOpaque ( true ) ; setBorder ( BORDER ) ; this . messages = messages ; this . extLangSuffix = extLangSuffix ; } private String getTranslatedName ( Language language ) { if ( language . isExternal ( ) ) { return language . getName ( ) + extLangSuffix ; } else { return language . getTranslatedName ( messages ) ; } } @ Override public Component getListCellRendererComponent ( JList list , Language lang , int index , boolean isSelected , boolean cellHasFocus ) { setComponentOrientation ( list . getComponentOrientation ( ) ) ; if ( isSelected ) { setBackground ( list . getSelectionBackground ( ) ) ; setForeground ( list . getSelectionForeground ( ) ) ; } else { setBackground ( list . getBackground ( ) ) ; setForeground ( list . getForeground ( ) ) ; } setText ( getTranslatedName ( lang ) ) ; String langTag = lang . getLocaleWithCountryAndVariant ( ) . toLanguageTag ( ) ; String country = lang . getLocaleWithCountryAndVariant ( ) . getCountry ( ) . toLowerCase ( ) ; ResourceDataBroker dataBroker = JLanguageTool . getDataBroker ( ) ; String filename = "flags/bytag/" + langTag + ".png" ; if ( ! dataBroker . resourceExists ( filename ) ) { filename = "flags/" + country + ".png" ; } if ( ! dataBroker . resourceExists ( filename ) ) { filename = "flags/empty.png" ; } ImageIcon icon = new ImageIcon ( dataBroker . getFromResourceDirAsUrl ( filename ) ) ; setIcon ( icon ) ; setEnabled ( list . isEnabled ( ) ) ; setFont ( list . getFont ( ) ) ; setBorder ( BORDER ) ; return this ; } }
package org . languagetool . gui ; import java . awt . Container ; import java . awt . Frame ; import java . awt . GridBagConstraints ; import java . awt . GridBagLayout ; import java . awt . Insets ; import java . awt . event . ActionEvent ; import java . awt . event . ActionListener ; import java . awt . event . KeyEvent ; import java . io . File ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import javax . swing . JButton ; import javax . swing . JComponent ; import javax . swing . JDialog ; import javax . swing . JList ; import javax . swing . JOptionPane ; import javax . swing . JPanel ; import javax . swing . JRootPane ; import javax . swing . JScrollPane ; import javax . swing . KeyStroke ; import javax . swing . filechooser . FileFilter ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . language . LanguageBuilder ; public class LanguageManagerDialog implements ActionListener { private final List < File > ruleFiles = new ArrayList < > ( ) ; private final Frame owner ; private final ResourceBundle messages ; private JDialog dialog ; private JList < File > list ; private JButton addButton ; private JButton removeButton ; private JButton closeButton ; public LanguageManagerDialog ( Frame owner , List < Language > languages ) { this . owner = owner ; for ( Language lang : languages ) { for ( final String ruleFile : lang . getRuleFileNames ( ) ) { ruleFiles . add ( new File ( ruleFile ) ) ; } } messages = JLanguageTool . getMessageBundle ( ) ; } public void show ( ) { dialog = new JDialog ( owner , true ) ; dialog . setTitle ( messages . getString ( "guiLanguageManagerDialog" ) ) ; final KeyStroke stroke = KeyStroke . getKeyStroke ( KeyEvent . VK_ESCAPE , 0 ) ; final ActionListener actionListener = new ActionListener ( ) { @ Override @ SuppressWarnings ( "unused" ) public void actionPerformed ( ActionEvent actionEvent ) { dialog . setVisible ( false ) ; } } ; final JRootPane rootPane = dialog . getRootPane ( ) ; rootPane . registerKeyboardAction ( actionListener , stroke , JComponent . WHEN_IN_FOCUSED_WINDOW ) ; final Container contentPane = dialog . getContentPane ( ) ; contentPane . setLayout ( new GridBagLayout ( ) ) ; list = new JList < > ( ruleFiles . toArray ( new File [ ruleFiles . size ( ) ] ) ) ; GridBagConstraints cons = new GridBagConstraints ( ) ; cons . insets = new Insets ( 4 , 4 , 4 , 4 ) ; cons . gridx = 0 ; cons . gridy = 0 ; cons . fill = GridBagConstraints . BOTH ; cons . weightx = 2.0f ; cons . weighty = 2.0f ; contentPane . add ( new JScrollPane ( list ) , cons ) ; cons = new GridBagConstraints ( ) ; cons . insets = new Insets ( 4 , 4 , 4 , 4 ) ; cons . fill = GridBagConstraints . HORIZONTAL ; final JPanel buttonPanel = new JPanel ( ) ; buttonPanel . setLayout ( new GridBagLayout ( ) ) ; addButton = new JButton ( messages . getString ( "guiAddButton" ) ) ; addButton . addActionListener ( this ) ; cons . gridx = 1 ; cons . gridy = 0 ; buttonPanel . add ( addButton , cons ) ; removeButton = new JButton ( messages . getString ( "guiRemoveButton" ) ) ; removeButton . addActionListener ( this ) ; cons . gridx = 1 ; cons . gridy = 1 ; buttonPanel . add ( removeButton , cons ) ; closeButton = new JButton ( messages . getString ( "guiCloseButton" ) ) ; closeButton . addActionListener ( this ) ; cons . gridx = 1 ; cons . gridy = 2 ; buttonPanel . add ( closeButton , cons ) ; cons . gridx = 1 ; cons . gridy = 0 ; cons = new GridBagConstraints ( ) ; cons . anchor = GridBagConstraints . NORTH ; contentPane . add ( buttonPanel , cons ) ; dialog . pack ( ) ; dialog . setSize ( 300 , 200 ) ; dialog . setLocationByPlatform ( true ) ; dialog . setVisible ( true ) ; } @ Override public void actionPerformed ( ActionEvent e ) { if ( e . getSource ( ) == addButton ) { Configuration config = null ; try { config = new Configuration ( null ) ; } catch ( IOException e1 ) { throw new RuntimeException ( e1 ) ; } File initialDir ; File ruleFile ; if ( config . getExternalRuleDirectory ( ) != null ) { initialDir = new File ( config . getExternalRuleDirectory ( ) ) ; if ( initialDir . isDirectory ( ) ) { ruleFile = Tools . openFileDialog ( owner , new XMLFileFilter ( ) , initialDir ) ; } else { ruleFile = Tools . openFileDialog ( owner , new XMLFileFilter ( ) ) ; } } else { ruleFile = Tools . openFileDialog ( owner , new XMLFileFilter ( ) ) ; } if ( ruleFile == null ) { return ; } if ( config != null ) { config . setExternalRuleDirectory ( ruleFile . getParent ( ) ) ; try { config . saveConfiguration ( null ) ; } catch ( IOException e1 ) { throw new RuntimeException ( e1 ) ; } } if ( ! ruleFiles . contains ( ruleFile ) ) { ruleFiles . add ( ruleFile ) ; list . setListData ( ruleFiles . toArray ( new File [ ruleFiles . size ( ) ] ) ) ; } else { final JOptionPane jop = new JOptionPane ( ) ; JOptionPane . showMessageDialog ( jop , messages . getString ( "guiDuplicate" ) , messages . getString ( "guiWarning" ) , JOptionPane . WARNING_MESSAGE ) ; } } else if ( e . getSource ( ) == removeButton ) { if ( list . getSelectedIndex ( ) != - 1 ) { ruleFiles . remove ( list . getSelectedIndex ( ) ) ; list . setListData ( ruleFiles . toArray ( new File [ ruleFiles . size ( ) ] ) ) ; } } else if ( e . getSource ( ) == closeButton ) { dialog . setVisible ( false ) ; } else { throw new IllegalArgumentException ( "Don't know how to handle " + e ) ; } } List < Language > getLanguages ( ) throws IllegalAccessException , InstantiationException { final List < Language > languages = new ArrayList < > ( ) ; for ( File ruleFile : ruleFiles ) { if ( ruleFile != null ) { final Language newLanguage = LanguageBuilder . makeAdditionalLanguage ( ruleFile ) ; languages . add ( newLanguage ) ; } } return languages ; } static class XMLFileFilter extends FileFilter { @ Override public boolean accept ( final File f ) { if ( f . getName ( ) . startsWith ( "rules" ) && f . getName ( ) . toLowerCase ( ) . endsWith ( ".xml" ) || f . isDirectory ( ) ) { return true ; } return false ; } @ Override public String getDescription ( ) { return "rules*.xml" ; } } }
package org . languagetool . gui ; import java . awt . ComponentOrientation ; import java . awt . Font ; import java . awt . Frame ; import java . awt . GraphicsEnvironment ; import java . awt . GridBagConstraints ; import java . awt . GridBagLayout ; import java . awt . Insets ; import java . awt . event . ActionEvent ; import java . awt . event . ActionListener ; import java . awt . event . KeyEvent ; import java . awt . event . WindowAdapter ; import java . awt . event . WindowEvent ; import java . util . Locale ; import java . util . ResourceBundle ; import javax . swing . AbstractAction ; import javax . swing . BorderFactory ; import javax . swing . JButton ; import javax . swing . JComponent ; import javax . swing . JDialog ; import javax . swing . JLabel ; import javax . swing . JList ; import javax . swing . JPanel ; import javax . swing . JScrollPane ; import javax . swing . JTextArea ; import javax . swing . JTextField ; import javax . swing . KeyStroke ; import javax . swing . ListSelectionModel ; import javax . swing . border . TitledBorder ; import javax . swing . event . DocumentEvent ; import javax . swing . event . DocumentListener ; import javax . swing . event . ListSelectionEvent ; import javax . swing . event . ListSelectionListener ; import org . languagetool . JLanguageTool ; class FontChooser extends JDialog implements ActionListener , DocumentListener , ListSelectionListener { private static final Integer [ ] fontSizesArray = { 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 18 , 20 , 22 , 24 , 26 , 28 , 32 } ; private String [ ] fontStylesArray ; private final ResourceBundle messages ; private JTextField fontNameTextField ; private JTextField fontStyleTextField ; private JTextField fontSizeTextField ; private JList < String > fontNameList ; private JList < String > fontStyleList ; private JList < Integer > fontSizeList ; private JTextArea previewArea ; private Font selectedFont ; private Font defaultFont ; FontChooser ( Frame owner , boolean modal ) { super ( owner , modal ) ; messages = JLanguageTool . getMessageBundle ( ) ; initComponents ( ) ; } Font getSelectedFont ( ) { return selectedFont ; } void setSelectedFont ( Font font ) { this . selectedFont = font ; fontNameList . setSelectedValue ( font . getFamily ( ) , true ) ; fontStyleList . setSelectedValue ( getStyle ( font ) , true ) ; fontSizeList . setSelectedValue ( font . getSize ( ) , true ) ; } private void initComponents ( ) { final KeyStroke stroke = KeyStroke . getKeyStroke ( KeyEvent . VK_ESCAPE , 0 ) ; getRootPane ( ) . getInputMap ( JComponent . WHEN_IN_FOCUSED_WINDOW ) . put ( stroke , "Hide" ) ; getRootPane ( ) . getActionMap ( ) . put ( "Hide" , new AbstractAction ( ) { @ Override public void actionPerformed ( ActionEvent e ) { selectedFont = null ; setVisible ( false ) ; } } ) ; this . addWindowListener ( new WindowAdapter ( ) { @ Override public void windowClosing ( WindowEvent e ) { selectedFont = null ; setVisible ( false ) ; } } ) ; setTitle ( messages . getString ( "FontChooser.title" ) ) ; fontStylesArray = new String [ ] { messages . getString ( "FontChooser.style.plain" ) , messages . getString ( "FontChooser.style.bold" ) , messages . getString ( "FontChooser.style.italic" ) , messages . getString ( "FontChooser.style.bold_italic" ) } ; String [ ] fontNamesArray = GraphicsEnvironment . getLocalGraphicsEnvironment ( ) . getAvailableFontFamilyNames ( ) ; getContentPane ( ) . setLayout ( new GridBagLayout ( ) ) ; GridBagConstraints c = new GridBagConstraints ( ) ; c . insets = new Insets ( 4 , 4 , 4 , 4 ) ; final JPanel fontPanel = new JPanel ( new GridBagLayout ( ) ) ; c . gridx = 0 ; c . gridy = 0 ; c . fill = GridBagConstraints . HORIZONTAL ; JLabel fontNameLabel = new JLabel ( messages . getString ( "FontChooser.label.name" ) ) ; fontPanel . add ( fontNameLabel , c ) ; c . gridx = 1 ; c . gridy = 0 ; JLabel fontStyleLabel = new JLabel ( messages . getString ( "FontChooser.label.style" ) ) ; fontPanel . add ( fontStyleLabel , c ) ; c . gridx = 2 ; c . gridy = 0 ; JLabel fontSizeLabel = new JLabel ( messages . getString ( "FontChooser.label.size" ) ) ; fontPanel . add ( fontSizeLabel , c ) ; c . gridx = 0 ; c . gridy = 1 ; c . weightx = 1.0 ; c . fill = GridBagConstraints . HORIZONTAL ; fontNameTextField = new JTextField ( ) ; fontNameTextField . setEnabled ( false ) ; fontNameTextField . getDocument ( ) . addDocumentListener ( this ) ; fontPanel . add ( fontNameTextField , c ) ; c . weightx = 0.0 ; c . gridx = 1 ; c . gridy = 1 ; fontStyleTextField = new JTextField ( ) ; fontStyleTextField . setEnabled ( false ) ; fontStyleTextField . getDocument ( ) . addDocumentListener ( this ) ; fontPanel . add ( fontStyleTextField , c ) ; c . gridx = 2 ; c . gridy = 1 ; fontSizeTextField = new JTextField ( ) ; fontSizeTextField . setColumns ( 4 ) ; fontSizeTextField . getDocument ( ) . addDocumentListener ( this ) ; fontPanel . add ( fontSizeTextField , c ) ; c . gridx = 0 ; c . gridy = 2 ; c . weightx = 1.0 ; c . weighty = 1 ; c . fill = GridBagConstraints . BOTH ; fontNameList = new JList < > ( fontNamesArray ) ; fontNameList . addListSelectionListener ( this ) ; fontNameList . setVisibleRowCount ( 5 ) ; fontNameList . setSelectionMode ( ListSelectionModel . SINGLE_SELECTION ) ; JScrollPane fontNameListPane = new JScrollPane ( fontNameList , JScrollPane . VERTICAL_SCROLLBAR_ALWAYS , JScrollPane . HORIZONTAL_SCROLLBAR_AS_NEEDED ) ; fontPanel . add ( fontNameListPane , c ) ; c . gridx = 1 ; c . gridy = 2 ; c . weightx = 0.5 ; fontStyleList = new JList < > ( fontStylesArray ) ; fontStyleList . addListSelectionListener ( this ) ; fontStyleList . setVisibleRowCount ( 5 ) ; fontStyleList . setSelectionMode ( ListSelectionModel . SINGLE_SELECTION ) ; JScrollPane fontStyleListPane = new JScrollPane ( fontStyleList , JScrollPane . VERTICAL_SCROLLBAR_ALWAYS , JScrollPane . HORIZONTAL_SCROLLBAR_AS_NEEDED ) ; fontPanel . add ( fontStyleListPane , c ) ; c . gridx = 2 ; c . gridy = 2 ; fontSizeList = new JList < > ( fontSizesArray ) ; fontSizeList . addListSelectionListener ( this ) ; fontSizeList . setSelectionMode ( ListSelectionModel . SINGLE_SELECTION ) ; fontSizeList . setVisibleRowCount ( 5 ) ; JScrollPane fontSizeListPane = new JScrollPane ( fontSizeList , JScrollPane . VERTICAL_SCROLLBAR_ALWAYS , JScrollPane . HORIZONTAL_SCROLLBAR_AS_NEEDED ) ; fontPanel . add ( fontSizeListPane , c ) ; c . insets = new Insets ( 8 , 8 , 4 , 8 ) ; c . gridx = 0 ; c . gridy = 0 ; c . weightx = 0.0 ; c . weighty = 0.4 ; getContentPane ( ) . add ( fontPanel , c ) ; c . insets = new Insets ( 4 , 8 , 4 , 8 ) ; c . gridx = 0 ; c . gridy = 1 ; c . weightx = 1.0 ; c . weighty = 0.6 ; previewArea = new JTextArea ( messages . getString ( "FontChooser.pangram" ) ) ; previewArea . setLineWrap ( true ) ; previewArea . setRows ( 4 ) ; JScrollPane pane = new JScrollPane ( previewArea ) ; TitledBorder border = BorderFactory . createTitledBorder ( messages . getString ( "FontChooser.preview" ) ) ; pane . setBorder ( border ) ; getContentPane ( ) . add ( pane , c ) ; final JPanel buttonPanel = new JPanel ( new GridBagLayout ( ) ) ; c . insets = new Insets ( 4 , 4 , 4 , 4 ) ; c . gridx = 0 ; c . gridy = 0 ; c . weightx = 1.0 ; c . weighty = 0.0 ; c . anchor = GridBagConstraints . LINE_START ; c . fill = GridBagConstraints . NONE ; JButton resetButton = new JButton ( Tools . getLabel ( messages . getString ( "FontChooser.reset" ) ) ) ; resetButton . setMnemonic ( Tools . getMnemonic ( messages . getString ( "FontChooser.reset" ) ) ) ; resetButton . setActionCommand ( "RESET" ) ; resetButton . addActionListener ( this ) ; buttonPanel . add ( resetButton , c ) ; c . gridx = 1 ; c . gridy = 0 ; c . weightx = 0.0 ; c . weighty = 0.0 ; c . anchor = GridBagConstraints . LINE_END ; c . fill = GridBagConstraints . NONE ; JButton cancelButton = new JButton ( Tools . getLabel ( messages . getString ( "guiCancelButton" ) ) ) ; cancelButton . setMnemonic ( Tools . getMnemonic ( messages . getString ( "guiCancelButton" ) ) ) ; cancelButton . setActionCommand ( "CANCEL" ) ; cancelButton . addActionListener ( this ) ; buttonPanel . add ( cancelButton , c ) ; c . gridx = 2 ; c . gridy = 0 ; JButton okButton = new JButton ( Tools . getLabel ( messages . getString ( "guiOKButton" ) ) ) ; okButton . setMnemonic ( Tools . getMnemonic ( messages . getString ( "guiOKButton" ) ) ) ; okButton . setActionCommand ( "OK" ) ; okButton . addActionListener ( this ) ; buttonPanel . add ( okButton , c ) ; c . insets = new Insets ( 4 , 8 , 8 , 8 ) ; c . gridx = 0 ; c . gridy = 2 ; c . anchor = GridBagConstraints . LINE_START ; c . fill = GridBagConstraints . HORIZONTAL ; getContentPane ( ) . add ( buttonPanel , c ) ; this . defaultFont = previewArea . getFont ( ) ; setDefaultFont ( ) ; getRootPane ( ) . setDefaultButton ( cancelButton ) ; this . applyComponentOrientation ( ComponentOrientation . getOrientation ( Locale . getDefault ( ) ) ) ; pack ( ) ; } @ Override public void actionPerformed ( ActionEvent e ) { if ( "CANCEL" . equals ( e . getActionCommand ( ) ) ) { this . selectedFont = null ; setVisible ( false ) ; } else if ( "OK" . equals ( e . getActionCommand ( ) ) ) { setVisible ( false ) ; } else if ( "RESET" . equals ( e . getActionCommand ( ) ) ) { setDefaultFont ( ) ; } } @ Override public void valueChanged ( ListSelectionEvent e ) { if ( e . getValueIsAdjusting ( ) ) { return ; } if ( e . getSource ( ) == this . fontNameList ) { String fontName = this . fontNameList . getSelectedValue ( ) ; if ( fontName != null ) { this . fontNameTextField . setText ( fontName ) ; } } else if ( e . getSource ( ) == this . fontStyleList ) { String fontStyle = this . fontStyleList . getSelectedValue ( ) ; if ( fontStyle != null ) { this . fontStyleTextField . setText ( fontStyle ) ; } } else if ( e . getSource ( ) == this . fontSizeList ) { Integer fontSize = this . fontSizeList . getSelectedValue ( ) ; if ( fontSize != null ) { this . fontSizeTextField . setText ( fontSize . toString ( ) ) ; } } } @ Override public void insertUpdate ( DocumentEvent e ) { updateFont ( ) ; } @ Override public void removeUpdate ( DocumentEvent e ) { updateFont ( ) ; } @ Override public void changedUpdate ( DocumentEvent e ) { updateFont ( ) ; } private void updateFont ( ) { String fontName = this . fontNameTextField . getText ( ) ; String styleName = this . fontStyleTextField . getText ( ) ; Integer fontSize = null ; try { fontSize = Integer . parseInt ( this . fontSizeTextField . getText ( ) ) ; } catch ( NumberFormatException ex ) { } int style = Font . PLAIN ; if ( fontStylesArray [ 1 ] . equals ( styleName ) ) { style = Font . BOLD ; } else if ( fontStylesArray [ 2 ] . equals ( styleName ) ) { style = Font . ITALIC ; } else if ( fontStylesArray [ 3 ] . equals ( styleName ) ) { style = Font . BOLD | Font . ITALIC ; } if ( fontName != null && fontSize != null ) { Font newFont = new Font ( fontName , style , fontSize ) ; this . selectedFont = newFont ; previewArea . setFont ( newFont ) ; } } private String getStyle ( Font font ) { switch ( font . getStyle ( ) ) { case Font . PLAIN : return fontStylesArray [ 0 ] ; case Font . BOLD : return fontStylesArray [ 1 ] ; case Font . ITALIC : return fontStylesArray [ 2 ] ; case Font . BOLD | Font . ITALIC : return fontStylesArray [ 3 ] ; default : return fontStylesArray [ 0 ] ; } } private void setDefaultFont ( ) { this . selectedFont = defaultFont ; fontNameList . setSelectedValue ( defaultFont . getFontName ( ) , true ) ; fontStyleList . setSelectedValue ( getStyle ( defaultFont ) , true ) ; fontSizeList . setSelectedValue ( defaultFont . getSize ( ) , true ) ; } }
package org . languagetool . gui ; import java . awt . BasicStroke ; import java . awt . Color ; import java . awt . Component ; import java . awt . ComponentOrientation ; import java . awt . Graphics ; import java . awt . Graphics2D ; import java . awt . Rectangle ; import java . awt . RenderingHints ; import java . awt . Shape ; import java . awt . event . ActionEvent ; import java . awt . event . ActionListener ; import java . awt . event . MouseEvent ; import java . awt . event . MouseListener ; import java . io . File ; import java . io . IOException ; import java . lang . reflect . InvocationTargetException ; import java . util . ArrayList ; import java . util . Collections ; import java . util . Comparator ; import java . util . HashMap ; import java . util . HashSet ; import java . util . List ; import java . util . Locale ; import java . util . Map ; import java . util . ResourceBundle ; import java . util . Set ; import java . util . TreeMap ; import java . util . concurrent . ScheduledExecutorService ; import java . util . concurrent . ScheduledThreadPoolExecutor ; import java . util . concurrent . ThreadFactory ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . atomic . AtomicInteger ; import javax . swing . JFrame ; import javax . swing . JLabel ; import javax . swing . JMenu ; import javax . swing . JMenuItem ; import javax . swing . JPopupMenu ; import javax . swing . JSeparator ; import javax . swing . SwingUtilities ; import javax . swing . event . DocumentEvent ; import javax . swing . event . DocumentListener ; import javax . swing . event . EventListenerList ; import javax . swing . event . PopupMenuEvent ; import javax . swing . event . PopupMenuListener ; import javax . swing . text . AbstractDocument ; import javax . swing . text . BadLocationException ; import javax . swing . text . DefaultHighlighter ; import javax . swing . text . Document ; import javax . swing . text . Highlighter ; import javax . swing . text . JTextComponent ; import javax . swing . text . Position ; import javax . swing . text . View ; import org . apache . commons . lang . StringUtils ; import org . jetbrains . annotations . Nullable ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . MultiThreadedJLanguageTool ; import org . languagetool . language . LanguageIdentifier ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; class LanguageToolSupport { static final String CONFIG_FILE = ".languagetool.cfg" ; private static final int MAX_RULES_NO_CATEGORY_MENU = 12 ; private static final int MAX_RULES_PER_MENU = 12 ; private static final int MAX_CATEGORIES_PER_MENU = 12 ; private final UndoRedoSupport undo ; private final LanguageIdentifier langIdentifier ; private final JFrame frame ; private final JTextComponent textComponent ; private final EventListenerList listenerList = new EventListenerList ( ) ; private final ResourceBundle messages ; private final Map < Language , ConfigurationDialog > configDialogs = new HashMap < > ( ) ; private final List < RuleMatch > ruleMatches ; private final List < Span > documentSpans ; private MultiThreadedJLanguageTool languageTool ; private ScheduledExecutorService checkExecutor ; private MouseListener mouseListener ; private ActionListener actionListener ; private int millisecondDelay = 1500 ; private AtomicInteger check ; private boolean popupMenuEnabled = true ; private boolean backgroundCheckEnabled = true ; private Configuration config ; private boolean mustDetectLanguage = false ; public LanguageToolSupport ( JFrame frame , JTextComponent textComponent ) { this ( frame , textComponent , null ) ; } public LanguageToolSupport ( JFrame frame , JTextComponent textComponent , UndoRedoSupport support ) { this . frame = frame ; this . textComponent = textComponent ; this . messages = JLanguageTool . getMessageBundle ( ) ; ruleMatches = new ArrayList < > ( ) ; documentSpans = new ArrayList < > ( ) ; this . undo = support ; this . langIdentifier = new LanguageIdentifier ( ) ; init ( ) ; } void addLanguageToolListener ( LanguageToolListener ltListener ) { listenerList . add ( LanguageToolListener . class , ltListener ) ; } void removeLanguageToolListener ( LanguageToolListener ltListener ) { listenerList . remove ( LanguageToolListener . class , ltListener ) ; } private void fireEvent ( LanguageToolEvent . Type type , Object caller ) { Object [ ] listeners = listenerList . getListenerList ( ) ; LanguageToolEvent event = new LanguageToolEvent ( this , type , caller ) ; for ( int i = listeners . length - 2 ; i >= 0 ; i -= 2 ) { if ( listeners [ i ] == LanguageToolListener . class ) { ( ( LanguageToolListener ) listeners [ i + 1 ] ) . languageToolEventOccurred ( event ) ; } } } JTextComponent getTextComponent ( ) { return textComponent ; } List < RuleMatch > getMatches ( ) { return this . ruleMatches ; } ConfigurationDialog getCurrentConfigDialog ( ) { Language language = this . languageTool . getLanguage ( ) ; final ConfigurationDialog configDialog ; if ( configDialogs . containsKey ( language ) ) { configDialog = configDialogs . get ( language ) ; } else { configDialog = new ConfigurationDialog ( frame , false , config ) ; configDialogs . put ( language , configDialog ) ; } return configDialog ; } void reloadConfig ( ) { boolean update = false ; Set < String > disabledRules = config . getDisabledRuleIds ( ) ; if ( disabledRules == null ) { disabledRules = Collections . emptySet ( ) ; } Set < String > common = new HashSet < > ( disabledRules ) ; common . retainAll ( languageTool . getDisabledRules ( ) ) ; Set < String > toDisable = new HashSet < > ( disabledRules ) ; toDisable . removeAll ( common ) ; Set < String > toEnable = new HashSet < > ( languageTool . getDisabledRules ( ) ) ; toEnable . removeAll ( common ) ; for ( final String ruleId : toDisable ) { languageTool . disableRule ( ruleId ) ; update = true ; } for ( final String ruleId : toEnable ) { languageTool . enableRule ( ruleId ) ; update = true ; } Set < String > disabledCategories = config . getDisabledCategoryNames ( ) ; if ( disabledCategories == null ) { disabledCategories = Collections . emptySet ( ) ; } common = new HashSet < > ( disabledCategories ) ; common . retainAll ( languageTool . getDisabledCategories ( ) ) ; toDisable = new HashSet < > ( disabledCategories ) ; toDisable . removeAll ( common ) ; toEnable = new HashSet < > ( languageTool . getDisabledCategories ( ) ) ; toEnable . removeAll ( common ) ; if ( ! toDisable . isEmpty ( ) ) { languageTool . getDisabledCategories ( ) . addAll ( toDisable ) ; languageTool . disableRules ( new ArrayList < String > ( ) ) ; update = true ; } if ( ! toEnable . isEmpty ( ) ) { languageTool . getDisabledCategories ( ) . removeAll ( toEnable ) ; languageTool . disableRules ( new ArrayList < String > ( ) ) ; update = true ; } Set < String > enabledRules = config . getEnabledRuleIds ( ) ; if ( enabledRules == null ) { enabledRules = Collections . emptySet ( ) ; } for ( String ruleName : enabledRules ) { languageTool . enableDefaultOffRule ( ruleName ) ; languageTool . enableRule ( ruleName ) ; } if ( update ) { checkImmediately ( null ) ; fireEvent ( LanguageToolEvent . Type . RULE_ENABLED , null ) ; } } private void loadConfig ( ) { final Set < String > disabledRules = config . getDisabledRuleIds ( ) ; if ( disabledRules != null ) { for ( final String ruleId : disabledRules ) { languageTool . disableRule ( ruleId ) ; } } final Set < String > disabledCategories = config . getDisabledCategoryNames ( ) ; if ( disabledCategories != null ) { for ( final String categoryName : disabledCategories ) { languageTool . disableCategory ( categoryName ) ; } } final Set < String > enabledRules = config . getEnabledRuleIds ( ) ; if ( enabledRules != null ) { for ( String ruleName : enabledRules ) { languageTool . enableDefaultOffRule ( ruleName ) ; languageTool . enableRule ( ruleName ) ; } } } private void reloadLanguageTool ( Language language ) { try { config = new Configuration ( new File ( System . getProperty ( "user.home" ) ) , CONFIG_FILE , language ) ; this . config . setLanguage ( language ) ; if ( languageTool != null ) { languageTool . shutdown ( ) ; } languageTool = new MultiThreadedJLanguageTool ( language , config . getMotherTongue ( ) ) ; loadConfig ( ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } private void init ( ) { try { config = new Configuration ( new File ( System . getProperty ( "user.home" ) ) , CONFIG_FILE , null ) ; } catch ( IOException ex ) { throw new RuntimeException ( "Could not load configuration" , ex ) ; } Language defaultLanguage = config . getLanguage ( ) ; if ( defaultLanguage == null ) { defaultLanguage = Languages . getLanguageForLocale ( Locale . getDefault ( ) ) ; } reloadLanguageTool ( defaultLanguage ) ; checkExecutor = new ScheduledThreadPoolExecutor ( 1 , new ThreadFactory ( ) { @ Override public Thread newThread ( Runnable r ) { Thread t = new Thread ( r ) ; t . setDaemon ( true ) ; t . setPriority ( Thread . MIN_PRIORITY ) ; t . setName ( t . getName ( ) + "-lt-background" ) ; return t ; } } ) ; check = new AtomicInteger ( 0 ) ; this . textComponent . getDocument ( ) . addDocumentListener ( new DocumentListener ( ) { @ Override public void insertUpdate ( DocumentEvent e ) { mustDetectLanguage = config . getAutoDetect ( ) ; recalculateSpans ( e . getOffset ( ) , e . getLength ( ) , false ) ; if ( backgroundCheckEnabled ) { checkDelayed ( null ) ; } } @ Override public void removeUpdate ( DocumentEvent e ) { mustDetectLanguage = config . getAutoDetect ( ) ; recalculateSpans ( e . getOffset ( ) , e . getLength ( ) , true ) ; if ( backgroundCheckEnabled ) { checkDelayed ( null ) ; } } @ Override public void changedUpdate ( DocumentEvent e ) { mustDetectLanguage = config . getAutoDetect ( ) ; if ( backgroundCheckEnabled ) { checkDelayed ( null ) ; } } } ) ; mouseListener = new MouseListener ( ) { @ Override public void mouseClicked ( MouseEvent me ) { } @ Override public void mousePressed ( MouseEvent me ) { if ( me . isPopupTrigger ( ) ) { showPopup ( me ) ; } } @ Override public void mouseReleased ( MouseEvent me ) { if ( me . isPopupTrigger ( ) ) { showPopup ( me ) ; } } @ Override public void mouseEntered ( MouseEvent me ) { } @ Override public void mouseExited ( MouseEvent me ) { } } ; this . textComponent . addMouseListener ( mouseListener ) ; actionListener = new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { _actionPerformed ( e ) ; } } ; mustDetectLanguage = config . getAutoDetect ( ) ; if ( ! this . textComponent . getText ( ) . isEmpty ( ) && backgroundCheckEnabled ) { checkImmediately ( null ) ; } } public int getMillisecondDelay ( ) { return millisecondDelay ; } public void setMillisecondDelay ( int millisecondDelay ) { this . millisecondDelay = millisecondDelay ; } public boolean isPopupMenuEnabled ( ) { return popupMenuEnabled ; } public void setPopupMenuEnabled ( boolean popupMenuEnabled ) { if ( this . popupMenuEnabled == popupMenuEnabled ) { return ; } this . popupMenuEnabled = popupMenuEnabled ; if ( popupMenuEnabled ) { textComponent . addMouseListener ( mouseListener ) ; } else { textComponent . removeMouseListener ( mouseListener ) ; } } public boolean isBackgroundCheckEnabled ( ) { return backgroundCheckEnabled ; } public void setBackgroundCheckEnabled ( boolean backgroundCheckEnabled ) { if ( this . backgroundCheckEnabled == backgroundCheckEnabled ) { return ; } this . backgroundCheckEnabled = backgroundCheckEnabled ; if ( backgroundCheckEnabled ) { checkImmediately ( null ) ; } } public void setLanguage ( Language language ) { reloadLanguageTool ( language ) ; if ( backgroundCheckEnabled ) { checkImmediately ( null ) ; } } Language getLanguage ( ) { return this . languageTool . getLanguage ( ) ; } public Configuration getConfig ( ) { return config ; } JLanguageTool getLanguageTool ( ) { return languageTool ; } void disableRule ( String ruleId ) { Rule rule = this . getRuleForId ( ruleId ) ; if ( rule == null ) { return ; } if ( rule . isDefaultOff ( ) ) { config . getEnabledRuleIds ( ) . remove ( ruleId ) ; } else { config . getDisabledRuleIds ( ) . add ( ruleId ) ; } languageTool . disableRule ( ruleId ) ; updateHighlights ( ruleId ) ; fireEvent ( LanguageToolEvent . Type . RULE_DISABLED , null ) ; } void enableRule ( String ruleId ) { Rule rule = this . getRuleForId ( ruleId ) ; if ( rule == null ) { return ; } if ( rule . isDefaultOff ( ) ) { config . getEnabledRuleIds ( ) . add ( ruleId ) ; languageTool . enableDefaultOffRule ( ruleId ) ; } else { config . getDisabledRuleIds ( ) . remove ( ruleId ) ; } languageTool . enableRule ( ruleId ) ; fireEvent ( LanguageToolEvent . Type . RULE_ENABLED , null ) ; checkImmediately ( null ) ; } @ Nullable private Span getSpan ( int offset ) { for ( final Span cur : documentSpans ) { if ( cur . end > cur . start && cur . start <= offset && offset < cur . end ) { return cur ; } } return null ; } private void showPopup ( MouseEvent event ) { if ( documentSpans . isEmpty ( ) && languageTool . getDisabledRules ( ) . isEmpty ( ) ) { return ; } int offset = this . textComponent . viewToModel ( event . getPoint ( ) ) ; final Span span = getSpan ( offset ) ; JPopupMenu popup = new JPopupMenu ( "Grammar Menu" ) ; if ( span != null ) { JLabel msgItem = new JLabel ( "<html>" + span . msg . replace ( "<suggestion>" , "<b>" ) . replace ( "</suggestion>" , "</b>" ) + "</html>" ) ; msgItem . setToolTipText ( span . desc . replace ( "<suggestion>" , "" ) . replace ( "</suggestion>" , "" ) ) ; msgItem . setBorder ( new JMenuItem ( ) . getBorder ( ) ) ; popup . add ( msgItem ) ; popup . add ( new JSeparator ( ) ) ; for ( String r : span . replacement ) { ReplaceMenuItem item = new ReplaceMenuItem ( r , span ) ; popup . add ( item ) ; item . addActionListener ( actionListener ) ; } popup . add ( new JSeparator ( ) ) ; JMenuItem moreItem = new JMenuItem ( messages . getString ( "guiMore" ) ) ; moreItem . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { showDialog ( textComponent , span . msg , span . desc , span . rule ) ; } } ) ; popup . add ( moreItem ) ; JMenuItem ignoreItem = new JMenuItem ( messages . getString ( "guiTurnOffRule" ) ) ; ignoreItem . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { disableRule ( span . rule . getId ( ) ) ; } } ) ; popup . add ( ignoreItem ) ; popup . applyComponentOrientation ( ComponentOrientation . getOrientation ( Locale . getDefault ( ) ) ) ; } List < Rule > disabledRules = getDisabledRules ( ) ; if ( ! disabledRules . isEmpty ( ) ) { JMenu activateRuleMenu = new JMenu ( messages . getString ( "guiActivateRule" ) ) ; addDisabledRulesToMenu ( disabledRules , activateRuleMenu ) ; popup . add ( activateRuleMenu ) ; } if ( span != null ) { textComponent . setCaretPosition ( span . start ) ; textComponent . moveCaretPosition ( span . end ) ; } popup . addPopupMenuListener ( new PopupMenuListener ( ) { @ Override public void popupMenuWillBecomeVisible ( PopupMenuEvent e ) { } @ Override public void popupMenuWillBecomeInvisible ( PopupMenuEvent e ) { } @ Override public void popupMenuCanceled ( PopupMenuEvent e ) { if ( span != null ) { textComponent . setCaretPosition ( span . start ) ; } } } ) ; popup . show ( textComponent , event . getPoint ( ) . x , event . getPoint ( ) . y ) ; } private List < Rule > getDisabledRules ( ) { List < Rule > disabledRules = new ArrayList < > ( ) ; for ( String ruleId : languageTool . getDisabledRules ( ) ) { Rule rule = getRuleForId ( ruleId ) ; if ( rule == null || rule . isDefaultOff ( ) ) { continue ; } disabledRules . add ( rule ) ; } Collections . sort ( disabledRules , new Comparator < Rule > ( ) { @ Override public int compare ( Rule r1 , Rule r2 ) { return r1 . getDescription ( ) . compareTo ( r2 . getDescription ( ) ) ; } } ) ; return disabledRules ; } private void addDisabledRulesToMenu ( List < Rule > disabledRules , JMenu menu ) { if ( disabledRules . size ( ) <= MAX_RULES_NO_CATEGORY_MENU ) { createRulesMenu ( menu , disabledRules ) ; return ; } TreeMap < String , ArrayList < Rule > > categories = new TreeMap < > ( ) ; for ( Rule rule : disabledRules ) { if ( ! categories . containsKey ( rule . getCategory ( ) . getName ( ) ) ) { categories . put ( rule . getCategory ( ) . getName ( ) , new ArrayList < Rule > ( ) ) ; } categories . get ( rule . getCategory ( ) . getName ( ) ) . add ( rule ) ; } JMenu parent = menu ; int count = 0 ; for ( String category : categories . keySet ( ) ) { count ++ ; JMenu submenu = new JMenu ( category ) ; parent . add ( submenu ) ; createRulesMenu ( submenu , categories . get ( category ) ) ; if ( categories . keySet ( ) . size ( ) <= MAX_CATEGORIES_PER_MENU ) { continue ; } if ( ( count % ( MAX_CATEGORIES_PER_MENU - 1 ) == 0 ) && ( categories . keySet ( ) . size ( ) - count > 1 ) ) { JMenu more = new JMenu ( messages . getString ( "guiActivateRuleMoreCategories" ) ) ; parent . add ( more ) ; parent = more ; } } } private void createRulesMenu ( JMenu parent , List < Rule > rules ) { JMenu menu = parent ; int count = 0 ; for ( Rule rule : rules ) { count ++ ; final String id = rule . getId ( ) ; JMenuItem ruleItem = new JMenuItem ( rule . getDescription ( ) ) ; ruleItem . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { enableRule ( id ) ; } } ) ; menu . add ( ruleItem ) ; if ( rules . size ( ) <= MAX_RULES_PER_MENU ) { continue ; } if ( ( count % ( MAX_RULES_PER_MENU - 1 ) == 0 ) && ( rules . size ( ) - count > 1 ) ) { JMenu more = new JMenu ( messages . getString ( "guiActivateRuleMoreRules" ) ) ; menu . add ( more ) ; menu = more ; } } } @ Nullable Rule getRuleForId ( String ruleId ) { final List < Rule > allRules = languageTool . getAllRules ( ) ; for ( Rule rule : allRules ) { if ( rule . getId ( ) . equals ( ruleId ) ) { return rule ; } } return null ; } private void _actionPerformed ( ActionEvent e ) { ReplaceMenuItem src = ( ReplaceMenuItem ) e . getSource ( ) ; this . documentSpans . remove ( src . span ) ; applySuggestion ( e . getActionCommand ( ) , src . span . start , src . span . end ) ; } private void applySuggestion ( String str , int start , int end ) { if ( end < start ) { throw new IllegalArgumentException ( "end before start: " + end + " < " + start ) ; } Document doc = this . textComponent . getDocument ( ) ; if ( doc != null ) { try { if ( this . undo != null ) { this . undo . startCompoundEdit ( ) ; } if ( doc instanceof AbstractDocument ) { ( ( AbstractDocument ) doc ) . replace ( start , end - start , str , null ) ; } else { doc . remove ( start , end - start ) ; doc . insertString ( start , str , null ) ; } } catch ( BadLocationException e ) { throw new IllegalArgumentException ( e ) ; } finally { if ( this . undo != null ) { this . undo . endCompoundEdit ( ) ; } } } } public void checkDelayed ( ) { checkDelayed ( null ) ; } public void checkDelayed ( Object caller ) { check . getAndIncrement ( ) ; checkExecutor . schedule ( new RunnableImpl ( caller ) , millisecondDelay , TimeUnit . MILLISECONDS ) ; } public void checkImmediately ( ) { checkImmediately ( null ) ; } public void checkImmediately ( Object caller ) { check . getAndIncrement ( ) ; checkExecutor . schedule ( new RunnableImpl ( caller ) , 0 , TimeUnit . MILLISECONDS ) ; } Language autoDetectLanguage ( String text ) { Language lang = langIdentifier . detectLanguage ( text ) ; if ( lang == null ) { lang = Languages . getLanguageForLocale ( Locale . getDefault ( ) ) ; } if ( lang . hasVariant ( ) ) { lang = lang . getDefaultLanguageVariant ( ) ; } return lang ; } private synchronized List < RuleMatch > checkText ( final Object caller ) throws IOException { if ( this . mustDetectLanguage ) { mustDetectLanguage = false ; if ( ! this . textComponent . getText ( ) . isEmpty ( ) ) { Language detectedLanguage = autoDetectLanguage ( this . textComponent . getText ( ) ) ; if ( ! detectedLanguage . equals ( this . languageTool . getLanguage ( ) ) ) { reloadLanguageTool ( detectedLanguage ) ; if ( SwingUtilities . isEventDispatchThread ( ) ) { fireEvent ( LanguageToolEvent . Type . LANGUAGE_CHANGED , caller ) ; } else { try { SwingUtilities . invokeAndWait ( new Runnable ( ) { @ Override public void run ( ) { fireEvent ( LanguageToolEvent . Type . LANGUAGE_CHANGED , caller ) ; } } ) ; } catch ( InterruptedException ex ) { } catch ( InvocationTargetException ex ) { throw new RuntimeException ( ex ) ; } } } } } if ( SwingUtilities . isEventDispatchThread ( ) ) { fireEvent ( LanguageToolEvent . Type . CHECKING_STARTED , caller ) ; } else { try { SwingUtilities . invokeAndWait ( new Runnable ( ) { @ Override public void run ( ) { fireEvent ( LanguageToolEvent . Type . CHECKING_STARTED , caller ) ; } } ) ; } catch ( InterruptedException ex ) { } catch ( InvocationTargetException ex ) { throw new RuntimeException ( ex ) ; } } final List < RuleMatch > matches = this . languageTool . check ( this . textComponent . getText ( ) ) ; int v = check . get ( ) ; if ( v == 0 ) { if ( ! SwingUtilities . isEventDispatchThread ( ) ) { SwingUtilities . invokeLater ( new Runnable ( ) { @ Override public void run ( ) { updateHighlights ( matches ) ; fireEvent ( LanguageToolEvent . Type . CHECKING_FINISHED , caller ) ; } } ) ; } else { updateHighlights ( matches ) ; fireEvent ( LanguageToolEvent . Type . CHECKING_FINISHED , caller ) ; } } return matches ; } private void removeHighlights ( ) { for ( Highlighter . Highlight hl : textComponent . getHighlighter ( ) . getHighlights ( ) ) { if ( hl . getPainter ( ) instanceof HighlightPainter ) { textComponent . getHighlighter ( ) . removeHighlight ( hl ) ; } } } private void recalculateSpans ( int offset , int length , boolean remove ) { if ( length == 0 ) { return ; } for ( Span span : this . documentSpans ) { if ( offset >= span . end ) { continue ; } if ( ! remove ) { if ( offset <= span . start ) { span . start += length ; } span . end += length ; } else { if ( offset + length <= span . end ) { if ( offset > span . start ) { } else if ( offset + length <= span . start ) { span . start -= length ; } else { span . start = offset ; } span . end -= length ; } else { span . end -= Math . min ( length , span . end - offset ) ; } } } updateHighlights ( ) ; } private void updateHighlights ( String disabledRule ) { List < Span > spans = new ArrayList < > ( ) ; List < RuleMatch > matches = new ArrayList < > ( ) ; for ( RuleMatch match : ruleMatches ) { if ( match . getRule ( ) . getId ( ) . equals ( disabledRule ) ) { continue ; } matches . add ( match ) ; spans . add ( new Span ( match ) ) ; } prepareUpdateHighlights ( matches , spans ) ; } private void updateHighlights ( List < RuleMatch > matches ) { List < Span > spans = new ArrayList < > ( ) ; for ( RuleMatch match : matches ) { spans . add ( new Span ( match ) ) ; } prepareUpdateHighlights ( matches , spans ) ; } private void prepareUpdateHighlights ( List < RuleMatch > matches , List < Span > spans ) { ruleMatches . clear ( ) ; documentSpans . clear ( ) ; ruleMatches . addAll ( matches ) ; documentSpans . addAll ( spans ) ; updateHighlights ( ) ; } private void updateHighlights ( ) { removeHighlights ( ) ; Highlighter h = textComponent . getHighlighter ( ) ; for ( Span span : documentSpans ) { if ( span . start == span . end ) { continue ; } try { if ( span . start < span . end ) { ITSIssueType issueType = span . rule . getLocQualityIssueType ( ) ; Color colorForIssueType = getConfig ( ) . getErrorColors ( ) . get ( issueType ) ; Color bgColor = colorForIssueType != null ? colorForIssueType : null ; Color underlineColor = ITSIssueType . Misspelling == span . rule . getLocQualityIssueType ( ) ? Color . red : Color . blue ; HighlightPainter painter = new HighlightPainter ( bgColor , underlineColor ) ; h . addHighlight ( span . start , span . end , painter ) ; } } catch ( BadLocationException ex ) { ex . printStackTrace ( ) ; } } } private void showDialog ( Component parent , String title , String message , Rule rule ) { Tools . showRuleInfoDialog ( parent , title , message , rule , messages , languageTool . getLanguage ( ) . getShortNameWithCountryAndVariant ( ) ) ; } private static class HighlightPainter extends DefaultHighlighter . DefaultHighlightPainter { private static final BasicStroke OO_STROKE1 = new BasicStroke ( 1.0f , BasicStroke . CAP_ROUND , BasicStroke . JOIN_ROUND , 10.0f , new float [ ] { 3.0f , 5.0f } , 2 ) ; private static final BasicStroke OO_STROKE2 = new BasicStroke ( 1.0f , BasicStroke . CAP_ROUND , BasicStroke . JOIN_ROUND , 10.0f , new float [ ] { 1.0f , 3.0f } , 3 ) ; private static final BasicStroke OO_STROKE3 = new BasicStroke ( 1.0f , BasicStroke . CAP_ROUND , BasicStroke . JOIN_ROUND , 10.0f , new float [ ] { 3.0f , 5.0f } , 6 ) ; private static final BasicStroke ZIGZAG_STROKE1 = new BasicStroke ( 1.0f , BasicStroke . CAP_ROUND , BasicStroke . JOIN_ROUND , 10.0f , new float [ ] { 1.0f , 1.0f } , 0 ) ; private final Color underlineColor ; private final Color backgroundColor ; private HighlightPainter ( Color backgroundColor , Color underlineColor ) { super ( backgroundColor ) ; this . backgroundColor = backgroundColor ; this . underlineColor = underlineColor ; } @ Override public Shape paintLayer ( Graphics g , int offs0 , int offs1 , Shape bounds , JTextComponent c , View view ) { if ( backgroundColor != null ) { super . paintLayer ( g , offs0 , offs1 , bounds , c , view ) ; } Rectangle rect ; if ( offs0 == view . getStartOffset ( ) && offs1 == view . getEndOffset ( ) ) { if ( bounds instanceof Rectangle ) { rect = ( Rectangle ) bounds ; } else { rect = bounds . getBounds ( ) ; } } else { try { Shape shape = view . modelToView ( offs0 , Position . Bias . Forward , offs1 , Position . Bias . Backward , bounds ) ; rect = shape instanceof Rectangle ? ( Rectangle ) shape : shape . getBounds ( ) ; } catch ( BadLocationException e ) { rect = null ; } } if ( rect != null ) { Color color = underlineColor ; if ( color == null ) { g . setColor ( c . getSelectionColor ( ) ) ; } else { g . setColor ( color ) ; } rect . width = Math . max ( rect . width , 1 ) ; int descent = c . getFontMetrics ( c . getFont ( ) ) . getDescent ( ) ; if ( descent > 3 ) { drawCurvedLine ( g , rect ) ; } else if ( descent > 2 ) { drawCurvedLine ( g , rect ) ; } else { drawLine ( g , rect ) ; } } return rect ; } private void drawCurvedLine ( Graphics g , Rectangle rect ) { int x1 = rect . x ; int x2 = rect . x + rect . width ; int y = rect . y + rect . height ; Graphics2D g2 = ( Graphics2D ) g ; g2 . setRenderingHint ( RenderingHints . KEY_ANTIALIASING , RenderingHints . VALUE_ANTIALIAS_ON ) ; g2 . setStroke ( OO_STROKE1 ) ; g2 . drawLine ( x1 , y - 1 , x2 , y - 1 ) ; g2 . setStroke ( OO_STROKE2 ) ; g2 . drawLine ( x1 , y - 2 , x2 , y - 2 ) ; g2 . setStroke ( OO_STROKE3 ) ; g2 . drawLine ( x1 , y - 3 , x2 , y - 3 ) ; } private void drawLine ( Graphics g , Rectangle rect ) { int x1 = rect . x ; int x2 = rect . x + rect . width ; int y = rect . y + rect . height ; Graphics2D g2 = ( Graphics2D ) g ; g2 . setStroke ( ZIGZAG_STROKE1 ) ; g2 . drawLine ( x1 , y - 1 , x2 , y - 1 ) ; } } private static class ReplaceMenuItem extends JMenuItem { private final Span span ; private ReplaceMenuItem ( String name , Span span ) { super ( name ) ; this . span = span ; } } private static class Span { private int start ; private int end ; private final String msg ; private final String desc ; private final List < String > replacement ; private final Rule rule ; private Span ( RuleMatch match ) { start = match . getFromPos ( ) ; end = match . getToPos ( ) ; String tmp = match . getShortMessage ( ) ; if ( StringUtils . isEmpty ( tmp ) ) { tmp = match . getMessage ( ) ; } msg = Tools . shortenComment ( tmp ) ; desc = match . getMessage ( ) ; replacement = new ArrayList < > ( ) ; replacement . addAll ( match . getSuggestedReplacements ( ) ) ; rule = match . getRule ( ) ; } } private class RunnableImpl implements Runnable { private final Object caller ; private RunnableImpl ( Object caller ) { this . caller = caller ; } @ Override public void run ( ) { int v = check . decrementAndGet ( ) ; if ( v != 0 ) { return ; } try { checkText ( caller ) ; } catch ( Exception ex ) { Tools . showError ( ex ) ; } } } }
package org . languagetool . tagging . ro ; public class RomanianTaggerDiacriticsTest extends AbstractRomanianTaggerTest { @ Override protected RomanianTagger createTagger ( ) { return new RomanianTagger ( "/ro/test_diacritics.dict" ) ; } public void testTaggerMerseseram ( ) throws Exception { assertHasLemmaAndPos ( "făcusem" , "face" , "004" ) ; assertHasLemmaAndPos ( "cuțitul" , "cuțit" , "002" ) ; assertHasLemmaAndPos ( "merseserăm" , "merge" , "002" ) ; } public void testTaggerCuscaCutit ( ) throws Exception { assertHasLemmaAndPos ( "cușcă" , "cușcă" , "001" ) ; assertHasLemmaAndPos ( "cuțit" , "cuțit" , "001" ) ; assertHasLemmaAndPos ( "cuțitul" , "cuțit" , "002" ) ; } }
package org . languagetool . gui ; import java . awt . Image ; import java . awt . Toolkit ; import java . awt . event . ActionEvent ; import java . awt . event . KeyEvent ; import java . util . ResourceBundle ; import javax . swing . AbstractAction ; import javax . swing . Action ; import javax . swing . ImageIcon ; import javax . swing . InputMap ; import javax . swing . KeyStroke ; import javax . swing . event . UndoableEditEvent ; import javax . swing . event . UndoableEditListener ; import javax . swing . text . JTextComponent ; import javax . swing . undo . CannotRedoException ; import javax . swing . undo . CannotUndoException ; import javax . swing . undo . CompoundEdit ; import javax . swing . undo . UndoManager ; import org . languagetool . JLanguageTool ; class UndoRedoSupport { final UndoAction undoAction ; final RedoAction redoAction ; private final UndoManager undoManager ; private final ResourceBundle messages ; private boolean compoundMode = false ; private CompoundEdit ce = null ; UndoRedoSupport ( JTextComponent textComponent , ResourceBundle messages ) { this . messages = messages ; undoManager = new UndoManager ( ) ; undoAction = new UndoAction ( ) ; redoAction = new RedoAction ( ) ; textComponent . getDocument ( ) . addUndoableEditListener ( new UndoableEditListener ( ) { @ Override public void undoableEditHappened ( UndoableEditEvent e ) { if ( compoundMode ) { ce . addEdit ( e . getEdit ( ) ) ; } else { undoManager . addEdit ( e . getEdit ( ) ) ; } undoAction . updateUndoState ( ) ; redoAction . updateRedoState ( ) ; } } ) ; InputMap inputMap = textComponent . getInputMap ( ) ; KeyStroke key = KeyStroke . getKeyStroke ( KeyEvent . VK_Z , Toolkit . getDefaultToolkit ( ) . getMenuShortcutKeyMask ( ) ) ; inputMap . put ( key , "undo" ) ; textComponent . getActionMap ( ) . put ( "undo" , undoAction ) ; key = KeyStroke . getKeyStroke ( KeyEvent . VK_Z , Toolkit . getDefaultToolkit ( ) . getMenuShortcutKeyMask ( ) | java . awt . event . InputEvent . SHIFT_DOWN_MASK ) ; inputMap . put ( key , "redo" ) ; textComponent . getActionMap ( ) . put ( "redo" , redoAction ) ; } void startCompoundEdit ( ) { if ( compoundMode ) { throw new RuntimeException ( "already in compound mode" ) ; } ce = new CompoundEdit ( ) ; compoundMode = true ; } void endCompoundEdit ( ) { if ( ! compoundMode ) { throw new RuntimeException ( "not in compound mode" ) ; } ce . end ( ) ; undoManager . addEdit ( ce ) ; ce = null ; compoundMode = false ; } class UndoAction extends AbstractAction { private UndoAction ( ) { super ( messages . getString ( "guiUndo" ) ) ; Image img ; img = Toolkit . getDefaultToolkit ( ) . getImage ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( "sc_undo.png" ) ) ; putValue ( Action . SMALL_ICON , new ImageIcon ( img ) ) ; img = Toolkit . getDefaultToolkit ( ) . getImage ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( "lc_undo.png" ) ) ; putValue ( Action . LARGE_ICON_KEY , new ImageIcon ( img ) ) ; KeyStroke key = KeyStroke . getKeyStroke ( KeyEvent . VK_Z , Toolkit . getDefaultToolkit ( ) . getMenuShortcutKeyMask ( ) ) ; putValue ( Action . ACCELERATOR_KEY , key ) ; putValue ( Action . MNEMONIC_KEY , KeyEvent . VK_U ) ; setEnabled ( false ) ; } @ Override public void actionPerformed ( ActionEvent e ) { try { undoManager . undo ( ) ; } catch ( CannotUndoException ex ) { } updateUndoState ( ) ; redoAction . updateRedoState ( ) ; } private void updateUndoState ( ) { if ( undoManager . canUndo ( ) ) { setEnabled ( true ) ; } else { setEnabled ( false ) ; } } } class RedoAction extends AbstractAction { private RedoAction ( ) { super ( messages . getString ( "guiRedo" ) ) ; Image img ; img = Toolkit . getDefaultToolkit ( ) . getImage ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( "sc_redo.png" ) ) ; putValue ( Action . SMALL_ICON , new ImageIcon ( img ) ) ; img = Toolkit . getDefaultToolkit ( ) . getImage ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( "lc_redo.png" ) ) ; putValue ( Action . LARGE_ICON_KEY , new ImageIcon ( img ) ) ; KeyStroke key = KeyStroke . getKeyStroke ( KeyEvent . VK_Z , Toolkit . getDefaultToolkit ( ) . getMenuShortcutKeyMask ( ) | java . awt . event . InputEvent . SHIFT_DOWN_MASK ) ; putValue ( Action . ACCELERATOR_KEY , key ) ; putValue ( Action . MNEMONIC_KEY , KeyEvent . VK_R ) ; setEnabled ( false ) ; } @ Override public void actionPerformed ( ActionEvent e ) { try { undoManager . redo ( ) ; } catch ( CannotRedoException ex ) { } updateRedoState ( ) ; undoAction . updateUndoState ( ) ; } private void updateRedoState ( ) { if ( undoManager . canRedo ( ) ) { setEnabled ( true ) ; } else { setEnabled ( false ) ; } } } }
package org . languagetool . gui ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . Rule ; import org . languagetool . server . HTTPServer ; import org . languagetool . server . HTTPServerConfig ; import org . languagetool . server . PortBindingException ; import org . languagetool . tools . JnaTools ; import org . languagetool . tools . StringTools ; import javax . swing . * ; import javax . swing . filechooser . FileFilter ; import java . awt . * ; import java . awt . datatransfer . Clipboard ; import java . awt . datatransfer . DataFlavor ; import java . awt . datatransfer . Transferable ; import java . awt . event . * ; import java . io . * ; import java . net . URL ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; import java . util . ResourceBundle ; import javax . swing . text . DefaultEditorKit ; import javax . swing . text . JTextComponent ; import javax . swing . text . TextAction ; public final class Main { static final String EXTERNAL_LANGUAGE_SUFFIX = " (ext.)" ; static final String HTML_FONT_START = "<font face='Arial,Helvetica'>" ; static final String HTML_FONT_END = "</font>" ; static final String HTML_GREY_FONT_START = "<font face='Arial,Helvetica' color='#666666'>" ; private static final String TRAY_ICON = "/TrayIcon.png" ; private static final String TRAY_SERVER_ICON = "/TrayIconWithServer.png" ; private static final String TRAY_SMALL_ICON = "/TrayIconSmall.png" ; private static final String TRAY_SMALL_SERVER_ICON = "/TrayIconSmallWithServer.png" ; private static final String TRAY_TOOLTIP = "LanguageTool" ; private static final String TAG_COLOR = "#888888" ; private static final int WINDOW_WIDTH = 600 ; private static final int WINDOW_HEIGHT = 550 ; private final ResourceBundle messages ; private final List < Language > externalLanguages = new ArrayList < > ( ) ; private JFrame frame ; private JDialog taggerDialog ; private JTextPane taggerArea ; private JTextArea textArea ; private JTextPane resultArea ; private ResultArea resultAreaHelper ; private LanguageComboBox languageBox ; private CheckboxMenuItem enableHttpServerItem ; private HTTPServer httpServer ; private TrayIcon trayIcon ; private boolean closeHidesToTray ; private boolean isInTray ; private LanguageToolSupport ltSupport ; private OpenAction openAction ; private SaveAction saveAction ; private SaveAsAction saveAsAction ; private AutoCheckAction autoCheckAction ; private CheckAction checkAction ; private File currentFile ; private UndoRedoSupport undoRedo ; private long startTime ; private final JLabel statusLabel = new JLabel ( " " , null , SwingConstants . RIGHT ) ; private FontChooser fontChooserDialog ; private Main ( ) { messages = JLanguageTool . getMessageBundle ( ) ; } private void loadFile ( ) { final File file = Tools . openFileDialog ( frame , new PlainTextFileFilter ( ) ) ; if ( file == null ) { return ; } loadFile ( file ) ; } private void loadFile ( File file ) { try ( FileInputStream inputStream = new FileInputStream ( file ) ) { final String fileContents = StringTools . readStream ( inputStream , null ) ; textArea . setText ( fileContents ) ; currentFile = file ; updateTitle ( ) ; } catch ( IOException e ) { Tools . showError ( e ) ; } } private void saveFile ( boolean newFile ) { if ( currentFile == null || newFile ) { final JFileChooser jfc = new JFileChooser ( ) ; jfc . setFileFilter ( new PlainTextFileFilter ( ) ) ; jfc . showSaveDialog ( frame ) ; File file = jfc . getSelectedFile ( ) ; if ( file == null ) { return ; } currentFile = file ; updateTitle ( ) ; } try ( BufferedWriter writer = new BufferedWriter ( new FileWriter ( currentFile ) ) ) { writer . write ( textArea . getText ( ) ) ; } catch ( IOException ex ) { Tools . showError ( ex ) ; } } private void addLanguage ( ) throws InstantiationException , IllegalAccessException { final LanguageManagerDialog dialog = new LanguageManagerDialog ( frame , externalLanguages ) ; dialog . show ( ) ; List < Language > newExtLanguages = dialog . getLanguages ( ) ; externalLanguages . clear ( ) ; externalLanguages . addAll ( newExtLanguages ) ; languageBox . populateLanguageBox ( externalLanguages ) ; languageBox . selectLanguage ( ltSupport . getLanguage ( ) ) ; } private void showOptions ( ) { final JLanguageTool langTool = ltSupport . getLanguageTool ( ) ; final List < Rule > rules = langTool . getAllRules ( ) ; final ConfigurationDialog configDialog = ltSupport . getCurrentConfigDialog ( ) ; configDialog . show ( rules ) ; Configuration config = ltSupport . getConfig ( ) ; try { config . saveConfiguration ( langTool . getLanguage ( ) ) ; } catch ( IOException e ) { Tools . showError ( e ) ; } ltSupport . reloadConfig ( ) ; stopServer ( ) ; maybeStartServer ( ) ; } private void showSelectFontDialog ( ) { Configuration config = ltSupport . getConfig ( ) ; if ( fontChooserDialog == null ) { fontChooserDialog = new FontChooser ( frame , true ) ; Tools . centerDialog ( fontChooserDialog ) ; } fontChooserDialog . setSelectedFont ( this . textArea . getFont ( ) ) ; fontChooserDialog . setVisible ( true ) ; if ( fontChooserDialog . getSelectedFont ( ) != null ) { this . textArea . setFont ( fontChooserDialog . getSelectedFont ( ) ) ; config . setFontName ( fontChooserDialog . getSelectedFont ( ) . getFamily ( ) ) ; config . setFontStyle ( fontChooserDialog . getSelectedFont ( ) . getStyle ( ) ) ; config . setFontSize ( fontChooserDialog . getSelectedFont ( ) . getSize ( ) ) ; try { config . saveConfiguration ( ltSupport . getLanguage ( ) ) ; } catch ( IOException e ) { Tools . showError ( e ) ; } } } private Component getFrame ( ) { return frame ; } private void updateTitle ( ) { if ( currentFile == null ) { frame . setTitle ( "LanguageTool " + JLanguageTool . VERSION ) ; } else { frame . setTitle ( currentFile . getName ( ) + " - LanguageTool " + JLanguageTool . VERSION ) ; } } private void createGUI ( ) { frame = new JFrame ( "LanguageTool " + JLanguageTool . VERSION ) ; setLookAndFeel ( ) ; openAction = new OpenAction ( ) ; saveAction = new SaveAction ( ) ; saveAsAction = new SaveAsAction ( ) ; checkAction = new CheckAction ( ) ; autoCheckAction = new AutoCheckAction ( true ) ; frame . setDefaultCloseOperation ( WindowConstants . DO_NOTHING_ON_CLOSE ) ; frame . addWindowListener ( new CloseListener ( ) ) ; final URL iconUrl = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( TRAY_ICON ) ; frame . setIconImage ( new ImageIcon ( iconUrl ) . getImage ( ) ) ; textArea = new JTextArea ( ) ; textArea . setLineWrap ( true ) ; textArea . setWrapStyleWord ( true ) ; textArea . addKeyListener ( new ControlReturnTextCheckingListener ( ) ) ; resultArea = new JTextPane ( ) ; undoRedo = new UndoRedoSupport ( this . textArea , messages ) ; frame . setJMenuBar ( createMenuBar ( ) ) ; final GridBagConstraints buttonCons = new GridBagConstraints ( ) ; final JPanel insidePanel = new JPanel ( ) ; insidePanel . setOpaque ( false ) ; insidePanel . setLayout ( new GridBagLayout ( ) ) ; buttonCons . gridx = 0 ; buttonCons . gridy = 0 ; buttonCons . anchor = GridBagConstraints . LINE_START ; insidePanel . add ( new JLabel ( messages . getString ( "textLanguage" ) + " " ) , buttonCons ) ; languageBox = new LanguageComboBox ( messages , EXTERNAL_LANGUAGE_SUFFIX ) ; languageBox . setRenderer ( new LanguageComboBoxRenderer ( messages , EXTERNAL_LANGUAGE_SUFFIX ) ) ; buttonCons . gridx = 1 ; buttonCons . gridy = 0 ; buttonCons . anchor = GridBagConstraints . LINE_START ; insidePanel . add ( languageBox , buttonCons ) ; final JCheckBox autoDetectBox = new JCheckBox ( messages . getString ( "atd" ) ) ; buttonCons . gridx = 2 ; buttonCons . gridy = 0 ; buttonCons . gridwidth = GridBagConstraints . REMAINDER ; buttonCons . anchor = GridBagConstraints . LINE_START ; insidePanel . add ( autoDetectBox , buttonCons ) ; buttonCons . gridx = 0 ; buttonCons . gridy = 1 ; buttonCons . gridwidth = GridBagConstraints . REMAINDER ; buttonCons . fill = GridBagConstraints . HORIZONTAL ; buttonCons . anchor = GridBagConstraints . LINE_END ; buttonCons . weightx = 1.0 ; insidePanel . add ( statusLabel , buttonCons ) ; final Container contentPane = frame . getContentPane ( ) ; final GridBagLayout gridLayout = new GridBagLayout ( ) ; contentPane . setLayout ( gridLayout ) ; final GridBagConstraints cons = new GridBagConstraints ( ) ; cons . gridx = 0 ; cons . gridy = 1 ; cons . fill = GridBagConstraints . HORIZONTAL ; cons . anchor = GridBagConstraints . FIRST_LINE_START ; JToolBar toolbar = new JToolBar ( "Toolbar" , JToolBar . HORIZONTAL ) ; toolbar . setFloatable ( false ) ; contentPane . add ( toolbar , cons ) ; JButton openButton = new JButton ( openAction ) ; openButton . setHideActionText ( true ) ; openButton . setFocusable ( false ) ; toolbar . add ( openButton ) ; JButton saveButton = new JButton ( saveAction ) ; saveButton . setHideActionText ( true ) ; saveButton . setFocusable ( false ) ; toolbar . add ( saveButton ) ; JButton saveAsButton = new JButton ( saveAsAction ) ; saveAsButton . setHideActionText ( true ) ; saveAsButton . setFocusable ( false ) ; toolbar . add ( saveAsButton ) ; JButton spellButton = new JButton ( this . checkAction ) ; spellButton . setHideActionText ( true ) ; spellButton . setFocusable ( false ) ; toolbar . add ( spellButton ) ; JToggleButton autoSpellButton = new JToggleButton ( autoCheckAction ) ; autoSpellButton . setHideActionText ( true ) ; autoSpellButton . setFocusable ( false ) ; toolbar . add ( autoSpellButton ) ; JButton clearTextButton = new JButton ( new ClearTextAction ( ) ) ; clearTextButton . setHideActionText ( true ) ; clearTextButton . setFocusable ( false ) ; toolbar . add ( clearTextButton ) ; cons . insets = new Insets ( 5 , 5 , 5 , 5 ) ; cons . fill = GridBagConstraints . BOTH ; cons . weightx = 10.0f ; cons . weighty = 10.0f ; cons . gridx = 0 ; cons . gridy = 2 ; cons . weighty = 5.0f ; final JSplitPane splitPane = new JSplitPane ( JSplitPane . VERTICAL_SPLIT , new JScrollPane ( textArea ) , new JScrollPane ( resultArea ) ) ; splitPane . setDividerLocation ( 200 ) ; contentPane . add ( splitPane , cons ) ; cons . fill = GridBagConstraints . HORIZONTAL ; cons . gridx = 0 ; cons . gridy = 3 ; cons . weightx = 1.0f ; cons . weighty = 0.0f ; cons . insets = new Insets ( 4 , 12 , 4 , 12 ) ; contentPane . add ( insidePanel , cons ) ; ltSupport = new LanguageToolSupport ( this . frame , this . textArea , this . undoRedo ) ; resultAreaHelper = new ResultArea ( messages , ltSupport , resultArea ) ; languageBox . selectLanguage ( ltSupport . getLanguage ( ) ) ; languageBox . setEnabled ( ! ltSupport . getConfig ( ) . getAutoDetect ( ) ) ; autoDetectBox . setSelected ( ltSupport . getConfig ( ) . getAutoDetect ( ) ) ; languageBox . addItemListener ( new ItemListener ( ) { @ Override public void itemStateChanged ( ItemEvent e ) { if ( e . getStateChange ( ) == ItemEvent . SELECTED ) { frame . applyComponentOrientation ( ComponentOrientation . getOrientation ( Locale . getDefault ( ) ) ) ; Language lang = ( Language ) languageBox . getSelectedItem ( ) ; ComponentOrientation componentOrientation = ComponentOrientation . getOrientation ( lang . getLocale ( ) ) ; textArea . applyComponentOrientation ( componentOrientation ) ; resultArea . applyComponentOrientation ( componentOrientation ) ; ltSupport . setLanguage ( lang ) ; } } } ) ; autoDetectBox . addItemListener ( new ItemListener ( ) { @ Override public void itemStateChanged ( ItemEvent e ) { boolean selected = e . getStateChange ( ) == ItemEvent . SELECTED ; languageBox . setEnabled ( ! selected ) ; ltSupport . getConfig ( ) . setAutoDetect ( selected ) ; if ( selected ) { Language detected = ltSupport . autoDetectLanguage ( textArea . getText ( ) ) ; languageBox . selectLanguage ( detected ) ; } } } ) ; ltSupport . addLanguageToolListener ( new LanguageToolListener ( ) { @ Override public void languageToolEventOccurred ( LanguageToolEvent event ) { if ( event . getType ( ) == LanguageToolEvent . Type . CHECKING_STARTED ) { final String msg = Tools . makeTexti18n ( messages , "checkStart" ) ; statusLabel . setText ( msg ) ; if ( event . getCaller ( ) == getFrame ( ) ) { startTime = System . currentTimeMillis ( ) ; setWaitCursor ( ) ; checkAction . setEnabled ( false ) ; } } else if ( event . getType ( ) == LanguageToolEvent . Type . CHECKING_FINISHED ) { if ( event . getCaller ( ) == getFrame ( ) ) { checkAction . setEnabled ( true ) ; unsetWaitCursor ( ) ; resultAreaHelper . setRunTime ( System . currentTimeMillis ( ) - startTime ) ; resultAreaHelper . displayResult ( ) ; final String msg = Tools . makeTexti18n ( messages , "checkDone" , event . getSource ( ) . getMatches ( ) . size ( ) , System . currentTimeMillis ( ) - startTime ) ; statusLabel . setText ( msg ) ; } else { final String msg = Tools . makeTexti18n ( messages , "checkDoneNoTime" , event . getSource ( ) . getMatches ( ) . size ( ) ) ; statusLabel . setText ( msg ) ; } } else if ( event . getType ( ) == LanguageToolEvent . Type . LANGUAGE_CHANGED ) { languageBox . selectLanguage ( ltSupport . getLanguage ( ) ) ; } } } ) ; frame . applyComponentOrientation ( ComponentOrientation . getOrientation ( Locale . getDefault ( ) ) ) ; Language lang = ltSupport . getLanguage ( ) ; ComponentOrientation componentOrientation = ComponentOrientation . getOrientation ( lang . getLocale ( ) ) ; textArea . applyComponentOrientation ( componentOrientation ) ; resultArea . applyComponentOrientation ( componentOrientation ) ; ResourceBundle textLanguageMessageBundle = JLanguageTool . getMessageBundle ( ltSupport . getLanguage ( ) ) ; textArea . setText ( textLanguageMessageBundle . getString ( "guiDemoText" ) ) ; Configuration config = ltSupport . getConfig ( ) ; if ( config . getFontName ( ) != null || config . getFontStyle ( ) != Configuration . FONT_STYLE_INVALID || config . getFontSize ( ) != Configuration . FONT_SIZE_INVALID ) { String fontName = config . getFontName ( ) ; if ( fontName == null ) { fontName = textArea . getFont ( ) . getFamily ( ) ; } int fontSize = config . getFontSize ( ) ; if ( fontSize == Configuration . FONT_SIZE_INVALID ) { fontSize = textArea . getFont ( ) . getSize ( ) ; } Font font = new Font ( fontName , config . getFontStyle ( ) , fontSize ) ; textArea . setFont ( font ) ; } frame . pack ( ) ; frame . setSize ( WINDOW_WIDTH , WINDOW_HEIGHT ) ; frame . setLocationByPlatform ( true ) ; maybeStartServer ( ) ; } private String getLabel ( String key ) { return Tools . getLabel ( messages . getString ( key ) ) ; } private int getMnemonic ( String key ) { return Tools . getMnemonic ( messages . getString ( key ) ) ; } private KeyStroke getMenuKeyStroke ( int keyEvent ) { return KeyStroke . getKeyStroke ( keyEvent , Toolkit . getDefaultToolkit ( ) . getMenuShortcutKeyMask ( ) ) ; } private JMenuBar createMenuBar ( ) { JMenuBar menuBar = new JMenuBar ( ) ; final JMenu fileMenu = new JMenu ( getLabel ( "guiMenuFile" ) ) ; fileMenu . setMnemonic ( getMnemonic ( "guiMenuFile" ) ) ; final JMenu editMenu = new JMenu ( getLabel ( "guiMenuEdit" ) ) ; editMenu . setMnemonic ( getMnemonic ( "guiMenuEdit" ) ) ; final JMenu grammarMenu = new JMenu ( getLabel ( "guiMenuGrammar" ) ) ; grammarMenu . setMnemonic ( getMnemonic ( "guiMenuGrammar" ) ) ; final JMenu helpMenu = new JMenu ( getLabel ( "guiMenuHelp" ) ) ; helpMenu . setMnemonic ( getMnemonic ( "guiMenuHelp" ) ) ; fileMenu . add ( openAction ) ; fileMenu . add ( saveAction ) ; fileMenu . add ( saveAsAction ) ; fileMenu . addSeparator ( ) ; fileMenu . add ( new HideAction ( ) ) ; fileMenu . addSeparator ( ) ; fileMenu . add ( new QuitAction ( ) ) ; grammarMenu . add ( checkAction ) ; JCheckBoxMenuItem item = new JCheckBoxMenuItem ( autoCheckAction ) ; grammarMenu . add ( item ) ; grammarMenu . add ( new CheckClipboardAction ( ) ) ; grammarMenu . add ( new TagTextAction ( ) ) ; grammarMenu . add ( new AddRulesAction ( ) ) ; grammarMenu . add ( new OptionsAction ( ) ) ; grammarMenu . add ( new SelectFontAction ( ) ) ; JMenu lafMenu = new JMenu ( messages . getString ( "guiLookAndFeelMenu" ) ) ; UIManager . LookAndFeelInfo [ ] lafInfo = UIManager . getInstalledLookAndFeels ( ) ; ButtonGroup buttonGroup = new ButtonGroup ( ) ; for ( UIManager . LookAndFeelInfo laf : lafInfo ) { if ( ! "Nimbus" . equals ( laf . getName ( ) ) ) { continue ; } addLookAndFeelMenuItem ( lafMenu , laf , buttonGroup ) ; } for ( UIManager . LookAndFeelInfo laf : lafInfo ) { if ( "Nimbus" . equals ( laf . getName ( ) ) ) { continue ; } addLookAndFeelMenuItem ( lafMenu , laf , buttonGroup ) ; } grammarMenu . add ( lafMenu ) ; helpMenu . add ( new AboutAction ( ) ) ; undoRedo . undoAction . putValue ( Action . NAME , getLabel ( "guiMenuUndo" ) ) ; undoRedo . undoAction . putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuUndo" ) ) ; undoRedo . redoAction . putValue ( Action . NAME , getLabel ( "guiMenuRedo" ) ) ; undoRedo . redoAction . putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuRedo" ) ) ; editMenu . add ( undoRedo . undoAction ) ; editMenu . add ( undoRedo . redoAction ) ; editMenu . addSeparator ( ) ; Action cutAction = new DefaultEditorKit . CutAction ( ) ; cutAction . putValue ( Action . SMALL_ICON , getImageIcon ( "sc_cut.png" ) ) ; cutAction . putValue ( Action . LARGE_ICON_KEY , getImageIcon ( "lc_cut.png" ) ) ; cutAction . putValue ( Action . NAME , getLabel ( "guiMenuCut" ) ) ; cutAction . putValue ( Action . MNEMONIC_KEY , KeyEvent . VK_T ) ; editMenu . add ( cutAction ) ; Action copyAction = new DefaultEditorKit . CopyAction ( ) ; copyAction . putValue ( Action . SMALL_ICON , getImageIcon ( "sc_copy.png" ) ) ; copyAction . putValue ( Action . LARGE_ICON_KEY , getImageIcon ( "lc_copy.png" ) ) ; copyAction . putValue ( Action . NAME , getLabel ( "guiMenuCopy" ) ) ; copyAction . putValue ( Action . MNEMONIC_KEY , KeyEvent . VK_C ) ; editMenu . add ( copyAction ) ; Action pasteAction = new DefaultEditorKit . PasteAction ( ) ; pasteAction . putValue ( Action . SMALL_ICON , getImageIcon ( "sc_paste.png" ) ) ; pasteAction . putValue ( Action . LARGE_ICON_KEY , getImageIcon ( "lc_paste.png" ) ) ; pasteAction . putValue ( Action . NAME , getLabel ( "guiMenuPaste" ) ) ; pasteAction . putValue ( Action . MNEMONIC_KEY , KeyEvent . VK_P ) ; editMenu . add ( pasteAction ) ; editMenu . addSeparator ( ) ; editMenu . add ( new SelectAllAction ( ) ) ; menuBar . add ( fileMenu ) ; menuBar . add ( editMenu ) ; menuBar . add ( grammarMenu ) ; menuBar . add ( helpMenu ) ; return menuBar ; } private void addLookAndFeelMenuItem ( JMenu lafMenu , UIManager . LookAndFeelInfo laf , ButtonGroup buttonGroup ) { JRadioButtonMenuItem lfItem = new JRadioButtonMenuItem ( new SelectLFAction ( laf ) ) ; lafMenu . add ( lfItem ) ; buttonGroup . add ( lfItem ) ; if ( laf . getName ( ) . equals ( UIManager . getLookAndFeel ( ) . getName ( ) ) ) { buttonGroup . setSelected ( lfItem . getModel ( ) , true ) ; } } private void setLookAndFeel ( ) { String lookAndFeelName = null ; String className = null ; try { Configuration config = new Configuration ( new File ( System . getProperty ( "user.home" ) ) , LanguageToolSupport . CONFIG_FILE , null ) ; if ( config . getLookAndFeelName ( ) != null ) { lookAndFeelName = config . getLookAndFeelName ( ) ; } } catch ( IOException ex ) { } if ( lookAndFeelName == null ) { lookAndFeelName = "Nimbus" ; } for ( UIManager . LookAndFeelInfo info : UIManager . getInstalledLookAndFeels ( ) ) { if ( lookAndFeelName . equals ( info . getName ( ) ) ) { className = info . getClassName ( ) ; break ; } } if ( className != null ) { try { UIManager . setLookAndFeel ( className ) ; } catch ( Exception ignored ) { } } } private PopupMenu makePopupMenu ( ) { final PopupMenu popup = new PopupMenu ( ) ; final ActionListener rmbListener = new TrayActionRMBListener ( ) ; enableHttpServerItem = new CheckboxMenuItem ( Tools . getLabel ( messages . getString ( "tray_menu_enable_server" ) ) ) ; enableHttpServerItem . setState ( httpServer != null && httpServer . isRunning ( ) ) ; enableHttpServerItem . addItemListener ( new TrayActionItemListener ( ) ) ; popup . add ( enableHttpServerItem ) ; final MenuItem checkClipboardItem = new MenuItem ( Tools . getLabel ( messages . getString ( "guiMenuCheckClipboard" ) ) ) ; checkClipboardItem . addActionListener ( rmbListener ) ; popup . add ( checkClipboardItem ) ; final MenuItem restoreItem = new MenuItem ( Tools . getLabel ( messages . getString ( "guiMenuShowMainWindow" ) ) ) ; restoreItem . addActionListener ( rmbListener ) ; popup . add ( restoreItem ) ; final MenuItem exitItem = new MenuItem ( Tools . getLabel ( messages . getString ( "guiMenuQuit" ) ) ) ; exitItem . addActionListener ( rmbListener ) ; popup . add ( exitItem ) ; return popup ; } private void checkClipboardText ( ) { final String s = getClipboardText ( ) ; textArea . setText ( s ) ; } private void hideToTray ( ) { if ( ! isInTray ) { final SystemTray tray = SystemTray . getSystemTray ( ) ; final String iconPath = tray . getTrayIconSize ( ) . height > 16 ? TRAY_ICON : TRAY_SMALL_ICON ; final URL iconUrl = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( iconPath ) ; final Image img = Toolkit . getDefaultToolkit ( ) . getImage ( iconUrl ) ; final PopupMenu popup = makePopupMenu ( ) ; try { trayIcon = new TrayIcon ( img , TRAY_TOOLTIP , popup ) ; trayIcon . addMouseListener ( new TrayActionListener ( ) ) ; setTrayIcon ( ) ; tray . add ( trayIcon ) ; } catch ( AWTException e1 ) { Tools . showError ( e1 ) ; } } isInTray = true ; frame . setVisible ( false ) ; } private void tagText ( ) { if ( StringTools . isEmpty ( textArea . getText ( ) . trim ( ) ) ) { textArea . setText ( messages . getString ( "enterText2" ) ) ; return ; } setWaitCursor ( ) ; new Thread ( ) { @ Override public void run ( ) { try { tagTextAndDisplayResults ( ) ; } finally { SwingUtilities . invokeLater ( new Runnable ( ) { @ Override public void run ( ) { unsetWaitCursor ( ) ; } } ) ; } } } . start ( ) ; } private void quitOrHide ( ) { if ( closeHidesToTray ) { hideToTray ( ) ; } else { quit ( ) ; } } private void quit ( ) { stopServer ( ) ; try { Configuration config = ltSupport . getConfig ( ) ; config . setLanguage ( ltSupport . getLanguage ( ) ) ; config . saveConfiguration ( ltSupport . getLanguage ( ) ) ; } catch ( IOException e ) { Tools . showError ( e ) ; } frame . setVisible ( false ) ; JLanguageTool . removeTemporaryFiles ( ) ; System . exit ( 0 ) ; } private void setTrayIcon ( ) { if ( trayIcon != null ) { final SystemTray tray = SystemTray . getSystemTray ( ) ; final boolean httpServerRunning = httpServer != null && httpServer . isRunning ( ) ; final boolean smallTray = tray . getTrayIconSize ( ) . height <= 16 ; final String iconPath ; if ( httpServerRunning ) { trayIcon . setToolTip ( messages . getString ( "tray_tooltip_server_running" ) ) ; iconPath = smallTray ? TRAY_SMALL_SERVER_ICON : TRAY_SERVER_ICON ; } else { trayIcon . setToolTip ( TRAY_TOOLTIP ) ; iconPath = smallTray ? TRAY_SMALL_ICON : TRAY_ICON ; } final URL iconUrl = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( iconPath ) ; final Image img = Toolkit . getDefaultToolkit ( ) . getImage ( iconUrl ) ; trayIcon . setImage ( img ) ; } } private void showGUI ( ) { frame . setVisible ( true ) ; } private void restoreFromTray ( ) { frame . setVisible ( true ) ; } private void restoreFromTrayAndCheck ( ) { final String s = getClipboardText ( ) ; restoreFromTray ( ) ; textArea . setText ( s ) ; } private String getClipboardText ( ) { Clipboard clipboard = Toolkit . getDefaultToolkit ( ) . getSystemSelection ( ) ; if ( clipboard == null ) { clipboard = Toolkit . getDefaultToolkit ( ) . getSystemClipboard ( ) ; } String s ; final Transferable data = clipboard . getContents ( this ) ; try { if ( data != null && data . isDataFlavorSupported ( DataFlavor . getTextPlainUnicodeFlavor ( ) ) ) { final DataFlavor df = DataFlavor . getTextPlainUnicodeFlavor ( ) ; try ( Reader sr = df . getReaderForText ( data ) ) { s = StringTools . readerToString ( sr ) ; } } else { s = "" ; } } catch ( Exception ex ) { s = data . toString ( ) ; } return s ; } private boolean maybeStartServer ( ) { Configuration config = ltSupport . getConfig ( ) ; if ( config . getRunServer ( ) ) { try { final HTTPServerConfig serverConfig = new HTTPServerConfig ( config . getServerPort ( ) , false ) ; httpServer = new HTTPServer ( serverConfig , true ) ; httpServer . run ( ) ; if ( enableHttpServerItem != null ) { enableHttpServerItem . setState ( httpServer . isRunning ( ) ) ; setTrayIcon ( ) ; } } catch ( PortBindingException e ) { JOptionPane . showMessageDialog ( null , e . getMessage ( ) , "Error" , JOptionPane . ERROR_MESSAGE ) ; } } return httpServer != null && httpServer . isRunning ( ) ; } private void stopServer ( ) { if ( httpServer != null ) { httpServer . stop ( ) ; if ( enableHttpServerItem != null ) { enableHttpServerItem . setState ( httpServer . isRunning ( ) ) ; setTrayIcon ( ) ; } httpServer = null ; } } private void checkTextAndDisplayResults ( ) { if ( StringTools . isEmpty ( textArea . getText ( ) . trim ( ) ) ) { textArea . setText ( messages . getString ( "enterText2" ) ) ; return ; } ltSupport . checkImmediately ( getFrame ( ) ) ; } private String getStackTraceAsHtml ( Exception e ) { return "<br><br><b><font color=\"red\">" + org . languagetool . tools . Tools . getFullStackTrace ( e ) . replace ( "\n" , "<br/>" ) + "</font></b><br>" ; } private void setWaitCursor ( ) { frame . setCursor ( Cursor . getPredefinedCursor ( Cursor . WAIT_CURSOR ) ) ; textArea . setCursor ( Cursor . getPredefinedCursor ( Cursor . WAIT_CURSOR ) ) ; resultArea . setCursor ( Cursor . getPredefinedCursor ( Cursor . WAIT_CURSOR ) ) ; } private void unsetWaitCursor ( ) { frame . setCursor ( Cursor . getDefaultCursor ( ) ) ; textArea . setCursor ( Cursor . getDefaultCursor ( ) ) ; resultArea . setCursor ( Cursor . getDefaultCursor ( ) ) ; } private void tagTextAndDisplayResults ( ) { final JLanguageTool langTool = ltSupport . getLanguageTool ( ) ; final List < String > sentences = langTool . sentenceTokenize ( textArea . getText ( ) ) ; final StringBuilder sb = new StringBuilder ( ) ; try { for ( String sent : sentences ) { final AnalyzedSentence analyzedText = langTool . getAnalyzedSentence ( sent ) ; final String analyzedTextString = StringTools . escapeHTML ( analyzedText . toString ( "," ) ) . replace ( "&lt;S&gt;" , "&lt;S&gt;<br>" ) . replace ( "[" , "<font color='" + TAG_COLOR + "'>[" ) . replace ( "]" , "]</font><br>" ) ; sb . append ( analyzedTextString ) . append ( '\n' ) ; } } catch ( Exception e ) { sb . append ( getStackTraceAsHtml ( e ) ) ; } SwingUtilities . invokeLater ( new Runnable ( ) { @ Override public void run ( ) { if ( taggerDialog == null ) { taggerDialog = new JDialog ( frame ) ; taggerDialog . setTitle ( messages . getString ( "taggerWindowTitle" ) ) ; taggerDialog . setDefaultCloseOperation ( JDialog . HIDE_ON_CLOSE ) ; taggerDialog . setResizable ( true ) ; taggerDialog . setSize ( 640 , 480 ) ; taggerDialog . setLocationRelativeTo ( frame ) ; KeyStroke stroke = KeyStroke . getKeyStroke ( KeyEvent . VK_ESCAPE , 0 ) ; ActionListener actionListener = new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent actionEvent ) { taggerDialog . setVisible ( false ) ; } } ; taggerDialog . getRootPane ( ) . registerKeyboardAction ( actionListener , stroke , JComponent . WHEN_IN_FOCUSED_WINDOW ) ; JPanel panel = new JPanel ( new GridBagLayout ( ) ) ; taggerDialog . add ( panel ) ; taggerArea = new JTextPane ( ) ; taggerArea . setContentType ( "text/html" ) ; taggerArea . setEditable ( false ) ; GridBagConstraints c = new GridBagConstraints ( ) ; c . gridx = 0 ; c . gridy = 0 ; c . weightx = 1.0 ; c . weighty = 1.0 ; c . insets = new Insets ( 8 , 8 , 4 , 8 ) ; c . fill = GridBagConstraints . BOTH ; panel . add ( new JScrollPane ( taggerArea ) , c ) ; c . gridx = 0 ; c . gridy = 1 ; c . weightx = 0.0 ; c . weighty = 0.0 ; c . insets = new Insets ( 4 , 8 , 8 , 8 ) ; c . fill = GridBagConstraints . NONE ; c . anchor = GridBagConstraints . EAST ; JButton closeButton = new JButton ( messages . getString ( "guiCloseButton" ) ) ; closeButton . addActionListener ( actionListener ) ; panel . add ( closeButton , c ) ; } taggerDialog . applyComponentOrientation ( ComponentOrientation . getOrientation ( ( ( Language ) languageBox . getSelectedItem ( ) ) . getLocale ( ) ) ) ; taggerDialog . setVisible ( true ) ; taggerArea . setText ( HTML_FONT_START + sb + HTML_FONT_END ) ; } } ) ; } private void setTrayMode ( boolean trayMode ) { this . closeHidesToTray = trayMode ; } public static void main ( final String [ ] args ) { if ( System . getSecurityManager ( ) == null ) { JnaTools . setBugWorkaroundProperty ( ) ; } final Main prg = new Main ( ) ; if ( args . length == 1 && ( args [ 0 ] . equals ( "-t" ) || args [ 0 ] . equals ( "--tray" ) ) ) { SwingUtilities . invokeLater ( new Runnable ( ) { @ Override public void run ( ) { try { prg . createGUI ( ) ; prg . setTrayMode ( true ) ; prg . hideToTray ( ) ; } catch ( Exception e ) { Tools . showError ( e ) ; System . exit ( 1 ) ; } } } ) ; } else if ( args . length == 0 || args . length == 1 ) { SwingUtilities . invokeLater ( new Runnable ( ) { @ Override public void run ( ) { try { prg . createGUI ( ) ; prg . showGUI ( ) ; if ( args . length == 1 ) { prg . loadFile ( new File ( args [ 0 ] ) ) ; } } catch ( Exception e ) { Tools . showError ( e ) ; } } } ) ; } else { System . out . println ( "Usage: java org.languagetool.gui.Main [-t|--tray]" ) ; System . out . println ( " or java org.languagetool.gui.Main [file]" ) ; System . out . println ( "Parameters:" ) ; System . out . println ( " -t, --tray: dock LanguageTool to system tray on startup" ) ; System . out . println ( " file: a plain text file to load on startup" ) ; } } private class ControlReturnTextCheckingListener implements KeyListener { @ Override public void keyTyped ( KeyEvent e ) { } @ Override public void keyReleased ( KeyEvent e ) { } @ Override public void keyPressed ( KeyEvent e ) { if ( e . getKeyCode ( ) == KeyEvent . VK_ENTER ) { if ( ( e . getModifiersEx ( ) & KeyEvent . CTRL_DOWN_MASK ) == KeyEvent . CTRL_DOWN_MASK ) { checkTextAndDisplayResults ( ) ; } } } } class TrayActionItemListener implements ItemListener { @ Override public void itemStateChanged ( ItemEvent e ) { try { final Configuration config = ltSupport . getConfig ( ) ; if ( e . getStateChange ( ) == ItemEvent . SELECTED ) { config . setRunServer ( true ) ; final boolean serverStarted = maybeStartServer ( ) ; enableHttpServerItem . setState ( serverStarted ) ; config . setRunServer ( serverStarted ) ; config . saveConfiguration ( ltSupport . getLanguage ( ) ) ; } else if ( e . getStateChange ( ) == ItemEvent . DESELECTED ) { config . setRunServer ( false ) ; config . saveConfiguration ( ltSupport . getLanguage ( ) ) ; stopServer ( ) ; } } catch ( IOException ex ) { Tools . showError ( ex ) ; } } } class TrayActionRMBListener implements ActionListener { @ Override public void actionPerformed ( ActionEvent e ) { if ( isCommand ( e , "guiMenuCheckClipboard" ) ) { restoreFromTrayAndCheck ( ) ; } else if ( isCommand ( e , "guiMenuShowMainWindow" ) ) { restoreFromTray ( ) ; } else if ( isCommand ( e , "guiMenuQuit" ) ) { quit ( ) ; } else { JOptionPane . showMessageDialog ( null , "Unknown action: " + e . getActionCommand ( ) , "Error" , JOptionPane . ERROR_MESSAGE ) ; } } private boolean isCommand ( ActionEvent e , String label ) { return e . getActionCommand ( ) . equalsIgnoreCase ( Tools . getLabel ( messages . getString ( label ) ) ) ; } } class TrayActionListener implements MouseListener { @ Override public void mouseClicked ( @ SuppressWarnings ( "unused" ) MouseEvent e ) { if ( frame . isVisible ( ) && frame . isActive ( ) ) { frame . setVisible ( false ) ; } else if ( frame . isVisible ( ) && ! frame . isActive ( ) ) { frame . toFront ( ) ; restoreFromTrayAndCheck ( ) ; } else { restoreFromTrayAndCheck ( ) ; } } @ Override public void mouseEntered ( @ SuppressWarnings ( "unused" ) MouseEvent e ) { } @ Override public void mouseExited ( @ SuppressWarnings ( "unused" ) MouseEvent e ) { } @ Override public void mousePressed ( @ SuppressWarnings ( "unused" ) MouseEvent e ) { } @ Override public void mouseReleased ( @ SuppressWarnings ( "unused" ) MouseEvent e ) { } } class CloseListener implements WindowListener { @ Override public void windowClosing ( @ SuppressWarnings ( "unused" ) WindowEvent e ) { quitOrHide ( ) ; } @ Override public void windowActivated ( @ SuppressWarnings ( "unused" ) WindowEvent e ) { } @ Override public void windowClosed ( @ SuppressWarnings ( "unused" ) WindowEvent e ) { } @ Override public void windowDeactivated ( @ SuppressWarnings ( "unused" ) WindowEvent e ) { } @ Override public void windowDeiconified ( @ SuppressWarnings ( "unused" ) WindowEvent e ) { } @ Override public void windowIconified ( @ SuppressWarnings ( "unused" ) WindowEvent e ) { } @ Override public void windowOpened ( @ SuppressWarnings ( "unused" ) WindowEvent e ) { } } static class PlainTextFileFilter extends FileFilter { @ Override public boolean accept ( final File f ) { final boolean isTextFile = f . getName ( ) . toLowerCase ( ) . endsWith ( ".txt" ) ; return isTextFile || f . isDirectory ( ) ; } @ Override public String getDescription ( ) { return "*.txt" ; } } class OpenAction extends AbstractAction { OpenAction ( ) { super ( getLabel ( "guiMenuOpen" ) ) ; putValue ( Action . SHORT_DESCRIPTION , messages . getString ( "guiMenuOpenShortDesc" ) ) ; putValue ( Action . LONG_DESCRIPTION , messages . getString ( "guiMenuOpenLongDesc" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuOpen" ) ) ; putValue ( Action . ACCELERATOR_KEY , getMenuKeyStroke ( KeyEvent . VK_O ) ) ; putValue ( Action . SMALL_ICON , getImageIcon ( "sc_open.png" ) ) ; putValue ( Action . LARGE_ICON_KEY , getImageIcon ( "lc_open.png" ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { loadFile ( ) ; } } class SaveAction extends AbstractAction { SaveAction ( ) { super ( getLabel ( "guiMenuSave" ) ) ; putValue ( Action . SHORT_DESCRIPTION , messages . getString ( "guiMenuSaveShortDesc" ) ) ; putValue ( Action . LONG_DESCRIPTION , messages . getString ( "guiMenuSaveLongDesc" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuSave" ) ) ; putValue ( Action . ACCELERATOR_KEY , KeyStroke . getKeyStroke ( KeyEvent . VK_S , Toolkit . getDefaultToolkit ( ) . getMenuShortcutKeyMask ( ) ) ) ; putValue ( Action . SMALL_ICON , getImageIcon ( "sc_save.png" ) ) ; putValue ( Action . LARGE_ICON_KEY , getImageIcon ( "lc_save.png" ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { saveFile ( false ) ; } } class SaveAsAction extends AbstractAction { SaveAsAction ( ) { super ( getLabel ( "guiMenuSaveAs" ) ) ; putValue ( Action . SHORT_DESCRIPTION , messages . getString ( "guiMenuSaveAsShortDesc" ) ) ; putValue ( Action . LONG_DESCRIPTION , messages . getString ( "guiMenuSaveAsLongDesc" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuSaveAs" ) ) ; putValue ( Action . SMALL_ICON , getImageIcon ( "sc_saveas.png" ) ) ; putValue ( Action . LARGE_ICON_KEY , getImageIcon ( "lc_saveas.png" ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { saveFile ( true ) ; } } class CheckClipboardAction extends AbstractAction { CheckClipboardAction ( ) { super ( getLabel ( "guiMenuCheckClipboard" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuCheckClipboard" ) ) ; putValue ( Action . ACCELERATOR_KEY , getMenuKeyStroke ( KeyEvent . VK_Y ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { checkClipboardText ( ) ; } } class TagTextAction extends AbstractAction { TagTextAction ( ) { super ( getLabel ( "guiTagText" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiTagText" ) ) ; putValue ( Action . ACCELERATOR_KEY , getMenuKeyStroke ( KeyEvent . VK_T ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { tagText ( ) ; } } class AddRulesAction extends AbstractAction { AddRulesAction ( ) { super ( getLabel ( "guiMenuAddRules" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuAddRules" ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { try { addLanguage ( ) ; } catch ( Exception ex ) { Tools . showError ( ex ) ; } } } class OptionsAction extends AbstractAction { OptionsAction ( ) { super ( getLabel ( "guiMenuOptions" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuOptions" ) ) ; putValue ( Action . ACCELERATOR_KEY , getMenuKeyStroke ( KeyEvent . VK_S ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { showOptions ( ) ; } } class SelectFontAction extends AbstractAction { SelectFontAction ( ) { super ( getLabel ( "guiSelectFont" ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { showSelectFontDialog ( ) ; } } class SelectLFAction extends AbstractAction { private final UIManager . LookAndFeelInfo lf ; SelectLFAction ( UIManager . LookAndFeelInfo lf ) { super ( lf . getName ( ) ) ; this . lf = lf ; } @ Override public void actionPerformed ( ActionEvent e ) { try { UIManager . setLookAndFeel ( lf . getClassName ( ) ) ; SwingUtilities . updateComponentTreeUI ( frame ) ; frame . pack ( ) ; ltSupport . getConfig ( ) . setLookAndFeelName ( lf . getName ( ) ) ; } catch ( ClassNotFoundException | InstantiationException | IllegalAccessException | UnsupportedLookAndFeelException ex ) { Tools . showError ( ex ) ; } } } class HideAction extends AbstractAction { HideAction ( ) { super ( getLabel ( "guiMenuHide" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuHide" ) ) ; putValue ( Action . ACCELERATOR_KEY , getMenuKeyStroke ( KeyEvent . VK_D ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { hideToTray ( ) ; } } class QuitAction extends AbstractAction { QuitAction ( ) { super ( getLabel ( "guiMenuQuit" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuQuit" ) ) ; putValue ( Action . ACCELERATOR_KEY , getMenuKeyStroke ( KeyEvent . VK_Q ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { quit ( ) ; } } class AboutAction extends AbstractAction { AboutAction ( ) { super ( getLabel ( "guiMenuAbout" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "guiMenuAbout" ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { AboutDialog about = new AboutDialog ( messages , getFrame ( ) ) ; about . show ( ) ; } } class CheckAction extends AbstractAction { CheckAction ( ) { super ( getLabel ( "checkText" ) ) ; putValue ( Action . SHORT_DESCRIPTION , messages . getString ( "checkTextShortDesc" ) ) ; putValue ( Action . LONG_DESCRIPTION , messages . getString ( "checkTextLongDesc" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "checkText" ) ) ; putValue ( Action . SMALL_ICON , getImageIcon ( "sc_spelldialog.png" ) ) ; putValue ( Action . LARGE_ICON_KEY , getImageIcon ( "lc_spelldialog.png" ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { checkTextAndDisplayResults ( ) ; } } class AutoCheckAction extends AbstractAction { private boolean enable ; AutoCheckAction ( boolean initial ) { super ( getLabel ( "autoCheckText" ) ) ; putValue ( Action . SHORT_DESCRIPTION , messages . getString ( "autoCheckTextShortDesc" ) ) ; putValue ( Action . LONG_DESCRIPTION , messages . getString ( "autoCheckTextLongDesc" ) ) ; putValue ( Action . MNEMONIC_KEY , getMnemonic ( "autoCheckText" ) ) ; putValue ( Action . SMALL_ICON , getImageIcon ( "sc_spellonline.png" ) ) ; putValue ( Action . LARGE_ICON_KEY , getImageIcon ( "lc_spellonline.png" ) ) ; enable = initial ; putValue ( Action . SELECTED_KEY , enable ) ; } @ Override public void actionPerformed ( ActionEvent e ) { enable = ! enable ; putValue ( Action . SELECTED_KEY , enable ) ; ltSupport . setBackgroundCheckEnabled ( enable ) ; } } class ClearTextAction extends AbstractAction { ClearTextAction ( ) { super ( getLabel ( "clearText" ) ) ; putValue ( Action . SHORT_DESCRIPTION , messages . getString ( "clearText" ) ) ; putValue ( Action . SMALL_ICON , getImageIcon ( "sc_closedoc.png" ) ) ; putValue ( Action . LARGE_ICON_KEY , getImageIcon ( "lc_closedoc.png" ) ) ; } @ Override public void actionPerformed ( ActionEvent e ) { ltSupport . getTextComponent ( ) . setText ( "" ) ; } } private class SelectAllAction extends TextAction { private SelectAllAction ( ) { super ( getLabel ( "guiMenuSelectAll" ) ) ; putValue ( Action . MNEMONIC_KEY , KeyEvent . VK_A ) ; } @ Override public void actionPerformed ( ActionEvent e ) { JTextComponent component = getFocusedComponent ( ) ; component . selectAll ( ) ; } } private ImageIcon getImageIcon ( String filename ) { Image image = Toolkit . getDefaultToolkit ( ) . getImage ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( filename ) ) ; return new ImageIcon ( image ) ; } }
package org . languagetool . gui ; import java . util . EventListener ; interface LanguageToolListener extends EventListener { public void languageToolEventOccurred ( LanguageToolEvent event ) ; }
package org . languagetool . gui ; import java . util . Comparator ; import java . util . ResourceBundle ; import org . languagetool . Language ; class LanguageComparator implements Comparator < Language > { private final ResourceBundle messages ; private final String extLangSuffix ; LanguageComparator ( ResourceBundle messages , String extLangSuffix ) { this . messages = messages ; this . extLangSuffix = extLangSuffix ; } @ Override public int compare ( Language o1 , Language o2 ) { return getTranslatedName ( o1 ) . compareTo ( getTranslatedName ( o2 ) ) ; } private String getTranslatedName ( Language language ) { if ( language . isExternal ( ) ) { return language . getName ( ) + extLangSuffix ; } else { return language . getTranslatedName ( messages ) ; } } }
package org . languagetool . gui ; class LanguageToolEvent { public enum Type { CHECKING_STARTED , CHECKING_FINISHED , LANGUAGE_CHANGED , RULE_DISABLED , RULE_ENABLED } private final LanguageToolSupport source ; private final Type type ; private final Object caller ; LanguageToolEvent ( LanguageToolSupport source , Type type , Object caller ) { this . source = source ; this . type = type ; this . caller = caller ; } LanguageToolSupport getSource ( ) { return source ; } Object getCaller ( ) { return caller ; } Type getType ( ) { return type ; } }
package org . languagetool . gui ; import org . languagetool . rules . Rule ; class RuleLink { private static final String DEACTIVATE_URL = "http://languagetool.org/deactivate/" ; private static final String REACTIVATE_URL = "http://languagetool.org/reactivate/" ; private final String urlPrefix ; private final String id ; private RuleLink ( String urlPrefix , String id ) { this . urlPrefix = urlPrefix ; this . id = id ; } static RuleLink buildDeactivationLink ( Rule rule ) { return new RuleLink ( DEACTIVATE_URL , rule . getId ( ) ) ; } static RuleLink buildReactivationLink ( Rule rule ) { return new RuleLink ( REACTIVATE_URL , rule . getId ( ) ) ; } static RuleLink getFromString ( String ruleLink ) { final String id ; if ( ruleLink . startsWith ( DEACTIVATE_URL ) ) { id = ruleLink . substring ( DEACTIVATE_URL . length ( ) ) ; return new RuleLink ( DEACTIVATE_URL , id ) ; } else if ( ruleLink . startsWith ( REACTIVATE_URL ) ) { id = ruleLink . substring ( REACTIVATE_URL . length ( ) ) ; return new RuleLink ( REACTIVATE_URL , id ) ; } else { throw new RuntimeException ( "Unknown link prefix: " + ruleLink ) ; } } String getId ( ) { return id ; } @ Override public String toString ( ) { return urlPrefix + id ; } }
package org . languagetool . gui ; import javax . swing . * ; import javax . swing . text . MutableAttributeSet ; import javax . swing . text . html . HTML ; import javax . swing . text . html . HTMLEditorKit ; import javax . swing . text . html . parser . ParserDelegator ; import java . awt . datatransfer . Clipboard ; import java . awt . datatransfer . DataFlavor ; import java . awt . datatransfer . Transferable ; import java . awt . datatransfer . UnsupportedFlavorException ; import java . io . IOException ; import java . io . Reader ; import java . io . StringReader ; class RetainLineBreakTransferHandler extends TransferHandler { @ Override protected Transferable createTransferable ( JComponent c ) { final JEditorPane pane = ( JEditorPane ) c ; final String htmlText = pane . getText ( ) ; final String plainText = extractText ( new StringReader ( htmlText ) ) ; return new MyTransferable ( plainText , htmlText ) ; } private String extractText ( Reader reader ) { final StringBuilder result = new StringBuilder ( ) ; final HTMLEditorKit . ParserCallback parserCallback = new HTMLEditorKit . ParserCallback ( ) { @ Override public void handleText ( final char [ ] data , final int pos ) { result . append ( data ) ; } @ Override public void handleStartTag ( HTML . Tag tag , MutableAttributeSet attribute , int pos ) { } @ Override public void handleEndTag ( HTML . Tag tag , final int pos ) { } @ Override public void handleSimpleTag ( HTML . Tag tag , MutableAttributeSet a , final int pos ) { if ( tag . equals ( HTML . Tag . BR ) ) { result . append ( '\n' ) ; } } @ Override public void handleComment ( final char [ ] data , final int pos ) { } @ Override public void handleError ( final String errMsg , final int pos ) { } } ; try { new ParserDelegator ( ) . parse ( reader , parserCallback , true ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } return result . toString ( ) ; } @ Override public void exportToClipboard ( JComponent comp , Clipboard clip , int action ) throws IllegalStateException { if ( action == COPY ) { clip . setContents ( this . createTransferable ( comp ) , null ) ; } } @ Override public int getSourceActions ( JComponent c ) { return COPY ; } static class MyTransferable implements Transferable { private static final DataFlavor [ ] supportedFlavors ; static { try { supportedFlavors = new DataFlavor [ ] { new DataFlavor ( "text/html;class=java.lang.String" ) , new DataFlavor ( "text/plain;class=java.lang.String" ) } ; } catch ( ClassNotFoundException e ) { throw new ExceptionInInitializerError ( e ) ; } } private final String plainData ; private final String htmlData ; MyTransferable ( String plainData , String htmlData ) { this . plainData = plainData ; this . htmlData = htmlData ; } @ Override public DataFlavor [ ] getTransferDataFlavors ( ) { return supportedFlavors ; } @ Override public boolean isDataFlavorSupported ( DataFlavor flavor ) { for ( DataFlavor supportedFlavor : supportedFlavors ) { if ( supportedFlavor == flavor ) { return true ; } } return false ; } @ Override public Object getTransferData ( DataFlavor flavor ) throws UnsupportedFlavorException { if ( flavor . equals ( supportedFlavors [ 0 ] ) ) { return htmlData ; } if ( flavor . equals ( supportedFlavors [ 1 ] ) ) { return plainData ; } throw new UnsupportedFlavorException ( flavor ) ; } } }
package org . languagetool . gui ; import java . awt . Cursor ; import java . awt . Desktop ; import java . io . IOException ; import java . net . URL ; import java . util . ArrayList ; import java . util . List ; import java . util . ResourceBundle ; import java . util . Set ; import javax . swing . JTextPane ; import javax . swing . event . HyperlinkEvent ; import javax . swing . event . HyperlinkListener ; import org . apache . commons . lang . StringUtils ; import org . languagetool . Language ; import org . languagetool . rules . ITSIssueType ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tools . ContextTools ; import org . languagetool . tools . StringTools ; class ResultArea { private static final String DEACTIVATE_URL = "http://languagetool.org/deactivate/" ; private static final String REACTIVATE_URL = "http://languagetool.org/reactivate/" ; private static final String LT_ERROR_MARKER_START = "<b><font bgcolor=\"#d7d7ff\">" ; private static final String SPELL_ERROR_MARKER_START = "<b><font bgcolor=\"#ffd7d7\">" ; private final ResourceBundle messages ; private final JTextPane statusPane ; private final LanguageToolSupport ltSupport ; private final Object marker = new Object ( ) ; private String inputText ; private String startText ; private List < RuleMatch > allRuleMatches ; private List < RuleMatch > ruleMatches ; private long runTime ; ResultArea ( final ResourceBundle messages , final LanguageToolSupport ltSupport , final JTextPane statusPane ) { this . messages = messages ; this . ltSupport = ltSupport ; this . statusPane = statusPane ; statusPane . setContentType ( "text/html" ) ; statusPane . setText ( Main . HTML_GREY_FONT_START + messages . getString ( "resultAreaText" ) + Main . HTML_FONT_END ) ; statusPane . setEditable ( false ) ; statusPane . addHyperlinkListener ( new MyHyperlinkListener ( ) ) ; statusPane . setTransferHandler ( new RetainLineBreakTransferHandler ( ) ) ; ltSupport . addLanguageToolListener ( new LanguageToolListener ( ) { @ Override public void languageToolEventOccurred ( LanguageToolEvent event ) { if ( event . getType ( ) == LanguageToolEvent . Type . CHECKING_STARTED ) { final Language lang = ltSupport . getLanguage ( ) ; final String langName ; if ( lang . isExternal ( ) ) { langName = lang . getTranslatedName ( messages ) + Main . EXTERNAL_LANGUAGE_SUFFIX ; } else { langName = lang . getTranslatedName ( messages ) ; } final String startCheckText = Main . HTML_GREY_FONT_START + Tools . makeTexti18n ( messages , "startChecking" , langName ) + "..." + Main . HTML_FONT_END ; statusPane . setText ( startCheckText ) ; setStartText ( startCheckText ) ; if ( event . getCaller ( ) == marker ) { statusPane . setCursor ( Cursor . getPredefinedCursor ( Cursor . WAIT_CURSOR ) ) ; } } else if ( event . getType ( ) == LanguageToolEvent . Type . CHECKING_FINISHED ) { inputText = event . getSource ( ) . getTextComponent ( ) . getText ( ) ; setRuleMatches ( event . getSource ( ) . getMatches ( ) ) ; if ( event . getCaller ( ) == marker || event . getCaller ( ) == null ) { displayResult ( ) ; if ( event . getCaller ( ) == marker ) { statusPane . setCursor ( Cursor . getDefaultCursor ( ) ) ; } } } else if ( event . getType ( ) == LanguageToolEvent . Type . RULE_DISABLED || event . getType ( ) == LanguageToolEvent . Type . RULE_ENABLED ) { inputText = event . getSource ( ) . getTextComponent ( ) . getText ( ) ; setRuleMatches ( event . getSource ( ) . getMatches ( ) ) ; displayResult ( ) ; } } } ) ; } private String getRuleMatchHtml ( List < RuleMatch > ruleMatches , String text , String startCheckText ) { final ContextTools contextTools = new ContextTools ( ) ; final StringBuilder sb = new StringBuilder ( 200 ) ; sb . append ( startCheckText ) ; sb . append ( "<br>\n" ) ; int i = 0 ; for ( final RuleMatch match : ruleMatches ) { final String output = Tools . makeTexti18n ( messages , "result1" , i + 1 , match . getLine ( ) + 1 , match . getColumn ( ) ) ; sb . append ( output ) ; final String msg = match . getMessage ( ) . replaceAll ( "<suggestion>" , "<b>" ) . replaceAll ( "</suggestion>" , "</b>" ) . replaceAll ( "<old>" , "<b>" ) . replaceAll ( "</old>" , "</b>" ) ; sb . append ( "<b>" ) . append ( messages . getString ( "errorMessage" ) ) . append ( "</b> " ) ; sb . append ( msg ) ; final RuleLink ruleLink = RuleLink . buildDeactivationLink ( match . getRule ( ) ) ; sb . append ( " <a href=\"" ) . append ( ruleLink ) . append ( "\">" ) . append ( messages . getString ( "deactivateRule" ) ) . append ( "</a><br>\n" ) ; if ( match . getSuggestedReplacements ( ) . size ( ) > 0 ) { final String replacement = StringTools . listToString ( match . getSuggestedReplacements ( ) , "; " ) ; sb . append ( "<b>" ) . append ( messages . getString ( "correctionMessage" ) ) . append ( "</b> " ) . append ( replacement ) . append ( "<br>\n" ) ; } if ( ITSIssueType . Misspelling . equals ( match . getRule ( ) . getLocQualityIssueType ( ) ) ) { contextTools . setErrorMarkerStart ( SPELL_ERROR_MARKER_START ) ; } else { contextTools . setErrorMarkerStart ( LT_ERROR_MARKER_START ) ; } final String context = contextTools . getContext ( match . getFromPos ( ) , match . getToPos ( ) , text ) ; sb . append ( "<b>" ) . append ( messages . getString ( "errorContext" ) ) . append ( "</b> " ) . append ( context ) ; sb . append ( "<br>\n" ) ; if ( match . getRule ( ) . getUrl ( ) != null && Desktop . isDesktopSupported ( ) ) { sb . append ( "<b>" ) . append ( messages . getString ( "moreInfo" ) ) . append ( "</b> <a href=\"" ) ; final String url = match . getRule ( ) . getUrl ( ) . toString ( ) ; sb . append ( url ) ; final String shortUrl = StringUtils . abbreviate ( url , 60 ) ; sb . append ( "\">" ) . append ( shortUrl ) . append ( "</a><br>\n" ) ; } i ++ ; } sb . append ( Main . HTML_GREY_FONT_START ) ; sb . append ( getDisabledRulesHtml ( ) ) ; final String checkDone = Tools . makeTexti18n ( messages , "checkDone" , ruleMatches . size ( ) , runTime ) ; sb . append ( "<br>\n" ) . append ( checkDone ) ; sb . append ( "<br>\n" ) . append ( messages . getString ( "makeLanguageToolBetter" ) ) ; sb . append ( Main . HTML_FONT_END ) . append ( "<br>\n" ) ; return sb . toString ( ) ; } private String getDisabledRulesHtml ( ) { final StringBuilder sb = new StringBuilder ( 40 ) ; sb . append ( messages . getString ( "deactivatedRulesText" ) ) ; int i = 0 ; int deactivatedRuleCount = 0 ; for ( String ruleId : ltSupport . getConfig ( ) . getDisabledRuleIds ( ) ) { if ( ruleId . trim ( ) . isEmpty ( ) ) { continue ; } final Rule rule = ltSupport . getRuleForId ( ruleId ) ; if ( rule == null || rule . isDefaultOff ( ) ) { continue ; } if ( i ++ > 0 ) { sb . append ( ',' ) ; } final RuleLink reactivationLink = RuleLink . buildReactivationLink ( rule ) ; sb . append ( " <a href=\"" ) . append ( reactivationLink ) . append ( "\">" ) . append ( rule . getDescription ( ) ) . append ( "</a>" ) ; deactivatedRuleCount ++ ; } sb . append ( "<br>" ) ; if ( deactivatedRuleCount == 0 ) { return "" ; } else { return sb . toString ( ) ; } } private void setStartText ( String startText ) { this . startText = startText ; } void setRunTime ( long runTime ) { this . runTime = runTime ; } void setRuleMatches ( List < RuleMatch > ruleMatches ) { this . allRuleMatches = new ArrayList < > ( ruleMatches ) ; this . ruleMatches = new ArrayList < > ( ruleMatches ) ; } void displayResult ( ) { ruleMatches = filterRuleMatches ( ) ; final String ruleMatchHtml = getRuleMatchHtml ( ruleMatches , inputText , startText ) ; displayText ( ruleMatchHtml ) ; } private void displayText ( String text ) { statusPane . setText ( Main . HTML_FONT_START + text + Main . HTML_FONT_END ) ; statusPane . setCaretPosition ( 0 ) ; } private List < RuleMatch > filterRuleMatches ( ) { final List < RuleMatch > filtered = new ArrayList < > ( ) ; final Set < String > disabledRuleIds = ltSupport . getConfig ( ) . getDisabledRuleIds ( ) ; for ( RuleMatch ruleMatch : allRuleMatches ) { if ( ! disabledRuleIds . contains ( ruleMatch . getRule ( ) . getId ( ) ) ) { filtered . add ( ruleMatch ) ; } } return filtered ; } private class MyHyperlinkListener implements HyperlinkListener { private MyHyperlinkListener ( ) { } @ Override public void hyperlinkUpdate ( HyperlinkEvent e ) { if ( e . getEventType ( ) == HyperlinkEvent . EventType . ACTIVATED ) { final URL url = e . getURL ( ) ; try { final String uri = url . toURI ( ) . toString ( ) ; if ( uri . startsWith ( DEACTIVATE_URL ) || uri . startsWith ( REACTIVATE_URL ) ) { handleRuleLinkClick ( uri ) ; } else { handleHttpClick ( url ) ; } } catch ( Exception ex ) { throw new RuntimeException ( "Could not handle URL click: " + url , ex ) ; } } } private void handleRuleLinkClick ( String uri ) throws IOException { final RuleLink ruleLink = RuleLink . getFromString ( uri ) ; final String ruleId = ruleLink . getId ( ) ; if ( uri . startsWith ( DEACTIVATE_URL ) ) { ltSupport . disableRule ( ruleId ) ; } else { ltSupport . enableRule ( ruleId ) ; } ltSupport . getConfig ( ) . saveConfiguration ( ltSupport . getLanguage ( ) ) ; ltSupport . checkImmediately ( marker ) ; } private void handleHttpClick ( URL url ) { if ( Desktop . isDesktopSupported ( ) ) { try { final Desktop desktop = Desktop . getDesktop ( ) ; desktop . browse ( url . toURI ( ) ) ; } catch ( Exception ex ) { throw new RuntimeException ( "Could not open URL: " + url , ex ) ; } } } } }
package org . languagetool . gui ; import java . awt . ComponentOrientation ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; import java . util . Locale ; import java . util . ResourceBundle ; import javax . swing . JComboBox ; import org . languagetool . Language ; import org . languagetool . Languages ; public class LanguageComboBox extends JComboBox < Language > { private final List < Language > languages = new ArrayList < > ( ) ; private final LanguageComparator langComparator ; public LanguageComboBox ( ResourceBundle messages , String extLangSuffix ) { this . langComparator = new LanguageComparator ( messages , extLangSuffix ) ; populateLanguageBox ( ) ; } final void populateLanguageBox ( List < Language > externalLanguages ) { removeAllItems ( ) ; initAllLanguages ( externalLanguages ) ; } final void populateLanguageBox ( ) { populateLanguageBox ( Collections . < Language > emptyList ( ) ) ; } void selectLanguage ( Language language ) { for ( final Language lang : languages ) { if ( lang . toString ( ) . equals ( language . toString ( ) ) ) { setSelectedItem ( lang ) ; } } } private void initAllLanguages ( List < Language > externalLanguages ) { applyComponentOrientation ( ComponentOrientation . getOrientation ( Locale . getDefault ( ) ) ) ; languages . clear ( ) ; for ( Language language : Languages . get ( ) ) { final boolean skip = language . hasVariant ( ) ; final boolean simpleGermanWorkaround = language . getShortNameWithCountryAndVariant ( ) . equals ( "de-DE" ) ; if ( ! skip || simpleGermanWorkaround ) { languages . add ( language ) ; } } for ( Language externalLanguage : externalLanguages ) { addItem ( externalLanguage ) ; } Collections . sort ( languages , langComparator ) ; for ( final Language language : languages ) { addItem ( language ) ; } } }
package org . languagetool . dev ; import org . apache . lucene . document . Document ; import org . apache . lucene . index . DirectoryReader ; import org . apache . lucene . index . Term ; import org . apache . lucene . search . IndexSearcher ; import org . apache . lucene . search . Query ; import org . apache . lucene . search . ScoreDoc ; import org . apache . lucene . search . TermQuery ; import org . apache . lucene . store . FSDirectory ; import org . junit . Ignore ; import org . junit . Test ; import java . io . File ; import java . io . IOException ; import java . util . Scanner ; public class FrequencyIndexCreatorTest { private static final File INDEX_DIR = new File ( "/media/Data/google-ngram/3gram/lucene-index" ) ; @ Test @ Ignore ( "Interactive use only" ) public void testReadPerformance ( ) throws IOException { try ( FSDirectory directory = FSDirectory . open ( INDEX_DIR ) ) { DirectoryReader reader = DirectoryReader . open ( directory ) ; IndexSearcher searcher = new IndexSearcher ( reader ) ; try ( Scanner scanner = new Scanner ( new File ( "/lt/performance-test/en.txt" ) ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; String [ ] parts = line . split ( " " ) ; accessNgrams ( parts , searcher ) ; } } } } private void accessNgrams ( String [ ] parts , IndexSearcher searcher ) throws IOException { String prevPart = null ; String prevPrevPart = null ; for ( String part : parts ) { if ( prevPart != null && prevPrevPart != null ) { String ngram = prevPrevPart + " " + prevPart + " " + part ; long startTime = System . currentTimeMillis ( ) ; Query query = new TermQuery ( new Term ( "ngram" , ngram ) ) ; ScoreDoc [ ] hits = searcher . search ( query , null , 10 ) . scoreDocs ; for ( ScoreDoc hit : hits ) { Document hitDoc = searcher . doc ( hit . doc ) ; long runTime = System . currentTimeMillis ( ) - startTime ; System . out . println ( ngram + ": " + hitDoc . getField ( "count" ) . stringValue ( ) + " (" + runTime + "ms)" ) ; } } prevPrevPart = prevPart ; prevPart = part ; } } }
package org . languagetool . tagging . ro ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . TestTools ; import org . languagetool . language . Romanian ; import org . languagetool . tokenizers . WordTokenizer ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; public abstract class AbstractRomanianTaggerTest extends TestCase { private RomanianTagger tagger ; private WordTokenizer tokenizer ; @ Override public void setUp ( ) { tagger = createTagger ( ) ; tokenizer = new WordTokenizer ( ) ; } public void testDictionary ( ) throws IOException { TestTools . testDictionary ( tagger , new Romanian ( ) ) ; } protected RomanianTagger createTagger ( ) { return new RomanianTagger ( ) ; } protected void assertHasLemmaAndPos ( String inflected , String lemma , String posTag ) throws IOException { final List < AnalyzedTokenReadings > tags = tagger . tag ( Arrays . asList ( inflected ) ) ; final StringBuilder allTags = new StringBuilder ( ) ; boolean found = false ; for ( AnalyzedTokenReadings analyzedTokenReadings : tags ) { for ( AnalyzedToken token : analyzedTokenReadings ) { final String crtLemma = token . getLemma ( ) ; final String crtPOSTag = token . getPOSTag ( ) ; allTags . append ( String . format ( "[%s/%s]" , crtLemma , crtPOSTag ) ) ; found = ( lemma == null || lemma . equals ( crtLemma ) ) && ( posTag == null || posTag . equals ( crtPOSTag ) ) ; if ( found ) { break ; } } if ( found ) { break ; } } assertTrue ( String . format ( "Lemma and POS not found for word [%s]! " + "Expected [%s/%s]. Actual: %s" , inflected , lemma , posTag , allTags . toString ( ) ) , found ) ; } public RomanianTagger getTagger ( ) { return tagger ; } public WordTokenizer getTokenizer ( ) { return tokenizer ; } }
package org . languagetool . dev . eval ; import org . junit . Test ; import org . languagetool . rules . IncorrectExample ; import javax . xml . xpath . XPathExpressionException ; import static junit . framework . TestCase . assertFalse ; import static junit . framework . TestCase . assertTrue ; public class AfterTheDeadlineEvaluatorTest { @ Test public void testIsExpectedErrorFound ( ) throws XPathExpressionException { AfterTheDeadlineEvaluator evaluator = new AfterTheDeadlineEvaluator ( "fake" ) ; IncorrectExample example = new IncorrectExample ( "This <marker>is is</marker> a test" ) ; assertTrue ( evaluator . isExpectedErrorFound ( example , "<results><error><string>is is</string></error></results>" ) ) ; assertFalse ( evaluator . isExpectedErrorFound ( example , "<results><error><string>This is</string></error></results>" ) ) ; assertFalse ( evaluator . isExpectedErrorFound ( example , "<results></results>" ) ) ; assertTrue ( evaluator . isExpectedErrorFound ( example , "<results>" + "<error><string>foo bar</string></error>" + "<error><string>is is</string></error>" + "</results>" ) ) ; } }
package org . languagetool . dev . eval ; import com . google . common . io . CharStreams ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . language . LanguageIdentifier ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . io . InputStream ; import java . io . InputStreamReader ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; class LanguageDetectionEval { private final LanguageIdentifier languageIdentifier ; private int totalInputs = 0 ; private int totalFailures = 0 ; LanguageDetectionEval ( ) { languageIdentifier = new LanguageIdentifier ( ) ; } private void evaluate ( Language language ) throws IOException { if ( language . isVariant ( ) ) { return ; } String evalTextFile = "/org/languagetool/dev/eval/lang/" + language . getShortName ( ) + ".txt" ; InputStream stream = LanguageDetectionEval . class . getResourceAsStream ( evalTextFile ) ; System . out . println ( "=== " + language + " ===" ) ; if ( stream == null ) { throw new RuntimeException ( "No eval data found for " + language ) ; } else { int minChars = 0 ; int failures = 0 ; List < String > list = getLines ( stream ) ; for ( String line : list ) { try { int minChar = getShortestCorrectDetection ( line , language ) ; minChars += minChar ; } catch ( DetectionException e ) { failures ++ ; } } int avgMinChars = minChars / list . size ( ) ; System . out . println ( "Average minimum size still correctly detected: " + avgMinChars ) ; System . out . println ( "Detection failures: " + failures + " of " + list . size ( ) ) ; totalFailures += failures ; } } private int getShortestCorrectDetection ( String line , Language expectedLanguage ) { totalInputs ++ ; String [ ] tokens = line . split ( "\\s+" ) ; for ( int i = tokens . length ; i > 0 ; i -- ) { String text = StringTools . listToString ( Arrays . asList ( tokens ) . subList ( 0 , i ) , " " ) ; Language detectedLangObj = languageIdentifier . detectLanguage ( text ) ; String detectedLang = null ; if ( detectedLangObj != null ) { detectedLang = detectedLangObj . getShortName ( ) ; } if ( detectedLang == null && i == tokens . length ) { throw new DetectionException ( "Detection failed for '" + line + "', detected <null>" ) ; } else if ( detectedLang != null && ! expectedLanguage . getShortName ( ) . equals ( detectedLang ) ) { if ( i == tokens . length ) { throw new DetectionException ( "Detection failed for '" + line + "', detected " + detectedLang ) ; } else { int textLength = getTextLength ( tokens , i + 1 ) ; return textLength ; } } } return tokens [ 0 ] . length ( ) ; } private int getTextLength ( String [ ] tokens , int tokenPos ) { int i = 0 ; int charCount = 0 ; for ( String token : tokens ) { if ( i ++ > tokenPos ) { return charCount ; } charCount += token . length ( ) ; } return charCount ; } private List < String > getLines ( InputStream stream ) throws IOException { List < String > lines = CharStreams . readLines ( new InputStreamReader ( stream ) ) ; List < String > result = new ArrayList < > ( ) ; for ( String line : lines ) { if ( ! line . startsWith ( "#" ) ) { result . add ( line ) ; } } return result ; } public static void main ( String [ ] args ) throws IOException { LanguageDetectionEval eval = new LanguageDetectionEval ( ) ; long startTime = System . currentTimeMillis ( ) ; for ( Language language : Languages . get ( ) ) { eval . evaluate ( language ) ; } long endTime = System . currentTimeMillis ( ) ; System . out . println ( ) ; System . out . println ( "Time: " + ( endTime - startTime ) + "ms" ) ; System . out . println ( "Total detection failures: " + eval . totalFailures + "/" + eval . totalInputs ) ; } class DetectionException extends RuntimeException { DetectionException ( String s ) { super ( s ) ; } } }
package org . languagetool . dev . eval ; import com . optimaize . langdetect . ngram . NgramExtractors ; import com . optimaize . langdetect . profiles . LanguageProfile ; import com . optimaize . langdetect . profiles . LanguageProfileBuilder ; import com . optimaize . langdetect . profiles . LanguageProfileWriter ; import com . optimaize . langdetect . text . CommonTextObjectFactories ; import com . optimaize . langdetect . text . TextObject ; import com . optimaize . langdetect . text . TextObjectFactory ; import org . apache . commons . io . IOUtils ; import java . io . File ; import java . io . FileReader ; import java . io . IOException ; final class LanguageDetectionTrainer { public static void main ( String [ ] args ) throws IOException { if ( args . length != 3 ) { System . out . println ( "Usage: " + LanguageDetectionTrainer . class . getName ( ) + " <languageCode> <plainTextFile> <minimalFrequency>" ) ; System . exit ( 1 ) ; } String langCode = args [ 0 ] ; String fileName = args [ 1 ] ; int minimalFrequency = Integer . parseInt ( args [ 2 ] ) ; String text = IOUtils . toString ( new FileReader ( fileName ) ) ; TextObjectFactory textObjectFactory = CommonTextObjectFactories . forIndexingCleanText ( ) ; TextObject inputText = textObjectFactory . create ( ) . append ( text ) ; LanguageProfile languageProfile = new LanguageProfileBuilder ( langCode ) . ngramExtractor ( NgramExtractors . standard ( ) ) . minimalFrequency ( minimalFrequency ) . addText ( inputText ) . build ( ) ; File outputDir = new File ( System . getProperty ( "user.dir" ) ) ; new LanguageProfileWriter ( ) . writeToDirectory ( languageProfile , outputDir ) ; System . out . println ( "Language profile written to " + new File ( outputDir , langCode ) . getAbsolutePath ( ) ) ; } }
package org . languagetool . dev . eval ; import org . junit . Ignore ; import org . junit . Test ; import java . io . File ; import java . io . IOException ; import java . net . URL ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class RealWordCorpusEvaluatorTest { @ Ignore ( "requires local ngram index" ) @ Test public void testCheck ( ) throws IOException { RealWordCorpusEvaluator evaluator = new RealWordCorpusEvaluator ( new File ( "/data/google-ngram-index/" ) ) ; URL errors = RealWordCorpusEvaluatorTest . class . getResource ( "/org/languagetool/dev/eval" ) ; evaluator . run ( new File ( errors . getFile ( ) ) ) ; assertThat ( evaluator . getSentencesChecked ( ) , is ( 3 ) ) ; assertThat ( evaluator . getErrorsChecked ( ) , is ( 5 ) ) ; assertThat ( evaluator . getRealErrorsFound ( ) , is ( 3 ) ) ; assertThat ( evaluator . getRealErrorsFoundWithGoodSuggestion ( ) , is ( 2 ) ) ; } }
package org . languagetool . dev . errorcorpus ; import org . junit . Test ; import java . io . File ; import java . io . IOException ; import java . net . URL ; import java . util . Iterator ; import static junit . framework . TestCase . assertTrue ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertThat ; public class PedlerCorpusTest { @ Test public void testCorpusAccess ( ) throws IOException { URL errors = PedlerCorpusTest . class . getResource ( "/org/languagetool/dev/eval" ) ; PedlerCorpus corpus = new PedlerCorpus ( new File ( errors . getFile ( ) ) ) ; Iterator < ErrorSentence > iterator = corpus . iterator ( ) ; assertTrue ( iterator . hasNext ( ) ) ; ErrorSentence sentence1 = iterator . next ( ) ; assertThat ( sentence1 . getAnnotatedText ( ) . getPlainText ( ) , is ( "But also please not that grammar checkers aren't perfect." ) ) ; assertThat ( sentence1 . getMarkupText ( ) , is ( "But <ERR targ=foo>also</ERR> please <ERR targ=note>not</ERR> that grammar checkers aren't perfect." ) ) ; ErrorSentence sentence2 = iterator . next ( ) ; assertThat ( sentence2 . getAnnotatedText ( ) . getPlainText ( ) , is ( "But also also please note note that grammar checkers aren't perfect." ) ) ; assertThat ( sentence2 . getMarkupText ( ) , is ( "But <ERR targ=bad suggestion>also also</ERR> please <ERR targ=note>note note</ERR> that grammar checkers aren't perfect." ) ) ; assertTrue ( iterator . hasNext ( ) ) ; iterator . next ( ) ; assertFalse ( iterator . hasNext ( ) ) ; } }
package org . languagetool . dev ; import morfologik . stemming . Dictionary ; import morfologik . stemming . DictionaryLookup ; import morfologik . stemming . WordData ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . language . German ; import org . languagetool . tagging . Tagger ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . util . Collections ; import java . util . List ; public class GermanTaggerEnhancer { private static final String [ ] ADJ_READINGS = { "ADJ:NOM:SIN:MAS:GRU" , "ADJ:NOM:SIN:NEU:GRU" , "ADJ:NOM:SIN:FEM:GRU" , "ADJ:GEN:SIN:MAS:GRU" , "ADJ:GEN:SIN:NEU:GRU" , "ADJ:GEN:SIN:FEM:GRU" , "ADJ:DAT:SIN:MAS:GRU" , "ADJ:DAT:SIN:NEU:GRU" , "ADJ:DAT:SIN:FEM:GRU" , "ADJ:AKK:SIN:MAS:GRU" , "ADJ:AKK:SIN:NEU:GRU" , "ADJ:AKK:SIN:FEM:GRU" , "ADJ:NOM:PLU:MAS:GRU" , "ADJ:NOM:PLU:NEU:GRU" , "ADJ:NOM:PLU:FEM:GRU" , "ADJ:GEN:PLU:MAS:GRU" , "ADJ:GEN:PLU:NEU:GRU" , "ADJ:GEN:PLU:FEM:GRU" , "ADJ:DAT:PLU:MAS:GRU" , "ADJ:DAT:PLU:NEU:GRU" , "ADJ:DAT:PLU:FEM:GRU" , "ADJ:AKK:PLU:MAS:GRU" , "ADJ:AKK:PLU:NEU:GRU" , "ADJ:AKK:PLU:FEM:GRU" , } ; private void run ( ) throws IOException { final Dictionary dictionary = Dictionary . read ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( "/de/german.dict" ) ) ; final DictionaryLookup dl = new DictionaryLookup ( dictionary ) ; Tagger tagger = new German ( ) . getTagger ( ) ; String prev = null ; for ( WordData wd : dl ) { String word = wd . getWord ( ) . toString ( ) ; if ( word . endsWith ( "er" ) && StringTools . startsWithUppercase ( word ) ) { if ( ! hasAdjReading ( tagger , word ) && isEigenname ( tagger , word . substring ( 0 , word . length ( ) - 2 ) ) && ! word . equals ( prev ) ) { for ( String newTags : ADJ_READINGS ) { System . out . println ( word + "\t" + word + "\t" + newTags + ":DEF" ) ; System . out . println ( word + "\t" + word + "\t" + newTags + ":IND" ) ; System . out . println ( word + "\t" + word + "\t" + newTags + ":SOL" ) ; } prev = word ; } } } } private boolean isEigenname ( Tagger tagger , String word ) throws IOException { List < AnalyzedTokenReadings > readings = tagger . tag ( Collections . singletonList ( word ) ) ; for ( AnalyzedTokenReadings reading : readings ) { if ( reading . hasPartialPosTag ( "EIG" ) ) { return true ; } } return false ; } private boolean hasAdjReading ( Tagger tagger , String word ) throws IOException { List < AnalyzedTokenReadings > readings = tagger . tag ( Collections . singletonList ( word ) ) ; for ( AnalyzedTokenReadings reading : readings ) { if ( reading . hasPartialPosTag ( "ADJ:NOM" ) ) { return true ; } } return false ; } public static void main ( String [ ] args ) throws IOException { GermanTaggerEnhancer enhancer = new GermanTaggerEnhancer ( ) ; enhancer . run ( ) ; } }
package org . languagetool . dev ; import java . io . File ; import java . io . InputStream ; import java . text . SimpleDateFormat ; import java . util . ArrayList ; import java . util . Calendar ; import java . util . Collections ; import java . util . Date ; import java . util . GregorianCalendar ; import java . util . List ; import java . util . Scanner ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . tools . StringTools ; public final class RuleActivityOverview { private static final int PAST_DAYS = 365 / 2 ; RuleActivityOverview ( ) { } private void run ( ) { System . out . println ( "Commits per language in the last " + PAST_DAYS + " days" ) ; System . out . println ( "Date: " + new SimpleDateFormat ( "yyyy-MM-dd" ) . format ( new Date ( ) ) ) ; List < String > sortedLanguages = new ArrayList < > ( ) ; for ( Language element : Languages . get ( ) ) { sortedLanguages . add ( element . getName ( ) ) ; } Collections . sort ( sortedLanguages ) ; for ( String langName : sortedLanguages ) { Language lang = Languages . getLanguageForName ( langName ) ; int commits = getActivityFor ( lang , PAST_DAYS ) ; System . out . println ( commits + "\t" + lang . getName ( ) + ( lang . isVariant ( ) ? " (including the parent language)" : "" ) ) ; } } int getActivityFor ( Language lang , int pastDays ) { try { Calendar past = GregorianCalendar . getInstance ( ) ; past . add ( Calendar . DAY_OF_MONTH , - pastDays ) ; SimpleDateFormat dateFormat = new SimpleDateFormat ( "yyyy-MM-dd" ) ; String pastString = dateFormat . format ( past . getTime ( ) ) ; String langCode = lang . getShortName ( ) ; List < File > xmlFiles = getAllXmlFiles ( lang , langCode ) ; int commits = 0 ; for ( File file : xmlFiles ) { if ( ! file . exists ( ) ) { throw new RuntimeException ( "Not found: " + file ) ; } String command = "git log --after=" + pastString + " " + file ; Runtime runtime = Runtime . getRuntime ( ) ; Process process = runtime . exec ( command ) ; InputStream inputStream = process . getInputStream ( ) ; String output = StringTools . readStream ( inputStream , "utf-8" ) ; process . waitFor ( ) ; commits += getCommits ( output ) ; } return commits ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } private List < File > getAllXmlFiles ( Language lang , String langCode ) { List < File > files = new ArrayList < > ( ) ; List < String > ruleFileNames = lang . getRuleFileNames ( ) ; for ( String ruleFileName : ruleFileNames ) { files . add ( new File ( "../languagetool-language-modules/" + langCode + "/src/main/resources/" + ruleFileName ) ) ; } File disambiguationFile = new File ( "../languagetool-language-modules/" + langCode + "/src/main/resources/org/languagetool/resource/" + langCode + "/disambiguation.xml" ) ; if ( disambiguationFile . exists ( ) ) { files . add ( disambiguationFile ) ; } return files ; } private int getCommits ( String svnOutput ) { int count = 0 ; try ( Scanner scanner = new Scanner ( svnOutput ) ) { while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; if ( line . startsWith ( "commit " ) ) { count ++ ; } } } return count ; } public static void main ( String [ ] args ) throws Exception { RuleActivityOverview prg = new RuleActivityOverview ( ) ; prg . run ( ) ; } }
package org . languagetool . dev ; import org . apache . commons . io . IOUtils ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . AbstractPatternRule ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . tools . StringTools ; import java . io . File ; import java . io . FileReader ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; final class ExampleSentenceCorrectionCreator { private int addedCorrectionsCount = 0 ; private void run ( Language lang ) throws IOException { File basePath = new File ( "/lt/git/languagetool/languagetool-language-modules" ) ; if ( ! basePath . exists ( ) ) { throw new RuntimeException ( "basePath does not exist: " + basePath ) ; } String langCode = lang . getShortName ( ) ; File xml = new File ( basePath , "/" + langCode + "/src/main/resources/org/languagetool/rules/" + langCode + "/grammar.xml" ) ; List < String > xmlLines = IOUtils . readLines ( new FileReader ( xml ) ) ; JLanguageTool tool = new JLanguageTool ( lang ) ; for ( Rule rule : tool . getAllRules ( ) ) { if ( ! ( rule instanceof PatternRule ) ) { continue ; } List < IncorrectExample > incorrectExamples = rule . getIncorrectExamples ( ) ; for ( IncorrectExample incorrectExample : incorrectExamples ) { checkCorrections ( rule , incorrectExample , xmlLines , tool ) ; } } System . err . println ( "Added corrections: " + addedCorrectionsCount ) ; for ( String xmlLine : xmlLines ) { System . out . println ( xmlLine ) ; } } private void checkCorrections ( Rule rule , IncorrectExample incorrectExample , List < String > xmlLines , JLanguageTool tool ) throws IOException { List < String > corrections = incorrectExample . getCorrections ( ) ; if ( corrections != null && corrections . size ( ) == 0 ) { for ( Rule r : tool . getAllActiveRules ( ) ) { tool . disableRule ( r . getId ( ) ) ; } tool . enableRule ( rule . getId ( ) ) ; tool . enableDefaultOffRule ( rule . getId ( ) ) ; String incorrectSentence = incorrectExample . getExample ( ) . replaceAll ( "</?marker>" , "" ) ; List < RuleMatch > matches = tool . check ( incorrectSentence ) ; System . err . println ( "no corrections: " + rule . getId ( ) + ", " + matches . size ( ) + " matches" ) ; if ( matches . size ( ) == 0 ) { throw new RuntimeException ( "Got no rule match: " + incorrectSentence ) ; } List < String > suggestedReplacements = matches . get ( 0 ) . getSuggestedReplacements ( ) ; String newAttribute = "correction=\"" + StringTools . listToString ( suggestedReplacements , "|" ) + "\"" ; addAttribute ( rule , newAttribute , xmlLines ) ; } } private void addAttribute ( Rule rule , String newAttribute , List < String > xmlLines ) { List < Integer > linesToModify = new ArrayList < > ( ) ; String currentRuleId = null ; Pattern pattern = Pattern . compile ( ".*id=[\"'](.*?)[\"'].*" ) ; String expectedSubId = ( ( AbstractPatternRule ) rule ) . getSubId ( ) ; int lineCount = 0 ; int subRuleCount = 0 ; int modifyCount = 0 ; boolean inRuleGroup = false ; for ( String xmlLine : xmlLines ) { if ( xmlLine . contains ( "<rulegroup" ) ) { subRuleCount = 0 ; inRuleGroup = true ; } else if ( xmlLine . contains ( "</rulegroup>" ) ) { subRuleCount = 0 ; inRuleGroup = false ; } else if ( ( xmlLine . contains ( "<rule " ) || xmlLine . contains ( "<rule>" ) ) && inRuleGroup ) { subRuleCount ++ ; } Matcher m = pattern . matcher ( xmlLine ) ; if ( m . matches ( ) ) { currentRuleId = m . group ( 1 ) ; } if ( xmlLine . contains ( "type=\"incorrect\"" ) || xmlLine . contains ( "type='incorrect'" ) ) { if ( currentRuleId != null && ! currentRuleId . equals ( rule . getId ( ) ) ) { lineCount ++ ; continue ; } if ( ! inRuleGroup ) { subRuleCount = 1 ; } if ( ! expectedSubId . equals ( "0" ) && ! expectedSubId . equals ( String . valueOf ( subRuleCount ) ) ) { lineCount ++ ; continue ; } linesToModify . add ( lineCount ) ; break ; } lineCount ++ ; } for ( Integer s : linesToModify ) { String newLine = xmlLines . get ( s ) . replaceFirst ( "type=[\"']incorrect[\"']" , newAttribute ) ; xmlLines . set ( s , newLine ) ; addedCorrectionsCount ++ ; modifyCount ++ ; } if ( modifyCount == 0 ) { System . err . println ( "No line modified: " + rule + "[" + expectedSubId + "]" ) ; } } public static void main ( String [ ] args ) throws IOException { ExampleSentenceCorrectionCreator prg = new ExampleSentenceCorrectionCreator ( ) ; prg . run ( Languages . getLanguageForShortName ( "de" ) ) ; } }
package org . languagetool . dev ; import org . languagetool . Language ; import org . languagetool . Languages ; import javax . xml . stream . XMLEventReader ; import javax . xml . stream . XMLInputFactory ; import javax . xml . stream . XMLStreamException ; import javax . xml . stream . events . Attribute ; import javax . xml . stream . events . XMLEvent ; import java . io . InputStream ; import java . util . * ; class XmlUsageCounter { private final Map < String , Integer > map = new HashMap < > ( ) ; private void countElementsAndAttributes ( InputStream in ) throws XMLStreamException { XMLInputFactory inputFactory = XMLInputFactory . newInstance ( ) ; XMLEventReader eventReader = inputFactory . createXMLEventReader ( in ) ; while ( eventReader . hasNext ( ) ) { XMLEvent event = eventReader . nextEvent ( ) ; if ( event . isStartElement ( ) ) { String elementName = event . asStartElement ( ) . getName ( ) . getLocalPart ( ) ; add ( elementName ) ; Iterator attributes = event . asStartElement ( ) . getAttributes ( ) ; while ( attributes . hasNext ( ) ) { Attribute att = ( Attribute ) attributes . next ( ) ; add ( elementName + "/" + att . getName ( ) ) ; } } } } private void add ( String name ) { if ( map . containsKey ( name ) ) { int oldCount = map . get ( name ) ; map . put ( name , oldCount + 1 ) ; } else { map . put ( name , 1 ) ; } } private void printResult ( ) { List < ElemCount > elemCounts = new ArrayList < > ( ) ; for ( Map . Entry < String , Integer > entry : map . entrySet ( ) ) { elemCounts . add ( new ElemCount ( entry . getKey ( ) , entry . getValue ( ) ) ) ; } Collections . sort ( elemCounts , new Comparator < ElemCount > ( ) { @ Override public int compare ( ElemCount ec1 , ElemCount ec2 ) { return ec2 . count - ec1 . count ; } } ) ; for ( ElemCount elemCount : elemCounts ) { System . out . println ( elemCount . count + " " + elemCount . elem ) ; } } public static void main ( String [ ] args ) throws XMLStreamException { XmlUsageCounter counter = new XmlUsageCounter ( ) ; Set < String > countedFiles = new HashSet < > ( ) ; for ( Language language : Languages . get ( ) ) { List < String > ruleFileNames = language . getRuleFileNames ( ) ; for ( String ruleFileName : ruleFileNames ) { if ( countedFiles . contains ( ruleFileName ) ) { continue ; } System . err . println ( "Counting elements for " + ruleFileName ) ; InputStream ruleStream = XmlUsageCounter . class . getResourceAsStream ( ruleFileName ) ; if ( ruleStream == null ) { System . err . println ( "Not found, ignoring: " + ruleFileName ) ; continue ; } counter . countElementsAndAttributes ( ruleStream ) ; countedFiles . add ( ruleFileName ) ; } } counter . printResult ( ) ; } static class ElemCount { String elem ; Integer count ; ElemCount ( String elem , Integer count ) { this . elem = elem ; this . count = count ; } } }
package org . languagetool . dev ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . standard . StandardAnalyzer ; import org . apache . lucene . document . * ; import org . apache . lucene . index . IndexWriter ; import org . apache . lucene . index . IndexWriterConfig ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . FSDirectory ; import org . apache . lucene . util . Version ; import org . languagetool . languagemodel . LanguageModel ; import java . io . * ; import java . text . NumberFormat ; import java . util . * ; import java . util . zip . GZIPInputStream ; public class FrequencyIndexCreator { private static final int MIN_YEAR = 1910 ; private static final String NAME_REGEX1 = "googlebooks-eng-all-[1-5]gram-20120701-(.*?).gz" ; private static final String NAME_REGEX2 = "[a-z0-9]+-[a-z0-9]+-[a-z0-9]+-[a-z0-9]+-[a-z0-9]+[_-](.*?).gz" ; private static final int BUFFER_SIZE = 16384 ; private long totalTokenCount ; private void run ( File inputDir , File indexBaseDir ) throws IOException { List < File > files = Arrays . asList ( inputDir . listFiles ( ) ) ; Collections . sort ( files ) ; for ( File file : files ) { String name = file . getName ( ) ; if ( name . matches ( ".*_[A-Z]+_.*" ) ) { System . out . println ( "Skipping POS tag file " + name ) ; continue ; } File indexDir ; boolean hiveMode ; if ( name . matches ( NAME_REGEX1 ) ) { indexDir = new File ( indexBaseDir , name . replaceAll ( NAME_REGEX1 , "$1" ) ) ; hiveMode = false ; System . out . println ( "Running in corpus mode (i.e. aggregation of years)" ) ; } else if ( name . matches ( NAME_REGEX2 ) ) { indexDir = new File ( indexBaseDir , name . replaceAll ( NAME_REGEX2 , "$1" ) ) ; hiveMode = true ; System . out . println ( "Running in Hive mode (i.e. no aggregation of years)" ) ; } else { System . out . println ( "Skipping " + name + " - doesn't match regex " + NAME_REGEX1 + " or " + NAME_REGEX2 ) ; continue ; } if ( indexDir . exists ( ) && indexDir . isDirectory ( ) ) { System . out . println ( "Skipping " + name + " - index dir '" + indexDir + "' already exists" ) ; continue ; } System . out . println ( "Index dir: " + indexDir ) ; Directory directory = FSDirectory . open ( indexDir ) ; Analyzer analyzer = new StandardAnalyzer ( Version . LUCENE_4_10_3 ) ; IndexWriterConfig config = new IndexWriterConfig ( Version . LUCENE_4_10_3 , analyzer ) ; config . setUseCompoundFile ( false ) ; try ( IndexWriter writer = new IndexWriter ( directory , config ) ) { indexLinesFromGoogleFile ( writer , file , hiveMode ) ; } } } private void indexLinesFromGoogleFile ( IndexWriter writer , File inputFile , boolean hiveMode ) throws IOException { System . out . println ( "==== Working on " + inputFile + " ====" ) ; try ( InputStream fileStream = new FileInputStream ( inputFile ) ; InputStream gzipStream = new GZIPInputStream ( fileStream , BUFFER_SIZE ) ; Reader decoder = new InputStreamReader ( gzipStream , "utf-8" ) ; BufferedReader buffered = new BufferedReader ( decoder , BUFFER_SIZE ) ) { int i = 0 ; long docCount = 0 ; long lineCount = 0 ; String prevText = null ; long startTime = System . nanoTime ( ) / 1000 ; String line ; while ( ( line = buffered . readLine ( ) ) != null ) { lineCount ++ ; String [ ] parts = line . split ( "\t" ) ; String text = parts [ 0 ] ; if ( isRealPosTag ( text ) ) { continue ; } if ( hiveMode ) { String docCountStr = parts [ 1 ] ; addDoc ( writer , text , Long . parseLong ( docCountStr ) ) ; if ( ++ i % 500_000 == 0 ) { printStats ( i , Long . parseLong ( docCountStr ) , lineCount , text , startTime ) ; } } else { int year = Integer . parseInt ( parts [ 1 ] ) ; if ( year < MIN_YEAR ) { continue ; } if ( prevText == null || prevText . equals ( text ) ) { docCount += Long . parseLong ( parts [ 2 ] ) ; } else { addDoc ( writer , prevText , docCount ) ; if ( ++ i % 5_000 == 0 ) { printStats ( i , docCount , lineCount , prevText , startTime ) ; } docCount = Long . parseLong ( parts [ 2 ] ) ; } } prevText = text ; } printStats ( i , docCount , lineCount , prevText , startTime ) ; } addTotalTokenCountDoc ( writer , totalTokenCount ) ; } private boolean isRealPosTag ( String text ) { int idx = text . indexOf ( '_' ) ; if ( idx == - 1 ) { return false ; } else { String tag = idx + 7 <= text . length ( ) ? text . substring ( idx , idx + 7 ) : "" ; if ( tag . equals ( LanguageModel . GOOGLE_SENTENCE_START ) ) { return false ; } String tag2 = idx + 5 <= text . length ( ) ? text . substring ( idx , idx + 5 ) : "" ; if ( tag2 . equals ( LanguageModel . GOOGLE_SENTENCE_END ) ) { return false ; } return true ; } } private void printStats ( int i , long docCount , long lineCount , String prevText , long startTimeMicros ) { long microsNow = System . nanoTime ( ) / 1000 ; float millisPerDoc = ( microsNow - startTimeMicros ) / Math . max ( 1 , i ) ; NumberFormat format = NumberFormat . getNumberInstance ( Locale . US ) ; System . out . printf ( "doc:%s line:%s ngram:%s occ:%s (%.0fµs/doc)\n" , format . format ( i ) , format . format ( lineCount ) , prevText , format . format ( docCount ) , millisPerDoc ) ; } private void addDoc ( IndexWriter writer , String text , long count ) throws IOException { Document doc = new Document ( ) ; doc . add ( new Field ( "ngram" , text , StringField . TYPE_NOT_STORED ) ) ; FieldType fieldType = new FieldType ( ) ; fieldType . setStored ( true ) ; Field countField = new Field ( "count" , String . valueOf ( count ) , fieldType ) ; doc . add ( countField ) ; totalTokenCount += count ; writer . addDocument ( doc ) ; } private void addTotalTokenCountDoc ( IndexWriter writer , long totalTokenCount ) throws IOException { FieldType fieldType = new FieldType ( ) ; fieldType . setIndexed ( true ) ; fieldType . setStored ( true ) ; Field countField = new Field ( "totalTokenCount" , String . valueOf ( totalTokenCount ) , fieldType ) ; Document doc = new Document ( ) ; doc . add ( countField ) ; writer . addDocument ( doc ) ; } public static void main ( String [ ] args ) throws IOException { if ( args . length != 2 ) { System . out . println ( "Usage: " + FrequencyIndexCreator . class . getSimpleName ( ) + " <inputDir> <outputDir>" ) ; System . out . println ( " <inputDir> is the Google ngram data aggregated by Hive," ) ; System . out . println ( " please see http://wiki.languagetool.org/finding-errors-using-big-data" ) ; System . exit ( 1 ) ; } FrequencyIndexCreator creator = new FrequencyIndexCreator ( ) ; creator . run ( new File ( args [ 0 ] ) , new File ( args [ 1 ] ) ) ; } }
package org . languagetool . tagging . disambiguation . rules . ro ; import java . io . IOException ; import junit . framework . TestCase ; import org . languagetool . TestTools ; import org . languagetool . language . Romanian ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . disambiguation . xx . DemoDisambiguator ; import org . languagetool . tagging . ro . RomanianTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . ro . RomanianWordTokenizer ; public class RomanianRuleDisambiguatorTest extends TestCase { private RomanianTagger tagger ; private RomanianWordTokenizer tokenizer ; private SentenceTokenizer sentenceTokenizer ; private XmlRuleDisambiguator disambiguator ; private DemoDisambiguator disamb2 ; @ Override public void setUp ( ) { tagger = new RomanianTagger ( ) ; tokenizer = new RomanianWordTokenizer ( ) ; Romanian language = new Romanian ( ) ; sentenceTokenizer = new SRXSentenceTokenizer ( language ) ; disambiguator = new XmlRuleDisambiguator ( language ) ; disamb2 = new DemoDisambiguator ( ) ; } public void testCare1 ( ) throws IOException { TestTools . myAssert ( "Persoana care face treabă." , "/[null]SENT_START Persoana/[persoană]Sfs3aac000 /[null]null care/[car]Snp3anc000|care/[care]0000000000|care/[care]N000a0l000|care/[căra]V0p3000cz0|care/[căra]V0s3000cz0 /[null]null face/[face]V000000f00|face/[face]V0s3000iz0 /[null]null treabă/[treabă]Sfs3anc000 ./[null]null" , tokenizer , sentenceTokenizer , tagger , disamb2 ) ; TestTools . myAssert ( "Persoana care face treabă." , "/[null]SENT_START Persoana/[persoană]Sfs3aac000 /[null]null care/[care]N000a0l000 /[null]null face/[face]V000000f00|face/[face]V0s3000iz0 /[null]null treabă/[treabă]Sfs3anc000 ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; } public void testEsteO ( ) throws IOException { TestTools . myAssert ( "este o masă." , "/[null]SENT_START este/[fi]V0s3000izb /[null]null o/[o]Dfs3a0t000|o/[o]I00000o000|o/[o]Nfs3a0p00c|o/[o]Sms3anc000|o/[vrea]V0s3000iov /[null]null masă/[masa]V0s3000is0|masă/[masă]Sfs3anc000 ./[null]null" , tokenizer , sentenceTokenizer , tagger , disamb2 ) ; TestTools . myAssert ( "este o masă." , "/[null]SENT_START este/[fi]V0s3000izb /[null]null o/[o]Dfs3a0t000|o/[o]I00000o000|o/[o]Nfs3a0p00c|o/[o]Sms3anc000|o/[vrea]V0s3000iov /[null]null masă/[masă]Sfs3anc000 ./[null]null" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "este o masă" , "/[null]SENT_START este/[fi]V0s3000izb /[null]null o/[o]Dfs3a0t000|o/[o]I00000o000|o/[o]Nfs3a0p00c|o/[o]Sms3anc000|o/[vrea]V0s3000iov /[null]null masă/[masă]Sfs3anc000" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; } public void testDezambiguizareVerb ( ) throws IOException { TestTools . myAssert ( "vom participa la" , "/[null]SENT_START vom/[vrea]V0p1000ivv /[null]null participa/[participa]V000000f00|participa/[participa]V0s3000ii0 /[null]null la/[la]P000000000|la/[la]Sms3anc000" , tokenizer , sentenceTokenizer , tagger , disamb2 ) ; TestTools . myAssert ( "vom participa la" , "/[null]SENT_START vom/[vrea]V0p1000ivv /[null]null participa/[participa]V000000f00 /[null]null la/[la]P000000000|la/[la]Sms3anc000" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "vom culege" , "/[null]SENT_START vom/[vrea]V0p1000ivv /[null]null culege/[culege]V000000f00|culege/[culege]V0s2000m00|culege/[culege]V0s3000iz0" , tokenizer , sentenceTokenizer , tagger , disamb2 ) ; TestTools . myAssert ( "vom culege" , "/[null]SENT_START vom/[vrea]V0p1000ivv /[null]null culege/[culege]V000000f00" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; TestTools . myAssert ( "veți culege" , "/[null]SENT_START veți/[vrea]V0p2000ivv /[null]null culege/[culege]V000000f00" , tokenizer , sentenceTokenizer , tagger , disambiguator ) ; } }
package org . languagetool . dev ; import org . apache . commons . io . IOUtils ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . rules . Rule ; import org . languagetool . rules . patterns . AbstractPatternRule ; import java . io . File ; import java . io . FileReader ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; final class UselessExampleFinder { private int uselessExampleCount ; private int removedLinesCount ; private void run ( Language lang ) throws IOException { File basePath = new File ( "/lt/git/languagetool/languagetool-language-modules" ) ; if ( ! basePath . exists ( ) ) { throw new RuntimeException ( "basePath does not exist: " + basePath ) ; } String langCode = lang . getShortName ( ) ; File xml = new File ( basePath , "/" + langCode + "/src/main/resources/org/languagetool/rules/" + langCode + "/grammar.xml" ) ; List < String > xmlLines = IOUtils . readLines ( new FileReader ( xml ) ) ; JLanguageTool tool = new JLanguageTool ( lang ) ; for ( Rule rule : tool . getAllActiveRules ( ) ) { List < String > correctExamples = rule . getCorrectExamples ( ) ; List < IncorrectExample > incorrectExamples = rule . getIncorrectExamples ( ) ; for ( IncorrectExample incorrectExample : incorrectExamples ) { checkCorrections ( rule , correctExamples , incorrectExample , xmlLines ) ; } } System . err . println ( "Useless examples: " + uselessExampleCount ) ; System . err . println ( "Removed lines: " + removedLinesCount ) ; for ( String xmlLine : xmlLines ) { System . out . println ( xmlLine ) ; } } private void checkCorrections ( Rule rule , List < String > correctExamples , IncorrectExample incorrectExample , List < String > xmlLines ) { List < String > corrections = incorrectExample . getCorrections ( ) ; if ( corrections != null && corrections . size ( ) == 1 ) { for ( String correction : corrections ) { String fixedSentence = incorrectExample . getExample ( ) . replaceAll ( "<marker>.*?</marker>" , "<marker>" + correction . replace ( "$" , "\\$" ) + "</marker>" ) ; if ( correctExamples . contains ( fixedSentence ) ) { System . err . println ( "Useless: " + fixedSentence + " in " + rule . getId ( ) ) ; removeLinesFromXml ( rule , fixedSentence , xmlLines ) ; uselessExampleCount ++ ; } } } } private void removeLinesFromXml ( Rule rule , String sentenceToRemove , List < String > xmlLines ) { List < Integer > linesToRemove = new ArrayList < > ( ) ; String currentRuleId = null ; Pattern pattern = Pattern . compile ( ".*id=[\"'](.*?)[\"'].*" ) ; String expectedSubId = ( ( AbstractPatternRule ) rule ) . getSubId ( ) ; int lineCount = 0 ; int subRuleCount = 0 ; int removedCount = 0 ; boolean inRuleGroup = false ; for ( String xmlLine : xmlLines ) { if ( xmlLine . contains ( "<rulegroup" ) ) { subRuleCount = 0 ; inRuleGroup = true ; } else if ( xmlLine . contains ( "</rulegroup>" ) ) { subRuleCount = 0 ; inRuleGroup = false ; } else if ( ( xmlLine . contains ( "<rule " ) || xmlLine . contains ( "<rule>" ) ) && inRuleGroup ) { subRuleCount ++ ; } Matcher m = pattern . matcher ( xmlLine ) ; if ( m . matches ( ) ) { currentRuleId = m . group ( 1 ) ; } if ( ( xmlLine . contains ( "type=\"correct\"" ) || xmlLine . contains ( "type='correct'" ) ) && xmlLine . contains ( sentenceToRemove + "</example>" ) ) { if ( currentRuleId != null && ! currentRuleId . equals ( rule . getId ( ) ) ) { lineCount ++ ; continue ; } if ( ! inRuleGroup ) { subRuleCount = 1 ; } if ( ! expectedSubId . equals ( "0" ) && ! expectedSubId . equals ( String . valueOf ( subRuleCount ) ) ) { lineCount ++ ; continue ; } linesToRemove . add ( lineCount ) ; break ; } lineCount ++ ; } Collections . reverse ( linesToRemove ) ; for ( Integer s : linesToRemove ) { xmlLines . remove ( s . intValue ( ) ) ; removedLinesCount ++ ; removedCount ++ ; } if ( removedCount == 0 ) { System . err . println ( "No line removed: " + rule + "[" + expectedSubId + "]" ) ; } } public static void main ( String [ ] args ) throws IOException { UselessExampleFinder prg = new UselessExampleFinder ( ) ; prg . run ( Languages . getLanguageForShortName ( "de" ) ) ; } }
package org . languagetool . dev ; import java . io . BufferedInputStream ; import java . io . BufferedReader ; import java . io . IOException ; import java . io . InputStreamReader ; import java . util . ArrayList ; import java . util . List ; import org . languagetool . * ; public final class POSTagLanguageModel { public static void main ( final String [ ] args ) throws IOException { if ( args . length == 1 ) { final Language language = getLanguageOrExit ( args [ 0 ] ) ; final JLanguageTool lt = new JLanguageTool ( language , null ) ; runOnStdIn ( lt ) ; } else { exitWithUsageMessage ( ) ; } } private static Language getLanguageOrExit ( final String lang ) { Language language = null ; boolean foundLanguage = false ; final List < String > supportedLanguages = new ArrayList < > ( ) ; for ( final Language tmpLang : Languages . get ( ) ) { supportedLanguages . add ( tmpLang . getShortName ( ) ) ; if ( lang . equals ( tmpLang . getShortName ( ) ) ) { language = tmpLang ; foundLanguage = true ; break ; } } if ( ! foundLanguage ) { System . out . println ( "Unknown language '" + lang + "'. Supported languages are: " + supportedLanguages ) ; exitWithUsageMessage ( ) ; } return language ; } private static void exitWithUsageMessage ( ) { System . out . println ( "Usage: java org.languagetool.dev.POSTagLanguageModel <language>" ) ; } private static void runOnStdIn ( final JLanguageTool lt ) throws IOException { final int MAX_FILE_SIZE = 64_000 ; InputStreamReader isr = null ; BufferedReader br = null ; StringBuilder sb = new StringBuilder ( ) ; try { isr = new InputStreamReader ( new BufferedInputStream ( System . in ) ) ; br = new BufferedReader ( isr ) ; String line ; while ( ( line = br . readLine ( ) ) != null ) { sb . append ( line ) ; sb . append ( '\n' ) ; if ( lt . getLanguage ( ) . getSentenceTokenizer ( ) . singleLineBreaksMarksPara ( ) ) { tagText ( sb . toString ( ) , lt ) ; sb = new StringBuilder ( ) ; } else { if ( "" . equals ( line ) || sb . length ( ) >= MAX_FILE_SIZE ) { tagText ( sb . toString ( ) , lt ) ; sb = new StringBuilder ( ) ; } } } } finally { if ( sb . length ( ) > 0 ) { tagText ( sb . toString ( ) , lt ) ; } } br . close ( ) ; isr . close ( ) ; } private static void tagText ( final String contents , final JLanguageTool lt ) throws IOException { AnalyzedSentence analyzedText ; final List < String > sentences = lt . sentenceTokenize ( contents ) ; for ( final String sentence : sentences ) { analyzedText = lt . getAnalyzedSentence ( sentence ) ; System . out . println ( getSentence ( analyzedText ) ) ; } } private static String getSentence ( final AnalyzedSentence sent ) { final StringBuilder sb = new StringBuilder ( ) ; sb . append ( "<S>" ) ; for ( final AnalyzedTokenReadings atr : sent . getTokensWithoutWhitespace ( ) ) { sb . append ( getPOS ( atr ) ) ; sb . append ( ' ' ) ; } sb . append ( "</S>" ) ; return sb . toString ( ) ; } private static String getPOS ( final AnalyzedTokenReadings atr ) { final StringBuilder sb = new StringBuilder ( ) ; final int readNum = atr . getReadingsLength ( ) ; for ( int i = 0 ; i < readNum ; i ++ ) { if ( ! atr . isWhitespace ( ) ) { sb . append ( atr . getAnalyzedToken ( i ) . getPOSTag ( ) ) ; if ( i != readNum - 1 ) { sb . append ( '+' ) ; } } } return sb . toString ( ) ; } }
package org . languagetool . dev ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import java . io . File ; import java . io . IOException ; import java . util . Scanner ; class SentenceChecker { private static final int BATCH_SIZE = 1000 ; private void run ( Language language , File file ) throws IOException { JLanguageTool lt = new JLanguageTool ( language ) ; Scanner scanner = new Scanner ( file ) ; int count = 0 ; long startTime = System . currentTimeMillis ( ) ; while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; lt . check ( line ) ; if ( ++ count % BATCH_SIZE == 0 ) { long time = ( System . currentTimeMillis ( ) - startTime ) ; System . out . println ( count + ". " + time + "ms per " + BATCH_SIZE + " sentences" ) ; startTime = System . currentTimeMillis ( ) ; } } } public static void main ( String [ ] args ) throws IOException { if ( args . length != 2 ) { System . err . println ( "Usage: " + SentenceChecker . class . getSimpleName ( ) + " <langCode> <sentenceFile>" ) ; System . exit ( 1 ) ; } SentenceChecker checker = new SentenceChecker ( ) ; checker . run ( Languages . getLanguageForShortName ( args [ 0 ] ) , new File ( args [ 1 ] ) ) ; } }
package org . languagetool . dev ; import org . apache . commons . io . IOUtils ; import java . io . * ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import java . util . zip . GZIPInputStream ; public class OccurrenceAdder { private static final int BUFFER_SIZE = 16384 ; private void run ( Map < String , Integer > map , File dir ) throws IOException { File [ ] files = dir . listFiles ( ) ; for ( File file : files ) { runOnFile ( map , file ) ; } } private void runOnFile ( Map < String , Integer > map , File file ) throws IOException { System . out . println ( "Working on " + file ) ; try ( InputStream fileStream = new FileInputStream ( file ) ; InputStream gzipStream = new GZIPInputStream ( fileStream , BUFFER_SIZE ) ; Reader decoder = new InputStreamReader ( gzipStream , "utf-8" ) ; BufferedReader buffered = new BufferedReader ( decoder , BUFFER_SIZE ) ) { String line ; while ( ( line = buffered . readLine ( ) ) != null ) { String [ ] parts = line . split ( "\t" ) ; String word = parts [ 0 ] ; int occurrences = Integer . parseInt ( parts [ 2 ] ) ; Integer val = map . get ( word ) ; if ( val != null ) { map . put ( word , val + occurrences ) ; } } } } public static void main ( String [ ] args ) throws IOException { if ( args . length != 2 ) { System . out . println ( "Usage: " + OccurrenceAdder . class . getName ( ) + " <wordfile> <dir>" ) ; System . exit ( 1 ) ; } OccurrenceAdder occurrenceAdder = new OccurrenceAdder ( ) ; Map < String , Integer > map = new HashMap < > ( ) ; List < String > words = IOUtils . readLines ( new FileInputStream ( args [ 0 ] ) ) ; for ( String word : words ) { map . put ( word , 0 ) ; } occurrenceAdder . run ( map , new File ( args [ 1 ] ) ) ; System . out . println ( "-------------------------" ) ; for ( Map . Entry < String , Integer > entry : map . entrySet ( ) ) { System . out . println ( entry . getValue ( ) + "\t" + entry . getKey ( ) ) ; } } }
package org . languagetool . dev ; import com . google . common . base . Charsets ; import morfologik . fsa . FSA ; import org . languagetool . JLanguageTool ; import org . languagetool . tools . StringTools ; import java . io . IOException ; import java . nio . ByteBuffer ; import java . nio . file . FileSystems ; import java . nio . file . Files ; import java . util . * ; public class ExportGermanNouns { private static final String DICT_FILENAME = "/de/german.dict" ; private static final String ADDED_DICT_FILENAME = "languagetool-language-modules/de/src/main/resources/org/languagetool/resource/de/added.txt" ; private ExportGermanNouns ( ) { } private List < String > getSortedWords ( ) throws IOException { Set < String > words1 = getBinaryDictWords ( ) ; Set < String > words2 = getAddedDictWords ( ) ; List < String > sortedWords = new ArrayList < > ( ) ; sortedWords . addAll ( words1 ) ; sortedWords . addAll ( words2 ) ; Collections . sort ( sortedWords ) ; return sortedWords ; } private Set < String > getBinaryDictWords ( ) throws IOException { final FSA fsa = FSA . read ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( DICT_FILENAME ) ) ; final Set < String > set = new HashSet < > ( ) ; for ( ByteBuffer buffer : fsa ) { final byte [ ] sequence = new byte [ buffer . remaining ( ) ] ; buffer . get ( sequence ) ; final String output = new String ( sequence , "iso-8859-1" ) ; if ( isRelevantNoun ( output ) ) { final String [ ] parts = output . split ( "\\+" ) ; final String term = parts [ 0 ] . toLowerCase ( ) ; set . add ( term ) ; } } return set ; } private Set < String > getAddedDictWords ( ) throws IOException { final Set < String > set = new HashSet < > ( ) ; List < String > lines = Files . readAllLines ( FileSystems . getDefault ( ) . getPath ( ADDED_DICT_FILENAME ) , Charsets . UTF_8 ) ; for ( String line : lines ) { if ( isRelevantNoun ( line ) ) { final String [ ] parts = line . split ( "\t" ) ; final String term = parts [ 0 ] . toLowerCase ( ) ; set . add ( term ) ; } } return set ; } private boolean isRelevantNoun ( String output ) { boolean isNoun = output . contains ( "SUB:" ) || ( output . contains ( "EIG:" ) && output . contains ( "COU" ) ) ; return isNoun && ! output . contains ( ":ADJ" ) && ! StringTools . isAllUppercase ( output ) ; } public static void main ( String [ ] args ) throws IOException { ExportGermanNouns prg = new ExportGermanNouns ( ) ; List < String > words = prg . getSortedWords ( ) ; System . out . println ( "# DO NOT MODIFY - automatically exported" ) ; System . out . println ( "# Exporting class: " + ExportGermanNouns . class . getName ( ) ) ; System . out . println ( "# Export date: " + new Date ( ) ) ; System . out . println ( "# LanguageTool: " + JLanguageTool . VERSION + " (" + JLanguageTool . BUILD_DATE + ")" ) ; System . out . println ( "# Potential German compound parts." ) ; System . out . println ( "# Data from Morphy (http://www.wolfganglezius.de/doku.php?id=cl:morphy)" ) ; System . out . println ( "# with extensions by LanguageTool (https://languagetool.org)" ) ; System . out . println ( "# License: Creative Commons Attribution-Share Alike 4.0, http://creativecommons.org/licenses/by-sa/4.0/" ) ; for ( String word : words ) { System . out . println ( word ) ; } } }
package org . languagetool . dev ; import java . io . BufferedReader ; import java . io . BufferedWriter ; import java . io . IOException ; import java . io . InputStreamReader ; import java . io . OutputStreamWriter ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . Languages ; public final class WordTokenizer { public static void main ( final String [ ] args ) throws IOException { final WordTokenizer prg = new WordTokenizer ( ) ; if ( args . length != 1 ) { System . err . println ( "Please supply the language code as the only argument." ) ; System . exit ( - 1 ) ; } prg . run ( args [ 0 ] ) ; } private void run ( final String lang ) throws IOException { JLanguageTool langTool = new JLanguageTool ( Languages . getLanguageForShortName ( lang ) ) ; BufferedReader in = null ; BufferedWriter out = null ; try { in = new BufferedReader ( new InputStreamReader ( System . in ) ) ; out = new BufferedWriter ( new OutputStreamWriter ( System . out ) ) ; String line ; while ( ( line = in . readLine ( ) ) != null ) { AnalyzedTokenReadings [ ] atr = langTool . getRawAnalyzedSentence ( line ) . getTokensWithoutWhitespace ( ) ; for ( AnalyzedTokenReadings a : atr ) { out . write ( a . getToken ( ) ) ; out . write ( "\n" ) ; } } } finally { if ( in != null ) { in . close ( ) ; } if ( out != null ) { out . flush ( ) ; out . close ( ) ; } } } }
package org . languagetool . dev ; import org . apache . commons . lang . StringUtils ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . language . Contributor ; import org . languagetool . tools . StringTools ; import org . languagetool . tools . Tools ; import java . io . File ; import java . io . FileFilter ; import java . io . IOException ; import java . net . URL ; import java . text . SimpleDateFormat ; import java . util . * ; @ SuppressWarnings ( "StringConcatenationInsideStringBufferAppend" ) public final class RuleOverview { private static final List < String > LANGUAGES_WITH_NEW_MAINTAINER_NEED = Arrays . asList ( "en" , "ja" , "is" , "sv" , "lt" , "ro" , "ml" ) ; private static final List < String > LANGUAGES_WITH_CO_MAINTAINER_NEED = Arrays . asList ( "da" , "be" , "zh" , "gl" ) ; public static void main ( final String [ ] args ) throws IOException { if ( args . length != 1 ) { System . out . println ( "Usage: " + RuleOverview . class . getName ( ) + " <webRoot>" ) ; System . exit ( 1 ) ; } final RuleOverview prg = new RuleOverview ( ) ; prg . run ( new File ( args [ 0 ] ) ) ; } private RuleOverview ( ) { } private void run ( File webRoot ) throws IOException { System . out . println ( "<b>Rules in LanguageTool " + JLanguageTool . VERSION + "</b><br />" ) ; System . out . println ( "Date: " + new SimpleDateFormat ( "yyyy-MM-dd" ) . format ( new Date ( ) ) + "<br /><br />\n" ) ; System . out . println ( "<table class=\"tablesorter sortable\" style=\"width: auto\">" ) ; System . out . println ( "<thead>" ) ; System . out . println ( "<tr>" ) ; System . out . println ( " <th valign='bottom' width=\"200\">Language</th>" ) ; System . out . println ( " <th valign='bottom' align=\"left\" width=\"60\">XML<br/>rules</th>" ) ; System . out . println ( " <th></th>" ) ; System . out . println ( " <th align=\"left\" width=\"60\">Java<br/>rules</th>" ) ; System . out . println ( " <th align=\"left\" width=\"60\">False<br/>friends</th>" ) ; System . out . println ( " <th valign='bottom' align=\"left\" width=\"70\">Activity</th>" ) ; System . out . println ( " <th valign='bottom' align=\"left\">Rule Maintainers</th>" ) ; System . out . println ( "</tr>" ) ; System . out . println ( "</thead>" ) ; System . out . println ( "<tbody>" ) ; final List < Language > sortedLanguages = getSortedLanguages ( ) ; final String falseFriendFile = JLanguageTool . getDataBroker ( ) . getRulesDir ( ) + File . separator + "false-friends.xml" ; final String falseFriendRules = StringTools . readStream ( Tools . getStream ( falseFriendFile ) , "utf-8" ) . replaceAll ( "(?s)<!--.*?-->" , "" ) . replaceAll ( "(?s)<rules.*?>" , "" ) ; int overallJavaCount = 0 ; int langSpecificWebsiteCount = 0 ; RuleActivityOverview activity = new RuleActivityOverview ( ) ; for ( final Language lang : sortedLanguages ) { if ( lang . isVariant ( ) ) { continue ; } System . out . print ( "<tr>" ) ; final String langCode = lang . getShortName ( ) ; final File langSpecificWebsite = new File ( webRoot , langCode ) ; final List < String > variants = getVariants ( sortedLanguages , lang ) ; String variantsText = "" ; if ( variants . size ( ) > 0 ) { variantsText = "<br/><span class='langVariants'>Variants for: " + StringUtils . join ( variants , ", " ) + "</span>" ; } if ( langSpecificWebsite . isDirectory ( ) ) { System . out . print ( "<td valign=\"top\"><a href=\"../" + langCode + "/\">" + lang . getName ( ) + "</a>" + variantsText + "</td>" ) ; langSpecificWebsiteCount ++ ; } else { System . out . print ( "<td valign=\"top\">" + lang . getName ( ) + " " + variantsText + "</td>" ) ; } int allRules = countRulesForLanguage ( lang ) ; if ( allRules == 0 ) { System . out . println ( "<td valign=\"top\" align=\"right\">0</td>" ) ; } else { final String ruleBase = "https://github.com/languagetool-org/languagetool/blob/master/languagetool-language-modules/" + langCode + "/src/main/resources/org/languagetool/rules/" ; System . out . print ( "<td valign=\"top\" align=\"right\">" + allRules + "</td>" ) ; System . out . print ( "<td valign=\"top\" align=\"right\">" + "<a href=\"http://community.languagetool.org/rule/list?lang=" + langCode + "\">Browse</a>,&nbsp;" + "<a href=\"" + ruleBase + langCode + "/grammar.xml\">XML</a>" + "</td>" ) ; } final File dir = new File ( "../languagetool-language-modules/" + langCode + "/src/main/java" + JLanguageTool . getDataBroker ( ) . getRulesDir ( ) + "/" + langCode ) ; if ( ! dir . exists ( ) ) { System . out . print ( "<td valign=\"top\" align=\"right\">0</td>" ) ; } else { final File [ ] javaRules = dir . listFiles ( new JavaFilter ( lang . getName ( ) ) ) ; final int javaCount = javaRules . length ; if ( javaCount > 0 ) { final String sourceCodeLink = "https://github.com/languagetool-org/languagetool/blob/master/languagetool-language-modules/" + langCode + "/src/main/java/org/languagetool/rules/" + langCode + "/" ; System . out . print ( "<td valign=\"top\" align=\"right\"><a href=\"" + sourceCodeLink + "\">" + javaCount + "</a></td>" ) ; } else { System . out . print ( "<td valign=\"top\" align=\"right\">" + javaCount + "</td>" ) ; } overallJavaCount ++ ; } final int count = countFalseFriendRules ( falseFriendRules , lang ) ; System . out . print ( "<td valign=\"top\" align=\"right\">" + count + "</td>" ) ; int commits = activity . getActivityFor ( lang , 365 / 2 ) ; int width = ( int ) Math . max ( commits * 0.5 , 1 ) ; String images = "" ; if ( width > 50 ) { images += "<img title='" + commits + " commits in the last 6 months' src='../images/bar-end.png' width='22' height='10'/>" ; width = 50 ; } images += "<img title='" + commits + " commits in the last 6 months' src='../images/bar.png' width='" + width + "' height='10'/>" ; System . out . print ( "<td valign=\"top\" align=\"right\"><span style='display:none'>" + commits + "</span>" + images + "</td>" ) ; final StringBuilder maintainerInfo = getMaintainerInfo ( lang ) ; final String maintainerText ; if ( langCode . equals ( "pt" ) ) { maintainerText = " - <span class='maintainerNeeded'><a href='http://wiki.languagetool.org/tasks-for-language-maintainers'>Looking for a maintainer for Brazilian Portuguese</a></span>" ; } else if ( LANGUAGES_WITH_NEW_MAINTAINER_NEED . contains ( langCode ) ) { maintainerText = " - <span class='maintainerNeeded'><a href='http://wiki.languagetool.org/tasks-for-language-maintainers'>Looking for new maintainer</a></span>" ; } else if ( LANGUAGES_WITH_CO_MAINTAINER_NEED . contains ( langCode ) ) { maintainerText = " - <span class='maintainerNeeded'><a href='http://wiki.languagetool.org/tasks-for-language-maintainers'>Looking for co-maintainer</a></span>" ; } else { maintainerText = "" ; } System . out . print ( "<td valign=\"top\" align=\"left\">" + maintainerInfo + maintainerText + "</td>" ) ; System . out . println ( "</tr>" ) ; } if ( overallJavaCount == 0 ) { throw new RuntimeException ( "No Java rules found - start this script from the languagetool-standalone directory" ) ; } if ( langSpecificWebsiteCount == 0 ) { throw new RuntimeException ( "No language specific websites found - please let the web root parameter " + "point to the 'www' directory (current value: '" + webRoot + "')" ) ; } System . out . println ( "</tbody>" ) ; System . out . println ( "</table>" ) ; } private int countRulesForLanguage ( Language lang ) throws IOException { List < String > ruleFileNames = lang . getRuleFileNames ( ) ; int count = 0 ; for ( String ruleFileName : ruleFileNames ) { final URL url = this . getClass ( ) . getResource ( ruleFileName ) ; if ( url != null ) { String xmlRules = StringTools . readStream ( Tools . getStream ( ruleFileName ) , "utf-8" ) ; xmlRules = xmlRules . replaceAll ( "(?s)<!--.*?-->" , "" ) ; xmlRules = xmlRules . replaceAll ( "(?s)<rules.*?>" , "" ) ; count += countXmlRules ( xmlRules ) ; count += countXmlRuleGroupRules ( xmlRules ) ; } } return count ; } private List < String > getVariants ( List < Language > allLanguages , Language lang ) { List < String > variants = new ArrayList < > ( ) ; for ( Language sortedLanguage : allLanguages ) { if ( sortedLanguage . isVariant ( ) && lang . getShortName ( ) . equals ( sortedLanguage . getShortName ( ) ) ) { variants . add ( sortedLanguage . getName ( ) . replaceAll ( ".*\\((.*?)\\).*" , "$1" ) . trim ( ) ) ; } } return variants ; } private List < Language > getSortedLanguages ( ) { final List < Language > sortedLanguages = new ArrayList < > ( Languages . get ( ) ) ; Collections . sort ( sortedLanguages , new Comparator < Language > ( ) { @ Override public int compare ( Language o1 , Language o2 ) { return o1 . getName ( ) . compareTo ( o2 . getName ( ) ) ; } } ) ; return sortedLanguages ; } private int countXmlRules ( String xmlRules ) { int pos = 0 ; int count = 0 ; while ( true ) { pos = xmlRules . indexOf ( "<rule " , pos + 1 ) ; if ( pos == - 1 ) { break ; } count ++ ; } return count ; } private int countXmlRuleGroupRules ( String xmlRules ) { int pos = 0 ; int countInRuleGroup = 0 ; while ( true ) { pos = xmlRules . indexOf ( "<rule>" , pos + 1 ) ; if ( pos == - 1 ) { break ; } countInRuleGroup ++ ; } return countInRuleGroup ; } private int countFalseFriendRules ( String falseFriendRules , Language lang ) { int pos = 0 ; int count = 0 ; while ( true ) { pos = falseFriendRules . indexOf ( "<pattern lang=\"" + lang . getShortName ( ) , pos + 1 ) ; if ( pos == - 1 ) { break ; } count ++ ; } return count ; } private StringBuilder getMaintainerInfo ( Language lang ) { final StringBuilder maintainerInfo = new StringBuilder ( ) ; if ( lang . getMaintainers ( ) != null ) { for ( Contributor contributor : lang . getMaintainers ( ) ) { if ( ! StringTools . isEmpty ( maintainerInfo . toString ( ) ) ) { maintainerInfo . append ( ", " ) ; } if ( contributor . getUrl ( ) != null ) { maintainerInfo . append ( "<a href=\"" ) ; maintainerInfo . append ( contributor . getUrl ( ) ) ; maintainerInfo . append ( "\">" ) ; } maintainerInfo . append ( contributor . getName ( ) ) ; if ( contributor . getUrl ( ) != null ) { maintainerInfo . append ( "</a>" ) ; } } } return maintainerInfo ; } private static class JavaFilter implements FileFilter { private final String langName ; JavaFilter ( String langName ) { this . langName = langName ; } @ Override public boolean accept ( final File f ) { final String filename = f . getName ( ) ; final boolean isAbstractTopClass = filename . endsWith ( langName + "Rule.java" ) ; final boolean isSpellerClass = filename . endsWith ( "SpellerRule.java" ) ; return filename . endsWith ( ".java" ) && ! isAbstractTopClass && ! isSpellerClass ; } } }
package org . languagetool . dev ; import org . languagetool . JLanguageTool ; import org . languagetool . rules . ConfusionSet ; import org . languagetool . rules . ConfusionSetLoader ; import java . io . IOException ; import java . io . InputStream ; import java . util . * ; final class ConfusionSetUrlGenerator { private ConfusionSetUrlGenerator ( ) { } public static void main ( String [ ] args ) throws IOException { ConfusionSetLoader confusionSetLoader = new ConfusionSetLoader ( ) ; InputStream inputStream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( "/en/homophones.txt" ) ; Map < String , List < ConfusionSet > > map = confusionSetLoader . loadConfusionSet ( inputStream ) ; String url = "http://storage.googleapis.com/books/ngrams/books/googlebooks-eng-all-2gram-20120701-<XX>.gz" ; Set < String > nameSet = new HashSet < > ( ) ; for ( String s : map . keySet ( ) ) { if ( s . length ( ) < 2 ) { nameSet . add ( s . substring ( 0 , 1 ) . toLowerCase ( ) + "_" ) ; } else { nameSet . add ( s . substring ( 0 , 2 ) . toLowerCase ( ) ) ; } } List < String > nameList = new ArrayList < > ( nameSet ) ; Collections . sort ( nameList ) ; for ( String name : nameList ) { System . out . println ( url . replace ( "<XX>" , name ) ) ; } System . err . println ( "Number of files: " + nameList . size ( ) ) ; } }
package org . languagetool . dev ; import java . io . * ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; import java . util . Scanner ; class VersionDiffGenerator { public static void main ( String [ ] args ) throws IOException { final VersionDiffGenerator generator = new VersionDiffGenerator ( ) ; generator . makeDiff ( args [ 0 ] ) ; } private void makeDiff ( String lang ) throws IOException { final List < Rule > oldRules = getRules ( new File ( "tools/ltdiff/old" ) ) ; final List < Rule > newRules = getRules ( new File ( "tools/ltdiff/new" ) ) ; final List < Rule > modifiedRules = new ArrayList < > ( ) ; Collections . sort ( oldRules ) ; Collections . sort ( newRules ) ; final FileWriter fileWriter = new FileWriter ( "changes_" + lang + ".html" ) ; final BufferedWriter out = new BufferedWriter ( fileWriter ) ; for ( Rule newRule1 : newRules ) { boolean found = false ; for ( int j = 0 ; j < oldRules . size ( ) && ! found ; j ++ ) { if ( newRule1 . id . equals ( oldRules . get ( j ) . id ) || newRule1 . name . equals ( oldRules . get ( j ) . name ) ) { found = true ; if ( newRule1 . numberOfExamples ( ) > oldRules . get ( j ) . numberOfExamples ( ) ) { final Rule r = newRule1 ; for ( int k = 0 ; k < r . correct . size ( ) ; k ++ ) { for ( int l = 0 ; l < oldRules . get ( j ) . correct . size ( ) && r . correct . size ( ) > 0 ; l ++ ) { if ( r . correct . get ( k ) . equals ( oldRules . get ( j ) . correct . get ( l ) ) ) { r . correct . remove ( k ) ; if ( k > 0 ) k -- ; } } } for ( int k = 0 ; k < r . incorrect . size ( ) ; k ++ ) { for ( int l = 0 ; l < oldRules . get ( j ) . incorrect . size ( ) && r . incorrect . size ( ) > 0 ; l ++ ) { if ( r . incorrect . get ( k ) . equals ( oldRules . get ( j ) . incorrect . get ( l ) ) ) { r . incorrect . remove ( k ) ; if ( k > 0 ) k -- ; } } } r . removeCorrectExamplesWithRelatedIncorrectExample ( ) ; modifiedRules . add ( r ) ; } } } if ( ! found ) { out . write ( "<tr class=\"new\"><td>4NEWRULE</td><td>" + newRule1 . name + newRule1 . getExamples ( false ) + "</td></tr>\n" ) ; } } for ( Rule modifiedRule : modifiedRules ) { out . write ( "<tr class=\"modified\"><td>6IMPROVEDRULE</td><td>" + modifiedRule . name + modifiedRule . getExamples ( true ) + "</td></tr>\n" ) ; } for ( Rule oldRule : oldRules ) { boolean found = false ; for ( Rule newRule : newRules ) { if ( newRule . id . equals ( oldRule . id ) || newRule . name . equals ( oldRule . name ) ) { found = true ; } } if ( ! found && ! oldRule . name . contains ( "<" ) ) { out . write ( "<tr class=\"removed\"><td>5REMOVEDRULE</td><td>" + oldRule . name + "</td></tr>\n" ) ; } } out . close ( ) ; } private List < Rule > getRules ( File file ) throws IOException { final List < Rule > rules = new ArrayList < > ( ) ; final Scanner scanner = new Scanner ( file ) ; Rule r = new Rule ( ) ; while ( scanner . hasNextLine ( ) ) { String line = scanner . nextLine ( ) ; if ( line . contains ( "id=\"" ) && line . contains ( "rule" ) ) { if ( ! line . contains ( "name=\"" ) ) { line += scanner . nextLine ( ) ; } if ( r . numberOfExamples ( ) > 0 ) { rules . add ( r ) ; r = new Rule ( ) ; } r . id = line ; r . name = line ; r . id = r . id . replaceAll ( ".*id=\"" , "" ) . replaceAll ( "\".*" , "" ) ; r . name = r . name . replaceAll ( ".*name=\"" , "" ) . replaceAll ( "\".*" , "" ) ; for ( Rule rule : rules ) { if ( r . name . equals ( rule . name ) ) { r . name += " " ; } } } else if ( line . contains ( "type=\"correct\"" ) || line . contains ( "type='correct'" ) ) { while ( ! line . contains ( "</example>" ) ) { line += scanner . nextLine ( ) ; } r . correct . add ( line . replaceAll ( "marker" , "b" ) . replaceAll ( ".*<example.*?>" , "" ) . replaceAll ( "</example>.*" , "" ) ) ; } else if ( line . contains ( "type=\"incorrect\"" ) || line . contains ( "type='incorrect'" ) ) { while ( ! line . contains ( "</example>" ) ) { line += scanner . nextLine ( ) ; } r . incorrect . add ( line . replaceAll ( "marker" , "b" ) . replaceAll ( ".*<example.*?>" , "" ) . replaceAll ( "</example>.*" , "" ) ) ; } } scanner . close ( ) ; return rules ; } class Rule implements Comparable < Rule > { private final List < String > correct = new ArrayList < > ( ) ; private final List < String > incorrect = new ArrayList < > ( ) ; private String name = "" ; private String id ; int numberOfExamples ( ) { return correct . size ( ) + incorrect . size ( ) ; } String getExamples ( boolean all ) { String s = "<div>" ; for ( String anIncorrect : incorrect ) { s += "<span>7FINDERR</span>" + anIncorrect + "<br/>" ; } if ( all ) { for ( String aCorrect : correct ) { s += "<span>8FINDNOTERR</span>" + aCorrect + "<br/>" ; } } s = s . substring ( 0 , s . length ( ) - 5 ) + "</div>" ; return s ; } public void removeCorrectExamplesWithRelatedIncorrectExample ( ) { for ( int i = 0 ; i < correct . size ( ) ; i ++ ) { boolean found = false ; for ( int j = 0 ; j < incorrect . size ( ) && ! found ; j ++ ) { String correctExample = correct . get ( i ) ; String incorrectExample = incorrect . get ( j ) ; if ( correctExample . startsWith ( incorrectExample . substring ( 0 , incorrectExample . indexOf ( "<b>" ) + 3 ) ) && correctExample . endsWith ( incorrectExample . substring ( incorrectExample . indexOf ( "</b>" ) ) ) ) { correct . remove ( i ) ; i -- ; found = true ; } } } } @ Override public int compareTo ( Rule r ) { return this . name . compareTo ( r . name ) ; } } }
package org . languagetool . dev ; import morfologik . fsa . FSA ; import org . apache . commons . io . FileUtils ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . JLanguageTool ; import org . languagetool . tagging . de . GermanTagger ; import java . io . File ; import java . io . IOException ; import java . nio . ByteBuffer ; import java . util . * ; public class MissingGenitiveFinder { private static final String DICT_FILENAME = "/de/german.dict" ; private final Map < String , Integer > occurrences ; private MissingGenitiveFinder ( ) throws IOException { occurrences = loadOccurrences ( "/media/Data/google-ngram/de/1gram-aggregated/all_without_underscore" ) ; } @ SuppressWarnings ( "unchecked" ) private Map < String , Integer > loadOccurrences ( String filename ) throws IOException { System . err . println ( "Loading " + filename ) ; Map < String , Integer > map = new HashMap < > ( ) ; List < String > lines = ( List < String > ) FileUtils . readLines ( new File ( filename ) ) ; for ( String line : lines ) { String [ ] parts = line . split ( " " ) ; map . put ( parts [ 0 ] , Integer . valueOf ( parts [ 1 ] ) ) ; } System . err . println ( "Loaded " + map . size ( ) + " occurrence items" ) ; return map ; } @ SuppressWarnings ( "UnnecessaryParentheses" ) private void run ( ) throws IOException { GermanTagger tagger = new GermanTagger ( ) ; final FSA fsa = FSA . read ( JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( DICT_FILENAME ) ) ; int i = 0 ; for ( ByteBuffer buffer : fsa ) { final byte [ ] sequence = new byte [ buffer . remaining ( ) ] ; buffer . get ( sequence ) ; final String output = new String ( sequence , "iso-8859-1" ) ; boolean isNoun = output . contains ( "+SUB:" ) || ( output . contains ( "+EIG:" ) && output . contains ( "COU" ) ) ; if ( isNoun && output . contains ( ":GEN:" ) ) { final String [ ] parts = output . split ( "\\+" ) ; String word = parts [ 0 ] ; String esWord = parts [ 0 ] . replaceFirst ( "s$" , "es" ) ; if ( isRelevantWord ( word ) ) { boolean hasEsGenitive = hasEsGenitive ( tagger , word ) ; boolean ignore1 = word . endsWith ( "els" ) && ! word . endsWith ( "iels" ) ; Integer occurrence = occurrences . get ( esWord ) ; if ( ! hasEsGenitive && ! ignore1 && occurrence != null ) { System . out . println ( esWord + "\t" + word . replaceFirst ( "s$" , "" ) + "\t" + parts [ 2 ] ) ; i ++ ; } } } } } private boolean isRelevantWord ( String word ) { return word . endsWith ( "s" ) && ! word . endsWith ( "es" ) && ! word . endsWith ( "ens" ) && ! word . endsWith ( "ems" ) && ! word . endsWith ( "els" ) && ! word . endsWith ( "ers" ) && ! word . endsWith ( "lings" ) && ! word . endsWith ( "leins" ) && ! word . endsWith ( "chens" ) && ! word . endsWith ( "erns" ) && ! word . endsWith ( "elns" ) && ! word . endsWith ( "os" ) && ! word . endsWith ( "us" ) && ! word . endsWith ( "is" ) && ! word . endsWith ( "as" ) && ! word . endsWith ( "ols" ) ; } private boolean hasEsGenitive ( GermanTagger tagger , String word ) throws IOException { String esForm = word . replaceFirst ( "s$" , "es" ) ; List < AnalyzedTokenReadings > readings = tagger . tag ( Collections . singletonList ( esForm ) ) ; for ( AnalyzedTokenReadings reading : readings ) { if ( reading . isTagged ( ) ) { return true ; } } return false ; } public static void main ( String [ ] args ) throws IOException { MissingGenitiveFinder prg = new MissingGenitiveFinder ( ) ; prg . run ( ) ; } }
package org . languagetool . tokenizers . ro ; import java . util . List ; import junit . framework . TestCase ; public class RomanianWordTokenizerTest extends TestCase { public void testTokenize ( ) { RomanianWordTokenizer w = new RomanianWordTokenizer ( ) ; List < String > testList = w . tokenize ( "Aceaste mese sunt bune" ) ; assertEquals ( testList . size ( ) , 7 ) ; assertEquals ( "[Aceaste, , mese, , sunt, , bune]" , testList . toString ( ) ) ; testList = w . tokenize ( "Această carte este frumoasă" ) ; assertEquals ( testList . size ( ) , 7 ) ; assertEquals ( "[Această, , carte, , este, , frumoasă]" , testList . toString ( ) ) ; testList = w . tokenize ( "nu-ți doresc" ) ; assertEquals ( testList . size ( ) , 5 ) ; assertEquals ( "[nu, -, ți, , doresc]" , testList . toString ( ) ) ; testList = w . tokenize ( "zicea „merge" ) ; assertEquals ( testList . size ( ) , 4 ) ; assertEquals ( "[zicea, , „, merge]" , testList . toString ( ) ) ; testList = w . tokenize ( "zicea „ merge" ) ; assertEquals ( testList . size ( ) , 5 ) ; assertEquals ( "[zicea, , „, , merge]" , testList . toString ( ) ) ; testList = w . tokenize ( "zicea merge”" ) ; assertEquals ( testList . size ( ) , 4 ) ; assertEquals ( "[zicea, , merge, ”]" , testList . toString ( ) ) ; testList = w . tokenize ( "zicea „merge bine”" ) ; assertEquals ( testList . size ( ) , 7 ) ; assertEquals ( "[zicea, , „, merge, , bine, ”]" , testList . toString ( ) ) ; testList = w . tokenize ( "ți-am" ) ; assertEquals ( testList . size ( ) , 3 ) ; assertEquals ( "[ți, -, am]" , testList . toString ( ) ) ; testList = w . tokenize ( "zicea «merge bine»" ) ; assertEquals ( testList . size ( ) , 7 ) ; assertEquals ( "[zicea, , «, merge, , bine, »]" , testList . toString ( ) ) ; testList = w . tokenize ( "zicea <<merge bine>>" ) ; assertEquals ( testList . size ( ) , 9 ) ; assertEquals ( "[zicea, , <, <, merge, , bine, >, >]" , testList . toString ( ) ) ; testList = w . tokenize ( "avea 15% apă" ) ; assertEquals ( testList . size ( ) , 6 ) ; assertEquals ( "[avea, , 15, %, , apă]" , testList . toString ( ) ) ; testList = w . tokenize ( "are 30°C" ) ; assertEquals ( testList . size ( ) , 5 ) ; assertEquals ( "[are, , 30, °, C]" , testList . toString ( ) ) ; testList = w . tokenize ( "fructe=mere" ) ; assertEquals ( testList . size ( ) , 3 ) ; assertEquals ( "[fructe, =, mere]" , testList . toString ( ) ) ; testList = w . tokenize ( "pere|mere" ) ; assertEquals ( testList . size ( ) , 3 ) ; assertEquals ( "[pere, |, mere]" , testList . toString ( ) ) ; testList = w . tokenize ( "pere\nmere" ) ; assertEquals ( testList . size ( ) , 3 ) ; assertEquals ( "[pere, \n, mere]" , testList . toString ( ) ) ; testList = w . tokenize ( "pere\rmere" ) ; assertEquals ( testList . size ( ) , 3 ) ; assertEquals ( "[pere, \r, mere]" , testList . toString ( ) ) ; testList = w . tokenize ( "pere\n\rmere" ) ; assertEquals ( testList . size ( ) , 4 ) ; assertEquals ( "[pere, \n, \r, mere]" , testList . toString ( ) ) ; } }
package org . languagetool . dev . blogs ; import org . apache . commons . io . FileUtils ; import org . apache . commons . lang . StringEscapeUtils ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . commandline . CommandLineTools ; import java . io . File ; import java . io . IOException ; class BlogChecker { private void check ( File dir , Language lang ) throws IOException { JLanguageTool lt = new JLanguageTool ( lang ) ; lt . disableRule ( "WHITESPACE_RULE" ) ; lt . disableRule ( "UNPAIRED_BRACKETS" ) ; File [ ] files = dir . listFiles ( ) ; for ( File file : files ) { System . out . println ( "\n=== " + file . getName ( ) + " ================================" ) ; String content = cleanup ( FileUtils . readFileToString ( file , "utf-8" ) ) ; CommandLineTools . checkText ( content , lt ) ; } } private String cleanup ( String content ) { String result = content . replaceAll ( "\\s+" , " " ) . replaceAll ( "<div.*?>" , "" ) . replaceAll ( "</div>" , "\n\n" ) . replaceAll ( "</h[1-6]>" , "\n\n" ) . replaceAll ( "<li>" , "\n" ) . replaceAll ( "<p.*?>" , "" ) . replaceAll ( "</p>" , "\n\n" ) . replaceAll ( "<a.*?>" , "" ) . replaceAll ( "</a>" , "" ) . replaceAll ( "<br\\s*/>" , "" ) . replaceAll ( "<br>" , "" ) . replaceAll ( "<.*?>" , "" ) ; return StringEscapeUtils . unescapeHtml ( result ) . replace ( " " , " " ) ; } public static void main ( String [ ] args ) throws IOException { if ( args . length != 2 ) { System . err . println ( "Usage: " + BlogChecker . class . getSimpleName ( ) + " <langCode> <contentDir>" ) ; System . exit ( 1 ) ; } BlogChecker checker = new BlogChecker ( ) ; Language lang = Languages . getLanguageForShortName ( args [ 0 ] ) ; checker . check ( new File ( args [ 1 ] ) , lang ) ; } }
package org . languagetool . dev . blogs ; import com . fasterxml . jackson . databind . ObjectMapper ; import com . sun . syndication . feed . synd . SyndEntryImpl ; import com . sun . syndication . feed . synd . SyndFeed ; import com . sun . syndication . io . SyndFeedInput ; import com . sun . syndication . io . XmlReader ; import org . apache . commons . io . FileUtils ; import org . languagetool . tools . StringTools ; import java . io . * ; import java . net . URL ; import java . util . ArrayList ; import java . util . List ; import java . util . Map ; import java . util . Scanner ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; class BlogFetcher { private static final String READABILITY_API_KEY_FILE = "/home/dnaber/.readability-parser.txt" ; private static final Pattern linkPattern = Pattern . compile ( "<link[^>]+?type=\"application/rss\\+xml\"[^>]+?/>" , Pattern . DOTALL ) ; private static final Pattern linkHrefPattern = Pattern . compile ( "href=[\"'](.*?)[\"']" ) ; private final String secretReadabilityToken ; BlogFetcher ( String secretReadabilityToken ) { this . secretReadabilityToken = secretReadabilityToken ; } private List < String > getBlogContent ( String url ) throws IOException { List < String > result = new ArrayList < > ( ) ; String content = getContent ( new URL ( url ) ) ; Matcher matcher = linkPattern . matcher ( content ) ; if ( matcher . find ( ) ) { String linkContent = matcher . group ( ) ; Matcher hrefMatcher = linkHrefPattern . matcher ( linkContent ) ; if ( hrefMatcher . find ( ) ) { String feedUrl = hrefMatcher . group ( 1 ) ; SyndFeedInput input = new SyndFeedInput ( ) ; try { SyndFeed feed = input . build ( new XmlReader ( new URL ( feedUrl ) ) ) ; List < String > contentList = getContent ( feed . getEntries ( ) ) ; result . addAll ( contentList ) ; return result ; } catch ( Exception e ) { throw new RuntimeException ( "Could not get feed data from " + feedUrl , e ) ; } } else { System . err . println ( "No 'href' found for feed: " + url ) ; } } System . err . println ( "No '<link>' found for feed: " + url ) ; return result ; } private List < String > getContent ( List entries ) throws IOException { List < String > result = new ArrayList < > ( ) ; for ( Object entry : entries ) { SyndEntryImpl syndEntry = ( SyndEntryImpl ) entry ; System . out . println ( " Getting " + syndEntry . getUri ( ) ) ; String json = getPageContent ( syndEntry . getUri ( ) ) ; ObjectMapper mapper = new ObjectMapper ( ) ; Map map = mapper . readValue ( json , Map . class ) ; result . add ( map . get ( "content" ) . toString ( ) ) ; } return result ; } private String getContent ( URL pageUrl ) throws IOException { try ( InputStream inputStream = pageUrl . openStream ( ) ) { return StringTools . streamToString ( inputStream , "utf-8" ) ; } } private String getPageContent ( String pageUrl ) throws IOException { if ( ! pageUrl . startsWith ( "http" ) ) { throw new IllegalArgumentException ( "Invalid feed URL: " + pageUrl ) ; } URL url = new URL ( "https://www.readability.com/api/content/v1/parser?url=" + pageUrl + "&token=" + secretReadabilityToken ) ; return getContent ( url ) ; } public static void main ( String [ ] args ) throws IOException { if ( args . length != 2 ) { System . err . println ( "Usage: " + BlogFetcher . class . getSimpleName ( ) + " <urlListFile> <outputDir>" ) ; System . exit ( 1 ) ; } String secret = FileUtils . readFileToString ( new File ( READABILITY_API_KEY_FILE ) , "utf-8" ) . trim ( ) ; BlogFetcher fetcher = new BlogFetcher ( secret ) ; File outputDir = new File ( args [ 1 ] ) ; if ( ! outputDir . exists ( ) || ! outputDir . isDirectory ( ) ) { System . err . println ( "Output directory does not exist or is not a directory: " + outputDir ) ; System . exit ( 1 ) ; } try ( Scanner scanner = new Scanner ( new File ( args [ 0 ] ) ) ) { while ( scanner . hasNextLine ( ) ) { String url = scanner . nextLine ( ) ; try { File output = new File ( outputDir , new URL ( url ) . getHost ( ) ) ; System . out . println ( "Working on " + url + ", writing result to " + output ) ; List < String > blogContentList = fetcher . getBlogContent ( url ) ; try ( FileWriter writer = new FileWriter ( output ) ) { for ( String content : blogContentList ) { writer . write ( content ) ; writer . write ( "\n" ) ; } } } catch ( Exception e ) { e . printStackTrace ( ) ; } } } } }
package org . languagetool . dev . conversion ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . net . URISyntaxException ; import java . net . URL ; import java . util . * ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import morfologik . stemming . Dictionary ; import morfologik . stemming . DictionaryLookup ; import morfologik . stemming . IStemmer ; import morfologik . stemming . WordData ; import org . languagetool . JLanguageTool ; public class AtdRuleConverter extends RuleConverter { private static final Pattern nounInPattern = Pattern . compile ( "NN(?!P|S|\\.)" ) ; private static final Pattern wordReference = Pattern . compile ( "\\\\(\\d+)" ) ; private static final Pattern wordReferenceTransform = Pattern . compile ( "\\\\(\\d+):([^:]+)" ) ; private static final Pattern uppercase = Pattern . compile ( "[A-Z]" ) ; private static final String ENGLISH_DICT = "/en/english.dict" ; private static IStemmer dictLookup = ( DictionaryLookup ) loadDictionary ( ) ; private String avoidMessage = "" ; public AtdRuleConverter ( ) { super ( ) ; } public AtdRuleConverter ( String inFile , String outFile , String specificFileType ) { super ( inFile , outFile , specificFileType ) ; } @ Override public String getOriginalRuleString ( Object ruleObject ) { return ( String ) ruleObject ; } @ Override public String generateName ( Object ruleObject ) { String name = "rule_" + nameIndex ; nameIndex ++ ; return name ; } @ Override public String generateId ( Object ruleObject ) { String name = "rule_" + idIndex ; idIndex ++ ; return name ; } @ Override public String [ ] getAcceptableFileTypes ( ) { String [ ] ft = { "default" , "avoid" } ; return ft ; } @ Override public void parseRuleFile ( ) throws IOException { Scanner in = new Scanner ( new FileInputStream ( inFileName ) ) ; List < String > ruleList = new ArrayList < > ( ) ; try { int lineCount = 0 ; while ( in . hasNextLine ( ) ) { String line = in . nextLine ( ) . trim ( ) ; if ( line . startsWith ( "#?" ) && lineCount == 0 && ruleType . equals ( "avoid" ) ) { avoidMessage = line . substring ( 2 ) ; } else if ( line . startsWith ( "#" ) || line . equals ( "" ) ) { continue ; } else { if ( line . contains ( "#" ) ) { line = line . substring ( 0 , line . indexOf ( "#" ) ) ; } ruleList . add ( line ) ; } lineCount ++ ; } } finally { in . close ( ) ; } ruleObjects = ruleList ; allLtRules = new ArrayList < > ( ) ; ltRules = new ArrayList < > ( ) ; disambiguationRules = new ArrayList < > ( ) ; originalRuleStrings = new ArrayList < > ( ) ; warnings = new ArrayList < > ( ) ; for ( Object ruleObject : ruleObjects ) { String ruleString = ( String ) ruleObject ; HashMap < String , String > ruleMap = parseRule ( ruleString ) ; List < String > ruleAsList = ltRuleAsList ( ruleMap , getIdFromName ( ruleMap . get ( "name" ) ) , fixName ( ruleMap . get ( "name" ) ) , this . ruleType ) ; if ( notKilledRule ( ruleMap ) ) { ltRules . add ( ruleAsList ) ; } else { disambiguationRules . add ( ruleAsList ) ; } allLtRules . add ( ruleAsList ) ; originalRuleStrings . add ( ruleMap . get ( "ruleString" ) ) ; } } @ Override public boolean isDisambiguationRule ( Object ruleObject ) { String rule = ( String ) ruleObject ; Map < String , String > ruleMap = parseRule ( rule ) ; return ( ruleMap . containsKey ( "filter" ) && ( ruleMap . get ( "filter" ) . equals ( "kill" ) || ruleMap . get ( "filter" ) . equals ( "die" ) ) ) ; } public HashMap < String , String > parseRule ( String rule ) { HashMap < String , String > outRule = new HashMap < > ( ) ; if ( this . ruleType . equals ( "default" ) ) { String [ ] splitRule = rule . split ( "::" ) ; outRule . put ( "pattern" , splitRule [ 0 ] ) ; outRule . put ( "name" , getNameFromPattern ( splitRule [ 0 ] ) ) ; if ( splitRule . length > 1 ) { for ( int i = 1 ; i < splitRule . length ; i ++ ) { String [ ] splitDeclaration = splitRule [ i ] . split ( "=" ) ; try { outRule . put ( splitDeclaration [ 0 ] , splitDeclaration [ 1 ] ) ; } catch ( ArrayIndexOutOfBoundsException e ) { System . err . println ( "Incorrect declaration for rule " + rule + "; rule skipped" ) ; } } } } else if ( this . ruleType . equals ( "avoid" ) ) { if ( rule . contains ( "::word" ) ) { String [ ] splitRule = rule . split ( "::" ) ; outRule . put ( "pattern" , splitRule [ 0 ] ) ; outRule . put ( "name" , getNameFromPattern ( splitRule [ 0 ] ) ) ; if ( splitRule . length > 1 ) { for ( int i = 1 ; i < splitRule . length ; i ++ ) { String [ ] splitDeclaration = splitRule [ i ] . split ( "=" ) ; try { outRule . put ( splitDeclaration [ 0 ] , splitDeclaration [ 1 ] ) ; } catch ( ArrayIndexOutOfBoundsException e ) { System . err . println ( "Incorrect declaration for rule " + rule + "; rule skipped" ) ; } } } } else { String [ ] splitRule = rule . split ( "\t+" ) ; outRule . put ( "pattern" , splitRule [ 0 ] ) ; outRule . put ( "name" , getNameFromPattern ( splitRule [ 0 ] ) ) ; if ( splitRule . length > 1 ) { outRule . put ( "explanation" , splitRule [ 1 ] ) ; } else { outRule . put ( "explanation" , "" ) ; } } } if ( isCaseSensitiveRule ( outRule . get ( "pattern" ) ) ) { outRule . put ( "casesensitive" , "true" ) ; } else { outRule . put ( "casesensitive" , "false" ) ; } outRule . put ( "ruleString" , rule ) ; return outRule ; } @ SuppressWarnings ( "unchecked" ) @ Override public List < String > ltRuleAsList ( Object ruleObject , String id , String name , String type ) { Collection < HashMap < String , String > > outerList = new ArrayList < > ( ) ; HashMap < String , String > mainRule = ( HashMap < String , String > ) ruleObject ; ArrayList < String > currentWarnings = new ArrayList < > ( ) ; String [ ] mainPattern = mainRule . get ( "pattern" ) . split ( "\\ +" ) ; for ( int i = 0 ; i < mainPattern . length ; i ++ ) { mainPattern [ i ] = expandMacro ( mainPattern [ i ] ) ; } mainRule . put ( "pattern" , gluePattern ( mainPattern ) ) ; if ( isApostropheCase ( mainRule . get ( "pattern" ) . split ( "\\ +" ) ) ) { Iterable < HashMap < String , String > > splitRules = handleApostropheCase ( mainRule , ruleObject , type ) ; for ( HashMap < String , String > splitRule : splitRules ) { outerList . add ( splitRule ) ; } } else { outerList . add ( mainRule ) ; } List < String > bigLtRule = new ArrayList < > ( ) ; bigLtRule . add ( "<!-- " + mainRule . get ( "ruleString" ) + " -->" ) ; if ( outerList . size ( ) > 1 ) { bigLtRule . add ( "<rulegroup id=\"" + id + "\" name=\"" + name + "\">" ) ; } for ( HashMap < String , String > rule : outerList ) { ArrayList < String > ltRule = new ArrayList < > ( ) ; if ( outerList . size ( ) == 1 ) { ltRule . add ( firstIndent + "<rule id=\"" + id + "\" name=\"" + name + "\">" ) ; } else { ltRule . add ( firstIndent + "<rule>" ) ; } String exceptions = null ; if ( rule . containsKey ( "avoid" ) ) { exceptions = getAvoidWords ( rule . get ( "avoid" ) ) ; } if ( Boolean . parseBoolean ( rule . get ( "casesensitive" ) ) ) { ltRule . add ( secondIndent + "<pattern case_sensitive=\"yes\">" ) ; } else { ltRule . add ( secondIndent + "<pattern>" ) ; } String [ ] pattern = rule . get ( "pattern" ) . split ( "\\ +" ) ; String [ ] newpattern = fixApostrophes ( pattern ) ; String suggestion = null ; if ( rule . containsKey ( "word" ) ) { suggestion = rule . get ( "word" ) ; if ( rule . get ( "pattern" ) . contains ( "'" ) ) { if ( ! currentWarnings . contains ( WARNINGS . APOSTROPHES . value ) ) { currentWarnings . add ( WARNINGS . APOSTROPHES . value ) ; } } } pattern = newpattern ; for ( String e : pattern ) { currentWarnings = getWarningsFromPatternElement ( currentWarnings , e ) ; ltRule = addTokenHelper ( ltRule , e , thirdIndentInt , exceptions ) ; } ltRule . add ( secondIndent + "</pattern>" ) ; if ( suggestion != null ) { currentWarnings = getWarningsFromSuggestion ( currentWarnings , suggestion ) ; ltRule = addSuggestion ( ltRule , suggestion , pattern , secondIndentInt ) ; } if ( rule . containsKey ( "explanation" ) ) { String explanation = rule . get ( "explanation" ) ; ltRule = addExplanation ( ltRule , explanation , secondIndentInt ) ; } if ( rule . containsKey ( "filter" ) ) { if ( rule . get ( "filter" ) . equals ( "kill" ) || rule . get ( "filter" ) . equals ( "die" ) ) { ltRule . add ( secondIndent + "<disambig action=\"immunize\"/>" ) ; } else { currentWarnings = getWarningsFromFilter ( currentWarnings , rule . get ( "filter" ) ) ; } } ltRule . add ( firstIndent + "</rule>" ) ; bigLtRule . addAll ( ltRule ) ; } if ( outerList . size ( ) > 1 ) { bigLtRule . add ( "</rulegroup>" ) ; } warnings . add ( currentWarnings . toArray ( new String [ currentWarnings . size ( ) ] ) ) ; return bigLtRule ; } private String getNameFromPattern ( String pattern ) { String [ ] sp = pattern . split ( "\\s+" ) ; StringBuilder name = new StringBuilder ( ) ; for ( String s : sp ) { if ( ! hasPosTag ( s ) ) { String [ ] orSplit = s . split ( "\\|" ) ; if ( orSplit . length > 3 ) { String truncOr = orSplit [ 0 ] + "|" + orSplit [ 1 ] + "|" + orSplit [ 2 ] ; name . append ( truncOr ) . append ( " " ) ; } else { name . append ( s ) . append ( " " ) ; } } else if ( justPosTag ( s ) ) { String [ ] ss = s . split ( "/" ) ; name . append ( ss [ 1 ] ) . append ( " " ) ; } else { name . append ( s ) . append ( " " ) ; } } return name . toString ( ) . trim ( ) ; } private String getIdFromName ( String name ) { name = name . replaceAll ( "\\ +" , "_" ) ; name = name . replaceAll ( "<|>|!|&|\\.|\\*|\\+|/|\\[.*?\\]" , "" ) ; name = name . toUpperCase ( Locale . ENGLISH ) ; return name ; } private String fixName ( String name ) { name = name . replaceAll ( "<|>|!|&|\\.|\\*|\\+|/|\\[.*?\\]" , "" ) ; return name ; } private ArrayList < String > getWarningsFromPatternElement ( ArrayList < String > curWarn , String element ) { String token ; if ( hasPosTag ( element ) ) { token = element . split ( "/" ) [ 0 ] ; } else { token = element ; } if ( isRegex ( token ) && ( token . contains ( "<" ) || token . contains ( ">" ) ) ) { if ( ! curWarn . contains ( WARNINGS . ANGLE_BRACKETS . value ) ) { curWarn . add ( WARNINGS . ANGLE_BRACKETS . value ) ; } } if ( justPosTag ( element ) ) { if ( ! curWarn . contains ( WARNINGS . EXCLUSIVE . value ) ) { curWarn . add ( WARNINGS . EXCLUSIVE . value ) ; } } return curWarn ; } private ArrayList < String > getWarningsFromSuggestion ( ArrayList < String > curWarn , String sugg ) { String [ ] splitSuggs = sugg . split ( ",\\s*" ) ; for ( String ss : splitSuggs ) { String [ ] suggestionParts = ss . split ( "\\ +" ) ; for ( String sp : suggestionParts ) { String transform = getTransformString ( sp ) ; switch ( transform ) { case ":positive" : if ( ! curWarn . contains ( WARNINGS . POSITIVE . value ) ) { curWarn . add ( WARNINGS . POSITIVE . value ) ; } break ; case ":determiner" : if ( ! curWarn . contains ( WARNINGS . DETERMINER . value ) ) { curWarn . add ( WARNINGS . DETERMINER . value ) ; } break ; case ":nosuffix" : if ( ! curWarn . contains ( WARNINGS . NO_SUFFIX . value ) ) { curWarn . add ( WARNINGS . NO_SUFFIX . value ) ; } break ; } } } return curWarn ; } private ArrayList < String > getWarningsFromFilter ( ArrayList < String > curWarn , String filter ) { switch ( filter ) { case "indefarticle" : if ( ! curWarn . contains ( WARNINGS . INDEFARTICLE . value ) ) { curWarn . add ( WARNINGS . INDEFARTICLE . value ) ; } break ; case "stats" : if ( ! curWarn . contains ( WARNINGS . STATS . value ) ) { curWarn . add ( WARNINGS . STATS . value ) ; } break ; case "nextonly" : if ( ! curWarn . contains ( WARNINGS . NEXTONLY . value ) ) { curWarn . add ( WARNINGS . NEXTONLY . value ) ; } break ; } return curWarn ; } private String [ ] fixApostrophes ( String [ ] p ) { ArrayList < String > retList = new ArrayList < > ( ) ; for ( String s : p ) { if ( s . equals ( "'" ) ) { retList . add ( s ) ; } else if ( s . contains ( "'" ) ) { String [ ] temp = s . replaceAll ( "'" , " ' " ) . split ( "\\ +" ) ; Collections . addAll ( retList , temp ) ; } else { retList . add ( s ) ; } } return retList . toArray ( new String [ retList . size ( ) ] ) ; } public boolean isApostropheCase ( String [ ] pattern ) { for ( String s : pattern ) { if ( s . contains ( "'" ) && s . contains ( "|" ) ) { return true ; } } return false ; } public List < HashMap < String , String > > handleApostropheCase ( HashMap < String , String > rule , Object ruleObject , String type ) { String [ ] pattern = rule . get ( "pattern" ) . split ( "\\ +" ) ; String oldSuggestion = null ; if ( rule . containsKey ( "word" ) ) { oldSuggestion = rule . get ( "word" ) ; } String offendingToken = "" ; int offendingTokenIndex = 0 ; for ( int i = 0 ; i < pattern . length ; i ++ ) { String token = pattern [ i ] ; if ( token . contains ( "'" ) && token . contains ( "|" ) ) { offendingToken = token ; offendingTokenIndex = i ; break ; } } String [ ] brokenToken = offendingToken . split ( "\\|" ) ; HashMap < String , ArrayList < String > > suffixMap = new HashMap < > ( ) ; for ( String token : brokenToken ) { if ( ! token . contains ( "'" ) ) { suffixMap = addItemSmart ( suffixMap , "regular" , token ) ; } else { String [ ] splitToken = token . split ( "'" ) ; if ( splitToken . length == 1 ) { suffixMap = addItemSmart ( suffixMap , "" , splitToken [ 0 ] ) ; } else { suffixMap = addItemSmart ( suffixMap , splitToken [ 1 ] , splitToken [ 0 ] ) ; } } } Collection < String > newPatterns = new ArrayList < > ( ) ; for ( String suffix : suffixMap . keySet ( ) ) { String newPattern = "" ; for ( int i = 0 ; i < pattern . length ; i ++ ) { if ( i == offendingTokenIndex ) { Iterable < String > prefixes = suffixMap . get ( suffix ) ; String prefixString = "" ; for ( String prefix : prefixes ) { prefixString = prefixString + prefix + "|" ; } prefixString = prefixString . substring ( 0 , prefixString . length ( ) - 1 ) ; if ( suffix . equals ( "regular" ) ) { newPattern = newPattern + prefixString + " " ; } else { newPattern = newPattern + prefixString + " ' " + suffix + " " ; } } else { newPattern = newPattern + pattern [ i ] + " " ; } } newPattern = newPattern . trim ( ) ; newPatterns . add ( newPattern ) ; } List < HashMap < String , String > > allRules = new ArrayList < > ( ) ; for ( String newPattern : newPatterns ) { HashMap < String , String > r = new HashMap < > ( rule ) ; r . put ( "pattern" , newPattern ) ; if ( oldSuggestion != null ) { } allRules . add ( r ) ; } return allRules ; } public static boolean isMacro ( String e ) { return e . contains ( "&" ) ; } public static String expandMacro ( String e ) { if ( e . charAt ( 0 ) == '&' ) { return MACRO_EXPANSIONS . valueOf ( e . substring ( 1 ) ) . value ; } else { return e ; } } public String getAvoidWords ( String exceptions ) { String [ ] avoidWords = exceptions . split ( ", " ) ; String retString = "" ; for ( String s : avoidWords ) { retString = retString + s + "|" ; } retString = retString . substring ( 0 , retString . length ( ) - 1 ) ; return retString ; } public ArrayList < String > addTokenHelper ( ArrayList < String > ltRule , String e , int spaces , String exceptions ) { if ( e . equals ( "0BEGIN.0" ) ) { ltRule = addToken ( ltRule , "" , SENT_START , null , false , false , false , 0 , thirdIndentInt ) ; return ltRule ; } if ( e . equals ( "0END.0" ) ) { ltRule = addToken ( ltRule , "" , SENT_END , null , false , false , false , 0 , thirdIndentInt ) ; return ltRule ; } if ( hasPosTag ( e ) ) { String [ ] parts = e . split ( "/" ) ; parts [ 1 ] = fixNoun ( parts [ 1 ] ) ; ltRule = addToken ( ltRule , parts [ 0 ] , parts [ 1 ] , exceptions , false , false , false , 0 , thirdIndentInt ) ; } else { ltRule = addToken ( ltRule , e , null , exceptions , false , false , false , 0 , thirdIndentInt ) ; } return ltRule ; } private static ArrayList < String > addSuggestion ( ArrayList < String > orig , String suggestion , String [ ] pattern , int indent ) { String space = getSpace ( indent ) ; orig . add ( space + "<message> " + expandSuggestion ( suggestion , pattern ) + "</message>" ) ; return orig ; } private ArrayList < String > addExplanation ( ArrayList < String > orig , String explanation , int indent ) { String space = getSpace ( indent ) ; String explanationString = "" ; if ( ! explanation . equals ( "" ) ) { explanationString = " \"" + explanation + "\"" ; } orig . add ( space + "<message>" + avoidMessage + explanationString + "</message>" ) ; return orig ; } public static String expandSuggestion ( String suggestion , String [ ] pattern ) { String [ ] splitSuggestion = suggestion . split ( "," ) ; StringBuilder sb = new StringBuilder ( ) ; sb . append ( "Did you mean " ) ; for ( int i = 0 ; i < splitSuggestion . length ; i ++ ) { String s = splitSuggestion [ i ] ; String [ ] ss = s . split ( "\\ +" ) ; for ( int j = 0 ; j < ss . length ; j ++ ) { String e = ss [ j ] ; Matcher m2 = wordReferenceTransform . matcher ( e ) ; Matcher m1 = wordReference . matcher ( e ) ; if ( m2 . find ( ) ) { ss [ j ] = expandTransform ( e , pattern ) ; } else if ( m1 . find ( ) ) { int numMatched = Integer . parseInt ( m1 . group ( ) . replaceAll ( "\\\\" , "" ) ) ; if ( Arrays . asList ( pattern ) . contains ( "0BEGIN.0" ) ) { numMatched ++ ; } ss [ j ] = "<match no=\"" + Integer . toString ( numMatched + 1 ) + "\"/>" ; } } sb . append ( "<suggestion>" ) ; for ( int j = 0 ; j < ss . length ; j ++ ) { sb . append ( ss [ j ] ) ; if ( j < ss . length - 1 ) { sb . append ( " " ) ; } } sb . append ( "</suggestion>" ) ; if ( i < splitSuggestion . length - 1 && splitSuggestion . length > 1 ) { sb . append ( " or " ) ; } } sb . append ( "?" ) ; return sb . toString ( ) ; } public static String expandTransform ( String element , String [ ] pattern ) { String [ ] se = element . split ( ":" ) ; int numMatched = Integer . parseInt ( se [ 0 ] . replaceAll ( "\\\\" , "" ) ) ; if ( Arrays . asList ( pattern ) . contains ( "0BEGIN.0" ) ) { numMatched ++ ; } String transform = se [ 1 ] ; String retString = null ; String refWord = pattern [ numMatched ] ; switch ( transform ) { case "nosuffix" : if ( refWord . endsWith ( "able" ) || refWord . endsWith ( "ible" ) ) { String strip = refWord . substring ( 0 , refWord . length ( ) - 4 ) ; if ( inDictionary ( strip . concat ( "ated" ) ) ) { retString = strip . concat ( "ated" ) ; } else if ( inDictionary ( strip . concat ( "e" ) ) ) { retString = strip . concat ( "e" ) ; } else if ( inDictionary ( strip . concat ( "y" ) ) ) { retString = strip . concat ( "y" ) ; } else if ( inDictionary ( strip ) ) { retString = strip ; } else { retString = refWord ; } } else { retString = refWord ; } break ; case "upper" : retString = "<match no=\"" + Integer . toString ( numMatched + 1 ) + "\" case_conversion=\"startupper\" />" ; break ; case "lower" : retString = "<match no=\"" + Integer . toString ( numMatched + 1 ) + "\" case_conversion=\"alllower\" />" ; break ; case "singular" : retString = "<match no=\"" + Integer . toString ( numMatched + 1 ) + "\" postag=\"NNP|NN(:U.?)?\" postag_regexp=\"yes\" />" ; break ; case "plural" : retString = "<match no=\"" + Integer . toString ( numMatched + 1 ) + "\" postag=\"NNPS|NNS\" postag_regexp=\"yes\" />" ; break ; case "participle" : retString = "<match no=\"" + Integer . toString ( numMatched + 1 ) + "\" postag=\"VBN\" />" ; break ; case "base" : retString = "<match no=\"" + Integer . toString ( numMatched + 1 ) + "\" postag=\"VB\" />" ; break ; case "past" : retString = "<match no=\"" + Integer . toString ( numMatched + 1 ) + "\" postag=\"VBD\" />" ; break ; case "present" : retString = "<match no=\"" + Integer . toString ( numMatched + 1 ) + "\" postag=\"VBG\" />" ; break ; case "determiner" : case "determiner2" : retString = "the" ; break ; case "positive" : break ; case "possessive" : retString = "<match no=\"" + Integer . toString ( numMatched + 1 ) + "\" postag=\"NN(:U.?)?\" postag_regexp=\"yes\" />'s" ; break ; } return retString ; } public boolean isCaseSensitiveRule ( String pattern ) { boolean caseSensitive = false ; String [ ] splitPattern = pattern . split ( "\\ +" ) ; for ( String s : splitPattern ) { if ( s . equals ( "0BEGIN.0" ) || s . equals ( "0END.0" ) ) { continue ; } String [ ] splitS = s . split ( "/" ) ; if ( uppercase . matcher ( splitS [ 0 ] ) . find ( ) ) { caseSensitive = true ; } } return caseSensitive ; } public static String fixNoun ( String postag ) { Matcher m = nounInPattern . matcher ( postag ) ; if ( m . find ( ) ) { postag = postag . replaceFirst ( "NN(?!P|S|\\.)" , "NN|NN:UN?" ) ; } return postag ; } public boolean notKilledRule ( Map < String , String > rule ) { if ( rule . containsKey ( "filter" ) ) { if ( rule . get ( "filter" ) . equals ( "kill" ) || rule . get ( "filter" ) . equals ( "die" ) ) { return false ; } } return true ; } private static String gluePattern ( String [ ] p ) { StringBuilder sb = new StringBuilder ( ) ; for ( String s : p ) { sb . append ( s ) ; sb . append ( ' ' ) ; } return sb . toString ( ) . trim ( ) ; } private static String getTransformString ( String ref ) { Matcher m2 = wordReferenceTransform . matcher ( ref ) ; if ( m2 . find ( ) ) { return ":" + m2 . group ( 2 ) ; } return "" ; } private static boolean inDictionary ( String word ) { if ( dictLookup == null ) { dictLookup = loadDictionary ( ) ; } return ! dictLookup . lookup ( word ) . isEmpty ( ) ; } private static IStemmer loadDictionary ( ) { IStemmer dictLookup ; URL url = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsUrl ( ENGLISH_DICT ) ; File dictFile ; try { dictFile = new File ( url . toURI ( ) ) ; } catch ( URISyntaxException e ) { throw new RuntimeException ( "Could not load " + ENGLISH_DICT , e ) ; } try { dictLookup = new DictionaryLookup ( Dictionary . read ( dictFile ) ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not load " + dictFile , e ) ; } return dictLookup ; } public static boolean hasSpecificPosTag ( String word , String posTag ) { if ( dictLookup == null ) { dictLookup = ( DictionaryLookup ) loadDictionary ( ) ; } if ( hasPosTag ( word ) ) { final String [ ] splitWord = word . split ( "/" ) ; if ( Pattern . matches ( splitWord [ 1 ] , posTag ) ) { return true ; } return false ; } final List < WordData > lwd = dictLookup . lookup ( word ) ; for ( WordData wd : lwd ) { if ( wd . getTag ( ) . toString ( ) . equals ( posTag ) ) { return true ; } } return false ; } public static HashMap < String , ArrayList < String > > addItemSmart ( HashMap < String , ArrayList < String > > map , String key , String item ) { if ( map . containsKey ( key ) ) { ArrayList < String > existing = map . get ( key ) ; existing . add ( item ) ; map . put ( key , existing ) ; } else { ArrayList < String > newList = new ArrayList < > ( ) ; newList . add ( item ) ; map . put ( key , newList ) ; } return map ; } private static boolean hasPosTag ( String e ) { return e . contains ( "/" ) ; } private static boolean justPosTag ( String e ) { if ( e . length ( ) < 3 ) return false ; return ( e . charAt ( 0 ) == '.' && e . charAt ( 1 ) == '*' && e . charAt ( 2 ) == '/' ) ; } private enum WARNINGS { APOSTROPHES ( "Apostrophes in the pattern may have affected the numbering in the suggestion." ) , ANGLE_BRACKETS ( "Angle brackets in regular expressions need to be written as &gt; or &lt;" ) , EXCLUSIVE ( "AtD POS tags are not exclusive, and so rules may be too greedy. Consider adding this." ) , POSITIVE ( "Positive transform not supported." ) , DETERMINER ( "Determiner transform relies on bigram probabilities. Current implementation just returns \"the\"" ) , NO_SUFFIX ( "No suffix transform doesn't work for match elements or regular expressions." ) , INDEFARTICLE ( "Indefarticle filter uses n-gram probabilities. Rules using it should probably be discarded." ) , STATS ( "Stats filter uses n-gram probabilities. Rules using it should probably be discarded." ) , NEXTONLY ( "Nextonly filter uses n-gram probabilities. Rules using it should probably be discarded." ) ; public String value ; WARNINGS ( String v ) { this . value = v ; } } private enum MACRO_EXPANSIONS { selfwords ( "self-education|self-administering|self-fertilization|self-consequence|self-preservation|self-preservative" + "|self-interested|self-mastery|self-conceit|self-protection|self-identity|self-distrust|self-dissatisfaction" + "|self-depreciation|self-congratulation|self-government|self-pity|self-closing|self-consistent|self-propelling" + "|self-declared|self-starter|self-effacing|self-produced|self-constituted|self-exertion|self-cleaning|self-seeking" + "|self-limited|self-hypnosis|self-surrender|self-contained|self-complacency|self-sacrifice|self-congratulatory" + "|self-absorption|self-development|self-exile|self-aggrandizing|self-sufficient|self-enrichment|self-proclaimed" + "|self-repression|self-affirmation|self-contradictory|self-taught|self-deprecating|self-deprecation|self-perpetuating" + "|self-satisfied|self-explanatory|self-indulgence|self-sustained|self-aware|self-generating|self-devotion" + "|self-maintenance|self-ruling|self-laudation|self-abasement|self-luminous|self-complacent|self-criticism" + "|self-deceiving|self-pitying|self-evident|self-contradiction|self-originated|self-trust|self-revelation" + "|self-reflection|self-reflective|self-worth|self-regulatory|self-conceited|self-determining|self-flagellation" + "|self-inflicted|self-employed|self-regulating|self-regulation|self-injury|self-trained|self-similar|self-serve" + "|self-determination|self-same|self-absorbed|self-adjusting|self-sown|self-propagating|self-defence|self-awareness" + "|self-organization|self-defense|self-defeating|self-lighting|self-confident|self-containment|self-centered" + "|self-indulgent|self-justification|self-rule|self-sustaining|self-selection|self-addressed|self-knowledge" + "|self-deception|self-possessed|self-assertiveness|self-incrimination|self-exaltation|self-improvement" + "|self-righteous|self-reflexive|self-training|self-glorification|self-fertilize|self-delusion|self-correcting" + "|self-responsibility|self-forgetfulness|self-confessed|self-destructive|self-educated|self-employment" + "|self-propelled|self-destruction|self-healing|self-sacrificingly|self-exalting|self-examination|self-doubt" + "|self-immolation|self-justified|self-named|self-existent|self-satisfaction|self-control|self-estrangement" + "|self-starting|self-analysis|self-limiting|self-importance|self-gratulation|self-regarding|self-help" + "|self-treatment|self-respecting|self-instruction|self-governing|self-sufficiently|self-condemnation" + "|self-renunciation|self-heal|self-contemplation|self-deluded|self-respect|self-sufficiency|self-deceived" + "|self-hatred|self-winding|self-love|self-abuse|self-communion|self-convicted|self-torture|self-dual|self-initiated" + "|self-realization|self-denying|self-representation|self-reproach|self-activity|self-cultivation|self-evaluation" + "|self-created|self-suggestion|self-attraction|self-command|self-assertive|self-asserting|self-assertion" + "|self-derived|self-fulfilling|self-assured|self-betrayal|self-loading|self-possession|self-study|self-dependence" + "|self-reliant|self-appointed|self-injurious|self-sufficing|self-action|self-acting|self-imposed|self-serving" + "|self-restrained|self-service|self-effacement|self-elected|self-caused|self-reform|self-expression|self-assurance" + "|self-raising|self-restraining|self-aggrandizement|self-flattery|self-adornment|self-approval|self-dependent" + "|self-image|self-division|self-interest|self-regulated|self-will|self-regard|self-shining|self-written|self-abnegation" + "|self-important|self-consciousness|self-obsessed|self-pride|self-subsistent|self-condemned|self-restraint" + "|self-portrait|self-determined|self-righteousness|self-gratification|self-powered|self-defensive|self-ownership" + "|self-denial|self-induced|self-governed|self-forgetful|self-sacrificing|self-generated|self-moving|self-given" + "|self-identification|self-discipline|self-reliance|self-care|self-appreciation|self-definition|self-accusatory" + "|self-mortification|self-esteem|self-professed|self-reference|self-disgust|self-controlled|self-supporting" + "|self-mutilation|self-styled|self-culture|self-accusation|self-directed|self-devoted|self-advertisement" + "|self-confidence|self-described|self-conscious|self-administered|self-opinion|self-support|self-centred|self-made" + "|self-critical|self-consciously|self-conquest|self-repressed|self-willed" ) , absolutes ( "dead|disappeared|empty|false|full|gone|illegal|infinite|invaluable|legal|perfect|pervasive|pregnant" + "|professional|true|whole|vanished|(omni[a-z]+)" ) , uncountable ( "accommodation|advice|access|baggage|bread|equipment|garbage|luggage|money|cattle|knowledge|sand|furniture" + "|meat|food|news|pasta|progress|research|water|freedom|maturity|intelligence|travel|pollution|traffic" ) , modal_verbs ( "can|could|may|must|should|will|would|can't|couldn't|mustn't|shouldn't|won't|wouldn't" ) , comparisons_base ( "good|bad|hot|cold|lame|less|more|great|heavy|light|smart|dumb|cheap|sexy|tall|short|fast|slow|old" + "|young|easy|hard|high|low|large|small|big|soon|late|strong|loud|quiet|dark|bright" ) , comparisons ( "hotter|colder|lamer|less|lesser|more|greater|heavier|lighter|better|worse|smarter|dumber|cheaper|sexier" + "|taller|shorter|faster|slower|older|younger|easier|harder|farther|closer|higher|lower|larger|smaller|sooner" + "|later|weaker|stronger|louder|quieter|darker|brighter|Hotter|Colder|Lamer|Less|Lesser|More|Greater|Heavier" + "|Lighter|Better|Worse|Smarter|Dumber|Cheaper|Sexier|Taller|Shorter|Faster|Slower|Older|Younger|Easier|Harder" + "|Farther|Closer|Higher|Lower|Larger|Smaller|Sooner|Later|Weaker|Stronger|Louder|Quieter|Darker|Brighter" ) , past ( "\\w+ed|awoken|borne|beaten|become|begun|bent|bet|bitten|bled|blown|broken|bred|brought|built|burnt|burst|bought" + "|caught|chosen|come|cost|cut|dealt|done|drawn|dreamt|drunk|driven|eaten|made|meant|met|paid|put|quit|read|ridden" + "|rung|risen|run|said|seen|sought|sold|sent|set|shaken|shone|shot|shown|shut|sung|sunk|sat|slept|smelt|spoken" + "|spent|spilt|spoilt|spread|stood|stolen|stuck|stung|stunk|struck|sworn|swum|taken|taught|torn|told|thought|thrown" + "|understood|woken|worn|wept|won|written" ) , irregular_nouns_plural ( "addenda|alumni|analyses|axes|bacilli|bacteria|bases|calves|crises|criteria|curricula|data|dice" + "|diagnoses|elves|ellipses|emphases|errata|firemen|feet|genera|geese|halves|hypotheses|knives|leaves|lives|loaves" + "|lice|men|matrices|media|memoranda|mice|neuroses|nuclei|oases|ova|paralyses|parentheses|people|phenomena|selves" + "|shelves|stimuli|strata|syntheses|synopses|those|theses|thieves|these|teeth|wives|wolves|women" ) , irregular_verb_past_perfect ( "arisen|awoken|backbitten|been|beaten|befallen|begotten|begun|begirt|bespoken|bestridden|betaken" + "|bidden|bided|bitten|blawn|blown|bowstrung|broken|chosen|cleeked|counterdrawn|cowritten|crash-dived|crib-bitten|cross" + "-bitten|crowed|dared|deep-frozen|dived|done|drawn|drunk|driven|eaten|fallen|farebeaten|flash-frozen|flown|flyblown" + "|forbidden|fordone|foregone|foreknown|foreseen|forespoken|forgotten|forgiven|forlorn|forsaken|forsworn|free-fallen" + "|frozen|frostbitten|ghostwritten|given|gone|grown|hagridden|halterbroken|hand-ridden|handwritten|hewn|hidden|hoten" + "|housebroken|interwoven|known|lain|mischosen|misdone|misfallen|misgiven|misknown|misspoken|missworn|mistaken|misworn" + "|miswritten|mown|outdone|outdrawn|outdrunk|outdriven|outflown|outgrown|outridden|outseen|outsung|outspoken|outsprung" + "|outsworn|outswum|outthrown|outworn|outwritten|overborne|overblown|overdone|overdrawn|overdrunk|overdriven|overeaten" + "|overflown|overgrown|overlain|overridden|overseen|overspoken|oversprung|overstridden|overtaken|overthrown|overworn" + "|overwritten|partaken|predone|preshrunk|quick-frozen|redone|redrawn|regrown|retaken|retorn|retrodden|reworn|rewritten" + "|ridden|rung|risen|rough-hewn|seen|shaken|shown|shrunk|shriven|sightseen|sung|sunk|skywritten|slain|smitten|sown|spoken" + "|spun|sprung|stolen|stunk|stridden|striven|sworn|swollen|swum|swonken|taken|torn|test-driven|test-flown|thrown|trodden" + "|typewritten|underdone|undergone|underlain|undertaken|underwritten|undone|undrawn|undrawn|unfrozen|unhidden|unspoken" + "|unsworn|untrodden|unwoven|unwritten|uprisen|upsprung|uptorn|woken|worn|woven|wiredrawn|withdrawn|written" ) , irregular_verb_past ( "arose|ate|awoke|bade|beat|became|befell|began|begot|bespoke|bestrode|betook|bit|blew|bode|bore|broke" + "|built|came|chose|cowrote|crew|did|dove|drank|drew|drove|fell|flew|forbade|forbore|foresaw|forewent|forgave|forgot" + "|forsook|froze|gave|grew|hewed|hid|hight|knew|lay|misgave|misspoke|mistook|mowed|outdid|outgrew|outran|overbore" + "|overcame|overlay|overran|overrode|oversaw|overthrew|overtook|partook|ran|rang|reawoke|redid|redrew|retook|rewrote" + "|rived|rode|rose|sang|sank|saw|shook|shore|showed|shrank|slew|smote|sowed|span|spoke|sprang|stank|stole|strewed" + "|strode|strove|swam|swelled|swore|threw|took|tore|trod|underlay|undertook|underwent|underwrote|undid|uprose|was|went" + "|withdrew|woke|wore|wove|wrote" ) , irregular_verb_base ( "abide|alight|arise|awake|backlight|be|bear|befall|beget|begin|behold|belay|bend|beseech|bespeak|betake" + "|bethink|bid|bide|bind|bite|bleed|blend|bless|blow|bowstring|break|breed|bring|build|burn|buy|catch|chide|choose" + "|clap|cleave|cling|clothe|creep|crossbreed|crow|dare|daydream|deal|dig|disprove|dive|do|dogfight|dow|draw|dream|drink" + "|drive|dwell|eat|engrave|fall|feed|feel|fight|find|flee|fling|fly|forbear|forbid|forego|foresee|foretell|forget|forgive" + "|forsake|forswear|freeze|frostbite|gainsay|gaslight|geld|get|gild|gin|gird|give|gnaw|go|grave|grind|grow|hamstring" + "|hang|have|hear|heave|hew|hide|hoist|hold|inbreed|inlay|interbreed|interweave|keep|ken|kneel|know|lade|landslide|lay" + "|lead|lean|leap|learn|leave|lend|lie|light|lose|make|mean|meet|melt|mislead|misspell|mistake|misunderstand|moonlight" + "|mow|outdo|outgrow|outlay|outride|outshine|overdo|overeat|overhang|overhear|overlay|overleap|overlie|overpass|override" + "|oversee|overshoot|overspill|overtake|overthrow|overwrite|partake|pay|pen|plead|prove|rap|rebuild|redo|redraw|reeve" + "|regrow|relay|relight|remake|rend|repay|resell|retake|retell|rethink|retrofit|rewind|rewrite|ride|ring|rise|saw|say" + "|see|seek|sell|send|sew|shake|shave|shear|shew|shine|shoe|shoot|show|shrink|sing|sink|sit|slay|sleep|slide|sling|slink" + "|smell|smite|sneak|sow|speak|speed|spell|spend|spill|spin|spoil|spring|stand|stave|steal|stick|sting|stink|strew|stride" + "|strike|string|strip|strive|sunburn|swear|sweep|swell|swim|swing|take|teach|tear|tell|think|thrive|throw|tine|tread" + "|troubleshoot|typewrite|unbend|unbind|undergo|underlay|underlie|underpay|undersell|undershoot|understand|undertake" + "|underwrite|undo|unlearn|unmake|unsay|unwind|uphold|uprise|vex|wake|waylay|wear|weave|wed|weep|wend|whipsaw|win|wind" + "|wit|withdraw|withhold|withstand|work|wrap|wreak|wring|write|zinc" ) , determiner_wanted ( "absence|adult|affair|agreement|airport|alliance|amount|angle|announcement|apartment|appearance|appointment" + "|argument|arrangement|arrival|assertion|assumption|atmosphere|atom|attitude|aunt|author|automobile|bag|ballot|bar|barrel" + "|beast|bird|birthday|bit|blade|boat|bottle|bottom|bow|breast|bridge|brother|bullet|bundle|burden|cabin|cabinet|canal" + "|candle|car|career|carriage|case|castle|cat|cave|ceiling|centre|chamber|chapter|charm|chest|child|circumstance|citizen" + "|clerk|clip|clock|coalition|colleague|collection|combination|companion|complaint|concept|conclusion|condition|constitution" + "|continent|corner|coup|couple|cousin|cow|creator|creature|crew|crowd|crown|decade|default|defect|departure|description" + "|desk|device|distance|dock|doctor|doctrine|document|dog|dome|dozen|draft|duration|ear|earthquake|edge|editorial|egg" + "|election|employer|encyclopedia|endorsement|engagement|envelope|episode|equation|eruption|essay|establishment|estate|event" + "|exception|expedition|explosion|extension|extent|fan|farmer|feast|fee|fence|field|finger|flood|floor|flower|fool|forehead" + "|formation|fraction|framework|friend|frontier|future|gadget|gallon|gap|garden|gate|generation|gift|glance|glimpse" + "|grandfather|group|guy|handful|harbour|hat|height|hero|hole|holiday|horizon|horse|hospital|hotel|hour|household|husband" + "|iPhone|iPod|illustration|impression|impulse|institution|instrument|intention|interior|interval|interview|introduction" + "|investigation|invitation|island|job|joke|journal|journey|kid|kitchen|knife|knight|lamp|laptop|lawsuit|lawyer|leg|legislature" + "|lesson|lifetime|lion|lot|lover|manner|manuscript|margin|meal|message|method|mile|mill|mind|minimum|minute|mirror|mission" + "|mixture|moment|monarch|monster|month|monument|moon|mouth|movie|museum|name|nation|needle|neighborhood|nest|nose|notebook" + "|notion|nurse|oath|obligation|opinion|opponent|orchestra|organ|organism|ounce|outbreak|outcome|oven|pair|parent|partnership" + "|path|patient|patron|pattern|peasant|pen|pencil|period|person|phenomenon|photo|photograph|phrase|picture|piece|pile|pilot" + "|pint|pipe|plane|planet|plot|pocket|poem|portrait|pot|pound|presence|presentation|price|principle|prisoner|problem|product" + "|profession|project|proposal|proposition|province|publication|pupil|puzzle|race|reader|realm|recession|redirect|refusal" + "|regiment|region|reign|relationship|remainder|report|reporter|reputation|request|requirement|resolution|restaurant|ring|road" + "|role|roof|rope|row|rumor|sake|scene|sea|seat|sentence|servant|shadow|shaft|ship|shore|signature|sister|situation|skin|slave" + "|slope|smile|soldier|song|soul|speaker|sphere|stage|statement|statue|stomach|storm|stranger|street|student|successor|suggestion" + "|sum|summit|sun|surface|sword|symbol|tail|tale|telescope|template|temple|term|theme|thing|threat|throat|throne|thumb|tide|tip" + "|title|tomb|tongue|topic|transition|tree|trend|triangle|trick|trip|trunk|type|uncle|universe|verb|vessel|village|visitor|volcano" + "|voyage|weapon|web|wedding|week|weekend|widow|window|winner|world|yard|effort|environment|genre|list|photo|picture|population" + "|range|response|stake|suburb|thing|type|understanding|view|warning" ) , irregular_verb ( "abide|abode|alight|arise|arose|ate|awake|awoke|be|bear|became|befall|befell|began|beget|begin|begot|behold|bend" + "|beseech|betake|bethink|betook|bind|bit|bite|bleed|blew|blow|bore|break|breed|bring|broke|browbeat|build|burn|buy|came" + "|catch|chide|choose|chose|clap|cling|clothe|creep|dare|daydream|deal|did|dig|disprove|dive|do|dove|drank|draw|dream" + "|drew|drink|drive|drove|dwell|eat|fall|feed|feel|fell|fight|find|flee|flew|fling|fly|forbade|forbear|forbid|forbore" + "|forego|foresaw|foresee|foretell|forewent|forgave|forget|forgive|forgot|forsake|forsook|forswear|freeze|frostbite|froze" + "|gainsay|gave|get|gild|give|go|grew|grind|grow|hang|have|hear|heave|hew|hewed|hid|hide|hold|inbreed|inlay|keep|kneel" + "|knew|know|lade|landslide|lay|lead|lean|leap|learn|leave|lend|lie|light|lose|make|mean|meet|mislead|misspell|mistake" + "|mistook|misunderstand|mow|outdid|outdo|outgrew|outgrow|outlay|outran|outride|outshine|overbore|overcame|overdo|overeat" + "|overhang|overhear|overlay|overlay|overleap|overlie|overran|override|oversaw|oversee|overtake|overthrew|overthrow|overtook" + "|overwrite|partake|partook|pay|plead|prove|ran|rang|rebuild|redid|redo|reeve|refit|regrow|relay|relight|remake|rend|repay" + "|retake|retell|rethink|retook|rewind|rewrite|rewrote|ride|ring|rise|rived|rode|rose|sang|sank|saw|saw|say|see|seek|sell" + "|send|sew|shake|shave|shear|sheared|shine|shoe|shook|shoot|show|showed|shrank|shrink|sing|sink|sit|slay|sleep|slide|sling" + "|slink|smell|smite|sneak|sow|sowed|speak|speed|spell|spend|spill|spin|spoil|spoke|sprang|spring|stand|stank|stave|steal" + "|stick|sting|stink|stole|strew|strewed|stride|strike|string|strip|strive|strode|strove|sunburn|swam|swear|sweep|swell" + "|swelled|swim|swing|swore|take|teach|tear|tell|think|threw|thrive|throve|throw|took|tore|tread|troubleshoot|typewrite" + "|unbend|unbind|undergo|underlay|underlay|underlie|undersell|understand|undertake|undertook|underwent|undid|undo|unlearn" + "|unmake|unsay|unwind|uphold|vex|wake|was|waylay|wear|weave|wed|weep|went|whet|win|wind|withdraw|withdrew|withhold|withstand" + "|woke|wore|wove|wring|write|wrote" ) ; private String value ; MACRO_EXPANSIONS ( String v ) { this . value = v ; } } }
package org . languagetool . dev . conversion ; import java . io . FileOutputStream ; import java . io . IOException ; import java . io . OutputStreamWriter ; import java . io . PrintWriter ; import java . util . List ; import org . languagetool . language . English ; public class RuleConverterMain { private static final String [ ] supportedGeneralFiletypes = { "atd" , "cg" } ; private static final String [ ] supportedSpecificFiletypes = { "avoid" , "default" } ; private final String grammarFile ; private final String specificFiletype ; private final String discardFile ; private final String disambigFile ; private RuleConverter rc ; private static void exitWithUsageMessage ( ) { System . out . println ( "Usage: java org.languagetool.tools.RuleConverterMain " + "[-h|--help] [-g|--generalFiletype] [-s|--specificFiletype] [-i|--inputFile] [-a|--disambigFile] " + "[-d|--discardFile] [-o|--outputFile]" ) ; System . exit ( 1 ) ; } private RuleConverterMain ( String inFilename , String grammarFile , String discardFile , String disambigFile , String generalFileType , String specificFileType ) { this . grammarFile = grammarFile ; this . specificFiletype = specificFileType ; this . disambigFile = disambigFile ; this . discardFile = discardFile ; if ( generalFileType . equals ( "atd" ) ) { rc = new AtdRuleConverter ( inFilename , grammarFile , specificFileType ) ; } else if ( generalFileType . equals ( "cg" ) ) { rc = new CgRuleConverter ( inFilename , grammarFile , specificFileType ) ; } } private void run ( ) throws IOException { rc . parseRuleFile ( ) ; PrintWriter w = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( grammarFile ) , "UTF-8" ) ) ; w . write ( "<rules>\n" ) ; w . write ( "<category name=\"Auto-generated rules\">\n" ) ; for ( List < String > ltRule : rc . ltRules ) { for ( String line : ltRule ) { w . write ( line + '\n' ) ; } } w . write ( "</category>\n" ) ; w . write ( "</rules>" ) ; w . close ( ) ; if ( rc . disambiguationRules . size ( ) > 0 ) { w = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( disambigFile ) , "UTF-8" ) ) ; for ( List < String > killedRule : rc . disambiguationRules ) { for ( String line : killedRule ) { w . write ( line + '\n' ) ; } } w . close ( ) ; System . out . println ( Integer . toString ( rc . disambiguationRules . size ( ) ) + " disambiguation rules written to " + disambigFile ) ; } } public static void main ( String [ ] args ) throws IOException { String grammarFile = null ; String ruleFile = null ; String specificFileType = null ; String generalFiletType = null ; String discardFile = null ; String disambigFile = null ; if ( args . length < 4 ) { exitWithUsageMessage ( ) ; } try { if ( args [ 0 ] . equals ( "--check" ) ) { RuleCoverage checker = new RuleCoverage ( new English ( ) ) ; String inFile = args [ 1 ] ; checker . evaluateRules ( inFile ) ; System . exit ( 1 ) ; } } catch ( Exception e ) { throw new RuntimeException ( e ) ; } for ( int i = 0 ; i < args . length ; i ++ ) { switch ( args [ i ] ) { case "-h" : case "--help" : case "--?" : case "-help" : exitWithUsageMessage ( ) ; break ; case "-s" : case "--specificFiletype" : specificFileType = getSpecificFiletypeOrExit ( args [ ++ i ] ) ; break ; case "-g" : case "--generalFiletype" : generalFiletType = getGeneralFiletypeOrExit ( args [ ++ i ] ) ; break ; case "--outputFile" : case "-o" : grammarFile = args [ ++ i ] ; break ; case "--discardFile" : case "-d" : discardFile = args [ ++ i ] ; break ; case "--disambigFile" : case "-a" : disambigFile = args [ ++ i ] ; break ; case "--inputFile" : case "-i" : ruleFile = args [ ++ i ] ; break ; default : System . err . println ( "Unknown option: " + args [ i ] ) ; exitWithUsageMessage ( ) ; break ; } } if ( specificFileType == null ) { specificFileType = "default" ; } if ( generalFiletType == null ) { generalFiletType = "atd" ; } if ( grammarFile == null ) { System . err . println ( "Need to specify a grammar file" ) ; exitWithUsageMessage ( ) ; } if ( ruleFile == null ) { System . err . println ( "Need to specify a rule file" ) ; exitWithUsageMessage ( ) ; } if ( disambigFile == null ) { disambigFile = "disambig.xml" ; } if ( discardFile == null ) { discardFile = "discard.xml" ; } RuleConverterMain prg = new RuleConverterMain ( ruleFile , grammarFile , discardFile , disambigFile , generalFiletType , specificFileType ) ; prg . run ( ) ; } public static String getSpecificFiletypeOrExit ( String arg ) { String type = null ; boolean foundType = false ; for ( String s : supportedSpecificFiletypes ) { if ( arg . equals ( s ) ) { type = s ; foundType = true ; break ; } } if ( ! foundType ) { System . out . println ( "Unknown specific filetype " + arg ) ; System . out . print ( "Supported filetypes are" ) ; for ( String s : supportedSpecificFiletypes ) { System . out . print ( " " + s ) ; } System . out . println ( ) ; exitWithUsageMessage ( ) ; } return type ; } public static String getGeneralFiletypeOrExit ( String arg ) { String type = null ; boolean foundType = false ; for ( String s : supportedGeneralFiletypes ) { if ( arg . equals ( s ) ) { type = s ; foundType = true ; break ; } } if ( ! foundType ) { System . out . println ( "Unknown general filetype " + arg ) ; System . out . print ( "Supported filetypes are" ) ; for ( String s : supportedGeneralFiletypes ) { System . out . print ( " " + s ) ; } System . out . println ( ) ; exitWithUsageMessage ( ) ; } return type ; } }
package org . languagetool . dev . conversion ; import java . io . IOException ; import java . io . InputStream ; import java . util . ArrayList ; import java . util . List ; import java . util . Scanner ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . languagetool . JLanguageTool ; public abstract class RuleConverter { protected static final String firstIndent = " " ; protected static final String secondIndent = " " ; protected static final String thirdIndent = " " ; protected static final String fourthIndent = " " ; protected static final int firstIndentInt = 2 ; protected static final int secondIndentInt = 4 ; protected static final int thirdIndentInt = 6 ; protected static final int fourthIndentInt = 8 ; protected String inFileName ; protected String outFileName ; protected String ruleType ; protected List < ? extends Object > ruleObjects ; protected ArrayList < List < String > > allLtRules ; protected ArrayList < List < String > > ltRules ; protected ArrayList < List < String > > disambiguationRules ; protected ArrayList < String > originalRuleStrings ; protected ArrayList < String [ ] > warnings ; protected int idIndex ; protected int nameIndex ; protected String SENT_START = "SENT_START" ; protected String SENT_END = "SENT_END" ; private static Pattern regex = Pattern . compile ( "[\\.\\^\\$\\*\\+\\?\\{\\}\\[\\]\\|\\(\\)]" ) ; public static String xmlHeader = "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n" + "<?xml-stylesheet type=\"text/xsl\" href=\"../print.xsl\" ?>\n" + "<?xml-stylesheet type=\"text/css\" href=\"../rules.css\"\n" + "title=\"Easy editing stylesheet\" ?>\n" + "<!--\n" + "English Grammar and Typo Rules for LanguageTool\n" + "See tagset.txt for the meaning of the POS tags\n" + "Copyright (C) 2001-2007 Daniel Naber (http://www.danielnaber.de)\n" + "$Id: grammar.xml,v 1.129 2010-11-13 23:24:21 dnaber Exp $\n" + "-->\n" + "<!--suppress CheckTagEmptyBody -->\n" + "<rules lang=\"en\" xsi:noNamespaceSchemaLocation=\"../rules.xsd\" xmlns:xsi=\"http://\n" + "www.w3.org/2001/XMLSchema-instance\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\">\n" ; public RuleConverter ( ) { idIndex = 0 ; nameIndex = 0 ; } public RuleConverter ( String inFileName , String outFileName , String ruleType ) { this . inFileName = inFileName ; this . outFileName = outFileName ; if ( ruleType == null ) { this . ruleType = "default" ; } else { this . ruleType = ruleType ; } idIndex = 0 ; nameIndex = 0 ; } public List < ? extends Object > getRules ( ) { return this . ruleObjects ; } public ArrayList < List < String > > getAllLtRules ( ) { return this . allLtRules ; } public ArrayList < List < String > > getLtRules ( ) { return this . ltRules ; } public ArrayList < List < String > > getDisambiguationRules ( ) { return this . disambiguationRules ; } public ArrayList < String > getOriginalRuleStrings ( ) { return this . originalRuleStrings ; } public ArrayList < String [ ] > getWarnings ( ) { return this . warnings ; } public String getInFile ( ) { return inFileName ; } public String getOutFile ( ) { return outFileName ; } public String getFileType ( ) { return ruleType ; } public String getSentStart ( ) { return this . SENT_START ; } public String getSentEnd ( ) { return this . SENT_END ; } public void setInFile ( String filename ) { this . inFileName = filename ; } public void setOutFile ( String filename ) { this . outFileName = filename ; } public void setFileType ( String fileType ) { this . ruleType = fileType ; } public void setSentStart ( String sent_start ) { this . SENT_START = sent_start ; } public void setSentEnd ( String sent_end ) { this . SENT_END = sent_end ; } public abstract void parseRuleFile ( ) throws IOException ; public abstract String getOriginalRuleString ( Object ruleObject ) ; public abstract List < String > ltRuleAsList ( Object rule , String id , String name , String type ) ; public abstract String generateId ( Object ruleObject ) ; public abstract String generateName ( Object ruleObject ) ; public abstract String [ ] getAcceptableFileTypes ( ) ; public abstract boolean isDisambiguationRule ( Object ruleObject ) ; protected static ArrayList < String > addToken ( ArrayList < String > orig , String token , String postag , String exceptions , boolean careful , boolean inflected , boolean negate , int skip , int indent ) { String space = getSpace ( indent ) ; if ( token . equals ( ".*" ) ) { token = "" ; } String inflectedString = "" ; if ( inflected ) { inflectedString = " inflected=\"yes\"" ; } String skipString = "" ; if ( skip == - 1 ) { skipString = " skip=\"-1\"" ; } String regexpString = "" ; if ( isRegex ( token ) ) { regexpString = " regexp=\"yes\"" ; } String exceptionString = "" ; if ( exceptions != null ) { if ( exceptions . contains ( "<exception" ) ) { exceptionString = exceptions ; } else { exceptionString = "<exception regexp=\"yes\">" + exceptions + "</exception>" ; } } String postagRegexp = "" ; if ( isRegex ( postag ) ) { postagRegexp = " postag_regexp=\"yes\"" ; } String postagString = "" ; if ( postag != null ) { if ( ! postag . isEmpty ( ) ) { postagString = " postag=\"" + postag + "\"" ; } } String carefulString = "" ; if ( careful ) { carefulString = "<exception" + postagString + postagRegexp + " negate_pos=\"yes\"/>" ; } String negateString = "" ; if ( ! token . isEmpty ( ) && negate ) { negateString = " negate=\"yes\"" ; } String negatePosString = "" ; if ( ! postagString . isEmpty ( ) && negate ) { negatePosString = " negate_pos=\"yes\"" ; } orig . add ( space + "<token" + inflectedString + skipString + regexpString + postagString + postagRegexp + negateString + negatePosString + ">" + token + carefulString + exceptionString + "</token>" ) ; return orig ; } public static ArrayList < String > fileToListNoBlanks ( String filename ) { ArrayList < String > returnList = new ArrayList < > ( ) ; Scanner in = null ; InputStream is ; try { is = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( filename ) ; in = new Scanner ( is ) ; while ( in . hasNextLine ( ) ) { String line = in . nextLine ( ) ; if ( ! line . equals ( "" ) && ! line . equals ( "\n" ) ) { returnList . add ( line ) ; } } } catch ( Exception e ) { throw new RuntimeException ( "Could not load " + filename , e ) ; } finally { if ( in != null ) { in . close ( ) ; } } return returnList ; } protected static boolean isRegex ( String e ) { if ( e == null ) { return false ; } Matcher m = regex . matcher ( e ) ; return m . find ( ) ; } protected static String getSpace ( int indent ) { StringBuilder sb = new StringBuilder ( ) ; for ( int i = 0 ; i < indent ; i ++ ) { sb . append ( ' ' ) ; } return sb . toString ( ) ; } public static String getRuleStringFromList ( List < String > rule ) { StringBuilder sb = new StringBuilder ( ) ; for ( String line : rule ) { sb . append ( line ) ; sb . append ( '\n' ) ; } return sb . toString ( ) ; } public static String glueWords ( ArrayList < String > words ) { StringBuilder sb = new StringBuilder ( ) ; if ( words == null ) { return "" ; } for ( String word : words ) { sb . append ( word ) ; sb . append ( "|" ) ; } String str = sb . toString ( ) ; if ( str . length ( ) > 1 ) { return str . substring ( 0 , str . length ( ) - 1 ) ; } else { return str ; } } public static String glueWords ( String [ ] words ) { StringBuilder sb = new StringBuilder ( ) ; if ( words == null ) { return "" ; } for ( String word : words ) { sb . append ( word ) ; sb . append ( "|" ) ; } String str = sb . toString ( ) ; if ( str . length ( ) > 1 ) { return str . substring ( 0 , str . length ( ) - 1 ) ; } else { return str ; } } }
package org . languagetool . dev . conversion ; import java . io . ByteArrayInputStream ; import java . io . File ; import java . io . FileOutputStream ; import java . io . IOException ; import java . io . InputStream ; import java . io . OutputStreamWriter ; import java . io . PrintWriter ; import java . nio . charset . Charset ; import java . util . ArrayList ; import java . util . List ; import java . util . Random ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import morfologik . stemming . Dictionary ; import morfologik . stemming . DictionaryIterator ; import morfologik . stemming . DictionaryLookup ; import morfologik . stemming . IStemmer ; import morfologik . stemming . WordData ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . language . English ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . patterns . PatternToken ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . rules . patterns . PatternRuleLoader ; public class RuleCoverage { private JLanguageTool tool ; private DictionaryIterator dictIterator ; private DictionaryLookup dictLookup ; private Language language ; private String filename ; private File dictFile ; private String ruleFileHeader = RuleConverter . xmlHeader ; private String categoriesString = "<category name=\"test\">" ; private String endCategoriesString = "</category>" ; private String endRulesString = "</rules>" ; private static Pattern regexSet = Pattern . compile ( "^\\[([^\\-])*?\\]$" ) ; public RuleCoverage ( ) throws IOException { language = new English ( ) ; tool = new JLanguageTool ( language ) ; tool . disableRule ( "UPPERCASE_SENTENCE_START" ) ; tool . disableRule ( "EN_UNPAIRED_BRACKETS" ) ; tool . disableRule ( "EN_A_VS_AN" ) ; setupDictionaryFiles ( ) ; } public RuleCoverage ( Language language ) throws IOException { this . language = language ; tool = new JLanguageTool ( language ) ; setupDictionaryFiles ( ) ; } public RuleCoverage ( String dictFileName ) throws IOException { language = new English ( ) ; tool = new JLanguageTool ( language ) ; tool . disableRule ( "UPPERCASE_SENTENCE_START" ) ; tool . disableRule ( "EN_UNPAIRED_BRACKETS" ) ; tool . disableRule ( "EN_A_VS_AN" ) ; this . filename = dictFileName ; this . dictFile = new File ( filename ) ; setupDictionaryFiles ( ) ; } public JLanguageTool getLanguageTool ( ) { return tool ; } public void evaluateRules ( String grammarfile ) throws IOException { List < PatternRule > rules = loadPatternRules ( grammarfile ) ; for ( PatternRule rule : rules ) { String example = generateIncorrectExample ( rule ) ; System . out . println ( "Rule " + rule . getId ( ) + " is covered by " + isCoveredBy ( example ) + " for example " + example ) ; } } public void splitOutCoveredRules ( String grammarfile , String discardfile ) throws IOException { List < PatternRule > rules = loadPatternRules ( grammarfile ) ; PrintWriter w = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( grammarfile ) , "UTF-8" ) ) ; PrintWriter w2 = null ; int discardedRules = 0 ; for ( PatternRule rule : rules ) { String example = generateIncorrectExample ( rule ) ; if ( isCoveredBy ( example ) == null ) { w . write ( rule . toXML ( ) ) ; } else { if ( w2 == null ) { w2 = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( discardfile ) , "UTF-8" ) ) ; } discardedRules ++ ; w2 . write ( rule . toXML ( ) ) ; } } if ( discardedRules > 0 ) { System . out . println ( Integer . toString ( discardedRules ) + " rules already covered, written to " + discardfile ) ; } w . close ( ) ; if ( w2 != null ) { w2 . close ( ) ; } } public boolean isCovered ( String str ) throws IOException { List < RuleMatch > matches = tool . check ( str ) ; return ( matches . size ( ) > 0 ) ; } public String [ ] isCoveredBy ( String str ) throws IOException { List < RuleMatch > matches = tool . check ( str ) ; ArrayList < String > coverages = new ArrayList < > ( ) ; if ( matches . size ( ) > 0 ) { for ( RuleMatch match : matches ) { coverages . add ( match . getRule ( ) . getId ( ) ) ; } } return coverages . toArray ( new String [ coverages . size ( ) ] ) ; } public String [ ] isCoveredBy ( PatternRule rule ) throws IOException { ArrayList < String > coverages = new ArrayList < > ( ) ; String example = generateIncorrectExample ( rule ) ; List < RuleMatch > matches = tool . check ( example ) ; if ( matches . size ( ) > 0 ) { for ( RuleMatch match : matches ) { coverages . add ( match . getRule ( ) . getId ( ) ) ; } } return coverages . toArray ( new String [ coverages . size ( ) ] ) ; } public ArrayList < String [ ] > isCoveredBy ( List < PatternRule > rules ) throws IOException { ArrayList < String [ ] > coverages = new ArrayList < > ( ) ; for ( PatternRule rule : rules ) { String [ ] cov = isCoveredBy ( rule ) ; coverages . add ( cov ) ; } return coverages ; } public String generateIncorrectExample ( PatternRule patternrule ) { ArrayList < String > examples = new ArrayList < > ( ) ; List < PatternToken > patternTokens = patternrule . getPatternTokens ( ) ; for ( int i = 0 ; i < patternTokens . size ( ) ; i ++ ) { List < PatternToken > prevExceptions ; if ( i == patternTokens . size ( ) - 1 ) { prevExceptions = new ArrayList < > ( ) ; } else { prevExceptions = patternTokens . get ( i + 1 ) . getPreviousExceptionList ( ) ; if ( prevExceptions == null ) prevExceptions = new ArrayList < > ( ) ; } examples . add ( getSpecificExample ( patternTokens . get ( i ) , prevExceptions , patternTokens , examples ) ) ; } StringBuilder sb = new StringBuilder ( ) ; for ( String example : examples ) { sb . append ( example ) . append ( " " ) ; } String s = sb . toString ( ) . replaceAll ( "\\ \\.\\ " , "" ) . trim ( ) ; return s ; } @ SuppressWarnings ( "unchecked" ) public String getSpecificExample ( PatternToken e , List < PatternToken > prevExceptions , List < PatternToken > patternTokens , ArrayList < String > examples ) { if ( e . hasAndGroup ( ) ) { List < PatternToken > andGroup = e . getAndGroup ( ) ; andGroup . add ( e ) ; for ( PatternToken and : andGroup ) { if ( isJustToken ( and ) ) { return and . getString ( ) ; } if ( isPunctuation ( and ) ) { return getOnePunc ( and ) ; } } List < Pattern > tokenPatterns = new ArrayList < > ( andGroup . size ( ) ) ; List < Pattern > posPatterns = new ArrayList < > ( andGroup . size ( ) ) ; List < PatternToken > allExceptions = new ArrayList < > ( ) ; allExceptions . addAll ( prevExceptions ) ; for ( int a = 0 ; a < andGroup . size ( ) ; a ++ ) { PatternToken and = andGroup . get ( a ) ; List < PatternToken > ex = and . getExceptionList ( ) ; if ( ex != null ) { allExceptions . addAll ( and . getExceptionList ( ) ) ; } if ( and . isReferenceElement ( ) ) { and = getReferenceElement ( and , patternTokens , examples ) ; } String andPostag = and . getPOStag ( ) ; String andToken = and . getString ( ) ; tokenPatterns . add ( Pattern . compile ( andToken ) ) ; if ( andPostag != null ) { if ( and . isPOStagRegularExpression ( ) ) { posPatterns . add ( Pattern . compile ( andPostag ) ) ; } else { posPatterns . add ( Pattern . compile ( Pattern . quote ( andPostag ) ) ) ; } } else { posPatterns . add ( null ) ; } andGroup . set ( a , and ) ; } List < List < Pattern > > exceptionAttributes = getExceptionAttributes ( allExceptions ) ; int numResets = 0 ; while ( numResets < 2 ) { if ( ! dictIterator . hasNext ( ) ) { dictIterator = resetDictIterator ( ) ; numResets ++ ; } String word = dictIterator . next ( ) . getWord ( ) . toString ( ) ; boolean matched = true ; for ( int i = 0 ; i < andGroup . size ( ) ; i ++ ) { if ( ! isExampleOf ( word , tokenPatterns . get ( i ) , posPatterns . get ( i ) , andGroup . get ( i ) ) ) { matched = false ; break ; } } if ( matched ) { if ( ! inExceptionList ( word , exceptionAttributes , allExceptions ) ) { return word ; } } } } else { if ( e . isReferenceElement ( ) ) { e = getReferenceElement ( e , patternTokens , examples ) ; } String token = e . getString ( ) ; String postag = e . getPOStag ( ) ; List < PatternToken > exceptions = e . getExceptionList ( ) ; if ( exceptions == null ) { exceptions = new ArrayList < > ( ) ; } exceptions . addAll ( prevExceptions ) ; List < List < Pattern > > exceptionAttributes = getExceptionAttributes ( exceptions ) ; if ( e . isSentenceStart ( ) ) { return "" ; } if ( isJustToken ( e ) ) { return token ; } if ( isPunctuation ( e ) ) { return getOnePunc ( e ) ; } if ( isSimpleOrRegex ( e ) ) { return randomOredElement ( e ) ; } Pattern tokenPattern = Pattern . compile ( token ) ; Pattern posPattern ; if ( postag != null ) { if ( e . isPOStagRegularExpression ( ) ) { posPattern = Pattern . compile ( postag ) ; } else { posPattern = Pattern . compile ( Pattern . quote ( postag ) ) ; } if ( postag . equals ( "SENT_END" ) ) { posPattern = null ; } } else { posPattern = null ; } int numResets = 0 ; while ( numResets < 2 ) { if ( ! dictIterator . hasNext ( ) ) { dictIterator = resetDictIterator ( ) ; numResets ++ ; } String word = dictIterator . next ( ) . getWord ( ) . toString ( ) ; if ( isExampleOf ( word , tokenPattern , posPattern , e ) && ! inExceptionList ( word , exceptionAttributes , exceptions ) ) { return word ; } } } return null ; } private PatternToken getReferenceElement ( PatternToken e , List < PatternToken > patternTokens , ArrayList < String > examples ) { int r = e . getMatch ( ) . getTokenRef ( ) ; PatternToken newPatternToken = new PatternToken ( examples . get ( r ) , patternTokens . get ( r ) . isCaseSensitive ( ) , false , false ) ; newPatternToken . setNegation ( e . getNegation ( ) ) ; return newPatternToken ; } @ SuppressWarnings ( "unchecked" ) private List < List < Pattern > > getExceptionAttributes ( List < PatternToken > exceptions ) { if ( exceptions . size ( ) == 0 ) { return new ArrayList < > ( ) ; } int size = exceptions . size ( ) ; List < List < Pattern > > ret = new ArrayList < > ( 6 ) ; List < Pattern > tokenPatterns = new ArrayList < > ( size ) ; List < Pattern > posPatterns = new ArrayList < > ( size ) ; for ( PatternToken e : exceptions ) { String token = e . getString ( ) ; String postag = e . getPOStag ( ) ; Pattern tokenPattern = Pattern . compile ( token ) ; Pattern posPattern ; if ( postag != null ) { posPattern = Pattern . compile ( postag ) ; } else { posPattern = null ; } tokenPatterns . add ( tokenPattern ) ; posPatterns . add ( posPattern ) ; } ret . add ( tokenPatterns ) ; ret . add ( posPatterns ) ; return ret ; } private String randomOredElement ( PatternToken e ) { String [ ] split = e . getString ( ) . split ( "\\|" ) ; Random rng = new Random ( ) ; int index = rng . nextInt ( split . length ) ; return split [ index ] ; } @ SuppressWarnings ( "unchecked" ) private boolean inExceptionList ( String word , List < List < Pattern > > exceptionAttributes , List < PatternToken > exceptions ) { if ( exceptions . size ( ) == 0 ) { return false ; } List < Pattern > tokenPatterns = exceptionAttributes . get ( 0 ) ; List < Pattern > posPatterns = exceptionAttributes . get ( 1 ) ; for ( int i = 0 ; i < exceptions . size ( ) ; i ++ ) { PatternToken curException = exceptions . get ( i ) ; if ( isExampleOf ( word , tokenPatterns . get ( i ) , posPatterns . get ( i ) , curException ) ) { return true ; } } return false ; } public boolean isExampleOf ( String word , Pattern tokenPattern , Pattern posPattern , PatternToken e ) { if ( tokenPattern . pattern ( ) . isEmpty ( ) && posPattern == null ) { return true ; } boolean tokenMatches = true ; boolean postagMatches = false ; boolean isTokenEmpty = e . getString ( ) . isEmpty ( ) ; boolean hasPosTag = ( posPattern != null ) ; boolean negate = e . getNegation ( ) ; boolean postagNegate = e . getPOSNegation ( ) ; boolean inflected = e . isInflected ( ) ; if ( posPattern == null ) { postagMatches = true ; } if ( ! isTokenEmpty ) { Matcher m ; boolean matches = false ; if ( inflected ) { if ( isInflectedStringMatch ( word , e ) ) { matches = true ; } } else { m = tokenPattern . matcher ( word ) ; if ( m . matches ( ) ) matches = true ; } if ( matches ) { if ( negate ) { tokenMatches = false ; } } else { if ( ! negate ) { tokenMatches = false ; } } } if ( hasPosTag ) { List < String > postags = getPosTags ( word ) ; for ( String s : postags ) { Matcher m = posPattern . matcher ( s ) ; if ( m . matches ( ) ) { if ( ! postagNegate ) { postagMatches = true ; break ; } } else { if ( postagNegate ) { postagMatches = true ; break ; } } } if ( postags . size ( ) == 0 ) { postagMatches = false ; } } return ( tokenMatches && postagMatches ) ; } private boolean isInflectedStringMatch ( String word , PatternToken e ) { Matcher m ; Pattern lemmaPattern = Pattern . compile ( RuleConverter . glueWords ( getLemmas ( e ) ) ) ; List < String > wordLemmas = getLemmas ( word ) ; for ( String lemma : wordLemmas ) { m = lemmaPattern . matcher ( lemma ) ; if ( m . matches ( ) ) { return true ; } } return false ; } private List < String > getPosTags ( String word ) { List < WordData > lwd = dictLookup . lookup ( word ) ; ArrayList < String > postags = new ArrayList < > ( ) ; for ( WordData wd : lwd ) { postags . add ( wd . getTag ( ) . toString ( ) ) ; } return postags ; } private ArrayList < String > getLemmas ( String word ) { List < WordData > lwd = dictLookup . lookup ( word ) ; ArrayList < String > lemmas = new ArrayList < > ( ) ; for ( WordData wd : lwd ) { if ( ! lemmas . contains ( wd . getStem ( ) ) ) { lemmas . add ( wd . getStem ( ) . toString ( ) ) ; } } return lemmas ; } private ArrayList < String > getLemmas ( PatternToken e ) { if ( ! e . isRegularExpression ( ) ) { return getLemmas ( e . getString ( ) ) ; } else { if ( isOrRegex ( e ) ) { ArrayList < String > lemmas = new ArrayList < > ( ) ; String [ ] words = e . getString ( ) . split ( "\\|" ) ; for ( String word : words ) { lemmas . addAll ( getLemmas ( word ) ) ; } return lemmas ; } return null ; } } private static boolean isJustToken ( PatternToken e ) { return ( ! e . getString ( ) . isEmpty ( ) && ! e . isRegularExpression ( ) && ! e . getNegation ( ) && e . getExceptionList ( ) == null ) ; } public static boolean isPunctuation ( PatternToken e ) { if ( regexSet . matcher ( e . getString ( ) ) . matches ( ) && ! e . getNegation ( ) && e . getPOStag ( ) == null ) { return true ; } return false ; } public String getOnePunc ( PatternToken e ) { String set = e . getString ( ) ; Matcher m = regexSet . matcher ( set ) ; m . find ( ) ; return m . group ( 1 ) ; } private static boolean isSimpleOrRegex ( PatternToken e ) { if ( e . getString ( ) . isEmpty ( ) ) return false ; if ( e . getPOStag ( ) != null ) return false ; if ( e . getNegation ( ) ) return false ; if ( ! e . isRegularExpression ( ) ) return false ; if ( e . hasAndGroup ( ) ) return false ; if ( e . getExceptionList ( ) != null ) return false ; if ( e . isReferenceElement ( ) ) return false ; if ( e . isSentenceStart ( ) ) return false ; String token = e . getString ( ) ; String [ ] ors = token . split ( "\\|" ) ; for ( String s : ors ) { if ( RuleConverter . isRegex ( s ) ) { return false ; } } return true ; } private static boolean isOrRegex ( PatternToken e ) { if ( e . getString ( ) . isEmpty ( ) ) return false ; String token = e . getString ( ) ; String [ ] ors = token . split ( "\\|" ) ; for ( String s : ors ) { if ( RuleConverter . isRegex ( s ) ) { return false ; } } return true ; } private DictionaryIterator resetDictIterator ( ) { DictionaryIterator ret = null ; try { ret = new DictionaryIterator ( Dictionary . read ( dictFile ) , Charset . forName ( "utf8" ) . newDecoder ( ) , true ) ; } catch ( IOException e ) { throw new RuntimeException ( "Could not read " + dictFile , e ) ; } return ret ; } private IStemmer loadDictionary ( ) throws IOException { IStemmer dictLookup = new DictionaryLookup ( Dictionary . read ( dictFile ) ) ; return dictLookup ; } private void setupDictionaryFiles ( ) { try { filename = "" + JLanguageTool . getDataBroker ( ) . getResourceDir ( ) + "/" + language . getShortName ( ) + "/" + language . getName ( ) . toLowerCase ( ) + ".dict" ; dictFile = new File ( filename ) ; dictLookup = ( DictionaryLookup ) loadDictionary ( ) ; dictIterator = resetDictIterator ( ) ; } catch ( IOException e ) { try { filename = "./src/" + JLanguageTool . getDataBroker ( ) . getResourceDir ( ) + "/" + language . getShortName ( ) + "/" + language . getName ( ) . toLowerCase ( ) + ".dict" ; dictFile = new File ( filename ) ; dictLookup = ( DictionaryLookup ) loadDictionary ( ) ; dictIterator = resetDictIterator ( ) ; } catch ( IOException e2 ) { throw new RuntimeException ( e2 ) ; } } } public List < PatternRule > loadPatternRules ( final String filename ) throws IOException { final PatternRuleLoader ruleLoader = new PatternRuleLoader ( ) ; InputStream is = this . getClass ( ) . getResourceAsStream ( filename ) ; if ( is == null ) { return ruleLoader . getRules ( new File ( filename ) ) ; } else { return ruleLoader . getRules ( is , filename ) ; } } public List < PatternRule > parsePatternRule ( final String ruleString ) { final PatternRuleLoader ruleLoader = new PatternRuleLoader ( ) ; String ruleFileString = ruleFileHeader + categoriesString + ruleString + endCategoriesString + endRulesString ; InputStream is = new ByteArrayInputStream ( ruleFileString . getBytes ( ) ) ; try { return ruleLoader . getRules ( is , null ) ; } catch ( IOException e ) { return new ArrayList < > ( ) ; } } public List < PatternRule > parsePatternRuleExtraTokens ( final String ruleString ) { String rs = ruleString ; rs = rs . replace ( "<pattern>\n" , "<pattern>\n<token/>\n" ) ; rs = rs . replace ( "</pattern>\n" , "<token/>\n</pattern>\n" ) ; final PatternRuleLoader ruleLoader = new PatternRuleLoader ( ) ; String ruleFileString = ruleFileHeader + categoriesString + rs + endCategoriesString + endRulesString ; InputStream is = new ByteArrayInputStream ( ruleFileString . getBytes ( ) ) ; try { return ruleLoader . getRules ( is , null ) ; } catch ( IOException e ) { return new ArrayList < > ( ) ; } } public void enableRule ( String id ) { tool . enableDefaultOffRule ( id ) ; } }
package org . languagetool . dev . conversion ; import java . io . BufferedReader ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . io . InputStreamReader ; import java . util . * ; import org . languagetool . dev . conversion . cg . CgCompositeTag ; import org . languagetool . dev . conversion . cg . CgContextualTest ; import org . languagetool . dev . conversion . cg . CgContextualTest . POS ; import org . languagetool . dev . conversion . cg . CgGrammar ; import org . languagetool . dev . conversion . cg . CgRule ; import org . languagetool . dev . conversion . cg . CgSet ; import org . languagetool . dev . conversion . cg . CgTag ; import org . languagetool . dev . conversion . cg . CgTextualParser ; public class CgRuleConverter extends RuleConverter { private CgGrammar grammar ; private String [ ] lines ; private static String tagDelimiter = ":" ; public CgRuleConverter ( ) { super ( ) ; } public CgRuleConverter ( String infile , String outfile , String specificFiletype ) { super ( infile , outfile , specificFiletype ) ; } public CgGrammar getGrammar ( ) { return this . grammar ; } public void setGrammar ( CgGrammar grammar ) { this . grammar = grammar ; } public void setTagDelimiter ( String td ) { tagDelimiter = td ; } @ Override public void parseRuleFile ( ) throws IOException { parseCgFile ( ) ; List < CgRule > ruleList = new ArrayList < > ( ) ; for ( CgRule rule : grammar . rule_by_number ) { ruleList . add ( rule ) ; } ruleObjects = ruleList ; ltRules = new ArrayList < > ( ) ; allLtRules = new ArrayList < > ( ) ; disambiguationRules = new ArrayList < > ( ) ; originalRuleStrings = new ArrayList < > ( ) ; warnings = new ArrayList < > ( ) ; for ( Object ruleObject : ruleObjects ) { CgRule cgrule = ( CgRule ) ruleObject ; List < String > ruleAsList = ltRuleAsList ( cgrule , generateId ( ruleObject ) , generateName ( ruleObject ) , cgrule . type . name ( ) ) ; disambiguationRules . add ( ruleAsList ) ; allLtRules . add ( ruleAsList ) ; originalRuleStrings . add ( lines [ cgrule . line ] ) ; } } @ Override public boolean isDisambiguationRule ( Object ruleObject ) { return true ; } public void parseCgFile ( ) throws IOException { File file = new File ( inFileName ) ; grammar = new CgGrammar ( ) ; CgTextualParser parser = new CgTextualParser ( grammar , file ) ; int result = parser . parse_grammar_from_file ( inFileName , null , null ) ; if ( result == 0 ) { } else { System . err . println ( "Failed to parse constraint grammar file " + inFileName ) ; } getGrammarFileLines ( inFileName ) ; } public void getGrammarFileLines ( String filename ) { BufferedReader reader = null ; StringBuilder sb = new StringBuilder ( ) ; String inArray = "" ; sb . append ( " " ) ; try { reader = new BufferedReader ( new InputStreamReader ( new FileInputStream ( filename ) , "UTF-8" ) ) ; int c = reader . read ( ) ; while ( c != - 1 ) { sb . append ( ( char ) c ) ; c = reader . read ( ) ; } inArray = sb . toString ( ) ; reader . close ( ) ; } catch ( IOException e ) { System . err . println ( "Error opening grammar file" ) ; System . exit ( 1 ) ; } String [ ] lines = inArray . split ( "\n" ) ; this . lines = lines ; } @ Override public List < String > ltRuleAsList ( Object ruleObject , String id , String name , String type ) { CgRule rule = ( CgRule ) ruleObject ; type = rule . type . name ( ) ; List < String > ltRule = new ArrayList < > ( ) ; List < String > currentWarnings = new ArrayList < > ( ) ; String cgRuleString = lines [ rule . line ] ; ltRule . add ( "<!-- " + cgRuleString + " -->" ) ; ArrayList < Token > tokensList = new ArrayList < > ( ) ; List < ArrayList < Token > > outerList = new ArrayList < > ( ) ; ArrayList < Token [ ] > processedLists = new ArrayList < > ( ) ; CgSet targetSet = expandSetSets ( grammar . getSet ( rule . target ) ) ; Token target = new Token ( targetSet , false , 0 , false , false , new CgSet ( ) , false , 0 , false ) ; if ( ! isOrCompatible ( target ) ) { System . err . println ( "Target for rule on line " + rule . line + " cannot be represented as one LT rule. Consider rewriting it." ) ; return new ArrayList < > ( ) ; } tokensList . add ( target ) ; List < CgContextualTest > sortedTestsHeads = new ArrayList < > ( ) ; for ( CgContextualTest test : rule . test_heads ) { if ( test . isParentTest ( ) ) { sortedTestsHeads . add ( test ) ; } else { sortedTestsHeads . add ( 0 , test ) ; } } for ( CgContextualTest test : sortedTestsHeads ) { if ( test . isNormalTest ( ) ) { Token testToken = getTokenFromNormalTest ( test ) ; tokensList . add ( testToken ) ; } else if ( test . isParentTest ( ) ) { if ( ! outerList . isEmpty ( ) ) { System . err . println ( "Can't have two parent tests in one test on line " + rule . line + "\nTry splitting it up." ) ; System . exit ( 1 ) ; } for ( int testInt : test . ors ) { ArrayList < Token > newTokenList = copyTokenList ( tokensList ) ; CgContextualTest childTest = rule . test_map . get ( testInt ) ; if ( childTest . isNormalTest ( ) ) { Token childTestToken = getTokenFromNormalTest ( childTest ) ; newTokenList . add ( childTestToken ) ; } else if ( childTest . isLinkedTest ( ) ) { ArrayList < CgContextualTest > linkedTests = new ArrayList < > ( ) ; CgContextualTest curTest = childTest ; while ( curTest . next != 0 ) { linkedTests . add ( curTest ) ; curTest = rule . test_map . get ( curTest . next ) ; } linkedTests . add ( curTest ) ; Token headLinkedToken = getLinkedTokens ( linkedTests ) ; newTokenList . add ( headLinkedToken ) ; } outerList . add ( newTokenList ) ; } } else if ( test . isLinkedTest ( ) ) { ArrayList < CgContextualTest > linkedTests = new ArrayList < > ( ) ; CgContextualTest curTest = test ; while ( curTest . next != 0 ) { linkedTests . add ( curTest ) ; curTest = rule . test_map . get ( curTest . next ) ; } linkedTests . add ( curTest ) ; Token headLinkedToken = getLinkedTokens ( linkedTests ) ; tokensList . add ( headLinkedToken ) ; } } if ( outerList . isEmpty ( ) ) { outerList . add ( tokensList ) ; } for ( int i = 0 ; i < outerList . size ( ) ; i ++ ) { Token [ ] tokens = outerList . get ( i ) . toArray ( new Token [ outerList . get ( i ) . size ( ) ] ) ; if ( negativeBackwardBarrierScan ( tokens ) ) { Iterable < List < Token > > split = splitNegativeBackwardBarrierScan ( tokens ) ; outerList . remove ( i ) ; for ( List < Token > splitList : split ) { outerList . add ( i , new ArrayList < > ( splitList ) ) ; i ++ ; } } } for ( ArrayList < Token > anOuterList : outerList ) { Token [ ] tokens = anOuterList . toArray ( new Token [ anOuterList . size ( ) ] ) ; Arrays . sort ( tokens ) ; tokens = addGapTokens ( tokens ) ; if ( skipSafe ( tokens ) ) { tokens = addSkipTokens ( tokens ) ; tokens = resolveLinkedTokens ( tokens ) ; if ( ! singleRuleCompatible ( tokens ) ) { Iterable < List < Token > > singleRuleCompatibleTokens = splitForSingleRule ( tokens ) ; for ( List < Token > srctl : singleRuleCompatibleTokens ) { Token [ ] srcta = srctl . toArray ( new Token [ srctl . size ( ) ] ) ; processedLists . add ( srcta ) ; } } else { processedLists . add ( tokens ) ; } } else { List < List < Token > > splitTokenLists = getSkipSafeTokens ( tokens ) ; for ( int j = 0 ; j < splitTokenLists . size ( ) ; j ++ ) { Token [ ] indSplitTokenList = splitTokenLists . get ( j ) . toArray ( new Token [ splitTokenLists . get ( j ) . size ( ) ] ) ; indSplitTokenList = addSkipTokens ( indSplitTokenList ) ; indSplitTokenList = resolveLinkedTokens ( indSplitTokenList ) ; Arrays . sort ( indSplitTokenList ) ; indSplitTokenList = addGapTokens ( indSplitTokenList ) ; if ( ! singleRuleCompatible ( indSplitTokenList ) ) { Iterable < List < Token > > singleRuleCompatibleTokens = splitForSingleRule ( indSplitTokenList ) ; for ( List < Token > srctl : singleRuleCompatibleTokens ) { Token [ ] srcta = srctl . toArray ( new Token [ srctl . size ( ) ] ) ; processedLists . add ( srcta ) ; } } else { processedLists . add ( indSplitTokenList ) ; } } } } if ( processedLists . size ( ) == 1 ) { Token [ ] tokens = processedLists . get ( 0 ) ; List < String > ltRule2 = getRuleByType ( targetSet , tokens , rule , id , name , type ) ; ltRule . addAll ( ltRule2 ) ; } else { ltRule . add ( "<rulegroup name=\"" + generateName ( ruleObject ) + "\">" ) ; for ( Token [ ] tokens : processedLists ) { List < String > ltRule2 = getRuleByType ( targetSet , tokens , rule , null , null , type ) ; ltRule . addAll ( ltRule2 ) ; } ltRule . add ( "</rulegroup>" ) ; } warnings . add ( currentWarnings . toArray ( new String [ currentWarnings . size ( ) ] ) ) ; return ltRule ; } public List < List < Token > > splitForSingleRule ( Token [ ] tokens ) { List < List < Token > > list = new ArrayList < > ( ) ; List < Token > tokenList = new ArrayList < > ( Arrays . asList ( tokens ) ) ; list . add ( tokenList ) ; boolean notdone = true ; while ( notdone ) { for ( int i = 0 ; i < list . size ( ) ; i ++ ) { List < Token > insideList = list . get ( i ) ; if ( singleRuleCompatible ( insideList . toArray ( new Token [ insideList . size ( ) ] ) ) ) { if ( i == list . size ( ) - 1 ) notdone = false ; continue ; } else { list . remove ( i ) ; Iterable < List < Token > > splitTokens = splitListForSingleRule ( insideList ) ; for ( List < Token > ind : splitTokens ) { list . add ( ind ) ; } break ; } } } return list ; } public List < List < Token > > splitListForSingleRule ( List < Token > tokens ) { ArrayList < List < Token > > list = new ArrayList < > ( ) ; final List < Token > firstList = new ArrayList < > ( ) ; list . add ( firstList ) ; int i ; for ( i = 0 ; i < tokens . size ( ) ; i ++ ) { if ( isOrCompatible ( tokens . get ( i ) ) ) { firstList . add ( tokens . get ( i ) ) ; } else { list . remove ( firstList ) ; Iterable < CgSet > newSets = splitCgSet ( tokens . get ( i ) . target ) ; for ( CgSet set : newSets ) { Token newToken = new Token ( tokens . get ( i ) ) ; newToken . target = expandSetSets ( set ) ; newToken . postags = newToken . target . getPostagsString ( ) ; newToken . baseforms = newToken . target . getSingleTagBaseformsString ( ) ; newToken . surfaceforms = newToken . target . getSingleTagSurfaceformsString ( ) ; newToken . compositeTags = newToken . target . getCompositeTags ( ) ; List < Token > newList = new ArrayList < > ( ) ; for ( Token token : firstList ) { newList . add ( new Token ( token ) ) ; } newList . add ( newToken ) ; list . add ( newList ) ; } break ; } } for ( int j = i + 1 ; j < tokens . size ( ) ; j ++ ) { for ( int k = 0 ; k < list . size ( ) ; k ++ ) { List < Token > insideList = list . get ( k ) ; insideList . add ( tokens . get ( j ) ) ; list . set ( k , insideList ) ; } } return list ; } public List < CgSet > splitCgSet ( CgSet target ) { List < CgSet > newSets = new ArrayList < > ( ) ; CgTag [ ] postags = target . getSingleTagPostags ( ) ; CgTag [ ] baseforms = target . getSingleTagBaseforms ( ) ; CgTag [ ] surfaceforms = target . getSingleTagSurfaceforms ( ) ; CgCompositeTag [ ] compositePostags = target . getCompositePostags ( ) ; if ( postags . length > 0 && baseforms . length > 0 ) { CgSet set1 = new CgSet ( target ) ; CgSet set2 = new CgSet ( set1 ) ; set1 . single_tags . removeAll ( Arrays . asList ( postags ) ) ; set1 . tags . removeAll ( Arrays . asList ( compositePostags ) ) ; set2 . single_tags . removeAll ( Arrays . asList ( baseforms ) ) ; newSets . add ( set1 ) ; newSets . add ( set2 ) ; return newSets ; } if ( postags . length > 0 && surfaceforms . length > 0 ) { CgSet set1 = new CgSet ( target ) ; CgSet set2 = new CgSet ( target ) ; set1 . single_tags . removeAll ( Arrays . asList ( postags ) ) ; set1 . tags . removeAll ( Arrays . asList ( compositePostags ) ) ; set2 . single_tags . removeAll ( Arrays . asList ( surfaceforms ) ) ; newSets . add ( set1 ) ; newSets . add ( set2 ) ; return newSets ; } if ( surfaceforms . length > 0 && baseforms . length > 0 ) { CgSet set1 = new CgSet ( target ) ; CgSet set2 = new CgSet ( target ) ; set1 . single_tags . removeAll ( Arrays . asList ( surfaceforms ) ) ; set2 . single_tags . removeAll ( Arrays . asList ( baseforms ) ) ; newSets . add ( set1 ) ; newSets . add ( set2 ) ; return newSets ; } newSets = groupCompositeTags ( target ) ; return newSets ; } @ SuppressWarnings ( "unchecked" ) private List < CgSet > groupCompositeTags ( CgSet target ) { HashMap < String , ArrayList < CgCompositeTag > > bf = new HashMap < > ( ) ; Map < String , ArrayList < CgCompositeTag > > sf = new HashMap < > ( ) ; Map < String , CgCompositeTag > dict = new HashMap < > ( ) ; for ( CgCompositeTag ctag : target . tags ) { CgCompositeTag postags = new CgCompositeTag ( ) ; CgCompositeTag baseforms = new CgCompositeTag ( ) ; CgCompositeTag surfaceforms = new CgCompositeTag ( ) ; for ( CgTag tag : ctag . tags ) { if ( isBaseForm ( tag . tag ) ) { baseforms . addTag ( tag ) ; } else if ( isSurfaceForm ( tag . tag ) ) { surfaceforms . addTag ( tag ) ; } else if ( isPostag ( tag . tag ) ) { postags . addTag ( tag ) ; } } if ( ! postags . isEmpty ( ) ) { if ( ! baseforms . isEmpty ( ) ) { bf = ( HashMap ) smartPut ( bf , postags . toString ( ) , baseforms ) ; } else if ( ! surfaceforms . isEmpty ( ) ) { sf = ( HashMap ) smartPut ( sf , postags . toString ( ) , surfaceforms ) ; } } dict . put ( postags . toString ( ) , postags ) ; } List < CgSet > ret = new ArrayList < > ( ) ; for ( String postagSet : bf . keySet ( ) ) { CgSet newSet = new CgSet ( target ) ; newSet . tags = new HashSet < > ( ) ; Iterable < CgCompositeTag > bfs = bf . get ( postagSet ) ; for ( CgCompositeTag singleBf : bfs ) { CgCompositeTag newTotalTag = new CgCompositeTag ( ) ; for ( CgTag tag : dict . get ( postagSet ) . tags ) { newTotalTag . addTag ( tag ) ; } for ( CgTag tag : singleBf . tags ) { newTotalTag . addTag ( tag ) ; } newSet . addCompositeTag ( newTotalTag ) ; } ret . add ( newSet ) ; } return ret ; } public List < List < Token > > getSkipSafeTokens ( Token [ ] tokens ) { List < List < Token > > list = new ArrayList < > ( ) ; List < Token > tokenList = Arrays . asList ( tokens ) ; list . add ( tokenList ) ; boolean notdone = true ; while ( notdone ) { for ( int i = 0 ; i < list . size ( ) ; i ++ ) { List < Token > insideList = list . get ( i ) ; if ( skipSafe ( insideList . toArray ( new Token [ insideList . size ( ) ] ) ) ) { if ( i == list . size ( ) - 1 ) { notdone = false ; } } else { list . remove ( i ) ; Iterable < List < Token > > splitTokens = splitOutSkipTokens ( insideList ) ; for ( List < Token > isl : splitTokens ) { list . add ( isl ) ; } break ; } } } return list ; } public List < List < Token > > splitOutSkipTokens ( List < Token > tokens ) { ArrayList < List < Token > > list = new ArrayList < > ( ) ; ArrayList < Token > scanningTokens = new ArrayList < > ( ) ; ArrayList < Token > reverseScanningTokens = new ArrayList < > ( ) ; ArrayList < Token > normalTokens = new ArrayList < > ( ) ; for ( Token token : tokens ) { if ( token . scanahead ) scanningTokens . add ( token ) ; else if ( token . scanbehind ) reverseScanningTokens . add ( token ) ; else normalTokens . add ( token ) ; } for ( final Token scanning : scanningTokens ) { for ( int n = 0 ; n < normalTokens . size ( ) ; n ++ ) { final Token normal = normalTokens . get ( n ) ; if ( normal . offset >= scanning . offset ) { List < Token > newTokenList1 = new ArrayList < > ( ) ; List < Token > newTokenList2 = new ArrayList < > ( ) ; for ( Token ntoken : normalTokens ) { newTokenList1 . add ( ntoken ) ; newTokenList2 . add ( ntoken ) ; } Token newNormalToken = new Token ( scanning ) ; newNormalToken . scanahead = false ; newTokenList1 . add ( newNormalToken ) ; scanning . offset ++ ; newTokenList2 . add ( scanning ) ; list . add ( newTokenList1 ) ; list . add ( newTokenList2 ) ; return list ; } } } for ( final Token scanning : reverseScanningTokens ) { for ( int n = 0 ; n < normalTokens . size ( ) ; n ++ ) { final Token normal = normalTokens . get ( n ) ; if ( normal . offset <= scanning . offset ) { List < Token > newTokenList1 = new ArrayList < > ( ) ; List < Token > newTokenList2 = new ArrayList < > ( ) ; for ( Token ntoken : normalTokens ) { newTokenList1 . add ( ntoken ) ; newTokenList2 . add ( ntoken ) ; } Token newNormalToken = new Token ( scanning ) ; newNormalToken . scanbehind = false ; newTokenList1 . add ( newNormalToken ) ; scanning . offset -- ; newTokenList2 . add ( scanning ) ; list . add ( newTokenList1 ) ; list . add ( newTokenList2 ) ; return list ; } } } return null ; } public List < List < Token > > splitNegativeBackwardBarrierScan ( Token [ ] tokens ) { ArrayList < List < Token > > list = new ArrayList < > ( ) ; List < Token > newTokenList1 = new ArrayList < > ( ) ; List < Token > newTokenList2 = new ArrayList < > ( ) ; int index = 0 ; for ( index = 0 ; index < tokens . length ; index ++ ) { if ( tokens [ index ] . scanbehind && tokens [ index ] . negate && ! tokens [ index ] . barrier . isEmpty ( ) ) { Token newToken = new Token ( tokens [ index ] ) ; newToken . barrier = new CgSet ( ) ; newTokenList1 . add ( tokens [ index ] ) ; newTokenList2 . add ( newToken ) ; break ; } else { newTokenList1 . add ( tokens [ index ] ) ; newTokenList2 . add ( tokens [ index ] ) ; } } for ( index = index + 1 ; index < tokens . length ; index ++ ) { newTokenList1 . add ( tokens [ index ] ) ; newTokenList2 . add ( tokens [ index ] ) ; } list . add ( newTokenList1 ) ; list . add ( newTokenList2 ) ; return list ; } public Token [ ] resolveLinkedTokens ( Token [ ] tokens ) { List < Token > tokenList = new ArrayList < > ( Arrays . asList ( tokens ) ) ; boolean notdone = true ; while ( notdone ) { for ( int i = 0 ; i < tokenList . size ( ) ; i ++ ) { Token curToken = tokenList . get ( i ) ; if ( curToken . nextToken != null ) { Token tempToken = new Token ( curToken . nextToken ) ; tempToken . offset = curToken . offset + tempToken . relativeOffset ; tokenList . add ( i + 1 , tempToken ) ; Token temp2 = new Token ( curToken ) ; temp2 . nextToken = null ; tokenList . set ( i , temp2 ) ; break ; } else { if ( i == tokenList . size ( ) - 1 ) notdone = false ; } } } return tokenList . toArray ( new Token [ tokenList . size ( ) ] ) ; } public Token getLinkedTokens ( ArrayList < CgContextualTest > tests ) { ArrayList < Token > tokens = new ArrayList < > ( ) ; for ( int i = 0 ; i < tests . size ( ) ; i ++ ) { if ( i == 0 ) { tokens . add ( getTokenFromNormalTest ( tests . get ( i ) ) ) ; } else { Token token = getTokenFromNormalTest ( tests . get ( i ) ) ; token . relativeOffset = token . offset ; token . offset = token . offset + tokens . get ( i - 1 ) . offset ; token . prevToken = tokens . get ( i - 1 ) ; tokens . add ( token ) ; } } Token [ ] ts = tokens . toArray ( new Token [ tokens . size ( ) ] ) ; Arrays . sort ( ts ) ; for ( Token t : ts ) { if ( t . scanahead ) { t . scanahead = false ; ts [ 0 ] . scanahead = true ; break ; } } for ( int i = 1 ; i < ts . length ; i ++ ) { if ( ts [ i ] . scanahead ) { System . err . println ( "Two scan tests in one series of linked tests. This is really hard to represent in LT format. Try to split it into several rules" ) ; System . exit ( 1 ) ; } } ts = addLinkedGapTokens ( ts ) ; for ( int i = 0 ; i < ts . length ; i ++ ) { if ( i == 0 ) { ts [ i ] . relativeOffset = 0 ; } else { ts [ i ] . relativeOffset = 1 ; } if ( i != ts . length - 1 ) ts [ i ] . nextToken = ts [ i + 1 ] ; if ( i != 0 ) ts [ i ] . prevToken = ts [ i - 1 ] ; } return ts [ 0 ] ; } public Token [ ] addLinkedGapTokens ( Token [ ] ts ) { ArrayList < Token > tokens = new ArrayList < > ( Arrays . asList ( ts ) ) ; boolean notdone = true ; while ( notdone ) { for ( int i = 0 ; i < tokens . size ( ) ; i ++ ) { if ( i == 0 ) continue ; else if ( i > 0 && i < tokens . size ( ) ) { if ( tokens . get ( i ) . offset == tokens . get ( i - 1 ) . offset || tokens . get ( i ) . offset == ( tokens . get ( i - 1 ) . offset + 1 ) ) { if ( i == tokens . size ( ) - 1 ) notdone = false ; continue ; } else { Token newToken = new Token ( new CgSet ( ) , false , tokens . get ( i - 1 ) . offset + 1 , false , false , new CgSet ( ) , false , 0 , false ) ; newToken . relativeOffset = tokens . get ( i - 1 ) . relativeOffset + 1 ; Token oldToken = tokens . get ( i - 1 ) ; oldToken . relativeOffset = - 1 ; tokens . set ( i - 1 , oldToken ) ; tokens . add ( i , newToken ) ; break ; } } if ( i == tokens . size ( ) - 1 ) { notdone = false ; } } } return tokens . toArray ( new Token [ tokens . size ( ) ] ) ; } public Token [ ] addSkipTokens ( Token [ ] tokens ) { ArrayList < Token > tokenList = new ArrayList < > ( Arrays . asList ( tokens ) ) ; for ( int i = 0 ; i < tokenList . size ( ) ; i ++ ) { if ( tokenList . get ( i ) . scanahead ) { if ( i == 0 ) { Token newToken = new Token ( new CgSet ( ) , false , tokenList . get ( i ) . offset - 1 , false , false , new CgSet ( ) , false , - 1 , false ) ; if ( ! tokenList . get ( i ) . barrier . isEmpty ( ) || tokenList . get ( i ) . negate ) { newToken . exceptionString = getBarrierExceptionStringFromToken ( tokenList . get ( i ) ) ; } Token oldToken = tokenList . get ( i ) ; if ( oldToken . negate ) { CgSet newTarget = oldToken . barrier ; CgTag sentEndTag = new CgTag ( ) ; sentEndTag . tag = SENT_END ; newTarget . single_tags . add ( sentEndTag ) ; oldToken . target = newTarget ; oldToken . postags = oldToken . target . getPostagsString ( ) ; oldToken . baseforms = oldToken . target . getSingleTagBaseformsString ( ) ; oldToken . surfaceforms = oldToken . target . getSingleTagSurfaceformsString ( ) ; oldToken . compositeTags = oldToken . target . getCompositeTags ( ) ; tokenList . set ( 0 , oldToken ) ; } tokenList . add ( 0 , newToken ) ; } else { int index = i - 1 ; String exceptionString = null ; if ( ! tokenList . get ( i ) . barrier . isEmpty ( ) || tokenList . get ( i ) . negate ) { exceptionString = getBarrierExceptionStringFromToken ( tokenList . get ( i ) ) ; } int prevOffset = tokenList . get ( index ) . offset ; while ( index >= 0 && tokenList . get ( index ) . offset == prevOffset ) { Token prevToken = tokenList . get ( index ) ; prevToken . skip = - 1 ; prevToken . exceptionString = exceptionString ; tokenList . set ( index , prevToken ) ; index -- ; } Token oldToken = tokenList . get ( i ) ; if ( oldToken . negate ) { CgSet newTarget = oldToken . barrier ; CgTag sentEndTag = new CgTag ( ) ; sentEndTag . tag = SENT_END ; newTarget . single_tags . add ( sentEndTag ) ; oldToken . target = newTarget ; oldToken . postags = oldToken . target . getPostagsString ( ) ; oldToken . baseforms = oldToken . target . getSingleTagBaseformsString ( ) ; oldToken . surfaceforms = oldToken . target . getSingleTagSurfaceformsString ( ) ; oldToken . compositeTags = oldToken . target . getCompositeTags ( ) ; oldToken . negate = false ; tokenList . set ( i , oldToken ) ; } } } else if ( tokenList . get ( i ) . scanbehind ) { Token newToken = new Token ( new CgSet ( ) , false , tokenList . get ( i ) . offset - 1 , false , false , new CgSet ( ) , false , - 1 , false ) ; String exceptionString = null ; if ( ! tokenList . get ( i ) . barrier . isEmpty ( ) || tokenList . get ( i ) . negate ) { exceptionString = getBarrierExceptionStringFromToken ( tokenList . get ( i ) ) ; } CgSet newTarget = newToken . target ; CgTag sentStartTag = new CgTag ( ) ; sentStartTag . tag = SENT_START ; newTarget . single_tags . add ( sentStartTag ) ; newToken . target = newTarget ; newToken . postags = newToken . target . getPostagsString ( ) ; newToken . baseforms = newToken . target . getSingleTagBaseformsString ( ) ; newToken . surfaceforms = newToken . target . getSingleTagSurfaceformsString ( ) ; newToken . compositeTags = newToken . target . getCompositeTags ( ) ; newToken . skip = - 1 ; Token oldToken = tokenList . get ( i ) ; oldToken . skip = - 1 ; oldToken . scanbehind = false ; if ( oldToken . barrier . isEmpty ( ) ) { if ( oldToken . negate ) { newToken . exceptionString = exceptionString ; newToken . offset ++ ; tokenList . set ( i , newToken ) ; } else { tokenList . set ( i , oldToken ) ; tokenList . add ( i , newToken ) ; i ++ ; } } else { if ( oldToken . negate ) { oldToken . target = oldToken . barrier ; oldToken . postags = oldToken . target . getPostagsString ( ) ; oldToken . baseforms = oldToken . target . getSingleTagBaseformsString ( ) ; oldToken . surfaceforms = oldToken . target . getSingleTagSurfaceformsString ( ) ; oldToken . compositeTags = oldToken . target . getCompositeTags ( ) ; oldToken . exceptionString = exceptionString ; tokenList . set ( i , oldToken ) ; tokenList . add ( i , newToken ) ; } else { oldToken . exceptionString = exceptionString ; tokenList . set ( i , oldToken ) ; tokenList . add ( i , newToken ) ; i ++ ; } } } } return tokenList . toArray ( new Token [ tokenList . size ( ) ] ) ; } public Token [ ] addGapTokens ( Token [ ] tokens ) { boolean notdone = true ; ArrayList < Token > tokenList = new ArrayList < > ( Arrays . asList ( tokens ) ) ; while ( notdone ) { for ( int i = 0 ; i < tokenList . size ( ) ; i ++ ) { if ( i == 0 ) continue ; else if ( i > 0 && i < tokenList . size ( ) ) { if ( tokenList . get ( i ) . offset == tokenList . get ( i - 1 ) . offset ) { if ( i == tokenList . size ( ) - 1 ) notdone = false ; continue ; } if ( tokenList . get ( i ) . offset != ( tokenList . get ( i - 1 ) . offset + 1 ) && tokenList . get ( i ) . prevToken == null ) { tokenList . add ( i , new Token ( new CgSet ( ) , false , tokenList . get ( i - 1 ) . offset + 1 , false , false , new CgSet ( ) , false , 0 , false ) ) ; break ; } } if ( i == tokenList . size ( ) - 1 ) { notdone = false ; } } } return tokenList . toArray ( new Token [ tokenList . size ( ) ] ) ; } public ArrayList < Token > copyTokenList ( Iterable < Token > tokens ) { ArrayList < Token > newList = new ArrayList < > ( ) ; for ( Token token : tokens ) { newList . add ( new Token ( token ) ) ; } return newList ; } public ArrayList < Token > removeExtraEmptyTokens ( ArrayList < Token > tokens ) { if ( tokens . size ( ) == 1 ) { return tokens ; } else { ArrayList < Token > newTokenList = new ArrayList < > ( ) ; for ( Token token : tokens ) { if ( ! token . isEmpty ( ) ) { newTokenList . add ( token ) ; } } if ( newTokenList . isEmpty ( ) ) { newTokenList . add ( tokens . get ( 0 ) ) ; } return newTokenList ; } } public boolean skipSafe ( Token [ ] tokens ) { Collection < Token > scanningTokens = new HashSet < > ( ) ; Collection < Token > reverseScanningTokens = new HashSet < > ( ) ; Collection < Token > normalTokens = new HashSet < > ( ) ; for ( Token token : tokens ) { if ( token . scanahead ) { scanningTokens . add ( token ) ; } else if ( token . scanbehind ) { reverseScanningTokens . add ( token ) ; } else { normalTokens . add ( token ) ; } } for ( Token s : scanningTokens ) { for ( Token o : normalTokens ) { if ( s . offset <= o . offset ) return false ; } } for ( Token s : reverseScanningTokens ) { for ( Token o : normalTokens ) { if ( s . offset >= o . offset ) return false ; } } return true ; } public boolean negativeBackwardBarrierScan ( Token [ ] tokens ) { for ( Token token : tokens ) { if ( token . scanbehind && token . negate && ! token . barrier . isEmpty ( ) ) { return true ; } } return false ; } public boolean singleRuleCompatible ( Token [ ] tokens ) { for ( Token token : tokens ) { if ( ! isOrCompatible ( token ) ) return false ; } return true ; } public boolean isOrCompatible ( Token token ) { if ( token . postags . length > 0 && ( token . baseforms . length > 0 || token . surfaceforms . length > 0 ) ) { return false ; } if ( token . baseforms . length > 0 && token . surfaceforms . length > 0 ) { return false ; } if ( token . compositeTags . length > 0 && ( token . postags . length > 0 || token . baseforms . length > 0 || token . surfaceforms . length > 0 ) ) { return false ; } Collection < String > pos = new HashSet < > ( ) ; Collection < String > base = new HashSet < > ( ) ; Collection < String > surf = new HashSet < > ( ) ; for ( CgCompositeTag ctag : token . compositeTags ) { CgCompositeTag postagCompile = new CgCompositeTag ( ) ; for ( CgTag tag : ctag . tags ) { if ( isPostag ( tag . tag ) ) { postagCompile . addTag ( tag ) ; } else if ( isSurfaceForm ( tag . tag ) ) { surf . add ( tag . tag ) ; } else if ( isBaseForm ( tag . tag ) ) { base . add ( tag . tag ) ; } } pos . add ( postagCompile . toString ( ) ) ; } if ( pos . size ( ) > 1 && ( surf . size ( ) > 1 || base . size ( ) > 1 ) ) { return false ; } if ( surf . size ( ) > 1 && base . size ( ) > 1 ) { return false ; } if ( surf . size ( ) > 0 && base . size ( ) > 0 && pos . size ( ) > 0 ) { return false ; } return true ; } @ SuppressWarnings ( "unchecked" ) public List < String > getRuleByType ( CgSet target , Token [ ] tokens , CgRule rule , String id , String name , String type ) { ArrayList < String > ltRule = new ArrayList < > ( ) ; TreeMap < Integer , ArrayList < Token > > tokenmap = new TreeMap < > ( ) ; for ( Token token : tokens ) { tokenmap = ( TreeMap ) smartPut ( tokenmap , token . offset , token ) ; } if ( name != null || id != null ) { ltRule . add ( "<rule id=\"" + id + "\" name=\"" + name + "\">" ) ; } else { ltRule . add ( "<rule>" ) ; } int mark = getPositionOfTarget ( tokens ) ; ltRule . add ( firstIndent + "<pattern mark=\"" + mark + "\">" ) ; for ( Integer key : tokenmap . keySet ( ) ) { ArrayList < Token > value = tokenmap . get ( key ) ; value = removeExtraEmptyTokens ( value ) ; if ( value . size ( ) == 1 ) { Token token = value . get ( 0 ) ; ltRule = addCgToken ( ltRule , token , secondIndentInt ) ; } else { ltRule . add ( secondIndent + "<and>" ) ; for ( Token token : value ) { ltRule = addCgToken ( ltRule , token , thirdIndentInt ) ; } ltRule . add ( secondIndent + "</and>" ) ; } } ltRule . add ( firstIndent + "</pattern>" ) ; if ( type . equals ( "K_REMOVE" ) ) { ltRule . add ( firstIndent + "<disambig action=\"remove\">" + removeTarget ( target ) + "</disambig>" ) ; } else if ( type . equals ( "K_SELECT" ) ) { ltRule . add ( firstIndent + filterTarget ( target , mark + 1 ) ) ; } else if ( type . equals ( "K_MAP" ) ) { ltRule . add ( firstIndent + "<disambig action=\"add\" postag=\"" + addRegexp ( rule . maplist ) + "\" postag_regexp=\"yes\"/>" ) ; } ltRule . add ( "</rule>" ) ; return ltRule ; } public ArrayList < String > addCgToken ( ArrayList < String > ltRule , Token token , int indent ) { String postags = postagsToString ( token . postags ) ; String baseforms = glueWords ( cleanForms ( token . baseforms ) ) ; String surfaceforms = glueWords ( cleanForms ( token . surfaceforms ) ) ; CgCompositeTag [ ] compositeTags = token . compositeTags ; if ( compositeTags . length != 0 ) { ArrayList < String > baseformsList = new ArrayList < > ( ) ; ArrayList < String > surfaceformsList = new ArrayList < > ( ) ; for ( CgCompositeTag ctag : compositeTags ) { CgCompositeTag postagCompiled = new CgCompositeTag ( ) ; for ( CgTag tag : ctag . tags ) { if ( isPostag ( tag . tag ) ) { postagCompiled . addTag ( tag ) ; } else if ( isBaseForm ( tag . tag ) ) { baseformsList . add ( tag . tag ) ; } else if ( isSurfaceForm ( tag . tag ) ) { surfaceformsList . add ( tag . tag ) ; } } postags = compositePostagToString ( postagCompiled ) ; } baseforms = glueWords ( cleanForms ( baseformsList . toArray ( new String [ baseformsList . size ( ) ] ) ) ) ; surfaceforms = glueWords ( cleanForms ( surfaceformsList . toArray ( new String [ surfaceformsList . size ( ) ] ) ) ) ; } boolean careful = token . careful ; boolean negate = token . negate ; String exceptions = token . exceptionString ; int skip = token . skip ; if ( postags . equals ( "" ) && baseforms . equals ( "" ) && surfaceforms . equals ( "" ) ) { ltRule = addToken ( ltRule , baseforms , postags , exceptions , careful , false , negate , skip , indent ) ; return ltRule ; } if ( ! baseforms . equals ( "" ) ) { ltRule = addToken ( ltRule , baseforms , postags , exceptions , careful , true , negate , skip , indent ) ; } else if ( ! surfaceforms . equals ( "" ) ) { ltRule = addToken ( ltRule , surfaceforms , postags , exceptions , careful , false , negate , skip , indent ) ; } else { ltRule = addToken ( ltRule , surfaceforms , postags , exceptions , careful , false , negate , skip , indent ) ; } return ltRule ; } public String getBarrierExceptionStringFromToken ( Token token ) { boolean not = token . negate ; boolean inflected = true ; String barrierPos = glueWords ( expandSetSets ( token . barrier ) . getPostagsString ( ) ) ; if ( token . scanahead ) { barrierPos = barrierPos . concat ( "|" + SENT_END ) ; } String barrierToken = glueWords ( token . barrier . getSingleTagBaseformsString ( ) ) ; if ( barrierToken . isEmpty ( ) ) { barrierToken = glueWords ( token . barrier . getSingleTagSurfaceformsString ( ) ) ; inflected = false ; } String targetPos = glueWords ( token . postags ) ; String targetToken = glueWords ( token . baseforms ) ; if ( targetToken . isEmpty ( ) ) { targetToken = glueWords ( token . surfaceforms ) ; if ( not ) inflected = false ; } String postagString = "" ; String tokenString = "" ; String inflectedString = "" ; String regexpString = "" ; String postagRegexpString = "" ; if ( not ) { if ( ! targetPos . isEmpty ( ) ) { postagString = " postag=\"" + targetPos + "\"" ; if ( isRegex ( targetPos ) ) { postagRegexpString = " postag_regexp=\"yes\"" ; } } if ( ! targetToken . isEmpty ( ) ) { tokenString = " " . concat ( targetToken ) ; if ( isRegex ( tokenString ) ) { regexpString = " regexp=\"yes\"" ; } } } else { if ( ! barrierPos . isEmpty ( ) ) { postagString = " postag=\"" + barrierPos + "\"" ; } if ( isRegex ( barrierPos ) ) { postagRegexpString = " postag_regexp=\"yes\"" ; } if ( ! barrierToken . isEmpty ( ) ) { tokenString = barrierToken ; if ( isRegex ( tokenString ) ) { regexpString = " postag_regexp=\"yes\"" ; } } } if ( inflected ) { inflectedString = " inflected=\"yes\"" ; } String retString = "<exception" + postagString + inflectedString + regexpString + postagRegexpString + " scope=\"next\">" + tokenString + "</exception>" ; return retString ; } public int getPositionOfTarget ( Token [ ] tokens ) { Token firstToken = tokens [ 0 ] ; return - 1 * firstToken . offset ; } public Token getTokenFromNormalTest ( CgContextualTest test ) { CgSet testTarget = expandSetSets ( grammar . getSet ( test . target ) ) ; boolean testCareful = test . pos . contains ( POS . POS_CAREFUL . value ) ; int testOffset = test . offset ; boolean testScanAhead = test . pos . contains ( POS . POS_SCANFIRST . value ) && testOffset >= 0 ; boolean testScanBehind = test . pos . contains ( POS . POS_SCANFIRST . value ) && testOffset < 0 ; boolean testNot = test . pos . contains ( POS . POS_NOT . value ) ; CgSet testBarrier = grammar . getSet ( test . barrier ) ; CgSet testCBarrier = grammar . getSet ( test . cbarrier ) ; CgSet barrier = null ; boolean cbarrier = false ; if ( testBarrier != null && testCBarrier != null ) { System . err . println ( "Can't have both a barrier and a careful barrier" ) ; System . exit ( 1 ) ; } if ( testBarrier != null ) { barrier = testBarrier ; cbarrier = false ; } else if ( testCBarrier != null ) { barrier = testCBarrier ; cbarrier = true ; } else { barrier = new CgSet ( ) ; cbarrier = false ; } if ( test . line == 548 && test . offset == 1 ) { System . out . println ( ) ; } return new Token ( testTarget , testCareful , testOffset , testScanAhead , testScanBehind , barrier , cbarrier , 0 , testNot ) ; } public CgSet expandSetSets ( CgSet set ) { CgSet newSet = new CgSet ( ) ; newSet . line = set . line ; newSet . type = set . type ; newSet . name = set . name ; if ( set . sets . isEmpty ( ) ) { return set ; } else if ( set . sets . size ( ) > 1 && set . set_ops . isEmpty ( ) ) { System . err . println ( "Error: something wonky with the set on line " + set . line ) ; System . exit ( 1 ) ; } else if ( set . set_ops . isEmpty ( ) ) { CgSet expandedSet = expandSetSets ( grammar . getSet ( set . sets . get ( 0 ) ) ) ; for ( CgCompositeTag ctag : expandedSet . tags ) { newSet . tags . add ( ctag ) ; } for ( CgTag tag : expandedSet . single_tags ) { newSet . single_tags . add ( tag ) ; } } else { for ( int op = 0 ; op < set . set_ops . size ( ) ; op ++ ) { CgSet expandedSet1 = expandSetSets ( grammar . getSet ( set . sets . get ( op ) ) ) ; CgSet expandedSet2 = expandSetSets ( grammar . getSet ( set . sets . get ( op + 1 ) ) ) ; if ( set . set_ops . get ( op ) == 4 ) { for ( CgTag tag : expandedSet1 . single_tags ) { for ( CgTag tag2 : expandedSet2 . single_tags ) { if ( tag . tag . equals ( tag2 . tag ) ) { newSet . addTag ( tag ) ; } else { CgCompositeTag ctag = new CgCompositeTag ( ) ; ctag . addTag ( tag ) ; ctag . addTag ( tag2 ) ; newSet . addCompositeTag ( ctag ) ; } } } for ( CgCompositeTag ctag : expandedSet1 . tags ) { for ( CgTag tag : expandedSet2 . single_tags ) { if ( ctag . tags . contains ( tag ) ) { newSet . addCompositeTag ( ctag ) ; } else { CgCompositeTag ctagnew = new CgCompositeTag ( ) ; for ( CgTag tag2 : ctag . tags ) { ctagnew . addTag ( tag2 ) ; } ctagnew . addTag ( tag ) ; newSet . addCompositeTag ( ctagnew ) ; } } } for ( CgCompositeTag ctag : expandedSet2 . tags ) { for ( CgTag tag : expandedSet1 . single_tags ) { if ( ctag . tags . contains ( tag ) ) { newSet . addCompositeTag ( ctag ) ; } else { CgCompositeTag ctagnew = new CgCompositeTag ( ) ; for ( CgTag tag2 : ctag . tags ) { ctagnew . addTag ( tag2 ) ; } ctagnew . addTag ( tag ) ; newSet . addCompositeTag ( ctagnew ) ; } } } for ( CgCompositeTag ctag : expandedSet1 . tags ) { for ( CgCompositeTag ctag2 : expandedSet2 . tags ) { CgCompositeTag ctagnew = new CgCompositeTag ( ) ; for ( CgTag tag : ctag . tags ) { if ( ! ctagnew . tags . contains ( tag ) ) { ctagnew . addTag ( tag ) ; } } for ( CgTag tag : ctag2 . tags ) { if ( ! ctagnew . tags . contains ( tag ) ) { ctagnew . addTag ( tag ) ; } } newSet . addCompositeTag ( ctagnew ) ; } } } else if ( set . set_ops . get ( op ) == 3 ) { for ( CgCompositeTag ctag : expandedSet1 . tags ) { newSet . addCompositeTag ( ctag ) ; } for ( CgCompositeTag ctag : expandedSet2 . tags ) { newSet . addCompositeTag ( ctag ) ; } for ( CgTag tag : expandedSet1 . single_tags ) { newSet . addTag ( tag ) ; } for ( CgTag tag : expandedSet2 . single_tags ) { newSet . addTag ( tag ) ; } } } } return newSet ; } @ Override public String generateName ( Object ruleObject ) { CgRule rule = ( CgRule ) ruleObject ; String name = rule . name ; if ( name == null ) { name = "rule_" + nameIndex ; nameIndex ++ ; } return name ; } @ Override public String generateId ( Object ruleObject ) { CgRule rule = ( CgRule ) ruleObject ; String name = rule . name ; if ( name == null ) { name = "rule_" + idIndex ; idIndex ++ ; } return name ; } @ Override public String getOriginalRuleString ( Object ruleObject ) { CgRule rule = ( CgRule ) ruleObject ; return lines [ rule . line ] ; } @ Override public String [ ] getAcceptableFileTypes ( ) { String [ ] ft = { "default" } ; return ft ; } public class Token implements Comparable < Token > { public CgSet target ; public String [ ] postags ; public String [ ] surfaceforms ; public String [ ] baseforms ; public CgCompositeTag [ ] compositeTags ; public boolean careful ; public int offset ; public boolean scanahead ; public boolean scanbehind ; public CgSet barrier ; public boolean cbarrier ; public int skip ; public boolean negate ; public int relativeOffset ; public Token nextToken ; public Token prevToken ; public String exceptionString ; public Token ( ) { } public Token ( Token another ) { this . target = new CgSet ( another . target ) ; this . postags = target . getPostagsString ( ) ; this . surfaceforms = target . getSingleTagSurfaceformsString ( ) ; this . baseforms = target . getSingleTagBaseformsString ( ) ; this . compositeTags = target . getCompositeTags ( ) ; this . careful = another . careful ; this . offset = another . offset ; this . scanahead = another . scanahead ; this . scanbehind = another . scanbehind ; this . barrier = new CgSet ( another . barrier ) ; this . cbarrier = another . cbarrier ; this . skip = another . skip ; this . negate = another . negate ; this . nextToken = another . nextToken ; this . prevToken = another . prevToken ; this . relativeOffset = another . relativeOffset ; this . exceptionString = another . exceptionString ; } public Token ( CgSet target , boolean careful , int offset , boolean scanahead , boolean scanbehind , CgSet barrier , boolean cbarrier , int skip , boolean negate ) { this . target = target ; this . postags = target . getPostagsString ( ) ; this . surfaceforms = target . getSingleTagSurfaceformsString ( ) ; this . baseforms = target . getSingleTagBaseformsString ( ) ; this . compositeTags = target . getCompositeTags ( ) ; this . careful = careful ; this . offset = offset ; this . scanahead = scanahead ; this . scanbehind = scanbehind ; this . barrier = barrier ; this . cbarrier = cbarrier ; this . skip = skip ; this . negate = negate ; this . nextToken = null ; this . prevToken = null ; this . relativeOffset = 0 ; } @ Override public int compareTo ( Token token ) { if ( this . offset < token . offset ) { return - 1 ; } else if ( this . offset == token . offset ) { return 0 ; } else { return 1 ; } } public boolean isEmpty ( ) { return ( this . postags . length == 0 ) && ( this . baseforms . length == 0 ) && ( this . surfaceforms . length == 0 ) && ( this . compositeTags . length == 0 ) ; } @ Override public String toString ( ) { StringBuilder sb = new StringBuilder ( ) ; for ( String postag : this . postags ) { sb . append ( postag ) . append ( " " ) ; } for ( String baseform : this . baseforms ) { sb . append ( baseform ) . append ( " " ) ; } for ( String surfaceform : this . surfaceforms ) { sb . append ( surfaceform ) . append ( " " ) ; } for ( CgCompositeTag ctag : this . compositeTags ) { sb . append ( ctag . toString ( ) ) . append ( " " ) ; } return sb . toString ( ) ; } } public static boolean isPostag ( String tag ) { return ! ( tag . matches ( "\"\\<.*\\>\"r?i?" ) || tag . matches ( "\".*\"r?i?" ) ) ; } public static boolean isSurfaceForm ( String form ) { return ( form . matches ( "\"\\<.*\\>\"r?i?" ) || form . matches ( "\"\"\\<.*\\>\"r?i?\"" ) ) ; } public static boolean isBaseForm ( String form ) { return ( form . matches ( "\"[^<]*[^>]\"r?i?" ) || form . matches ( "\"\"[^<]*[^>]\"r?i?\"" ) ) ; } public static boolean isCompositePostag ( CgCompositeTag ctag ) { for ( CgTag tag : ctag . tags ) { if ( isBaseForm ( tag . tag ) || isSurfaceForm ( tag . tag ) ) { return false ; } } return true ; } public static boolean sameStrings ( String [ ] s1 , String [ ] s2 ) { if ( s1 . length != s2 . length ) { return false ; } else { for ( String ss1 : s1 ) { for ( String ss2 : s2 ) { if ( ! ss1 . equals ( ss2 ) ) return false ; } } } return true ; } public static String [ ] cleanForms ( String [ ] words ) { for ( int i = 0 ; i < words . length ; i ++ ) { words [ i ] = words [ i ] . replaceAll ( ">\"r?i?" , "" ) . replaceAll ( ">\"" , "" ) . replaceAll ( "\"<" , "" ) . replaceAll ( "\"r?i?" , "" ) ; } return words ; } public static String filterRegexp ( CgSet target ) { String [ ] postags = target . getPostagsString ( ) ; String postagString = glueWords ( postags ) ; postagString = "(" . concat ( postagString ) . concat ( ")" ) ; String postagRegexp = toStringRegexpFormat ( postagString ) ; return "(?!" + postagRegexp + ").*" ; } public static String filterTarget ( CgSet target , int targetNo ) { StringBuilder sb = new StringBuilder ( ) ; String [ ] lemmas = cleanForms ( target . getSingleTagBaseformsString ( ) ) ; String [ ] postags = cleanForms ( target . getPostagsString ( ) ) ; CgCompositeTag [ ] compositeTags = target . getCompositeTags ( ) ; String [ ] surfaceforms = cleanForms ( target . getSingleTagSurfaceformsString ( ) ) ; if ( lemmas . length > 0 && ( compositeTags . length > 0 || postags . length > 0 || surfaceforms . length > 0 ) ) { System . err . println ( "Error: something went wrong here." ) ; } if ( lemmas . length > 0 ) { sb . append ( "<disambig action=\"filter\"><match no=\"" ) . append ( targetNo ) . append ( "\">" ) . append ( glueWords ( lemmas ) ) . append ( "</match></disambig>" ) ; } if ( postags . length > 0 ) { String postagRegexp = "" ; if ( isRegex ( glueWords ( postags ) ) ) { postagRegexp = " postag_regexp=\"yes\"" ; } sb . append ( "<disambig postag=\"" ) . append ( glueWords ( postags ) ) . append ( "\"" ) . append ( postagRegexp ) . append ( "/>" ) ; } return sb . toString ( ) ; } public static String removeTarget ( CgSet target ) { StringBuilder sb = new StringBuilder ( ) ; sb . append ( "<wd " ) ; String [ ] lemmas = target . getSingleTagBaseformsString ( ) ; String [ ] postags = target . getPostagsString ( ) ; CgCompositeTag [ ] compositeTags = target . getCompositeTags ( ) ; String [ ] surfaceforms = target . getSingleTagSurfaceformsString ( ) ; if ( lemmas . length > 0 && ( compositeTags . length > 0 || postags . length > 0 || surfaceforms . length > 0 ) ) { System . err . println ( "Error: something went wrong here." ) ; } if ( lemmas . length > 0 ) { sb . append ( "lemma=" ) . append ( glueWords ( lemmas ) ) ; } if ( postags . length > 0 ) { sb . append ( "pos=\"" ) . append ( glueWords ( postags ) ) . append ( "\"" ) ; } sb . append ( "/>" ) ; return sb . toString ( ) ; } public static String replaceRegexp ( CgSet target ) { String [ ] postags = target . getPostagsString ( ) ; String postagString = glueWords ( postags ) ; postagString = "(" . concat ( postagString ) . concat ( ")" ) ; String postagRegexp = toStringRegexpFormat ( postagString ) ; return postagRegexp ; } public static String addRegexp ( CgSet target ) { String [ ] postags = target . getSingleTagPostagsString ( ) ; if ( postags . length != 1 ) { System . err . println ( "Error: trying to map more than one mapping tag on line " + target . line ) ; System . exit ( 1 ) ; } String postag = postags [ 0 ] ; return postag ; } public static String postagsToString ( String [ ] postags ) { if ( postags . length == 0 ) { return "" ; } StringBuilder sb = new StringBuilder ( ) ; for ( String pos : postags ) { sb . append ( pos ) . append ( "|" ) ; } String ret = sb . toString ( ) ; return ret . substring ( 0 , ret . length ( ) - 1 ) ; } public static String toStringRegexpFormat ( String t ) { return t ; } public static String compositePostagToString ( CgCompositeTag ctag ) { StringBuilder sb = new StringBuilder ( ) ; for ( CgTag tag : ctag . tags ) { if ( isPostag ( tag . tag ) ) { sb . append ( tag . tag ) ; sb . append ( tagDelimiter ) ; } } sb . deleteCharAt ( sb . length ( ) - 1 ) ; sb . append ( ".*" ) ; return sb . toString ( ) ; } public static String tagToString ( CgTag tag ) { return tag . tag ; } public static < K , V > Map < K , ArrayList < V > > smartPut ( Map < K , ArrayList < V > > map , K key , V value ) { if ( map . containsKey ( key ) ) { ArrayList < V > original = map . get ( key ) ; original . add ( value ) ; map . put ( key , original ) ; } else { ArrayList < V > newcollection = new ArrayList < > ( ) ; newcollection . add ( value ) ; map . put ( key , newcollection ) ; } return map ; } }
package org . languagetool . dev . conversion . gui ; import java . awt . Color ; import java . awt . Container ; import java . awt . Dimension ; import java . awt . FileDialog ; import java . awt . Frame ; import java . awt . GridBagConstraints ; import java . awt . GridBagLayout ; import java . awt . Insets ; import java . awt . event . ActionEvent ; import java . awt . event . ActionListener ; import java . awt . event . KeyEvent ; import java . awt . event . WindowEvent ; import java . awt . event . WindowListener ; import java . io . BufferedReader ; import java . io . File ; import java . io . FileOutputStream ; import java . io . FileReader ; import java . io . IOException ; import java . io . OutputStreamWriter ; import java . io . PrintWriter ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import javax . swing . JButton ; import javax . swing . JCheckBox ; import javax . swing . JComboBox ; import javax . swing . JComponent ; import javax . swing . JDialog ; import javax . swing . JFrame ; import javax . swing . JLabel ; import javax . swing . JOptionPane ; import javax . swing . JPanel ; import javax . swing . JRootPane ; import javax . swing . JScrollPane ; import javax . swing . JTextPane ; import javax . swing . KeyStroke ; import javax . swing . UIManager ; import javax . swing . border . LineBorder ; import net . boplicity . xmleditor . XmlTextPane ; import org . languagetool . JLanguageTool ; import org . languagetool . dev . conversion . AtdRuleConverter ; import org . languagetool . dev . conversion . CgRuleConverter ; import org . languagetool . dev . conversion . RuleConverter ; import org . languagetool . dev . conversion . RuleCoverage ; import org . languagetool . rules . Rule ; import org . languagetool . rules . patterns . PatternRule ; public final class Main implements ActionListener { private JFrame frame ; private JComboBox rulesBox ; private XmlTextPane resultArea ; private JComboBox ruleTypeBox ; private JComboBox specificRuleTypeBox ; private JTextPane coveredByPane ; private JTextPane warningPane ; private JButton convert ; private JButton saveEditedRule ; private JButton deleteCurrentRule ; private JButton toggleDefaultOff ; private JButton makeRuleExclusive ; private JButton toggleExtraTokens ; private JButton checkRulesCoveredButton ; private JButton recheckCurrentRuleCoverage ; private JButton writeRulesToFileButton ; private JCheckBox regularRules ; private JCheckBox disambigRules ; private JCheckBox noWarningRules ; private JCheckBox warningRules ; private JCheckBox coveredRules ; private JCheckBox notCoveredRules ; private JTextPane mainRuleFilePane ; private JTextPane outFilePane ; private JTextPane disambigOutFilePane ; private JCheckBox writeCoveredRules ; private JCheckBox editBeforeWriting ; private JTextPane numRulesPane ; private JTextPane displayedNumRulesPane ; private List < ? extends Object > ruleObjects ; private ArrayList < List < String > > allRulesList ; private ArrayList < String > ruleStrings ; private ArrayList < String > originalRuleStrings ; private ArrayList < String [ ] > warnings ; private boolean [ ] disambigRuleIndices ; private ArrayList < String [ ] > coveredByList ; private RuleCoverage checker ; private String filename = "" ; private String outfilename = "" ; private String disambigOutFile = "" ; private boolean defaultOff = false ; private boolean extraTokens = true ; private int numberOfRules ; private static String cgString = "Constraint Grammar" ; private static String atdString = "After the Deadline" ; private static final int WINDOW_WIDTH = 850 ; private static final int WINDOW_HEIGHT = 800 ; private static Pattern ruleHeaderRegex = Pattern . compile ( "<rule(group)?\\s+id=\".*?\"\\s+name=\".*?\"" ) ; private static Pattern defaultOffRegex = Pattern . compile ( " default=\"off\"" ) ; private static String defaultOffString = " default=\"off\"" ; private static Pattern postagToken = Pattern . compile ( "(<token postag=\"(.*?)\"( postag_regexp=\"yes\")?>)(</token>)" ) ; public static void main ( final String [ ] args ) { try { final Main prg = new Main ( ) ; if ( args . length > 0 ) { System . out . println ( "Usage: java -jar RuleConverterGUI.jar" ) ; System . out . println ( " no arguments" ) ; } else { javax . swing . SwingUtilities . invokeLater ( new Runnable ( ) { @ Override public void run ( ) { try { prg . createGUI ( ) ; prg . showGUI ( ) ; } catch ( final Exception e ) { showError ( e ) ; } } } ) ; } } catch ( final Exception e ) { showError ( e ) ; } } private void createGUI ( ) { frame = new JFrame ( "Language Tool Rule Converter" ) ; frame . addWindowListener ( new CloseListener ( ) ) ; frame . setJMenuBar ( new MainMenuBar ( this ) ) ; setLookAndFeel ( ) ; resultArea = new XmlTextPane ( ) ; resultArea . requestFocusInWindow ( ) ; JScrollPane scrollPane = new JScrollPane ( resultArea ) ; scrollPane . setPreferredSize ( new Dimension ( 250 , 145 ) ) ; scrollPane . setMinimumSize ( new Dimension ( 10 , 10 ) ) ; rulesBox = new JComboBox ( ) ; rulesBox . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { displaySelectedRule ( ) ; displayCoveredBy ( ) ; displayWarnings ( ) ; } } ) ; ruleTypeBox = new JComboBox ( ) ; ruleTypeBox . addItem ( atdString ) ; ruleTypeBox . addItem ( cgString ) ; ruleTypeBox . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { populateSpecificRuleType ( ) ; } } ) ; specificRuleTypeBox = new JComboBox ( ) ; populateSpecificRuleType ( ) ; mainRuleFilePane = new JTextPane ( ) ; mainRuleFilePane . setText ( filename ) ; mainRuleFilePane . setBorder ( new LineBorder ( Color . BLACK , 1 ) ) ; outFilePane = new JTextPane ( ) ; outFilePane . setText ( outfilename ) ; outFilePane . setBorder ( new LineBorder ( Color . BLACK , 1 ) ) ; disambigOutFilePane = new JTextPane ( ) ; disambigOutFilePane . setText ( disambigOutFile ) ; disambigOutFilePane . setBorder ( new LineBorder ( Color . BLACK , 1 ) ) ; convert = new JButton ( "Convert" ) ; convert . setMnemonic ( 'C' ) ; convert . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { convertRuleFile ( ) ; populateRuleBox ( ) ; } } ) ; deleteCurrentRule = new JButton ( "Delete current rule" ) ; deleteCurrentRule . setMnemonic ( 'D' ) ; deleteCurrentRule . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { deleteCurrentRule ( ) ; } } ) ; toggleDefaultOff = new JButton ( "Toggle default=\"off\"" ) ; toggleDefaultOff . setMnemonic ( 't' ) ; toggleDefaultOff . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { if ( ! defaultOff ) { setDefaultOff ( ) ; defaultOff = true ; } else { setDefaultOn ( ) ; defaultOff = false ; } } } ) ; makeRuleExclusive = new JButton ( "Make rule exclusive" ) ; makeRuleExclusive . setMnemonic ( 'x' ) ; makeRuleExclusive . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { makeCurrentRuleExclusive ( ) ; } } ) ; toggleExtraTokens = new JButton ( "Toggle extra tokens" ) ; toggleExtraTokens . setMnemonic ( 'a' ) ; toggleExtraTokens . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { if ( ! extraTokens ) { addExtraTokens ( ) ; extraTokens = true ; } else { removeExtraTokens ( ) ; extraTokens = false ; } } } ) ; saveEditedRule = new JButton ( "Save rule" ) ; saveEditedRule . setMnemonic ( 'S' ) ; saveEditedRule . addActionListener ( new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { saveEditedVisibleRule ( ) ; } } ) ; writeRulesToFileButton = new JButton ( "Write rules to file" ) ; writeRulesToFileButton . setMnemonic ( 'W' ) ; writeRulesToFileButton . addActionListener ( this ) ; coveredByPane = new JTextPane ( ) ; coveredByPane . setBorder ( new LineBorder ( Color . BLACK , 1 ) ) ; warningPane = new JTextPane ( ) ; warningPane . setBorder ( new LineBorder ( Color . BLACK , 1 ) ) ; JPanel coveredWarningPanel = new JPanel ( new GridBagLayout ( ) ) ; GridBagConstraints cwcons = new GridBagConstraints ( ) ; cwcons . weightx = 1f ; cwcons . fill = GridBagConstraints . BOTH ; cwcons . anchor = GridBagConstraints . WEST ; coveredWarningPanel . add ( new JLabel ( "Covered by:" ) , cwcons ) ; cwcons . gridx = 1 ; coveredWarningPanel . add ( new JLabel ( "Warnings:" ) , cwcons ) ; cwcons . gridy = 1 ; coveredWarningPanel . add ( warningPane , cwcons ) ; cwcons . gridx = 0 ; coveredWarningPanel . add ( coveredByPane , cwcons ) ; regularRules = new JCheckBox ( "Show regular rules" , true ) ; disambigRules = new JCheckBox ( "Show disambiguation rules" , true ) ; warningRules = new JCheckBox ( "Show rules with warnings" , true ) ; noWarningRules = new JCheckBox ( "Show rules without warnings" , true ) ; coveredRules = new JCheckBox ( "Show covered rules" , true ) ; notCoveredRules = new JCheckBox ( "Show not covered rules" , true ) ; regularRules . addActionListener ( this ) ; disambigRules . addActionListener ( this ) ; warningRules . addActionListener ( this ) ; noWarningRules . addActionListener ( this ) ; coveredRules . addActionListener ( this ) ; notCoveredRules . addActionListener ( this ) ; writeCoveredRules = new JCheckBox ( "Write duplicate rules to file" ) ; editBeforeWriting = new JCheckBox ( "Edit rules before writing" ) ; checkRulesCoveredButton = new JButton ( "Check rule coverage" ) ; checkRulesCoveredButton . setMnemonic ( 'E' ) ; checkRulesCoveredButton . addActionListener ( this ) ; recheckCurrentRuleCoverage = new JButton ( "Check displayed rule coverage" ) ; recheckCurrentRuleCoverage . setMnemonic ( 'R' ) ; recheckCurrentRuleCoverage . addActionListener ( this ) ; final JLabel numRulesLabel = new JLabel ( "Total number of rules:" ) ; numRulesPane = new JTextPane ( ) ; final JLabel numDisplayedRulesLabel = new JLabel ( "Number of displayed rules:" ) ; displayedNumRulesPane = new JTextPane ( ) ; final Container contentPane = frame . getContentPane ( ) ; final GridBagLayout gridLayout = new GridBagLayout ( ) ; contentPane . setLayout ( gridLayout ) ; final GridBagConstraints cons = new GridBagConstraints ( ) ; cons . fill = GridBagConstraints . BOTH ; final GridBagConstraints buttonCons = new GridBagConstraints ( ) ; final JPanel insidePanel = new JPanel ( ) ; insidePanel . setOpaque ( true ) ; insidePanel . setLayout ( new GridBagLayout ( ) ) ; insidePanel . setBorder ( new LineBorder ( Color . BLACK , 1 ) ) ; buttonCons . fill = GridBagConstraints . BOTH ; JPanel ruleTypePanel = new JPanel ( new GridBagLayout ( ) ) ; GridBagConstraints c = new GridBagConstraints ( ) ; ruleTypePanel . add ( new JLabel ( "Rule type:" ) , c ) ; c . gridx = 1 ; ruleTypePanel . add ( ruleTypeBox , c ) ; c . gridx = 2 ; ruleTypePanel . add ( specificRuleTypeBox , c ) ; insidePanel . add ( ruleTypePanel , buttonCons ) ; JPanel displayRulesPanel = new JPanel ( new GridBagLayout ( ) ) ; c . anchor = GridBagConstraints . WEST ; c . gridx = 0 ; displayRulesPanel . add ( regularRules , c ) ; c . gridx = 1 ; displayRulesPanel . add ( disambigRules , c ) ; c . gridx = 0 ; c . gridy = 1 ; displayRulesPanel . add ( warningRules , c ) ; c . gridx = 1 ; displayRulesPanel . add ( noWarningRules , c ) ; c . gridx = 0 ; c . gridy = 2 ; displayRulesPanel . add ( coveredRules , c ) ; c . gridx = 1 ; displayRulesPanel . add ( notCoveredRules , c ) ; c . anchor = GridBagConstraints . CENTER ; buttonCons . gridy = 1 ; insidePanel . add ( displayRulesPanel , buttonCons ) ; JPanel coveragePanel = new JPanel ( new GridBagLayout ( ) ) ; c . gridx = 0 ; coveragePanel . add ( checkRulesCoveredButton , c ) ; c . gridx = 1 ; coveragePanel . add ( recheckCurrentRuleCoverage , c ) ; buttonCons . gridy = 2 ; buttonCons . fill = GridBagConstraints . NONE ; insidePanel . add ( coveragePanel , buttonCons ) ; JPanel modifyRulesPanel = new JPanel ( new GridBagLayout ( ) ) ; c . gridx = 0 ; modifyRulesPanel . add ( toggleDefaultOff , c ) ; c . gridx = 1 ; modifyRulesPanel . add ( makeRuleExclusive , c ) ; c . gridx = 2 ; modifyRulesPanel . add ( toggleExtraTokens , c ) ; buttonCons . gridy = 3 ; insidePanel . add ( modifyRulesPanel , buttonCons ) ; JPanel savePanel = new JPanel ( new GridBagLayout ( ) ) ; c . gridx = 0 ; savePanel . add ( saveEditedRule , c ) ; c . gridx = 1 ; savePanel . add ( deleteCurrentRule , c ) ; buttonCons . gridy = 4 ; insidePanel . add ( savePanel , buttonCons ) ; JPanel convertPanel = new JPanel ( new GridBagLayout ( ) ) ; c . gridx = 0 ; convertPanel . add ( convert , c ) ; c . gridx = 1 ; convertPanel . add ( writeRulesToFileButton , c ) ; buttonCons . gridy = 5 ; insidePanel . add ( convertPanel , buttonCons ) ; JPanel writeOptionsPanel = new JPanel ( new GridBagLayout ( ) ) ; c . gridx = 0 ; writeOptionsPanel . add ( writeCoveredRules , c ) ; c . gridx = 1 ; writeOptionsPanel . add ( editBeforeWriting , c ) ; buttonCons . gridy = 6 ; insidePanel . add ( writeOptionsPanel , buttonCons ) ; JPanel numRulesPanel = new JPanel ( new GridBagLayout ( ) ) ; c . gridx = 0 ; numRulesPanel . add ( numRulesLabel , c ) ; c . gridx = 1 ; numRulesPanel . add ( numRulesPane , c ) ; c . gridx = 2 ; numRulesPanel . add ( numDisplayedRulesLabel , c ) ; c . gridx = 3 ; numRulesPanel . add ( displayedNumRulesPane , c ) ; buttonCons . gridy = 7 ; insidePanel . add ( numRulesPanel , buttonCons ) ; cons . gridx = 0 ; cons . gridy = 0 ; cons . ipadx = 1 ; cons . ipady = 1 ; JLabel ruleLabel = new JLabel ( "Original rule:" ) ; contentPane . add ( ruleLabel , cons ) ; cons . gridx = 0 ; cons . gridy = 2 ; JLabel convertedRuleLabel = new JLabel ( "Converted rule:" ) ; contentPane . add ( convertedRuleLabel , cons ) ; cons . gridx = 0 ; cons . gridy = 1 ; cons . weightx = 10f ; cons . weighty = 2f ; contentPane . add ( rulesBox , cons ) ; cons . gridx = 0 ; cons . gridy = 3 ; cons . weightx = 10f ; cons . weighty = 10f ; cons . ipady = 150 ; scrollPane . setMinimumSize ( new Dimension ( 0 , 200 ) ) ; contentPane . add ( scrollPane , cons ) ; cons . gridx = 0 ; cons . gridy = 4 ; cons . ipady = 0 ; cons . ipadx = 0 ; cons . weightx = 0 ; cons . weighty = 0 ; cons . anchor = GridBagConstraints . WEST ; contentPane . add ( coveredWarningPanel , cons ) ; cons . gridy = 5 ; contentPane . add ( insidePanel , cons ) ; cons . gridx = 0 ; cons . gridy = 6 ; contentPane . add ( new JLabel ( "Rule file:" ) , cons ) ; cons . gridy = 7 ; contentPane . add ( mainRuleFilePane , cons ) ; cons . gridy = 8 ; contentPane . add ( new JLabel ( "Out file:" ) , cons ) ; cons . gridy = 9 ; contentPane . add ( outFilePane , cons ) ; cons . gridy = 10 ; contentPane . add ( new JLabel ( "Disambiguation out file:" ) , cons ) ; cons . gridy = 11 ; contentPane . add ( disambigOutFilePane , cons ) ; frame . pack ( ) ; frame . setSize ( WINDOW_WIDTH , WINDOW_HEIGHT ) ; } private void setLookAndFeel ( ) { try { for ( UIManager . LookAndFeelInfo info : UIManager . getInstalledLookAndFeels ( ) ) { if ( "Nimbus" . equals ( info . getName ( ) ) ) { UIManager . setLookAndFeel ( info . getClassName ( ) ) ; break ; } } } catch ( Exception ignored ) { } } private void showGUI ( ) { frame . setVisible ( true ) ; } void quit ( ) { frame . setVisible ( false ) ; System . exit ( 0 ) ; } private void displaySelectedRule ( ) { if ( rulesBox . getSelectedIndex ( ) == - 1 ) { resultArea . setText ( "" ) ; } else { String selectedRule = ( String ) rulesBox . getSelectedItem ( ) ; for ( int i = 0 ; i < originalRuleStrings . size ( ) ; i ++ ) { if ( selectedRule . equals ( originalRuleStrings . get ( i ) ) ) { resultArea . setText ( ruleStrings . get ( i ) ) ; break ; } } resultArea . repaint ( ) ; } } private void displayCoveredBy ( ) { if ( rulesBox . getSelectedIndex ( ) == - 1 ) { coveredByPane . setText ( "" ) ; } else { if ( coveredByList != null ) { int index = getCurrentRuleIndex ( ) ; String [ ] cov = coveredByList . get ( index ) ; StringBuilder sb = new StringBuilder ( ) ; for ( String s : cov ) { sb . append ( s ) . append ( ", " ) ; } coveredByPane . setText ( sb . toString ( ) . trim ( ) ) ; } } } public void displayCoveringRules ( ) { String [ ] ruleIds = coveredByPane . getText ( ) . split ( ",\\ ?" ) ; openExistingRuleWindow ( ruleIds ) ; } private void displayWarnings ( ) { if ( rulesBox . getSelectedIndex ( ) == - 1 ) { warningPane . setText ( "" ) ; } else { if ( warnings != null ) { int index = getCurrentRuleIndex ( ) ; warningPane . setText ( listToString ( warnings . get ( index ) ) ) ; warningPane . repaint ( ) ; } } } private void openExistingRuleWindow ( String [ ] ruleIds ) { if ( checker == null ) { return ; } JLanguageTool tool = checker . getLanguageTool ( ) ; String fetchedRuleString = "<pre>" ; List < Rule > rules = tool . getAllRules ( ) ; for ( String ruleId : ruleIds ) { for ( Rule rule : rules ) { if ( rule . getId ( ) . equals ( ruleId ) ) { try { PatternRule patternRule = ( PatternRule ) rule ; String tempRuleString = patternRule . toXML ( ) ; tempRuleString = tempRuleString . replaceAll ( "\\<" , "&lt;" ) . replaceAll ( "\\>" , "&gt;" ) ; fetchedRuleString = fetchedRuleString . concat ( tempRuleString ) . concat ( "<br>" ) ; break ; } catch ( ClassCastException e ) { fetchedRuleString += "Can't display Java rules" ; break ; } } } } fetchedRuleString = fetchedRuleString . concat ( "</pre>" ) ; showDialog ( "<html>" + fetchedRuleString + "</html>" , "Existing LT Rule" ) ; } private void tieOutFileNames ( ) { filename = getCurrentFilename ( ) ; outfilename = filename + ".grammar.xml" ; disambigOutFile = filename + ".disambig.xml" ; outFilePane . setText ( outfilename ) ; disambigOutFilePane . setText ( disambigOutFile ) ; } public void deleteCurrentRule ( ) { if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return ; } int index = getCurrentRuleIndex ( ) ; ruleObjects . remove ( index ) ; allRulesList . remove ( index ) ; ruleStrings . remove ( index ) ; originalRuleStrings . remove ( index ) ; warnings . remove ( index ) ; disambigRuleIndices = removeIndexFromBooleanArray ( disambigRuleIndices , index ) ; coveredByList . remove ( index ) ; numberOfRules -- ; numRulesPane . setText ( Integer . toString ( numberOfRules ) ) ; populateRuleBox ( ) ; if ( index > 0 ) { rulesBox . setSelectedItem ( originalRuleStrings . get ( index - 1 ) ) ; } } private static boolean [ ] removeIndexFromBooleanArray ( boolean [ ] array , int index ) { boolean [ ] n = new boolean [ array . length - 1 ] ; System . arraycopy ( array , 0 , n , 0 , index ) ; System . arraycopy ( array , index + 1 , n , index + 1 - 1 , array . length - ( index + 1 ) ) ; return n ; } public void makeCurrentRuleExclusive ( ) { if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return ; } int index = getCurrentRuleIndex ( ) ; String rs = ruleStrings . get ( index ) ; rs = makeTokensExclusive ( rs ) ; ruleStrings . set ( index , rs ) ; displaySelectedRule ( ) ; } public void makeAllRulesExclusive ( ) { if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return ; } for ( int i = 0 ; i < ruleStrings . size ( ) ; i ++ ) { ruleStrings . set ( i , makeTokensExclusive ( ruleStrings . get ( i ) ) ) ; } populateRuleBox ( ) ; } private String makeTokensExclusive ( String ruleString ) { Matcher m = postagToken . matcher ( ruleString ) ; while ( m . find ( ) ) { String r = generateExclusiveException ( m . group ( 2 ) , m . group ( 3 ) != null ) ; ruleString = ruleString . replace ( m . group ( ) , m . group ( 1 ) + r + m . group ( 4 ) ) ; } return ruleString ; } private String generateExclusiveException ( String postags , boolean regexp ) { String ex = "<exception postag=\"" ; ex = ex . concat ( postags ) . concat ( "\"" ) ; if ( regexp ) { ex = ex . concat ( " postag_regexp=\"yes\" negate_pos=\"yes\"/>" ) ; } else { ex = ex . concat ( " negate_pos=\"yes\"/>" ) ; } if ( postags . equals ( getCurrentRuleConverter ( ) . getSentStart ( ) ) || postags . equals ( getCurrentRuleConverter ( ) . getSentEnd ( ) ) ) { return "" ; } return ex ; } private void setDefaultOff ( ) { if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return ; } for ( int i = 0 ; i < ruleStrings . size ( ) ; i ++ ) { String oldRuleString = ruleStrings . get ( i ) ; String newRuleString = addOffAttribute ( oldRuleString ) ; ruleStrings . set ( i , newRuleString ) ; } displaySelectedRule ( ) ; } private void setDefaultOn ( ) { if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return ; } for ( int i = 0 ; i < ruleStrings . size ( ) ; i ++ ) { String oldRuleString = ruleStrings . get ( i ) ; String newRuleString = removeOffAttribute ( oldRuleString ) ; ruleStrings . set ( i , newRuleString ) ; } displaySelectedRule ( ) ; } private String removeOffAttribute ( String rule ) { Matcher alreadyOff = defaultOffRegex . matcher ( rule ) ; if ( alreadyOff . find ( ) ) { String newRule = rule . replace ( alreadyOff . group ( ) , "" ) ; return newRule ; } else { return rule ; } } private String addOffAttribute ( String rule ) { Matcher alreadyOff = defaultOffRegex . matcher ( rule ) ; if ( alreadyOff . find ( ) ) { return rule ; } else { Matcher ruleHeader = ruleHeaderRegex . matcher ( rule ) ; if ( ! ruleHeader . find ( ) ) { System . out . println ( ) ; } String newRule = rule . replace ( ruleHeader . group ( ) , ruleHeader . group ( ) . concat ( defaultOffString ) ) ; return newRule ; } } private void convertRuleFile ( ) { RuleConverter rc = getCurrentRuleConverter ( ) ; this . rulesBox . removeAllItems ( ) ; try { rc . parseRuleFile ( ) ; ruleObjects = rc . getRules ( ) ; allRulesList = rc . getAllLtRules ( ) ; ruleStrings = new ArrayList < > ( ) ; originalRuleStrings = rc . getOriginalRuleStrings ( ) ; warnings = rc . getWarnings ( ) ; for ( List < String > ruleList : allRulesList ) { String ruleString = RuleConverter . getRuleStringFromList ( ruleList ) ; ruleStrings . add ( ruleString ) ; } removeDuplicateRules ( ) ; disambigRuleIndices = new boolean [ allRulesList . size ( ) ] ; coveredByList = new ArrayList < > ( ) ; numberOfRules = allRulesList . size ( ) ; numRulesPane . setText ( Integer . toString ( numberOfRules ) ) ; for ( int i = 0 ; i < ruleObjects . size ( ) ; i ++ ) { Object ruleObject = ruleObjects . get ( i ) ; if ( rc . isDisambiguationRule ( ruleObject ) ) { disambigRuleIndices [ i ] = true ; } else { disambigRuleIndices [ i ] = false ; } coveredByList . add ( new String [ 0 ] ) ; } tieOutFileNames ( ) ; } catch ( IOException e ) { showDialog ( "IOException while loading/parsing file " + filename , null ) ; } } private void removeDuplicateRules ( ) { boolean notdone = true ; while ( notdone ) { for ( int i = 0 ; i < originalRuleStrings . size ( ) ; i ++ ) { String originalRuleString = originalRuleStrings . get ( i ) ; if ( originalRuleStrings . subList ( i + 1 , originalRuleStrings . size ( ) ) . contains ( originalRuleString ) ) { originalRuleStrings . remove ( i ) ; ruleStrings . remove ( i ) ; allRulesList . remove ( i ) ; ruleObjects . remove ( i ) ; warnings . remove ( i ) ; break ; } else { if ( i == originalRuleStrings . size ( ) - 1 ) notdone = false ; } } } } private void populateRuleBox ( ) { rulesBox . removeAllItems ( ) ; boolean showRegularRules = regularRules . isSelected ( ) ; boolean showDisambigRules = disambigRules . isSelected ( ) ; boolean showWarningRules = warningRules . isSelected ( ) ; boolean showNoWarningRules = noWarningRules . isSelected ( ) ; boolean showCoveredRules = coveredRules . isSelected ( ) ; boolean showNotCoveredRules = notCoveredRules . isSelected ( ) ; int numDisplayed = 0 ; if ( originalRuleStrings != null ) { for ( int i = 0 ; i < originalRuleStrings . size ( ) ; i ++ ) { boolean cov = coveredByList . get ( i ) . length != 0 ; boolean war = ! ( warnings . get ( i ) . length == 0 ) ; boolean dis = disambigRuleIndices [ i ] ; if ( dis && cov && war ) { if ( showDisambigRules && showCoveredRules && showWarningRules ) { rulesBox . addItem ( originalRuleStrings . get ( i ) ) ; numDisplayed ++ ; } } else if ( dis && cov && ! war ) { if ( showDisambigRules && showCoveredRules && showNoWarningRules ) { rulesBox . addItem ( originalRuleStrings . get ( i ) ) ; numDisplayed ++ ; } } else if ( dis && ! cov && war ) { if ( showDisambigRules && showNotCoveredRules && showWarningRules ) { rulesBox . addItem ( originalRuleStrings . get ( i ) ) ; numDisplayed ++ ; } } else if ( dis && ! cov && ! war ) { if ( showDisambigRules && showNotCoveredRules && showNoWarningRules ) { rulesBox . addItem ( originalRuleStrings . get ( i ) ) ; numDisplayed ++ ; } } else if ( ! dis && cov && war ) { if ( showRegularRules && showCoveredRules && showWarningRules ) { rulesBox . addItem ( originalRuleStrings . get ( i ) ) ; numDisplayed ++ ; } } else if ( ! dis && cov && ! war ) { if ( showRegularRules && showCoveredRules && showNoWarningRules ) { rulesBox . addItem ( originalRuleStrings . get ( i ) ) ; numDisplayed ++ ; } } else if ( ! dis && ! cov && war ) { if ( showRegularRules && showNotCoveredRules && showWarningRules ) { rulesBox . addItem ( originalRuleStrings . get ( i ) ) ; numDisplayed ++ ; } } else if ( ! dis && ! cov && ! war ) { if ( showRegularRules && showNotCoveredRules && showNoWarningRules ) { rulesBox . addItem ( originalRuleStrings . get ( i ) ) ; numDisplayed ++ ; } } } displayedNumRulesPane . setText ( Integer . toString ( numDisplayed ) ) ; } } private void populateSpecificRuleType ( ) { String [ ] ft = getCurrentRuleConverter ( ) . getAcceptableFileTypes ( ) ; specificRuleTypeBox . removeAllItems ( ) ; for ( String s : ft ) { specificRuleTypeBox . addItem ( s ) ; } } private RuleConverter getCurrentRuleConverter ( ) { RuleConverter rc = null ; String type = ( String ) ruleTypeBox . getSelectedItem ( ) ; String specificType = ( String ) specificRuleTypeBox . getSelectedItem ( ) ; if ( specificType == null ) { specificType = "default" ; } if ( type . equals ( atdString ) ) { rc = new AtdRuleConverter ( getCurrentFilename ( ) , null , specificType ) ; } else if ( type . equals ( cgString ) ) { rc = new CgRuleConverter ( getCurrentFilename ( ) , null , specificType ) ; } return rc ; } private String getCurrentFilename ( ) { try { String fn = mainRuleFilePane . getText ( ) ; filename = fn ; return mainRuleFilePane . getText ( ) ; } catch ( NullPointerException e ) { return "" ; } } private int getCurrentRuleIndex ( ) { String selectedRule = ( String ) rulesBox . getSelectedItem ( ) ; int index ; for ( index = 0 ; index < originalRuleStrings . size ( ) ; index ++ ) { if ( selectedRule . equals ( originalRuleStrings . get ( index ) ) ) { break ; } } return index ; } private String getCurrentOutfile ( ) { if ( outfilename . equals ( "" ) ) { outfilename = filename + ".grammar.xml" ; return outfilename ; } else { if ( ! outFilePane . getText ( ) . equals ( outfilename ) ) { outfilename = outFilePane . getText ( ) ; } return outfilename ; } } private String getCurrentDisambigFile ( ) { if ( disambigOutFile . equals ( "" ) ) { disambigOutFile = filename + ".disambig.xml" ; return disambigOutFile ; } else { if ( ! disambigOutFilePane . getText ( ) . equals ( disambigOutFile ) ) { disambigOutFile = disambigOutFilePane . getText ( ) ; } return disambigOutFile ; } } @ Override public void actionPerformed ( ActionEvent e ) { if ( e . getSource ( ) == checkRulesCoveredButton ) { checkIfAllCurrentRulesCovered ( ) ; } else if ( e . getSource ( ) == writeRulesToFileButton ) { try { writeRulesToFile ( ) ; } catch ( IOException ex ) { showError ( ex ) ; } } else if ( e . getSource ( ) == recheckCurrentRuleCoverage ) { checkDisplayedRuleCoverage ( ) ; } else if ( e . getSource ( ) == disambigRules || e . getSource ( ) == regularRules || e . getSource ( ) == warningRules || e . getSource ( ) == noWarningRules || e . getSource ( ) == coveredRules || e . getSource ( ) == notCoveredRules ) { populateRuleBox ( ) ; } } public void checkDisplayedRuleCoverage ( ) { if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return ; } try { if ( checker == null ) { checker = new RuleCoverage ( ) ; } int index = getCurrentRuleIndex ( ) ; if ( ! ruleStrings . get ( index ) . equals ( resultArea . getText ( ) ) ) { showDialog ( "Current rule not yet saved" , null ) ; } else { List < PatternRule > patternRules = checker . parsePatternRule ( resultArea . getText ( ) ) ; ArrayList < String [ ] > allCoveringRules = checker . isCoveredBy ( patternRules ) ; ArrayList < String > coveringRules = new ArrayList < > ( ) ; for ( String [ ] s : allCoveringRules ) { Collections . addAll ( coveringRules , s ) ; } coveredByList . set ( index , coveringRules . toArray ( new String [ coveringRules . size ( ) ] ) ) ; displayCoveredBy ( ) ; } } catch ( IOException e ) { showDialog ( "Couldn't parse or check the rule's coverage for some reason" , null ) ; } } private void addExtraTokens ( ) { if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return ; } int index = getCurrentRuleIndex ( ) ; String rs = ruleStrings . get ( index ) ; rs = rs . replace ( "<pattern>\n" , "<pattern>\n<token/>\n" ) ; rs = rs . replace ( "</pattern>\n" , "<token/>\n</pattern>\n" ) ; ruleStrings . set ( index , rs ) ; displaySelectedRule ( ) ; } private void removeExtraTokens ( ) { if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return ; } int index = getCurrentRuleIndex ( ) ; String rs = ruleStrings . get ( index ) ; rs = rs . replace ( "<pattern>\n<token/>\n" , "<pattern>\n" ) ; rs = rs . replace ( "<token/>\n</pattern>\n" , "</pattern>\n" ) ; ruleStrings . set ( index , rs ) ; displaySelectedRule ( ) ; } public void checkIfAllCurrentRulesCovered ( ) { if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return ; } try { checker = new RuleCoverage ( ) ; for ( int i = 0 ; i < ruleStrings . size ( ) ; i ++ ) { if ( disambigRuleIndices [ i ] ) { continue ; } List < PatternRule > patternRules = checker . parsePatternRule ( ruleStrings . get ( i ) ) ; ArrayList < String [ ] > allCoveringRules = checker . isCoveredBy ( patternRules ) ; ArrayList < String > coveringRules = new ArrayList < > ( ) ; for ( String [ ] s : allCoveringRules ) { Collections . addAll ( coveringRules , s ) ; } coveredByList . set ( i , coveringRules . toArray ( new String [ coveringRules . size ( ) ] ) ) ; displayCoveredBy ( ) ; } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } private void saveEditedVisibleRule ( ) { if ( originalRuleStrings != null && ruleStrings != null && rulesBox . getSelectedItem ( ) != null ) { String newRule = resultArea . getText ( ) ; String selectedRule = ( String ) rulesBox . getSelectedItem ( ) ; int index ; for ( index = 0 ; index < originalRuleStrings . size ( ) ; index ++ ) { if ( selectedRule . equals ( originalRuleStrings . get ( index ) ) ) { break ; } } ruleStrings . set ( index , newRule ) ; } } public void clickSaveButton ( ) { saveEditedRule . doClick ( ) ; } public void removeCoveringRules ( ) { int index = getCurrentRuleIndex ( ) ; coveredByList . set ( index , new String [ 0 ] ) ; displayCoveredBy ( ) ; } public void removeWarnings ( ) { int index = getCurrentRuleIndex ( ) ; warnings . set ( index , new String [ 0 ] ) ; displayWarnings ( ) ; } public void writeRulesToFile ( ) throws IOException { if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return ; } boolean writeCovered = writeCoveredRules . isSelected ( ) ; int numReg = 0 ; int numDis = 0 ; StringBuilder regWriteString = new StringBuilder ( ) ; StringBuilder disWriteString = new StringBuilder ( ) ; if ( anyRegularRules ( ) ) { regWriteString . append ( "<category name=\"Auto-generated rules " ) . append ( new File ( filename ) . getName ( ) ) . append ( "\">\n" ) ; for ( int i = 0 ; i < ruleStrings . size ( ) ; i ++ ) { if ( ! disambigRuleIndices [ i ] && ( writeCovered || ( ! writeCovered && coveredByList . get ( i ) . length == 0 ) ) ) { regWriteString . append ( ruleStrings . get ( i ) ) ; numReg ++ ; } } regWriteString . append ( "</category>" ) ; } if ( anyDisambiguationRules ( ) ) { disWriteString . append ( "<category name=\"Auto-generated rules " ) . append ( new File ( filename ) . getName ( ) ) . append ( "\">\n" ) ; for ( int i = 0 ; i < ruleStrings . size ( ) ; i ++ ) { if ( disambigRuleIndices [ i ] ) { disWriteString . append ( ruleStrings . get ( i ) ) ; numDis ++ ; } } disWriteString . append ( "</category>" ) ; } String disString = disWriteString . toString ( ) ; String regString = regWriteString . toString ( ) ; if ( editBeforeWriting . isSelected ( ) ) { writeWithEditing ( disString , regString , numDis , numReg ) ; } else { writeWithoutEditing ( disString , regString , numDis , numReg ) ; } } private void writeWithEditing ( String dis , String reg , int numDis , int numReg ) throws IOException { XmlDisplay regdisplay = new XmlDisplay ( reg , getCurrentOutfile ( ) , "Edit regular out file" ) ; regdisplay . show ( ) ; XmlDisplay disdisplay = new XmlDisplay ( dis , getCurrentDisambigFile ( ) , "Edit disambiguation file" ) ; disdisplay . show ( ) ; } private void writeWithoutEditing ( String dis , String reg , int numDis , int numReg ) throws IOException { if ( ! reg . isEmpty ( ) ) { PrintWriter w = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( outfilename ) , "UTF-8" ) ) ; w . write ( reg ) ; w . close ( ) ; } if ( ! dis . isEmpty ( ) ) { PrintWriter w = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( disambigOutFile ) , "UTF-8" ) ) ; w . write ( dis ) ; w . close ( ) ; } String message = "" ; if ( numReg > 0 ) { message += Integer . toString ( numReg ) + " rules written to " + outfilename + "<br>" ; } if ( numDis > 0 ) { message += Integer . toString ( numDis ) + " rules written to " + disambigOutFile ; } if ( message . equals ( "" ) ) { message = "No rules written" ; } showDialog ( message , null ) ; } private boolean anyRegularRules ( ) { for ( boolean b : disambigRuleIndices ) { if ( ! b ) return true ; } return false ; } private boolean anyDisambiguationRules ( ) { for ( boolean b : disambigRuleIndices ) { if ( b ) return true ; } return false ; } private void showDialog ( String message , String title ) { final JDialog writeDialog = new JDialog ( this . frame ) ; JLabel label = new JLabel ( "<html>" + message + "</html>" ) ; GridBagConstraints cons = new GridBagConstraints ( ) ; cons . insets = new Insets ( 2 , 2 , 2 , 2 ) ; cons . gridx = 0 ; cons . gridy = 0 ; cons . ipady = 10 ; cons . ipadx = 10 ; writeDialog . setLayout ( new GridBagLayout ( ) ) ; writeDialog . add ( label , cons ) ; if ( title == null ) { title = "Message" ; } writeDialog . setTitle ( title ) ; writeDialog . setLocation ( 300 , 300 ) ; final KeyStroke stroke = KeyStroke . getKeyStroke ( KeyEvent . VK_ESCAPE , 0 ) ; final ActionListener actionListener = new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent actionEvent ) { writeDialog . setVisible ( false ) ; } } ; final JRootPane rootPane = writeDialog . getRootPane ( ) ; rootPane . registerKeyboardAction ( actionListener , stroke , JComponent . WHEN_IN_FOCUSED_WINDOW ) ; writeDialog . pack ( ) ; writeDialog . setVisible ( true ) ; } private String loadFile ( Frame f , String title , String fileType ) { String fn = getCurrentFilename ( ) ; FileDialog fd = new FileDialog ( f , title , FileDialog . LOAD ) ; fd . setFile ( fileType ) ; String path = fn . replaceAll ( new File ( fn ) . getName ( ) , "" ) ; fd . setDirectory ( path ) ; fd . setLocation ( 50 , 50 ) ; fd . setVisible ( true ) ; return fd . getDirectory ( ) + fd . getFile ( ) ; } public void loadFile ( ) { String fn = loadFile ( frame , "Load grammar file" , null ) ; if ( ! fn . equals ( "nullnull" ) ) { filename = fn ; mainRuleFilePane . setText ( filename ) ; String fileString = readFileAsString ( filename ) ; if ( fileString . contains ( "::" ) ) { ruleTypeBox . setSelectedItem ( "After the Deadline" ) ; } else if ( fileString . contains ( "REMOVE" ) || fileString . contains ( "SELECT" ) || fileString . contains ( "LIST" ) || fileString . contains ( "SET" ) ) { ruleTypeBox . setSelectedItem ( "Constraint Grammar" ) ; } mainRuleFilePane . setText ( filename ) ; mainRuleFilePane . repaint ( ) ; } } private String readFileAsString ( String filename ) { String line = null ; StringBuilder sb = new StringBuilder ( ) ; try { BufferedReader reader = new BufferedReader ( new FileReader ( filename ) ) ; while ( ( line = reader . readLine ( ) ) != null ) { sb . append ( line ) ; sb . append ( '\n' ) ; } } catch ( IOException e ) { } return sb . toString ( ) ; } public void showAllRules ( ) { final JDialog rulesDialog = new JDialog ( this . frame ) ; rulesDialog . setMinimumSize ( new Dimension ( 500 , 500 ) ) ; JTextPane rulesPane = new JTextPane ( ) ; String allRules = getAllRules ( ) ; rulesPane . setText ( allRules ) ; JScrollPane scrollPane = new JScrollPane ( rulesPane ) ; final KeyStroke stroke = KeyStroke . getKeyStroke ( KeyEvent . VK_ESCAPE , 0 ) ; final ActionListener actionListener = new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent actionEvent ) { rulesDialog . setVisible ( false ) ; } } ; final JRootPane rootPane = rulesDialog . getRootPane ( ) ; rootPane . registerKeyboardAction ( actionListener , stroke , JComponent . WHEN_IN_FOCUSED_WINDOW ) ; rulesDialog . add ( scrollPane ) ; rulesDialog . setVisible ( true ) ; } private String getAllRules ( ) { StringBuilder sb = new StringBuilder ( ) ; if ( ruleStrings == null || rulesBox . getSelectedItem ( ) == null ) { return "" ; } for ( String r : ruleStrings ) { sb . append ( r ) ; } return sb . toString ( ) ; } public void showOriginalRuleFile ( ) { if ( filename == null ) { return ; } String f = readFileAsString ( filename ) ; XmlDisplay regdisplay = new XmlDisplay ( f , filename , "Edit existing rules file" ) ; regdisplay . show ( ) ; } public void displayAboutDialog ( ) { showDialog ( "RuleConverterGUI:<br>Tool for converting rule files from other modalities to LT format.<br>" + "Currently supported: After the Deadline and Constraint Grammar\n" , "About" ) ; } public void nextRule ( ) { if ( rulesBox != null ) { try { rulesBox . setSelectedIndex ( rulesBox . getSelectedIndex ( ) + 1 ) ; } catch ( IndexOutOfBoundsException e ) { } catch ( IllegalArgumentException e ) { } } } public void prevRule ( ) { if ( rulesBox != null ) { try { rulesBox . setSelectedIndex ( rulesBox . getSelectedIndex ( ) - 1 ) ; } catch ( IndexOutOfBoundsException e ) { } catch ( IllegalArgumentException e ) { } } } public static void showError ( final Exception e ) { final String msg = org . languagetool . tools . Tools . getFullStackTrace ( e ) ; JOptionPane . showMessageDialog ( null , msg , "Error" , JOptionPane . ERROR_MESSAGE ) ; e . printStackTrace ( ) ; } private static String listToString ( String [ ] list ) { StringBuilder sb = new StringBuilder ( ) ; for ( String s : list ) { sb . append ( s ) ; sb . append ( "\n" ) ; } return sb . toString ( ) ; } public void cutSelectedText ( ) { resultArea . cut ( ) ; } public void copySelectedText ( ) { resultArea . copy ( ) ; } public void pasteText ( ) { resultArea . paste ( ) ; } class XmlDisplay implements ActionListener { private JFrame xmlframe ; private XmlTextPane pane ; private JScrollPane scrollpane ; private JButton done ; private JButton cancel ; private String text ; private String title ; private String fn ; public XmlDisplay ( String text , String filename , String title ) { this . text = text ; this . fn = filename ; this . title = title ; } public boolean isVisible ( ) { return this . xmlframe . isVisible ( ) ; } public void show ( ) { xmlframe = new JFrame ( title ) ; final Container contentPane = xmlframe . getContentPane ( ) ; final GridBagLayout gridLayout = new GridBagLayout ( ) ; contentPane . setLayout ( gridLayout ) ; GridBagConstraints c = new GridBagConstraints ( ) ; c . fill = GridBagConstraints . BOTH ; c . weightx = 1f ; c . weighty = 1f ; pane = new XmlTextPane ( ) ; pane . setText ( text ) ; pane . requestFocusInWindow ( ) ; scrollpane = new JScrollPane ( pane ) ; scrollpane . setVerticalScrollBarPolicy ( JScrollPane . VERTICAL_SCROLLBAR_ALWAYS ) ; done = new JButton ( "Done" ) ; done . addActionListener ( this ) ; done . setMnemonic ( 'D' ) ; cancel = new JButton ( "Cancel" ) ; cancel . addActionListener ( this ) ; cancel . setMnemonic ( 'C' ) ; c . gridwidth = 2 ; contentPane . add ( scrollpane , c ) ; c . gridy = 1 ; c . weighty = 0 ; c . gridwidth = 1 ; c . fill = GridBagConstraints . NONE ; contentPane . add ( done , c ) ; c . gridx = 1 ; contentPane . add ( cancel , c ) ; final JRootPane rootPane = xmlframe . getRootPane ( ) ; final KeyStroke escStroke = KeyStroke . getKeyStroke ( KeyEvent . VK_ESCAPE , 0 ) ; final ActionListener actionListener = new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { xmlframe . setVisible ( false ) ; } } ; rootPane . registerKeyboardAction ( actionListener , escStroke , JComponent . WHEN_IN_FOCUSED_WINDOW ) ; final KeyStroke enterStroke = KeyStroke . getKeyStroke ( KeyEvent . VK_ENTER , KeyEvent . CTRL_MASK ) ; final ActionListener actionListener2 = new ActionListener ( ) { @ Override public void actionPerformed ( ActionEvent e ) { done . doClick ( ) ; } } ; rootPane . registerKeyboardAction ( actionListener2 , enterStroke , JComponent . WHEN_IN_FOCUSED_WINDOW ) ; xmlframe . pack ( ) ; xmlframe . setSize ( WINDOW_WIDTH , WINDOW_HEIGHT ) ; xmlframe . setVisible ( true ) ; } public String getText ( ) { return this . text ; } private void write ( ) { if ( ! this . text . isEmpty ( ) ) { try { PrintWriter w = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( fn ) , "UTF-8" ) ) ; w . write ( this . text ) ; w . close ( ) ; showDialog ( "Written to " + fn , null ) ; } catch ( IOException e ) { showError ( e ) ; } } } @ Override public void actionPerformed ( ActionEvent e ) { if ( e . getSource ( ) == done ) { this . text = pane . getText ( ) ; this . write ( ) ; xmlframe . setVisible ( false ) ; } else if ( e . getSource ( ) == cancel ) { xmlframe . setVisible ( false ) ; } } } class CloseListener implements WindowListener { @ Override public void windowClosing ( WindowEvent e ) { quit ( ) ; } @ Override public void windowActivated ( WindowEvent e ) { } @ Override public void windowClosed ( WindowEvent e ) { } @ Override public void windowDeactivated ( WindowEvent e ) { } @ Override public void windowDeiconified ( WindowEvent e ) { } @ Override public void windowIconified ( WindowEvent e ) { } @ Override public void windowOpened ( WindowEvent e ) { } } }
package org . languagetool . dev . conversion . gui ; import java . awt . Event ; import java . awt . event . ActionEvent ; import java . awt . event . ActionListener ; import java . awt . event . KeyEvent ; import java . io . IOException ; import javax . swing . JMenu ; import javax . swing . JMenuBar ; import javax . swing . JMenuItem ; import javax . swing . KeyStroke ; class MainMenuBar extends JMenuBar implements ActionListener { private static final long serialVersionUID = - 7160998682243081767L ; private String openText ; private String quitText ; private String writeText ; private String showRulesText ; private String showCoveringRulesText ; private String showOriginalFileText ; private String saveRuleText ; private String removeCoveringRulesText ; private String removeWarningsText ; private String cutText ; private String copyText ; private String pasteText ; private String nextRuleText ; private String prevRuleText ; private String aboutText ; private String allRulesExclusiveText ; private final Main prg ; private JMenu fileMenu ; private JMenu editMenu ; private JMenu navigateMenu ; private JMenu helpMenu ; MainMenuBar ( Main prg ) { this . prg = prg ; initStrings ( ) ; fileMenu . setMnemonic ( 0 ) ; editMenu . setMnemonic ( 0 ) ; navigateMenu . setMnemonic ( 0 ) ; helpMenu . setMnemonic ( 0 ) ; final JMenuItem openItem = new JMenuItem ( openText ) ; openItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_O , Event . CTRL_MASK ) ) ; openItem . setMnemonic ( 0 ) ; openItem . addActionListener ( this ) ; fileMenu . add ( openItem ) ; final JMenuItem writeItem = new JMenuItem ( writeText ) ; writeItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_S , Event . CTRL_MASK | Event . SHIFT_MASK ) ) ; writeItem . setMnemonic ( 0 ) ; writeItem . addActionListener ( this ) ; fileMenu . add ( writeItem ) ; final JMenuItem showRulesItem = new JMenuItem ( showRulesText ) ; showRulesItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_R , Event . CTRL_MASK ) ) ; showRulesItem . setMnemonic ( 0 ) ; showRulesItem . addActionListener ( this ) ; fileMenu . add ( showRulesItem ) ; final JMenuItem showCoveringRulesItem = new JMenuItem ( showCoveringRulesText ) ; showCoveringRulesItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_L , Event . CTRL_MASK ) ) ; showCoveringRulesItem . addActionListener ( this ) ; fileMenu . add ( showCoveringRulesItem ) ; final JMenuItem showOriginalFileItem = new JMenuItem ( showOriginalFileText ) ; showOriginalFileItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_W , Event . CTRL_MASK ) ) ; showOriginalFileItem . addActionListener ( this ) ; fileMenu . add ( showOriginalFileItem ) ; final JMenuItem quitItem = new JMenuItem ( quitText ) ; quitItem . setMnemonic ( 0 ) ; quitItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_Q , Event . CTRL_MASK ) ) ; quitItem . addActionListener ( this ) ; fileMenu . add ( quitItem ) ; final JMenuItem saveRuleItem = new JMenuItem ( saveRuleText ) ; saveRuleItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_S , Event . CTRL_MASK ) ) ; saveRuleItem . addActionListener ( this ) ; editMenu . add ( saveRuleItem ) ; final JMenuItem removeCoveringRulesItem = new JMenuItem ( removeCoveringRulesText ) ; removeCoveringRulesItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_I , Event . CTRL_MASK ) ) ; removeCoveringRulesItem . addActionListener ( this ) ; editMenu . add ( removeCoveringRulesItem ) ; final JMenuItem removeWarningsItem = new JMenuItem ( removeWarningsText ) ; removeWarningsItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_G , Event . CTRL_MASK ) ) ; removeWarningsItem . addActionListener ( this ) ; editMenu . add ( removeWarningsItem ) ; final JMenuItem allRulesExclusiveItem = new JMenuItem ( allRulesExclusiveText ) ; allRulesExclusiveItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_X , Event . CTRL_MASK | Event . ALT_MASK | Event . SHIFT_MASK ) ) ; allRulesExclusiveItem . addActionListener ( this ) ; editMenu . add ( allRulesExclusiveItem ) ; final JMenuItem cutItem = new JMenuItem ( cutText ) ; cutItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_X , Event . CTRL_MASK ) ) ; cutItem . addActionListener ( this ) ; editMenu . add ( cutItem ) ; final JMenuItem copyItem = new JMenuItem ( copyText ) ; copyItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_C , Event . CTRL_MASK ) ) ; copyItem . addActionListener ( this ) ; editMenu . add ( copyItem ) ; final JMenuItem pasteItem = new JMenuItem ( pasteText ) ; pasteItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_P , Event . CTRL_MASK ) ) ; pasteItem . addActionListener ( this ) ; editMenu . add ( pasteItem ) ; final JMenuItem nextRuleItem = new JMenuItem ( nextRuleText ) ; nextRuleItem . setMnemonic ( 0 ) ; nextRuleItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_DOWN , Event . CTRL_MASK ) ) ; nextRuleItem . addActionListener ( this ) ; navigateMenu . add ( nextRuleItem ) ; final JMenuItem prevRuleItem = new JMenuItem ( prevRuleText ) ; prevRuleItem . setMnemonic ( 0 ) ; prevRuleItem . setAccelerator ( KeyStroke . getKeyStroke ( KeyEvent . VK_UP , Event . CTRL_MASK ) ) ; prevRuleItem . addActionListener ( this ) ; navigateMenu . add ( prevRuleItem ) ; final JMenuItem aboutItem = new JMenuItem ( aboutText ) ; aboutItem . addActionListener ( this ) ; aboutItem . setMnemonic ( 0 ) ; helpMenu . add ( aboutItem ) ; add ( fileMenu ) ; add ( editMenu ) ; add ( navigateMenu ) ; add ( helpMenu ) ; } private void initStrings ( ) { fileMenu = new JMenu ( "File" ) ; editMenu = new JMenu ( "Edit" ) ; navigateMenu = new JMenu ( "Navigate" ) ; helpMenu = new JMenu ( "Help" ) ; openText = "Open" ; writeText = "Write rules to file" ; showRulesText = "Show all rules" ; showCoveringRulesText = "Show covering rules" ; showOriginalFileText = "Show original rule file" ; quitText = "Quit" ; saveRuleText = "Save current rule" ; removeCoveringRulesText = "Remove covering rules" ; removeWarningsText = "Remove warnings" ; allRulesExclusiveText = "All rules exclusive" ; cutText = "Cut" ; copyText = "Copy" ; pasteText = "Paste" ; nextRuleText = "Next rule" ; prevRuleText = "Previous rule" ; aboutText = "About" ; } @ Override public void actionPerformed ( ActionEvent e ) { if ( e . getActionCommand ( ) . equals ( openText ) ) { prg . loadFile ( ) ; } else if ( e . getActionCommand ( ) . equals ( quitText ) ) { prg . quit ( ) ; } else if ( e . getActionCommand ( ) . equals ( writeText ) ) { try { prg . writeRulesToFile ( ) ; } catch ( IOException ex ) { throw new RuntimeException ( "Could not write rules to file" , ex ) ; } } else if ( e . getActionCommand ( ) . equals ( nextRuleText ) ) { prg . nextRule ( ) ; } else if ( e . getActionCommand ( ) . equals ( prevRuleText ) ) { prg . prevRule ( ) ; } else if ( e . getActionCommand ( ) . equals ( saveRuleText ) ) { prg . clickSaveButton ( ) ; } else if ( e . getActionCommand ( ) . equals ( showRulesText ) ) { prg . showAllRules ( ) ; } else if ( e . getActionCommand ( ) . equals ( showCoveringRulesText ) ) { prg . displayCoveringRules ( ) ; } else if ( e . getActionCommand ( ) . equals ( aboutText ) ) { prg . displayAboutDialog ( ) ; } else if ( e . getActionCommand ( ) . equals ( cutText ) ) { prg . cutSelectedText ( ) ; } else if ( e . getActionCommand ( ) . equals ( copyText ) ) { prg . copySelectedText ( ) ; } else if ( e . getActionCommand ( ) . equals ( pasteText ) ) { prg . pasteText ( ) ; } else if ( e . getActionCommand ( ) . equals ( removeCoveringRulesText ) ) { prg . removeCoveringRules ( ) ; } else if ( e . getActionCommand ( ) . equals ( removeWarningsText ) ) { prg . removeWarnings ( ) ; } else if ( e . getActionCommand ( ) . equals ( showOriginalFileText ) ) { prg . showOriginalRuleFile ( ) ; } else if ( e . getActionCommand ( ) . equals ( allRulesExclusiveText ) ) { prg . makeAllRulesExclusive ( ) ; } else { throw new IllegalArgumentException ( "Unknown action " + e ) ; } } }
package org . languagetool . dev . conversion . cg ; import java . util . HashMap ; import java . util . HashSet ; import org . languagetool . dev . conversion . cg . CgStrings . KEYWORDS ; public class CgRule { public HashSet < Integer > flags = new HashSet < > ( ) ; public int line ; public KEYWORDS type ; public int wordform ; public int varname ; public int childset1 ; public int childset2 ; public int jumpstart ; public int jumpend ; public int section ; public int target ; public int number ; public CgSet sublist ; public CgSet maplist ; public CgContextualTest dep_test_head ; public CgContextualTest dep_target ; public HashSet < CgContextualTest > all_tests = new HashSet < > ( ) ; public HashMap < Integer , CgContextualTest > test_map = new HashMap < > ( ) ; public HashSet < CgContextualTest > test_heads = new HashSet < > ( ) ; public String name ; public void setName ( String name ) { this . name = name ; } public CgRule ( ) { } public CgRule ( CgRule rule ) { this . flags = new HashSet < > ( rule . flags ) ; this . line = rule . line ; this . type = rule . type ; this . wordform = rule . wordform ; this . varname = rule . varname ; this . childset1 = rule . childset1 ; this . childset2 = rule . childset2 ; this . jumpstart = rule . jumpstart ; this . jumpend = rule . jumpend ; this . section = rule . section ; this . target = rule . target ; this . number = rule . number ; this . sublist = new CgSet ( rule . sublist ) ; this . maplist = new CgSet ( rule . maplist ) ; this . dep_target = new CgContextualTest ( rule . dep_target ) ; this . dep_test_head = new CgContextualTest ( rule . dep_test_head ) ; this . all_tests = new HashSet < > ( ) ; for ( CgContextualTest test : rule . all_tests ) { this . all_tests . add ( new CgContextualTest ( test ) ) ; } this . test_map = new HashMap < > ( ) ; for ( Integer index : rule . test_map . keySet ( ) ) { this . test_map . put ( index , new CgContextualTest ( rule . test_map . get ( index ) ) ) ; } this . test_heads = new HashSet < > ( ) ; for ( CgContextualTest test : rule . test_heads ) { this . test_heads . add ( new CgContextualTest ( test ) ) ; } } public CgContextualTest allocateContextualTest ( ) { return new CgContextualTest ( ) ; } public void addContextualTest ( CgContextualTest t , CgContextualTest head ) { this . all_tests . add ( t ) ; } public enum RFLAGS { RF_NEAREST ( 1 < < 0 ) , RF_ALLOWLOOP ( 1 < < 1 ) , RF_DELAYED ( 1 < < 2 ) , RF_IMMEDIATE ( 1 < < 3 ) , RF_LOOKDELETED ( 1 < < 4 ) , RF_LOOKDELAYED ( 1 < < 5 ) , RF_UNSAFE ( 1 < < 6 ) , RF_SAFE ( 1 < < 7 ) , RF_REMEMBERX ( 1 < < 8 ) , RF_RESETX ( 1 < < 9 ) , RF_KEEPORDER ( 1 < < 10 ) , RF_VARYORDER ( 1 < < 11 ) , RF_ENCL_INNER ( 1 < < 12 ) , RF_ENCL_OUTER ( 1 < < 13 ) , RF_ENCL_FINAL ( 1 < < 14 ) , RF_ENCL_ANY ( 1 < < 15 ) , RF_ALLOWCROSS ( 1 < < 16 ) , RF_WITHCHILD ( 1 < < 17 ) , RF_NOCHILD ( 1 < < 18 ) , RF_ITERATE ( 1 < < 19 ) , RF_NOITERATE ( 1 < < 20 ) , RF_UNMAPLAST ( 1 < < 21 ) , RF_REVERSE ( 1 < < 22 ) ; public int value ; RFLAGS ( int v ) { this . value = v ; } } }
package org . languagetool . tokenizers . ro ; import junit . framework . TestCase ; import org . languagetool . Language ; import org . languagetool . TestTools ; import org . languagetool . language . Romanian ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; public class RomanianSentenceTokenizerTest extends TestCase { Language lang = new Romanian ( ) ; private final SentenceTokenizer stokenizer = new SRXSentenceTokenizer ( lang ) ; private final SentenceTokenizer stokenizer2 = new SRXSentenceTokenizer ( lang ) ; @ Override public final void setUp ( ) { stokenizer . setSingleLineBreaksMarksParagraph ( true ) ; stokenizer2 . setSingleLineBreaksMarksParagraph ( false ) ; } public final void testTokenize ( ) { testSplit ( "Aceasta este o propozitie fara diacritice. " ) ; testSplit ( "Aceasta este o fraza fara diacritice. " , "Propozitia a doua, tot fara diacritice. " ) ; testSplit ( "Aceasta este o propoziție cu diacritice. " ) ; testSplit ( "Aceasta este o propoziție cu diacritice. " , "Propoziția a doua, cu diacritice. " ) ; testSplit ( "O propoziție! " , "Și încă o propoziție. " ) ; testSplit ( "O propoziție... " , "Și încă o propoziție. " ) ; testSplit ( "La adresa http://www.archeus.ro găsiți resurse lingvistice. " ) ; testSplit ( "Data de 10.02.2009 nu trebuie să fie separator de propoziții. " ) ; testSplit ( "Astăzi suntem în data de 07.05.2007. " ) ; testSplit ( "Astăzi suntem în data de 07/05/2007. " ) ; testSplit ( "La anumărul (1) avem puține informații. " ) ; testSplit ( "To jest 1. wydanie." ) ; testSplit ( "La anumărul 1. avem puține informații. " ) ; testSplit ( "La anumărul 13. avem puține informații. " ) ; testSplit ( "La anumărul 1.3.3 avem puține informații. " ) ; testSplit ( "O singură propoziție... " ) ; testSplit ( "Colegii mei s-au dus... " ) ; testSplit ( "O singură propoziție!!! " ) ; testSplit ( "O singură propoziție??? " ) ; testSplit ( "Propoziții: una și alta. " ) ; testSplit ( "Domnu' a plecat. " ) ; testSplit ( "Profu' de istorie tre' să predea lecția. " ) ; testSplit ( "Sal'tare! " ) ; testSplit ( "'Neaţa! " ) ; testSplit ( "Deodat'apare un urs. " ) ; testSplit ( "A făcut două cópii. " ) ; testSplit ( "Ionel adúnă acum ceea ce Maria aduná înainte să vin eu. " ) ; testSplit ( "Domnu' a plecat" ) ; testSplit ( "Domnu' a plecat. " , "El nu a plecat" ) ; testSplit ( "Se pot întâlni și abrevieri precum S.U.A. " + "sau B.C.R. într-o singură propoziție." ) ; testSplit ( "Se pot întâlni și abrevieri precum S.U.A. sau B.C.R. " , "Aici sunt două propoziții." ) ; testSplit ( "Același lucru aici... " , "Aici sunt două propoziții." ) ; testSplit ( "Același lucru aici... dar cu o singură propoziție." ) ; testSplit ( "„O propoziție!” " , "O alta." ) ; testSplit ( "„O propoziție!!!” " , "O alta." ) ; testSplit ( "„O propoziție?” " , "O alta." ) ; testSplit ( "„O propoziție?!?” " , "O alta." ) ; testSplit ( "«O propoziție!» " , "O alta." ) ; testSplit ( "«O propoziție!!!» " , "O alta." ) ; testSplit ( "«O propoziție?» " , "O alta." ) ; testSplit ( "«O propoziție???» " , "O alta." ) ; testSplit ( "«O propoziție?!?» " , "O alta." ) ; testSplit ( "O primă propoziție. " , "(O alta.)" ) ; testSplit ( "A venit domnu' Vasile. " ) ; testSplit ( "A venit domnu' acela. " ) ; TestTools . testSplit ( new String [ ] { "A venit domnul\n\n" , "Vasile." } , stokenizer2 ) ; TestTools . testSplit ( new String [ ] { "A venit domnul\n" , "Vasile." } , stokenizer ) ; TestTools . testSplit ( new String [ ] { "A venit domnu'\n\n" , "Vasile." } , stokenizer2 ) ; TestTools . testSplit ( new String [ ] { "A venit domnu'\n" , "Vasile." } , stokenizer ) ; testSplit ( "El este din România!" , "Acum e plecat cu afaceri." ) ; testSplit ( "Temperatura este de 30°C." , "Este destul de cald." ) ; testSplit ( "A alergat 50 m. " , "Deja a obosit." ) ; testSplit ( "Pentru dvs. vom face o excepție." ) ; testSplit ( "Pt. dumneavoastră vom face o excepție." ) ; testSplit ( "Pt. dvs. vom face o excepție." ) ; testSplit ( "A expus problema d.p.d.v. artistic." ) ; testSplit ( "A expus problema dpdv. artistic." ) ; testSplit ( "Are mere, pere, șamd. dar nu are alune." ) ; testSplit ( "Are mere, pere, ș.a.m.d. dar nu are alune." ) ; testSplit ( "Are mere, pere, ș.a.m.d. " , "În schimb, nu are alune." ) ; testSplit ( "Are mere, pere, ş.c.l. dar nu are alune." ) ; testSplit ( "Are mere, pere, ş.c.l. " , "Nu are alune." ) ; testSplit ( "Are mere, pere, etc. dar nu are alune." ) ; testSplit ( "Are mere, pere, etc. " , "Nu are alune." ) ; testSplit ( "Are mere, pere, ș.a. dar nu are alune." ) ; testSplit ( "Lecția începe la pag. următoare și are trei pagini." ) ; testSplit ( "Lecția începe la pag. 20 și are trei pagini." ) ; testSplit ( "A acționat în conformitate cu lg. 144, art. 33." ) ; testSplit ( "A acționat în conformitate cu leg. 144, art. 33." ) ; testSplit ( "A acționat în conformitate cu legea nr. 11." ) ; testSplit ( "Lupta a avut loc în anul 2000 î.H. și a durat trei ani." ) ; testSplit ( "Discuția a avut loc pe data de douăzeci aug. și a durat două ore." ) ; testSplit ( "Discuția a avut loc pe data de douăzeci ian. și a durat două ore." ) ; testSplit ( "Discuția a avut loc pe data de douăzeci feb. și a durat două ore." ) ; testSplit ( "Discuția a avut loc pe data de douăzeci ian." , "A durat două ore." ) ; testSplit ( "A fost și la M.Ap.N. dar nu l-au primit. " ) ; testSplit ( "A fost și la M.Ap.N. " , "Nu l-au primit. " ) ; testSplit ( "Apo' da' tulai (sic!) că mult mai e de mers." ) ; testSplit ( "Apo' da' tulai(sic!) că mult mai e de mers." ) ; testSplit ( "Aici este o frază […] mult prescurtată." ) ; testSplit ( "Aici este o frază [...] mult prescurtată." ) ; } private void testSplit ( final String ... sentences ) { TestTools . testSplit ( sentences , stokenizer2 ) ; } }
package org . languagetool . rules . ca ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . TextLevelRule ; import java . io . IOException ; import java . util . Collections ; import java . util . List ; public class CatalanUnpairedBracketsRuleTest extends TestCase { private TextLevelRule rule ; private JLanguageTool langTool ; @ Override public void setUp ( ) throws IOException { rule = new CatalanUnpairedBracketsRule ( TestTools . getEnglishMessages ( ) , new Catalan ( ) ) ; langTool = new JLanguageTool ( new Catalan ( ) ) ; } public void testRule ( ) throws IOException { assertCorrect ( "L'«home és així»" ) ; assertCorrect ( "l'«home»" ) ; assertCorrect ( "«\"És així\" o no»" ) ; assertCorrect ( "«\"És així\", va dir.»" ) ; assertCorrect ( "«És \"així\" o no»" ) ; assertCorrect ( "(l'execució a mans d'\"especialistes\")" ) ; assertCorrect ( "(L'\"especialista\")" ) ; assertCorrect ( "\"Vine\", li va dir." ) ; assertCorrect ( "(Una frase de prova)." ) ; assertCorrect ( "Aquesta és la paraula 'prova'." ) ; assertCorrect ( "This is a sentence with a smiley :-)" ) ; assertCorrect ( "This is a sentence with a smiley ;-) and so on..." ) ; assertCorrect ( "Aquesta és l'hora de les decisions." ) ; assertCorrect ( "Aquesta és l’hora de les decisions." ) ; assertCorrect ( "(fig. 20)" ) ; assertCorrect ( "\"Sóc la teva filla. El corcó no et rosegarà més.\"\n\n" ) ; assertCorrect ( "–\"Club dels llagoters\" –va repetir en Ron." ) ; assertCorrect ( "—\"Club dels llagoters\" –va repetir en Ron." ) ; assertCorrect ( "»Això em porta a demanar-t'ho." ) ; assertCorrect ( "»Això em porta (sí) a demanar-t'ho." ) ; assertCorrect ( "al capítol 12 \"Llavors i fruits oleaginosos\"" ) ; assertCorrect ( "\"Per què serveixen les forquilles?\" i aquest respon \"per menjar\"." ) ; assertCorrect ( "És a 60º 50' 23\"" ) ; assertCorrect ( "És a 60º 50' 23'" ) ; assertCorrect ( "60° 50' 23'" ) ; assertCorrect ( "60° 50'" ) ; assertCorrect ( "El tràiler té una picada d'ullet quan diu que \"no es pot fer una pel·lícula 'slasher' com si fos una sèrie\"." ) ; assertCorrect ( "El tràiler –que té una picada d'ullet quan diu que \"no es pot fer una pel·lícula 'slasher' com si fos una sèrie\"– ja " ) ; assertCorrect ( "This is a [test] sentence..." ) ; assertCorrect ( "The plight of Tamil refugees caused a surge of support from most of the Tamil political parties.[90]" ) ; assertCorrect ( "This is what he said: \"We believe in freedom. This is what we do.\"" ) ; assertCorrect ( "(([20] [20] [20]))" ) ; assertCorrect ( "This is a \"special test\", right?" ) ; assertCorrect ( "We discussed this in Chapter 1)." ) ; assertCorrect ( "The jury recommended that: (1) Four additional deputies be employed." ) ; assertCorrect ( "We discussed this in section 1a)." ) ; assertCorrect ( "We discussed this in section iv)." ) ; assertCorrect ( "In addition, the government would pay a $1,000 \"cost of education\" grant to the schools." ) ; assertCorrect ( "Porta'l cap ací." ) ; assertCorrect ( "Porta-me'n cinquanta!" ) ; assertIncorrect ( "(L'\"especialista\"" ) ; assertIncorrect ( "L'«home és així" ) ; assertIncorrect ( "S'«esperava 'el' (segon) \"resultat\"" ) ; assertIncorrect ( "l'«home" ) ; assertIncorrect ( "Ploraria.\"" ) ; assertIncorrect ( "Aquesta és l555’hora de les decisions." ) ; assertIncorrect ( "Vine\", li va dir." ) ; assertIncorrect ( "Aquesta és l‘hora de les decisions." ) ; assertIncorrect ( "(This is a test sentence." ) ; assertIncorrect ( "This is a test with an apostrophe &'." ) ; assertIncorrect ( "&'" ) ; assertIncorrect ( "!'" ) ; assertIncorrect ( "What?'" ) ; assertIncorrect ( "Some text (and some funny remark :-) with more text to follow" ) ; RuleMatch [ ] matches ; matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( "(This is a test” sentence." ) ) ) ; assertEquals ( 2 , matches . length ) ; matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( "This [is (a test} sentence." ) ) ) ; assertEquals ( 3 , matches . length ) ; } private void assertCorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( sentence ) ) ) ; assertEquals ( 0 , matches . length ) ; } private void assertIncorrect ( String sentence ) throws IOException { final RuleMatch [ ] matches = rule . match ( Collections . singletonList ( langTool . getAnalyzedSentence ( sentence ) ) ) ; assertEquals ( 1 , matches . length ) ; } public void testMultipleSentences ( ) throws IOException { final JLanguageTool tool = new JLanguageTool ( new Catalan ( ) ) ; tool . enableRule ( "CA_UNPAIRED_BRACKETS" ) ; List < RuleMatch > matches ; matches = tool . check ( "Aquesta és una sentència múltiple amb claudàtors: " + "[Ací hi ha un claudàtor. Amb algun text.] i ací continua.\n" ) ; assertEquals ( 0 , matches . size ( ) ) ; matches = tool . check ( "\"Sóc la teva filla. El corcó no et rosegarà més.\"\n\n" ) ; assertEquals ( 0 , matches . size ( ) ) ; matches = tool . check ( "\"Sóc la teva filla. El corcó no et rosegarà més\".\n\n" ) ; assertEquals ( 0 , matches . size ( ) ) ; matches = tool . check ( "Aquesta és una sentència múltiple amb claudàtors: " + "[Ací hi ha un claudàtor. Amb algun text. I ací continua.\n\n" ) ; assertEquals ( 1 , matches . size ( ) ) ; matches = tool . check ( "«Els manaments diuen: \"No desitjaràs la dona del teu veí\"»" ) ; matches = tool . check ( "Aquesta és una sentència múltiple amb parèntesis " + "(Ací hi ha un parèntesi. \n\n Amb algun text.) i ací continua." ) ; assertEquals ( 0 , matches . size ( ) ) ; } }
package org . languagetool . dev . conversion . cg ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . HashSet ; import org . languagetool . dev . conversion . cg . CgSet . ST ; import org . languagetool . dev . conversion . cg . CgStrings . STRINGS ; import org . languagetool . dev . conversion . cg . CgTag . TAGS ; public class CgGrammar { public boolean has_dep ; public boolean has_encl_final ; public boolean is_binary ; public int grammar_size ; public String mapping_prefix ; public int lines ; public int verbosity_level ; public double total_time ; public int tag_any ; ArrayList < CgTag > single_tags_list = new ArrayList < > ( ) ; HashMap < Integer , CgTag > single_tags = new HashMap < > ( ) ; ArrayList < CgCompositeTag > tags_list = new ArrayList < > ( ) ; HashMap < Integer , CgCompositeTag > tags = new HashMap < > ( ) ; ArrayList < CgSet > sets_list = new ArrayList < > ( ) ; HashSet < CgSet > sets_all = new HashSet < > ( ) ; HashMap < Integer , CgSet > sets_by_name = new HashMap < > ( ) ; HashMap < Integer , Integer > set_name_seeds = new HashMap < > ( ) ; HashMap < Integer , CgSet > sets_by_contents = new HashMap < > ( ) ; HashMap < Integer , Integer > set_alias = new HashMap < > ( ) ; HashMap < Integer , HashSet < Integer > > sets_by_tag = new HashMap < > ( ) ; HashSet < Integer > sets_any = new HashSet < > ( ) ; ArrayList < String > static_sets = new ArrayList < > ( ) ; ArrayList < CgContextualTest > template_list = new ArrayList < > ( ) ; HashMap < Integer , CgContextualTest > templates = new HashMap < > ( ) ; HashMap < Integer , ArrayList < Integer > > rules_by_set = new HashMap < > ( ) ; HashMap < Integer , ArrayList < Integer > > rules_by_tag = new HashMap < > ( ) ; ArrayList < Integer > rules_any = new ArrayList < > ( ) ; public ArrayList < CgRule > rule_by_number = new ArrayList < > ( ) ; public ArrayList < CgRule > rules = new ArrayList < > ( ) ; ArrayList < Integer > preferred_targets ; HashMap < Integer , Integer > parentheses = new HashMap < > ( ) ; HashMap < Integer , Integer > parentheses_reverse = new HashMap < > ( ) ; HashMap < Integer , Integer > anchor_by_hash = new HashMap < > ( ) ; HashMap < Integer , CgAnchor > anchor_by_line = new HashMap < > ( ) ; ArrayList < Integer > sections = new ArrayList < > ( ) ; ArrayList < CgRule > before_sections = new ArrayList < > ( ) ; ArrayList < CgRule > after_sections = new ArrayList < > ( ) ; ArrayList < CgRule > null_section = new ArrayList < > ( ) ; CgSet delimiters ; CgSet soft_delimiters ; public CgGrammar ( ) { } public void addPreferredTarget ( String s ) { CgTag tag = allocateTag ( s , false ) ; preferred_targets . add ( tag . hash ) ; } public void addSet ( CgSet to ) { if ( this . delimiters == null && to . name . equals ( CgTextualParser . stringbits [ STRINGS . S_DELIMITSET . value ] ) ) { this . delimiters = to ; } else if ( this . soft_delimiters == null && to . name . equals ( CgTextualParser . stringbits [ STRINGS . S_SOFTDELIMITSET . value ] ) ) { this . soft_delimiters = to ; } to . hashContents ( ) ; if ( ! this . sets_all . contains ( to ) ) { this . sets_list . add ( to ) ; } this . sets_all . add ( to ) ; this . sets_by_name . put ( to . hash , to ) ; this . sets_by_contents . put ( to . chash , to ) ; } public CgSet getSet ( int which ) { if ( this . sets_by_name . containsKey ( which ) ) { return this . sets_by_name . get ( which ) ; } return null ; } public CgSet allocateSet ( CgSet from ) { CgSet ns = null ; if ( from != null ) { ns = new CgSet ( from ) ; } else { ns = new CgSet ( ) ; } this . sets_all . add ( ns ) ; return ns ; } public CgSet allocateSet ( ) { return new CgSet ( ) ; } public void destroySet ( CgSet s ) { if ( this . sets_all . contains ( s ) ) { this . sets_all . remove ( s ) ; } } public void addSetToList ( CgSet s ) { if ( s . number == 0 ) { if ( this . sets_list . isEmpty ( ) || this . sets_list . get ( 0 ) != s ) { if ( ! s . sets . isEmpty ( ) ) { for ( int setID : s . sets ) { this . addSetToList ( this . getSet ( setID ) ) ; } } s . number = this . sets_list . size ( ) ; this . sets_list . add ( s ) ; } } } public CgSet parseSet ( String name ) { int sh = name . hashCode ( ) ; if ( name . length ( ) > 2 && ( name . charAt ( 0 ) == '$' && name . charAt ( 1 ) == '$' ) || ( name . charAt ( 0 ) == '&' && name . charAt ( 1 ) == '&' ) ) { String wname = name . substring ( 2 ) ; int wrap = wname . hashCode ( ) ; CgSet wtmp = this . getSet ( wrap ) ; if ( wtmp == null ) { System . err . println ( "Error: attempted to reference undefined set " + wname + " on line " + this . lines ) ; System . exit ( 1 ) ; } CgSet tmp = this . getSet ( sh ) ; if ( tmp == null ) { CgSet ns = this . allocateSet ( ) ; ns . line = this . lines ; ns . setName ( name ) ; ns . sets . add ( wtmp . hash ) ; if ( name . charAt ( 0 ) == '$' && name . charAt ( 1 ) == '$' ) { ns . type . add ( ST . ST_TAG_UNIFY . value ) ; } else if ( name . charAt ( 0 ) == '&' && name . charAt ( 1 ) == '&' ) { ns . type . add ( ST . ST_SET_UNIFY . value ) ; } this . addSet ( ns ) ; } } if ( this . set_alias . containsKey ( sh ) ) { sh = this . set_alias . get ( sh ) ; } CgSet tmp = this . getSet ( sh ) ; if ( tmp == null ) { System . err . println ( "Error: attempted to reference undefined set " + name + " on line " + this . lines ) ; System . exit ( 1 ) ; } return tmp ; } public void addAnchor ( String s , int line ) { int ah = s . hashCode ( ) ; if ( this . anchor_by_hash . containsKey ( ah ) ) { System . err . println ( "Error: attempted to redefine anchor on line " + line ) ; System . exit ( 1 ) ; } CgAnchor anc = new CgAnchor ( ) ; anc . setName ( s ) ; anc . line = line ; this . anchor_by_hash . put ( ah , line ) ; this . anchor_by_line . put ( line , anc ) ; } public CgTag allocateTag ( String txt , boolean raw ) { if ( txt . startsWith ( "(" ) ) { System . err . println ( "Error: tag cannot start with (" ) ; System . exit ( 1 ) ; } CgTag tag = new CgTag ( ) ; if ( raw ) { tag = tag . parseTagRaw ( tag , txt ) ; } else { tag = tag . parseTag ( tag , txt , this ) ; } tag . type . add ( TAGS . T_GRAMMAR . value ) ; int hash = tag . rehash ( ) ; this . single_tags_list . add ( tag ) ; this . single_tags . put ( hash , tag ) ; return this . single_tags . get ( hash ) ; } public CgTag allocateTag ( ) { return new CgTag ( ) ; } public void destroyTag ( CgTag tag ) { } public CgCompositeTag addTagToCompositeTag ( CgTag simpletag , CgCompositeTag tag ) { if ( simpletag != null && ! ( simpletag . tag == null || simpletag . tag == "" ) ) { tag . addTag ( simpletag ) ; } else { System . err . println ( "Error: attempted to add empty tag to grammar on line " + this . lines ) ; System . exit ( 1 ) ; } return tag ; } public CgSet addTagToSet ( CgTag rtag , CgSet set ) { set . single_tags . add ( rtag ) ; set . single_tags_hash . add ( rtag . hashCode ( ) ) ; if ( rtag . type . contains ( TAGS . T_ANY . value ) ) { set . type . add ( ST . ST_ANY . value ) ; } if ( rtag . type . contains ( TAGS . T_SPECIAL . value ) ) { set . type . add ( ST . ST_SPECIAL . value ) ; } if ( rtag . type . contains ( TAGS . T_FAILFAST . value ) ) { set . ff_tags . add ( rtag ) ; } return set ; } public CgCompositeTag addCompositeTag ( CgCompositeTag tag ) { if ( tag != null && tag . tags . size ( ) > 0 ) { tag . rehash ( ) ; if ( this . tags . containsKey ( tag . hash ) ) { } else { tag . number = this . tags_list . size ( ) ; this . tags . put ( tag . hash , tag ) ; this . tags_list . add ( tag ) ; } } else { System . err . println ( "Error: attempted to add empty composite tag to grammar on line " + this . lines ) ; System . exit ( 1 ) ; } return this . tags . get ( tag . hash ) ; } public CgSet addCompositeTagToSet ( CgSet set , CgCompositeTag tag ) { if ( tag != null && ! tag . tags . isEmpty ( ) ) { if ( tag . tags . size ( ) == 1 ) { } else { tag = addCompositeTag ( tag ) ; set . tags . add ( tag ) ; if ( tag . is_special ) { set . type . add ( ST . ST_SPECIAL . value ) ; } } } else { System . err . println ( "Error: attempted to add empty composite tag to set on line " + this . lines ) ; System . exit ( 1 ) ; } this . addCompositeTag ( tag ) ; return set ; } public CgCompositeTag allocateCompositeTag ( ) { return new CgCompositeTag ( ) ; } public void destroyCompositeTag ( CgCompositeTag tag ) { } public CgRule allocateRule ( ) { return new CgRule ( ) ; } public void addRule ( CgRule rule ) { rule . number = this . rule_by_number . size ( ) ; this . rule_by_number . add ( rule ) ; } public void destroyRule ( CgRule rule ) { } public CgContextualTest allocateContextualTest ( ) { return new CgContextualTest ( ) ; } public void addContextualTest ( CgContextualTest test , String name ) { int cn = name . hashCode ( ) ; if ( this . templates . containsKey ( cn ) ) { System . err . println ( "Error: attempted to redefine template " + name + " on line " + this . lines ) ; System . exit ( 1 ) ; } this . templates . put ( cn , test ) ; this . template_list . add ( test ) ; } public void resetStatistics ( ) { } public void reindex ( boolean unused_sets ) { } public void renameAllRules ( ) { } }
package org . languagetool . dev . conversion . cg ; import java . util . ArrayList ; import java . util . HashSet ; public class CgContextualTest { public int line ; public int name ; public HashSet < Integer > pos = new HashSet < > ( ) ; public int offset ; public int relation ; public int target ; public int cbarrier ; public int barrier ; public int linked = 0 ; public int next = 0 ; public int prev = 0 ; public ArrayList < Integer > ors = new ArrayList < > ( ) ; public boolean isParentTest ( ) { return ! this . ors . isEmpty ( ) ; } public boolean isLinkedTest ( ) { return this . next != 0 ; } public boolean isNormalTest ( ) { return ( this . ors . isEmpty ( ) && this . next == 0 ) ; } public void rehash ( ) { } public CgContextualTest allocateContextualTest ( ) { return new CgContextualTest ( ) ; } public CgContextualTest ( ) { this . barrier = 0 ; this . cbarrier = 0 ; this . line = 0 ; this . name = 0 ; this . offset = 0 ; this . target = 0 ; this . pos = new HashSet < > ( ) ; this . relation = 0 ; } public CgContextualTest ( CgContextualTest test ) { if ( test == null ) { this . barrier = 0 ; this . cbarrier = 0 ; this . line = 0 ; this . name = 0 ; this . offset = 0 ; this . target = 0 ; this . pos = new HashSet < > ( ) ; this . relation = 0 ; } else { this . barrier = test . barrier ; this . cbarrier = test . cbarrier ; this . line = test . line ; this . name = test . name ; this . offset = test . offset ; this . target = test . target ; this . pos = new HashSet < > ( test . pos ) ; this . relation = test . relation ; this . ors = new ArrayList < > ( test . ors ) ; } } public enum POS { POS_CAREFUL ( 1 < < 0 ) , POS_NEGATE ( 1 < < 1 ) , POS_NOT ( 1 < < 2 ) , POS_SCANFIRST ( 1 < < 3 ) , POS_SCANALL ( 1 < < 4 ) , POS_ABSOLUTE ( 1 < < 5 ) , POS_SPAN_RIGHT ( 1 < < 6 ) , POS_SPAN_LEFT ( 1 < < 7 ) , POS_SPAN_BOTH ( 1 < < 8 ) , POS_DEP_PARENT ( 1 < < 9 ) , POS_DEP_SIBLING ( 1 < < 10 ) , POS_DEP_CHILD ( 1 < < 11 ) , POS_PASS_ORIGIN ( 1 < < 12 ) , POS_NO_PASS_ORIGIN ( 1 < < 13 ) , POS_LEFT_PAR ( 1 < < 14 ) , POS_RIGHT_PAR ( 1 < < 15 ) , POS_SELF ( 1 < < 16 ) , POS_NONE ( 1 < < 17 ) , POS_ALL ( 1 < < 18 ) , POS_DEP_DEEP ( 1 < < 19 ) , POS_MARK_SET ( 1 < < 20 ) , POS_MARK_JUMP ( 1 < < 21 ) , POS_LOOK_DELETED ( 1 < < 22 ) , POS_LOOK_DELAYED ( 1 < < 23 ) , POS_TMPL_OVERRIDE ( 1 < < 24 ) , POS_UNKNOWN ( 1 < < 25 ) , POS_RELATION ( 1 < < 26 ) , POS_ATTACH_TO ( 1 < < 27 ) ; public int value ; POS ( int v ) { this . value = v ; } } }
package org . languagetool . dev . conversion . cg ; import java . util . HashSet ; import java . util . regex . Pattern ; import org . languagetool . dev . conversion . cg . CgStrings . STRINGS ; public class CgTag { public HashSet < Integer > type ; public int hash ; public int plain_hash ; public int comparison_hash ; public int seed ; public String tag ; public Pattern regexp ; public CgTag ( ) { this . tag = "" ; this . type = new HashSet < > ( ) ; this . hash = 0 ; this . plain_hash = 0 ; this . comparison_hash = 0 ; this . seed = 0 ; } public CgTag parseTagRaw ( CgTag tag , String to ) { tag . type = new HashSet < > ( ) ; if ( to . length ( ) > 0 ) { String tmp = to ; int len = tmp . length ( ) ; if ( tmp . charAt ( 0 ) != ( char ) 0 && ( tmp . charAt ( 0 ) == '"' || tmp . charAt ( 0 ) == '<' ) ) { if ( ( ( tmp . charAt ( 0 ) == '"' ) && ( tmp . charAt ( len - 1 ) == '"' ) ) || ( ( tmp . charAt ( 0 ) == '<' ) && ( tmp . charAt ( len - 1 ) ) == '>' ) ) { tag . type . add ( TAGS . T_TEXTUAL . value ) ; if ( tmp . charAt ( 0 ) == '"' && tmp . charAt ( len - 1 ) == '"' ) { if ( tmp . charAt ( 1 ) == '<' && tmp . charAt ( len - 2 ) == '>' ) { tag . type . add ( TAGS . T_WORDFORM . value ) ; } else { tag . type . add ( TAGS . T_BASEFORM . value ) ; } } } } tag . tag = tmp ; if ( ! tag . tag . isEmpty ( ) && tag . tag . charAt ( 0 ) == '<' && tag . tag . charAt ( len - 1 ) == '>' ) { tag = parseNumeric ( tag ) ; } if ( ! tag . tag . isEmpty ( ) && tag . tag . charAt ( 0 ) == '#' ) { } } if ( tag . type . contains ( TAGS . T_SPECIAL . value ) ) { tag . type . remove ( TAGS . T_SPECIAL . value ) ; } if ( tag . type . contains ( TAGS . T_NUMERICAL . value ) ) { tag . type . add ( TAGS . T_SPECIAL . value ) ; } return tag ; } public CgTag parseTag ( CgTag tag , String to , CgGrammar grammar ) { tag . type = new HashSet < > ( ) ; ; if ( to != null && to . length ( ) > 0 ) { char [ ] tmp = to . toCharArray ( ) ; int tmpIndex = 0 ; while ( tmp . length > 0 && ( tmp [ tmpIndex ] == '!' || tmp [ tmpIndex ] == '^' ) ) { if ( tmp [ tmpIndex ] == '!' ) { tag . type . add ( TAGS . T_NEGATIVE . value ) ; tmpIndex ++ ; } if ( tmp [ tmpIndex ] == '^' ) { tag . type . add ( TAGS . T_FAILFAST . value ) ; tmpIndex ++ ; } } if ( tmp [ tmpIndex ] == 'T' && tmp [ tmpIndex + 1 ] == ':' ) { System . out . println ( "Warning: the tag on line " + grammar . lines + " looks like a misplaced template marker." ) ; } if ( tmp [ tmpIndex ] == 'M' && tmp [ tmpIndex + 1 ] == 'E' && tmp [ tmpIndex + 2 ] == 'T' && tmp [ tmpIndex + 3 ] == 'A' && tmp [ tmpIndex + 4 ] == ':' ) { tag . type . add ( TAGS . T_META . value ) ; tmpIndex += 5 ; } if ( tmp [ tmpIndex ] == 'V' && tmp [ tmpIndex + 1 ] == 'A' && tmp [ tmpIndex + 2 ] == 'R' && tmp [ tmpIndex + 3 ] == ':' ) { tag . type . add ( TAGS . T_VARIABLE . value ) ; tmpIndex += 4 ; } if ( tmp [ tmpIndex ] == 'S' && tmp [ tmpIndex + 1 ] == 'E' && tmp [ tmpIndex + 2 ] == 'T' && tmp [ tmpIndex + 3 ] == ':' ) { tag . type . add ( TAGS . T_SET . value ) ; tmpIndex += 4 ; } if ( tmp [ tmpIndex ] == 'V' && tmp [ tmpIndex + 1 ] == 'S' && tmp [ tmpIndex + 2 ] == 'T' && tmp [ tmpIndex + 3 ] == 'R' && tmp [ tmpIndex + 4 ] == ':' ) { tag . type . add ( TAGS . T_VARSTRING . value ) ; tag . type . add ( TAGS . T_VSTR . value ) ; tmpIndex += 5 ; StringBuilder sb = new StringBuilder ( ) ; for ( int i = tmpIndex ; i < tmp . length ; i ++ ) { sb . append ( tmp [ i ] ) ; } tag . tag = sb . toString ( ) ; } if ( tmpIndex < tmp . length && ( tmp [ tmpIndex ] == '"' || tmp [ tmpIndex ] == '<' ) ) { int endIndex = tmp . length - 1 ; while ( tmp [ endIndex ] == 'i' || tmp [ endIndex ] == 'r' || tmp [ endIndex ] == 'v' ) { if ( ! tag . type . contains ( TAGS . T_VARSTRING . value ) && tmp [ endIndex ] == 'v' ) { tag . type . add ( TAGS . T_VARSTRING . value ) ; endIndex -- ; continue ; } if ( ! tag . type . contains ( TAGS . T_REGEXP . value ) && tmp [ endIndex ] == 'r' ) { tag . type . add ( TAGS . T_REGEXP . value ) ; endIndex -- ; continue ; } if ( ! tag . type . contains ( TAGS . T_CASE_INSENSITIVE . value ) && tmp [ endIndex ] == 'i' ) { tag . type . add ( TAGS . T_CASE_INSENSITIVE . value ) ; endIndex -- ; continue ; } break ; } if ( tmp [ tmpIndex ] == '"' && tmp [ endIndex ] == '"' ) { if ( tmp [ tmpIndex + 1 ] == '<' && tmp [ endIndex - 1 ] == '>' ) { tag . type . add ( TAGS . T_WORDFORM . value ) ; } else { tag . type . add ( TAGS . T_BASEFORM . value ) ; } } if ( ( tmp [ tmpIndex ] == '"' && tmp [ endIndex ] == '"' ) || ( tmp [ tmpIndex ] == '<' && tmp [ endIndex ] == '>' ) ) { tag . type . add ( TAGS . T_TEXTUAL . value ) ; } else { if ( tag . type . contains ( TAGS . T_VARSTRING . value ) ) { tag . type . remove ( TAGS . T_VARSTRING . value ) ; } if ( tag . type . contains ( TAGS . T_REGEXP . value ) ) { tag . type . remove ( TAGS . T_REGEXP . value ) ; } if ( tag . type . contains ( TAGS . T_CASE_INSENSITIVE . value ) ) { tag . type . remove ( TAGS . T_CASE_INSENSITIVE . value ) ; } if ( tag . type . contains ( TAGS . T_WORDFORM . value ) ) { tag . type . remove ( TAGS . T_WORDFORM . value ) ; } if ( tag . type . contains ( TAGS . T_BASEFORM . value ) ) { tag . type . remove ( TAGS . T_BASEFORM . value ) ; } endIndex = tmp . length - 1 ; } } for ( int i = 0 ; i < tmp . length ; ++ i ) { if ( tmp [ i ] == '\\' ) { ++ i ; } if ( i >= tmp . length ) { break ; } tag . tag = tag . tag . concat ( Character . toString ( tmp [ i ] ) ) ; } if ( tag . tag . isEmpty ( ) ) { System . err . println ( "Error: parsing tag on line " + grammar . lines + " resulted in an empty tag." ) ; System . exit ( 1 ) ; } tag . comparison_hash = CgStrings . hash_sdbm_uchar ( tag . tag , 0 , 0 ) ; if ( ! tag . tag . isEmpty ( ) && tag . tag . charAt ( 0 ) == '<' && tag . tag . charAt ( tag . tag . length ( ) - 1 ) == '>' ) { tag = parseNumeric ( tag ) ; } if ( tag . tag . equals ( CgTextualParser . stringbits [ STRINGS . S_MULTIPLY . value ] ) ) { tag . type . add ( TAGS . T_ANY . value ) ; } else if ( tag . tag . equals ( CgTextualParser . stringbits [ STRINGS . S_UU_LEFT . value ] ) ) { tag . type . add ( TAGS . T_PAR_LEFT . value ) ; } else if ( tag . tag . equals ( CgTextualParser . stringbits [ STRINGS . S_UU_RIGHT . value ] ) ) { tag . type . add ( TAGS . T_PAR_RIGHT . value ) ; } else if ( tag . tag . equals ( CgTextualParser . stringbits [ STRINGS . S_UU_TARGET . value ] ) ) { tag . type . add ( TAGS . T_TARGET . value ) ; } else if ( tag . tag . equals ( CgTextualParser . stringbits [ STRINGS . S_UU_MARK . value ] ) ) { tag . type . add ( TAGS . T_MARK . value ) ; } else if ( tag . tag . equals ( CgTextualParser . stringbits [ STRINGS . S_UU_ATTACHTO . value ] ) ) { tag . type . add ( TAGS . T_ATTACHTO . value ) ; } if ( tag . type . contains ( TAGS . T_REGEXP . value ) ) { if ( tag . tag . equals ( CgTextualParser . stringbits [ STRINGS . S_RXTEXT_ANY . value ] ) || tag . tag . equals ( CgTextualParser . stringbits [ STRINGS . S_RXBASE_ANY . value ] ) || tag . tag . equals ( CgTextualParser . stringbits [ STRINGS . S_RXWORD_ANY . value ] ) ) { tag . type . add ( TAGS . T_REGEXP_ANY . value ) ; if ( tag . type . contains ( TAGS . T_REGEXP . value ) ) { tag . type . remove ( TAGS . T_REGEXP . value ) ; } } else { String rt = "^" ; rt = rt . concat ( tag . tag ) ; rt = rt . concat ( "$" ) ; if ( tag . type . contains ( TAGS . T_CASE_INSENSITIVE . value ) ) { regexp = Pattern . compile ( rt , Pattern . CASE_INSENSITIVE ) ; } else { regexp = Pattern . compile ( rt ) ; } } } } if ( tag . type . contains ( TAGS . T_SPECIAL . value ) ) { tag . type . remove ( TAGS . T_SPECIAL . value ) ; } if ( tag . type . contains ( TAGS . T_ANY . value ) || tag . type . contains ( TAGS . T_TARGET . value ) || tag . type . contains ( TAGS . T_MARK . value ) || tag . type . contains ( TAGS . T_ATTACHTO . value ) || tag . type . contains ( TAGS . T_PAR_LEFT . value ) || tag . type . contains ( TAGS . T_PAR_RIGHT . value ) || tag . type . contains ( TAGS . T_NUMERICAL . value ) || tag . type . contains ( TAGS . T_VARIABLE . value ) || tag . type . contains ( TAGS . T_META . value ) || tag . type . contains ( TAGS . T_NEGATIVE . value ) || tag . type . contains ( TAGS . T_FAILFAST . value ) || tag . type . contains ( TAGS . T_CASE_INSENSITIVE . value ) || tag . type . contains ( TAGS . T_REGEXP . value ) || tag . type . contains ( TAGS . T_REGEXP_ANY . value ) || tag . type . contains ( TAGS . T_VARSTRING . value ) || tag . type . contains ( TAGS . T_SET . value ) ) { tag . type . add ( TAGS . T_SPECIAL . value ) ; } if ( tag . type . contains ( TAGS . T_VARSTRING . value ) && ( tag . type . contains ( TAGS . T_REGEXP . value ) || tag . type . contains ( TAGS . T_REGEXP_ANY . value ) || tag . type . contains ( TAGS . T_VARIABLE . value ) || tag . type . contains ( TAGS . T_META . value ) ) ) { System . err . println ( "Error: cannot mix varstring with any other special features on line " + grammar . lines ) ; System . exit ( 1 ) ; } return tag ; } public CgTag parseNumeric ( CgTag tag ) { return tag ; } public int rehash ( ) { this . hash = 0 ; this . plain_hash = 0 ; if ( this . type . contains ( TAGS . T_NEGATIVE . value ) ) { this . hash = CgStrings . hash_sdbm_char ( "!" , this . hash , 0 ) ; } if ( this . type . contains ( TAGS . T_FAILFAST . value ) ) { this . hash = CgStrings . hash_sdbm_char ( "^" , this . hash , 0 ) ; } if ( this . type . contains ( TAGS . T_META . value ) ) { this . hash = CgStrings . hash_sdbm_char ( "META:" , this . hash , 0 ) ; } if ( this . type . contains ( TAGS . T_VARIABLE . value ) ) { this . hash = CgStrings . hash_sdbm_char ( "VAR:" , this . hash , 0 ) ; } if ( this . type . contains ( TAGS . T_SET . value ) ) { this . hash = CgStrings . hash_sdbm_char ( "SET:" , this . hash , 0 ) ; } if ( this . type . contains ( TAGS . T_NEGATIVE . value ) ) { this . hash = CgStrings . hash_sdbm_char ( "!" , this . hash , 0 ) ; } this . plain_hash = CgStrings . hash_sdbm_uchar ( this . tag , 0 , 0 ) ; if ( this . hash != 0 ) { this . hash = CgStrings . hash_sdbm_uint32_t ( this . plain_hash , this . hash ) ; } else { this . hash = this . plain_hash ; } if ( this . type . contains ( TAGS . T_CASE_INSENSITIVE . value ) ) { this . hash = CgStrings . hash_sdbm_char ( "i" , this . hash , 0 ) ; } if ( this . type . contains ( TAGS . T_REGEXP . value ) ) { this . hash = CgStrings . hash_sdbm_char ( "r" , this . hash , 0 ) ; } if ( this . type . contains ( TAGS . T_VARSTRING . value ) ) { CgStrings . hash_sdbm_char ( "v" , this . hash , 0 ) ; } if ( this . seed != 0 ) { hash += this . seed ; } if ( this . type . contains ( TAGS . T_SPECIAL . value ) ) { this . type . remove ( TAGS . T_SPECIAL . value ) ; } if ( this . type . contains ( TAGS . T_ANY . value ) || this . type . contains ( TAGS . T_TARGET . value ) || this . type . contains ( TAGS . T_MARK . value ) || this . type . contains ( TAGS . T_ATTACHTO . value ) || this . type . contains ( TAGS . T_PAR_LEFT . value ) || this . type . contains ( TAGS . T_PAR_RIGHT . value ) || this . type . contains ( TAGS . T_NUMERICAL . value ) || this . type . contains ( TAGS . T_VARIABLE . value ) || this . type . contains ( TAGS . T_META . value ) || this . type . contains ( TAGS . T_NEGATIVE . value ) || this . type . contains ( TAGS . T_FAILFAST . value ) || this . type . contains ( TAGS . T_CASE_INSENSITIVE . value ) || this . type . contains ( TAGS . T_REGEXP . value ) || this . type . contains ( TAGS . T_REGEXP_ANY . value ) || this . type . contains ( TAGS . T_VARSTRING . value ) || this . type . contains ( TAGS . T_SET . value ) ) { this . type . add ( TAGS . T_SPECIAL . value ) ; } return this . hash ; } public enum TAGS { T_ANY ( 1 < < 0 ) , T_NUMERICAL ( 1 < < 1 ) , T_MAPPING ( 1 < < 2 ) , T_VARIABLE ( 1 < < 3 ) , T_META ( 1 < < 4 ) , T_WORDFORM ( 1 < < 5 ) , T_BASEFORM ( 1 < < 6 ) , T_TEXTUAL ( 1 < < 7 ) , T_DEPENDENCY ( 1 < < 8 ) , T_NEGATIVE ( 1 < < 9 ) , T_FAILFAST ( 1 < < 10 ) , T_CASE_INSENSITIVE ( 1 < < 11 ) , T_REGEXP ( 1 < < 12 ) , T_PAR_LEFT ( 1 < < 13 ) , T_PAR_RIGHT ( 1 < < 14 ) , T_REGEXP_ANY ( 1 < < 15 ) , T_VARSTRING ( 1 < < 16 ) , T_TARGET ( 1 < < 17 ) , T_MARK ( 1 < < 18 ) , T_ATTACHTO ( 1 < < 19 ) , T_SPECIAL ( 1 < < 20 ) , T_USED ( 1 < < 21 ) , T_GRAMMAR ( 1 < < 22 ) , T_SET ( 1 < < 23 ) , T_VSTR ( 1 < < 24 ) ; public int value ; TAGS ( int v ) { this . value = v ; } } }
package org . languagetool . dev . conversion . cg ; import java . util . ArrayList ; import java . util . HashSet ; import java . util . Random ; import org . languagetool . dev . conversion . CgRuleConverter ; import org . languagetool . dev . conversion . cg . CgTag . TAGS ; public class CgSet { public int line ; public int hash ; public int chash ; public String name ; public HashSet < Integer > type ; public int number ; public HashSet < CgCompositeTag > tags ; public HashSet < CgTag > single_tags ; public HashSet < Integer > single_tags_hash ; public ArrayList < Integer > sets ; public ArrayList < Integer > set_ops ; public ArrayList < CgCompositeTag . AnyTag > tags_list ; public HashSet < CgTag > ff_tags ; public CgSet ( ) { this . number = 0 ; this . line = 0 ; this . hash = 0 ; this . name = null ; this . setName ( 0 ) ; this . type = new HashSet < > ( ) ; this . chash = 0 ; this . tags = new HashSet < > ( ) ; this . single_tags = new HashSet < > ( ) ; this . single_tags_hash = new HashSet < > ( ) ; this . sets = new ArrayList < > ( ) ; this . set_ops = new ArrayList < > ( ) ; this . tags_list = new ArrayList < > ( ) ; this . ff_tags = new HashSet < > ( ) ; } public CgSet ( CgSet from ) { if ( from == null ) { this . number = 0 ; this . line = 0 ; this . hash = 0 ; this . name = null ; this . setName ( 0 ) ; this . type = new HashSet < > ( ) ; this . chash = 0 ; this . tags = new HashSet < > ( ) ; this . single_tags = new HashSet < > ( ) ; this . single_tags_hash = new HashSet < > ( ) ; this . sets = new ArrayList < > ( ) ; this . set_ops = new ArrayList < > ( ) ; this . tags_list = new ArrayList < > ( ) ; this . ff_tags = new HashSet < > ( ) ; } else { this . tags_list = from . tags_list ; this . tags = new HashSet < > ( from . tags ) ; this . single_tags = new HashSet < > ( from . single_tags ) ; this . single_tags_hash = from . single_tags_hash ; this . ff_tags = from . ff_tags ; this . set_ops = from . set_ops ; this . sets = from . sets ; this . hash = this . hashCode ( ) ; this . number = from . number ; this . name = from . name ; this . type = from . type ; this . line = from . line ; this . hashContents ( ) ; } } public CgCompositeTag [ ] getCompositeTags ( ) { ArrayList < CgCompositeTag > tags = new ArrayList < > ( ) ; if ( ! this . tags . isEmpty ( ) ) { for ( CgCompositeTag ctag : this . tags ) { if ( ! CgRuleConverter . isCompositePostag ( ctag ) ) { tags . add ( ctag ) ; } } } return tags . toArray ( new CgCompositeTag [ tags . size ( ) ] ) ; } public CgCompositeTag [ ] getCompositePostags ( ) { ArrayList < CgCompositeTag > postags = new ArrayList < > ( ) ; if ( ! this . tags . isEmpty ( ) ) { for ( CgCompositeTag ctag : this . tags ) { if ( CgRuleConverter . isCompositePostag ( ctag ) ) { postags . add ( ctag ) ; } } } return postags . toArray ( new CgCompositeTag [ postags . size ( ) ] ) ; } public String [ ] getSingleTagPostagsString ( ) { ArrayList < String > postags = new ArrayList < > ( ) ; if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag tag : this . single_tags ) { if ( CgRuleConverter . isPostag ( tag . tag ) ) { postags . add ( tag . tag ) ; } } } return postags . toArray ( new String [ postags . size ( ) ] ) ; } public CgTag [ ] getSingleTagPostags ( ) { ArrayList < CgTag > postags = new ArrayList < > ( ) ; if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag tag : this . single_tags ) { if ( CgRuleConverter . isPostag ( tag . tag ) ) postags . add ( tag ) ; } } return postags . toArray ( new CgTag [ postags . size ( ) ] ) ; } public String [ ] getSingleTagBaseformsString ( ) { ArrayList < String > forms = new ArrayList < > ( ) ; if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag tag : this . single_tags ) { String tagtag = tag . tag ; if ( CgRuleConverter . isBaseForm ( tagtag ) ) forms . add ( tagtag ) ; } } return forms . toArray ( new String [ forms . size ( ) ] ) ; } public CgTag [ ] getSingleTagBaseforms ( ) { ArrayList < CgTag > forms = new ArrayList < > ( ) ; if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag tag : this . single_tags ) { if ( CgRuleConverter . isBaseForm ( tag . tag ) ) forms . add ( tag ) ; } } return forms . toArray ( new CgTag [ forms . size ( ) ] ) ; } public String [ ] getSingleTagSurfaceformsString ( ) { ArrayList < String > forms = new ArrayList < > ( ) ; if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag tag : this . single_tags ) { String tagtag = tag . tag ; if ( CgRuleConverter . isSurfaceForm ( tagtag ) ) forms . add ( tagtag ) ; } } return forms . toArray ( new String [ forms . size ( ) ] ) ; } public CgTag [ ] getSingleTagSurfaceforms ( ) { ArrayList < CgTag > forms = new ArrayList < > ( ) ; if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag tag : this . single_tags ) { String tagtag = tag . tag ; if ( CgRuleConverter . isSurfaceForm ( tagtag ) ) forms . add ( tag ) ; } } return forms . toArray ( new CgTag [ forms . size ( ) ] ) ; } public String [ ] getPostagsString ( ) { ArrayList < String > tags = new ArrayList < > ( ) ; if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag tag : this . single_tags ) { if ( CgRuleConverter . isPostag ( tag . tag ) ) { tags . add ( CgRuleConverter . tagToString ( tag ) ) ; } } } if ( ! this . tags . isEmpty ( ) ) { for ( CgCompositeTag ctag : this . tags ) { if ( CgRuleConverter . isCompositePostag ( ctag ) ) { tags . add ( CgRuleConverter . compositePostagToString ( ctag ) ) ; } } } return tags . toArray ( new String [ tags . size ( ) ] ) ; } public ArrayList < String > getSurfaceFormsString ( CgGrammar grammar ) { ArrayList < String > forms = new ArrayList < > ( ) ; if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag tag : this . single_tags ) { String tagtag = tag . tag ; if ( CgRuleConverter . isSurfaceForm ( tagtag ) ) { forms . add ( tagtag ) ; } } } if ( ! this . tags . isEmpty ( ) ) { for ( CgCompositeTag ctag : this . tags ) { for ( CgTag tag : ctag . tags ) { String tagtag = tag . tag ; if ( CgRuleConverter . isSurfaceForm ( tagtag ) ) { forms . add ( tagtag ) ; } } } } if ( ! this . sets . isEmpty ( ) ) { for ( int setint : this . sets ) { ArrayList < String > setForms = grammar . getSet ( setint ) . getSurfaceFormsString ( grammar ) ; for ( String setForm : setForms ) { forms . add ( setForm ) ; } } } return forms ; } public ArrayList < String > getBaseformsString ( CgGrammar grammar ) { ArrayList < String > forms = new ArrayList < > ( ) ; if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag tag : this . single_tags ) { String tagtag = tag . tag ; if ( CgRuleConverter . isBaseForm ( tagtag ) ) { forms . add ( tagtag ) ; } } } if ( ! this . tags . isEmpty ( ) ) { for ( CgCompositeTag ctag : this . tags ) { for ( CgTag tag : ctag . tags ) { String tagtag = tag . tag ; if ( CgRuleConverter . isBaseForm ( tagtag ) ) { forms . add ( tagtag ) ; } } } } if ( ! this . sets . isEmpty ( ) ) { for ( int setint : this . sets ) { ArrayList < String > setForms = grammar . getSet ( setint ) . getBaseformsString ( grammar ) ; for ( String setForm : setForms ) { forms . add ( setForm ) ; } } } return forms ; } public ArrayList < String > getPostagsString ( CgGrammar grammar ) { ArrayList < String > postags = new ArrayList < > ( ) ; if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag tag : this . single_tags ) { if ( CgRuleConverter . isPostag ( tag . tag ) ) { postags . add ( tag . tag ) ; } } } if ( ! this . tags . isEmpty ( ) ) { for ( CgCompositeTag ctag : this . tags ) { if ( CgRuleConverter . isCompositePostag ( ctag ) ) { postags . add ( ctag . toString ( ) ) ; } } } return postags ; } public String toString ( CgGrammar grammar ) { StringBuilder sb = new StringBuilder ( ) ; if ( ! this . tags . isEmpty ( ) ) { for ( CgCompositeTag ctag : this . tags ) { sb . append ( "(" ) ; for ( CgTag stag : ctag . tags ) { sb . append ( stag ) . append ( " " ) ; } sb . append ( ")" ) ; } } else if ( ! this . single_tags . isEmpty ( ) ) { for ( CgTag stag : this . single_tags ) { sb . append ( "(" ) ; sb . append ( stag . tag ) ; sb . append ( ")" ) ; } } else if ( ! this . sets . isEmpty ( ) ) { for ( int s2 : this . sets ) { sb . append ( grammar . getSet ( s2 ) . toString ( grammar ) ) ; } } return sb . toString ( ) ; } public void setName ( String name ) { this . name = name ; this . hash = name . hashCode ( ) ; } public void setName ( int to ) { if ( to == 0 ) { Random gen = new Random ( ) ; to = gen . nextInt ( ) ; } this . name = "_G_" + line + "_" + to ; this . hash = this . name . hashCode ( ) ; } public boolean isEmpty ( ) { return ( this . single_tags . isEmpty ( ) && this . tags . isEmpty ( ) && this . sets . isEmpty ( ) ) ; } public void addTag ( CgTag t ) { this . single_tags . add ( t ) ; this . hashContents ( ) ; } public void addCompositeTag ( CgCompositeTag t ) { this . tags . add ( t ) ; } public HashSet < CgCompositeTag . AnyTag > getTagList ( final CgGrammar grammar ) { HashSet < CgCompositeTag . AnyTag > theTags = new HashSet < > ( ) ; if ( sets . isEmpty ( ) ) { for ( int i = 0 ; i < sets . size ( ) ; i ++ ) { HashSet < CgCompositeTag . AnyTag > recursiveTags = grammar . getSet ( i ) . getTagList ( grammar ) ; for ( CgCompositeTag . AnyTag t : recursiveTags ) { theTags . add ( t ) ; } } } else { for ( CgCompositeTag . AnyTag t : this . tags_list ) { theTags . add ( t ) ; } } return theTags ; } public void reindex ( CgGrammar grammar ) { if ( this . type . contains ( ST . ST_SPECIAL . value ) ) { this . type . remove ( ST . ST_SPECIAL . value ) ; } if ( this . type . contains ( ST . ST_CHILD_UNIFY . value ) ) { this . type . remove ( ST . ST_CHILD_UNIFY . value ) ; } if ( this . sets . isEmpty ( ) ) { for ( CgTag tomp_iter : this . single_tags ) { if ( tomp_iter . type . contains ( TAGS . T_SPECIAL . value ) ) { this . type . add ( ST . ST_SPECIAL . value ) ; } if ( tomp_iter . type . contains ( TAGS . T_MAPPING . value ) ) { this . type . add ( ST . ST_MAPPING . value ) ; } } for ( CgCompositeTag comp_iter : this . tags ) { for ( CgTag tag_iter : comp_iter . tags ) { if ( tag_iter . type . contains ( TAGS . T_SPECIAL . value ) ) { this . type . add ( ST . ST_SPECIAL . value ) ; } if ( tag_iter . type . contains ( TAGS . T_MAPPING . value ) ) { this . type . add ( ST . ST_MAPPING . value ) ; } } } } } public void hashContents ( ) { int h = this . name . hashCode ( ) ; if ( ! this . tags . isEmpty ( ) ) { for ( CgCompositeTag t : this . tags ) { h = h < < t . hashCode ( ) ; } } this . chash = h ; } public void rehash ( ) { this . hashContents ( ) ; this . hash = this . hash < < this . chash ; } public enum ST { ST_ANY ( 1 < < 0 ) , ST_SPECIAL ( 1 < < 1 ) , ST_TAG_UNIFY ( 1 < < 2 ) , ST_SET_UNIFY ( 1 < < 3 ) , ST_CHILD_UNIFY ( 1 < < 4 ) , ST_MAPPING ( 1 < < 5 ) , ST_USED ( 1 < < 6 ) , ST_STATIC ( 1 < < 7 ) ; public int value ; ST ( int v ) { this . value = v ; } } }
package org . languagetool . dev . conversion . cg ; import java . util . ArrayList ; import java . util . HashSet ; import org . languagetool . dev . conversion . CgRuleConverter ; public class CgCompositeTag { public boolean is_used ; public boolean is_special ; public int hash ; public int number ; public HashSet < CgTag > tags_set = new HashSet < > ( ) ; public ArrayList < CgTag > tags = new ArrayList < > ( ) ; public String toString ( ) { StringBuilder sb = new StringBuilder ( ) ; sb . append ( "(" ) ; for ( int i = 0 ; i < tags . size ( ) ; i ++ ) { if ( i == tags . size ( ) - 1 ) { sb . append ( tags . get ( i ) . tag ) . append ( ")" ) ; } else { sb . append ( tags . get ( i ) . tag ) . append ( " " ) ; } } return sb . toString ( ) ; } public void addTag ( CgTag t ) { this . tags_set . add ( t ) ; this . tags . add ( t ) ; } public String getPostags ( ) { return CgRuleConverter . compositePostagToString ( this ) ; } public String getBaseform ( ) { String baseform = "" ; for ( CgTag tag : this . tags ) { if ( CgRuleConverter . isBaseForm ( tag . tag ) ) { baseform = tag . tag ; } } return baseform ; } public String getSurfaceform ( ) { String surfaceform = "" ; for ( CgTag tag : this . tags ) { if ( CgRuleConverter . isSurfaceForm ( tag . tag ) ) { surfaceform = tag . tag ; } } return surfaceform ; } public enum ANYTAG_TYPE { ANYTAG_TAG ( 0 ) , ANYTAG_COMPOSITE ( 1 ) , NUM_ANYTAG ( 2 ) ; public final int value ; ANYTAG_TYPE ( int v ) { value = v ; } } public int rehash ( ) { int retval = 0 ; for ( CgTag t : this . tags ) { retval = CgStrings . hash_sdbm_uint32_t ( t . hash , retval ) ; } this . hash = retval ; return retval ; } public class AnyTag { int which ; CgTag tag ; CgCompositeTag ct ; public CgTag getTag ( ) { return tag ; } public CgCompositeTag getCompositeTag ( ) { return ct ; } } public boolean isEmpty ( ) { return ( this . tags . size ( ) == 0 ) ; } }
package org . languagetool . dev . conversion . cg ; public class CgAnchor { public int line ; public String name ; public int hash ; public void setName ( String n ) { this . name = n ; this . hash = n . hashCode ( ) ; } }
package org . languagetool . dev . conversion . cg ; public class CgStrings { public enum KEYWORDS { K_IGNORE ( 0 ) , K_SETS ( 1 ) , K_LIST ( 2 ) , K_SET ( 3 ) , K_DELIMITERS ( 4 ) , K_SOFT_DELIMITERS ( 5 ) , K_PREFERRED_TARGETS ( 6 ) , K_MAPPING_PREFIX ( 7 ) , K_MAPPINGS ( 8 ) , K_CONSTRAINTS ( 9 ) , K_CORRECTIONS ( 10 ) , K_SECTION ( 11 ) , K_BEFORE_SECTIONS ( 12 ) , K_AFTER_SECTIONS ( 13 ) , K_NULL_SECTION ( 14 ) , K_ADD ( 15 ) , K_MAP ( 16 ) , K_REPLACE ( 17 ) , K_SELECT ( 18 ) , K_REMOVE ( 19 ) , K_IFF ( 20 ) , K_APPEND ( 21 ) , K_SUBSTITUTE ( 22 ) , K_START ( 23 ) , K_END ( 24 ) , K_ANCHOR ( 25 ) , K_EXECUTE ( 26 ) , K_JUMP ( 27 ) , K_REMVARIABLE ( 28 ) , K_SETVARIABLE ( 29 ) , K_DELIMIT ( 30 ) , K_MATCH ( 31 ) , K_SETPARENT ( 32 ) , K_SETCHILD ( 33 ) , K_ADDRELATION ( 34 ) , K_SETRELATION ( 35 ) , K_REMRELATION ( 36 ) , K_ADDRELATIONS ( 37 ) , K_SETRELATIONS ( 38 ) , K_REMRELATIONS ( 39 ) , K_TEMPLATE ( 40 ) , K_MOVE ( 41 ) , K_MOVE_AFTER ( 42 ) , K_MOVE_BEFORE ( 43 ) , K_SWITCH ( 44 ) , K_REMCOHORT ( 45 ) , K_STATIC_SETS ( 46 ) , K_UNMAP ( 47 ) , K_COPY ( 48 ) , K_ADDCOHORT ( 49 ) , K_ADDCOHORT_AFTER ( 50 ) , K_ADDCOHORT_BEFORE ( 51 ) , K_EXTERNAL ( 52 ) , K_EXTERNAL_ONCE ( 53 ) , K_EXTERNAL_ALWAYS ( 54 ) , KEYWORD_COUNT ( 55 ) ; public final int value ; KEYWORDS ( int v ) { this . value = v ; } } public enum STRINGS { S_IGNORE ( 0 ) , S_PIPE ( 1 ) , S_TO ( 2 ) , S_OR ( 3 ) , S_PLUS ( 4 ) , S_MINUS ( 5 ) , S_MULTIPLY ( 6 ) , S_ASTERIKTWO ( 7 ) , S_FAILFAST ( 8 ) , S_BACKSLASH ( 9 ) , S_HASH ( 10 ) , S_NOT ( 11 ) , S_TEXTNOT ( 12 ) , S_TEXTNEGATE ( 13 ) , S_ALL ( 14 ) , S_NONE ( 15 ) , S_LINK ( 16 ) , S_BARRIER ( 17 ) , S_CBARRIER ( 18 ) , S_CMD_FLUSH ( 19 ) , S_CMD_EXIT ( 20 ) , S_CMD_IGNORE ( 21 ) , S_CMD_RESUME ( 22 ) , S_TARGET ( 23 ) , S_AND ( 24 ) , S_IF ( 25 ) , S_DELIMITSET ( 26 ) , S_SOFTDELIMITSET ( 27 ) , S_BEGINTAG ( 28 ) , S_ENDTAG ( 29 ) , S_LINKZ ( 30 ) , S_SPACE ( 31 ) , S_UU_LEFT ( 32 ) , S_UU_RIGHT ( 33 ) , S_UU_PAREN ( 34 ) , S_UU_TARGET ( 35 ) , S_UU_MARK ( 36 ) , S_UU_ATTACHTO ( 37 ) , S_RXTEXT_ANY ( 38 ) , S_RXBASE_ANY ( 39 ) , S_RXWORD_ANY ( 40 ) , S_AFTER ( 41 ) , S_BEFORE ( 42 ) , S_WITH ( 43 ) , S_QUESTION ( 44 ) , S_VS1 ( 45 ) , S_VS2 ( 46 ) , S_VS3 ( 47 ) , S_VS4 ( 48 ) , S_VS5 ( 49 ) , S_VS6 ( 50 ) , S_VS7 ( 51 ) , S_VS8 ( 52 ) , S_VS9 ( 53 ) , S_VSu ( 54 ) , S_VSU ( 55 ) , S_VSl ( 56 ) , S_VSL ( 57 ) , S_GPREFIX ( 58 ) , S_POSITIVE ( 59 ) , S_NEGATIVE ( 60 ) , S_ONCE ( 61 ) , S_ALWAYS ( 62 ) , S_SET_ISECT_U ( 63 ) , S_SET_SYMDIFF_U ( 64 ) , S_FROM ( 65 ) , STRINGS_COUNT ( 66 ) ; public final int value ; STRINGS ( int v ) { this . value = v ; } } public enum SFLAGS { FL_NEAREST ( 0 ) , FL_ALLOWLOOP ( 1 ) , FL_DELAYED ( 2 ) , FL_IMMEDIATE ( 3 ) , FL_LOOKDELETED ( 4 ) , FL_LOOKDELAYED ( 5 ) , FL_UNSAFE ( 6 ) , FL_SAFE ( 7 ) , FL_REMEMBERX ( 8 ) , FL_RESETX ( 9 ) , FL_KEEPORDER ( 10 ) , FL_VARYORDER ( 11 ) , FL_ENCL_INNER ( 12 ) , FL_ENCL_OUTER ( 13 ) , FL_ENCL_FINAL ( 14 ) , FL_ENCL_ANY ( 15 ) , FL_ALLOWCROSS ( 16 ) , FL_WITHCHILD ( 17 ) , FL_NOCHILD ( 18 ) , FL_ITERATE ( 19 ) , FL_NOITERATE ( 20 ) , FL_UNMAPLAST ( 21 ) , FL_REVERSE ( 22 ) , FLAGS_COUNT ( 23 ) ; public int value ; SFLAGS ( int v ) { this . value = v ; } } public static final int CG3_HASH_SEED = 705577479 ; public static int hash_sdbm_char ( String str , int hash , int length ) { if ( hash == 0 ) { hash = CG3_HASH_SEED ; } if ( length == 0 ) { length = str . length ( ) ; } return ( int ) RSHash ( str ) ; } public static int hash_sdbm_uchar ( String str , int hash , int length ) { if ( hash == 0 ) { hash = CG3_HASH_SEED ; } if ( length == 0 ) { length = str . length ( ) ; } return ( int ) JSHash ( str ) ; } public static int hash_sdbm_uint32_t ( int c , int hash ) { if ( hash == 0 ) { hash = CG3_HASH_SEED ; } hash = c + ( hash < < 6 ) + ( hash < < 16 ) - hash ; return hash ; } public static long RSHash ( String str ) { int b = 378551 ; int a = 63689 ; long hash = 0 ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { hash = hash * a + str . charAt ( i ) ; a = a * b ; } return hash ; } public static long JSHash ( String str ) { long hash = 1315423911 ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { hash ^= ( ( hash < < 5 ) + str . charAt ( i ) + ( hash > > 2 ) ) ; } return hash ; } public long PJWHash ( String str ) { long BitsInUnsignedInt = ( long ) ( 4 * 8 ) ; long ThreeQuarters = ( long ) ( ( BitsInUnsignedInt * 3 ) / 4 ) ; long OneEighth = ( long ) ( BitsInUnsignedInt / 8 ) ; long HighBits = ( long ) ( 0xFFFFFFFF ) < < ( BitsInUnsignedInt - OneEighth ) ; long hash = 0 ; long test = 0 ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { hash = ( hash < < OneEighth ) + str . charAt ( i ) ; if ( ( test = hash & HighBits ) != 0 ) { hash = ( ( hash ^ ( test > > ThreeQuarters ) ) & ( ~ HighBits ) ) ; } } return hash ; } public long ELFHash ( String str ) { long hash = 0 ; long x = 0 ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { hash = ( hash < < 4 ) + str . charAt ( i ) ; if ( ( x = hash & 0xF0000000L ) != 0 ) { hash ^= ( x > > 24 ) ; } hash &= ~ x ; } return hash ; } public long BKDRHash ( String str ) { long seed = 131 ; long hash = 0 ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { hash = ( hash * seed ) + str . charAt ( i ) ; } return hash ; } public long SDBMHash ( String str ) { long hash = 0 ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { hash = str . charAt ( i ) + ( hash < < 6 ) + ( hash < < 16 ) - hash ; } return hash ; } public long DJBHash ( String str ) { long hash = 5381 ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { hash = ( ( hash < < 5 ) + hash ) + str . charAt ( i ) ; } return hash ; } public long DEKHash ( String str ) { long hash = str . length ( ) ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { hash = ( ( hash < < 5 ) ^ ( hash > > 27 ) ) ^ str . charAt ( i ) ; } return hash ; } public long BPHash ( String str ) { long hash = 0 ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { hash = hash < < 7 ^ str . charAt ( i ) ; } return hash ; } public long FNVHash ( String str ) { long fnv_prime = 0x811C9DC5 ; long hash = 0 ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { hash *= fnv_prime ; hash ^= str . charAt ( i ) ; } return hash ; } public long APHash ( String str ) { long hash = 0xAAAAAAAA ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { if ( ( i & 1 ) == 0 ) { hash ^= ( ( hash < < 7 ) ^ str . charAt ( i ) * ( hash > > 3 ) ) ; } else { hash ^= ( ~ ( ( hash < < 11 ) + str . charAt ( i ) ^ ( hash > > 5 ) ) ) ; } } return hash ; } }
package org . languagetool . dev . conversion . cg ; import java . io . BufferedReader ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . io . InputStreamReader ; import java . util . ArrayList ; import java . util . HashSet ; import org . languagetool . dev . conversion . cg . CgContextualTest . POS ; import org . languagetool . dev . conversion . cg . CgRule . RFLAGS ; import org . languagetool . dev . conversion . cg . CgSet . ST ; import org . languagetool . dev . conversion . cg . CgStrings . KEYWORDS ; import org . languagetool . dev . conversion . cg . CgStrings . SFLAGS ; import org . languagetool . dev . conversion . cg . CgStrings . STRINGS ; public class CgTextualParser { private int verbosity_level ; private int sets_counter ; private int seen_mapping_prefix ; private boolean option_vislcg_compat ; private boolean in_section , in_before_sections , in_after_sections , in_null_section ; private CgGrammar result ; private char [ ] inArray ; private int index = 0 ; private int length ; private int nindex ; private int sindex ; private int lpindex ; private CgContextualTest currentTest ; private CgContextualTest parentTest ; private boolean inLinkedTest ; private ArrayList < Integer > linkedTests = new ArrayList < > ( ) ; private boolean inParentTest ; public CgTextualParser ( CgGrammar result , File file ) { this . result = result ; option_vislcg_compat = false ; in_after_sections = false ; in_before_sections = false ; in_null_section = false ; in_section = false ; verbosity_level = 0 ; seen_mapping_prefix = 0 ; sets_counter = 100 ; } public void setCompatible ( boolean compat ) { option_vislcg_compat = compat ; } public void setVerbosity ( int level ) { verbosity_level = level ; } public CgGrammar getGrammar ( ) { return result ; } public int parse_grammar_from_file ( final String filename , final String locale , final String codepage ) { if ( result == null ) { System . err . println ( "Grammar hasn't been initialized. Make this happen." ) ; System . exit ( 1 ) ; } BufferedReader reader = null ; StringBuilder sb = new StringBuilder ( ) ; sb . append ( " " ) ; try { reader = new BufferedReader ( new InputStreamReader ( new FileInputStream ( filename ) , "UTF-8" ) ) ; int c = reader . read ( ) ; while ( c != - 1 ) { sb . append ( ( char ) c ) ; c = reader . read ( ) ; } inArray = sb . toString ( ) . toCharArray ( ) ; reader . close ( ) ; } catch ( IOException e ) { System . err . println ( "Error opening grammar file" ) ; System . exit ( 1 ) ; } index = 4 ; length = inArray . length ; result . addAnchor ( KEYWORDS . K_START . name ( ) , result . lines ) ; { CgTag tany = result . allocateTag ( stringbits [ S_ASTERISK . value ] , false ) ; result . tag_any = tany . hash ; } { CgSet set_c = result . allocateSet ( ) ; set_c . line = 0 ; set_c . setName ( stringbits [ STRINGS . S_UU_TARGET . value ] ) ; CgTag t = result . allocateTag ( stringbits [ STRINGS . S_UU_TARGET . value ] , false ) ; result . addTagToSet ( t , set_c ) ; result . addSet ( set_c ) ; } { CgSet set_c = result . allocateSet ( ) ; set_c . line = 0 ; set_c . setName ( stringbits [ STRINGS . S_UU_MARK . value ] ) ; CgTag t = result . allocateTag ( stringbits [ STRINGS . S_UU_MARK . value ] , false ) ; result . addTagToSet ( t , set_c ) ; result . addSet ( set_c ) ; } CgSet s_right = null ; { CgSet set_c = result . allocateSet ( ) ; set_c . line = 0 ; set_c . setName ( stringbits [ STRINGS . S_UU_ATTACHTO . value ] ) ; CgTag t = result . allocateTag ( stringbits [ STRINGS . S_UU_ATTACHTO . value ] , false ) ; result . addTagToSet ( t , set_c ) ; result . addSet ( set_c ) ; s_right = set_c ; } CgSet s_left = null ; { CgSet set_c = result . allocateSet ( ) ; set_c . line = 0 ; set_c . setName ( stringbits [ STRINGS . S_UU_LEFT . value ] ) ; CgTag t = result . allocateTag ( stringbits [ STRINGS . S_UU_LEFT . value ] , false ) ; result . addTagToSet ( t , set_c ) ; result . addSet ( set_c ) ; s_left = set_c ; } { CgSet set_c = result . allocateSet ( ) ; set_c . line = 0 ; set_c . setName ( stringbits [ STRINGS . S_UU_RIGHT . value ] ) ; CgTag t = result . allocateTag ( stringbits [ STRINGS . S_UU_RIGHT . value ] , false ) ; result . addTagToSet ( t , set_c ) ; result . addSet ( set_c ) ; } { CgSet set_c = result . allocateSet ( ) ; set_c . line = 0 ; set_c . setName ( stringbits [ STRINGS . S_UU_PAREN . value ] ) ; set_c . set_ops . add ( STRINGS . S_OR . value ) ; set_c . sets . add ( s_left . hash ) ; set_c . sets . add ( s_right . hash ) ; result . addSet ( set_c ) ; } int error = parseFromChar ( filename ) ; if ( error != 0 ) { return error ; } result . addAnchor ( "end" , result . lines ) ; return 0 ; } private boolean notDone ( ) { return index < length ; } private int parseFromChar ( String fname ) { if ( index >= length ) { System . err . println ( "No input stream or input stream is empty" ) ; System . exit ( 1 ) ; } while ( notDone ( ) ) { if ( verbosity_level > 0 && result . lines % 500 == 0 ) { System . out . println ( "Parsing line " + result . lines ) ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( index >= length ) { break ; } if ( ISCHR ( index , 0 , 'D' , 'd' ) && ISCHR ( index , 9 , 'S' , 's' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'L' , 'l' ) && ISCHR ( index , 3 , 'I' , 'i' ) && ISCHR ( index , 4 , 'M' , 'm' ) && ISCHR ( index , 5 , 'I' , 'i' ) && ISCHR ( index , 6 , 'T' , 't' ) && ISCHR ( index , 7 , 'E' , 'e' ) && ISCHR ( index , 8 , 'R' , 'r' ) && ! ISSTRING ( index , 9 ) ) { if ( result . delimiters != null ) { System . err . println ( "Cannot redefine delimiters on line " + result . lines ) ; System . exit ( 1 ) ; } CgSet delimiters = new CgSet ( ) ; delimiters . line = result . lines ; delimiters . setName ( stringbits [ STRINGS . S_DELIMITSET . value ] ) ; index += 10 ; result . lines += SKIPWS ( '=' , ( char ) 0 ) ; if ( inArray [ index ] != '=' ) { System . err . println ( "Error encountered before the expected = on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; delimiters = parseTagList ( delimiters , false ) ; result . addSet ( delimiters ) ; if ( result . delimiters . tags . isEmpty ( ) && result . delimiters . single_tags . isEmpty ( ) ) { System . err . println ( "Error: Delimiters declared, but line empty" ) ; System . exit ( 1 ) ; } result . lines += SKIPWS ( ';' , ( char ) 0 ) ; if ( inArray [ index ] != ';' ) { System . err . println ( "Error: missing ; to end line" ) ; System . exit ( 1 ) ; } } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 14 , 'S' , 's' ) && ISCHR ( index , 1 , 'O' , 'o' ) && ISCHR ( index , 2 , 'F' , 'f' ) && ISCHR ( index , 3 , 'T' , 't' ) && ISCHR ( index , 4 , '-' , '_' ) && ISCHR ( index , 5 , 'D' , 'd' ) && ISCHR ( index , 6 , 'E' , 'e' ) && ISCHR ( index , 7 , 'L' , 'l' ) && ISCHR ( index , 8 , 'I' , 'i' ) && ISCHR ( index , 9 , 'M' , 'm' ) && ISCHR ( index , 10 , 'I' , 'i' ) && ISCHR ( index , 11 , 'T' , 't' ) && ISCHR ( index , 12 , 'E' , 'e' ) && ISCHR ( index , 13 , 'R' , 'r' ) && ! ISSTRING ( index , 14 ) ) { if ( result . soft_delimiters != null ) { System . err . println ( "Cannot redefine soft delimiters on line " + result . lines ) ; System . exit ( 1 ) ; } CgSet soft_delimiters = new CgSet ( ) ; soft_delimiters . line = result . lines ; soft_delimiters . setName ( stringbits [ STRINGS . S_SOFTDELIMITSET . value ] ) ; index += 15 ; result . lines += SKIPWS ( '=' , ( char ) 0 ) ; if ( inArray [ index ] != '=' ) { System . err . println ( "Error encountered before the expected = on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; soft_delimiters = parseTagList ( soft_delimiters , false ) ; result . addSet ( soft_delimiters ) ; if ( result . soft_delimiters . tags . isEmpty ( ) && result . soft_delimiters . single_tags . isEmpty ( ) ) { System . err . println ( "Error: Soft-delimiters declared, but line is empty" ) ; System . exit ( 1 ) ; } result . lines += SKIPWS ( ';' , ( char ) 0 ) ; if ( inArray [ index ] != ';' ) { System . err . println ( "Missing closing ; on line " + result . lines ) ; System . exit ( 1 ) ; } } else if ( ISCHR ( index , 0 , 'M' , 'm' ) && ISCHR ( index , 13 , 'X' , 'x' ) && ISCHR ( index , 1 , 'A' , 'a' ) && ISCHR ( index , 2 , 'P' , 'p' ) && ISCHR ( index , 3 , 'P' , 'p' ) && ISCHR ( index , 4 , 'I' , 'i' ) && ISCHR ( index , 5 , 'N' , 'n' ) && ISCHR ( index , 6 , 'G' , 'g' ) && ISCHR ( index , 7 , '-' , '_' ) && ISCHR ( index , 8 , 'P' , 'p' ) && ISCHR ( index , 9 , 'R' , 'r' ) && ISCHR ( index , 10 , 'E' , 'e' ) && ISCHR ( index , 11 , 'F' , 'f' ) && ISCHR ( index , 12 , 'I' , 'i' ) && ! ISSTRING ( index , 13 ) ) { if ( seen_mapping_prefix != 0 ) { System . err . println ( "Error: saw mapping prefix on line " + seen_mapping_prefix + ", cannot change." ) ; System . exit ( 1 ) ; } seen_mapping_prefix = result . lines ; index += 14 ; result . lines += SKIPWS ( '=' , ( char ) 0 ) ; if ( inArray [ index ] != '=' ) { System . err . println ( "Error encountered before expected = on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; nindex = index ; result . lines += SKIPTOWS_N ( ';' , false ) ; StringBuilder mapping_prefix = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { mapping_prefix . append ( inArray [ i ] ) ; } result . mapping_prefix = mapping_prefix . toString ( ) ; index = nindex ; if ( result . mapping_prefix == null || result . mapping_prefix == "" ) { System . err . println ( "Error: mapping prefix declared on line " + result . lines + " but no definition given" ) ; System . exit ( 1 ) ; } result . lines += SKIPWS ( ';' , ( char ) 0 ) ; if ( inArray [ index ] != ';' ) { System . err . println ( "Missing closing ; at line " + result . lines ) ; System . exit ( 1 ) ; } } else if ( ISCHR ( index , 0 , 'P' , 'p' ) && ISCHR ( index , 16 , 'S' , 's' ) && ISCHR ( index , 1 , 'R' , 'r' ) && ISCHR ( index , 2 , 'E' , 'e' ) && ISCHR ( index , 3 , 'F' , 'f' ) && ISCHR ( index , 4 , 'E' , 'e' ) && ISCHR ( index , 5 , 'R' , 'r' ) && ISCHR ( index , 6 , 'R' , 'r' ) && ISCHR ( index , 7 , 'E' , 'e' ) && ISCHR ( index , 8 , 'D' , 'd' ) && ISCHR ( index , 9 , '-' , '_' ) && ISCHR ( index , 10 , 'T' , 't' ) && ISCHR ( index , 11 , 'A' , 'a' ) && ISCHR ( index , 12 , 'R' , 'r' ) && ISCHR ( index , 13 , 'G' , 'g' ) && ISCHR ( index , 14 , 'E' , 'e' ) && ISCHR ( index , 15 , 'T' , 't' ) && ! ISSTRING ( index , 16 ) ) { index += 17 ; result . lines += SKIPWS ( '=' , ( char ) 0 ) ; if ( inArray [ index ] != '=' ) { System . err . println ( "Error encountered before expected = on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; while ( notDone ( ) && inArray [ index ] != ';' ) { nindex = index ; if ( inArray [ nindex ] == '"' ) { nindex ++ ; result . lines += SKIPTO_NOSPAN_N ( '"' ) ; if ( inArray [ nindex ] != '"' ) { System . err . println ( "Error, missing closing \" on line " + result . lines ) ; System . exit ( 1 ) ; } } result . lines += SKIPTOWS_N ( ';' , true ) ; StringBuilder preferred_targets = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { preferred_targets . append ( inArray [ i ] ) ; } CgTag t = result . allocateTag ( preferred_targets . toString ( ) , false ) ; result . preferred_targets . add ( t . hash ) ; index = nindex ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; } if ( result . preferred_targets . isEmpty ( ) ) { System . err . println ( "Preferred targets declared, but no definition given on line " + result . lines ) ; System . exit ( 1 ) ; } result . lines += SKIPWS ( ';' , ( char ) 0 ) ; if ( inArray [ index ] != ';' ) { System . err . println ( "No closing ; at the end of line " + result . lines ) ; System . exit ( 1 ) ; } } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 10 , 'S' , 's' ) && ISCHR ( index , 1 , 'T' , 't' ) && ISCHR ( index , 2 , 'A' , 'a' ) && ISCHR ( index , 3 , 'T' , 't' ) && ISCHR ( index , 4 , 'I' , 'i' ) && ISCHR ( index , 5 , 'C' , 'c' ) && ISCHR ( index , 6 , '-' , '_' ) && ISCHR ( index , 7 , 'S' , 's' ) && ISCHR ( index , 8 , 'E' , 'e' ) && ISCHR ( index , 9 , 'T' , 't' ) && ! ISSTRING ( index , 10 ) ) { index += 11 ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; while ( notDone ( ) && inArray [ index ] != ';' ) { nindex = index ; result . lines += SKIPTOWS_N ( ';' , true ) ; StringBuilder static_sets = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { static_sets . append ( inArray [ i ] ) ; } result . static_sets . add ( static_sets . toString ( ) ) ; index = nindex ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; } if ( result . static_sets . isEmpty ( ) ) { System . err . println ( "Error: static sets declared on line " + result . lines + " but no definitions given" ) ; System . exit ( 1 ) ; } result . lines += SKIPWS ( ';' , ( char ) 0 ) ; if ( inArray [ index ] != ';' ) { System . err . println ( "Error: missing the closing ; at the end of line " + result . lines ) ; System . exit ( 1 ) ; } } else if ( ISCHR ( index , 0 , 'A' , 'a' ) && ISCHR ( index , 11 , 'S' , 's' ) && ISCHR ( index , 1 , 'D' , 'd' ) && ISCHR ( index , 2 , 'D' , 'd' ) && ISCHR ( index , 3 , 'R' , 'r' ) && ISCHR ( index , 4 , 'E' , 'e' ) && ISCHR ( index , 5 , 'L' , 'l' ) && ISCHR ( index , 6 , 'A' , 'a' ) && ISCHR ( index , 7 , 'T' , 't' ) && ISCHR ( index , 8 , 'I' , 'i' ) && ISCHR ( index , 9 , 'O' , 'o' ) && ISCHR ( index , 10 , 'N' , 'n' ) && ! ISSTRING ( index , 11 ) ) { parseRule ( KEYWORDS . K_ADDRELATIONS ) ; } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 11 , 'S' , 's' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'T' , 't' ) && ISCHR ( index , 3 , 'R' , 'r' ) && ISCHR ( index , 4 , 'E' , 'e' ) && ISCHR ( index , 5 , 'L' , 'l' ) && ISCHR ( index , 6 , 'A' , 'a' ) && ISCHR ( index , 7 , 'T' , 't' ) && ISCHR ( index , 8 , 'I' , 'i' ) && ISCHR ( index , 9 , 'O' , 'o' ) && ISCHR ( index , 10 , 'N' , 'n' ) && ! ISSTRING ( index , 11 ) ) { parseRule ( KEYWORDS . K_SETRELATIONS ) ; } else if ( ISCHR ( index , 0 , 'R' , 'r' ) && ISCHR ( index , 11 , 'S' , 's' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'M' , 'm' ) && ISCHR ( index , 3 , 'R' , 'r' ) && ISCHR ( index , 4 , 'E' , 'e' ) && ISCHR ( index , 5 , 'L' , 'l' ) && ISCHR ( index , 6 , 'A' , 'a' ) && ISCHR ( index , 7 , 'T' , 't' ) && ISCHR ( index , 8 , 'I' , 'i' ) && ISCHR ( index , 9 , 'O' , 'o' ) && ISCHR ( index , 10 , 'N' , 'n' ) && ! ISSTRING ( index , 11 ) ) { parseRule ( KEYWORDS . K_REMRELATIONS ) ; } else if ( ISCHR ( index , 0 , 'A' , 'a' ) && ISCHR ( index , 10 , 'N' , 'n' ) && ISCHR ( index , 1 , 'D' , 'd' ) && ISCHR ( index , 2 , 'D' , 'd' ) && ISCHR ( index , 3 , 'R' , 'r' ) && ISCHR ( index , 4 , 'E' , 'e' ) && ISCHR ( index , 5 , 'L' , 'l' ) && ISCHR ( index , 6 , 'A' , 'a' ) && ISCHR ( index , 7 , 'T' , 't' ) && ISCHR ( index , 8 , 'I' , 'i' ) && ISCHR ( index , 9 , 'O' , 'o' ) && ! ISSTRING ( index , 10 ) ) { parseRule ( KEYWORDS . K_ADDRELATION ) ; } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 10 , 'N' , 'n' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'T' , 't' ) && ISCHR ( index , 3 , 'R' , 'r' ) && ISCHR ( index , 4 , 'E' , 'e' ) && ISCHR ( index , 5 , 'L' , 'l' ) && ISCHR ( index , 6 , 'A' , 'a' ) && ISCHR ( index , 7 , 'T' , 't' ) && ISCHR ( index , 8 , 'I' , 'i' ) && ISCHR ( index , 9 , 'O' , 'o' ) && ! ISSTRING ( index , 10 ) ) { parseRule ( KEYWORDS . K_SETRELATION ) ; } else if ( ISCHR ( index , 0 , 'R' , 'r' ) && ISCHR ( index , 10 , 'N' , 'n' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'M' , 'm' ) && ISCHR ( index , 3 , 'R' , 'r' ) && ISCHR ( index , 4 , 'E' , 'e' ) && ISCHR ( index , 5 , 'L' , 'l' ) && ISCHR ( index , 6 , 'A' , 'a' ) && ISCHR ( index , 7 , 'T' , 't' ) && ISCHR ( index , 8 , 'I' , 'i' ) && ISCHR ( index , 9 , 'O' , 'o' ) && ! ISSTRING ( index , 10 ) ) { parseRule ( KEYWORDS . K_REMRELATION ) ; } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 8 , 'T' , 't' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'T' , 't' ) && ISCHR ( index , 3 , 'P' , 'p' ) && ISCHR ( index , 4 , 'A' , 'a' ) && ISCHR ( index , 5 , 'R' , 'r' ) && ISCHR ( index , 6 , 'E' , 'e' ) && ISCHR ( index , 7 , 'N' , 'n' ) && ! ISSTRING ( index , 8 ) ) { parseRule ( KEYWORDS . K_SETPARENT ) ; } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 7 , 'D' , 'd' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'T' , 't' ) && ISCHR ( index , 3 , 'C' , 'c' ) && ISCHR ( index , 4 , 'H' , 'h' ) && ISCHR ( index , 5 , 'I' , 'i' ) && ISCHR ( index , 6 , 'L' , 'l' ) && ! ISSTRING ( index , 7 ) ) { parseRule ( KEYWORDS . K_SETCHILD ) ; } else if ( ISCHR ( index , 0 , 'E' , 'e' ) && ISCHR ( index , 7 , 'L' , 'l' ) && ISCHR ( index , 1 , 'X' , 'x' ) && ISCHR ( index , 2 , 'T' , 't' ) && ISCHR ( index , 3 , 'E' , 'e' ) && ISCHR ( index , 4 , 'R' , 'r' ) && ISCHR ( index , 5 , 'N' , 'n' ) && ISCHR ( index , 6 , 'A' , 'a' ) && ! ISSTRING ( index , 7 ) ) { parseRule ( KEYWORDS . K_EXTERNAL ) ; } else if ( ISCHR ( index , 0 , 'R' , 'r' ) && ISCHR ( index , 8 , 'T' , 't' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'M' , 'm' ) && ISCHR ( index , 3 , 'C' , 'c' ) && ISCHR ( index , 4 , 'O' , 'o' ) && ISCHR ( index , 5 , 'H' , 'h' ) && ISCHR ( index , 6 , 'O' , 'o' ) && ISCHR ( index , 7 , 'R' , 'r' ) && ! ISSTRING ( index , 8 ) ) { parseRule ( KEYWORDS . K_REMCOHORT ) ; } else if ( ISCHR ( index , 0 , 'A' , 'a' ) && ISCHR ( index , 8 , 'T' , 't' ) && ISCHR ( index , 1 , 'D' , 'd' ) && ISCHR ( index , 2 , 'D' , 'd' ) && ISCHR ( index , 3 , 'C' , 'c' ) && ISCHR ( index , 4 , 'O' , 'o' ) && ISCHR ( index , 5 , 'H' , 'h' ) && ISCHR ( index , 6 , 'O' , 'o' ) && ISCHR ( index , 7 , 'R' , 'r' ) && ! ISSTRING ( index , 8 ) ) { parseRule ( KEYWORDS . K_ADDCOHORT ) ; } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 3 , 'S' , 's' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'T' , 't' ) && ! ISSTRING ( index , 3 ) ) { index += 4 ; } else if ( ISCHR ( index , 0 , 'L' , 'l' ) && ISCHR ( index , 3 , 'T' , 't' ) && ISCHR ( index , 1 , 'I' , 'i' ) && ISCHR ( index , 2 , 'S' , 's' ) && ! ISSTRING ( index , 3 ) ) { CgSet set = new CgSet ( ) ; set . line = result . lines ; index += 4 ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; while ( inArray [ nindex - 1 ] == ',' || inArray [ index - 1 ] == ']' ) { -- nindex ; } StringBuilder list_string = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { list_string . append ( inArray [ i ] ) ; } set . setName ( list_string . toString ( ) ) ; index = nindex ; result . lines += SKIPWS ( '=' , ( char ) 0 ) ; if ( inArray [ index ] != '=' ) { System . err . println ( "Error: encountered something before the expected = on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; set = parseTagList ( set , false ) ; CgSet temp = result . getSet ( set . hash ) ; if ( temp != null ) { if ( verbosity_level > 0 ) { System . out . println ( "Warning: LIST " + set . name + " was defined twice with the same contents on lines " + set . line + " and " + temp . line ) ; } } result . addSet ( set ) ; if ( set . tags . isEmpty ( ) && set . single_tags . isEmpty ( ) && set . sets . isEmpty ( ) ) { System . err . println ( "Error: list " + set . name + " is declared, but no definitions are given on line " + result . lines ) ; System . exit ( 1 ) ; } result . lines += SKIPWS ( ';' , ( char ) 0 ) ; if ( inArray [ index ] != ';' ) { System . err . println ( "Error: missing ; at the end of line " + result . lines ) ; System . exit ( 1 ) ; } } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 2 , 'T' , 't' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ! ISSTRING ( index , 2 ) ) { CgSet s = new CgSet ( ) ; s . line = result . lines ; index += 3 ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; while ( inArray [ nindex - 1 ] == ',' || inArray [ nindex - 1 ] == ']' ) { -- nindex ; } StringBuilder set_name = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { set_name . append ( inArray [ i ] ) ; } String sn = set_name . toString ( ) ; s . setName ( sn ) ; int sh = sn . hashCode ( ) ; index = nindex ; result . lines += SKIPWS ( '=' , ( char ) 0 ) ; if ( inArray [ index ] != '=' ) { System . err . println ( "Error encountered before expected = on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; s = parseSetInline ( s ) ; CgSet temp = result . getSet ( s . hash ) ; if ( temp != null ) { if ( verbosity_level > 0 ) { System . out . println ( "Warning: set " + s . name + " was defined twice with the same contents on lines " + s . line + " and " + temp . line ) ; } } else if ( s . sets . size ( ) == 1 && ! ( s . type . contains ( ST . ST_TAG_UNIFY ) ) ) { temp = result . getSet ( s . sets . get ( s . sets . size ( ) - 1 ) ) ; if ( verbosity_level > 0 ) { System . out . println ( "Warning: set " + s . name + "at line " + s . line + " has been aliased to " + temp . name + " at line " + temp . line ) ; } result . set_alias . put ( sh , temp . hash ) ; result . destroySet ( s ) ; s = temp ; } result . addSet ( s ) ; if ( s . sets . isEmpty ( ) && s . tags . isEmpty ( ) && s . single_tags . isEmpty ( ) ) { System . err . println ( "Error: set " + s . name + " declared on line " + s . line + " but no definition" ) ; System . exit ( 1 ) ; } result . lines += SKIPWS ( ';' , ( char ) 0 ) ; if ( inArray [ index ] != ';' ) { System . err . println ( "Error: missing closing ; at line " + result . lines ) ; System . exit ( 1 ) ; } } else if ( ISCHR ( index , 0 , 'M' , 'm' ) && ISCHR ( index , 7 , 'S' , 's' ) && ISCHR ( index , 1 , 'A' , 'a' ) && ISCHR ( index , 2 , 'P' , 'p' ) && ISCHR ( index , 3 , 'P' , 'p' ) && ISCHR ( index , 4 , 'I' , 'i' ) && ISCHR ( index , 5 , 'N' , 'n' ) && ISCHR ( index , 6 , 'G' , 'g' ) && ! ISSTRING ( index , 7 ) ) { index += 8 ; in_before_sections = true ; in_section = false ; in_after_sections = false ; in_null_section = false ; sindex = index ; SKIPLN_S ( ) ; SKIPWS_S ( ( char ) 0 , ( char ) 0 ) ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( index != sindex ) { nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder anchor = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { anchor . append ( inArray [ i ] ) ; } result . addAnchor ( anchor . toString ( ) , result . lines ) ; index = nindex ; } } else if ( ISCHR ( index , 0 , 'C' , 'c' ) && ISCHR ( index , 10 , 'S' , 's' ) && ISCHR ( index , 1 , 'O' , 'o' ) && ISCHR ( index , 2 , 'R' , 'r' ) && ISCHR ( index , 3 , 'R' , 'r' ) && ISCHR ( index , 4 , 'E' , 'e' ) && ISCHR ( index , 5 , 'C' , 'c' ) && ISCHR ( index , 6 , 'T' , 't' ) && ISCHR ( index , 7 , 'I' , 'i' ) && ISCHR ( index , 8 , 'O' , 'o' ) && ISCHR ( index , 9 , 'N' , 'n' ) && ! ISSTRING ( index , 10 ) ) { index += 11 ; in_before_sections = true ; in_section = false ; in_after_sections = false ; in_null_section = false ; sindex = index ; SKIPLN_S ( ) ; SKIPWS_S ( ( char ) 0 , ( char ) 0 ) ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( index != sindex ) { nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder anchor = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { anchor . append ( inArray [ i ] ) ; } result . addAnchor ( anchor . toString ( ) , result . lines ) ; index = nindex ; } } else if ( ISCHR ( index , 0 , 'B' , 'b' ) && ISCHR ( index , 14 , 'S' , 's' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'F' , 'f' ) && ISCHR ( index , 3 , 'O' , 'o' ) && ISCHR ( index , 4 , 'R' , 'r' ) && ISCHR ( index , 5 , 'E' , 'e' ) && ISCHR ( index , 6 , '-' , '_' ) && ISCHR ( index , 7 , 'S' , 's' ) && ISCHR ( index , 8 , 'E' , 'e' ) && ISCHR ( index , 9 , 'C' , 'c' ) && ISCHR ( index , 10 , 'T' , 't' ) && ISCHR ( index , 11 , 'I' , 'i' ) && ISCHR ( index , 12 , 'O' , 'o' ) && ISCHR ( index , 13 , 'N' , 'n' ) && ! ISSTRING ( index , 14 ) ) { index += 15 ; in_before_sections = true ; in_section = false ; in_after_sections = false ; in_null_section = false ; sindex = index ; SKIPLN_S ( ) ; SKIPWS_S ( ( char ) 0 , ( char ) 0 ) ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( index != sindex ) { nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder anchor = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { anchor . append ( inArray [ i ] ) ; } result . addAnchor ( anchor . toString ( ) , result . lines ) ; index = nindex ; } } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 6 , 'N' , 'n' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'C' , 'c' ) && ISCHR ( index , 3 , 'T' , 't' ) && ISCHR ( index , 4 , 'I' , 'i' ) && ISCHR ( index , 5 , 'O' , 'o' ) && ! ISSTRING ( index , 6 ) ) { index += 7 ; result . sections . add ( result . lines ) ; in_before_sections = false ; in_section = true ; in_after_sections = false ; in_null_section = false ; sindex = index ; SKIPLN_S ( ) ; SKIPWS_S ( ( char ) 0 , ( char ) 0 ) ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( index != sindex ) { nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder anchor = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { anchor . append ( inArray [ i ] ) ; } result . addAnchor ( anchor . toString ( ) , result . lines ) ; index = nindex ; } } else if ( ISCHR ( index , 0 , 'C' , 'c' ) && ISCHR ( index , 10 , 'S' , 's' ) && ISCHR ( index , 1 , 'O' , 'o' ) && ISCHR ( index , 2 , 'N' , 'n' ) && ISCHR ( index , 3 , 'S' , 's' ) && ISCHR ( index , 4 , 'T' , 't' ) && ISCHR ( index , 5 , 'R' , 'r' ) && ISCHR ( index , 6 , 'A' , 'a' ) && ISCHR ( index , 7 , 'I' , 'i' ) && ISCHR ( index , 8 , 'N' , 'n' ) && ISCHR ( index , 9 , 'T' , 't' ) && ! ISSTRING ( index , 10 ) ) { index += 11 ; result . sections . add ( result . lines ) ; in_before_sections = false ; in_section = true ; in_after_sections = false ; in_null_section = false ; sindex = index ; SKIPLN_S ( ) ; SKIPWS_S ( ( char ) 0 , ( char ) 0 ) ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( index != sindex ) { nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder anchor = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { anchor . append ( inArray [ i ] ) ; } result . addAnchor ( anchor . toString ( ) , result . lines ) ; index = nindex ; } } else if ( ISCHR ( index , 0 , 'A' , 'a' ) && ISCHR ( index , 13 , 'S' , 's' ) && ISCHR ( index , 1 , 'F' , 'f' ) && ISCHR ( index , 2 , 'T' , 't' ) && ISCHR ( index , 3 , 'E' , 'e' ) && ISCHR ( index , 4 , 'R' , 'r' ) && ISCHR ( index , 5 , '-' , '_' ) && ISCHR ( index , 6 , 'S' , 's' ) && ISCHR ( index , 7 , 'E' , 'e' ) && ISCHR ( index , 8 , 'C' , 'c' ) && ISCHR ( index , 9 , 'T' , 't' ) && ISCHR ( index , 10 , 'I' , 'i' ) && ISCHR ( index , 11 , 'O' , 'o' ) && ISCHR ( index , 12 , 'N' , 'n' ) && ! ISSTRING ( index , 13 ) ) { index += 14 ; in_before_sections = false ; in_section = false ; in_after_sections = true ; in_null_section = false ; sindex = index ; SKIPLN_S ( ) ; SKIPWS_S ( ( char ) 0 , ( char ) 0 ) ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( index != sindex ) { nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder anchor = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { anchor . append ( inArray [ i ] ) ; } result . addAnchor ( anchor . toString ( ) , result . lines ) ; index = nindex ; } } else if ( ISCHR ( index , 0 , 'N' , 'n' ) && ISCHR ( index , 11 , 'N' , 'n' ) && ISCHR ( index , 1 , 'U' , 'u' ) && ISCHR ( index , 2 , 'L' , 'l' ) && ISCHR ( index , 3 , 'L' , 'l' ) && ISCHR ( index , 4 , '-' , '_' ) && ISCHR ( index , 5 , 'S' , 's' ) && ISCHR ( index , 6 , 'E' , 'e' ) && ISCHR ( index , 7 , 'C' , 'c' ) && ISCHR ( index , 8 , 'T' , 't' ) && ISCHR ( index , 9 , 'I' , 'i' ) && ISCHR ( index , 10 , 'O' , 'o' ) && ! ISSTRING ( index , 11 ) ) { index += 12 ; in_before_sections = false ; in_section = false ; in_after_sections = false ; in_null_section = true ; sindex = index ; SKIPLN_S ( ) ; SKIPWS_S ( ( char ) 0 , ( char ) 0 ) ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( index != sindex ) { nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder anchor = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { anchor . append ( inArray [ i ] ) ; } result . addAnchor ( anchor . toString ( ) , result . lines ) ; index = nindex ; } } else if ( ISCHR ( index , 0 , 'A' , 'a' ) && ISCHR ( index , 5 , 'R' , 'r' ) && ISCHR ( index , 1 , 'N' , 'n' ) && ISCHR ( index , 2 , 'C' , 'c' ) && ISCHR ( index , 3 , 'H' , 'h' ) && ISCHR ( index , 4 , 'O' , 'o' ) && ! ISSTRING ( index , 5 ) ) { index += 6 ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder anchor = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { anchor . append ( inArray [ i ] ) ; } result . addAnchor ( anchor . toString ( ) , result . lines ) ; index = nindex ; result . lines += SKIPWS ( ';' , ( char ) 0 ) ; if ( inArray [ index ] != ';' ) { System . err . println ( "Error: missing closing ; on line " + result . lines ) ; System . exit ( 1 ) ; } } else if ( ISCHR ( index , 0 , 'I' , 'i' ) && ISCHR ( index , 6 , 'E' , 'e' ) && ISCHR ( index , 1 , 'N' , 'n' ) && ISCHR ( index , 2 , 'C' , 'c' ) && ISCHR ( index , 3 , 'L' , 'l' ) && ISCHR ( index , 4 , 'U' , 'u' ) && ISCHR ( index , 5 , 'D' , 'd' ) && ! ISSTRING ( index , 6 ) ) { System . err . println ( "INCLUDE keyword not supported yet in this CG parser. Please paste the contents of the other files in directly" ) ; System . exit ( 1 ) ; } else if ( ISCHR ( index , 0 , 'I' , 'i' ) && ISCHR ( index , 2 , 'F' , 'f' ) && ISCHR ( index , 1 , 'F' , 'f' ) && ! ISSTRING ( index , 2 ) ) { parseRule ( KEYWORDS . K_IFF ) ; } else if ( ISCHR ( index , 0 , 'M' , 'm' ) && ISCHR ( index , 2 , 'P' , 'p' ) && ISCHR ( index , 1 , 'A' , 'a' ) && ! ISSTRING ( index , 2 ) ) { parseRule ( KEYWORDS . K_MAP ) ; } else if ( ISCHR ( index , 0 , 'A' , 'a' ) && ISCHR ( index , 2 , 'D' , 'd' ) && ISCHR ( index , 1 , 'D' , 'd' ) && ! ISSTRING ( index , 2 ) ) { parseRule ( KEYWORDS . K_ADD ) ; } else if ( ISCHR ( index , 0 , 'A' , 'a' ) && ISCHR ( index , 5 , 'D' , 'd' ) && ISCHR ( index , 1 , 'P' , 'p' ) && ISCHR ( index , 2 , 'P' , 'p' ) && ISCHR ( index , 3 , 'E' , 'e' ) && ISCHR ( index , 4 , 'N' , 'n' ) && ! ISSTRING ( index , 5 ) ) { parseRule ( KEYWORDS . K_APPEND ) ; } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 5 , 'T' , 't' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'L' , 'l' ) && ISCHR ( index , 3 , 'E' , 'e' ) && ISCHR ( index , 4 , 'C' , 'c' ) && ! ISSTRING ( index , 5 ) ) { parseRule ( KEYWORDS . K_SELECT ) ; } else if ( ISCHR ( index , 0 , 'R' , 'r' ) && ISCHR ( index , 5 , 'E' , 'e' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'M' , 'm' ) && ISCHR ( index , 3 , 'O' , 'o' ) && ISCHR ( index , 4 , 'V' , 'v' ) && ! ISSTRING ( index , 5 ) ) { parseRule ( KEYWORDS . K_REMOVE ) ; } else if ( ISCHR ( index , 0 , 'R' , 'r' ) && ISCHR ( index , 6 , 'E' , 'e' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'P' , 'p' ) && ISCHR ( index , 3 , 'L' , 'l' ) && ISCHR ( index , 4 , 'A' , 'a' ) && ISCHR ( index , 5 , 'C' , 'c' ) && ! ISSTRING ( index , 6 ) ) { parseRule ( KEYWORDS . K_REPLACE ) ; } else if ( ISCHR ( index , 0 , 'D' , 'd' ) && ISCHR ( index , 6 , 'T' , 't' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'L' , 'l' ) && ISCHR ( index , 3 , 'I' , 'i' ) && ISCHR ( index , 4 , 'M' , 'm' ) && ISCHR ( index , 5 , 'I' , 'i' ) && ! ISSTRING ( index , 6 ) ) { parseRule ( KEYWORDS . K_DELIMIT ) ; } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 9 , 'E' , 'e' ) && ISCHR ( index , 1 , 'U' , 'u' ) && ISCHR ( index , 2 , 'B' , 'b' ) && ISCHR ( index , 3 , 'S' , 's' ) && ISCHR ( index , 4 , 'T' , 't' ) && ISCHR ( index , 5 , 'I' , 'i' ) && ISCHR ( index , 6 , 'T' , 't' ) && ISCHR ( index , 7 , 'U' , 'u' ) && ISCHR ( index , 8 , 'T' , 't' ) && ! ISSTRING ( index , 9 ) ) { parseRule ( KEYWORDS . K_SUBSTITUTE ) ; } else if ( ISCHR ( index , 0 , 'C' , 'c' ) && ISCHR ( index , 3 , 'Y' , 'y' ) && ISCHR ( index , 1 , 'O' , 'o' ) && ISCHR ( index , 2 , 'P' , 'p' ) && ! ISSTRING ( index , 3 ) ) { parseRule ( KEYWORDS . K_COPY ) ; } else if ( ISCHR ( index , 0 , 'J' , 'j' ) && ISCHR ( index , 3 , 'P' , 'p' ) && ISCHR ( index , 1 , 'U' , 'u' ) && ISCHR ( index , 2 , 'M' , 'm' ) && ! ISSTRING ( index , 3 ) ) { parseRule ( KEYWORDS . K_JUMP ) ; } else if ( ISCHR ( index , 0 , 'M' , 'm' ) && ISCHR ( index , 3 , 'E' , 'e' ) && ISCHR ( index , 1 , 'O' , 'o' ) && ISCHR ( index , 2 , 'V' , 'v' ) && ! ISSTRING ( index , 3 ) ) { parseRule ( KEYWORDS . K_MOVE ) ; } else if ( ISCHR ( index , 0 , 'S' , 's' ) && ISCHR ( index , 5 , 'H' , 'h' ) && ISCHR ( index , 1 , 'W' , 'w' ) && ISCHR ( index , 2 , 'I' , 'i' ) && ISCHR ( index , 3 , 'T' , 't' ) && ISCHR ( index , 4 , 'C' , 'c' ) && ! ISSTRING ( index , 5 ) ) { parseRule ( KEYWORDS . K_SWITCH ) ; } else if ( ISCHR ( index , 0 , 'E' , 'e' ) && ISCHR ( index , 6 , 'E' , 'e' ) && ISCHR ( index , 1 , 'X' , 'x' ) && ISCHR ( index , 2 , 'E' , 'e' ) && ISCHR ( index , 3 , 'C' , 'c' ) && ISCHR ( index , 4 , 'U' , 'u' ) && ISCHR ( index , 5 , 'T' , 't' ) && ! ISSTRING ( index , 6 ) ) { parseRule ( KEYWORDS . K_EXECUTE ) ; } else if ( ISCHR ( index , 0 , 'U' , 'u' ) && ISCHR ( index , 4 , 'P' , 'p' ) && ISCHR ( index , 1 , 'N' , 'n' ) && ISCHR ( index , 2 , 'M' , 'm' ) && ISCHR ( index , 3 , 'A' , 'a' ) && ! ISSTRING ( index , 4 ) ) { parseRule ( KEYWORDS . K_UNMAP ) ; } else if ( ISCHR ( index , 0 , 'T' , 't' ) && ISCHR ( index , 7 , 'E' , 'e' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'M' , 'm' ) && ISCHR ( index , 3 , 'P' , 'p' ) && ISCHR ( index , 4 , 'L' , 'l' ) && ISCHR ( index , 5 , 'A' , 'a' ) && ISCHR ( index , 6 , 'T' , 't' ) && ! ISSTRING ( index , 7 ) ) { System . err . println ( "Templates not supported yet in this CG parser. Sorry." ) ; System . exit ( 1 ) ; } else if ( ISCHR ( index , 0 , 'P' , 'p' ) && ISCHR ( index , 10 , 'S' , 's' ) && ISCHR ( index , 1 , 'A' , 'a' ) && ISCHR ( index , 2 , 'R' , 'r' ) && ISCHR ( index , 3 , 'E' , 'e' ) && ISCHR ( index , 4 , 'N' , 'n' ) && ISCHR ( index , 5 , 'T' , 't' ) && ISCHR ( index , 6 , 'H' , 'h' ) && ISCHR ( index , 7 , 'E' , 'e' ) && ISCHR ( index , 8 , 'S' , 's' ) && ISCHR ( index , 9 , 'E' , 'e' ) && ! ISSTRING ( index , 10 ) ) { index += 11 ; result . lines += SKIPWS ( '=' , ( char ) 0 ) ; if ( inArray [ index ] != '=' ) { System . err . println ( "Error: encountered a problem before the expected = on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; while ( notDone ( ) && inArray [ index ] != ';' ) { CgTag left = null ; CgTag right = null ; nindex = index ; result . lines += SKIPTOWS_N ( '(' , true ) ; if ( inArray [ nindex ] != '(' ) { System . err . println ( "Error encountered " + inArray [ nindex ] + " before the expected ) on line " + result . lines ) ; System . exit ( 1 ) ; } nindex ++ ; result . lines += SKIPWS_N ( ( char ) 0 , ( char ) 0 ) ; index = nindex ; if ( inArray [ nindex ] == '"' ) { nindex ++ ; result . lines += SKIPTO_NOSPAN_N ( '"' ) ; if ( inArray [ nindex ] != '"' ) { System . err . println ( "Error: missing closing \" on line " + result . lines ) ; System . exit ( 1 ) ; } } result . lines += SKIPTOWS_N ( ')' , true ) ; StringBuilder parens = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { parens . append ( inArray [ i ] ) ; } left = result . allocateTag ( parens . toString ( ) , false ) ; result . lines += SKIPWS_N ( ( char ) 0 , ( char ) 0 ) ; index = nindex ; if ( inArray [ index ] == ')' ) { System . err . println ( "Error: encountered ) before the expected Right tag on line " + result . lines ) ; System . exit ( 1 ) ; } if ( inArray [ nindex ] == '"' ) { nindex ++ ; result . lines += SKIPTO_NOSPAN_N ( '"' ) ; if ( inArray [ nindex ] != '"' ) { System . err . println ( "Missing closing \" on line " + result . lines ) ; System . exit ( 1 ) ; } } result . lines += SKIPTOWS_N ( ')' , true ) ; StringBuilder parens2 = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { parens2 . append ( inArray [ i ] ) ; } right = result . allocateTag ( parens2 . toString ( ) , false ) ; result . lines += SKIPWS_N ( ( char ) 0 , ( char ) 0 ) ; index = nindex ; if ( inArray [ index ] != ')' ) { System . err . println ( "Error: encounted " + inArray [ index ] + " before expected ) on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( left != null && right != null ) { result . parentheses . put ( left . hash , right . hash ) ; result . parentheses_reverse . put ( right . hash , left . hash ) ; } } if ( result . parentheses . isEmpty ( ) ) { System . out . println ( "Error: parentheses declared, but no definitions given on line " + result . lines ) ; System . exit ( 1 ) ; } result . lines += SKIPWS ( ';' , ( char ) 0 ) ; if ( inArray [ index ] != ';' ) { System . err . println ( "Error: missing closing ; on line " + result . lines ) ; System . exit ( 1 ) ; } } else if ( ISCHR ( index , 0 , 'E' , 'e' ) && ISCHR ( index , 2 , 'D' , 'd' ) && ISCHR ( index , 1 , 'N' , 'n' ) ) { if ( ISNL ( index - 1 ) || ISSPACE ( index - 1 ) ) { if ( inArray [ index + 3 ] == ( char ) 0 || ISNL ( index + 3 ) || ISSPACE ( index + 3 ) ) { break ; } } ++ index ; } else { if ( inArray [ index ] == ';' || inArray [ index ] == '"' ) { if ( inArray [ index ] == '"' ) { ++ index ; result . lines += SKIPTO_NOSPAN_P ( '"' ) ; if ( inArray [ index ] != '"' ) { System . err . println ( "Error: Missing closing \" on line " + result . lines ) ; System . exit ( 1 ) ; } } result . lines += SKIPTOWS_P ( ( char ) 0 , false ) ; } if ( notDone ( ) && inArray [ index ] != ';' && inArray [ index ] != '"' && ! ISNL ( index ) && ! ISSPACE ( index ) ) { System . err . println ( "Error: garbage data on line " + result . lines + "; I'm not really sure what's going on here" ) ; System . exit ( 1 ) ; } if ( ISNL ( index ) ) { result . lines += 1 ; } ++ index ; } } return 0 ; } private void addRuleToGrammar ( CgRule rule ) { if ( this . in_section ) { rule . section = result . sections . size ( ) - 1 ; result . addRule ( rule ) ; } else if ( this . in_before_sections ) { rule . section = - 1 ; result . addRule ( rule ) ; } else if ( this . in_after_sections ) { rule . section = - 2 ; result . addRule ( rule ) ; } else if ( this . in_null_section ) { rule . section = - 3 ; result . addRule ( rule ) ; } else { result . destroyRule ( rule ) ; System . err . println ( "Error: rule definition attempted outside of a section on line " + result . lines ) ; System . exit ( 1 ) ; } } private CgSet parseTagList ( CgSet s , boolean isinline ) { if ( isinline ) { if ( inArray [ index ] != '(' ) { System . err . println ( "Error: Missing opening ( on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; } while ( notDone ( ) && inArray [ index ] != ';' && inArray [ index ] != ')' ) { result . lines += SKIPWS ( ';' , ')' ) ; if ( notDone ( ) && inArray [ index ] != ';' && inArray [ index ] != ')' ) { if ( inArray [ index ] == '(' ) { ++ index ; ArrayList < CgTag > tags = new ArrayList < > ( ) ; while ( notDone ( ) && inArray [ index ] != ';' && inArray [ index ] != ')' ) { nindex = index ; if ( inArray [ nindex ] == '"' ) { nindex ++ ; result . lines += SKIPTO_NOSPAN_N ( '"' ) ; if ( inArray [ nindex ] != '"' ) { System . err . println ( "Error: missing closing \" on line " + result . lines ) ; System . exit ( 1 ) ; } } result . lines += SKIPTOWS_N ( ')' , true ) ; StringBuilder sb = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { sb . append ( inArray [ i ] ) ; } CgTag t = result . allocateTag ( sb . toString ( ) , false ) ; tags . add ( t ) ; index = nindex ; result . lines += SKIPWS ( ';' , ')' ) ; } if ( inArray [ index ] != ')' ) { System . err . println ( "Error: missing closing ) on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; if ( tags . size ( ) == 1 ) { s . addTag ( tags . get ( tags . size ( ) - 1 ) ) ; } else { CgCompositeTag ct = result . allocateCompositeTag ( ) ; for ( CgTag tag : tags ) { ct . addTag ( tag ) ; } s . addCompositeTag ( ct ) ; } } else { nindex = index ; if ( inArray [ nindex ] == '"' ) { nindex ++ ; result . lines += SKIPTO_NOSPAN_N ( '"' ) ; if ( inArray [ nindex ] != '"' ) { System . err . println ( "Error: missing closing \" on line " + result . lines ) ; System . exit ( 1 ) ; } } if ( isinline ) { result . lines += SKIPTOWS_N ( ')' , true ) ; } else { result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; } StringBuilder sb = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { sb . append ( inArray [ i ] ) ; } CgTag t = result . allocateTag ( sb . toString ( ) , false ) ; s . addTag ( t ) ; index = nindex ; } } } if ( isinline ) { if ( inArray [ index ] != ')' ) { System . err . println ( "Error: missing closing ) on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; } return s ; } private CgSet parseSetInline ( CgSet s ) { ArrayList < Integer > set_ops = new ArrayList < > ( ) ; ArrayList < Integer > sets = new ArrayList < > ( ) ; boolean wantop = false ; while ( notDone ( ) && inArray [ index ] != ';' && inArray [ index ] != ')' ) { result . lines += SKIPWS ( ';' , ')' ) ; if ( notDone ( ) && inArray [ index ] != ';' && inArray [ index ] != ')' ) { if ( ! wantop ) { if ( inArray [ index ] == '(' ) { ++ index ; CgSet set_c = result . allocateSet ( ) ; set_c . line = result . lines ; set_c . setName ( sets_counter ++ ) ; ArrayList < CgTag > tags = new ArrayList < > ( ) ; while ( notDone ( ) && inArray [ index ] != ';' && inArray [ index ] != ')' ) { result . lines += SKIPWS ( ';' , ')' ) ; nindex = index ; if ( inArray [ nindex ] == '"' ) { nindex ++ ; result . lines += SKIPTO_NOSPAN_N ( '"' ) ; if ( inArray [ nindex ] != '"' ) { System . err . println ( "Error: missing closing \" at line " + result . lines ) ; System . exit ( 1 ) ; } } result . lines += SKIPTOWS_N ( ')' , true ) ; StringBuilder sb = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { sb . append ( inArray [ i ] ) ; } CgTag t = result . allocateTag ( sb . toString ( ) , false ) ; tags . add ( t ) ; index = nindex ; result . lines += SKIPWS ( ';' , ')' ) ; } if ( inArray [ index ] != ')' ) { System . err . println ( "Error: missing closing ) on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; if ( tags . size ( ) == 1 ) { set_c . addTag ( tags . get ( tags . size ( ) - 1 ) ) ; } else { CgCompositeTag ct = result . allocateCompositeTag ( ) ; for ( CgTag tag : tags ) { ct . addTag ( tag ) ; } set_c . addCompositeTag ( ct ) ; } result . addSet ( set_c ) ; sets . add ( set_c . hash ) ; } else { nindex = index ; result . lines += SKIPTOWS_N ( ')' , true ) ; while ( inArray [ nindex - 1 ] == ',' || inArray [ nindex - 1 ] == ']' ) { -- nindex ; } StringBuilder sb = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { sb . append ( inArray [ i ] ) ; } CgSet tmp = result . parseSet ( sb . toString ( ) ) ; int sh = tmp . hash ; sets . add ( sh ) ; index = nindex ; } if ( ! set_ops . isEmpty ( ) && ( set_ops . get ( set_ops . size ( ) - 1 ) == STRINGS . S_SET_ISECT_U . value || set_ops . get ( set_ops . size ( ) - 1 ) == STRINGS . S_SET_SYMDIFF_U . value ) ) { System . out . println ( "Warning: intersection and symmetric difference with sets may not work correctly" ) ; final HashSet < CgCompositeTag . AnyTag > a = result . getSet ( sets . get ( sets . size ( ) - 1 ) ) . getTagList ( result ) ; final HashSet < CgCompositeTag . AnyTag > b = result . getSet ( sets . get ( sets . size ( ) - 2 ) ) . getTagList ( result ) ; ArrayList < CgCompositeTag . AnyTag > r = new ArrayList < > ( ) ; if ( set_ops . get ( set_ops . size ( ) - 1 ) == STRINGS . S_SET_ISECT_U . value ) { HashSet < CgCompositeTag . AnyTag > c = new HashSet < > ( ) ; c . addAll ( a ) ; c . addAll ( b ) ; for ( CgCompositeTag . AnyTag itag : c ) { r . add ( itag ) ; } } else if ( set_ops . get ( set_ops . size ( ) - 1 ) == STRINGS . S_SET_SYMDIFF_U . value ) { for ( CgCompositeTag . AnyTag itag : a ) { if ( ! b . contains ( itag ) ) { r . add ( itag ) ; } } for ( CgCompositeTag . AnyTag itag : b ) { if ( ! a . contains ( itag ) ) { r . add ( itag ) ; } } } set_ops . remove ( set_ops . size ( ) - 1 ) ; sets . remove ( sets . size ( ) - 1 ) ; sets . remove ( sets . size ( ) - 1 ) ; CgSet set_c = result . allocateSet ( ) ; set_c . line = result . lines ; set_c . setName ( sets_counter ++ ) ; for ( CgCompositeTag . AnyTag aR : r ) { if ( aR . which == CgCompositeTag . ANYTAG_TYPE . ANYTAG_TAG . value ) { CgTag t = aR . getTag ( ) ; set_c . addTag ( t ) ; } else { CgCompositeTag t = aR . getCompositeTag ( ) ; set_c . addCompositeTag ( t ) ; } } result . addSet ( set_c ) ; sets . add ( set_c . hash ) ; } wantop = true ; } else { nindex = index ; result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder sb = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { sb . append ( inArray [ i ] ) ; } int sop = ux_isSetOp ( sb . toString ( ) ) ; if ( sop != STRINGS . S_IGNORE . value ) { set_ops . add ( sop ) ; wantop = false ; index = nindex ; } else { break ; } } } } if ( s != null ) { s . sets = sets ; s . set_ops = set_ops ; } else if ( sets . size ( ) == 1 ) { s = result . getSet ( sets . get ( sets . size ( ) - 1 ) ) ; } else { s = result . allocateSet ( ) ; s . sets = sets ; s . set_ops = set_ops ; } return s ; } private CgSet parseSetInlineWrapper ( ) { int tmpLines = result . lines ; CgSet s = parseSetInline ( null ) ; if ( s . line == 0 ) { s . line = tmpLines ; } if ( s . name == null || s . name . isEmpty ( ) ) { s . setName ( sets_counter ++ ) ; } result . addSet ( s ) ; return s ; } private void parseContextualTestPosition ( ) { boolean negative = false ; boolean had_digits = false ; int tries = 0 ; while ( inArray [ index ] != ' ' && inArray [ index ] != '(' && tries < 100 ) { ++ tries ; if ( inArray [ index ] == '*' && inArray [ index + 1 ] == '*' ) { currentTest . pos . add ( POS . POS_SCANALL . value ) ; index += 2 ; } if ( inArray [ index ] == '*' ) { currentTest . pos . add ( POS . POS_SCANFIRST . value ) ; ++ index ; } if ( inArray [ index ] == 'C' ) { currentTest . pos . add ( POS . POS_CAREFUL . value ) ; ++ index ; } if ( inArray [ index ] == 'c' ) { currentTest . pos . add ( POS . POS_DEP_CHILD . value ) ; ++ index ; } if ( inArray [ index ] == 'p' ) { currentTest . pos . add ( POS . POS_DEP_PARENT . value ) ; ++ index ; } if ( inArray [ index ] == 's' ) { currentTest . pos . add ( POS . POS_DEP_SIBLING . value ) ; ++ index ; } if ( inArray [ index ] == 'S' ) { currentTest . pos . add ( POS . POS_SELF . value ) ; ++ index ; } if ( inArray [ index ] == '<' ) { currentTest . pos . add ( POS . POS_SPAN_LEFT . value ) ; ++ index ; } if ( inArray [ index ] == '>' ) { currentTest . pos . add ( POS . POS_SPAN_RIGHT . value ) ; ++ index ; } if ( inArray [ index ] == 'W' ) { currentTest . pos . add ( POS . POS_SPAN_BOTH . value ) ; ++ index ; } if ( inArray [ index ] == '@' ) { currentTest . pos . add ( POS . POS_ABSOLUTE . value ) ; ++ index ; } if ( inArray [ index ] == 'O' ) { currentTest . pos . add ( POS . POS_NO_PASS_ORIGIN . value ) ; ++ index ; } if ( inArray [ index ] == 'o' ) { currentTest . pos . add ( POS . POS_PASS_ORIGIN . value ) ; ++ index ; } if ( inArray [ index ] == 'L' ) { currentTest . pos . add ( POS . POS_LEFT_PAR . value ) ; ++ index ; } if ( inArray [ index ] == 'R' ) { currentTest . pos . add ( POS . POS_RIGHT_PAR . value ) ; ++ index ; } if ( inArray [ index ] == 'X' ) { currentTest . pos . add ( POS . POS_MARK_SET . value ) ; ++ index ; } if ( inArray [ index ] == 'x' ) { currentTest . pos . add ( POS . POS_MARK_JUMP . value ) ; ++ index ; } if ( inArray [ index ] == 'D' ) { currentTest . pos . add ( POS . POS_LOOK_DELETED . value ) ; ++ index ; } if ( inArray [ index ] == 'd' ) { currentTest . pos . add ( POS . POS_LOOK_DELAYED . value ) ; ++ index ; } if ( inArray [ index ] == 'A' ) { currentTest . pos . add ( POS . POS_ATTACH_TO . value ) ; ++ index ; } if ( inArray [ index ] == '?' ) { currentTest . pos . add ( POS . POS_UNKNOWN . value ) ; ++ index ; } if ( inArray [ index ] == '-' ) { negative = true ; ++ index ; } if ( Character . isDigit ( inArray [ index ] ) ) { had_digits = true ; while ( inArray [ index ] >= '0' && inArray [ index ] <= '9' ) { currentTest . offset = ( currentTest . offset * 10 ) + ( inArray [ index ] - '0' ) ; ++ index ; } } if ( inArray [ index ] == 'r' && inArray [ index + 1 ] == ':' ) { currentTest . pos . add ( POS . POS_RELATION . value ) ; index += 2 ; nindex = index ; SKIPTOWS_N ( '(' , true ) ; StringBuilder sb = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { sb . append ( inArray [ i ] ) ; } CgTag tag = result . allocateTag ( sb . toString ( ) , true ) ; currentTest . relation = tag . hash ; index = nindex ; } } if ( negative ) { currentTest . offset = ( - 1 ) * Math . abs ( currentTest . offset ) ; } if ( ( currentTest . pos . contains ( POS . POS_DEP_CHILD . value ) || currentTest . pos . contains ( POS . POS_DEP_SIBLING . value ) ) && currentTest . pos . contains ( POS . POS_SCANFIRST . value ) || currentTest . pos . contains ( POS . POS_SCANALL . value ) ) { if ( currentTest . pos . contains ( POS . POS_SCANFIRST . value ) ) { currentTest . pos . remove ( POS . POS_SCANFIRST . value ) ; } if ( currentTest . pos . contains ( POS . POS_SCANALL . value ) ) { currentTest . pos . remove ( POS . POS_SCANALL . value ) ; } currentTest . pos . add ( POS . POS_DEP_DEEP . value ) ; } if ( ( currentTest . pos . contains ( POS . POS_DEP_CHILD . value ) || currentTest . pos . contains ( POS . POS_DEP_SIBLING . value ) ) && currentTest . pos . contains ( POS . POS_CAREFUL . value ) ) { System . out . println ( "Warning: deprecated conversion from C to ALL on line " + result . lines ) ; if ( currentTest . pos . contains ( POS . POS_CAREFUL . value ) ) { currentTest . pos . remove ( POS . POS_CAREFUL . value ) ; } currentTest . pos . add ( POS . POS_ALL . value ) ; } if ( ( currentTest . pos . contains ( POS . POS_DEP_CHILD . value ) || currentTest . pos . contains ( POS . POS_DEP_SIBLING . value ) ) && currentTest . pos . contains ( POS . POS_NOT . value ) ) { System . out . println ( "Warning: deprecated conversion from NOT to NONE on line " + result . lines ) ; if ( currentTest . pos . contains ( POS . POS_NOT . value ) ) { currentTest . pos . remove ( POS . POS_NOT . value ) ; } currentTest . pos . add ( POS . POS_NONE . value ) ; } if ( currentTest . pos . contains ( POS . POS_RELATION . value ) && ( currentTest . pos . contains ( POS . POS_CAREFUL . value ) ) ) { System . out . println ( "Warning: deprecated conversion from C to ALL on line " + result . lines ) ; currentTest . pos . remove ( POS . POS_CAREFUL . value ) ; currentTest . pos . add ( POS . POS_NONE . value ) ; } if ( currentTest . pos . contains ( POS . POS_RELATION . value ) && ( currentTest . pos . contains ( POS . POS_NOT . value ) ) ) { System . out . println ( "Warning: deprecated from NOT to NONE on line " + result . lines ) ; currentTest . pos . remove ( POS . POS_NOT . value ) ; currentTest . pos . add ( POS . POS_NONE . value ) ; } if ( tries >= 5 ) { System . out . println ( "Warning: Position on line " + result . lines + " took too many loops" ) ; } if ( tries >= 100 ) { System . err . println ( "Error: invalid position on line " + result . lines + " caused endless loop" ) ; System . exit ( 1 ) ; } if ( had_digits ) { if ( currentTest . pos . contains ( POS . POS_DEP_CHILD . value ) || currentTest . pos . contains ( POS . POS_DEP_SIBLING . value ) || currentTest . pos . contains ( POS . POS_DEP_PARENT . value ) ) { System . err . println ( "Error: invalid position on line " + result . lines + " - cannot combine offsets with dependency" ) ; System . exit ( 1 ) ; } if ( currentTest . pos . contains ( POS . POS_LEFT_PAR . value ) || currentTest . pos . contains ( POS . POS_RIGHT_PAR . value ) ) { System . err . println ( "Error: invalid position on line " + result . lines + " - cannot combine offsets with enclosures" ) ; System . exit ( 1 ) ; } if ( currentTest . pos . contains ( POS . POS_RELATION . value ) ) { System . err . println ( "Error: invalid position on line " + result . lines + " - cannot combine offsets with relations" ) ; System . exit ( 1 ) ; } } if ( ( currentTest . pos . contains ( POS . POS_LEFT_PAR . value ) || currentTest . pos . contains ( POS . POS_RIGHT_PAR . value ) ) && ( currentTest . pos . contains ( POS . POS_SCANFIRST . value ) || currentTest . pos . contains ( POS . POS_SCANALL . value ) ) ) { System . err . println ( "Error: invalid position on line " + result . lines + " - cannot have both enclosure and scan" ) ; System . exit ( 1 ) ; } if ( currentTest . pos . contains ( POS . POS_PASS_ORIGIN . value ) && currentTest . pos . contains ( POS . POS_NO_PASS_ORIGIN . value ) ) { System . err . println ( "Error: invalid position on line " + result . lines + " - cannot have both O and o" ) ; System . exit ( 1 ) ; } if ( currentTest . pos . contains ( POS . POS_LEFT_PAR . value ) && currentTest . pos . contains ( POS . POS_RIGHT_PAR . value ) ) { System . err . println ( "Error: invalid position on line " + result . lines + " - cannot have both L and R" ) ; System . exit ( 1 ) ; } if ( currentTest . pos . contains ( POS . POS_ALL . value ) && currentTest . pos . contains ( POS . POS_NONE . value ) ) { System . err . println ( "Error: invalid position on line " + result . lines + " - cannot have both NONE and ALL" ) ; System . exit ( 1 ) ; } if ( currentTest . pos . contains ( POS . POS_UNKNOWN . value ) && ( currentTest . pos . size ( ) == 1 || had_digits ) ) { System . err . println ( "Error: invalid position on line " + result . lines + " - ? cannot be combined with anything else" ) ; System . exit ( 1 ) ; } if ( currentTest . pos . contains ( POS . POS_SCANALL . value ) && currentTest . pos . contains ( POS . POS_NOT . value ) ) { System . out . println ( "Warning: we don't think mixing NOT and ** makes sense on line " + result . lines ) ; } } private CgRule parseContextualTestList ( CgRule rule ) { if ( inLinkedTest ) { if ( ! linkedTests . isEmpty ( ) ) { CgContextualTest lastTest = rule . test_map . get ( linkedTests . get ( linkedTests . size ( ) - 1 ) ) ; lastTest . next = currentTest . hashCode ( ) ; linkedTests . remove ( linkedTests . get ( linkedTests . size ( ) - 1 ) ) ; linkedTests . add ( lastTest . hashCode ( ) ) ; currentTest . prev = lastTest . hashCode ( ) ; rule . test_map . put ( currentTest . hashCode ( ) , currentTest ) ; rule . test_map . put ( lastTest . hashCode ( ) , lastTest ) ; } linkedTests . add ( currentTest . hashCode ( ) ) ; rule . test_map . put ( currentTest . hashCode ( ) , currentTest ) ; } else { linkedTests = new ArrayList < > ( ) ; } currentTest = new CgContextualTest ( ) ; currentTest . line = result . lines ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( ISCHR ( index , 0 , 'N' , 'n' ) && ISCHR ( index , 5 , 'E' , 'e' ) && ISCHR ( index , 1 , 'E' , 'e' ) && ISCHR ( index , 2 , 'G' , 'g' ) && ISCHR ( index , 3 , 'A' , 'a' ) && ISCHR ( index , 4 , 'T' , 't' ) ) { index += 6 ; currentTest . pos . add ( POS . POS_NEGATE . value ) ; } if ( ISCHR ( index , 0 , 'A' , 'a' ) && ISCHR ( index , 2 , 'L' , 'l' ) && ISCHR ( index , 1 , 'L' , 'l' ) ) { index += 3 ; currentTest . pos . add ( POS . POS_ALL . value ) ; } if ( ISCHR ( index , 0 , 'N' , 'n' ) && ISCHR ( index , 3 , 'E' , 'e' ) && ISCHR ( index , 1 , 'O' , 'o' ) && ISCHR ( index , 2 , 'N' , 'n' ) ) { index += 4 ; currentTest . pos . add ( POS . POS_NONE . value ) ; } if ( ISCHR ( index , 0 , 'N' , 'n' ) && ISCHR ( index , 2 , 'T' , 't' ) && ISCHR ( index , 1 , 'O' , 'o' ) ) { index += 3 ; currentTest . pos . add ( POS . POS_NOT . value ) ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; nindex = index ; result . lines += SKIPTOWS_N ( '(' , false ) ; StringBuilder buf = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { buf . append ( inArray [ i ] ) ; } String str = buf . toString ( ) ; if ( ux_isEmpty ( str ) ) { index = nindex ; if ( parentTest != null ) { System . err . println ( "Can't have two nested tests on line " + result . lines + "\nTry splitting it up." ) ; System . exit ( 1 ) ; } parentTest = currentTest ; inParentTest = true ; for ( ; ; ) { if ( inArray [ index ] != '(' ) { System . err . println ( "Error: expected ( but found " + inArray [ index ] + " at line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; rule = parseContextualTestList ( rule ) ; ++ index ; if ( linkedTests . isEmpty ( ) ) { parentTest . ors . add ( currentTest . hashCode ( ) ) ; } else { parentTest . ors . add ( linkedTests . get ( 0 ) ) ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( ISCHR ( index , 0 , 'O' , 'o' ) && ISCHR ( index , 1 , 'R' , 'r' ) ) { index += 2 ; } else { inParentTest = false ; linkedTests = new ArrayList < > ( ) ; break ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; } } else if ( str . compareToIgnoreCase ( "[" ) == 0 ) { System . out . println ( "Warning: this feature may not work correctly in this implementation" ) ; ++ index ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; CgSet s1 = parseSetInlineWrapper ( ) ; currentTest . offset = 1 ; currentTest . target = s1 . hash ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; while ( inArray [ index ] == ',' ) { ++ index ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; CgContextualTest lnk = currentTest . allocateContextualTest ( ) ; CgSet s = parseSetInlineWrapper ( ) ; lnk . offset = 1 ; lnk . target = s . hash ; currentTest . linked = lnk . hashCode ( ) ; currentTest = lnk ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; } if ( inArray [ index ] != ']' ) { System . err . println ( "Error: expected ] on line " + result . lines + " but found " + inArray [ index ] ) ; System . exit ( 1 ) ; } ++ index ; } else if ( str . charAt ( 0 ) == 'T' && str . charAt ( 1 ) == ':' ) { System . err . println ( "Templates not supported in this CG parser. Sorry" ) ; System . exit ( 1 ) ; } else { parseContextualTestPosition ( ) ; index = nindex ; if ( currentTest . pos . contains ( POS . POS_DEP_CHILD . value ) || currentTest . pos . contains ( POS . POS_DEP_CHILD . value ) || currentTest . pos . contains ( POS . POS_DEP_SIBLING . value ) ) { result . has_dep = true ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( inArray [ index ] == 'T' && inArray [ index + 1 ] == ':' ) { System . err . println ( "Templates not supported in this CG parser. Sorry" ) ; System . exit ( 1 ) ; } else { CgSet s = parseSetInlineWrapper ( ) ; currentTest . target = s . hash ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( ISCHR ( index , 0 , 'C' , 'c' ) && ISCHR ( index , 7 , 'R' , 'r' ) && ISCHR ( index , 1 , 'B' , 'b' ) && ISCHR ( index , 2 , 'A' , 'a' ) && ISCHR ( index , 3 , 'R' , 'r' ) && ISCHR ( index , 4 , 'R' , 'r' ) && ISCHR ( index , 5 , 'I' , 'i' ) && ISCHR ( index , 6 , 'E' , 'e' ) ) { index += 8 ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; CgSet s = parseSetInlineWrapper ( ) ; currentTest . cbarrier = s . hash ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( ISCHR ( index , 0 , 'B' , 'b' ) && ISCHR ( index , 6 , 'R' , 'r' ) && ISCHR ( index , 1 , 'A' , 'a' ) && ISCHR ( index , 2 , 'R' , 'r' ) && ISCHR ( index , 3 , 'R' , 'r' ) && ISCHR ( index , 4 , 'I' , 'i' ) && ISCHR ( index , 5 , 'E' , 'e' ) ) { index += 7 ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; CgSet s = parseSetInlineWrapper ( ) ; currentTest . barrier = s . hash ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; } boolean linked = false ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( ISCHR ( index , 0 , 'A' , 'a' ) && ISCHR ( index , 2 , 'D' , 'd' ) && ISCHR ( index , 1 , 'N' , 'n' ) ) { System . err . println ( "AND is deprecated. Use LINK 0 or operator +. Found on line " + result . lines ) ; System . exit ( 1 ) ; } if ( ISCHR ( index , 0 , 'L' , 'l' ) && ISCHR ( index , 3 , 'K' , 'k' ) && ISCHR ( index , 1 , 'I' , 'i' ) && ISCHR ( index , 2 , 'N' , 'n' ) ) { index += 4 ; linked = true ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( linked ) { if ( currentTest . pos . contains ( POS . POS_NONE . value ) ) { System . err . println ( "Error: it does not make sense to link from a NONE test." ) ; System . exit ( 1 ) ; } inLinkedTest = true ; rule = parseContextualTestList ( rule ) ; inLinkedTest = false ; return rule ; } if ( rule != null ) { if ( rule . flags . contains ( RFLAGS . RF_LOOKDELETED . value ) ) { currentTest . pos . add ( POS . POS_LOOK_DELETED . value ) ; } if ( rule . flags . contains ( RFLAGS . RF_LOOKDELAYED . value ) ) { currentTest . pos . add ( POS . POS_LOOK_DELAYED . value ) ; } } if ( ! linkedTests . isEmpty ( ) ) { CgContextualTest lastTest = rule . test_map . get ( linkedTests . get ( linkedTests . size ( ) - 1 ) ) ; lastTest . next = currentTest . hashCode ( ) ; linkedTests . remove ( linkedTests . get ( linkedTests . size ( ) - 1 ) ) ; linkedTests . add ( lastTest . hashCode ( ) ) ; currentTest . prev = lastTest . hashCode ( ) ; rule . test_map . put ( currentTest . hashCode ( ) , currentTest ) ; rule . test_map . put ( lastTest . hashCode ( ) , lastTest ) ; linkedTests . add ( currentTest . hashCode ( ) ) ; if ( ! inParentTest ) { for ( int testint : linkedTests ) { rule . all_tests . add ( rule . test_map . get ( testint ) ) ; } rule . test_heads . add ( rule . test_map . get ( linkedTests . get ( 0 ) ) ) ; } } if ( parentTest != null && ! inParentTest ) { if ( option_vislcg_compat && currentTest . pos . contains ( POS . POS_NOT . value ) ) { currentTest . pos . remove ( POS . POS_NOT . value ) ; currentTest . pos . add ( POS . POS_NEGATE . value ) ; } rule . test_map . put ( parentTest . hashCode ( ) , parentTest ) ; rule . test_heads . add ( parentTest ) ; linkedTests = new ArrayList < > ( ) ; } if ( ! inParentTest && ! inLinkedTest && parentTest == null ) { if ( option_vislcg_compat && currentTest . pos . contains ( POS . POS_NOT . value ) ) { currentTest . pos . remove ( POS . POS_NOT . value ) ; currentTest . pos . add ( POS . POS_NEGATE . value ) ; } rule . all_tests . add ( currentTest ) ; rule . test_heads . add ( currentTest ) ; rule . test_map . put ( currentTest . hashCode ( ) , currentTest ) ; } if ( inParentTest && ! inLinkedTest ) { if ( option_vislcg_compat && currentTest . pos . contains ( POS . POS_NOT . value ) ) { currentTest . pos . remove ( POS . POS_NOT . value ) ; currentTest . pos . add ( POS . POS_NEGATE . value ) ; } rule . all_tests . add ( currentTest ) ; rule . test_map . put ( currentTest . hashCode ( ) , currentTest ) ; } return rule ; } private CgRule parseContextualTests ( CgRule rule ) { currentTest = null ; parentTest = null ; inParentTest = false ; inLinkedTest = false ; linkedTests = new ArrayList < > ( ) ; return parseContextualTestList ( rule ) ; } private CgRule parseContextualDependencyTests ( CgRule rule ) { System . out . println ( "Warning: dependency tests not tested in this implementation" ) ; return parseContextualTestList ( rule ) ; } private void parseRule ( KEYWORDS key ) { CgRule rule = result . allocateRule ( ) ; rule . line = result . lines ; rule . type = key ; lpindex = index ; BACKTONL_LP ( ) ; result . lines += SKIPWS_LP ( ( char ) 0 , ( char ) 0 ) ; if ( lpindex != index && lpindex < index ) { nindex = lpindex ; if ( inArray [ nindex ] == '"' ) { nindex ++ ; result . lines += SKIPTO_NOSPAN_N ( '"' ) ; if ( inArray [ nindex ] != '"' ) { System . err . println ( "Error: missing closing \" on line " + result . lines ) ; System . exit ( 1 ) ; } } result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder sb = new StringBuilder ( ) ; for ( int i = lpindex ; i < nindex ; i ++ ) { sb . append ( inArray [ i ] ) ; } CgTag wform = result . allocateTag ( sb . toString ( ) , false ) ; rule . wordform = wform . hash ; } index += keywords [ key . value ] . length ( ) ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( inArray [ index ] == ':' ) { ++ index ; nindex = index ; result . lines += SKIPTOWS_N ( '(' , false ) ; StringBuilder strname = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { strname . append ( inArray [ i ] ) ; } rule . setName ( strname . toString ( ) ) ; index = nindex ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( key == KEYWORDS . K_EXTERNAL ) { if ( ISCHR ( index , 0 , 'O' , 'o' ) && ISCHR ( index , 3 , 'E' , 'e' ) && ISCHR ( index , 1 , 'N' , 'n' ) && ISCHR ( index , 2 , 'C' , 'c' ) ) { index += 4 ; rule . type = KEYWORDS . K_EXTERNAL_ONCE ; } else if ( ISCHR ( index , 0 , 'A' , 'a' ) && ISCHR ( index , 5 , 'S' , 's' ) && ISCHR ( index , 1 , 'L' , 'l' ) && ISCHR ( index , 2 , 'W' , 'w' ) && ISCHR ( index , 3 , 'A' , 'a' ) && ISCHR ( index , 4 , 'Y' , 'y' ) ) { index += 6 ; rule . type = KEYWORDS . K_EXTERNAL_ALWAYS ; } else { System . err . println ( "Error: missing keyword ONCE or ALWAYS on line " + result . lines ) ; System . exit ( 1 ) ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; nindex = index ; if ( inArray [ nindex ] == '"' ) { ++ nindex ; result . lines += SKIPTO_NOSPAN_N ( '"' ) ; if ( inArray [ nindex ] != '"' ) { System . err . println ( "Error: missing closing \" on line " + result . lines ) ; System . exit ( 1 ) ; } } result . lines += SKIPTOWS_N ( ( char ) 0 , true ) ; StringBuilder varname = new StringBuilder ( ) ; if ( inArray [ index ] == '"' ) { for ( int i = index + 1 ; i < nindex - 1 ; i ++ ) { varname . append ( inArray [ i ] ) ; } } else { for ( int i = index ; i < nindex ; i ++ ) { varname . append ( inArray [ i ] ) ; } } CgTag ext = result . allocateTag ( varname . toString ( ) , true ) ; rule . varname = ext . hash ; index = nindex ; } boolean setflag = true ; while ( setflag ) { setflag = false ; for ( SFLAGS fl : SFLAGS . values ( ) ) { if ( ux_simplecasecmp ( fl . name ( ) ) ) { index += fl . name ( ) . length ( ) ; rule . flags . add ( ( 1 < < fl . value ) ) ; setflag = true ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( inArray [ index ] == '(' || inArray [ index ] == 'T' || inArray [ index ] == 't' || inArray [ index ] == ';' ) { break ; } } } if ( rule . flags . contains ( RFLAGS . RF_ENCL_OUTER . value ) && rule . flags . contains ( RFLAGS . RF_ENCL_INNER . value ) ) { System . err . println ( "Error: Line " + result . lines + " ENCL_OUTER and ENCL_INNER are mutually exclusive" ) ; System . exit ( 1 ) ; } if ( rule . flags . contains ( RFLAGS . RF_VARYORDER . value ) && rule . flags . contains ( RFLAGS . RF_KEEPORDER . value ) ) { System . err . println ( "Error: Line " + result . lines + " KEEPORDER and VARYORDER are mutually exclusive" ) ; System . exit ( 1 ) ; } if ( rule . flags . contains ( RFLAGS . RF_RESETX . value ) && rule . flags . contains ( RFLAGS . RF_REMEMBERX . value ) ) { System . err . println ( "Error: Line " + result . lines + " REMEMBERX and RESETX are mutually exclusive" ) ; System . exit ( 1 ) ; } if ( rule . flags . contains ( RFLAGS . RF_ALLOWLOOP . value ) && rule . flags . contains ( RFLAGS . RF_NEAREST . value ) ) { System . err . println ( "Error: Line " + result . lines + " NEAREST and ALLOWLOOP are mutually exclusive" ) ; System . exit ( 1 ) ; } if ( rule . flags . contains ( RFLAGS . RF_UNSAFE . value ) && rule . flags . contains ( RFLAGS . RF_SAFE . value ) ) { System . err . println ( "Error: Line " + result . lines + " UNSAFE and SAFE are mutually exclusive" ) ; System . exit ( 1 ) ; } if ( rule . flags . contains ( RFLAGS . RF_SAFE . value ) && rule . flags . contains ( RFLAGS . RF_UNMAPLAST . value ) ) { System . err . println ( "Error: Line " + result . lines + " UNMAPLAST and SAFE are mutually exclusive" ) ; System . exit ( 1 ) ; } if ( rule . flags . contains ( RFLAGS . RF_DELAYED . value ) && rule . flags . contains ( RFLAGS . RF_IMMEDIATE . value ) ) { System . err . println ( "Error: Line " + result . lines + " DELAYED and IMMEDIATE are mutually exclusive" ) ; System . exit ( 1 ) ; } if ( rule . flags . contains ( RFLAGS . RF_NOCHILD . value ) && rule . flags . contains ( RFLAGS . RF_WITHCHILD . value ) ) { System . err . println ( "Error: Line " + result . lines + " NO_CHILD and WITH_CHILD are mutually exclusive" ) ; System . exit ( 1 ) ; } if ( rule . flags . contains ( RFLAGS . RF_NOITERATE . value ) && rule . flags . contains ( RFLAGS . RF_ITERATE . value ) ) { System . err . println ( "Error: Line " + result . lines + " NOITERATE and ITERATE are mutually exclusive" ) ; System . exit ( 1 ) ; } if ( ! ( rule . flags . contains ( RFLAGS . RF_ITERATE . value ) || rule . flags . contains ( RFLAGS . RF_NOITERATE . value ) ) ) { if ( key != KEYWORDS . K_SELECT && key != KEYWORDS . K_REMOVE && key != KEYWORDS . K_IFF && key != KEYWORDS . K_DELIMIT && key != KEYWORDS . K_REMCOHORT && key != KEYWORDS . K_MOVE && key != KEYWORDS . K_SWITCH ) { rule . flags . add ( RFLAGS . RF_NOITERATE . value ) ; } } if ( key == KEYWORDS . K_UNMAP && ! ( rule . flags . contains ( RFLAGS . RF_SAFE . value ) || rule . flags . contains ( RFLAGS . RF_UNSAFE . value ) ) ) { rule . flags . add ( RFLAGS . RF_SAFE . value ) ; } if ( rule . flags . contains ( RFLAGS . RF_UNMAPLAST . value ) ) { rule . flags . add ( RFLAGS . RF_UNSAFE . value ) ; } if ( rule . flags . contains ( RFLAGS . RF_ENCL_FINAL . value ) ) { result . has_encl_final = true ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( rule . flags . contains ( RFLAGS . RF_WITHCHILD . value ) ) { result . has_dep = true ; CgSet s = parseSetInlineWrapper ( ) ; rule . childset1 = s . hash ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; } else if ( rule . flags . contains ( RFLAGS . RF_NOCHILD . value ) ) { rule . childset1 = 0 ; } if ( key == KEYWORDS . K_JUMP || key == KEYWORDS . K_EXECUTE ) { nindex = index ; result . lines += SKIPTOWS_N ( '(' , false ) ; if ( ! ux_isalnum ( inArray [ index ] ) ) { System . err . println ( "Error: Anchor name for " + key . name ( ) + " must be alphanumeric on line " + result . lines ) ; System . exit ( 1 ) ; } StringBuilder sb = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { sb . append ( inArray [ i ] ) ; } String jumpstart = sb . toString ( ) ; rule . jumpstart = jumpstart . hashCode ( ) ; index = nindex ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( key == KEYWORDS . K_EXECUTE ) { nindex = index ; result . lines += SKIPTOWS_N ( '(' , false ) ; if ( ! ux_isalnum ( inArray [ index ] ) ) { System . err . println ( "Error: anchor name for at line " + result . lines + " must be alphanumeric" ) ; System . exit ( 1 ) ; } StringBuilder sb = new StringBuilder ( ) ; for ( int i = index ; i < nindex ; i ++ ) { sb . append ( inArray [ i ] ) ; } String str = sb . toString ( ) ; int sh = str . hashCode ( ) ; rule . jumpend = sh ; index = nindex ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( key == KEYWORDS . K_SUBSTITUTE ) { CgSet s = parseSetInlineWrapper ( ) ; System . out . println ( "Warning: substitute behavior not tested" ) ; s . reindex ( result ) ; rule . sublist = s ; if ( s . isEmpty ( ) ) { System . err . println ( "Error: empty substitute set on line " + result . lines ) ; System . exit ( 1 ) ; } if ( s . tags_list . isEmpty ( ) && ! ( s . type . contains ( ST . ST_TAG_UNIFY . value ) || s . type . contains ( ST . ST_SET_UNIFY . value ) || s . type . contains ( ST . ST_CHILD_UNIFY . value ) ) ) { System . err . println ( "Error: substitute set on line " + result . lines + " was neither unified nor of LIST type" ) ; System . exit ( 1 ) ; } } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( key == KEYWORDS . K_MAP || key == KEYWORDS . K_ADD || key == KEYWORDS . K_REPLACE || key == KEYWORDS . K_APPEND || key == KEYWORDS . K_SUBSTITUTE || key == KEYWORDS . K_COPY || key == KEYWORDS . K_ADDRELATIONS || key == KEYWORDS . K_ADDRELATION || key == KEYWORDS . K_SETRELATIONS || key == KEYWORDS . K_SETRELATION || key == KEYWORDS . K_REMRELATIONS || key == KEYWORDS . K_REMRELATION || key == KEYWORDS . K_ADDCOHORT ) { CgSet s = parseSetInlineWrapper ( ) ; s . reindex ( result ) ; rule . maplist = s ; if ( s . isEmpty ( ) ) { System . err . println ( "Error: Empty mapping set on line " + result . lines ) ; System . exit ( 1 ) ; } if ( ( s . tags_list . isEmpty ( ) && s . single_tags . isEmpty ( ) ) && ! ( s . type . contains ( ST . ST_TAG_UNIFY . value ) || s . type . contains ( ST . ST_SET_UNIFY . value ) || s . type . contains ( ST . ST_CHILD_UNIFY . value ) ) ) { System . err . println ( "Error: substitute set on line " + result . lines + " was neither unified nor of LIST type" ) ; System . exit ( 1 ) ; } } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( key == KEYWORDS . K_ADDRELATIONS || key == KEYWORDS . K_SETRELATIONS || key == KEYWORDS . K_REMRELATIONS ) { CgSet s = parseSetInlineWrapper ( ) ; s . reindex ( result ) ; rule . sublist = s ; if ( s . isEmpty ( ) ) { System . err . println ( "Error: Empty mapping set on line " + result . lines ) ; System . exit ( 1 ) ; } if ( s . tags_list . isEmpty ( ) && ! ( s . type . contains ( ST . ST_TAG_UNIFY . value ) || s . type . contains ( ST . ST_SET_UNIFY . value ) || s . type . contains ( ST . ST_CHILD_UNIFY . value ) ) ) { System . err . println ( "Error: substitute set on line " + result . lines + " was neither unified nor of LIST type" ) ; System . exit ( 1 ) ; } } if ( key == KEYWORDS . K_ADDCOHORT ) { if ( ux_simplecasecmp ( stringbits [ STRINGS . S_AFTER . value ] ) ) { index += stringbits [ STRINGS . S_AFTER . value ] . length ( ) ; rule . type = KEYWORDS . K_ADDCOHORT_AFTER ; } else if ( ux_simplecasecmp ( stringbits [ STRINGS . S_BEFORE . value ] ) ) { index += stringbits [ STRINGS . S_BEFORE . value ] . length ( ) ; rule . type = KEYWORDS . K_ADDCOHORT_BEFORE ; } else { System . err . println ( "Error: missing position keyword AFTER or BEFORE on line " + result . lines ) ; System . exit ( 1 ) ; } } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( ux_simplecasecmp ( stringbits [ STRINGS . S_TARGET . value ] ) ) { index += stringbits [ STRINGS . S_TARGET . value ] . length ( ) ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; CgSet s = parseSetInlineWrapper ( ) ; rule . target = s . hash ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( ux_simplecasecmp ( stringbits [ STRINGS . S_IF . value ] ) ) { index += stringbits [ STRINGS . S_IF . value ] . length ( ) ; } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; while ( notDone ( ) && inArray [ index ] == '(' ) { ++ index ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; rule = parseContextualTests ( rule ) ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( inArray [ index ] != ')' ) { System . err . println ( "Error: missing closing ) on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; } if ( key == KEYWORDS . K_SETPARENT || key == KEYWORDS . K_SETCHILD || key == KEYWORDS . K_ADDRELATIONS || key == KEYWORDS . K_ADDRELATION || key == KEYWORDS . K_SETRELATIONS || key == KEYWORDS . K_SETRELATION || key == KEYWORDS . K_REMRELATIONS || key == KEYWORDS . K_REMRELATION || key == KEYWORDS . K_MOVE || key == KEYWORDS . K_SWITCH ) { result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( key == KEYWORDS . K_MOVE ) { if ( ux_simplecasecmp ( stringbits [ STRINGS . S_AFTER . value ] ) ) { index += stringbits [ STRINGS . S_AFTER . value ] . length ( ) ; rule . type = KEYWORDS . K_MOVE_AFTER ; } else if ( ux_simplecasecmp ( stringbits [ STRINGS . S_BEFORE . value ] ) ) { index += stringbits [ STRINGS . S_BEFORE . value ] . length ( ) ; rule . type = KEYWORDS . K_MOVE_BEFORE ; } else { System . err . println ( "Error: missing movement keyword AFTER or BEFORE on line " + result . lines ) ; System . exit ( 1 ) ; } } else if ( key == KEYWORDS . K_SWITCH ) { if ( ux_simplecasecmp ( stringbits [ STRINGS . S_WITH . value ] ) ) { index += stringbits [ STRINGS . S_WITH . value ] . length ( ) ; } else { System . err . println ( "Error: missing movement keyword WITH on line " + result . lines ) ; System . exit ( 1 ) ; } } else { if ( ux_simplecasecmp ( stringbits [ STRINGS . S_TO . value ] ) ) { index += stringbits [ STRINGS . S_TO . value ] . length ( ) ; } else if ( ux_simplecasecmp ( stringbits [ STRINGS . S_FROM . value ] ) ) { index += stringbits [ STRINGS . S_FROM . value ] . length ( ) ; rule . flags . add ( RFLAGS . RF_REVERSE . value ) ; } else { System . err . println ( "Error: missing dependency keyword TO or FROM on line " + result . lines ) ; System . exit ( 1 ) ; } } result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( key == KEYWORDS . K_MOVE ) { if ( ux_simplecasecmp ( flags [ SFLAGS . FL_WITHCHILD . value ] ) ) { index += flags [ SFLAGS . FL_WITHCHILD . value ] . length ( ) ; result . has_dep = true ; CgSet s2 = parseSetInlineWrapper ( ) ; rule . childset2 = s2 . hash ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; } else if ( ux_simplecasecmp ( flags [ SFLAGS . FL_NOCHILD . value ] ) ) { index += flags [ SFLAGS . FL_NOCHILD . value ] . length ( ) ; rule . childset2 = 0 ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; } } while ( notDone ( ) && inArray [ index ] != '(' ) { ++ index ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; parseContextualDependencyTests ( rule ) ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; if ( inArray [ index ] != ')' ) { System . err . println ( "Error: missing closing ) on line " + result . lines ) ; System . exit ( 1 ) ; } ++ index ; result . lines += SKIPWS ( ( char ) 0 , ( char ) 0 ) ; } if ( ! ( rule . dep_test_head != null ) ) { System . err . println ( "Error: missing dependency target on line " + result . lines ) ; System . exit ( 1 ) ; } rule . dep_target = rule . dep_test_head ; while ( rule . dep_target . next != 0 ) { rule . dep_target = rule . test_map . get ( rule . dep_target . next ) ; } if ( rule . dep_target == rule . dep_test_head ) { rule . dep_test_head = null ; } } if ( key == KEYWORDS . K_SETPARENT || key == KEYWORDS . K_SETCHILD ) { result . has_dep = true ; } addRuleToGrammar ( rule ) ; } private static boolean ux_isalnum ( char c ) { return Character . isLetterOrDigit ( c ) ; } private static boolean ux_isEmpty ( String s ) { int l = s . length ( ) ; if ( l > 0 ) { for ( char c : s . toCharArray ( ) ) { if ( ! Character . isWhitespace ( c ) ) { return false ; } } } return true ; } private static int ux_isSetOp ( String s ) { int retval = STRINGS . S_IGNORE . value ; if ( s . compareToIgnoreCase ( stringbits [ STRINGS . S_OR . value ] ) == 0 || s . compareToIgnoreCase ( stringbits [ STRINGS . S_PIPE . value ] ) == 0 ) { retval = STRINGS . S_OR . value ; } else if ( s . compareTo ( stringbits [ STRINGS . S_PLUS . value ] ) == 0 ) { retval = STRINGS . S_PLUS . value ; } else if ( s . compareTo ( stringbits [ STRINGS . S_MINUS . value ] ) == 0 ) { retval = STRINGS . S_MINUS . value ; } else if ( s . compareTo ( stringbits [ STRINGS . S_MULTIPLY . value ] ) == 0 ) { retval = STRINGS . S_MULTIPLY . value ; } else if ( s . compareTo ( stringbits [ STRINGS . S_FAILFAST . value ] ) == 0 ) { retval = STRINGS . S_FAILFAST . value ; } else if ( s . compareTo ( stringbits [ STRINGS . S_NOT . value ] ) == 0 ) { retval = STRINGS . S_NOT . value ; } else if ( s . compareTo ( stringbits [ STRINGS . S_SET_ISECT_U . value ] ) == 0 ) { retval = STRINGS . S_SET_ISECT_U . value ; } else if ( s . compareTo ( stringbits [ STRINGS . S_SET_SYMDIFF_U . value ] ) == 0 ) { retval = STRINGS . S_SET_SYMDIFF_U . value ; } return retval ; } private boolean ux_simplecasecmp ( String s ) { char [ ] ar = s . toCharArray ( ) ; for ( int i = 0 ; i < ar . length ; i ++ ) { if ( inArray [ index + i ] != ar [ i ] && inArray [ index + i ] != ar [ i ] + ( char ) 32 ) { return false ; } } return true ; } private boolean ISSTRING ( int position , int offset ) { if ( inArray [ position - 1 ] == '"' && inArray [ position + offset + 1 ] == '"' ) { return true ; } if ( inArray [ position - 1 ] == '<' && inArray [ position + offset + 1 ] == '>' ) { return true ; } return false ; } private boolean ISCHR ( int position , int offset , char c , char d ) { if ( position + offset >= length ) { return false ; } return inArray [ position + offset ] == c || inArray [ position + offset ] == d ; } private void BACKTONL_LP ( ) { while ( lpindex < inArray . length && ! ISNL ( lpindex ) && ( inArray [ lpindex ] != ';' || ISESC ( lpindex ) ) ) { lpindex -- ; } lpindex ++ ; } private int SKIPWS ( char a , char b ) { char s = ( char ) 0 ; while ( notDone ( ) && inArray [ index ] != a && inArray [ index ] != b ) { if ( ISNL ( index ) ) { ++ s ; } if ( inArray [ index ] == '#' && ! ISESC ( index ) ) { s += SKIPLN ( ) ; index -- ; } if ( ! ISSPACE ( index ) ) { break ; } ++ index ; } return s ; } private int SKIPWS_S ( char a , char b ) { char d = ( char ) 0 ; while ( ( sindex < inArray . length ) && inArray [ sindex ] != a && inArray [ sindex ] != b ) { if ( ISNL ( sindex ) ) { ++ d ; } if ( inArray [ sindex ] == '#' && ! ISESC ( sindex ) ) { d += SKIPLN_S ( ) ; sindex -- ; } if ( ! ISSPACE ( sindex ) ) { break ; } ++ sindex ; } return d ; } private int SKIPWS_N ( char a , char b ) { char d = ( char ) 0 ; while ( ( nindex < inArray . length ) && inArray [ nindex ] != a && inArray [ nindex ] != b ) { if ( ISNL ( nindex ) ) { ++ d ; } if ( inArray [ nindex ] == '#' && ! ISESC ( nindex ) ) { d += SKIPLN_N ( ) ; nindex -- ; } if ( ! ISSPACE ( nindex ) ) { break ; } ++ nindex ; } return d ; } private int SKIPWS_LP ( char a , char b ) { char d = ( char ) 0 ; while ( ( lpindex < inArray . length ) && inArray [ lpindex ] != a && inArray [ lpindex ] != b ) { if ( ISNL ( lpindex ) ) { ++ d ; } if ( inArray [ lpindex ] == '#' && ! ISESC ( lpindex ) ) { d += SKIPLN_N ( ) ; lpindex -- ; } if ( ! ISSPACE ( lpindex ) ) { break ; } ++ lpindex ; } return d ; } private int SKIPTOWS_N ( char b , boolean allowhash ) { int s = 0 ; while ( ( nindex < inArray . length ) && ! ISSPACE ( nindex ) ) { if ( ! allowhash && inArray [ nindex ] == '#' && ! ISESC ( nindex ) ) { s += SKIPLN_N ( ) ; nindex -- ; } if ( ISNL ( nindex ) ) { ++ s ; ++ nindex ; } if ( inArray [ nindex ] == ';' && ! ISESC ( nindex ) ) { break ; } if ( inArray [ nindex ] == b && ! ISESC ( nindex ) ) { break ; } ++ nindex ; } return s ; } private int SKIPTOWS_P ( char b , boolean allowhash ) { int s = 0 ; while ( notDone ( ) && ! ISSPACE ( index ) ) { if ( ! allowhash && inArray [ index ] == '#' && ! ISESC ( index ) ) { s += SKIPLN ( ) ; index -- ; } if ( ISNL ( index ) ) { ++ s ; ++ index ; } if ( inArray [ index ] == ';' && ! ISESC ( index ) ) { break ; } if ( inArray [ index ] == b && ! ISESC ( index ) ) { break ; } ++ index ; } return s ; } private int SKIPTO_NOSPAN_N ( char b ) { int s = 0 ; while ( ( nindex < inArray . length ) && ( inArray [ nindex ] != b || ISESC ( nindex ) ) ) { if ( ISNL ( nindex ) ) { break ; } ++ nindex ; } return s ; } private int SKIPTO_NOSPAN_P ( char b ) { int s = 0 ; while ( notDone ( ) && ( inArray [ index ] != b || ISESC ( index ) ) ) { if ( ISNL ( index ) ) { break ; } ++ index ; } return s ; } private int SKIPLN ( ) { while ( notDone ( ) && ! ISNL ( index ) ) { ++ index ; } ++ index ; return 1 ; } private int SKIPLN_S ( ) { while ( ( sindex < inArray . length ) && ! ISNL ( sindex ) ) { ++ sindex ; } ++ sindex ; return 1 ; } private int SKIPLN_N ( ) { while ( ( nindex < inArray . length ) && ! ISNL ( nindex ) ) { ++ nindex ; } ++ nindex ; return 1 ; } private boolean ISSPACE ( int position ) { char c = inArray [ position ] ; return ( c == ( char ) 0x20 || c == ( char ) 0x09 || Character . isWhitespace ( c ) ) ; } private boolean ISNL ( int position ) { char c = inArray [ position ] ; return ( c == ( char ) 0x2028L || c == ( char ) 0x2029L || c == ( char ) 0x0085L || c == ( char ) 0x000CL || c == ( char ) 0x00AL ) ; } private boolean ISESC ( int position ) { int a = 1 ; while ( ( ( position - a ) < inArray . length ) && ( inArray [ position - a ] == '\\' ) ) { a ++ ; } return ( a % 2 == 0 ) ; } public static String _S_SET_ISECT_U = "\u2229" ; public static String _S_SET_SYMDIFF_U = "\u2206" ; public static String [ ] stringbits = { "1f283fc29adb937a892e09bbc124b85c this is a dummy string to hold position 0" , "|" , "TO" , "OR" , "+" , "-" , "*" , "**" , "^" , "\\" , "#" , "!" , "NOT" , "NEGATE" , "ALL" , "NONE" , "LINK" , "BARRIER" , "CBARRIER" , "<STREAMCMD:FLUSH>" , "<STREAMCMD:EXIT>" , "<STREAMCMD:IGNORE>" , "<STREAMCMD:RESUME>" , "TARGET" , "AND" , "IF" , "_S_DELIMITERS_" , "_S_SOFT_DELIMITERS_" , ">>>" , "<<<" , " LINK 0 " , " " , "_LEFT_" , "_RIGHT_" , "_PAREN_" , "_TARGET_" , "_MARK_" , "_ATTACHTO_" , "<.*>" , "\".*\"" , "\"<.*>\"" , "AFTER" , "BEFORE" , "WITH" , "?" , "$1" , "$2" , "$3" , "$4" , "$5" , "$6" , "$7" , "$8" , "$9" , "%u" , "%U" , "%l" , "%L" , "_G_" , "POSITIVE" , "NEGATIVE" , "ONCE" , "ALWAYS" , _S_SET_ISECT_U , _S_SET_SYMDIFF_U , "FROM" } ; public String [ ] flags = { "NEAREST" , "ALLOWLOOP" , "DELAYED" , "IMMEDIATE" , "LOOKDELETED" , "LOOKDELAYED" , "UNSAFE" , "SAFE" , "REMEMBERX" , "RESETX" , "KEEPORDER" , "VARYORDER" , "ENCL_INNER" , "ENCL_OUTER" , "ENCL_FINAL" , "ENCL_ANY" , "ALLOWCROSS" , "WITHCHILD" , "NOCHILD" , "ITERATE" , "NOITERATE" , "UNMAPLAST" , "REVERSE" } ; public String [ ] keywords = { "1f283fc29adb937a892e09bbc124b85c this is a dummy keyword to hold position 0" , "SETS" , "LIST" , "SET" , "DELIMITERS" , "SOFT-DELIMITERS" , "PREFERRED-TARGETS" , "MAPPING-PREFIX" , "MAPPINGS" , "CONSTRAINTS" , "CORRECTIONS" , "SECTION" , "BEFORE-SECTIONS" , "AFTER-SECTIONS" , "NULL-SECTION" , "ADD" , "MAP" , "REPLACE" , "SELECT" , "REMOVE" , "IFF" , "APPEND" , "SUBSTITUTE" , "START" , "END" , "ANCHOR" , "EXECUTE" , "JUMP" , "REMVARIABLE" , "SETVARIABLE" , "DELIMIT" , "MATCH" , "SETPARENT" , "SETCHILD" , "ADDRELATION" , "SETRELATION" , "REMRELATION" , "ADDRELATIONS" , "SETRELATIONS" , "REMRELATIONS" , "TEMPLATE" , "MOVE" , "MOVE-AFTER" , "MOVE-BEFORE" , "SWITCH" , "REMCOHORT" , "STATIC-SETS" , "UNMAP" , "COPY" , "ADDCOHORT" , "ADDCOHORT-AFTER" , "ADDCOHORT-BEFORE" , "EXTERNAL" , "EXTERNAL-ONCE" , "EXTERNAL-ALWAYS" } ; public static STRINGS S_ASTERISK = STRINGS . S_MULTIPLY ; }
package org . languagetool . dev . bigdata ; import org . apache . lucene . analysis . core . KeywordAnalyzer ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Field ; import org . apache . lucene . document . TextField ; import org . apache . lucene . index . IndexWriter ; import org . apache . lucene . index . IndexWriterConfig ; import org . apache . lucene . store . FSDirectory ; import org . apache . lucene . util . Version ; import java . io . File ; import java . io . IOException ; final class LuceneSimpleIndexCreator { private LuceneSimpleIndexCreator ( ) { } public static void main ( String [ ] args ) throws IOException { IndexWriterConfig conf = new IndexWriterConfig ( Version . LATEST , new KeywordAnalyzer ( ) ) ; try ( IndexWriter iw1 = new IndexWriter ( FSDirectory . open ( new File ( "/tmp/1grams" ) ) , conf ) ) { addDoc ( iw1 , "the" , 55 ) ; addDoc ( iw1 , "nice" , 10 ) ; addDoc ( iw1 , "building" , 1 ) ; Document document = new Document ( ) ; document . add ( new TextField ( "totalTokenCount" , String . valueOf ( 3 ) , Field . Store . YES ) ) ; iw1 . addDocument ( document ) ; } IndexWriterConfig conf2 = new IndexWriterConfig ( Version . LATEST , new KeywordAnalyzer ( ) ) ; try ( IndexWriter iw2 = new IndexWriter ( FSDirectory . open ( new File ( "/tmp/2grams" ) ) , conf2 ) ) { addDoc ( iw2 , "the nice" , 3 ) ; addDoc ( iw2 , "nice building" , 2 ) ; } IndexWriterConfig conf3 = new IndexWriterConfig ( Version . LATEST , new KeywordAnalyzer ( ) ) ; try ( IndexWriter iw3 = new IndexWriter ( FSDirectory . open ( new File ( "/tmp/3grams" ) ) , conf3 ) ) { addDoc ( iw3 , "the nice building" , 1 ) ; } } private static void addDoc ( IndexWriter iw , String ngram , int count ) throws IOException { Document document = new Document ( ) ; document . add ( new TextField ( "ngram" , ngram , Field . Store . YES ) ) ; document . add ( new TextField ( "count" , String . valueOf ( count ) , Field . Store . YES ) ) ; iw . addDocument ( document ) ; } }
package org . languagetool . dev . bigdata ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . dev . dumpcheck . * ; import org . languagetool . dev . eval . FMeasure ; import org . languagetool . language . English ; import org . languagetool . languagemodel . LanguageModel ; import org . languagetool . languagemodel . LuceneLanguageModel ; import org . languagetool . rules . ConfusionProbabilityRule ; import org . languagetool . rules . ConfusionSet ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . en . EnglishConfusionProbabilityRule ; import org . languagetool . tools . StringTools ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . text . SimpleDateFormat ; import java . util . * ; import static java . util . Locale . ENGLISH ; class ConfusionRuleEvaluator { private static final String TOKEN = "there" ; private static final String TOKEN_HOMOPHONE = "their" ; private static final int FACTOR = 100 ; private static final int MAX_SENTENCES = 1000 ; private final Language language ; private final ConfusionProbabilityRule rule ; private final int grams ; private int truePositives = 0 ; private int trueNegatives = 0 ; private int falsePositives = 0 ; private int falseNegatives = 0 ; private ConfusionRuleEvaluator ( Language language , LanguageModel languageModel , int grams ) { this . language = language ; this . rule = new EnglishConfusionProbabilityRule ( JLanguageTool . getMessageBundle ( ) , languageModel , language , grams ) ; rule . setConfusionSet ( new ConfusionSet ( FACTOR , TOKEN_HOMOPHONE , TOKEN ) ) ; this . grams = grams ; } private void run ( List < String > inputsOrDir , String token , String homophoneToken , int maxSentences ) throws IOException { List < Sentence > allTokenSentences = getRelevantSentences ( inputsOrDir , token , maxSentences ) ; List < Sentence > allHomophoneSentences = getRelevantSentences ( inputsOrDir , homophoneToken , maxSentences ) ; evaluate ( allTokenSentences , true , token , homophoneToken ) ; evaluate ( allTokenSentences , false , homophoneToken , token ) ; evaluate ( allHomophoneSentences , false , token , homophoneToken ) ; evaluate ( allHomophoneSentences , true , homophoneToken , token ) ; printEvalResult ( allTokenSentences , allHomophoneSentences , inputsOrDir ) ; } @ SuppressWarnings ( "ConstantConditions" ) private void evaluate ( List < Sentence > sentences , boolean isCorrect , String token , String homophoneToken ) throws IOException { System . out . println ( "======================" ) ; System . out . printf ( "Starting evaluation on " + sentences . size ( ) + " sentences with %s/%s:\n" , token , homophoneToken ) ; JLanguageTool lt = new JLanguageTool ( new English ( ) ) ; for ( Sentence sentence : sentences ) { String textToken = isCorrect ? token : homophoneToken ; String plainText = sentence . getText ( ) ; String replacement = plainText . indexOf ( textToken ) == 0 ? StringTools . uppercaseFirstChar ( token ) : token ; String replacedTokenSentence = isCorrect ? plainText : plainText . replaceFirst ( "(?i)\\b" + textToken + "\\b" , replacement ) ; AnalyzedSentence analyzedSentence = lt . getAnalyzedSentence ( replacedTokenSentence ) ; RuleMatch [ ] matches = rule . match ( analyzedSentence ) ; boolean consideredCorrect = matches . length == 0 ; String displayStr = plainText . replaceFirst ( "(?i)\\b" + textToken + "\\b" , "**" + replacement + "**" ) ; if ( consideredCorrect && isCorrect ) { trueNegatives ++ ; } else if ( ! consideredCorrect && isCorrect ) { falsePositives ++ ; System . out . println ( "false positive: " + displayStr ) ; } else if ( consideredCorrect && ! isCorrect ) { falseNegatives ++ ; } else { truePositives ++ ; } } } private void printEvalResult ( List < Sentence > allTokenSentences , List < Sentence > allHomophoneSentences , List < String > inputsOrDir ) { int sentences = allTokenSentences . size ( ) + allHomophoneSentences . size ( ) ; System . out . println ( "======================" ) ; System . out . println ( "Evaluation results for " + TOKEN + "/" + TOKEN_HOMOPHONE + " with " + sentences + " sentences as of " + new Date ( ) + ":" ) ; float precision = ( float ) truePositives / ( truePositives + falsePositives ) ; float recall = ( float ) truePositives / ( truePositives + falseNegatives ) ; double fMeasure = FMeasure . getWeightedFMeasure ( precision , recall ) ; System . out . printf ( ENGLISH , " Precision: %.3f (%d false positives)\n" , precision , falsePositives ) ; System . out . printf ( ENGLISH , " Recall: %.3f (%d false negatives)\n" , recall , falseNegatives ) ; System . out . printf ( ENGLISH , " F-measure: %.3f (beta=0.5)\n" , fMeasure ) ; System . out . printf ( ENGLISH , " Matches: %d (true positives)\n" , truePositives ) ; System . out . printf ( ENGLISH , " Inputs: %s\n" , inputsOrDir ) ; System . out . printf ( ENGLISH , " Summary: precision=%.3f, recall=%.3f (%s) using %dgrams\n" , precision , recall , new SimpleDateFormat ( "yyyy-MM-dd" ) . format ( new Date ( ) ) , grams ) ; } private List < Sentence > getRelevantSentences ( List < String > inputs , String token , int maxSentences ) throws IOException { List < Sentence > sentences = new ArrayList < > ( ) ; for ( String input : inputs ) { if ( new File ( input ) . isDirectory ( ) ) { File file = new File ( input , token + ".txt" ) ; if ( ! file . exists ( ) ) { throw new RuntimeException ( "File with example sentences not found: " + file ) ; } try ( FileInputStream fis = new FileInputStream ( file ) ) { SentenceSource sentenceSource = new PlainTextSentenceSource ( fis , language ) ; sentences = getSentencesFromSource ( inputs , token , maxSentences , sentenceSource ) ; } } else { SentenceSource sentenceSource = MixingSentenceSource . create ( inputs , language ) ; sentences = getSentencesFromSource ( inputs , token , maxSentences , sentenceSource ) ; } } return sentences ; } private List < Sentence > getSentencesFromSource ( List < String > inputs , String token , int maxSentences , SentenceSource sentenceSource ) { List < Sentence > sentences = new ArrayList < > ( ) ; while ( sentenceSource . hasNext ( ) ) { Sentence sentence = sentenceSource . next ( ) ; if ( sentence . getText ( ) . toLowerCase ( ) . matches ( ".*\\b" + token + "\\b.*" ) ) { sentences . add ( sentence ) ; if ( sentences . size ( ) % 100 == 0 ) { System . out . println ( "Loaded sentence " + sentences . size ( ) + " with '" + token + "' from " + inputs ) ; } if ( sentences . size ( ) >= maxSentences ) { break ; } } } System . out . println ( "Loaded " + sentences . size ( ) + " sentences with '" + token + "' from " + inputs ) ; return sentences ; } public static void main ( String [ ] args ) throws IOException { if ( args . length < 3 || args . length > 4 ) { System . err . println ( "Usage: " + ConfusionRuleEvaluator . class . getSimpleName ( ) + " <langCode> <languageModelTopDir> <wikipediaXml|tatoebaFile|dir>..." ) ; System . err . println ( " <languageModelTopDir> is a directory with sub-directories '1grams', '2grams' and '3grams' with Lucene indexes" ) ; System . err . println ( " <wikipediaXml|tatoebaFile| dir> either a Wikipedia XML dump, or a Tatoeba file or" ) ; System . err . println ( " a directory with example sentences (where <word>.txt contains only the sentences for <word>)." ) ; System . err . println ( " You can specify both a Wikipedia file and a Tatoeba file." ) ; System . exit ( 1 ) ; } Language lang = Languages . getLanguageForShortName ( args [ 0 ] ) ; LanguageModel languageModel = new LuceneLanguageModel ( new File ( args [ 1 ] ) ) ; List < String > inputsFiles = new ArrayList < > ( ) ; inputsFiles . add ( args [ 2 ] ) ; if ( args . length >= 4 ) { inputsFiles . add ( args [ 3 ] ) ; } ConfusionRuleEvaluator generator = new ConfusionRuleEvaluator ( lang , languageModel , 3 ) ; generator . run ( inputsFiles , TOKEN , TOKEN_HOMOPHONE , MAX_SENTENCES ) ; } }
package org . languagetool . language ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . * ; import org . languagetool . rules . ro . CompoundRule ; import org . languagetool . rules . ro . MorfologikRomanianSpellerRule ; import org . languagetool . rules . ro . RomanianWordRepeatBeginningRule ; import org . languagetool . rules . ro . SimpleReplaceRule ; import org . languagetool . synthesis . Synthesizer ; import org . languagetool . synthesis . ro . RomanianSynthesizer ; import org . languagetool . tagging . Tagger ; import org . languagetool . tagging . disambiguation . Disambiguator ; import org . languagetool . tagging . disambiguation . rules . XmlRuleDisambiguator ; import org . languagetool . tagging . ro . RomanianTagger ; import org . languagetool . tokenizers . SRXSentenceTokenizer ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tokenizers . ro . RomanianWordTokenizer ; public class Romanian extends Language { private Tagger tagger ; private Synthesizer synthesizer ; private Disambiguator disambiguator ; private Tokenizer wordTokenizer ; private SentenceTokenizer sentenceTokenizer ; @ Override public String getName ( ) { return "Romanian" ; } @ Override public String getShortName ( ) { return "ro" ; } @ Override public String [ ] getCountries ( ) { return new String [ ] { "RO" } ; } @ Override public Tagger getTagger ( ) { if ( tagger == null ) { tagger = new RomanianTagger ( ) ; } return tagger ; } @ Override public Contributor [ ] getMaintainers ( ) { return new Contributor [ ] { new Contributor ( "Ionuț Păduraru" , "http://www.archeus.ro" ) } ; } @ Override public List < Rule > getRelevantRules ( ResourceBundle messages ) throws IOException { return Arrays . asList ( new CommaWhitespaceRule ( messages ) , new DoublePunctuationRule ( messages ) , new UppercaseSentenceStartRule ( messages , this ) , new MultipleWhitespaceRule ( messages , this ) , new GenericUnpairedBracketsRule ( messages , Arrays . asList ( "[" , "(" , "{" , "„" , "«" , "»" ) , Arrays . asList ( "]" , ")" , "}" , "”" , "»" , "«" ) ) , new WordRepeatRule ( messages , this ) , new MorfologikRomanianSpellerRule ( messages , this ) , new RomanianWordRepeatBeginningRule ( messages , this ) , new SimpleReplaceRule ( messages ) , new CompoundRule ( messages ) ) ; } @ Override public Synthesizer getSynthesizer ( ) { if ( synthesizer == null ) { synthesizer = new RomanianSynthesizer ( ) ; } return synthesizer ; } @ Override public Disambiguator getDisambiguator ( ) { if ( disambiguator == null ) { disambiguator = new XmlRuleDisambiguator ( new Romanian ( ) ) ; } return disambiguator ; } @ Override public Tokenizer getWordTokenizer ( ) { if ( wordTokenizer == null ) { wordTokenizer = new RomanianWordTokenizer ( ) ; } return wordTokenizer ; } @ Override public SentenceTokenizer getSentenceTokenizer ( ) { if ( sentenceTokenizer == null ) { sentenceTokenizer = new SRXSentenceTokenizer ( this ) ; } return sentenceTokenizer ; } }
package org . languagetool . dev . eval ; import org . languagetool . AnalyzedSentence ; import org . languagetool . markup . AnnotatedText ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tools . StringTools ; import org . w3c . dom . Document ; import org . w3c . dom . Node ; import org . w3c . dom . NodeList ; import org . xml . sax . InputSource ; import javax . xml . parsers . DocumentBuilder ; import javax . xml . parsers . DocumentBuilderFactory ; import javax . xml . xpath . XPath ; import javax . xml . xpath . XPathConstants ; import javax . xml . xpath . XPathExpressionException ; import javax . xml . xpath . XPathFactory ; import java . io . IOException ; import java . io . InputStream ; import java . io . StringReader ; import java . net . URL ; import java . net . URLConnection ; import java . net . URLEncoder ; import java . util . ArrayList ; import java . util . List ; class AtDEvaluator implements Evaluator { private static final int WAIT_MILLIS = 1500 ; private final String urlPrefix ; AtDEvaluator ( String urlPrefix ) { this . urlPrefix = urlPrefix ; } @ Override public List < RuleMatch > check ( AnnotatedText annotatedText ) { try { String text = annotatedText . getPlainText ( ) ; String xml = queryAtDServer ( text ) ; return getRuleMatches ( xml , annotatedText ) ; } catch ( XPathExpressionException e ) { throw new RuntimeException ( e ) ; } } @ Override public void close ( ) { } private String queryAtDServer ( String text ) { try { System . out . println ( "Sleeping " + WAIT_MILLIS + " before connecting " + urlPrefix + "..." ) ; Thread . sleep ( WAIT_MILLIS ) ; URL url = new URL ( urlPrefix + URLEncoder . encode ( text , "UTF-8" ) ) ; URLConnection conn = url . openConnection ( ) ; String atSign = "@" ; conn . setRequestProperty ( "User-Agent" , "AtDEvalChecker, contact daniel.naber " + atSign + " languagetool.org" ) ; InputStream contentStream = ( InputStream ) conn . getContent ( ) ; return StringTools . streamToString ( contentStream , "UTF-8" ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } private List < RuleMatch > getRuleMatches ( String resultXml , AnnotatedText text ) throws XPathExpressionException { List < RuleMatch > matches = new ArrayList < > ( ) ; Document document = getDocument ( resultXml ) ; XPath xPath = XPathFactory . newInstance ( ) . newXPath ( ) ; NodeList errors = ( NodeList ) xPath . evaluate ( "//error" , document , XPathConstants . NODESET ) ; for ( int i = 0 ; i < errors . getLength ( ) ; i ++ ) { Node error = errors . item ( i ) ; String string = xPath . evaluate ( "string" , error ) ; String description = xPath . evaluate ( "description" , error ) ; String preContext = xPath . evaluate ( "precontext" , error ) ; String errorText = preContext + " " + string ; int fromPos = text . getPlainText ( ) . indexOf ( errorText ) + preContext . length ( ) + 1 ; int toPos = fromPos + string . length ( ) ; NodeList suggestions = ( NodeList ) xPath . evaluate ( "suggestions" , error , XPathConstants . NODESET ) ; RuleMatch ruleMatch = new RuleMatch ( new AtdRule ( ) , text . getOriginalTextPositionFor ( fromPos ) , text . getOriginalTextPositionFor ( toPos ) , description ) ; for ( int j = 0 ; j < suggestions . getLength ( ) ; j ++ ) { Node option = suggestions . item ( j ) ; String optionStr = xPath . evaluate ( "option" , option ) ; ruleMatch . setSuggestedReplacement ( optionStr ) ; } matches . add ( ruleMatch ) ; } return matches ; } private Document getDocument ( String xml ) { try { DocumentBuilderFactory factory = DocumentBuilderFactory . newInstance ( ) ; DocumentBuilder builder = factory . newDocumentBuilder ( ) ; InputSource inputSource = new InputSource ( new StringReader ( xml ) ) ; return builder . parse ( inputSource ) ; } catch ( Exception e ) { throw new RuntimeException ( "Could not parse XML: " + xml ) ; } } class AtdRule extends Rule { @ Override public String getId ( ) { return "ATD_RULE" ; } @ Override public String getDescription ( ) { return "Result from remote After The Deadline server" ; } @ Override public RuleMatch [ ] match ( AnalyzedSentence sentence ) throws IOException { throw new RuntimeException ( "not implemented" ) ; } @ Override public void reset ( ) { } } }
package org . languagetool . dev . eval ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . IncorrectExample ; import org . languagetool . rules . Rule ; import org . languagetool . tools . StringTools ; import org . w3c . dom . Document ; import org . w3c . dom . NodeList ; import org . xml . sax . InputSource ; import javax . xml . parsers . DocumentBuilder ; import javax . xml . parsers . DocumentBuilderFactory ; import javax . xml . xpath . XPath ; import javax . xml . xpath . XPathConstants ; import javax . xml . xpath . XPathExpressionException ; import javax . xml . xpath . XPathFactory ; import java . io . IOException ; import java . io . InputStream ; import java . io . StringReader ; import java . net . URL ; import java . net . URLEncoder ; import java . util . ArrayList ; import java . util . List ; class AfterTheDeadlineEvaluator { private static final int WAIT_TIME_MILLIS = 1000 ; private final String urlPrefix ; AfterTheDeadlineEvaluator ( String urlPrefix ) { this . urlPrefix = urlPrefix ; } private void run ( Language lang ) throws IOException , InterruptedException { List < Rule > rules = getRules ( lang ) ; int sentenceCount = 0 ; int errorFoundCount = 0 ; System . out . println ( "Starting test for " + lang . getName ( ) + " on " + urlPrefix ) ; System . out . println ( "Wait time between HTTP requests: " + WAIT_TIME_MILLIS + "ms" ) ; System . out . println ( "Starting test on " + rules . size ( ) + " rules" ) ; for ( Rule rule : rules ) { if ( rule . isDefaultOff ( ) ) { System . out . println ( "Skipping rule that is off by default: " + rule . getId ( ) ) ; continue ; } List < IncorrectExample > incorrectExamples = rule . getIncorrectExamples ( ) ; System . out . println ( "\n" + rule . getId ( ) + ":" ) ; if ( incorrectExamples . size ( ) == 0 ) { System . out . println ( " (no examples)" ) ; continue ; } for ( IncorrectExample example : incorrectExamples ) { boolean match = queryAtDServer ( example ) ; sentenceCount ++ ; if ( match ) { errorFoundCount ++ ; } String marker = match ? "+" : "-" ; System . out . println ( " [" + marker + "] " + example . getExample ( ) . replace ( "<marker>" , "<m>" ) . replace ( "</marker>" , "</m>" ) ) ; Thread . sleep ( WAIT_TIME_MILLIS ) ; } } System . out . println ( "\nDone." ) ; System . out . println ( "Sentence count: " + sentenceCount ) ; float percentage = ( float ) errorFoundCount / sentenceCount * 100 ; System . out . printf ( "Expected errors found: " + errorFoundCount + " (%.2f%%)\n" , percentage ) ; } private List < Rule > getRules ( Language lang ) throws IOException { JLanguageTool langTool = new JLanguageTool ( lang ) ; return langTool . getAllActiveRules ( ) ; } private boolean queryAtDServer ( IncorrectExample example ) { String sentence = removeMarker ( example . getExample ( ) ) ; try { URL url = new URL ( urlPrefix + URLEncoder . encode ( sentence , "UTF-8" ) ) ; String result = getContent ( url ) ; if ( isExpectedErrorFound ( example , result ) ) { return true ; } } catch ( Exception e ) { throw new RuntimeException ( e ) ; } return false ; } private String removeMarker ( String sentence ) { return sentence . replace ( "<marker>" , "" ) . replace ( "</marker>" , "" ) ; } private String getContent ( URL url ) throws IOException { final InputStream contentStream = ( InputStream ) url . getContent ( ) ; return StringTools . streamToString ( contentStream , "UTF-8" ) ; } boolean isExpectedErrorFound ( IncorrectExample incorrectExample , String resultXml ) throws XPathExpressionException { String example = incorrectExample . getExample ( ) ; Document document = getDocument ( resultXml ) ; XPath xPath = XPathFactory . newInstance ( ) . newXPath ( ) ; NodeList errorStrings = ( NodeList ) xPath . evaluate ( "//string/text()" , document , XPathConstants . NODESET ) ; for ( int i = 0 ; i < errorStrings . getLength ( ) ; i ++ ) { String errorStr = errorStrings . item ( i ) . getNodeValue ( ) ; if ( errorStr . isEmpty ( ) ) { continue ; } List < Integer > errorStartPosList = getStartPositions ( incorrectExample , errorStr ) ; List < String > mismatches = new ArrayList < > ( ) ; for ( Integer errorStartPos : errorStartPosList ) { int errorEndPos = errorStartPos + errorStr . length ( ) ; int expectedErrorStartPos = example . indexOf ( "<marker>" ) ; int expectedErrorEndPos = errorStartPos + errorStr . length ( ) ; if ( errorStartPos == expectedErrorStartPos && errorEndPos == expectedErrorEndPos ) { return true ; } else { mismatches . add ( "Position mismatch: " + errorStartPos + "-" + errorEndPos + " != " + expectedErrorStartPos + "-" + expectedErrorEndPos ) ; } } for ( String mismatch : mismatches ) { System . out . println ( " " + mismatch ) ; } } return false ; } private List < Integer > getStartPositions ( IncorrectExample example , String searchStr ) { List < Integer > posList = new ArrayList < > ( ) ; int pos = 0 ; String sentence = removeMarker ( example . getExample ( ) ) ; while ( ( pos = sentence . indexOf ( searchStr , pos ) ) != - 1 ) { posList . add ( pos ) ; pos ++ ; } return posList ; } private Document getDocument ( String xml ) { try { DocumentBuilderFactory factory = DocumentBuilderFactory . newInstance ( ) ; DocumentBuilder builder = factory . newDocumentBuilder ( ) ; InputSource inputSource = new InputSource ( new StringReader ( xml ) ) ; return builder . parse ( inputSource ) ; } catch ( Exception e ) { throw new RuntimeException ( "Could not parse XML: " + xml ) ; } } public static void main ( String [ ] args ) throws Exception { if ( args . length != 2 ) { System . err . println ( "Usage: " + AfterTheDeadlineEvaluator . class . getSimpleName ( ) + " <langCode> <urlPrefix>" ) ; System . err . println ( " <urlPrefix> After the Deadline instance, e.g. 'http://de.service.afterthedeadline.com/checkDocument?key=test&data='" ) ; System . exit ( 1 ) ; } AfterTheDeadlineEvaluator evaluator = new AfterTheDeadlineEvaluator ( args [ 1 ] ) ; evaluator . run ( Languages . getLanguageForShortName ( args [ 0 ] ) ) ; } }
package org . languagetool . dev . eval ; import org . languagetool . JLanguageTool ; import org . languagetool . language . BritishEnglish ; import org . languagetool . language . English ; import org . languagetool . languagemodel . LanguageModel ; import org . languagetool . languagemodel . LuceneLanguageModel ; import org . languagetool . markup . AnnotatedText ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . en . EnglishConfusionProbabilityRule ; import java . io . File ; import java . io . IOException ; import java . util . List ; class LanguageToolEvaluator implements Evaluator { private final JLanguageTool langTool ; private final LanguageModel languageModel ; LanguageToolEvaluator ( File indexTopDir ) throws IOException { langTool = new JLanguageTool ( new BritishEnglish ( ) ) ; disableRules ( ) ; if ( indexTopDir != null ) { if ( indexTopDir . isDirectory ( ) ) { languageModel = new LuceneLanguageModel ( indexTopDir ) ; System . out . println ( "Using Lucene language model from " + languageModel ) ; EnglishConfusionProbabilityRule probabilityRule = new EnglishConfusionProbabilityRule ( JLanguageTool . getMessageBundle ( ) , languageModel , new English ( ) ) ; langTool . addRule ( probabilityRule ) ; } else { throw new RuntimeException ( "Does not exist or not a directory: " + indexTopDir ) ; } } else { languageModel = null ; } } @ Override public void close ( ) { if ( languageModel != null ) { languageModel . close ( ) ; } } private void disableRules ( ) { langTool . disableRule ( "COMMA_PARENTHESIS_WHITESPACE" ) ; langTool . disableRule ( "SENT_START_CONJUNCTIVE_LINKING_ADVERB_COMMA" ) ; langTool . disableRule ( "EN_QUOTES" ) ; langTool . disableRule ( "I_LOWERCASE" ) ; langTool . disableRule ( "LITTLE_BIT" ) ; langTool . disableRule ( "ALL_OF_THE" ) ; langTool . disableRule ( "SOME_OF_THE" ) ; langTool . disableRule ( "EN_GB_SIMPLE_REPLACE" ) ; langTool . disableRule ( "APARTMENT-FLAT" ) ; } @ Override public List < RuleMatch > check ( AnnotatedText annotatedText ) throws IOException { return langTool . check ( annotatedText ) ; } }
package org . languagetool . dev . eval ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . util . List ; import org . languagetool . JLanguageTool ; import org . languagetool . commandline . CommandLineTools ; import org . languagetool . language . English ; import org . languagetool . tokenizers . Tokenizer ; import org . languagetool . tools . StringTools ; public final class CheckBNC { private JLanguageTool langTool = null ; private final BNCTextFilter textFilter = new BNCTextFilter ( ) ; private static final boolean CHECK_BY_SENTENCE = true ; public static void main ( String [ ] args ) throws Exception { if ( args . length != 1 ) { System . out . println ( "Usage: CheckBNC <directory>" ) ; System . exit ( 1 ) ; } final CheckBNC prg = new CheckBNC ( ) ; prg . run ( new File ( args [ 0 ] ) ) ; } private CheckBNC ( ) throws IOException { langTool = new JLanguageTool ( new English ( ) ) ; final String [ ] disRules = { "UPPERCASE_SENTENCE_START" , "COMMA_PARENTHESIS_WHITESPACE" , "WORD_REPEAT_RULE" , "DOUBLE_PUNCTUATION" } ; System . err . println ( "Note: disabling the following rules:" ) ; for ( String disRule : disRules ) { langTool . disableRule ( disRule ) ; System . err . println ( " " + disRule ) ; } } private void run ( final File file ) throws IOException { if ( file . isDirectory ( ) ) { final File [ ] files = file . listFiles ( ) ; for ( File file1 : files ) { run ( new File ( file , file1 . getName ( ) ) ) ; } } else { System . out . println ( "Checking " + file . getAbsolutePath ( ) ) ; String text = StringTools . readStream ( new FileInputStream ( file . getAbsolutePath ( ) ) , "utf-8" ) ; text = textFilter . filter ( text ) ; if ( CHECK_BY_SENTENCE ) { final Tokenizer sentenceTokenizer = langTool . getLanguage ( ) . getSentenceTokenizer ( ) ; final List < String > sentences = sentenceTokenizer . tokenize ( text ) ; for ( String sentence : sentences ) { CommandLineTools . checkText ( sentence , langTool , false , 1000 ) ; } } else { CommandLineTools . checkText ( text , langTool ) ; } } } class BNCTextFilter { public String filter ( String text ) { String fText = text . replaceAll ( "(?s)<header.*?>.*?</header>" , "" ) ; fText = fText . replaceAll ( "<w.*?>" , "" ) ; fText = fText . replaceAll ( "<c.*?>" , "" ) ; fText = fText . replaceAll ( "<.*?>" , "" ) ; fText = fText . replaceAll ( " +" , " " ) ; fText = fText . replaceAll ( "&bquo|&equo" , "\"" ) ; fText = fText . replaceAll ( "&mdash;?" , "--" ) ; fText = fText . replaceAll ( "&amp;?" , "&" ) ; return fText ; } } }
package org . languagetool . dev . eval ; public final class FMeasure { private FMeasure ( ) { } public static double getWeightedFMeasure ( float precision , float recall ) { return getFMeasure ( precision , recall , 0.5f ) ; } public static double getFMeasure ( float precision , float recall , float beta ) { double betaSquared = Math . pow ( beta , 2 ) ; return ( 1 + betaSquared ) * ( precision * recall ) / ( ( betaSquared * precision ) + recall ) ; } }
package org . languagetool . dev . eval ; import org . languagetool . markup . AnnotatedText ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . List ; interface Evaluator { List < RuleMatch > check ( AnnotatedText annotatedText ) throws IOException ; void close ( ) ; }
package org . languagetool . dev . eval ; import org . languagetool . dev . errorcorpus . ErrorCorpus ; import org . languagetool . dev . errorcorpus . ErrorSentence ; import org . languagetool . dev . errorcorpus . PedlerCorpus ; import org . languagetool . rules . RuleMatch ; import java . io . File ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; class RealWordCorpusEvaluator { private final Evaluator checker ; private final List < String > badConfusionMatchWords = new ArrayList < > ( ) ; private int sentenceCount ; private int errorsInCorpusCount ; private int perfectMatches ; private int goodMatches ; private int matchCount ; private int perfectConfusionMatches ; private int goodConfusionMatches ; private int badConfusionMatches ; RealWordCorpusEvaluator ( File indexTopDir ) throws IOException { checker = new LanguageToolEvaluator ( indexTopDir ) ; } void close ( ) { checker . close ( ) ; } int getSentencesChecked ( ) { return sentenceCount ; } int getErrorsChecked ( ) { return errorsInCorpusCount ; } int getRealErrorsFound ( ) { return goodMatches ; } int getRealErrorsFoundWithGoodSuggestion ( ) { return perfectMatches ; } void run ( File dir ) throws IOException { System . out . println ( "Output explanation:" ) ; System . out . println ( " [ ] = this is not an expected error" ) ; System . out . println ( " [+ ] = this is an expected error" ) ; System . out . println ( " [++] = this is an expected error and the first suggestion is correct" ) ; System . out . println ( " [//] = not counted because already matches by a different rule" ) ; System . out . println ( "" ) ; ErrorCorpus corpus = new PedlerCorpus ( dir ) ; checkLines ( corpus ) ; printResults ( ) ; } private void checkLines ( ErrorCorpus corpus ) throws IOException { for ( ErrorSentence sentence : corpus ) { List < RuleMatch > matches = checker . check ( sentence . getAnnotatedText ( ) ) ; sentenceCount ++ ; errorsInCorpusCount += sentence . getErrors ( ) . size ( ) ; System . out . println ( sentence . getMarkupText ( ) + " => " + matches . size ( ) ) ; List < Span > detectedErrorPositions = new ArrayList < > ( ) ; for ( RuleMatch match : matches ) { boolean alreadyCounted = errorAlreadyCounted ( match , detectedErrorPositions ) ; if ( ! alreadyCounted && sentence . hasErrorCoveredByMatchAndGoodFirstSuggestion ( match ) ) { goodMatches ++ ; perfectMatches ++ ; matchCount ++ ; if ( isConfusionRule ( match ) ) { perfectConfusionMatches ++ ; } System . out . println ( " [++] " + match + ": " + match . getSuggestedReplacements ( ) ) ; } else if ( ! alreadyCounted && sentence . hasErrorCoveredByMatch ( match ) ) { goodMatches ++ ; matchCount ++ ; if ( isConfusionRule ( match ) ) { goodConfusionMatches ++ ; } System . out . println ( " [+ ] " + match + ": " + match . getSuggestedReplacements ( ) ) ; } else if ( alreadyCounted ) { System . out . println ( " [//] " + match + ": " + match . getSuggestedReplacements ( ) ) ; } else { System . out . println ( " [ ] " + match + ": " + match . getSuggestedReplacements ( ) ) ; matchCount ++ ; if ( isConfusionRule ( match ) ) { badConfusionMatches ++ ; badConfusionMatchWords . add ( sentence . getMarkupText ( ) . substring ( match . getFromPos ( ) , match . getToPos ( ) ) ) ; } } detectedErrorPositions . add ( new Span ( match . getFromPos ( ) , match . getToPos ( ) ) ) ; } } } private boolean isConfusionRule ( RuleMatch match ) { return match . getRule ( ) . getId ( ) . equals ( "CONFUSION_RULE" ) ; } private void printResults ( ) { System . out . println ( "" ) ; System . out . println ( sentenceCount + " lines checked with " + errorsInCorpusCount + " errors." ) ; System . out . println ( "Confusion rule matches: " + perfectConfusionMatches + " perfect, " + goodConfusionMatches + " good, " + badConfusionMatches + " bad (" + badConfusionMatchWords + ")" ) ; System . out . println ( "\nCounting matches, no matter whether the first suggestion is correct:" ) ; System . out . print ( " " + goodMatches + " out of " + matchCount + " matches are real errors" ) ; float goodPrecision = ( float ) goodMatches / matchCount ; float goodRecall = ( float ) goodMatches / errorsInCorpusCount ; System . out . printf ( " => %.2f precision, %.2f recall\n" , goodPrecision , goodRecall ) ; System . out . printf ( " => %.4f F(0.5) measure\n" , FMeasure . getWeightedFMeasure ( goodPrecision , goodRecall ) ) ; System . out . println ( "\nCounting only matches with a perfect first suggestion:" ) ; System . out . print ( " " + perfectMatches + " out of " + matchCount + " matches are real errors" ) ; float perfectPrecision = ( float ) perfectMatches / matchCount ; float perfectRecall = ( float ) perfectMatches / errorsInCorpusCount ; System . out . printf ( " => %.2f precision, %.2f recall\n" , perfectPrecision , perfectRecall ) ; System . out . printf ( " => %.4f F(0.5) measure\n" , FMeasure . getWeightedFMeasure ( perfectPrecision , perfectRecall ) ) ; } private boolean errorAlreadyCounted ( RuleMatch match , List < Span > detectedErrorPositions ) { for ( Span span : detectedErrorPositions ) { Span matchSpan = new Span ( match . getFromPos ( ) , match . getToPos ( ) ) ; if ( span . covers ( matchSpan ) || matchSpan . covers ( span ) ) { return true ; } } return false ; } public static void main ( String [ ] args ) throws IOException { if ( args . length != 1 && args . length != 2 ) { System . out . println ( "Usage: " + RealWordCorpusEvaluator . class . getSimpleName ( ) + " <corpusDirectory> [languageModel]" ) ; System . out . println ( " [languageModel] is a morfologik file or Lucene index directory with ngram frequency information (optional)" ) ; System . exit ( 1 ) ; } if ( args . length == 1 ) { System . out . println ( "Running without language model" ) ; RealWordCorpusEvaluator evaluator = new RealWordCorpusEvaluator ( null ) ; evaluator . run ( new File ( args [ 0 ] ) ) ; evaluator . close ( ) ; } else { File languageModelTopDir = new File ( args [ 1 ] ) ; System . out . println ( "Running with language model from " + languageModelTopDir ) ; RealWordCorpusEvaluator evaluator = new RealWordCorpusEvaluator ( languageModelTopDir ) ; evaluator . run ( new File ( args [ 0 ] ) ) ; evaluator . close ( ) ; } } class Span { private final int startPos ; private final int endPos ; Span ( int startPos , int endPos ) { this . startPos = startPos ; this . endPos = endPos ; } boolean covers ( Span other ) { return startPos <= other . startPos && endPos >= other . endPos ; } } }
package org . languagetool . dev . eval ; import org . apache . commons . io . IOUtils ; import org . languagetool . JLanguageTool ; import org . languagetool . language . BritishEnglish ; import org . languagetool . language . English ; import org . languagetool . languagemodel . LanguageModel ; import org . languagetool . languagemodel . LuceneLanguageModel ; import org . languagetool . rules . * ; import org . languagetool . rules . en . EnglishConfusionProbabilityRule ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . io . InputStream ; import java . util . * ; class RealWordFalseAlarmEvaluator { private static final boolean EVAL_MODE = true ; private static final int MAX_SENTENCES = 1000 ; private static final int MAX_ERROR_DISPLAY = 50 ; private static final int MIN_SENTENCES = 0 ; private static final float MAX_ERROR_RATE = 10 ; private final JLanguageTool langTool ; private final ConfusionProbabilityRule confusionRule ; private final Map < String , List < ConfusionSet > > confusionSets ; private final LanguageModel languageModel ; private int globalSentenceCount ; private int globalRuleMatches ; RealWordFalseAlarmEvaluator ( File languageModelIndexDir ) throws IOException { try ( InputStream inputStream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( "/en/confusion_sets.txt" ) ) { ConfusionSetLoader confusionSetLoader = new ConfusionSetLoader ( ) ; confusionSets = confusionSetLoader . loadConfusionSet ( inputStream ) ; } langTool = new JLanguageTool ( new BritishEnglish ( ) ) ; List < Rule > rules = langTool . getAllActiveRules ( ) ; for ( Rule rule : rules ) { langTool . disableRule ( rule . getId ( ) ) ; } languageModel = new LuceneLanguageModel ( languageModelIndexDir ) ; confusionRule = new EnglishConfusionProbabilityRule ( JLanguageTool . getMessageBundle ( ) , languageModel , new English ( ) ) ; langTool . addRule ( confusionRule ) ; } void close ( ) { if ( languageModel != null ) { languageModel . close ( ) ; } } void run ( File dir ) throws IOException { if ( EVAL_MODE ) { System . out . println ( "Running in eval mode, no 'DATA' lines will be printed, only a subset of the homophones will be used." ) ; } else { System . out . println ( "grep for '^DATA;' to get results in CVS format:" ) ; System . out . println ( "DATA;word;sentence_count;errors_found;errors_percent" ) ; } File [ ] files = dir . listFiles ( ) ; int fileCount = 1 ; for ( File file : files ) { if ( ! file . getName ( ) . endsWith ( ".txt" ) ) { System . out . println ( "Ignoring " + file + ", does not match *.txt" ) ; continue ; } try ( FileInputStream fis = new FileInputStream ( file ) ) { System . out . println ( "===== Working on " + file . getName ( ) + " (" + fileCount + "/" + files . length + ") =====" ) ; checkLines ( IOUtils . readLines ( fis ) , file . getName ( ) . replace ( ".txt" , "" ) ) ; fileCount ++ ; } } System . out . println ( "==============================" ) ; System . out . println ( globalSentenceCount + " sentences checked" ) ; System . out . println ( globalRuleMatches + " errors found" ) ; float percentage = ( float ) globalRuleMatches / ( float ) globalSentenceCount * 100 ; System . out . printf ( "%.2f%% of sentences have a match\n" , percentage ) ; } private void checkLines ( List < String > lines , String name ) throws IOException { List < ConfusionSet > subConfusionSet = confusionSets . get ( name ) ; if ( subConfusionSet == null ) { System . out . println ( "Skipping '" + name + "', homophone not loaded" ) ; return ; } if ( subConfusionSet . size ( ) > 1 ) { System . err . println ( "WARN: will only use first confusion set of " + subConfusionSet . size ( ) + ": " + subConfusionSet . get ( 0 ) ) ; } confusionRule . setConfusionSet ( subConfusionSet . get ( 0 ) ) ; int sentenceCount = 0 ; int ruleMatches = 0 ; for ( String line : lines ) { List < RuleMatch > matches = langTool . check ( line ) ; sentenceCount ++ ; globalSentenceCount ++ ; if ( matches . size ( ) > 0 ) { Set < String > suggestions = new HashSet < > ( ) ; for ( RuleMatch match : matches ) { suggestions . addAll ( match . getSuggestedReplacements ( ) ) ; ruleMatches ++ ; globalRuleMatches ++ ; } if ( ruleMatches <= MAX_ERROR_DISPLAY ) { System . out . println ( "[" + name + "] " + line + " => " + suggestions ) ; } } if ( sentenceCount > MAX_SENTENCES ) { System . out . println ( "Max sentences (" + MAX_SENTENCES + ") reached, stopping" ) ; break ; } } System . out . println ( sentenceCount + " sentences checked" ) ; System . out . println ( ruleMatches + " errors found" ) ; float percentage = ( float ) ruleMatches / ( float ) sentenceCount * 100 ; System . out . printf ( "%.2f%% of sentences have a match\n" , percentage ) ; if ( ! EVAL_MODE ) { System . out . printf ( Locale . ENGLISH , "DATA;%s;%d;%d;%.2f\n\n" , name , sentenceCount , ruleMatches , percentage ) ; } } public static void main ( String [ ] args ) throws IOException { if ( args . length != 2 ) { System . out . println ( "Usage: " + RealWordFalseAlarmEvaluator . class . getSimpleName ( ) + " <languageModel> <sentenceDirectory>" ) ; System . out . println ( " <languageModel> is a Lucene index with ngram frequency information" ) ; System . out . println ( " <sentenceDirectory> is a directory with filenames like 'xx.txt' where 'xx' is the homophone" ) ; System . exit ( 1 ) ; } RealWordFalseAlarmEvaluator evaluator = new RealWordFalseAlarmEvaluator ( new File ( args [ 0 ] ) ) ; File dir = new File ( args [ 1 ] ) ; if ( ! dir . isDirectory ( ) ) { throw new RuntimeException ( "Not a directory: " + dir ) ; } evaluator . run ( dir ) ; evaluator . close ( ) ; } }
package org . languagetool . dev . eval ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import java . io . * ; import java . util . List ; public class SpellCheckEvaluation { private static final int MAX_SUGGESTIONS = 5 ; private void run ( Language language , File file ) throws IOException { JLanguageTool lt = getLanguageToolForSpellCheck ( language ) ; checkFile ( file , lt ) ; } private JLanguageTool getLanguageToolForSpellCheck ( Language language ) { JLanguageTool lt = new JLanguageTool ( language ) ; for ( Rule rule : lt . getAllActiveRules ( ) ) { if ( ! rule . isDictionaryBasedSpellingRule ( ) ) { lt . disableRule ( rule . getId ( ) ) ; } } return lt ; } private void checkFile ( File file , JLanguageTool lt ) throws IOException { try ( FileInputStream fis = new FileInputStream ( file ) ; InputStreamReader reader = new InputStreamReader ( fis , "utf-8" ) ; BufferedReader br = new BufferedReader ( reader ) ) { String line ; while ( ( line = br . readLine ( ) ) != null ) { List < RuleMatch > matches = lt . check ( line ) ; for ( RuleMatch match : matches ) { String covered = line . substring ( match . getFromPos ( ) , match . getToPos ( ) ) ; List < String > suggestions = match . getSuggestedReplacements ( ) ; List < String > limitedSuggestions = suggestions . subList ( 0 , Math . min ( MAX_SUGGESTIONS , suggestions . size ( ) ) ) ; System . out . println ( covered + ": " + limitedSuggestions ) ; } } } } public static void main ( String [ ] args ) throws IOException { if ( args . length != 2 ) { System . out . println ( "Usage: " + SpellCheckEvaluation . class . getSimpleName ( ) + " <langCode> <textFile>" ) ; System . exit ( 1 ) ; } SpellCheckEvaluation eval = new SpellCheckEvaluation ( ) ; eval . run ( Languages . getLanguageForShortName ( args [ 0 ] ) , new File ( args [ 1 ] ) ) ; } }
package org . languagetool . dev . errorcorpus ; import org . languagetool . markup . AnnotatedText ; import org . languagetool . rules . RuleMatch ; import java . util . List ; public class ErrorSentence { private final String markupText ; private final AnnotatedText annotatedText ; private final List < Error > errors ; ErrorSentence ( String markupText , AnnotatedText annotatedText , List < Error > errors ) { this . markupText = markupText ; this . annotatedText = annotatedText ; this . errors = errors ; } public boolean hasErrorCoveredByMatchAndGoodFirstSuggestion ( RuleMatch match ) { if ( hasErrorCoveredByMatch ( match ) ) { List < String > suggestion = match . getSuggestedReplacements ( ) ; if ( suggestion . size ( ) > 0 ) { String firstSuggestion = suggestion . get ( 0 ) ; for ( Error error : errors ) { String correctedByCorpus = error . getAppliedCorrection ( markupText ) ; String correctedByRuleMarkup = markupText . substring ( 0 , match . getFromPos ( ) ) + match . getSuggestedReplacements ( ) . get ( 0 ) + markupText . substring ( match . getToPos ( ) ) ; String correctedByRule = correctedByRuleMarkup . replaceAll ( "<.*?>" , "" ) ; if ( correctedByRule . equals ( correctedByCorpus ) ) { return true ; } if ( error . getCorrection ( ) . equalsIgnoreCase ( firstSuggestion ) ) { return true ; } } } } return false ; } public boolean hasErrorCoveredByMatch ( RuleMatch match ) { for ( Error error : errors ) { if ( match . getFromPos ( ) <= error . getStartPos ( ) && match . getToPos ( ) >= error . getEndPos ( ) ) { return true ; } } return false ; } public String getMarkupText ( ) { return markupText ; } public AnnotatedText getAnnotatedText ( ) { return annotatedText ; } public List < Error > getErrors ( ) { return errors ; } @ Override public String toString ( ) { return markupText ; } }
package org . languagetool . synthesis . ro ; import java . io . IOException ; import java . io . InputStream ; import java . util . List ; import org . languagetool . JLanguageTool ; import org . languagetool . synthesis . BaseSynthesizer ; import org . languagetool . synthesis . ManualSynthesizer ; public class RomanianSynthesizer extends BaseSynthesizer { private static final String RESOURCE_FILENAME = "/ro/romanian_synth.dict" ; private static final String TAGS_FILE_NAME = "/ro/romanian_tags.txt" ; private static final String USER_DICT_FILENAME = "/ro/added.txt" ; private static ManualSynthesizer manualSynthesizer ; public RomanianSynthesizer ( ) { super ( RESOURCE_FILENAME , TAGS_FILE_NAME ) ; } @ Override protected void lookup ( String lemma , String posTag , List < String > results ) { super . lookup ( lemma , posTag , results ) ; initSynth ( ) ; final List < String > manualForms = manualSynthesizer . lookup ( lemma , posTag ) ; if ( manualForms != null ) { results . addAll ( manualForms ) ; } } @ Override protected void initPossibleTags ( ) throws IOException { super . initPossibleTags ( ) ; initSynth ( ) ; for ( String tag : manualSynthesizer . getPossibleTags ( ) ) { if ( ! possibleTags . contains ( tag ) ) { possibleTags . add ( tag ) ; } } } private void initSynth ( ) { if ( manualSynthesizer == null ) { try { try ( InputStream stream = JLanguageTool . getDataBroker ( ) . getFromResourceDirAsStream ( USER_DICT_FILENAME ) ) { manualSynthesizer = new ManualSynthesizer ( stream ) ; } } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } } }
package org . languagetool . dev . errorcorpus ; public interface ErrorCorpus extends Iterable < ErrorSentence > { }
package org . languagetool . dev . errorcorpus ; public class Error { private final int startPos ; private final int endPos ; private final String correction ; Error ( int startPos , int endPos , String correction ) { this . startPos = startPos ; this . endPos = endPos ; this . correction = correction ; } public int getStartPos ( ) { return startPos ; } public int getEndPos ( ) { return endPos ; } public String getCorrection ( ) { return correction ; } public String getAppliedCorrection ( String markupText ) { String correctionApplied = markupText . substring ( 0 , startPos ) + correction + markupText . substring ( endPos ) ; return correctionApplied . replaceAll ( "<.*?>" , "" ) ; } @ Override public String toString ( ) { return startPos + "-" + endPos + ":" + correction ; } }
package org . languagetool . dev . errorcorpus ; import org . apache . commons . io . IOUtils ; import org . languagetool . markup . AnnotatedText ; import org . languagetool . markup . AnnotatedTextBuilder ; import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Iterator ; import java . util . List ; import java . util . StringTokenizer ; public class PedlerCorpus implements ErrorCorpus { private static final String NORMALIZE_REGEX = "\\s*<ERR targ\\s*=\\s*([^>]*?)\\s*>\\s*(.*?)\\s*</ERR>\\s*" ; private final List < String > lines = new ArrayList < > ( ) ; private int pos ; public PedlerCorpus ( File dir ) throws IOException { File [ ] files = dir . listFiles ( ) ; if ( files == null ) { throw new RuntimeException ( "Directory not found: " + dir ) ; } for ( File file : files ) { if ( ! file . getName ( ) . endsWith ( ".txt" ) ) { System . out . println ( "Ignoring " + file + ", does not match *.txt" ) ; continue ; } try ( FileInputStream fis = new FileInputStream ( file ) ) { lines . addAll ( IOUtils . readLines ( fis ) ) ; } } } @ Override public Iterator < ErrorSentence > iterator ( ) { return new Iterator < ErrorSentence > ( ) { @ Override public boolean hasNext ( ) { return pos < lines . size ( ) ; } @ Override public ErrorSentence next ( ) { String line = lines . get ( pos ++ ) ; ErrorSentence sentence = getIncorrectSentence ( line ) ; return sentence ; } @ Override public void remove ( ) { throw new UnsupportedOperationException ( ) ; } } ; } private ErrorSentence getIncorrectSentence ( String line ) { String normalized = line . replaceAll ( NORMALIZE_REGEX , " <ERR targ=$1>$2</ERR> " ) . replaceAll ( "\\s+" , " " ) . trim ( ) ; List < Error > errors = new ArrayList < > ( ) ; int startPos = 0 ; while ( normalized . indexOf ( "<ERR targ=" , startPos ) != - 1 ) { int startTagStart = normalized . indexOf ( "<ERR targ=" , startPos ) ; int startTagEnd = normalized . indexOf ( ">" , startTagStart ) ; int endTagStart = normalized . indexOf ( "</ERR>" , startTagStart ) ; int correctionEnd = normalized . indexOf ( ">" , startTagStart ) ; String correction = normalized . substring ( startTagStart + "<ERR targ=" . length ( ) , correctionEnd ) ; errors . add ( new Error ( startTagEnd + 1 , endTagStart , correction ) ) ; startPos = startTagStart + 1 ; } return new ErrorSentence ( normalized , makeAnnotatedText ( normalized ) , errors ) ; } private AnnotatedText makeAnnotatedText ( String pseudoXml ) { AnnotatedTextBuilder builder = new AnnotatedTextBuilder ( ) ; StringTokenizer tokenizer = new StringTokenizer ( pseudoXml , "<>" , true ) ; boolean inMarkup = false ; while ( tokenizer . hasMoreTokens ( ) ) { String part = tokenizer . nextToken ( ) ; if ( part . startsWith ( "<" ) ) { builder . addMarkup ( part ) ; inMarkup = true ; } else if ( part . startsWith ( ">" ) ) { inMarkup = false ; builder . addMarkup ( part ) ; } else { if ( inMarkup ) { builder . addMarkup ( part ) ; } else { builder . addText ( part ) ; } } } return builder . build ( ) ; } }
package net . boplicity . xmleditor ; import java . awt . Color ; import java . awt . Graphics ; import java . util . HashMap ; import java . util . LinkedHashMap ; import java . util . Map ; import java . util . SortedMap ; import java . util . TreeMap ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import javax . swing . text . BadLocationException ; import javax . swing . text . Document ; import javax . swing . text . Element ; import javax . swing . text . PlainDocument ; import javax . swing . text . PlainView ; import javax . swing . text . Segment ; import javax . swing . text . Utilities ; public class XmlView extends PlainView { private static HashMap < Pattern , Color > patternColors ; private static String GENERIC_XML_NAME = "[A-Za-z]+[A-Za-z0-9\\-_]*(:[A-Za-z]+[A-Za-z0-9\\-_]+)?" ; private static String TAG_PATTERN = "(</?" + GENERIC_XML_NAME + ")" ; private static String TAG_END_PATTERN = "(>|/>)" ; private static String TAG_ATTRIBUTE_PATTERN = "(" + GENERIC_XML_NAME + ")\\w*\\=" ; private static String TAG_ATTRIBUTE_VALUE = "\\w*\\=\\w*(\"[^\"]*\")" ; private static String TAG_COMMENT = "(<\\!--[\\w ]*-->)" ; private static String TAG_CDATA = "(<\\!\\[CDATA\\[.*\\]\\]>)" ; static { patternColors = new LinkedHashMap < > ( ) ; patternColors . put ( Pattern . compile ( TAG_PATTERN ) , new Color ( 63 , 127 , 127 ) ) ; patternColors . put ( Pattern . compile ( TAG_CDATA ) , Color . GRAY ) ; patternColors . put ( Pattern . compile ( TAG_ATTRIBUTE_PATTERN ) , new Color ( 127 , 0 , 127 ) ) ; patternColors . put ( Pattern . compile ( TAG_END_PATTERN ) , new Color ( 63 , 127 , 127 ) ) ; patternColors . put ( Pattern . compile ( TAG_ATTRIBUTE_VALUE ) , new Color ( 42 , 0 , 255 ) ) ; patternColors . put ( Pattern . compile ( TAG_COMMENT ) , Color . BLUE ) ; } public XmlView ( Element element ) { super ( element ) ; getDocument ( ) . putProperty ( PlainDocument . tabSizeAttribute , 4 ) ; } @ Override protected int drawUnselectedText ( Graphics graphics , int x , int y , int p0 , int p1 ) throws BadLocationException { Document doc = getDocument ( ) ; String text = doc . getText ( p0 , p1 - p0 ) ; Segment segment = getLineBuffer ( ) ; SortedMap < Integer , Integer > startMap = new TreeMap < > ( ) ; SortedMap < Integer , Color > colorMap = new TreeMap < > ( ) ; for ( Map . Entry < Pattern , Color > entry : patternColors . entrySet ( ) ) { Matcher matcher = entry . getKey ( ) . matcher ( text ) ; while ( matcher . find ( ) ) { startMap . put ( matcher . start ( 1 ) , matcher . end ( ) ) ; colorMap . put ( matcher . start ( 1 ) , entry . getValue ( ) ) ; } } int i = 0 ; for ( Map . Entry < Integer , Integer > entry : startMap . entrySet ( ) ) { int start = entry . getKey ( ) ; int end = entry . getValue ( ) ; if ( i < start ) { graphics . setColor ( Color . black ) ; doc . getText ( p0 + i , start - i , segment ) ; x = Utilities . drawTabbedText ( segment , x , y , graphics , this , i ) ; } graphics . setColor ( colorMap . get ( start ) ) ; i = end ; doc . getText ( p0 + start , i - start , segment ) ; x = Utilities . drawTabbedText ( segment , x , y , graphics , this , start ) ; } if ( i < text . length ( ) ) { graphics . setColor ( Color . black ) ; doc . getText ( p0 + i , text . length ( ) - i , segment ) ; x = Utilities . drawTabbedText ( segment , x , y , graphics , this , i ) ; } return x ; } }
package net . boplicity . xmleditor ; import java . awt . GridLayout ; import javax . swing . JFrame ; import javax . swing . JPanel ; public class XmlEditor extends JFrame { private static final long serialVersionUID = 2623631186455160679L ; public static void main ( String [ ] args ) { XmlEditor xmlEditor = new XmlEditor ( ) ; xmlEditor . setVisible ( true ) ; } public XmlEditor ( ) { super ( "XML Text Editor Demo" ) ; setSize ( 800 , 600 ) ; JPanel panel = new JPanel ( ) ; panel . setLayout ( new GridLayout ( ) ) ; XmlTextPane xmlTextPane = new XmlTextPane ( ) ; panel . add ( xmlTextPane ) ; add ( panel ) ; } }
package net . boplicity . xmleditor ; import javax . swing . text . Element ; import javax . swing . text . View ; import javax . swing . text . ViewFactory ; public class XmlViewFactory extends Object implements ViewFactory { public View create ( Element element ) { return new XmlView ( element ) ; } }
package net . boplicity . xmleditor ; import javax . swing . text . StyledEditorKit ; import javax . swing . text . ViewFactory ; public class XmlEditorKit extends StyledEditorKit { private static final long serialVersionUID = 2969169649596107757L ; private ViewFactory xmlViewFactory ; public XmlEditorKit ( ) { xmlViewFactory = new XmlViewFactory ( ) ; } @ Override public ViewFactory getViewFactory ( ) { return xmlViewFactory ; } @ Override public String getContentType ( ) { return "text/xml" ; } }
package net . boplicity . xmleditor ; import java . awt . event . KeyEvent ; import java . awt . event . KeyListener ; import java . util . logging . Level ; import java . util . logging . Logger ; import javax . swing . JTextPane ; import javax . swing . text . BadLocationException ; import net . boplicity . xmleditor . XmlEditorKit ; public class XmlTextPane extends JTextPane { private static final long serialVersionUID = 6270183148379328084L ; private Logger logger = Logger . getLogger ( getClass ( ) . getName ( ) ) ; public XmlTextPane ( ) { this . setEditorKitForContentType ( "text/xml" , new XmlEditorKit ( ) ) ; this . setContentType ( "text/xml" ) ; addKeyListener ( new IndentKeyListener ( ) ) ; } private class IndentKeyListener implements KeyListener { private boolean enterFlag ; private final Character NEW_LINE = '\n' ; public void keyPressed ( KeyEvent event ) { enterFlag = false ; if ( ( event . getKeyCode ( ) == KeyEvent . VK_ENTER ) && ( event . getModifiers ( ) == 0 ) ) { if ( getSelectionStart ( ) == getSelectionEnd ( ) ) { enterFlag = true ; event . consume ( ) ; } } } public void keyReleased ( KeyEvent event ) { if ( ( event . getKeyCode ( ) == KeyEvent . VK_ENTER ) && ( event . getModifiers ( ) == 0 ) ) { if ( enterFlag ) { event . consume ( ) ; int start , end ; String text = getText ( ) ; int caretPosition = getCaretPosition ( ) ; try { if ( text . charAt ( caretPosition ) == NEW_LINE ) { caretPosition -- ; } } catch ( IndexOutOfBoundsException e ) { } start = text . lastIndexOf ( NEW_LINE , caretPosition ) + 1 ; end = start ; try { if ( text . charAt ( start ) != NEW_LINE ) { while ( ( end < text . length ( ) ) && ( Character . isWhitespace ( text . charAt ( end ) ) ) && ( text . charAt ( end ) != NEW_LINE ) ) { end ++ ; } if ( end > start ) { getDocument ( ) . insertString ( getCaretPosition ( ) , NEW_LINE + text . substring ( start , end ) , null ) ; } else { getDocument ( ) . insertString ( getCaretPosition ( ) , NEW_LINE . toString ( ) , null ) ; } } else { getDocument ( ) . insertString ( getCaretPosition ( ) , NEW_LINE . toString ( ) , null ) ; } } catch ( IndexOutOfBoundsException e ) { try { getDocument ( ) . insertString ( getCaretPosition ( ) , NEW_LINE . toString ( ) , null ) ; } catch ( BadLocationException e1 ) { logger . log ( Level . WARNING , e1 . toString ( ) ) ; } } catch ( BadLocationException e ) { logger . log ( Level . WARNING , e . toString ( ) ) ; } } } } public void keyTyped ( KeyEvent e ) { } } }
package org . languagetool . openoffice ; import junit . framework . TestCase ; import com . sun . star . beans . PropertyValue ; import com . sun . star . lang . Locale ; import com . sun . star . linguistic2 . ProofreadingResult ; public class MainTest extends TestCase { public void testDoProofreading ( ) { final Main prog = new Main ( null ) ; Main . setTestMode ( true ) ; final String testString = "To jest trudne zdanie. A to następne. A to przedostatnie jest.\u0002 Test ostatniego." ; final Locale plLoc = new Locale ( "pl" , "PL" , "" ) ; final PropertyValue [ ] prop = new PropertyValue [ 0 ] ; for ( int i = 0 ; i <= testString . length ( ) ; i ++ ) { final ProofreadingResult paRes = prog . doProofreading ( "1" , testString , plLoc , i , testString . length ( ) , prop ) ; assertEquals ( "1" , paRes . aDocumentIdentifier ) ; assertTrue ( paRes . nStartOfNextSentencePosition >= i ) ; if ( i < "To jest trudne zdanie. " . length ( ) ) { assertEquals ( "To jest trudne zdanie. " . length ( ) , paRes . nStartOfNextSentencePosition ) ; assertEquals ( 0 , paRes . nStartOfSentencePosition ) ; } } final ProofreadingResult paRes1 = prog . doProofreading ( "1" , testString , plLoc , 0 , testString . length ( ) , prop ) ; assertEquals ( "1" , paRes1 . aDocumentIdentifier ) ; assertEquals ( 23 , paRes1 . nStartOfNextSentencePosition ) ; assertEquals ( 0 , paRes1 . nStartOfSentencePosition ) ; final String testString2 = "To jest „nowy problem”. A to inny jeszcze( „problem. Co jest „?" ; final ProofreadingResult paRes2 = prog . doProofreading ( "1" , testString2 , plLoc , 0 , testString2 . length ( ) , prop ) ; assertEquals ( "1" , paRes2 . aDocumentIdentifier ) ; assertEquals ( 24 , paRes2 . nStartOfNextSentencePosition ) ; assertEquals ( 0 , paRes2 . nStartOfSentencePosition ) ; } public void testVariants ( ) { final Main prog = new Main ( null ) ; Main . setTestMode ( true ) ; final String testString = "Sigui quina siga la teva intenció. Això és una prova." ; final Locale cavaLoc = new Locale ( "qlt" , "ES" , "ca-ES-valencia" ) ; final PropertyValue [ ] prop = new PropertyValue [ 0 ] ; for ( int i = 0 ; i <= testString . length ( ) ; i ++ ) { final ProofreadingResult paRes = prog . doProofreading ( "1" , testString , cavaLoc , i , testString . length ( ) , prop ) ; assertEquals ( "1" , paRes . aDocumentIdentifier ) ; assertTrue ( paRes . nStartOfNextSentencePosition >= i ) ; if ( i < "Sigui quina siga la teva intenció. " . length ( ) ) { assertEquals ( "Sigui quina siga la teva intenció. " . length ( ) , paRes . nStartOfNextSentencePosition ) ; assertEquals ( 0 , paRes . nStartOfSentencePosition ) ; } } final Locale caLoc = new Locale ( "ca" , "ES" , "" ) ; final ProofreadingResult paRes = prog . doProofreading ( "1" , testString , caLoc , 0 , testString . length ( ) , prop ) ; assertEquals ( "1" , paRes . aDocumentIdentifier ) ; } public void testCleanFootnotes ( ) { final Main prog = new Main ( null ) ; Main . setTestMode ( true ) ; assertEquals ( "A house.¹ Here comes more text." , prog . cleanFootnotes ( "A house.1 Here comes more text." ) ) ; assertEquals ( "A road that's 3.4 miles long." , prog . cleanFootnotes ( "A road that's 3.4 miles long." ) ) ; assertEquals ( "A house.1234 Here comes more text." , prog . cleanFootnotes ( "A house.1234 Here comes more text." ) ) ; String input = "Das Haus.1 Hier kommt mehr Text2. Und nochmal!3 Und schon wieder ein Satz?4 Jetzt ist aber Schluss." ; String expected = "Das Haus.¹ Hier kommt mehr Text2. Und nochmal!¹ Und schon wieder ein Satz?¹ Jetzt ist aber Schluss." ; assertEquals ( expected , prog . cleanFootnotes ( input ) ) ; } }
package org . languagetool . openoffice ; import org . junit . Test ; import static junit . framework . TestCase . assertFalse ; import static junit . framework . TestCase . assertTrue ; import static junit . framework . TestCase . fail ; public class TamilDetectorTest { @ Test public void testIsThisLanguage ( ) { final TamilDetector detector = new TamilDetector ( ) ; assertTrue ( detector . isThisLanguage ( "இந்த" ) ) ; assertTrue ( detector . isThisLanguage ( "இ" ) ) ; assertTrue ( detector . isThisLanguage ( "\"லேங்குவேஜ்" ) ) ; assertFalse ( detector . isThisLanguage ( "Hallo" ) ) ; assertFalse ( detector . isThisLanguage ( "öäü" ) ) ; assertFalse ( detector . isThisLanguage ( "" ) ) ; try { assertFalse ( detector . isThisLanguage ( null ) ) ; fail ( ) ; } catch ( NullPointerException ignored ) { } } }
package org . languagetool . rules . ro ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . rules . AbstractCompoundRule ; import org . languagetool . rules . CompoundRuleData ; public class CompoundRule extends AbstractCompoundRule { private static final CompoundRuleData compoundData = new CompoundRuleData ( "/ro/compounds.txt" ) ; public CompoundRule ( final ResourceBundle messages ) throws IOException { super ( messages , "Cuvântul se scrie cu cratimă." , "Cuvântul se scrie legat." , "Cuvântul se scrie legat sau cu cratimă." , "Problemă de scriere (cratimă, spațiu, etc.)" ) ; } @ Override public boolean isHyphenIgnored ( ) { return false ; } @ Override public String getId ( ) { return "RO_COMPOUND" ; } @ Override public String getDescription ( ) { return "Greșeală de scriere (cuvinte scrise legat sau cu cratimă)" ; } @ Override protected CompoundRuleData getCompoundRuleData ( ) { return compoundData ; } }
package org . languagetool . openoffice ; import junit . framework . TestCase ; public class KhmerDetectorTest extends TestCase { public void testIsThisLanguage ( ) { final KhmerDetector detector = new KhmerDetector ( ) ; assertTrue ( detector . isThisLanguage ( "ប៉ុ" ) ) ; assertTrue ( detector . isThisLanguage ( "ប៉ុន្តែ​តើ" ) ) ; assertTrue ( detector . isThisLanguage ( "ហើយដោយ​ព្រោះ​" ) ) ; assertTrue ( detector . isThisLanguage ( "«ទៅ​បាន​។ «" ) ) ; assertFalse ( detector . isThisLanguage ( "Hallo" ) ) ; assertFalse ( detector . isThisLanguage ( "öäü" ) ) ; assertFalse ( detector . isThisLanguage ( "" ) ) ; try { assertFalse ( detector . isThisLanguage ( null ) ) ; fail ( ) ; } catch ( NullPointerException ignored ) { } } }
package org . languagetool . openoffice ; abstract class LanguageDetector { private static final int MAX_CHECK_LENGTH = 100 ; abstract int getLowerBound ( ) ; abstract int getUpperBound ( ) ; boolean isThisLanguage ( String str ) { final int maxCheckLength = Math . min ( str . length ( ) , MAX_CHECK_LENGTH ) ; for ( int i = 0 ; i < maxCheckLength ; i ++ ) { final int numericValue = str . charAt ( i ) ; if ( numericValue >= getLowerBound ( ) && numericValue <= getUpperBound ( ) ) { return true ; } } return false ; } }
package org . languagetool . openoffice ; import java . io . File ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . HashSet ; import java . util . List ; import java . util . ResourceBundle ; import java . util . Set ; import javax . swing . JOptionPane ; import javax . swing . UIManager ; import com . sun . star . lang . * ; import com . sun . star . lang . IllegalArgumentException ; import com . sun . star . linguistic2 . LinguServiceEvent ; import com . sun . star . linguistic2 . LinguServiceEventFlags ; import com . sun . star . text . TextMarkupType ; import org . jetbrains . annotations . Nullable ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . gui . AboutDialog ; import org . languagetool . gui . Configuration ; import org . languagetool . markup . AnnotatedText ; import org . languagetool . markup . AnnotatedTextBuilder ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . tools . StringTools ; import org . languagetool . tools . Tools ; import com . sun . star . beans . PropertyState ; import com . sun . star . beans . PropertyValue ; import com . sun . star . beans . XPropertySet ; import com . sun . star . frame . XDesktop ; import com . sun . star . frame . XModel ; import com . sun . star . lib . uno . helper . Factory ; import com . sun . star . lib . uno . helper . WeakBase ; import com . sun . star . linguistic2 . ProofreadingResult ; import com . sun . star . linguistic2 . SingleProofreadingError ; import com . sun . star . linguistic2 . XLinguServiceEventBroadcaster ; import com . sun . star . linguistic2 . XLinguServiceEventListener ; import com . sun . star . linguistic2 . XProofreader ; import com . sun . star . registry . XRegistryKey ; import com . sun . star . task . XJobExecutor ; import com . sun . star . text . XTextViewCursor ; import com . sun . star . text . XTextViewCursorSupplier ; import com . sun . star . uno . UnoRuntime ; import com . sun . star . uno . XComponentContext ; public class Main extends WeakBase implements XJobExecutor , XServiceDisplayName , XServiceInfo , XProofreader , XLinguServiceEventBroadcaster { private static final String [ ] SERVICE_NAMES = { "com.sun.star.linguistic2.Proofreader" , "org.languagetool.openoffice.Main" } ; private static final String CONFIG_FILE = ".languagetool-ooo.cfg" ; private static final ResourceBundle MESSAGES = JLanguageTool . getMessageBundle ( ) ; private static final String LIBREOFFICE_SPECIAL_LANGUAGE_TAG = "qlt" ; private static boolean testMode ; private final List < XLinguServiceEventListener > xEventListeners ; private Configuration config ; private JLanguageTool langTool ; private Language docLanguage ; private String docID ; private Set < String > disabledRules ; private Set < String > disabledRulesUI ; private boolean recheck ; private String currentPara ; private List < String > tokenizedSentences ; private int position ; private List < RuleMatch > paragraphMatches ; private XComponentContext xContext ; public Main ( final XComponentContext xCompContext ) { changeContext ( xCompContext ) ; xEventListeners = new ArrayList < > ( ) ; } private void prepareConfig ( final Language lang ) { try { final File homeDir = getHomeDir ( ) ; config = new Configuration ( homeDir , CONFIG_FILE , lang ) ; disabledRules = config . getDisabledRuleIds ( ) ; if ( disabledRules == null ) { disabledRules = new HashSet < > ( ) ; } disabledRulesUI = new HashSet < > ( disabledRules ) ; } catch ( final Throwable t ) { showError ( t ) ; } } public final void changeContext ( final XComponentContext xCompContext ) { xContext = xCompContext ; } @ Nullable private XComponent getXComponent ( ) { try { final XMultiComponentFactory xMCF = xContext . getServiceManager ( ) ; final Object desktop = xMCF . createInstanceWithContext ( "com.sun.star.frame.Desktop" , xContext ) ; final XDesktop xDesktop = UnoRuntime . queryInterface ( XDesktop . class , desktop ) ; return xDesktop . getCurrentComponent ( ) ; } catch ( final Throwable t ) { showError ( t ) ; return null ; } } @ Nullable private Language getLanguage ( ) { final XComponent xComponent = getXComponent ( ) ; final Locale charLocale ; final XPropertySet xCursorProps ; try { final XModel model = UnoRuntime . queryInterface ( XModel . class , xComponent ) ; final XTextViewCursorSupplier xViewCursorSupplier = UnoRuntime . queryInterface ( XTextViewCursorSupplier . class , model . getCurrentController ( ) ) ; final XTextViewCursor xCursor = xViewCursorSupplier . getViewCursor ( ) ; if ( xCursor . isCollapsed ( ) ) { xCursorProps = UnoRuntime . queryInterface ( XPropertySet . class , xCursor ) ; } else { xCursorProps = UnoRuntime . queryInterface ( XPropertySet . class , xCursor . getText ( ) . createTextCursorByRange ( xCursor . getStart ( ) ) ) ; } if ( new KhmerDetector ( ) . isThisLanguage ( xCursor . getText ( ) . getString ( ) ) ) { return Languages . getLanguageForShortName ( "km" ) ; } if ( new TamilDetector ( ) . isThisLanguage ( xCursor . getText ( ) . getString ( ) ) ) { return Languages . getLanguageForShortName ( "ta" ) ; } final Object obj = xCursorProps . getPropertyValue ( "CharLocale" ) ; if ( obj == null ) { return Languages . getLanguageForShortName ( "en-US" ) ; } charLocale = ( Locale ) obj ; boolean langIsSupported = false ; for ( Language element : Languages . get ( ) ) { if ( charLocale . Language . equalsIgnoreCase ( LIBREOFFICE_SPECIAL_LANGUAGE_TAG ) && element . getShortNameWithCountryAndVariant ( ) . equalsIgnoreCase ( charLocale . Variant ) ) { langIsSupported = true ; break ; } if ( element . getShortName ( ) . equals ( charLocale . Language ) ) { langIsSupported = true ; break ; } } if ( ! langIsSupported ) { final String message = org . languagetool . gui . Tools . makeTexti18n ( MESSAGES , "language_not_supported" , charLocale . Language ) ; JOptionPane . showMessageDialog ( null , message ) ; return null ; } } catch ( final Throwable t ) { showError ( t ) ; return null ; } return getLanguage ( charLocale ) ; } private Language getLanguage ( Locale locale ) { try { if ( locale . Language . equalsIgnoreCase ( LIBREOFFICE_SPECIAL_LANGUAGE_TAG ) ) { return Languages . getLanguageForShortName ( locale . Variant ) ; } else { return Languages . getLanguageForShortName ( locale . Language + "-" + locale . Country ) ; } } catch ( java . lang . IllegalArgumentException e ) { return Languages . getLanguageForShortName ( locale . Language ) ; } } @ Override public final ProofreadingResult doProofreading ( final String docID , final String paraText , final Locale locale , final int startOfSentencePos , final int nSuggestedBehindEndOfSentencePosition , final PropertyValue [ ] propertyValues ) { final ProofreadingResult paRes = new ProofreadingResult ( ) ; try { paRes . nStartOfSentencePosition = startOfSentencePos ; paRes . xProofreader = this ; paRes . aLocale = locale ; paRes . aDocumentIdentifier = docID ; paRes . aText = paraText ; paRes . aProperties = propertyValues ; int [ ] footnotePositions = getPropertyValues ( "FootnotePositions" , propertyValues ) ; return doGrammarCheckingInternal ( paraText , locale , paRes , footnotePositions ) ; } catch ( final Throwable t ) { showError ( t ) ; return paRes ; } } private int [ ] getPropertyValues ( String propName , PropertyValue [ ] propertyValues ) { for ( PropertyValue propertyValue : propertyValues ) { if ( propName . equals ( propertyValue . Name ) ) { if ( propertyValue . Value instanceof int [ ] ) { return ( int [ ] ) propertyValue . Value ; } else { System . err . println ( "Not of expected type int[]: " + propertyValue . Name + ": " + propertyValue . Value . getClass ( ) ) ; } } } return new int [ ] { } ; } private synchronized ProofreadingResult doGrammarCheckingInternal ( final String paraText , final Locale locale , final ProofreadingResult paRes , int [ ] footnotePositions ) { if ( ! StringTools . isEmpty ( paraText ) && hasLocale ( locale ) ) { Language langForShortName = getLanguage ( locale ) ; if ( ! langForShortName . equals ( docLanguage ) || langTool == null || recheck ) { docLanguage = langForShortName ; initLanguageTool ( ) ; } final Set < String > disabledRuleIds = config . getDisabledRuleIds ( ) ; if ( disabledRuleIds != null ) { final List < String > list = new ArrayList < > ( disabledRuleIds ) ; for ( final String id : list ) { langTool . disableRule ( id ) ; } } final Set < String > disabledCategories = config . getDisabledCategoryNames ( ) ; if ( disabledCategories != null ) { final List < String > list = new ArrayList < > ( disabledCategories ) ; for ( final String categoryName : list ) { langTool . disableCategory ( categoryName ) ; } } final Set < String > enabledRuleIds = config . getEnabledRuleIds ( ) ; if ( enabledRuleIds != null ) { final List < String > list = new ArrayList < > ( enabledRuleIds ) ; for ( String ruleName : list ) { langTool . enableDefaultOffRule ( ruleName ) ; langTool . enableRule ( ruleName ) ; } } try { final String sentence = getSentence ( paraText , paRes . nStartOfSentencePosition ) ; paRes . nStartOfSentencePosition = position ; paRes . nStartOfNextSentencePosition = position + sentence . length ( ) ; paRes . nBehindEndOfSentencePosition = paRes . nStartOfNextSentencePosition ; if ( ! StringTools . isEmpty ( sentence ) ) { AnnotatedText annotatedText = getAnnotatedText ( sentence , footnotePositions , paRes ) ; final List < RuleMatch > ruleMatches = langTool . check ( annotatedText , false , JLanguageTool . ParagraphHandling . ONLYNONPARA ) ; final SingleProofreadingError [ ] pErrors = checkParaRules ( paraText , paRes . nStartOfSentencePosition , paRes . nStartOfNextSentencePosition , paRes . aDocumentIdentifier ) ; int pErrorCount = 0 ; if ( pErrors != null ) { pErrorCount = pErrors . length ; } if ( ! ruleMatches . isEmpty ( ) ) { final SingleProofreadingError [ ] errorArray = new SingleProofreadingError [ ruleMatches . size ( ) + pErrorCount ] ; int i = 0 ; for ( final RuleMatch myRuleMatch : ruleMatches ) { errorArray [ i ] = createOOoError ( myRuleMatch , paRes . nStartOfSentencePosition ) ; i ++ ; } if ( pErrors != null ) { for ( SingleProofreadingError paraError : pErrors ) { if ( paraError != null ) { errorArray [ i ] = paraError ; i ++ ; } } } Arrays . sort ( errorArray , new ErrorPositionComparator ( ) ) ; paRes . aErrors = errorArray ; } else { if ( pErrors != null ) { paRes . aErrors = pErrors ; } } } } catch ( final Throwable t ) { showError ( t ) ; paRes . nBehindEndOfSentencePosition = paraText . length ( ) ; } } return paRes ; } private AnnotatedText getAnnotatedText ( String sentence , int [ ] footnotePos , ProofreadingResult paRes ) { Set < Integer > correctedPos = new HashSet < > ( ) ; for ( int pos : footnotePos ) { correctedPos . add ( pos - paRes . nStartOfSentencePosition ) ; } AnnotatedTextBuilder annotations = new AnnotatedTextBuilder ( ) ; for ( int i = 0 ; i < sentence . length ( ) ; i ++ ) { if ( correctedPos . contains ( i ) ) { annotations . addMarkup ( "\u200B" ) ; } else { annotations . addText ( String . valueOf ( sentence . charAt ( i ) ) ) ; } } return annotations . build ( ) ; } private void initLanguageTool ( ) { try { prepareConfig ( docLanguage ) ; langTool = new JLanguageTool ( docLanguage , config . getMotherTongue ( ) ) ; for ( Rule rule : langTool . getAllActiveRules ( ) ) { if ( rule . isDictionaryBasedSpellingRule ( ) ) { langTool . disableRule ( rule . getId ( ) ) ; } if ( rule . useInOffice ( ) ) { langTool . enableRule ( rule . getId ( ) ) ; } } recheck = false ; } catch ( final Throwable t ) { showError ( t ) ; } } private synchronized String getSentence ( final String paraText , final int startPos ) { if ( paraText . equals ( currentPara ) && tokenizedSentences != null ) { int i = 0 ; int index = - 1 ; while ( index < startPos && i < tokenizedSentences . size ( ) ) { index += tokenizedSentences . get ( i ) . length ( ) ; if ( index < startPos ) { i ++ ; } } position = index + 1 ; if ( i < tokenizedSentences . size ( ) ) { position -= tokenizedSentences . get ( i ) . length ( ) ; return tokenizedSentences . get ( i ) ; } return "" ; } currentPara = paraText ; tokenizedSentences = langTool . sentenceTokenize ( cleanFootnotes ( paraText ) ) ; position = 0 ; if ( ! tokenizedSentences . isEmpty ( ) ) { return tokenizedSentences . get ( 0 ) ; } return "" ; } String cleanFootnotes ( String paraText ) { return paraText . replaceAll ( "([^\\d][.!?])\\d " , "$1¹ " ) ; } @ Nullable private synchronized SingleProofreadingError [ ] checkParaRules ( final String paraText , final int startPos , final int endPos , final String docID ) { if ( startPos == 0 ) { try { paragraphMatches = langTool . check ( paraText , false , JLanguageTool . ParagraphHandling . ONLYPARA ) ; this . docID = docID ; } catch ( final Throwable t ) { showError ( t ) ; } } if ( paragraphMatches != null && ! paragraphMatches . isEmpty ( ) && docID . equals ( this . docID ) ) { final List < SingleProofreadingError > errorList = new ArrayList < > ( paragraphMatches . size ( ) ) ; for ( final RuleMatch myRuleMatch : paragraphMatches ) { final int startErrPos = myRuleMatch . getFromPos ( ) ; final int endErrPos = myRuleMatch . getToPos ( ) ; if ( startErrPos >= startPos && startErrPos < endPos && endErrPos >= startPos && endErrPos < endPos ) { errorList . add ( createOOoError ( myRuleMatch , 0 ) ) ; } } if ( ! errorList . isEmpty ( ) ) { final SingleProofreadingError [ ] errorArray = errorList . toArray ( new SingleProofreadingError [ errorList . size ( ) ] ) ; Arrays . sort ( errorArray , new ErrorPositionComparator ( ) ) ; return errorArray ; } } return null ; } private SingleProofreadingError createOOoError ( final RuleMatch ruleMatch , final int startIndex ) { final SingleProofreadingError aError = new SingleProofreadingError ( ) ; aError . nErrorType = TextMarkupType . PROOFREADING ; aError . aFullComment = ruleMatch . getMessage ( ) . replaceAll ( "<suggestion>" , "\"" ) . replaceAll ( "</suggestion>" , "\"" ) . replaceAll ( "([\r]*\n)" , " " ) ; if ( ! StringTools . isEmpty ( ruleMatch . getShortMessage ( ) ) ) { aError . aShortComment = ruleMatch . getShortMessage ( ) ; } else { aError . aShortComment = aError . aFullComment ; } aError . aShortComment = org . languagetool . gui . Tools . shortenComment ( aError . aShortComment ) ; aError . aSuggestions = ruleMatch . getSuggestedReplacements ( ) . toArray ( new String [ ruleMatch . getSuggestedReplacements ( ) . size ( ) ] ) ; aError . nErrorStart = ruleMatch . getFromPos ( ) + startIndex ; aError . nErrorLength = ruleMatch . getToPos ( ) - ruleMatch . getFromPos ( ) ; aError . aRuleIdentifier = ruleMatch . getRule ( ) . getId ( ) ; if ( ruleMatch . getRule ( ) . getUrl ( ) != null ) { aError . aProperties = new PropertyValue [ ] { new PropertyValue ( "FullCommentURL" , - 1 , ruleMatch . getRule ( ) . getUrl ( ) . toString ( ) , PropertyState . DIRECT_VALUE ) } ; } else { aError . aProperties = new PropertyValue [ 0 ] ; } return aError ; } @ Override public final boolean isSpellChecker ( ) { return false ; } public final void runOptionsDialog ( ) { final Language lang = getLanguage ( ) ; if ( lang == null ) { return ; } prepareConfig ( lang ) ; final ConfigThread configThread = new ConfigThread ( lang , config , this ) ; configThread . start ( ) ; } @ Override public final Locale [ ] getLocales ( ) { try { List < Locale > locales = new ArrayList < > ( ) ; for ( final Language lang : Languages . get ( ) ) { if ( lang . getCountries ( ) . length == 0 ) { if ( lang . getVariant ( ) != null ) { locales . add ( new Locale ( LIBREOFFICE_SPECIAL_LANGUAGE_TAG , "" , lang . getShortNameWithCountryAndVariant ( ) ) ) ; } else { locales . add ( new Locale ( lang . getShortName ( ) , "" , "" ) ) ; } } else { for ( final String country : lang . getCountries ( ) ) { if ( lang . getVariant ( ) != null ) { locales . add ( new Locale ( LIBREOFFICE_SPECIAL_LANGUAGE_TAG , country , lang . getShortNameWithCountryAndVariant ( ) ) ) ; } else { locales . add ( new Locale ( lang . getShortName ( ) , country , "" ) ) ; } } } } return locales . toArray ( new Locale [ locales . size ( ) ] ) ; } catch ( final Throwable t ) { showError ( t ) ; return new Locale [ 0 ] ; } } @ Override public final boolean hasLocale ( final Locale locale ) { try { for ( final Language element : Languages . get ( ) ) { if ( locale . Language . equalsIgnoreCase ( LIBREOFFICE_SPECIAL_LANGUAGE_TAG ) && element . getShortNameWithCountryAndVariant ( ) . equals ( locale . Variant ) ) { return true ; } if ( element . getShortName ( ) . equals ( locale . Language ) ) { return true ; } } } catch ( final Throwable t ) { showError ( t ) ; } return false ; } @ Override public final boolean addLinguServiceEventListener ( final XLinguServiceEventListener eventListener ) { if ( eventListener == null ) { return false ; } xEventListeners . add ( eventListener ) ; return true ; } @ Override public final boolean removeLinguServiceEventListener ( final XLinguServiceEventListener eventListener ) { if ( eventListener == null ) { return false ; } if ( xEventListeners . contains ( eventListener ) ) { xEventListeners . remove ( eventListener ) ; return true ; } return false ; } public final void resetDocument ( ) { if ( ! xEventListeners . isEmpty ( ) ) { for ( final XLinguServiceEventListener xEvLis : xEventListeners ) { if ( xEvLis != null ) { final LinguServiceEvent xEvent = new LinguServiceEvent ( ) ; xEvent . nEvent = LinguServiceEventFlags . PROOFREAD_AGAIN ; xEvLis . processLinguServiceEvent ( xEvent ) ; } } recheck = true ; disabledRules = config . getDisabledRuleIds ( ) ; if ( disabledRules == null ) { disabledRules = new HashSet < > ( ) ; } } } @ Override public String [ ] getSupportedServiceNames ( ) { return getServiceNames ( ) ; } public static String [ ] getServiceNames ( ) { return SERVICE_NAMES ; } @ Override public boolean supportsService ( final String sServiceName ) { for ( final String sName : SERVICE_NAMES ) { if ( sServiceName . equals ( sName ) ) { return true ; } } return false ; } @ Override public String getImplementationName ( ) { return Main . class . getName ( ) ; } public static XSingleComponentFactory __getComponentFactory ( final String sImplName ) { SingletonFactory xFactory = null ; if ( sImplName . equals ( Main . class . getName ( ) ) ) { xFactory = new SingletonFactory ( ) ; } return xFactory ; } public static boolean __writeRegistryServiceInfo ( final XRegistryKey regKey ) { return Factory . writeRegistryServiceInfo ( Main . class . getName ( ) , Main . getServiceNames ( ) , regKey ) ; } @ Override public void trigger ( final String sEvent ) { if ( Thread . currentThread ( ) . getContextClassLoader ( ) == null ) { Thread . currentThread ( ) . setContextClassLoader ( Main . class . getClassLoader ( ) ) ; } if ( ! javaVersionOkay ( ) ) { return ; } try { if ( "configure" . equals ( sEvent ) ) { runOptionsDialog ( ) ; } else if ( "about" . equals ( sEvent ) ) { final AboutDialogThread aboutThread = new AboutDialogThread ( MESSAGES ) ; aboutThread . start ( ) ; } else { System . err . println ( "Sorry, don't know what to do, sEvent = " + sEvent ) ; } } catch ( final Throwable e ) { showError ( e ) ; } } private boolean javaVersionOkay ( ) { final String version = System . getProperty ( "java.version" ) ; if ( version != null && ( version . startsWith ( "1.0" ) || version . startsWith ( "1.1" ) || version . startsWith ( "1.2" ) || version . startsWith ( "1.3" ) || version . startsWith ( "1.4" ) || version . startsWith ( "1.5" ) || version . startsWith ( "1.6" ) ) ) { final DialogThread dt = new DialogThread ( "Error: LanguageTool requires Java 7.0 or later. Current version: " + version ) ; dt . start ( ) ; return false ; } try { if ( ! System . getProperty ( "os.name" ) . contains ( "OS X" ) ) { for ( UIManager . LookAndFeelInfo info : UIManager . getInstalledLookAndFeels ( ) ) { if ( "Nimbus" . equals ( info . getName ( ) ) ) { UIManager . setLookAndFeel ( info . getClassName ( ) ) ; break ; } } } } catch ( Exception ignored ) { } return true ; } static void showError ( final Throwable e ) { if ( testMode ) { throw new RuntimeException ( e ) ; } String msg = "An error has occurred in LanguageTool " + JLanguageTool . VERSION + ":\n" + e + "\nStacktrace:\n" ; msg += Tools . getFullStackTrace ( e ) ; final String metaInfo = "OS: " + System . getProperty ( "os.name" ) + " on " + System . getProperty ( "os.arch" ) + ", Java version " + System . getProperty ( "java.version" ) + " from " + System . getProperty ( "java.vm.vendor" ) ; msg += metaInfo ; final DialogThread dt = new DialogThread ( msg ) ; e . printStackTrace ( ) ; dt . start ( ) ; } private File getHomeDir ( ) { final String homeDir = System . getProperty ( "user.home" ) ; if ( homeDir == null ) { showError ( new RuntimeException ( "Could not get home directory" ) ) ; } return new File ( homeDir ) ; } static void setTestMode ( boolean mode ) { testMode = mode ; } private static class AboutDialogThread extends Thread { private final ResourceBundle messages ; AboutDialogThread ( final ResourceBundle messages ) { this . messages = messages ; } @ Override public void run ( ) { final AboutDialog about = new AboutDialog ( messages , null ) ; about . show ( ) ; } } @ Override public void ignoreRule ( final String ruleId , final Locale locale ) throws IllegalArgumentException { disabledRulesUI . add ( ruleId ) ; config . setDisabledRuleIds ( disabledRulesUI ) ; try { config . saveConfiguration ( langTool . getLanguage ( ) ) ; } catch ( final Throwable t ) { showError ( t ) ; } recheck = true ; } @ Override public void resetIgnoreRules ( ) { config . setDisabledRuleIds ( disabledRules ) ; try { config . saveConfiguration ( langTool . getLanguage ( ) ) ; } catch ( final Throwable t ) { showError ( t ) ; } recheck = true ; } @ Override public String getServiceDisplayName ( Locale locale ) { return "LanguageTool" ; } static class DialogThread extends Thread { private final String text ; DialogThread ( final String text ) { this . text = text ; } @ Override public void run ( ) { JOptionPane . showMessageDialog ( null , text ) ; } } }
package org . languagetool . openoffice ; @ SuppressWarnings ( "MagicNumber" ) class TamilDetector extends LanguageDetector { @ Override int getLowerBound ( ) { return 2946 ; } @ Override int getUpperBound ( ) { return 3066 ; } }
package org . languagetool . openoffice ; import com . sun . star . linguistic2 . SingleProofreadingError ; import java . util . Comparator ; class ErrorPositionComparator implements Comparator < SingleProofreadingError > { @ Override public int compare ( final SingleProofreadingError match1 , final SingleProofreadingError match2 ) { if ( match1 . aSuggestions . length == 0 && match2 . aSuggestions . length > 0 ) { return 1 ; } if ( match2 . aSuggestions . length == 0 && match1 . aSuggestions . length > 0 ) { return - 1 ; } final int error1pos = match1 . nErrorStart ; final int error2pos = match2 . nErrorStart ; if ( error1pos > error2pos ) { return 1 ; } else if ( error1pos < error2pos ) { return - 1 ; } else { if ( match1 . aSuggestions . length != 0 && match2 . aSuggestions . length != 0 && match1 . aSuggestions . length != match2 . aSuggestions . length ) { return Integer . compare ( match1 . aSuggestions . length , match2 . aSuggestions . length ) ; } } return match1 . aRuleIdentifier . compareTo ( match2 . aRuleIdentifier ) ; } }
package org . languagetool . openoffice ; import com . sun . star . lang . XServiceInfo ; import com . sun . star . lang . XSingleComponentFactory ; import com . sun . star . uno . XComponentContext ; public class SingletonFactory implements XSingleComponentFactory , XServiceInfo { private transient org . languagetool . openoffice . Main instance ; @ Override public final Object createInstanceWithArgumentsAndContext ( final Object [ ] arguments , final XComponentContext xContext ) { return createInstanceWithContext ( xContext ) ; } @ Override public final Object createInstanceWithContext ( final XComponentContext xContext ) { if ( instance == null ) { instance = new org . languagetool . openoffice . Main ( xContext ) ; } else { instance . changeContext ( xContext ) ; } return instance ; } @ Override public final String getImplementationName ( ) { return Main . class . getName ( ) ; } @ Override public final boolean supportsService ( String serviceName ) { for ( String s : getSupportedServiceNames ( ) ) { if ( s . equals ( serviceName ) ) { return true ; } } return false ; } @ Override public final String [ ] getSupportedServiceNames ( ) { return Main . getServiceNames ( ) ; } }
package org . languagetool . openoffice ; @ SuppressWarnings ( "MagicNumber" ) class KhmerDetector extends LanguageDetector { @ Override int getLowerBound ( ) { return 6016 ; } @ Override int getUpperBound ( ) { return 6143 ; } }
package org . languagetool . openoffice ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . gui . Configuration ; import org . languagetool . gui . ConfigurationDialog ; class ConfigThread extends Thread { private final Language docLanguage ; private final Configuration config ; private final org . languagetool . openoffice . Main mainThread ; private final ConfigurationDialog cfgDialog ; ConfigThread ( final Language docLanguage , final Configuration config , final org . languagetool . openoffice . Main main ) { this . docLanguage = docLanguage ; this . config = config ; mainThread = main ; cfgDialog = new ConfigurationDialog ( null , true , config ) ; } @ Override public void run ( ) { try { final JLanguageTool langTool = new JLanguageTool ( docLanguage , config . getMotherTongue ( ) ) ; cfgDialog . show ( langTool . getAllRules ( ) ) ; config . saveConfiguration ( docLanguage ) ; if ( mainThread != null ) { mainThread . resetDocument ( ) ; } } catch ( Throwable e ) { Main . showError ( e ) ; } } }
package org . languagetool . clientexample ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; import java . util . List ; public class Example { public static void main ( String [ ] args ) throws IOException { final Language [ ] realLanguages = Language . REAL_LANGUAGES ; System . out . println ( "This example will test a short string with all languages known to LanguageTool." ) ; System . out . println ( "It's just a test to make sure there's at least no crash." ) ; System . out . println ( "Using LanguageTool " + JLanguageTool . VERSION + " (" + JLanguageTool . BUILD_DATE + ")" ) ; System . out . println ( "Supported languages: " + realLanguages . length ) ; for ( Language language : realLanguages ) { final JLanguageTool langTool = new JLanguageTool ( language ) ; final String input = "And the the" ; final List < RuleMatch > result = langTool . check ( input ) ; System . out . println ( "Checking '" + input + "' with " + language + ":" ) ; for ( RuleMatch ruleMatch : result ) { System . out . println ( " " + ruleMatch ) ; } } } }
package org . languagetool . commandline ; import org . apache . commons . lang . StringUtils ; import java . io . ByteArrayInputStream ; import java . io . ByteArrayOutputStream ; import java . io . File ; import java . io . FileInputStream ; import java . io . FileOutputStream ; import java . io . IOException ; import java . io . OutputStreamWriter ; import java . io . PrintStream ; import java . io . PrintWriter ; import static org . hamcrest . CoreMatchers . is ; import static org . junit . Assert . assertThat ; public class MainTest extends AbstractSecurityTestCase { private final File enTestFile ; private final File xxRuleFile ; private final File xxFalseFriendFile ; private final File bitextFile ; private ByteArrayOutputStream out ; private ByteArrayOutputStream err ; private PrintStream stdout ; private PrintStream stderr ; public MainTest ( String testName ) throws IOException { super ( testName ) ; enTestFile = writeToTempFile ( "This is an test.\n\n" + "This is a test of of language tool.\n\n" + "This is is a test of language tool." ) ; xxRuleFile = writeToTempXMLFile ( "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n" + "<rules lang=\"en\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n" + "xmlns:xs=\"http://www.w3.org/2001/XMLSchema\">\n" + "<category name=\"trivial category\">\n" + "<rule id=\"EXAMPLE_RULE\" name=\"External rule to test\">\n" + "<pattern><token>language</token><token>tool</token></pattern>\n" + "<message>This is wrong!</message>\n" + "<example correction=\"\">language tool</example>\n" + "</rule></category></rules>" ) ; xxFalseFriendFile = writeToTempXMLFile ( "<?xml version=\"1.0\" encoding=\"UTF-8\"?>" + "<!DOCTYPE rules SYSTEM \"false-friends.dtd\">\n" + "<rules>\n" + "<rulegroup id=\"LASKA_SK_PL\">\n" + " <rule>\n" + " <pattern lang=\"sk\">\n" + " <token>láska</token>\n" + " </pattern>\n" + " <translation lang=\"pl\">miłość</translation>\n" + " </rule>\n" + " <rule>\n" + " <pattern lang=\"pl\">\n" + " <token inflected=\"yes\">miłość</token>\n" + " </pattern>\n" + " <translation lang=\"sk\">laska</translation>\n" + " </rule>\n" + " </rulegroup>\n</rules>\n" + " " ) ; bitextFile = writeToTempXMLFile ( "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n" + "<rules targetLang=\"pl\" xsi:noNamespaceSchemaLocation=\"../bitext.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\">\n" + "<category name=\"idioms\">\n" + "<rule lang=\"pl\" id=\"red_herring\" name=\"Red herring -> odwraca uwagę\">\n" + "<pattern>\n" + "\t<source lang=\"en\">\n" + "\t\t<token>is</token>\n" + "\t\t<token>a</token>\n" + "\t\t<token>red</token>\n" + "\t\t<token>herring</token>\n" + "\t</source>\n" + "\t<target>\n" + "\t\t<token>jest</token>\n" + "\t\t<token>czerwony</token>\n" + "\t\t<token>śledź</token>\n" + "\t</target>\n" + "</pattern>\n" + "<message>Czy chodziło o <suggestion>odwraca uwagę</suggestion>?</message>\n" + "<example type=\"correct\"><srcExample>This is a red herring.</srcExample>\n" + "\t\t\t\t\t<trgExample>To odwraca uwagę.</trgExample></example>\n" + "<example type=\"incorrect\" correction=\"odwraca uwagę\"><srcExample>This <marker>is a red herring</marker>.</srcExample>\n" + "<trgExample>To <marker>jest czerwony śledź</marker>.</trgExample></example>\n" + "</rule></category></rules>\n" ) ; } @ Override public void setUp ( ) throws Exception { super . setUp ( ) ; this . stdout = System . out ; this . stderr = System . err ; this . out = new ByteArrayOutputStream ( ) ; this . err = new ByteArrayOutputStream ( ) ; System . setOut ( new PrintStream ( this . out ) ) ; System . setErr ( new PrintStream ( this . err ) ) ; } @ Override public void tearDown ( ) throws Exception { super . tearDown ( ) ; System . setOut ( this . stdout ) ; System . setErr ( this . stderr ) ; } public void testUsageMessage ( ) throws Exception { try { final String [ ] args = { "-h" } ; Main . main ( args ) ; fail ( "LT should have exited with status 0!" ) ; } catch ( ExitException e ) { final String output = new String ( this . out . toByteArray ( ) ) ; assertTrue ( output . contains ( "Usage: java -jar languagetool-commandline.jar" ) ) ; assertEquals ( "Exit status" , 1 , e . status ) ; } } public void testPrintLanguages ( ) throws Exception { try { final String [ ] args = { "--list" } ; Main . main ( args ) ; fail ( "LT should have exited with status 0!" ) ; } catch ( ExitException e ) { final String output = new String ( this . out . toByteArray ( ) ) ; assertTrue ( output . contains ( "German" ) ) ; assertTrue ( output . contains ( "de-DE" ) ) ; assertTrue ( output . contains ( "English" ) ) ; assertEquals ( "Exit status" , 0 , e . status ) ; } } public void testFileWithExternalRule ( ) throws Exception { final String [ ] args = { "-l" , "br" , "--rulefile" , getRuleFilePath ( ) , getTestFilePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Breton" ) == 0 ) ; assertTrue ( stdout . contains ( "Rule ID: EXAMPLE_RULE" ) ) ; } public void testEnglishFile ( ) throws Exception { final String [ ] args = { "-l" , "en" , getTestFilePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: English" ) == 0 ) ; assertTrue ( stdout . contains ( "1.) Line 1, column 9, Rule ID: EN_A_VS_AN" ) ) ; } public void testEnglishFileAutoDetect ( ) throws Exception { final String [ ] args = { "-adl" , getTestFilePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Using English for file" ) == 0 ) ; assertTrue ( stdout . contains ( "1.) Line 1, column 9, Rule ID: EN_A_VS_AN" ) ) ; } public void testEnglishStdInAutoDetect ( ) throws Exception { final String test = "This is an test." ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "-adl" } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Working on STDIN..." ) == 0 ) ; assertTrue ( stderr . contains ( "Language used is: English" ) ) ; assertTrue ( stdout . contains ( "1.) Line 1, column 9, Rule ID: EN_A_VS_AN" ) ) ; } public void testStdInWithExternalFalseFriends ( ) throws Exception { final String test = "Láska!\n" ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "-l" , "sk" , "--falsefriends" , getExternalFalseFriends ( ) , "-m" , "pl" , "-" } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . contains ( "Expected text language: Slovak" ) ) ; assertTrue ( stderr . contains ( "Working on STDIN..." ) ) ; assertTrue ( stdout . contains ( "Rule ID: LASKA" ) ) ; } public void testEnglishFileVerbose ( ) throws Exception { final String [ ] args = { "-l" , "en" , "-v" , getTestFilePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: English" ) == 0 ) ; assertTrue ( stdout . contains ( "1.) Line 1, column 9, Rule ID: EN_A_VS_AN" ) ) ; final String tagText = new String ( this . err . toByteArray ( ) ) ; assertTrue ( "Got: " + tagText , tagText . contains ( "<S> This[this/DT,B-NP-singular|E-NP-singular] is[be/VBZ,B-VP] an[a/DT,B-NP-singular] test[test/NN,E-NP-singular].[./.,</S>,O]" ) ) ; } public void testEnglishFileApplySuggestions ( ) throws Exception { final String [ ] args = { "-l" , "en" , "--apply" , getTestFilePath ( ) } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertTrue ( output . contains ( "This is a test.\n\n" + "This is a test of language tool.\n\n" + "This is a test of language tool." ) ) ; } public void testEnglishStdIn1 ( ) throws Exception { final String test = "This is an test." ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "-l" , "en" } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: English" ) == 0 ) ; assertTrue ( stdout . contains ( "1.) Line 1, column 9, Rule ID: EN_A_VS_AN" ) ) ; } public void testEnglishStdIn2 ( ) throws Exception { final String test = "This is an test." ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "-l" , "en" , "-" } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: English" ) == 0 ) ; assertTrue ( stdout . contains ( "1.) Line 1, column 9, Rule ID: EN_A_VS_AN" ) ) ; } public void testEnglishStdIn3 ( ) throws Exception { final String test = "This is an test." ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "-l" , "en" , "-a" , "-" } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertEquals ( "This is a test.\n" , output ) ; } public void testEnglishStdIn4 ( ) throws Exception { System . setIn ( new FileInputStream ( enTestFile ) ) ; final String [ ] args = { "-l" , "en" , "--api" , "-" } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertTrue ( "Got: " + output , output . contains ( "<error fromy=\"4\" fromx=\"5\" toy=\"4\" tox=\"10\" " + "ruleId=\"ENGLISH_WORD_REPEAT_RULE\" msg=\"Possible typo: you repeated a word\" replacements=\"is\" " + "context=\"This is is a test of language tool. \" contextoffset=\"5\" offset=\"5\" errorlength=\"5\" " + "category=\"Miscellaneous\" locqualityissuetype=\"duplication\"/>" ) ) ; } public void testEnglishLineMode ( ) throws Exception { final String test = "This is what I mean\nand you know it." ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "-l" , "en" , "-a" , "-b" , "-" } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertEquals ( "This is what I mean\nAnd you know it.\n" , output ) ; } public void testEnglishParaMode ( ) throws Exception { final String test = "This is what I mean\nand you know it." ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "-l" , "en" , "-a" , "-" } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertEquals ( "This is what I mean\nand you know it.\n" , output ) ; } public void testPolishStdInDefaultOff ( ) throws Exception { final String test = "To jest test, który zrobiłem, który mi się podoba." ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "-l" , "pl" , "-e" , "PL_WORD_REPEAT" , "-" } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Polish" ) == 0 ) ; assertTrue ( stderr . contains ( "Working on STDIN..." ) ) ; assertTrue ( stdout . contains ( "1.) Line 1, column 31, Rule ID: PL_WORD_REPEAT" ) ) ; } public void testPolishApiStdInDefaultOff ( ) throws Exception { final String test = "To jest test, który zrobiłem, który mi się podoba." ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "--api" , "-l" , "pl" , "-e" , "PL_WORD_REPEAT" , "-" } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertThat ( StringUtils . countMatches ( output , "<error " ) , is ( 1 ) ) ; assertThat ( StringUtils . countMatches ( output , "<matches " ) , is ( 1 ) ) ; assertThat ( StringUtils . countMatches ( output , "</matches>" ) , is ( 1 ) ) ; } public void testPolishApiStdInDefaultOffNoErrors ( ) throws Exception { final String test = "To jest test." ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "--api" , "-l" , "pl" , "-e" , "PL_WORD_REPEAT" , "-" } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertThat ( StringUtils . countMatches ( output , "<error " ) , is ( 0 ) ) ; assertThat ( StringUtils . countMatches ( output , "<matches " ) , is ( 1 ) ) ; assertThat ( StringUtils . countMatches ( output , "</matches>" ) , is ( 1 ) ) ; } public void testPolishSpelling ( ) throws Exception { final String test = "Zwuasdac?" ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "-l" , "pl" , "-e" , "MORFOLOGIK_RULE_PL_PL" , "-" } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Polish" ) == 0 ) ; assertTrue ( stderr . contains ( "Working on STDIN..." ) ) ; assertTrue ( stdout . contains ( "1.) Line 1, column 1, Rule ID: MORFOLOGIK_RULE_PL_PL" ) ) ; } public void testEnglishFileRuleDisabled ( ) throws Exception { final String [ ] args = { "-l" , "en" , "-d" , "EN_A_VS_AN" , getTestFilePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: English" ) == 0 ) ; assertTrue ( ! stdout . contains ( "Rule ID: EN_A_VS_AN" ) ) ; } public void testEnglishFileRuleEnabled ( ) throws Exception { final String [ ] args = { "-l" , "en" , "-e" , "EN_A_VS_AN" , getTestFilePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: English" ) == 0 ) ; assertTrue ( stdout . contains ( "Rule ID: EN_A_VS_AN" ) ) ; } public void testEnglishFileFakeRuleEnabled ( ) throws Exception { final String test = "Zwuasdac?" ; final byte [ ] b = test . getBytes ( ) ; System . setIn ( new ByteArrayInputStream ( b ) ) ; final String [ ] args = { "-l" , "en" , "-e" , "FOO_BAR_BLABLA" , "-" } ; Main . main ( args ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: English" ) == 0 ) ; } public void testEnglishFileAPI ( ) throws Exception { final String [ ] args = { "-l" , "en" , "--api" , getTestFilePath ( ) } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertTrue ( output . indexOf ( "<?xml version=\"1.0\" encoding=\"UTF-8\"?>" ) == 0 ) ; assertTrue ( output . contains ( "<error fromy=\"0\" fromx=\"8\" toy=\"0\" tox=\"10\" ruleId=\"EN_A_VS_AN\" " + "msg=\"Use &apos;a&apos; instead of &apos;an&apos; if the following word doesn&apos;t start with a vowel sound, e.g. &apos;a sentence&apos;, " + "&apos;a university&apos;\" replacements=\"a\" context=\"This is an test. This is a test of of language tool. ...\" " + "contextoffset=\"8\" offset=\"8\" errorlength=\"2\" category=\"Miscellaneous\" locqualityissuetype=\"misspelling\"/>" ) ) ; } public void testGermanFileWithURL ( ) throws Exception { final File input = writeToTempFile ( "Ward ihr zufrieden damit?" ) ; final String [ ] args = { "-l" , "de" , "--api" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertTrue ( output . indexOf ( "<?xml version=\"1.0\" encoding=\"UTF-8\"?>" ) == 0 ) ; assertTrue ( output . contains ( "ruleId=\"WARD_VS_WART\" subId=\"1\"" ) ) ; assertTrue ( output . contains ( "url=\"http://www.korrekturen.de/beliebte_fehler/ward.shtml\"" ) ) ; final String [ ] args2 = { "-l" , "de" , input . getAbsolutePath ( ) } ; Main . main ( args2 ) ; final String output2 = new String ( this . out . toByteArray ( ) ) ; assertTrue ( output2 . contains ( "More info: http://www.korrekturen.de/beliebte_fehler/ward.shtml" ) ) ; } public void testPolishFileAPI ( ) throws Exception { final File input = writeToTempFile ( "To jest świnia która się ślini." ) ; final String [ ] args = { "-l" , "pl" , "--api" , "-c" , "utf-8" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) , "UTF-8" ) ; assertTrue ( output . indexOf ( "<?xml version=\"1.0\" encoding=\"UTF-8\"?>" ) == 0 ) ; assertTrue ( output . contains ( "<error fromy=\"0\" fromx=\"8\" toy=\"0\" tox=\"20\" ruleId=\"BRAK_PRZECINKA_KTORY\"" ) ) ; assertTrue ( output . contains ( "msg=\"Brak przecinka w tym fragmencie zdania. Przecinek prawdopodobnie należy postawić tak: &apos;świnia, która&apos;.\" replacements=\"świnia, która\" " ) ) ; assertTrue ( output . contains ( "context=\"To jest świnia która się ślini." ) ) ; assertTrue ( output . contains ( "contextoffset=\"8\" offset=\"8\" errorlength=\"12\" category=\"Błędy interpunkcyjne\"" ) ) ; } public void testPolishLineNumbers ( ) throws Exception { final File input = writeToTempFile ( "Test.\n" + "Test.\n" + "Test.\n" + "Test.\n" + "Test.\n" + "Test.\n" + "\n" + "Test który wykaże błąd." ) ; final String [ ] args = { "-l" , "pl" , "-c" , "utf-8" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) , "UTF-8" ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Polish" ) == 0 ) ; assertTrue ( stdout . contains ( "Line 8, column 1, Rule ID: BRAK_PRZECINKA_KTORY" ) ) ; } public void testEnglishTagger ( ) throws Exception { final String [ ] args = { "-l" , "en" , "--taggeronly" , getTestFilePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: English" ) == 0 ) ; assertTrue ( "Got: " + stdout , stdout . contains ( "<S> This[this/DT,B-NP-singular|E-NP-singular] is[be/VBZ,B-VP] an[a/DT,B-NP-singular] test[test/NN,E-NP-singular].[./.,</S>,O]" ) ) ; } public void testBitextMode ( ) throws Exception { final File input = writeToTempFile ( "This is not actual.\tTo nie jest aktualne.\n" + "Test\tTest\n" + "ab\tVery strange data indeed, much longer than input" ) ; final String [ ] args = { "-l" , "pl" , "-c" , "UTF-8" , "--bitext" , "-m" , "en" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Polish" ) == 0 ) ; assertTrue ( stdout . contains ( "Message: Hint: \"aktualny\" (Polish) means \"current\", \"(the) latest\", \"up-to-date\" (English). Did you mean 'rzeczywisty'?" ) ) ; assertTrue ( stdout . contains ( "Line 1, column 32, Rule ID: ACTUAL" ) ) ; assertTrue ( stdout . contains ( "Line 3, column 3, Rule ID: TRANSLATION_LENGTH" ) ) ; } public void testBitextModeWithDisabledRule ( ) throws Exception { final File input = writeToTempFile ( "this is not actual.\tTo nie jest aktualne.\n" + "test\tTest\n" + "ab\tVery strange data indeed, much longer than input" ) ; final String [ ] args = { "-l" , "pl" , "--bitext" , "-m" , "en" , "-d" , "UPPERCASE_SENTENCE_START,TRANSLATION_LENGTH" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Polish" ) == 0 ) ; assertTrue ( stdout . contains ( "Message: Hint: \"aktualny\" (Polish) means \"current\", \"(the) latest\", \"up-to-date\" (English). Did you mean 'rzeczywisty'?" ) ) ; assertTrue ( stdout . contains ( "Line 1, column 32, Rule ID: ACTUAL" ) ) ; assertFalse ( stdout . contains ( "Rule ID: TRANSLATION_LENGTH" ) ) ; } public void testBitextModeWithEnabledRule ( ) throws Exception { final File input = writeToTempFile ( "this is not actual.\tTo nie jest aktualne.\n" + "test\tTest\n" + "ab\tVery strange data indeed, much longer than input" ) ; final String [ ] args = { "-l" , "pl" , "--bitext" , "-m" , "en" , "-e" , "TRANSLATION_LENGTH" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Polish" ) == 0 ) ; assertFalse ( stdout . contains ( "Message: Hint: \"aktualny\" (Polish) means \"current\", \"(the) latest\", \"up-to-date\" (English). Did you mean 'rzeczywisty'?" ) ) ; assertFalse ( stdout . contains ( "Line 1, column 32, Rule ID: ACTUAL" ) ) ; assertTrue ( stdout . contains ( "Rule ID: TRANSLATION_LENGTH" ) ) ; } public void testBitextModeApply ( ) throws Exception { final File input = writeToTempFile ( "There is a dog.\tNie ma psa." ) ; final String [ ] args = { "-l" , "pl" , "--bitext" , "-m" , "en" , "--apply" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertTrue ( output . startsWith ( "Istnieje psa." ) ) ; } public void testBitextWithExternalRule ( ) throws Exception { final File input = writeToTempFile ( "This is a red herring.\tTo jest czerwony śledź." ) ; final String [ ] args = { "-l" , "pl" , "-c" , "UTF-8" , "--bitext" , "-m" , "en" , "--bitextrules" , bitextFile . getAbsolutePath ( ) , input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertTrue ( "red_herring rule should be in the output" + output , output . contains ( "Rule ID: red_herring" ) ) ; } public void testListUnknown ( ) throws Exception { final String [ ] args = { "-l" , "pl" , "-u" , getTestFilePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Polish" ) == 0 ) ; assertTrue ( stdout . contains ( "Unknown words: [., This, an, is, language, of, tool]" ) ) ; } public void testNoListUnknown ( ) throws Exception { final String [ ] args = { "-l" , "pl" , getTestFilePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Polish" ) == 0 ) ; assertTrue ( ! stdout . contains ( "Unknown words: [This, an, is]" ) ) ; } public void testLangWithCountryVariant ( ) throws Exception { final File input = writeToTempFile ( "This is modelling." ) ; final String [ ] args = { "-l" , "en-US" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String stdout = new String ( this . out . toByteArray ( ) ) ; final String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: English (US)" ) == 0 ) ; assertTrue ( stdout . contains ( "MORFOLOGIK_RULE_EN_US" ) ) ; } public void testValencianCatalan ( ) throws Exception { File input = writeToTempFile ( "Que sigui així." ) ; String [ ] args = { "-l" , "ca-ES-valencia" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; String stdout = new String ( this . out . toByteArray ( ) ) ; String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Catalan (Valencian)" ) == 0 ) ; assertTrue ( stdout . contains ( "EXIGEIX_VERBS_VALENCIANS" ) ) ; } public void testCatalan ( ) throws Exception { File input = writeToTempFile ( "Que siga així." ) ; String [ ] args = { "-l" , "ca-ES" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; String stdout = new String ( this . out . toByteArray ( ) ) ; String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Catalan" ) == 0 ) ; assertTrue ( stdout . contains ( "EXIGEIX_VERBS_CENTRAL" ) ) ; } public void testCatalan2 ( ) throws Exception { File input = writeToTempFile ( "Que siga així." ) ; String [ ] args = { "-l" , "ca" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; String stdout = new String ( this . out . toByteArray ( ) ) ; String stderr = new String ( this . err . toByteArray ( ) ) ; assertTrue ( stderr . indexOf ( "Expected text language: Catalan" ) == 0 ) ; assertTrue ( stdout . contains ( "EXIGEIX_VERBS_CENTRAL" ) ) ; } public void testNoXmlFilteringByDefault ( ) throws Exception { final File input = writeToTempFile ( "This < is is > filtered." ) ; final String [ ] args = { input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertTrue ( output . contains ( "ENGLISH_WORD_REPEAT_RULE" ) ) ; } public void testXmlFiltering ( ) throws Exception { final File input = writeToTempFile ( "This < is is > filtered." ) ; final String [ ] args = { "--xmlfilter" , input . getAbsolutePath ( ) } ; Main . main ( args ) ; final String output = new String ( this . out . toByteArray ( ) ) ; assertFalse ( output . contains ( "ENGLISH_WORD_REPEAT_RULE" ) ) ; } private File writeToTempFile ( String content ) throws IOException { final File tempFile = createTempFile ( ) ; try ( PrintWriter writer = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( tempFile ) , "UTF-8" ) ) ) { writer . println ( content ) ; } return tempFile ; } private File createTempFile ( ) throws IOException { final File input = File . createTempFile ( MainTest . class . getName ( ) , ".txt" ) ; input . deleteOnExit ( ) ; return input ; } private File writeToTempXMLFile ( String content ) throws IOException { final File tempFile = createTempXMLFile ( ) ; try ( PrintWriter writer = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( tempFile ) , "UTF-8" ) ) ) { writer . println ( content ) ; } return tempFile ; } private File createTempXMLFile ( ) throws IOException { final File input = File . createTempFile ( "rules-xx-" , ".xml" ) ; input . deleteOnExit ( ) ; return input ; } private String getTestFilePath ( ) { return enTestFile . getAbsolutePath ( ) ; } private String getRuleFilePath ( ) { return xxRuleFile . getAbsolutePath ( ) ; } private String getExternalFalseFriends ( ) { return xxFalseFriendFile . getAbsolutePath ( ) ; } }
package org . languagetool . rules . ro ; import java . io . IOException ; import java . util . ResourceBundle ; import org . languagetool . Language ; import org . languagetool . rules . spelling . morfologik . MorfologikSpellerRule ; public final class MorfologikRomanianSpellerRule extends MorfologikSpellerRule { private static final String RESOURCE_FILENAME = "/ro/hunspell/ro_RO.dict" ; public MorfologikRomanianSpellerRule ( ResourceBundle messages , Language language ) throws IOException { super ( messages , language ) ; } @ Override public String getFileName ( ) { return RESOURCE_FILENAME ; } @ Override public String getId ( ) { return "MORFOLOGIK_RULE_RO_RO" ; } }
package org . languagetool . commandline ; import junit . framework . TestCase ; public class CommandLineParserTest extends TestCase { public void testUsage ( ) throws Exception { final CommandLineParser parser = new CommandLineParser ( ) ; try { parser . parseOptions ( new String [ ] { } ) ; fail ( ) ; } catch ( WrongParameterNumberException ignored ) { } final CommandLineOptions commandLineOptions = parser . parseOptions ( new String [ ] { "--help" } ) ; assertTrue ( commandLineOptions . isPrintUsage ( ) ) ; } public void testErrors ( ) throws Exception { final CommandLineParser parser = new CommandLineParser ( ) ; try { parser . parseOptions ( new String [ ] { "--apply" , "--taggeronly" } ) ; fail ( ) ; } catch ( IllegalArgumentException ignored ) { } } public void testSimple ( ) throws Exception { final CommandLineParser parser = new CommandLineParser ( ) ; CommandLineOptions options ; options = parser . parseOptions ( new String [ ] { "filename.txt" } ) ; assertNull ( options . getLanguage ( ) ) ; assertEquals ( "filename.txt" , options . getFilename ( ) ) ; assertFalse ( options . isVerbose ( ) ) ; options = parser . parseOptions ( new String [ ] { "--language" , "xx" , "filename.txt" } ) ; assertEquals ( "xx" , options . getLanguage ( ) . getShortName ( ) ) ; assertEquals ( "filename.txt" , options . getFilename ( ) ) ; assertFalse ( options . isVerbose ( ) ) ; options = parser . parseOptions ( new String [ ] { "-l" , "xx" , "filename.txt" } ) ; assertEquals ( "xx" , options . getLanguage ( ) . getShortName ( ) ) ; assertEquals ( "filename.txt" , options . getFilename ( ) ) ; assertFalse ( options . isVerbose ( ) ) ; options = parser . parseOptions ( new String [ ] { "-v" , "-l" , "xx" , "filename.txt" } ) ; assertEquals ( "xx" , options . getLanguage ( ) . getShortName ( ) ) ; assertEquals ( "filename.txt" , options . getFilename ( ) ) ; assertTrue ( options . isVerbose ( ) ) ; options = parser . parseOptions ( new String [ ] { "--version" } ) ; assertTrue ( options . isPrintVersion ( ) ) ; options = parser . parseOptions ( new String [ ] { "--list" } ) ; assertTrue ( options . isPrintLanguages ( ) ) ; } }
package org . languagetool . commandline ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . rules . WordRepeatRule ; import org . xml . sax . SAXException ; import javax . xml . parsers . ParserConfigurationException ; import java . io . ByteArrayOutputStream ; import java . io . IOException ; import java . io . PrintStream ; import java . util . Locale ; import java . util . ResourceBundle ; public class CommandLineToolsTest extends TestCase { private ByteArrayOutputStream out ; private PrintStream stdout ; private PrintStream stderr ; @ Override public void setUp ( ) throws Exception { super . setUp ( ) ; this . stdout = System . out ; this . stderr = System . err ; this . out = new ByteArrayOutputStream ( ) ; final ByteArrayOutputStream err = new ByteArrayOutputStream ( ) ; System . setOut ( new PrintStream ( this . out ) ) ; System . setErr ( new PrintStream ( err ) ) ; } @ Override public void tearDown ( ) throws Exception { super . tearDown ( ) ; System . setOut ( this . stdout ) ; System . setErr ( this . stderr ) ; } public void testCheck ( ) throws IOException , ParserConfigurationException , SAXException { final JLanguageTool tool = new JLanguageTool ( TestTools . getDemoLanguage ( ) ) ; int matches = CommandLineTools . checkText ( "Foo." , tool ) ; String output = new String ( this . out . toByteArray ( ) ) ; assertEquals ( 0 , output . indexOf ( "Time:" ) ) ; assertEquals ( 0 , matches ) ; tool . disableRule ( "test_unification_with_negation" ) ; tool . addRule ( new WordRepeatRule ( getMessages ( "en" ) , TestTools . getDemoLanguage ( ) ) ) ; matches = CommandLineTools . checkText ( "To jest problem problem." , tool ) ; output = new String ( this . out . toByteArray ( ) ) ; assertTrue ( output . contains ( "Rule ID: WORD_REPEAT_RULE" ) ) ; assertEquals ( 1 , matches ) ; } private static ResourceBundle getMessages ( String language ) { final ResourceBundle messages = ResourceBundle . getBundle ( JLanguageTool . MESSAGE_BUNDLE , new Locale ( language ) ) ; return messages ; } }
package org . languagetool . commandline ; import java . security . Permission ; import junit . framework . TestCase ; public class AbstractSecurityTestCase extends TestCase { public AbstractSecurityTestCase ( String name ) { super ( name ) ; } protected static class ExitException extends SecurityException { private static final long serialVersionUID = 1L ; public final int status ; public ExitException ( int status ) { super ( "There is no escape!" ) ; this . status = status ; } } private static class NoExitSecurityManager extends SecurityManager { @ Override public void checkPermission ( @ SuppressWarnings ( "unused" ) Permission perm ) { } @ Override @ SuppressWarnings ( "unused" ) public void checkPermission ( Permission perm , Object context ) { } @ Override public void checkExit ( int status ) { super . checkExit ( status ) ; throw new ExitException ( status ) ; } } @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; System . setSecurityManager ( new NoExitSecurityManager ( ) ) ; } @ Override protected void tearDown ( ) throws Exception { System . setSecurityManager ( null ) ; super . tearDown ( ) ; } public void testSomething ( ) { } }
package org . languagetool . commandline ; public class WrongParameterNumberException extends RuntimeException { }
package org . languagetool . commandline ; import org . jetbrains . annotations . Nullable ; import org . languagetool . Language ; import java . io . File ; import java . util . Objects ; public class CommandLineOptions { private boolean printUsage = false ; private boolean printVersion = false ; private boolean printLanguages = false ; private boolean verbose = false ; private boolean recursive = false ; private boolean taggerOnly = false ; private boolean singleLineBreakMarksParagraph = false ; private boolean apiFormat = false ; private boolean listUnknown = false ; private boolean applySuggestions = false ; private boolean profile = false ; private boolean bitext = false ; private boolean autoDetect = false ; private boolean xmlFiltering = false ; @ Nullable private Language language = null ; @ Nullable private Language motherTongue = null ; @ Nullable private File languageModel = null ; @ Nullable private String encoding = null ; @ Nullable private String filename = null ; private String [ ] disabledRules = { } ; private String [ ] enabledRules = { } ; private boolean useEnabledOnly = false ; @ Nullable private String ruleFile = null ; @ Nullable private String falseFriendFile = null ; @ Nullable private String bitextRuleFile = null ; public boolean isPrintUsage ( ) { return printUsage ; } public void setPrintUsage ( boolean printUsage ) { this . printUsage = printUsage ; } public boolean isPrintVersion ( ) { return printVersion ; } public void setPrintVersion ( boolean printVersion ) { this . printVersion = printVersion ; } public boolean isVerbose ( ) { return verbose ; } public void setVerbose ( boolean verbose ) { this . verbose = verbose ; } public boolean isRecursive ( ) { return recursive ; } public void setRecursive ( boolean recursive ) { this . recursive = recursive ; } public boolean isTaggerOnly ( ) { return taggerOnly ; } public void setTaggerOnly ( boolean taggerOnly ) { this . taggerOnly = taggerOnly ; } public boolean isSingleLineBreakMarksParagraph ( ) { return singleLineBreakMarksParagraph ; } public void setSingleLineBreakMarksParagraph ( boolean singleLineBreakMarksParagraph ) { this . singleLineBreakMarksParagraph = singleLineBreakMarksParagraph ; } public boolean isApiFormat ( ) { return apiFormat ; } public void setApiFormat ( boolean apiFormat ) { this . apiFormat = apiFormat ; } public boolean isListUnknown ( ) { return listUnknown ; } public void setListUnknown ( boolean listUnknown ) { this . listUnknown = listUnknown ; } public boolean isApplySuggestions ( ) { return applySuggestions ; } public void setApplySuggestions ( boolean applySuggestions ) { this . applySuggestions = applySuggestions ; } public boolean isProfile ( ) { return profile ; } public void setProfile ( boolean profile ) { this . profile = profile ; } public boolean isBitext ( ) { return bitext ; } public void setBitext ( boolean bitext ) { this . bitext = bitext ; } public boolean isAutoDetect ( ) { return autoDetect ; } public void setAutoDetect ( boolean autoDetect ) { this . autoDetect = autoDetect ; } @ Nullable public Language getLanguage ( ) { return language ; } public void setLanguage ( Language language ) { this . language = language ; } @ Nullable public Language getMotherTongue ( ) { return motherTongue ; } public void setMotherTongue ( Language motherTongue ) { this . motherTongue = motherTongue ; } @ Nullable public File getLanguageModel ( ) { return languageModel ; } public void setLanguageModel ( File languageModel ) { this . languageModel = languageModel ; } @ Nullable public String getRuleFile ( ) { return ruleFile ; } public void setRuleFile ( String ruleFile ) { this . ruleFile = ruleFile ; } @ Nullable public String getEncoding ( ) { return encoding ; } public void setEncoding ( String encoding ) { this . encoding = encoding ; } @ Nullable public String getFilename ( ) { return filename ; } public void setFilename ( String filename ) { this . filename = filename ; } public String [ ] getDisabledRules ( ) { return disabledRules ; } public void setDisabledRules ( String [ ] disabledRules ) { this . disabledRules = Objects . requireNonNull ( disabledRules ) ; } public String [ ] getEnabledRules ( ) { return enabledRules ; } public void setEnabledRules ( String [ ] enabledRules ) { this . enabledRules = Objects . requireNonNull ( enabledRules ) ; } public boolean isUseEnabledOnly ( ) { return useEnabledOnly ; } public void setUseEnabledOnly ( ) { this . useEnabledOnly = true ; } public boolean isXmlFiltering ( ) { return xmlFiltering ; } public void setXmlFiltering ( boolean xmlFiltering ) { this . xmlFiltering = xmlFiltering ; } public boolean isPrintLanguages ( ) { return printLanguages ; } public void setPrintLanguages ( boolean printLanguages ) { this . printLanguages = printLanguages ; } public void setFalseFriendFile ( String arg ) { falseFriendFile = arg ; } @ Nullable public String getFalseFriendFile ( ) { return falseFriendFile ; } @ Nullable public String getBitextRuleFile ( ) { return bitextRuleFile ; } public void setBitextRuleFile ( String bitextRuleFile ) { this . bitextRuleFile = bitextRuleFile ; } }
package org . languagetool . commandline ; import java . io . File ; import java . io . PrintStream ; import org . languagetool . Language ; import org . languagetool . Languages ; public class CommandLineParser { public CommandLineOptions parseOptions ( String [ ] args ) { if ( args . length < 1 || args . length > 12 ) { throw new WrongParameterNumberException ( ) ; } final CommandLineOptions options = new CommandLineOptions ( ) ; for ( int i = 0 ; i < args . length ; i ++ ) { if ( args [ i ] . equals ( "--version" ) ) { options . setPrintVersion ( true ) ; } else if ( args [ i ] . equals ( "--list" ) ) { options . setPrintLanguages ( true ) ; } else if ( args [ i ] . equals ( "-h" ) || args [ i ] . equals ( "-help" ) || args [ i ] . equals ( "--help" ) || args [ i ] . equals ( "--?" ) ) { options . setPrintUsage ( true ) ; } else if ( args [ i ] . equals ( "-adl" ) || args [ i ] . equals ( "--autoDetect" ) ) { options . setAutoDetect ( true ) ; } else if ( args [ i ] . equals ( "-v" ) || args [ i ] . equals ( "--verbose" ) ) { options . setVerbose ( true ) ; } else if ( args [ i ] . equals ( "-t" ) || args [ i ] . equals ( "--taggeronly" ) ) { options . setTaggerOnly ( true ) ; if ( options . isListUnknown ( ) ) { throw new IllegalArgumentException ( "You cannot list unknown words when tagging only" ) ; } if ( options . isApplySuggestions ( ) ) { throw new IllegalArgumentException ( "You cannot apply suggestions when tagging only" ) ; } } else if ( args [ i ] . equals ( "-r" ) || args [ i ] . equals ( "--recursive" ) ) { options . setRecursive ( true ) ; } else if ( args [ i ] . equals ( "-b2" ) || args [ i ] . equals ( "--bitext" ) ) { options . setBitext ( true ) ; } else if ( args [ i ] . equals ( "-eo" ) || args [ i ] . equals ( "--enabledonly" ) ) { if ( options . getDisabledRules ( ) . length > 0 ) { throw new IllegalArgumentException ( "You cannot specify both disabled rules and enabledonly" ) ; } options . setUseEnabledOnly ( ) ; } else if ( args [ i ] . equals ( "-d" ) || args [ i ] . equals ( "--disable" ) ) { if ( options . isUseEnabledOnly ( ) ) { throw new IllegalArgumentException ( "You cannot specify both disabled rules and enabledonly" ) ; } checkArguments ( "-d/--disable" , i , args ) ; final String rules = args [ ++ i ] ; options . setDisabledRules ( rules . split ( "," ) ) ; } else if ( args [ i ] . equals ( "-e" ) || args [ i ] . equals ( "--enable" ) ) { checkArguments ( "-e/--enable" , i , args ) ; final String rules = args [ ++ i ] ; options . setEnabledRules ( rules . split ( "," ) ) ; } else if ( args [ i ] . equals ( "-l" ) || args [ i ] . equals ( "--language" ) ) { checkArguments ( "-l/--language" , i , args ) ; options . setLanguage ( getLanguage ( args [ ++ i ] ) ) ; } else if ( args [ i ] . equals ( "-m" ) || args [ i ] . equals ( "--mothertongue" ) ) { checkArguments ( "-m/--mothertongue" , i , args ) ; options . setMotherTongue ( getLanguage ( args [ ++ i ] ) ) ; } else if ( args [ i ] . equals ( "--languagemodel" ) ) { checkArguments ( "--languagemodel" , i , args ) ; options . setLanguageModel ( new File ( args [ ++ i ] ) ) ; } else if ( args [ i ] . equals ( "--rulefile" ) ) { checkArguments ( "--rulefile" , i , args ) ; options . setRuleFile ( args [ ++ i ] ) ; } else if ( args [ i ] . equals ( "--falsefriends" ) ) { checkArguments ( "--falsefriends" , i , args ) ; options . setFalseFriendFile ( args [ ++ i ] ) ; } else if ( args [ i ] . equals ( "--bitextrules" ) ) { checkArguments ( "--bitextrules" , i , args ) ; options . setBitextRuleFile ( args [ ++ i ] ) ; } else if ( args [ i ] . equals ( "-c" ) || args [ i ] . equals ( "--encoding" ) ) { checkArguments ( "-c/--encoding" , i , args ) ; options . setEncoding ( args [ ++ i ] ) ; } else if ( args [ i ] . equals ( "-u" ) || args [ i ] . equals ( "--list-unknown" ) ) { options . setListUnknown ( true ) ; if ( options . isTaggerOnly ( ) ) { throw new IllegalArgumentException ( "You cannot list unknown words when tagging only" ) ; } } else if ( args [ i ] . equals ( "-b" ) ) { options . setSingleLineBreakMarksParagraph ( true ) ; } else if ( args [ i ] . equals ( "--api" ) ) { options . setApiFormat ( true ) ; if ( options . isApplySuggestions ( ) ) { throw new IllegalArgumentException ( "API format makes no sense for automatic application of suggestions" ) ; } } else if ( args [ i ] . equals ( "-a" ) || args [ i ] . equals ( "--apply" ) ) { options . setApplySuggestions ( true ) ; if ( options . isTaggerOnly ( ) ) { throw new IllegalArgumentException ( "You cannot apply suggestions when tagging only" ) ; } if ( options . isApiFormat ( ) ) { throw new IllegalArgumentException ( "API format makes no sense for automatic application of suggestions" ) ; } } else if ( args [ i ] . equals ( "-p" ) || args [ i ] . equals ( "--profile" ) ) { options . setProfile ( true ) ; if ( options . isApiFormat ( ) ) { throw new IllegalArgumentException ( "API format makes no sense for profiling" ) ; } if ( options . isApplySuggestions ( ) ) { throw new IllegalArgumentException ( "Applying suggestions makes no sense for profiling" ) ; } if ( options . isTaggerOnly ( ) ) { throw new IllegalArgumentException ( "Tagging makes no sense for profiling" ) ; } } else if ( args [ i ] . equals ( "--xmlfilter" ) ) { options . setXmlFiltering ( true ) ; } else if ( i == args . length - 1 ) { options . setFilename ( args [ i ] ) ; } else { throw new UnknownParameterException ( "Unknown parameter: " + args [ i ] ) ; } } return options ; } public void printUsage ( ) { printUsage ( System . out ) ; } public void printUsage ( PrintStream stream ) { stream . println ( "Usage: java -jar languagetool-commandline.jar [OPTION]... FILE\n" + " FILE plain text file to be checked\n" + " Available options:\n" + " -r, --recursive work recursively on directory, not on a single file\n" + " -c, --encoding ENC character set of the input text, e.g. utf-8 or latin1\n" + " -b assume that a single line break marks the end of a paragraph\n" + " -l, --language LANG the language code of the text, e.g. en for English, en-GB for British English\n" + " --list print all available languages and exit\n" + " -adl, --autoDetect auto-detect the language of the input text\n" + " -m, --mothertongue LANG the language code of your first language, used to activate false-friend checking\n" + " -d, --disable RULES a comma-separated list of rule ids to be disabled (use no spaces between ids)\n" + " -e, --enable RULES a comma-separated list of rule ids to be enabled (use no spaces between ids)\n" + " -eo, --enabledonly disable all rules except those enabled explicitly in -e\n" + " -t, --taggeronly don't check, but only print text analysis (sentences, part-of-speech tags)\n" + " -u, --list-unknown also print a summary of words from the input that LanguageTool doesn't know\n" + " -b2, --bitext check bilingual texts with a tab-separated input file,\n" + " see http://languagetool.wikidot.com/checking-translations-bilingual-texts\n" + " --api print results as XML\n" + " -p, --profile print performance measurements\n" + " -v, --verbose print text analysis (sentences, part-of-speech tags) to STDERR\n" + " --version print LanguageTool version number and exit\n" + " -a, --apply automatically apply suggestions if available, printing result to STDOUT\n" + " --rulefile FILE use an additional grammar file; if the filename contains a known language code,\n" + " it is used in addition of standard rules\n" + " --falsefriends FILE use external false friend file to be used along with the built-in rules\n" + " --bitextrules FILE use external bitext XML rule file (useful only in bitext mode)\n" + " --languagemodel DIR a directory with '1grams'...'3grams' sub directories with Lucene indexes that\n" + " contain ngram occurrence counts; activates the confusion rule if supported\n" + " --xmlfilter remove XML/HTML elements from input before checking (this is deprecated)" ) ; } private void checkArguments ( String option , int argParsingPos , String [ ] args ) { if ( argParsingPos + 1 >= args . length ) { throw new IllegalArgumentException ( "Missing argument to " + option + " command line option." ) ; } } private Language getLanguage ( String userSuppliedLangCode ) { return Languages . getLanguageForShortName ( userSuppliedLangCode ) ; } }
package org . languagetool . commandline ; import org . languagetool . JLanguageTool ; import org . languagetool . Language ; import org . languagetool . Languages ; import org . languagetool . MultiThreadedJLanguageTool ; import org . languagetool . bitext . TabBitextReader ; import org . languagetool . language . English ; import org . languagetool . language . LanguageIdentifier ; import org . languagetool . rules . Rule ; import org . languagetool . rules . bitext . BitextRule ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . rules . patterns . PatternRuleLoader ; import org . languagetool . tools . JnaTools ; import org . languagetool . tools . Tools ; import org . xml . sax . SAXException ; import javax . xml . parsers . ParserConfigurationException ; import java . io . * ; import java . nio . charset . Charset ; import java . util . * ; import static org . languagetool . tools . StringTools . * ; class Main { private static final int MAX_FILE_SIZE = 64000 ; private final boolean verbose ; private final boolean apiFormat ; private final boolean taggerOnly ; private final boolean applySuggestions ; private final boolean autoDetect ; private final boolean singleLineBreakMarksParagraph ; private final boolean listUnknownWords ; private final List < String > unknownWords ; private final String [ ] enabledRules ; private final String [ ] disabledRules ; private final Language motherTongue ; private MultiThreadedJLanguageTool lt ; private boolean profileRules ; private boolean bitextMode ; private MultiThreadedJLanguageTool srcLt ; private List < BitextRule > bRules ; private Rule currentRule ; Main ( CommandLineOptions options ) throws IOException { this . verbose = options . isVerbose ( ) ; this . apiFormat = options . isApiFormat ( ) ; this . taggerOnly = options . isTaggerOnly ( ) ; this . applySuggestions = options . isApplySuggestions ( ) ; this . autoDetect = options . isAutoDetect ( ) ; this . enabledRules = options . getEnabledRules ( ) ; this . disabledRules = options . getDisabledRules ( ) ; this . motherTongue = options . getMotherTongue ( ) ; this . singleLineBreakMarksParagraph = options . isSingleLineBreakMarksParagraph ( ) ; this . listUnknownWords = options . isListUnknown ( ) ; this . unknownWords = new ArrayList < > ( ) ; profileRules = false ; bitextMode = false ; srcLt = null ; bRules = null ; lt = new MultiThreadedJLanguageTool ( options . getLanguage ( ) , motherTongue ) ; if ( options . getRuleFile ( ) != null ) { addExternalRules ( options . getRuleFile ( ) ) ; } if ( options . getLanguageModel ( ) != null ) { lt . activateLanguageModelRules ( options . getLanguageModel ( ) ) ; } Tools . selectRules ( lt , disabledRules , enabledRules , options . isUseEnabledOnly ( ) ) ; } private void addExternalRules ( String filename ) throws IOException { PatternRuleLoader ruleLoader = new PatternRuleLoader ( ) ; try ( InputStream is = new FileInputStream ( filename ) ) { List < PatternRule > externalRules = ruleLoader . getRules ( is , filename ) ; for ( PatternRule externalRule : externalRules ) { lt . addRule ( externalRule ) ; } } } boolean isSpellCheckingActive ( ) { List < Rule > rules = lt . getAllActiveRules ( ) ; for ( Rule rule : rules ) { if ( rule . isDictionaryBasedSpellingRule ( ) ) { return true ; } } return false ; } JLanguageTool getJLanguageTool ( ) { return lt ; } private void setListUnknownWords ( final boolean listUnknownWords ) { lt . setListUnknownWords ( listUnknownWords ) ; } private void cleanUp ( ) { if ( lt != null ) { lt . shutdown ( ) ; } if ( srcLt != null ) { srcLt . shutdown ( ) ; } JLanguageTool . removeTemporaryFiles ( ) ; } private void setProfilingMode ( ) { profileRules = true ; } private void setBitextMode ( final Language sourceLang , final String [ ] disabledRules , final String [ ] enabledRules , final File bitextRuleFile ) throws IOException , ParserConfigurationException , SAXException { bitextMode = true ; final Language target = lt . getLanguage ( ) ; lt = new MultiThreadedJLanguageTool ( target , null ) ; srcLt = new MultiThreadedJLanguageTool ( sourceLang ) ; Tools . selectRules ( lt , disabledRules , enabledRules ) ; Tools . selectRules ( srcLt , disabledRules , enabledRules ) ; bRules = Tools . getBitextRules ( sourceLang , lt . getLanguage ( ) , bitextRuleFile ) ; List < BitextRule > bRuleList = new ArrayList < > ( bRules ) ; for ( final BitextRule bitextRule : bRules ) { for ( final String disabledRule : disabledRules ) { if ( bitextRule . getId ( ) . equals ( disabledRule ) ) { bRuleList . remove ( bitextRule ) ; } } } bRules = bRuleList ; if ( enabledRules . length > 0 ) { bRuleList = new ArrayList < > ( ) ; for ( final String enabledRule : enabledRules ) { for ( final BitextRule bitextRule : bRules ) { if ( bitextRule . getId ( ) . equals ( enabledRule ) ) { bRuleList . add ( bitextRule ) ; } } } bRules = bRuleList ; } } private void runOnFile ( final String filename , final String encoding , final boolean xmlFiltering ) throws IOException { boolean oneTime = false ; if ( ! isStdIn ( filename ) ) { if ( autoDetect ) { Language language = detectLanguageOfFile ( filename , encoding ) ; if ( language == null ) { System . err . println ( "Could not detect language well enough, using English" ) ; language = new English ( ) ; } changeLanguage ( language , motherTongue , disabledRules , enabledRules ) ; System . err . println ( "Using " + language . getName ( ) + " for file " + filename ) ; } final File file = new File ( filename ) ; oneTime = file . length ( ) < MAX_FILE_SIZE || bitextMode ; } if ( oneTime ) { runOnFileInOneGo ( filename , encoding , xmlFiltering ) ; } else { runOnFileLineByLine ( filename , encoding ) ; } } private void runOnFileInOneGo ( String filename , String encoding , boolean xmlFiltering ) throws IOException { if ( bitextMode ) { final TabBitextReader reader = new TabBitextReader ( filename , encoding ) ; if ( applySuggestions ) { CommandLineTools . correctBitext ( reader , srcLt , lt , bRules ) ; } else { CommandLineTools . checkBitext ( reader , srcLt , lt , bRules , apiFormat ) ; } } else { final String text = getFilteredText ( filename , encoding , xmlFiltering ) ; if ( applySuggestions ) { System . out . print ( Tools . correctText ( text , lt ) ) ; } else if ( profileRules ) { CommandLineTools . profileRulesOnText ( text , lt ) ; } else if ( ! taggerOnly ) { CommandLineTools . checkText ( text , lt , apiFormat , 0 , listUnknownWords ) ; } else { CommandLineTools . tagText ( text , lt ) ; } if ( listUnknownWords && ! apiFormat ) { System . out . println ( "Unknown words: " + lt . getUnknownWords ( ) ) ; } } } private void runOnFileLineByLine ( String filename , String encoding ) throws IOException { if ( verbose ) { lt . setOutput ( System . err ) ; } if ( ! apiFormat && ! applySuggestions ) { if ( isStdIn ( filename ) ) { System . err . println ( "Working on STDIN..." ) ; } else { System . err . println ( "Working on " + filename + "..." ) ; } } if ( profileRules && isStdIn ( filename ) ) { throw new IllegalArgumentException ( "Profiling mode cannot be used with input from STDIN" ) ; } int runCount = 1 ; final List < Rule > rules = lt . getAllActiveRules ( ) ; if ( profileRules ) { System . out . printf ( "Testing %d rules\n" , rules . size ( ) ) ; System . out . println ( "Rule ID\tTime\tSentences\tMatches\tSentences per sec." ) ; runCount = rules . size ( ) ; } int lineOffset = 0 ; int tmpLineOffset = 0 ; handleLine ( XmlPrintMode . START_XML , 0 , new StringBuilder ( ) ) ; StringBuilder sb = new StringBuilder ( ) ; for ( int ruleIndex = 0 ; ! rules . isEmpty ( ) && ruleIndex < runCount ; ruleIndex ++ ) { currentRule = rules . get ( ruleIndex ) ; int matches = 0 ; long sentences = 0 ; final long startTime = System . currentTimeMillis ( ) ; try ( InputStreamReader isr = getInputStreamReader ( filename , encoding ) ; BufferedReader br = new BufferedReader ( isr ) ) { String line ; int lineCount = 0 ; while ( ( line = br . readLine ( ) ) != null ) { sb . append ( line ) ; lineCount ++ ; if ( lineCount == 1 && autoDetect ) { Language language = detectLanguageOfString ( line ) ; if ( language == null ) { System . err . println ( "Could not detect language well enough, using English" ) ; language = new English ( ) ; } System . err . println ( "Language used is: " + language . getName ( ) ) ; language . getSentenceTokenizer ( ) . setSingleLineBreaksMarksParagraph ( singleLineBreakMarksParagraph ) ; changeLanguage ( language , motherTongue , disabledRules , enabledRules ) ; } sb . append ( '\n' ) ; tmpLineOffset ++ ; if ( isBreakPoint ( sb , line ) ) { matches += handleLine ( XmlPrintMode . CONTINUE_XML , lineOffset , sb ) ; sentences += lt . getSentenceCount ( ) ; if ( profileRules ) { sentences += lt . sentenceTokenize ( sb . toString ( ) ) . size ( ) ; } rememberUnknownWords ( ) ; sb = new StringBuilder ( ) ; lineOffset = tmpLineOffset ; } } } finally { if ( sb . length ( ) > 0 ) { sentences += lt . getSentenceCount ( ) ; if ( profileRules ) { sentences += lt . sentenceTokenize ( sb . toString ( ) ) . size ( ) ; } rememberUnknownWords ( ) ; } matches += handleLine ( XmlPrintMode . END_XML , tmpLineOffset - 1 , sb ) ; printTimingInformation ( rules , ruleIndex , matches , sentences , startTime ) ; } } } private boolean isBreakPoint ( StringBuilder sb , String line ) { return lt . getLanguage ( ) . getSentenceTokenizer ( ) . singleLineBreaksMarksPara ( ) || "" . equals ( line ) || sb . length ( ) >= MAX_FILE_SIZE ; } private void rememberUnknownWords ( ) { if ( listUnknownWords && ! taggerOnly ) { for ( String word : lt . getUnknownWords ( ) ) { if ( ! unknownWords . contains ( word ) ) { unknownWords . add ( word ) ; } } } } private InputStreamReader getInputStreamReader ( String filename , String encoding ) throws UnsupportedEncodingException , FileNotFoundException { final InputStreamReader isr ; if ( ! isStdIn ( filename ) ) { final File file = new File ( filename ) ; if ( encoding != null ) { isr = new InputStreamReader ( new BufferedInputStream ( new FileInputStream ( file ) ) , encoding ) ; } else { isr = new InputStreamReader ( new BufferedInputStream ( new FileInputStream ( file ) ) ) ; } } else { if ( encoding != null ) { isr = new InputStreamReader ( new BufferedInputStream ( System . in ) , encoding ) ; } else { isr = new InputStreamReader ( new BufferedInputStream ( System . in ) ) ; } } return isr ; } private boolean isStdIn ( String filename ) { return "-" . equals ( filename ) ; } private void printTimingInformation ( final List < Rule > rules , final int ruleIndex , final int matches , final long sentences , final long startTime ) { if ( ! applySuggestions ) { final long endTime = System . currentTimeMillis ( ) ; final long time = endTime - startTime ; final float timeInSeconds = time / 1000.0f ; final float sentencesPerSecond = sentences / timeInSeconds ; if ( apiFormat ) { System . out . println ( "<!--" ) ; } if ( profileRules ) { System . out . printf ( Locale . ENGLISH , "%s\t%d\t%d\t%d\t%.1f" , rules . get ( ruleIndex ) . getId ( ) , time , sentences , matches , sentencesPerSecond ) ; System . out . println ( ) ; } else { System . out . printf ( Locale . ENGLISH , "Time: %dms for %d sentences (%.1f sentences/sec)" , time , sentences , sentencesPerSecond ) ; System . out . println ( ) ; } if ( listUnknownWords && ! apiFormat ) { Collections . sort ( unknownWords ) ; System . out . println ( "Unknown words: " + unknownWords ) ; } if ( apiFormat ) { System . out . println ( "-->" ) ; } } } private int handleLine ( final XmlPrintMode mode , final int lineOffset , final StringBuilder sb ) throws IOException { int matches = 0 ; String s = filterXML ( sb . toString ( ) ) ; if ( applySuggestions ) { System . out . print ( Tools . correctText ( s , lt ) ) ; } else if ( profileRules ) { matches += Tools . profileRulesOnLine ( s , lt , currentRule ) ; } else if ( ! taggerOnly ) { matches += CommandLineTools . checkText ( s , lt , apiFormat , - 1 , lineOffset , matches , mode , listUnknownWords , unknownWords ) ; } else { CommandLineTools . tagText ( s , lt ) ; } return matches ; } private void runRecursive ( final String filename , final String encoding , final boolean xmlFiltering ) { final File dir = new File ( filename ) ; final File [ ] files = dir . listFiles ( ) ; if ( files == null ) { throw new IllegalArgumentException ( dir . getAbsolutePath ( ) + " is not a directory, cannot use recursion" ) ; } for ( final File file : files ) { try { if ( file . isDirectory ( ) ) { runRecursive ( file . getAbsolutePath ( ) , encoding , xmlFiltering ) ; } else { runOnFile ( file . getAbsolutePath ( ) , encoding , xmlFiltering ) ; } } catch ( Exception e ) { throw new RuntimeException ( "Could not check text in file " + file , e ) ; } } } private String getFilteredText ( final String filename , final String encoding , boolean xmlFiltering ) throws IOException { if ( verbose ) { lt . setOutput ( System . err ) ; } if ( ! apiFormat && ! applySuggestions ) { System . out . println ( "Working on " + filename + "..." ) ; } final String fileContents = streamToString ( new FileInputStream ( filename ) , encoding != null ? encoding : Charset . defaultCharset ( ) . name ( ) ) ; if ( xmlFiltering ) { return filterXML ( fileContents ) ; } else { return fileContents ; } } private void changeLanguage ( Language language , Language motherTongue , String [ ] disabledRules , String [ ] enabledRules ) { try { lt = new MultiThreadedJLanguageTool ( language , motherTongue ) ; Tools . selectRules ( lt , disabledRules , enabledRules ) ; if ( verbose ) { lt . setOutput ( System . err ) ; } } catch ( Exception e ) { throw new RuntimeException ( "Could not create LanguageTool instance for language " + language , e ) ; } } public static void main ( final String [ ] args ) throws IOException , ParserConfigurationException , SAXException { JnaTools . setBugWorkaroundProperty ( ) ; final CommandLineParser commandLineParser = new CommandLineParser ( ) ; CommandLineOptions options = null ; try { options = commandLineParser . parseOptions ( args ) ; } catch ( WrongParameterNumberException e ) { commandLineParser . printUsage ( ) ; System . exit ( 1 ) ; } catch ( IllegalArgumentException e ) { System . err . println ( e . toString ( ) ) ; System . exit ( 1 ) ; } catch ( UnknownParameterException e ) { if ( e . getMessage ( ) != null ) { System . err . println ( e . getMessage ( ) ) ; } else { System . err . println ( e . toString ( ) ) ; } commandLineParser . printUsage ( System . err ) ; System . exit ( 1 ) ; } if ( options . isPrintUsage ( ) ) { commandLineParser . printUsage ( ) ; System . exit ( 1 ) ; } if ( options . isPrintVersion ( ) ) { System . out . println ( "LanguageTool version " + JLanguageTool . VERSION + " (" + JLanguageTool . BUILD_DATE + ")" ) ; System . exit ( 0 ) ; } if ( options . isPrintLanguages ( ) ) { printLanguages ( ) ; System . exit ( 0 ) ; } if ( options . getFilename ( ) == null ) { options . setFilename ( "-" ) ; } String languageHint = null ; if ( options . getLanguage ( ) == null ) { if ( ! options . isApiFormat ( ) && ! options . isAutoDetect ( ) ) { System . err . println ( "No language specified, using English (no spell checking active, " + "specify a language variant like 'en-GB' if available)" ) ; } options . setLanguage ( new English ( ) ) ; } else if ( ! options . isApiFormat ( ) && ! options . isApplySuggestions ( ) ) { languageHint = "Expected text language: " + options . getLanguage ( ) . getName ( ) ; } options . getLanguage ( ) . getSentenceTokenizer ( ) . setSingleLineBreaksMarksParagraph ( options . isSingleLineBreakMarksParagraph ( ) ) ; final Main prg = new Main ( options ) ; if ( options . getFalseFriendFile ( ) != null ) { List < PatternRule > ffRules = prg . lt . loadFalseFriendRules ( options . getFalseFriendFile ( ) ) ; for ( PatternRule ffRule : ffRules ) { prg . lt . addRule ( ffRule ) ; } } if ( prg . lt . getAllActiveRules ( ) . size ( ) == 0 ) { throw new RuntimeException ( "WARNING: No rules are active. Please make sure your rule ids are correct: " + Arrays . toString ( options . getEnabledRules ( ) ) ) ; } if ( languageHint != null ) { String spellHint = prg . isSpellCheckingActive ( ) ? "" : " (no spell checking active, specify a language variant like 'en-GB' if available)" ; System . err . println ( languageHint + spellHint ) ; } prg . setListUnknownWords ( options . isListUnknown ( ) ) ; if ( options . isProfile ( ) ) { prg . setProfilingMode ( ) ; } if ( options . isBitext ( ) ) { if ( options . getMotherTongue ( ) == null ) { throw new IllegalArgumentException ( "You have to set the source language (as mother tongue) in bitext mode" ) ; } File bitextRuleFile = options . getBitextRuleFile ( ) != null ? new File ( options . getBitextRuleFile ( ) ) : null ; prg . setBitextMode ( options . getMotherTongue ( ) , options . getDisabledRules ( ) , options . getEnabledRules ( ) , bitextRuleFile ) ; } if ( options . isRecursive ( ) ) { prg . runRecursive ( options . getFilename ( ) , options . getEncoding ( ) , options . isXmlFiltering ( ) ) ; } else { prg . runOnFile ( options . getFilename ( ) , options . getEncoding ( ) , options . isXmlFiltering ( ) ) ; } prg . cleanUp ( ) ; } private static void printLanguages ( ) { final List < String > languages = new ArrayList < > ( ) ; for ( Language language : Languages . get ( ) ) { languages . add ( language . getShortNameWithCountryAndVariant ( ) + " " + language . getName ( ) ) ; } Collections . sort ( languages ) ; for ( String s : languages ) { System . out . println ( s ) ; } } private static Language detectLanguageOfFile ( final String filename , final String encoding ) throws IOException { final String text = readStream ( new FileInputStream ( filename ) , encoding ) ; return detectLanguageOfString ( text ) ; } private static Language detectLanguageOfString ( final String text ) { LanguageIdentifier identifier = new LanguageIdentifier ( ) ; return identifier . detectLanguage ( text ) ; } }
package org . languagetool . commandline ; import org . languagetool . AnalyzedSentence ; import org . languagetool . JLanguageTool ; import org . languagetool . bitext . BitextReader ; import org . languagetool . bitext . StringPair ; import org . languagetool . rules . Rule ; import org . languagetool . rules . RuleMatch ; import org . languagetool . rules . TextLevelRule ; import org . languagetool . rules . bitext . BitextRule ; import org . languagetool . rules . patterns . PatternRule ; import org . languagetool . tokenizers . SentenceTokenizer ; import org . languagetool . tools . ContextTools ; import org . languagetool . tools . RuleAsXmlSerializer ; import org . languagetool . tools . StringTools ; import org . languagetool . tools . Tools ; import java . io . IOException ; import java . io . PrintStream ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import java . util . Locale ; public final class CommandLineTools { private static final int DEFAULT_CONTEXT_SIZE = 45 ; private CommandLineTools ( ) { } public static void tagText ( final String contents , final JLanguageTool lt ) throws IOException { AnalyzedSentence analyzedText ; final List < String > sentences = lt . sentenceTokenize ( contents ) ; for ( final String sentence : sentences ) { analyzedText = lt . getAnalyzedSentence ( sentence ) ; System . out . println ( analyzedText ) ; } } public static int checkText ( final String contents , final JLanguageTool lt ) throws IOException { return checkText ( contents , lt , false , - 1 , 0 , 0 , StringTools . XmlPrintMode . NORMAL_XML , false , Collections . < String > emptyList ( ) ) ; } public static int checkText ( final String contents , final JLanguageTool lt , final boolean apiFormat , final int lineOffset ) throws IOException { return checkText ( contents , lt , apiFormat , - 1 , lineOffset , 0 , StringTools . XmlPrintMode . NORMAL_XML , false , Collections . < String > emptyList ( ) ) ; } public static int checkText ( final String contents , final JLanguageTool lt , final boolean apiFormat , final int lineOffset , final boolean listUnknownWords ) throws IOException { return checkText ( contents , lt , apiFormat , - 1 , lineOffset , 0 , StringTools . XmlPrintMode . NORMAL_XML , listUnknownWords , Collections . < String > emptyList ( ) ) ; } public static int checkText ( final String contents , final JLanguageTool lt , final boolean apiFormat , int contextSize , final int lineOffset , final int prevMatches , final StringTools . XmlPrintMode xmlMode , final boolean listUnknownWords , List < String > unknownWords ) throws IOException { if ( contextSize == - 1 ) { contextSize = DEFAULT_CONTEXT_SIZE ; } final long startTime = System . currentTimeMillis ( ) ; final List < RuleMatch > ruleMatches = lt . check ( contents ) ; for ( RuleMatch r : ruleMatches ) { r . setLine ( r . getLine ( ) + lineOffset ) ; r . setEndLine ( r . getEndLine ( ) + lineOffset ) ; } if ( apiFormat ) { if ( listUnknownWords && xmlMode == StringTools . XmlPrintMode . NORMAL_XML ) { unknownWords = lt . getUnknownWords ( ) ; } final RuleAsXmlSerializer serializer = new RuleAsXmlSerializer ( ) ; final String xml = serializer . ruleMatchesToXml ( ruleMatches , contents , contextSize , xmlMode , lt . getLanguage ( ) , unknownWords ) ; final PrintStream out = new PrintStream ( System . out , true , "UTF-8" ) ; out . print ( xml ) ; } else { printMatches ( ruleMatches , prevMatches , contents , contextSize ) ; } if ( xmlMode == StringTools . XmlPrintMode . NORMAL_XML ) { SentenceTokenizer sentenceTokenizer = lt . getLanguage ( ) . getSentenceTokenizer ( ) ; int sentenceCount = sentenceTokenizer . tokenize ( contents ) . size ( ) ; displayTimeStats ( startTime , sentenceCount , apiFormat ) ; } return ruleMatches . size ( ) ; } private static void displayTimeStats ( final long startTime , final long sentCount , final boolean apiFormat ) { final long endTime = System . currentTimeMillis ( ) ; final long time = endTime - startTime ; final float timeInSeconds = time / 1000.0f ; final float sentencesPerSecond = sentCount / timeInSeconds ; if ( apiFormat ) { System . out . println ( "<!--" ) ; } System . out . printf ( Locale . ENGLISH , "Time: %dms for %d sentences (%.1f sentences/sec)" , time , sentCount , sentencesPerSecond ) ; System . out . println ( ) ; if ( apiFormat ) { System . out . println ( "-->" ) ; } } private static void printMatches ( final List < RuleMatch > ruleMatches , final int prevMatches , final String contents , final int contextSize ) { int i = 1 ; final ContextTools contextTools = new ContextTools ( ) ; contextTools . setContextSize ( contextSize ) ; for ( final RuleMatch match : ruleMatches ) { Rule rule = match . getRule ( ) ; String output = i + prevMatches + ".) Line " + ( match . getLine ( ) + 1 ) + ", column " + match . getColumn ( ) + ", Rule ID: " + rule . getId ( ) ; if ( rule instanceof PatternRule ) { final PatternRule pRule = ( PatternRule ) rule ; if ( pRule . getSubId ( ) != null ) { output += "[" + pRule . getSubId ( ) + "]" ; } } System . out . println ( output ) ; String msg = match . getMessage ( ) ; msg = msg . replaceAll ( "<suggestion>" , "'" ) ; msg = msg . replaceAll ( "</suggestion>" , "'" ) ; System . out . println ( "Message: " + msg ) ; final List < String > replacements = match . getSuggestedReplacements ( ) ; if ( ! replacements . isEmpty ( ) ) { System . out . println ( "Suggestion: " + StringTools . listToString ( replacements , "; " ) ) ; } System . out . println ( contextTools . getPlainTextContext ( match . getFromPos ( ) , match . getToPos ( ) , contents ) ) ; if ( rule . getUrl ( ) != null ) { System . out . println ( "More info: " + rule . getUrl ( ) ) ; } if ( i < ruleMatches . size ( ) ) { System . out . println ( ) ; } i ++ ; } } public static int checkBitext ( final BitextReader reader , final JLanguageTool srcLt , final JLanguageTool trgLt , final List < BitextRule > bRules , final boolean apiFormat ) throws IOException { final long startTime = System . currentTimeMillis ( ) ; final int contextSize = DEFAULT_CONTEXT_SIZE ; final List < RuleMatch > ruleMatches = new ArrayList < > ( ) ; int matchCount = 0 ; int sentCount = 0 ; final RuleAsXmlSerializer serializer = new RuleAsXmlSerializer ( ) ; final PrintStream out = new PrintStream ( System . out , true , "UTF-8" ) ; if ( apiFormat ) { out . print ( serializer . getXmlStart ( null , null ) ) ; } for ( StringPair srcAndTrg : reader ) { final List < RuleMatch > curMatches = Tools . checkBitext ( srcAndTrg . getSource ( ) , srcAndTrg . getTarget ( ) , srcLt , trgLt , bRules ) ; final List < RuleMatch > fixedMatches = new ArrayList < > ( ) ; for ( RuleMatch thisMatch : curMatches ) { fixedMatches . add ( trgLt . adjustRuleMatchPos ( thisMatch , reader . getSentencePosition ( ) , reader . getColumnCount ( ) , reader . getLineCount ( ) , reader . getCurrentLine ( ) , null ) ) ; } ruleMatches . addAll ( fixedMatches ) ; if ( fixedMatches . size ( ) > 0 ) { if ( apiFormat ) { final String xml = serializer . ruleMatchesToXmlSnippet ( fixedMatches , reader . getCurrentLine ( ) , contextSize ) ; out . print ( xml ) ; } else { printMatches ( fixedMatches , matchCount , reader . getCurrentLine ( ) , contextSize ) ; matchCount += fixedMatches . size ( ) ; } } sentCount ++ ; } displayTimeStats ( startTime , sentCount , apiFormat ) ; if ( apiFormat ) { out . print ( serializer . getXmlEnd ( ) ) ; } return ruleMatches . size ( ) ; } public static void profileRulesOnText ( final String contents , final JLanguageTool lt ) throws IOException { final long [ ] workTime = new long [ 10 ] ; final List < Rule > rules = lt . getAllActiveRules ( ) ; final int ruleCount = rules . size ( ) ; System . out . printf ( "Testing %d rules%n" , ruleCount ) ; System . out . println ( "Rule ID\tTime\tSentences\tMatches\tSentences per sec." ) ; final List < String > sentences = lt . sentenceTokenize ( contents ) ; for ( Rule rule : rules ) { if ( rule instanceof TextLevelRule ) { continue ; } int matchCount = 0 ; for ( int k = 0 ; k < 10 ; k ++ ) { final long startTime = System . currentTimeMillis ( ) ; for ( String sentence : sentences ) { matchCount += rule . match ( lt . getAnalyzedSentence ( sentence ) ) . length ; } final long endTime = System . currentTimeMillis ( ) ; workTime [ k ] = endTime - startTime ; } final long time = median ( workTime ) ; final float timeInSeconds = time / 1000.0f ; final float sentencesPerSecond = sentences . size ( ) / timeInSeconds ; System . out . printf ( Locale . ENGLISH , "%s\t%d\t%d\t%d\t%.1f" , rule . getId ( ) , time , sentences . size ( ) , matchCount , sentencesPerSecond ) ; System . out . println ( ) ; } } private static long median ( long [ ] m ) { Arrays . sort ( m ) ; final int middle = m . length / 2 ; if ( m . length % 2 == 1 ) { return m [ middle ] ; } return ( m [ middle - 1 ] + m [ middle ] ) / 2 ; } public static void correctBitext ( final BitextReader reader , final JLanguageTool sourceLt , final JLanguageTool targetLt , final List < BitextRule > bRules ) throws IOException { for ( StringPair srcAndTrg : reader ) { final List < RuleMatch > curMatches = Tools . checkBitext ( srcAndTrg . getSource ( ) , srcAndTrg . getTarget ( ) , sourceLt , targetLt , bRules ) ; final List < RuleMatch > fixedMatches = new ArrayList < > ( ) ; for ( RuleMatch thisMatch : curMatches ) { fixedMatches . add ( targetLt . adjustRuleMatchPos ( thisMatch , 0 , reader . getTargetColumnCount ( ) , reader . getLineCount ( ) , reader . getCurrentLine ( ) , null ) ) ; } if ( fixedMatches . size ( ) > 0 ) { System . out . println ( correctTextFromMatches ( srcAndTrg . getTarget ( ) , fixedMatches ) ) ; } else { System . out . println ( srcAndTrg . getTarget ( ) ) ; } } } private static String correctTextFromMatches ( final String contents , final List < RuleMatch > matches ) { final StringBuilder sb = new StringBuilder ( contents ) ; final List < String > errors = new ArrayList < > ( ) ; for ( RuleMatch rm : matches ) { final List < String > replacements = rm . getSuggestedReplacements ( ) ; if ( ! replacements . isEmpty ( ) ) { errors . add ( sb . substring ( rm . getFromPos ( ) , rm . getToPos ( ) ) ) ; } } int offset = 0 ; int counter = 0 ; for ( RuleMatch rm : matches ) { final List < String > replacements = rm . getSuggestedReplacements ( ) ; if ( ! replacements . isEmpty ( ) ) { if ( errors . get ( counter ) . equals ( sb . substring ( rm . getFromPos ( ) - offset , rm . getToPos ( ) - offset ) ) ) { sb . replace ( rm . getFromPos ( ) - offset , rm . getToPos ( ) - offset , replacements . get ( 0 ) ) ; offset += ( rm . getToPos ( ) - rm . getFromPos ( ) ) - replacements . get ( 0 ) . length ( ) ; } counter ++ ; } } return sb . toString ( ) ; } }
package org . languagetool . commandline ; public class UnknownParameterException extends RuntimeException { public UnknownParameterException ( String message ) { super ( message ) ; } }
package org . languagetool . rules . ro ; import java . util . List ; import java . util . ResourceBundle ; import org . languagetool . AnalyzedToken ; import org . languagetool . AnalyzedTokenReadings ; import org . languagetool . Language ; import org . languagetool . rules . WordRepeatBeginningRule ; public class RomanianWordRepeatBeginningRule extends WordRepeatBeginningRule { public RomanianWordRepeatBeginningRule ( final ResourceBundle messages , final Language language ) { super ( messages , language ) ; } @ Override public String getId ( ) { return "ROMANIAN_WORD_REPEAT_BEGINNING_RULE" ; } protected boolean allowAmbiguousAdverbs ( ) { return false ; } @ Override protected boolean isAdverb ( final AnalyzedTokenReadings token ) { boolean isAdverb = false ; List < AnalyzedToken > readings = token . getReadings ( ) ; for ( AnalyzedToken analyzedToken : readings ) { if ( analyzedToken . getPOSTag ( ) != null ) { if ( analyzedToken . getPOSTag ( ) . startsWith ( "G" ) ) { isAdverb = true ; } else { if ( ! allowAmbiguousAdverbs ( ) ) { return false ; } } } } return isAdverb ; } }
package org . languagetool . rules . ro ; import org . languagetool . language . Romanian ; import org . languagetool . rules . AbstractSimpleReplaceRule2 ; import org . languagetool . rules . Category ; import java . io . IOException ; import java . util . Locale ; import java . util . ResourceBundle ; public class SimpleReplaceRule extends AbstractSimpleReplaceRule2 { public static final String ROMANIAN_SIMPLE_REPLACE_RULE = "RO_SIMPLE_REPLACE" ; private static final String FILE_NAME = "/ro/replace.txt" ; private static final Locale RO_LOCALE = new Locale ( "ro" ) ; @ Override public final String getFileName ( ) { return FILE_NAME ; } public SimpleReplaceRule ( final ResourceBundle messages ) throws IOException { super ( messages , new Romanian ( ) ) ; super . setCategory ( new Category ( messages . getString ( "category_misc" ) ) ) ; } @ Override public final String getId ( ) { return ROMANIAN_SIMPLE_REPLACE_RULE ; } @ Override public String getDescription ( ) { return "Cuvinte sau grupuri de cuvinte incorecte sau ieșite din uz" ; } @ Override public String getShort ( ) { return "Cuvânt incorect sau ieșit din uz" ; } @ Override public String getSuggestion ( ) { return " este incorect sau ieșit din uz, folosiți " ; } @ Override public String getSuggestionsSeparator ( ) { return " sau " ; } @ Override public Locale getLocale ( ) { return RO_LOCALE ; } }
package org . languagetool . tagging . ro ; import org . languagetool . tagging . BaseTagger ; import java . util . Locale ; public class RomanianTagger extends BaseTagger { public RomanianTagger ( ) { super ( "/ro/romanian.dict" , new Locale ( "ro" ) ) ; } RomanianTagger ( String dictPath ) { super ( dictPath , new Locale ( "ro" ) ) ; } @ Override public String getManualAdditionsFileName ( ) { return "/ro/added.txt" ; } }
package org . languagetool . tokenizers . ro ; import java . util . ArrayList ; import java . util . List ; import java . util . StringTokenizer ; import org . languagetool . tokenizers . Tokenizer ; public class RomanianWordTokenizer implements Tokenizer { public RomanianWordTokenizer ( ) { } @ Override public List < String > tokenize ( final String text ) { final List < String > l = new ArrayList < > ( ) ; final StringTokenizer st = new StringTokenizer ( text , "\u0020\u00A0\u115f\u1160\u1680" + "\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007" + "\u2008\u2009\u200A\u200B\u200c\u200d\u200e\u200f" + "\u2028\u2029\u202a\u202b\u202c\u202d\u202e\u202f" + "\u205F\u2060\u2061\u2062\u2063\u206A\u206b\u206c\u206d" + "\u206E\u206F\u3000\u3164\ufeff\uffa0\ufff9\ufffa\ufffb" + ",.;()[]{}!?:\"'’‘„“”…\\/\t\n\r«»<>%°" + "-|=" , true ) ; while ( st . hasMoreElements ( ) ) { l . add ( st . nextToken ( ) ) ; } return l ; } }
package org . languagetool ; import org . languagetool . language . AbstractLanguageConcurrencyTest ; import org . languagetool . language . Spanish ; public class SpanishConcurrencyTest extends AbstractLanguageConcurrencyTest { @ Override protected Language createLanguage ( ) { return new Spanish ( ) ; } @ Override protected String createSampleText ( ) { return "También puede que la página que buscas haya sido borrada." ; } }
package org . languagetool . synthesis . es ; import java . io . IOException ; import java . util . Arrays ; import junit . framework . TestCase ; import org . languagetool . AnalyzedToken ; public class SpanishSynthesizerTest extends TestCase { public final void testSynthesizeStringString ( ) throws IOException { SpanishSynthesizer synth = new SpanishSynthesizer ( ) ; assertEquals ( synth . synthesize ( dummyToken ( "blablabla" ) , "blablabla" ) . length , 0 ) ; assertEquals ( "[temiera, temiese]" , Arrays . toString ( synth . synthesize ( dummyToken ( "temer" ) , "VMSI3S0" ) ) ) ; assertEquals ( "[presidentes]" , Arrays . toString ( synth . synthesize ( dummyToken ( "presidente" ) , "NCMP000" ) ) ) ; assertEquals ( "[contéis]" , Arrays . toString ( synth . synthesize ( dummyToken ( "contar" ) , "VMSP2P0" ) ) ) ; assertEquals ( "[probado]" , Arrays . toString ( synth . synthesize ( dummyToken ( "probar" ) , "VMP00SM" ) ) ) ; assertEquals ( "[probado]" , Arrays . toString ( synth . synthesize ( dummyToken ( "probar" ) , "VMP00SM" , false ) ) ) ; assertEquals ( "[probado]" , Arrays . toString ( synth . synthesize ( dummyToken ( "probar" ) , "VMP00SM" , true ) ) ) ; assertEquals ( "[probando, probado]" , Arrays . toString ( synth . synthesize ( dummyToken ( "probar" ) , "VMP00SM|VMG0000" , true ) ) ) ; } private AnalyzedToken dummyToken ( String tokenStr ) { return new AnalyzedToken ( tokenStr , tokenStr , tokenStr ) ; } }
package org . languagetool . rules . ca ; import junit . framework . TestCase ; import org . languagetool . JLanguageTool ; import org . languagetool . TestTools ; import org . languagetool . language . Catalan ; import org . languagetool . rules . RuleMatch ; import java . io . IOException ; public class SimpleReplaceVerbsRuleTest extends TestCase { private SimpleReplaceVerbsRule rule ; private JLanguageTool langTool ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; rule = new SimpleReplaceVerbsRule ( TestTools . getMessages ( "ca" ) ) ; langTool = new JLanguageTool ( new Catalan ( ) ) ; } public void testRule ( ) throws IOException { RuleMatch [ ] matches = rule . match ( langTool . getAnalyzedSentence ( "abarca" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "abraça" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "abasta" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "agafa" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; assertEquals ( "estreny" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 3 ) ) ; assertEquals ( "comprèn" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 4 ) ) ; assertEquals ( "comprén" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 5 ) ) ; assertEquals ( "inclou" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 6 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "abarcaven" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "abraçaven" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "abastaven" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "agafaven" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; assertEquals ( "estrenyien" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 3 ) ) ; assertEquals ( "comprenien" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 4 ) ) ; assertEquals ( "incloïen" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 5 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "abarquéssim" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "abracéssim" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "antojà" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "passà pel cap" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "passà pel magí" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "antullà" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "alardeaven" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "feien gala" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "feien ostentació" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "alardejo" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "faig gala" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "faig ostentació" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "aclares" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "aclareixes" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "aclarisques" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "aclaresques" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "atossigues" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "acuites" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "apresses" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "dónes pressa" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; assertEquals ( "atabuixes" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 3 ) ) ; assertEquals ( "aclapares" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 4 ) ) ; assertEquals ( "afeixugues" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 5 ) ) ; assertEquals ( "mareges" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 6 ) ) ; assertEquals ( "afanyes" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 7 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "agobiem" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "aclaparem" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "atabalem" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "angoixem" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; assertEquals ( "estressem" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 3 ) ) ; assertEquals ( "(estar) molt a sobre" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 4 ) ) ; assertEquals ( "(cansar) molt" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 5 ) ) ; assertEquals ( "(ser) molt pesat" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 6 ) ) ; matches = rule . match ( langTool . getAnalyzedSentence ( "agobiïs" ) ) ; assertEquals ( 1 , matches . length ) ; assertEquals ( "aclaparis" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 0 ) ) ; assertEquals ( "atabalis" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 1 ) ) ; assertEquals ( "angoixis" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 2 ) ) ; assertEquals ( "estressis" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 3 ) ) ; assertEquals ( "(estar) molt a sobre" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 4 ) ) ; assertEquals ( "(cansar) molt" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 5 ) ) ; assertEquals ( "(ser) molt pesat" , matches [ 0 ] . getSuggestedReplacements ( ) . get ( 6 ) ) ; } }
